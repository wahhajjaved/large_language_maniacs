{"project": "pyrollbar", "commit_sha": "cda4191d332227ec36743c05b543efbf3d0bbc0c", "parent_sha": "03b554cb834c5af35083daa43bf3910068ef768c", "file_path": "rollbar/__init__.py", "project_url": "https://github.com/uploadcare/pyrollbar", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -714,7 +714,7 @@ def _build_werkzeug_request_data(request):\n     }\n \n     if request.get_json():\n-        request_data['body'] = _scrub_request_params(request.json)\n+        request_data['body'] = json.dumps(_scrub_request_params(request.json))\n \n     return request_data\n \n", "before": "request_data [ 'body' ] = _scrub_request_params ( request . json )", "after": "request_data [ 'body' ] = json . dumps ( _scrub_request_params ( request . json ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 32, 3, 67], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 32, 3, 67], [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N0\", [\"identifier:json\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:dumps\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"call\", 3, 32, 3, 67], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "pyrollbar", "commit_sha": "b210dd13bcd18fe5d6d0f6027a657c230d4afeda", "parent_sha": "c0b157919e28a8fb4cda75df1951a9f66cea4dd3", "file_path": "rollbar/__init__.py", "project_url": "https://github.com/uploadcare/pyrollbar", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -745,7 +745,7 @@ def _scrub_request_url(url_string):\n     scrubbed_qs_params = _scrub_obj(qs_params, replacement_character='-')\n \n     # Make sure the keys and values are all utf8-encoded strings\n-    scrubbed_qs_params = dict((_to_str(k), map(_to_str, v)) for k, v in scrubbed_qs_params.items())\n+    scrubbed_qs_params = dict((_to_str(k), list(map(_to_str, v))) for k, v in scrubbed_qs_params.items())\n     scrubbed_qs = urlencode(scrubbed_qs_params, doseq=True)\n \n     scrubbed_url = (url.scheme, url.netloc, url.path, url.params, scrubbed_qs, url.fragment)\n", "before": "scrubbed_qs_params = dict ( ( _to_str ( k ) , map ( _to_str , v ) ) for k , v in scrubbed_qs_params . items ( ) )", "after": "scrubbed_qs_params = dict ( ( _to_str ( k ) , list ( map ( _to_str , v ) ) ) for k , v in scrubbed_qs_params . items ( ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 44, 3, 59], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 44, 3, 59], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 44, 3, 59], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "trac", "commit_sha": "bc1d10f5381b28744f27a8689a519a253dc6098c", "parent_sha": "e0f5fe02f3cc427858addc5017a2ebf3faec612e", "file_path": "trac/ticket/api.py", "project_url": "https://github.com/arielnetworks/trac", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -525,7 +525,7 @@ class TicketSystem(Component):\n \n         >>> from trac.ticket.model import Ticket\n         >>> t = Ticket(env)\n-        >>> t.insert()\n+        >>> int(t.insert())\n         1\n         >>> resource_exists(env, t.resource)\n         True\n", "before": "t . insert ( )", "after": "int ( t . insert ( ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 13, 3, 23], [\"identifier:int\", \"T\"], 0], [\"Insert\", [\"call\", 3, 13, 3, 23], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 13, 3, 23], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "flask-oauthlib", "commit_sha": "56f917d530103abb6b51489075a2d759d6addf3f", "parent_sha": "6ac11dc96693c73e64bc951fd645d06b38bf0242", "file_path": "flask_oauthlib/client.py", "project_url": "https://github.com/underdogio/flask-oauthlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -456,7 +456,7 @@ class OAuthRemoteApp(object):\n         else:\n             assert callback is not None, 'Callback is required OAuth2'\n \n-            params = self.request_token_params or {}\n+            params = dict(self.request_token_params) or {}\n             client = self.make_client()\n \n             scope = params.pop('scope')\n", "before": "params = self . request_token_params or { }", "after": "params = dict ( self . request_token_params ) or { }", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 22, 3, 53], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"identifier:dict\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 3, 22, 3, 47], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "PyPDF2", "commit_sha": "685ff2bed7a2f0cf08aa276e2af4c95c74bbfae6", "parent_sha": "b44f0a0cc15d62eacc8689ed377ffe712e7a1331", "file_path": "PyPDF2/pdf.py", "project_url": "https://github.com/underdogio/PyPDF2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2011,7 +2011,7 @@ class ContentStream(DecodedStreamObject):\n         # multiple StreamObjects to be cat'd together.\n         stream = stream.getObject()\n         if isinstance(stream, ArrayObject):\n-            data = \"\"\n+            data = b_(\"\")\n             for s in stream:\n                 data += s.getObject().getData()\n             stream = BytesIO(data)\n", "before": "data = \"\"", "after": "data = b_ ( \"\" )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 13, 3, 22], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:b_\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"string:\\\"\\\"\", 3, 20, 3, 22], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "nixops", "commit_sha": "3bd019a445760a799c39c0ccd2724f3b44af3992", "parent_sha": "24d62de36ebe5af3afb82146b7b36c52fbe972ea", "file_path": "nixops/backends/hetzner.py", "project_url": "https://github.com/zalora/nixops", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -459,7 +459,7 @@ class HetznerState(MachineState):\n             ipv4, prefix = result\n             iface_attrs[iface] = {\n                 'ipAddress': ipv4,\n-                'prefixLength': prefix,\n+                'prefixLength': int(prefix),\n             }\n \n             # We can't handle Hetzner-specific networking info in test mode.\n", "before": "iface_attrs [ iface ] = { 'ipAddress' : ipv4 , 'prefixLength' : prefix , }", "after": "iface_attrs [ iface ] = { 'ipAddress' : ipv4 , 'prefixLength' : int ( prefix ) , }", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"pair\", 3, 17, 3, 39], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:int\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:prefix\", 3, 33, 3, 39], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "blink-qt", "commit_sha": "8d56ba227330b1f1f1f864fafe04fccfe18aa220", "parent_sha": "e4d9d346b944dde42eb083de89b444c6c25a0ce9", "file_path": "blink/resources.py", "project_url": "https://github.com/kogmbh/blink-qt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ class ApplicationData(object):\n         if cls._cached_directory is None:\n             if platform.system() == 'Darwin':\n                 from Foundation import NSApplicationSupportDirectory, NSSearchPathForDirectoriesInDomains, NSUserDomainMask\n-                cls._cached_directory = NSSearchPathForDirectoriesInDomains(NSApplicationSupportDirectory, NSUserDomainMask, True)[0]\n+                cls._cached_directory = os.path.join(NSSearchPathForDirectoriesInDomains(NSApplicationSupportDirectory, NSUserDomainMask, True)[0], u'Blink')\n             elif platform.system() == 'Windows':\n                 cls._cached_directory = os.path.join(os.environ['APPDATA'], 'Blink').decode(sys.getfilesystemencoding())\n             else:\n", "before": "cls . _cached_directory = NSSearchPathForDirectoriesInDomains ( NSApplicationSupportDirectory , NSUserDomainMask , True ) [ 0 ]", "after": "cls . _cached_directory = os . path . join ( NSSearchPathForDirectoriesInDomains ( NSApplicationSupportDirectory , NSUserDomainMask , True ) [ 0 ] , u'Blink' )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 17, 3, 134], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:join\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"subscript\", 3, 41, 3, 134], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"string:u'Blink'\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4], [\"Insert\", \"N3\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:path\", \"T\"], 2]]"}
{"project": "librosa", "commit_sha": "a5b31cfcf54f5b917b77eea74a35fa7f628214ab", "parent_sha": "3a82d9ac9ac07ee404df3eb14a4f08a02a89bb3f", "file_path": "tests/test_constantq.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ def make_signal(sr, duration, fmax='C8'):\n         fmax = librosa.note_to_hz(fmax) / sr\n \n     return np.sin(np.cumsum(2 * np.pi * np.logspace(np.log10(fmin), np.log10(fmax),\n-                                                    num=duration * sr)))\n+                                                    num=int(duration * sr))))\n \n \n def test_cqt():\n", "before": "return np . sin ( np . cumsum ( 2 * np . pi * np . logspace ( np . log10 ( fmin ) , np . log10 ( fmax ) , num = duration * sr ) ) )", "after": "return np . sin ( np . cumsum ( 2 * np . pi * np . logspace ( np . log10 ( fmin ) , np . log10 ( fmax ) , num = int ( duration * sr ) ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 53, 3, 70], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:int\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"binary_operator\", 3, 57, 3, 70], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "librosa", "commit_sha": "85fd6afe83cd84243710ce52e0a70643358f86ce", "parent_sha": "d49c3febae5cfa5eeccaf8b128d1bafe59346edc", "file_path": "librosa/core.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1013,7 +1013,7 @@ def peak_pick(x, pre_max, post_max, pre_avg, post_avg, delta, wait):\n \n     # Get the maximum of the signal over a sliding window\n     max_length  = pre_max + post_max + 1\n-    max_origin  = np.floor((pre_max - post_max)/2)\n+    max_origin  = int(np.floor((pre_max - post_max)/2))\n     mov_max     = scipy.ndimage.filters.maximum_filter1d(x, max_length, \n                                                             mode='constant', \n                                                             origin=max_origin)\n", "before": "max_origin = np . floor ( ( pre_max - post_max ) / 2 )", "after": "max_origin = int ( np . floor ( ( pre_max - post_max ) / 2 ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 19, 3, 51], [\"identifier:int\", \"T\"], 0], [\"Insert\", [\"call\", 3, 19, 3, 51], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 19, 3, 51], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "pyp-w1-gw-extensible-calculator", "commit_sha": "21a96cd5467ddf85137d757cc5cda34c09bfa0b8", "parent_sha": "43f55c71ea7104db8d6f8625ed28ff46e552ea32", "file_path": "calculator/main.py", "project_url": "https://github.com/ME7ROPOLIS/pyp-w1-gw-extensible-calculator", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -57,7 +57,7 @@ def add_new_operation(calc, operation):\n     if type(operation) != dict:\n         raise InvalidOperation('Given operation is invalid.')\n-    if operation.keys()[0] not in calc[\"operations\"]:\n+    if list(operation.keys())[0] not in calc[\"operations\"]:\n         calc[\"operations\"][operation.keys()[0]] = operation[operation.keys()[0]]\n \n \n", "before": "if operation . keys ( ) [ 0 ] not in calc [ \"operations\" ] : calc [ \"operations\" ] [ operation . keys ( ) [ 0 ] ] = operation [ operation . keys ( ) [ 0 ] ]", "after": "if list ( operation . keys ( ) ) [ 0 ] not in calc [ \"operations\" ] : calc [ \"operations\" ] [ operation . keys ( ) [ 0 ] ] = operation [ operation . keys ( ) [ 0 ] ]", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 2, 8, 2, 24], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 2, 8, 2, 24], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 2, 8, 2, 24], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "mdtraj", "commit_sha": "143f1d9f31a813b0252a13886471c13f836fde40", "parent_sha": "79cf1a6058533e1746c3b79d65f726e99070c6f9", "file_path": "MDTraj/trajectory.py", "project_url": "https://github.com/Eigenstate/mdtraj", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1267,7 +1267,7 @@ class Trajectory(object):\n         if self._topology is not None:\n             self._topology = self._topology.subset(atom_indices)\n-        self._xyz = self.xyz[:,atom_indices]\n+        self._xyz = np.array(self.xyz[:,atom_indices], order='C')\n         return self\n \n \n", "before": "self . _xyz = self . xyz [ : , atom_indices ]", "after": "self . _xyz = np . array ( self . xyz [ : , atom_indices ] , order = 'C' )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 2, 9, 2, 45], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"identifier:np\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:array\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"subscript\", 2, 21, 2, 45], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"keyword_argument\", \"N3\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4], [\"Insert\", \"N3\", [\"identifier:order\", \"T\"], 0], [\"Insert\", \"N3\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N3\", [\"string:'C'\", \"T\"], 2]]"}
{"project": "librosa", "commit_sha": "0b72d380067a9da2e17a18be4f6df473ff00050b", "parent_sha": "c269d500a30d58efd1b31643ab7103f0fd924f29", "file_path": "librosa/filters.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -599,7 +599,7 @@ def constant_q(sr, fmin=None, n_bins=84, bins_per_octave=12, tuning=0.0,\n     if pad_fft:\n         max_len = int(2.0**(np.ceil(np.log2(max_len))))\n     else:\n-        max_len = np.ceil(max_len)\n+        max_len = int(np.ceil(max_len))\n \n     filters = np.asarray([util.pad_center(filt, max_len, **kwargs)\n                           for filt in filters])\n", "before": "max_len = np . ceil ( max_len )", "after": "max_len = int ( np . ceil ( max_len ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 19, 3, 35], [\"identifier:int\", \"T\"], 0], [\"Insert\", [\"call\", 3, 19, 3, 35], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 19, 3, 35], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "librosa", "commit_sha": "d7568fdd030839ef36c5f46eea8d772c459c742e", "parent_sha": "b9a10c05883b533bedf197f42c2c6277e9e0e6e5", "file_path": "librosa/core/pitch.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -154,7 +154,7 @@ def pitch_tuning(frequencies, resolution=0.01, bins_per_octave=12):\n     # from the next tone up.\n     residual[residual >= 0.5] -= 1.0\n \n-    bins = np.linspace(-0.5, 0.5, np.ceil(1./resolution), endpoint=False)\n+    bins = np.linspace(-0.5, 0.5, int(np.ceil(1./resolution)), endpoint=False)\n \n     counts, tuning = np.histogram(residual, bins)\n \n", "before": "bins = np . linspace ( - 0.5 , 0.5 , np . ceil ( 1. / resolution ) , endpoint = False )", "after": "bins = np . linspace ( - 0.5 , 0.5 , int ( np . ceil ( 1. / resolution ) ) , endpoint = False )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 35, 3, 57], [\"identifier:int\", \"T\"], 0], [\"Insert\", [\"call\", 3, 35, 3, 57], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 35, 3, 57], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "mdtraj", "commit_sha": "f0b3e5465be9d53c3e39ceae1128559b5e7c1ac9", "parent_sha": "2f3e86ba7c90ddcdacb906989a6067a522ad876c", "file_path": "MDTraj/tests/test_trajectory.py", "project_url": "https://github.com/Eigenstate/mdtraj", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -265,7 +265,7 @@ def test_restrict_atoms_not_inplace():\n     eq(traj.xyz,  traj_backup.xyz)\n     eq(traj.topology, traj_backup.topology)\n \n-    eq(range(4), [a.index for a in sliced.top.atoms])\n+    eq(list(range(4)), [a.index for a in sliced.top.atoms])\n     eq(sliced.xyz.shape[1], 4)\n     eq(sliced.n_atoms, 4)\n     eq(sliced.n_residues, 1)\n", "before": "eq ( range ( 4 ) , [ a . index for a in sliced . top . atoms ] )", "after": "eq ( list ( range ( 4 ) ) , [ a . index for a in sliced . top . atoms ] )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 8, 3, 16], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 8, 3, 16], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 8, 3, 16], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "desk", "commit_sha": "b2787ea009421bb5d6596755e89154b8b12471e1", "parent_sha": "30368832b443cb8064ca08a9382220d201924f19", "file_path": "desk/plugin/invoice/invoice.py", "project_url": "https://github.com/yvess/desk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -220,7 +220,7 @@ class Invoice(object):\n             months = 0\n         item['months'] = months\n         item['amount'] = months * price\n-        item['tax'] = item['amount'] * self.tax\n+        item['tax'] = round(item['amount'] * self.tax, 1)\n         item['total'] = item['amount'] + item['tax']\n         self.doc['amount'] += item['amount']\n         self.doc['tax'] += item['tax']\n", "before": "item [ 'tax' ] = item [ 'amount' ] * self . tax", "after": "item [ 'tax' ] = round ( item [ 'amount' ] * self . tax , 1 )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 48], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:round\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"binary_operator\", 3, 23, 3, 48], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"integer:1\", \"T\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4]]"}
{"project": "MultiQC", "commit_sha": "f5d560f2c057f65284a3eb0e51fb7ce1854132c2", "parent_sha": "5de47f6262b78678cf2ea7800e81cdf0ceb92d66", "file_path": "multiqc/__init__.py", "project_url": "https://github.com/JAX-GM/MultiQC", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,4 +25,4 @@ class BaseMultiqcModule(object):\n                 l.append(delim.join([''] + h))\n             thesefields = [sn] + [ str(d[sn].get(k, '')) for k in h ]\n             l.append( delim.join( thesefields ) )\n-        return '\\n'.join(l)\n+        return unicode('\\n'.join(l))\n", "before": "return '\\n' . join ( l )", "after": "return unicode ( '\\n' . join ( l ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 16, 3, 28], [\"identifier:unicode\", \"T\"], 0], [\"Insert\", [\"call\", 3, 16, 3, 28], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 28], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "django-ddp", "commit_sha": "33052f48353012434c5b393ba29e006afda4451d", "parent_sha": "250bf0df78d34cb5703bb4eca6472ce6ad30cc34", "file_path": "dddp/models.py", "project_url": "https://github.com/yjmade/django-ddp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -108,7 +108,7 @@ def get_meteor_ids(model, object_ids):\n             object_id__in=list(result)\n         ).values_list('object_id', 'meteor_id')\n     for obj_pk, meteor_id in query:\n-        result[obj_pk] = meteor_id\n+        result[str(obj_pk)] = meteor_id\n     for obj_pk, meteor_id in result.items():\n         if meteor_id is None:\n             result[obj_pk] = get_meteor_id(model, obj_pk)\n", "before": "result [ obj_pk ] = meteor_id", "after": "result [ str ( obj_pk ) ] = meteor_id", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"subscript\", 3, 9, 3, 23], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:obj_pk\", 3, 16, 3, 22], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "holoclean", "commit_sha": "47b31908eae415e227838988a9e7e0827ec35f0f", "parent_sha": "81d186c2e43032d06ce9860315035e704575837d", "file_path": "repair/featurize/featurize.py", "project_url": "https://github.com/HoloClean/holoclean", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,7 +14,7 @@ class FeaturizedDataset:\n             f.setup_featurizer(self.ds, self.total_vars, self.classes, self.processes)\n         tensors = [f.create_tensor() for f in featurizers]\n         # save size info of all featurizers\n-        self.featurizer_info = [(type(featurizers[i]), t.cpu().numpy().shape[2]) for i, t in enumerate(tensors)]\n+        self.featurizer_info = [(str(type(featurizers[i])), t.cpu().numpy().shape[2]) for i, t in enumerate(tensors)]\n         tensor = torch.cat(tensors,2)\n         self.tensor = tensor\n         self.in_features = self.tensor.shape[2]\n", "before": "self . featurizer_info = [ ( type ( featurizers [ i ] ) , t . cpu ( ) . numpy ( ) . shape [ 2 ] ) for i , t in enumerate ( tensors ) ]", "after": "self . featurizer_info = [ ( str ( type ( featurizers [ i ] ) ) , t . cpu ( ) . numpy ( ) . shape [ 2 ] ) for i , t in enumerate ( tensors ) ]", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 34, 3, 54], [\"identifier:str\", \"T\"], 0], [\"Insert\", [\"call\", 3, 34, 3, 54], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 34, 3, 54], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "hyperdock", "commit_sha": "098194623ce383ed3f3afe5a5bbfc10069de3d7c", "parent_sha": "f576a6f89d687287e216de3e51bc553d21b59a4a", "file_path": "hyperdock/common/experiment.py", "project_url": "https://github.com/ErikGartner/hyperdock", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -191,7 +191,7 @@ class Experiment:\n             docker.errors.ImageNotFound,\n         ) as e:\n             self._logger.error(\"Failed to start container:\\n%s\" % e)\n-            self._result = {\"state\": \"fail\", \"msg\": e}\n+            self._result = {\"state\": \"fail\", \"msg\": str(e)}\n             return None\n \n     def _get_environment(self):\n", "before": "self . _result = { \"state\" : \"fail\" , \"msg\" : e }", "after": "self . _result = { \"state\" : \"fail\" , \"msg\" : str ( e ) }", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"pair\", 3, 46, 3, 54], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:e\", 3, 53, 3, 54], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "Mimic", "commit_sha": "b2d38031cf2c6d34e412ff76469cb6168de3c169", "parent_sha": "a3fbc0863f301c132dd8dfd2a079b1ab80252fa5", "file_path": "mimic/scripts/extern/pyqtgraph/widgets/GraphicsView.py", "project_url": "https://github.com/AutodeskRoboticsLab/Mimic", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -362,7 +362,7 @@ class GraphicsView(QtGui.QGraphicsView):\n     def mouseMoveEvent(self, ev):\n         if self.lastMousePos is None:\n             self.lastMousePos = Point(ev.pos())\n-        delta = Point(ev.pos() - self.lastMousePos)\n+        delta = Point(Point(ev.pos()) - self.lastMousePos)\n         self.lastMousePos = Point(ev.pos())\n \n         QtGui.QGraphicsView.mouseMoveEvent(self, ev)\n", "before": "delta = Point ( ev . pos ( ) - self . lastMousePos )", "after": "delta = Point ( Point ( ev . pos ( ) ) - self . lastMousePos )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 23, 3, 31], [\"identifier:Point\", \"T\"], 0], [\"Insert\", [\"call\", 3, 23, 3, 31], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 23, 3, 31], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "cc-utils", "commit_sha": "f34572ca39857b973ef427720393cdb321fd7855", "parent_sha": "11698b3a440a8b8c14908eaa38d4464c0078d929", "file_path": "whd/dispatcher.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -129,7 +129,7 @@ class GithubWebhookDispatcher(object):\n             # XXX hard-code structure of concourse-PR-resource's version dict\n             pr_numbers = map(lambda r: r.version()['pr'], resource_versions)\n \n-            return pr_event.number() in pr_numbers\n+            return str(pr_event.number()) in pr_numbers\n \n         # filter out all resources that are _not_ up-to-date (we only care about those)\n         outdated_resources = [\n", "before": "return pr_event . number ( ) in pr_numbers", "after": "return str ( pr_event . number ( ) ) in pr_numbers", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 20, 3, 37], [\"identifier:str\", \"T\"], 0], [\"Insert\", [\"call\", 3, 20, 3, 37], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 20, 3, 37], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "cc-utils", "commit_sha": "30343859dfed3dd8dd9a08860c10646aeb08da4b", "parent_sha": "e20d9152d323ebbd8a012026098f8fe14150cc20", "file_path": "concourse/steps/notification.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -45,7 +45,7 @@ def job_url(v):\n def determine_previous_build_status(v, cfg_set):\n     concourse_api = from_cfg(cfg_set.concourse(), team_name=v['build-team-name'])\n     try:\n-        build_number = int(v['build-name'])\n+        build_number = int(float(v['build-name']))\n         if build_number < 2:\n             ci.util.info('this seems to be the first build - will notify')\n             return BuildStatus.SUCCEEDED\n", "before": "build_number = int ( v [ 'build-name' ] )", "after": "build_number = int ( float ( v [ 'build-name' ] ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 27, 3, 44], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 27, 3, 44], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 27, 3, 44], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:float\", \"T\"], 0], [\"Move\", \"N0\", [\"argument_list\", 3, 27, 3, 44], 1]]"}
{"project": "geohash-hilbert", "commit_sha": "0bfe4c7cec194dd302d20ab02517acb68531c3e1", "parent_sha": "f63aaffb8ed597ec4a06fd48c97ef591d55ca724", "file_path": "tests/test_utils.py", "project_url": "https://github.com/tammoippen/geohash-hilbert", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ def test_neighbours(bpc, prec):\n         directions = {'north', 'north-east', 'north-west', 'east',\n                       'west', 'south', 'south-east', 'south-west'}\n \n-        assert directions == neighbours.keys()\n+        assert directions == set(neighbours.keys())\n \n         # no duplicates (depends on level)\n         assert len(neighbours) == len(set(neighbours.values()))\n", "before": "assert directions == neighbours . keys ( )", "after": "assert directions == set ( neighbours . keys ( ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 30, 3, 47], [\"identifier:set\", \"T\"], 0], [\"Insert\", [\"call\", 3, 30, 3, 47], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 30, 3, 47], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "FreeCAD_assembly3", "commit_sha": "fb707d71859c6d52c4f4c4b9db2464d45bf1448c", "parent_sha": "05f476c9e4accb42a39f594e161cfea33031b582", "file_path": "constraint.py", "project_url": "https://github.com/realthunder/FreeCAD_assembly3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -454,7 +454,7 @@ class Constraint(ProxyType):\n         if super(Constraint,mcs).onChanged(obj,prop):\n             try:\n                 if obj.Name==obj.Label or \\\n-                   mcs.getType(utils.getLabel(obj)):\n+                   mcs.getType(str(utils.getLabel(obj))):\n                     obj.Label = mcs.getTypeName(obj)\n             except Exception as e:\n                 logger.debug('auto constraint label failed: {}'.format(e))\n", "before": "if obj . Name == obj . Label or mcs . getType ( utils . getLabel ( obj ) ) : obj . Label = mcs . getTypeName ( obj )", "after": "if obj . Name == obj . Label or mcs . getType ( str ( utils . getLabel ( obj ) ) ) : obj . Label = mcs . getTypeName ( obj )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 32, 3, 51], [\"identifier:str\", \"T\"], 0], [\"Insert\", [\"call\", 3, 32, 3, 51], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 32, 3, 51], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "FreeCAD_assembly3", "commit_sha": "4edc0fbca6f148de7a2ddba385d911d38d6dcc29", "parent_sha": "490da825905d9fc06cc43384264428fb04031cc4", "file_path": "freecad/asm3/gui.py", "project_url": "https://github.com/realthunder/FreeCAD_assembly3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -12,7 +12,7 @@ from .FCADLogger import FCADLogger\n \n def _isCommandActive(cmd):\n     try:\n-        return FreeCADGui.Command.isActive(cmd)\n+        return FreeCADGui.Command.isActive(FreeCADGui.Command.get(cmd))\n     except Exception:\n         pass\n     try:\n", "before": "return FreeCADGui . Command . isActive ( cmd )", "after": "return FreeCADGui . Command . isActive ( FreeCADGui . Command . get ( cmd ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 43, 3, 48], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 43, 3, 48], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 43, 3, 48], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Move\", \"N0\", [\"argument_list\", 3, 43, 3, 48], 1], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:get\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:FreeCADGui\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:Command\", \"T\"], 2]]"}
{"project": "WMAS", "commit_sha": "e7d815262e4993341b7326c2970a3fd49ba5ece0", "parent_sha": "5e2237ccc2463179a431a63b70b40fcc3caaa52d", "file_path": "tools/travis/build.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -192,7 +192,7 @@ def main():\n     setup_virtualenv()\n     fetch_submodules()\n     update_dist()\n-    changesets = get_new_commits()\n+    changesets = list(get_new_commits())\n     print >> sys.stderr, \"Building %d changesets:\" % len(changesets)\n     print >> sys.stderr, \"\\n\".join(changesets)\n     if len(changesets) > 50:\n", "before": "changesets = get_new_commits ( )", "after": "changesets = list ( get_new_commits ( ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 18, 3, 35], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 18, 3, 35], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 18, 3, 35], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "pyFlightAnalysis", "commit_sha": "5d15a773003553b0607fb2de45c50b6d9cedf4fc", "parent_sha": "9bc84b47ff142f87bd4b926597eec24f683e8b7c", "file_path": "src/analysis.py", "project_url": "https://github.com/Marxlp/pyFlightAnalysis", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -338,7 +338,7 @@ class MainWindow(QtGui.QMainWindow):\n             start, end = self.ROI_region.getRegion() \n             t = self.current_time + start\n             # emit data\n-            indexes = map(self.getIndex, [self.time_stamp_position, self.time_stamp_attitude, self.time_stamp_output], [t, t, t])\n+            indexes = list(map(self.getIndex, [self.time_stamp_position, self.time_stamp_attitude, self.time_stamp_output], [t, t, t]))\n             state_data = [self.position_history[indexes[0]], \n                           self.attitude_history[indexes[1]], self.output_history[indexes[2]]]\n             self.quadrotorStateChanged.emit(state_data)\n", "before": "indexes = map ( self . getIndex , [ self . time_stamp_position , self . time_stamp_attitude , self . time_stamp_output ] , [ t , t , t ] )", "after": "indexes = list ( map ( self . getIndex , [ self . time_stamp_position , self . time_stamp_attitude , self . time_stamp_output ] , [ t , t , t ] ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 23, 3, 130], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 23, 3, 130], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 23, 3, 130], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "pyMaid", "commit_sha": "5024180cbbabb293fc4858b4804d595f8d853764", "parent_sha": "80300fb1e002c61d94820c3476ba7ec4415a8a24", "file_path": "pymaid/fetch.py", "project_url": "https://github.com/schlegelp/pyMaid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1712,7 +1712,7 @@ def get_connector_details(x, remote_instance=None):\n \r\n     # Depending on DATA_UPLOAD_MAX_NUMBER_FIELDS of your CATMAID server\r\n     # (default = 1000), we have to cut requests into batches smaller than that\r\n-    DATA_UPLOAD_MAX_NUMBER_FIELDS = 50000\r\n+    DATA_UPLOAD_MAX_NUMBER_FIELDS = min( 50000, len(connector_ids) )\r\n \r\n     connectors = []\r\n     with tqdm(total=len(connector_ids), desc='CN details', disable=pbar_hide, leave=pbar_leave) as pbar:\r\n", "before": "DATA_UPLOAD_MAX_NUMBER_FIELDS = 50000", "after": "DATA_UPLOAD_MAX_NUMBER_FIELDS = min ( 50000 , len ( connector_ids ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 5, 3, 42], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:min\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"integer:50000\", 3, 37, 3, 42], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4], [\"Insert\", \"N2\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:connector_ids\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "pyMaid", "commit_sha": "fffa45d3f8504e47c82d0a259814c225a30251ad", "parent_sha": "267d74a99159035a591f3f540549046935b25b49", "file_path": "pymaid/b3d.py", "project_url": "https://github.com/schlegelp/pyMaid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -508,7 +508,7 @@ class handler:\n         scn.objects.active = ob\n         ob.select = True\n \n-        me.from_pydata(list(blender_verts), [], volume.faces)\n+        me.from_pydata(list(blender_verts), [], list(volume.faces))\n         me.update()\n \n         bpy.ops.object.shade_smooth()\n", "before": "me . from_pydata ( list ( blender_verts ) , [ ] , volume . faces )", "after": "me . from_pydata ( list ( blender_verts ) , [ ] , list ( volume . faces ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 23, 3, 62], [\"call\", \"N0\"], 5], [\"Insert\", [\"argument_list\", 3, 23, 3, 62], [\"):)\", \"T\"], 6], [\"Insert\", \"N0\", [\"identifier:list\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 3, 49, 3, 61], 1], [\"Move\", \"N1\", [\"):)\", 3, 61, 3, 62], 2]]"}
{"project": "shut-up-bird", "commit_sha": "b1a3503ae82e4c92de4065b970be8a61b8267a6a", "parent_sha": "6a5132a830286fb34ce2da693b66f373eda53cf4", "file_path": "shut-up-bird.py", "project_url": "https://github.com/petarov/shut-up-bird", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -230,7 +230,7 @@ def archive_add(archive, status, addAuthor=False):\n     c.content = ''\n \n     if addAuthor and status.author:\n-        screen_name = preprocess('@' + status.author._json['screen_name'].encode('utf8'))\n+        screen_name = preprocess('@' + str(status.author._json['screen_name'].encode('utf8')))\n         c.content = \"<h5 align='center'>{0}</h5>\".format(screen_name)\n \n     c.content += preprocess(status.text)\n", "before": "screen_name = preprocess ( '@' + status . author . _json [ 'screen_name' ] . encode ( 'utf8' ) )", "after": "screen_name = preprocess ( '@' + str ( status . author . _json [ 'screen_name' ] . encode ( 'utf8' ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 40, 3, 89], [\"identifier:str\", \"T\"], 0], [\"Insert\", [\"call\", 3, 40, 3, 89], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 40, 3, 89], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "councillor-party", "commit_sha": "8216f4c79aa5e0d4915fa18edf48458b43d8da2f", "parent_sha": "a98e18e1611cce35646d0bcba10616cdc0961616", "file_path": "youtube.py", "project_url": "https://github.com/rbcarson/councillor-party", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -158,7 +158,7 @@ class YoutubeSession(OAuth2Session):\n                 'part': ','.join(video_resource.keys()),\n                 'notifySubscribers': notify_subscribers,\n             }, headers={\n-                'X-Upload-Content-Length': file_size,\n+                'X-Upload-Content-Length': str(file_size),\n                 'X-Upload-Content-Type': 'application/octet-stream',\n             },\n             json=video_resource,\n", "before": "headers = { 'X-Upload-Content-Length' : file_size , 'X-Upload-Content-Type' : 'application/octet-stream' , } ,", "after": "headers = { 'X-Upload-Content-Length' : str ( file_size ) , 'X-Upload-Content-Type' : 'application/octet-stream' , } ,", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"pair\", 3, 17, 3, 53], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:file_size\", 3, 44, 3, 53], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "project_euler", "commit_sha": "e497db636f0e2b2d47efdf7f77fcad40b20329fc", "parent_sha": "512879d5901f5e99261dd297af33b6b7ae0037a4", "file_path": "problem_7/python/problem7_3.py", "project_url": "https://github.com/btv/project_euler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -4,7 +4,7 @@ import math\n \n def is_prime(divided):\n   divisor = 3\n-  sqrt_divided = math.sqrt(divided)\n+  sqrt_divided = int(math.sqrt(divided))\n   while divisor <= sqrt_divided:\n     if divided % divisor == 0:\n       return False\n", "before": "sqrt_divided = math . sqrt ( divided )", "after": "sqrt_divided = int ( math . sqrt ( divided ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 18, 3, 36], [\"identifier:int\", \"T\"], 0], [\"Insert\", [\"call\", 3, 18, 3, 36], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 18, 3, 36], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "angr", "commit_sha": "fb7685d0c980d1f932c02414e7971487943a406d", "parent_sha": "3056aa92552622045b7f902777273cc3ab36314e", "file_path": "simuvex/procedures/libc___so___6/strstr.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ class strstr(simuvex.SimProcedure):\n                     l.debug(\"... exhausted remaining symbolic checks.\")\n                     break\n \n-            cases.append([ self.state.se.And(*exclusions), 0 ])\n+            cases.append([ self.state.se.And(*exclusions), self.state.se.BVV(0, self.state.arch.bits) ])\n             l.debug(\"... created %d cases\", len(cases))\n             r = self.state.se.ite_cases(cases, 0)\n             c = [ self.state.se.Or(*[c for c,_ in cases]) ]\n", "before": "cases . append ( [ self . state . se . And ( * exclusions ) , 0 ] )", "after": "cases . append ( [ self . state . se . And ( * exclusions ) , self . state . se . BVV ( 0 , self . state . arch . bits ) ] )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"list\", 3, 26, 3, 63], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:BVV\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"integer:0\", 3, 60, 3, 61], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N4\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4], [\"Insert\", \"N3\", [\"attribute\", \"N5\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:se\", \"T\"], 2], [\"Insert\", \"N4\", [\"attribute\", \"N6\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:bits\", \"T\"], 2], [\"Insert\", \"N5\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N5\", [\".:.\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:state\", \"T\"], 2], [\"Insert\", \"N6\", [\"attribute\", \"N7\"], 0], [\"Insert\", \"N6\", [\".:.\", \"T\"], 1], [\"Insert\", \"N6\", [\"identifier:arch\", \"T\"], 2], [\"Insert\", \"N7\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N7\", [\".:.\", \"T\"], 1], [\"Insert\", \"N7\", [\"identifier:state\", \"T\"], 2]]"}
{"project": "amazon-scrapy", "commit_sha": "4644aa4238a137068648815e29cc46d732b45c34", "parent_sha": "c67536ab40c02fe4ad4856263c80374de63bfaa8", "file_path": "amazon/amazon/spiders/sales_ranking_spider.py", "project_url": "https://github.com/geosson/amazon-scrapy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,7 +34,7 @@ class SalesRankingSpider(scrapy.Spider):\n             item = SalesRankingItem()\n             key_rank_str = product_detail[0]\n             key_rank_tuple = Helper.get_rank_classify(key_rank_str)\n-            item['rank'] = key_rank_tuple[0]\n+            item['rank'] = Helper.get_num_split_comma(key_rank_tuple[0])\n             item['classify'] = key_rank_tuple[1]\n             item['sk_id'] = response.meta['item']['id']\n             yield item\n", "before": "item [ 'rank' ] = key_rank_tuple [ 0 ]", "after": "item [ 'rank' ] = Helper . get_num_split_comma ( key_rank_tuple [ 0 ] )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 13, 3, 45], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"identifier:Helper\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:get_num_split_comma\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"subscript\", 3, 28, 3, 45], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "ottertune", "commit_sha": "340b327634f4f8b01e9405ba6660405bdc6dc1be", "parent_sha": "4d564956254d4510189b19d01f2c6bceb7aa2b49", "file_path": "client/driver/fabfile.py", "project_url": "https://github.com/master-MR-han/ottertune", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -165,7 +165,7 @@ def loop():\n \n @task\n def run_loops(max_iter=5):\n-    for i in range(max_iter):\n+    for i in range(int(max_iter)):\n         LOG.info('The %s-th Loop Starts / Total Loops %s', i + 1, max_iter)\n         loop()\n         LOG.info('The %s-th Loop Ends / Total Loops %s', i + 1, max_iter)\n", "before": "for i in range ( max_iter ) : LOG . info ( 'The %s-th Loop Starts / Total Loops %s' , i + 1 , max_iter ) loop ( ) LOG . info ( 'The %s-th Loop Ends / Total Loops %s' , i + 1 , max_iter )", "after": "for i in range ( int ( max_iter ) ) : LOG . info ( 'The %s-th Loop Starts / Total Loops %s' , i + 1 , max_iter ) loop ( ) LOG . info ( 'The %s-th Loop Ends / Total Loops %s' , i + 1 , max_iter )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 19, 3, 29], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 19, 3, 29], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 19, 3, 29], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:int\", \"T\"], 0], [\"Move\", \"N0\", [\"argument_list\", 3, 19, 3, 29], 1]]"}
{"project": "CerebralCortex-DataAnalysis", "commit_sha": "92174ae50795c32fb36d0f76aee0f5bfaec8aa6e", "parent_sha": "6386ce6ed32401d4d6277df83686081333066e33", "file_path": "core/feature/beacon/beacon.py", "project_url": "https://github.com/MD2Korg/CerebralCortex-DataAnalysis", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -197,7 +197,7 @@ class BeaconFeatures(ComputeFeatureBase):\n                     if ('1' in items.sample) & ('2' in items.sample):\n                         windowed_data[i, j] = 1\n                     else:\n-                        windowed_data[i, j] = values[0]\n+                        windowed_data[i, j] = int(values[0])\n \n                 else:\n                     windowed_data[i, j] = 0\n", "before": "windowed_data [ i , j ] = values [ 0 ]", "after": "windowed_data [ i , j ] = int ( values [ 0 ] )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 25, 3, 56], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:int\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"subscript\", 3, 47, 3, 56], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "django-pyodbc-azure", "commit_sha": "5c46355d49d586700d62e8663c8ff38f58e0a50c", "parent_sha": "e6eb706e8257cb19e8ce074d40be7ca0af0464ba", "file_path": "sql_server/pyodbc/query.py", "project_url": "https://github.com/mejimaru/django-pyodbc-azure", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -131,7 +131,7 @@ def query_class(QueryClass):\n             values = [self.convert_values(v, None) for v in row[:index_start]]\n             for value, field in map(None, row[index_start:], fields):\n                 values.append(self.convert_values(value, field))\n-            return values\n+            return tuple(values)\n \n         def modify_query(self, strategy, ordering, out_cols):\n", "before": "return values", "after": "return tuple ( values )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 13, 3, 26], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:tuple\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:values\", 3, 20, 3, 26], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "pyhttp", "commit_sha": "dfbeecad8458b75d2fff616f0c23bc840c617203", "parent_sha": "851e01edcc9f938eb3748399a9770a9e82347ce0", "file_path": "httptesting/library/func.py", "project_url": "https://github.com/HttpTesting/pyhttp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -121,7 +121,7 @@ class FUNC(Extend):\n-        lt = eval(lt)\n+        lt = eval(repr(lt))\n         len_list = len(lt) - 1\n         rint = randint(0, len_list)\n         return lt[rint]\n", "before": "lt = eval ( lt )", "after": "lt = eval ( repr ( lt ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 0, 18, 0, 22], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 0, 18, 0, 22], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 0, 18, 0, 22], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:repr\", \"T\"], 0], [\"Move\", \"N0\", [\"argument_list\", 0, 18, 0, 22], 1]]"}
{"project": "OpenNMT-entmax", "commit_sha": "b7356129221ece64081e15ac1a7caf1880c2974c", "parent_sha": "f8867dd75af01180d4c52446499e19d161932953", "file_path": "preprocess.py", "project_url": "https://github.com/deep-spin/OpenNMT-entmax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -74,7 +74,7 @@ def initVocabulary(name, dataFile, vocabFile, vocabSize):\n         print('Reading ' + name + ' vocabulary from \\'' + vocabFile + '\\'...')\n         vocab = onmt.Dict()\n         vocab.loadFile(vocabFile)\n-        print('Loaded ' + vocab.size() + ' ' + name + ' words')\n+        print('Loaded ' + str(vocab.size()) + ' ' + name + ' words')\n \n     if vocab is None:\n         # If a dictionary is still missing, generate it.\n", "before": "print ( 'Loaded ' + vocab . size ( ) + ' ' + name + ' words' )", "after": "print ( 'Loaded ' + str ( vocab . size ( ) ) + ' ' + name + ' words' )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 27, 3, 39], [\"identifier:str\", \"T\"], 0], [\"Insert\", [\"call\", 3, 27, 3, 39], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 27, 3, 39], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "sympy", "commit_sha": "2484d3e42c51b09cf10e15a3923e22bd372c05de", "parent_sha": "8e38534f967da233d0055ed45cdf2f5fc1a4b30f", "file_path": "sympy/functions/elementary/tests/test_trigonometric.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -89,7 +89,7 @@ def test_sin():\n \n     assert sin(pi/8) == sqrt((2 - sqrt(2))/4)\n \n-    assert sin(pi/10) == -1/4 + sqrt(5)/4\n+    assert sin(pi/10) == -S(1)/4 + sqrt(5)/4\n \n     assert sin(pi/12) == -sqrt(2)/4 + sqrt(6)/4\n     assert sin(5*pi/12) == sqrt(2)/4 + sqrt(6)/4\n", "before": "assert sin ( pi / 10 ) == - 1 / 4 + sqrt ( 5 ) / 4", "after": "assert sin ( pi / 10 ) == - S ( 1 ) / 4 + sqrt ( 5 ) / 4", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"unary_operator\", 3, 26, 3, 28], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:S\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"integer:1\", 3, 27, 3, 28], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "sympy", "commit_sha": "211cbc467cddcb3248af7eaa420a99af6342b4a5", "parent_sha": "855193661b0eaa108e3df51980bf51f8f4a9bbdd", "file_path": "sympy/core/tests/test_numbers.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1040,7 +1040,7 @@ def test_isqrt():\n \n     raises(ValueError, lambda: isqrt(-1))\n     raises(ValueError, lambda: isqrt(-10**1000))\n-    raises(ValueError, lambda: -S.Half)\n+    raises(ValueError, lambda: isqrt(-S.Half))\n \n     # Check that using an inaccurate math.sqrt doesn't affect the results.\n     from sympy.core import power\n", "before": "raises ( ValueError , lambda : - S . Half )", "after": "raises ( ValueError , lambda : isqrt ( - S . Half ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"lambda\", 3, 24, 3, 39], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:isqrt\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"unary_operator\", 3, 32, 3, 39], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "osc", "commit_sha": "e89bc8197b05c2724f6881dbb47fe46590c4cf3c", "parent_sha": "b85beda33b386c10c8cc8a7938b0bfe740a7244a", "file_path": "osc/core.py", "project_url": "https://github.com/lethliel/osc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -6325,7 +6325,7 @@ def get_commit_message_template(pac):\n         if pac.status(filename) == 'M':\n             diff += get_source_file_diff(pac.absdir, filename, pac.rev)\n         elif pac.status(filename) == 'A':\n-            f = open(filename, 'r')\n+            f = open(os.path.join(pac.absdir, filename), 'r')\n             for line in f:\n                 diff += '+' + line\n             f.close()\n", "before": "f = open ( filename , 'r' )", "after": "f = open ( os . path . join ( pac . absdir , filename ) , 'r' )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 21, 3, 36], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 21, 3, 36], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 21, 3, 36], [\"):)\", \"T\"], 5], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:join\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"attribute\", \"N4\"], 1], [\"Move\", \"N2\", [\",:,\", 3, 30, 3, 31], 2], [\"Move\", \"N2\", [\"identifier:filename\", 3, 22, 3, 30], 3], [\"Move\", \"N2\", [\"):)\", 3, 35, 3, 36], 4], [\"Insert\", \"N3\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:path\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:pac\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:absdir\", \"T\"], 2]]"}
{"project": "sympy", "commit_sha": "b5b1394050a2f5c1c82e81ceab997e0485e87691", "parent_sha": "9ba613eb3385c9fc63a834efc624595b0d7ac7b7", "file_path": "sympy/plotting/pygletplot/plot_mode_base.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -323,7 +323,7 @@ def _set_style(self, v):\n             for i in self.intervals:\n                 if i.v_steps is None:\n                     continue\n-                step_max = max([step_max, i.v_steps])\n+                step_max = max([step_max, int(i.v_steps)])\n             v = ['both', 'solid'][step_max > 40]\n         #try:\n         if v not in self.styles:\n", "before": "step_max = max ( [ step_max , i . v_steps ] )", "after": "step_max = max ( [ step_max , int ( i . v_steps ) ] )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"list\", 3, 32, 3, 53], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:int\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 3, 43, 3, 52], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "sympy", "commit_sha": "4f6ce01fcb258a3183c3db14ca7c6a7b7db4a3d2", "parent_sha": "b425652464523e13ba3f52c69422b0d1170db36f", "file_path": "sympy/utilities/tests/test_code_quality.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -179,7 +179,7 @@ def test_this_file(fname, test_file):\n             if gen_raise_re.search(line):\n                 assert False, message_gen_raise % (fname, idx + 1)\n             if (implicit_test_re.search(line) and\n-                    not filter(lambda ex: ex in fname, import_exclude)):\n+                    not list(filter(lambda ex: ex in fname, import_exclude))):\n                 assert False, message_implicit % (fname, idx + 1)\n             if func_is_re.search(line) and not test_file_re.search(fname):\n                 assert False, message_func_is % (fname, idx + 1)\n", "before": "if ( implicit_test_re . search ( line ) and not filter ( lambda ex : ex in fname , import_exclude ) ) : assert False , message_implicit % ( fname , idx + 1 )", "after": "if ( implicit_test_re . search ( line ) and not list ( filter ( lambda ex : ex in fname , import_exclude ) ) ) : assert False , message_implicit % ( fname , idx + 1 )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 25, 3, 71], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 25, 3, 71], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 25, 3, 71], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "sympy", "commit_sha": "db60703f06de5e1c5244161214596b6feb19e982", "parent_sha": "e63feae4618f954c434f8748ca5e9fefb7efc29b", "file_path": "sympy/stats/stochastic_process_types.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -152,7 +152,7 @@ def joint_distribution(self, *args):\n             return JointDistribution(*args)\n         # TODO: Add tests for the below part of the method, when implementation of Bernoulli Process\n         # is completed\n-        pdf = Lambda(args,\n+        pdf = Lambda(tuple(args),\n                     expr=Mul.fromiter(arg.pspace.process._pdf(arg) for arg in args))\n         return JointDistributionHandmade(pdf)\n \n", "before": "pdf = Lambda ( args , expr = Mul . fromiter ( arg . pspace . process . _pdf ( arg ) for arg in args ) )", "after": "pdf = Lambda ( tuple ( args ) , expr = Mul . fromiter ( arg . pspace . process . _pdf ( arg ) for arg in args ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 21, 4, 85], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:tuple\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:args\", 3, 22, 3, 26], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "sympy", "commit_sha": "31e0f858e44e30c9aedf767db8ef215f421b9f49", "parent_sha": "d5c302fa6deb694537c67caf451f5551a1565425", "file_path": "sympy/matrices/expressions/tests/test_permutation.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,6 +16,6 @@ def test_inputs():\n \n def test_matrix_interaction():\n     P = PermutationMatrix((1, 2, 0))\n-    assert P*Matrix(3, 3, range(9)) == Matrix([[3, 4, 5],\n-                                               [6, 7, 8],\n-                                               [0, 1, 2]])\n+    assert Matrix(P*Matrix(3, 3, range(9))) == Matrix([[3, 4, 5],\n+                                                       [6, 7, 8],\n+                                                       [0, 1, 2]])\n", "before": "assert P * Matrix ( 3 , 3 , range ( 9 ) ) == Matrix ( [ [ 3 , 4 , 5 ] , [ 6 , 7 , 8 ] , [ 0 , 1 , 2 ] ] )", "after": "assert Matrix ( P * Matrix ( 3 , 3 , range ( 9 ) ) ) == Matrix ( [ [ 3 , 4 , 5 ] , [ 6 , 7 , 8 ] , [ 0 , 1 , 2 ] ] )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 5, 59], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"identifier:Matrix\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"binary_operator\", 3, 12, 3, 36], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "sympy", "commit_sha": "3b8777c6f0428752738359145f0d4d6342247a60", "parent_sha": "1b8c8af37b5b9ea5ca3dfb9ab5e3ded0c141e10d", "file_path": "sympy/functions/elementary/piecewise.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1127,7 +1127,7 @@ def piecewise_simplify_arguments(expr, **kwargs):\n \n def piecewise_simplify(expr, **kwargs):\n     expr = piecewise_simplify_arguments(expr, **kwargs)\n-    args = expr.args\n+    args = list(expr.args)\n \n     _blessed = lambda e: getattr(e.lhs, '_diff_wrt', False) and (\n         getattr(e.rhs, '_diff_wrt', None) or\n", "before": "args = expr . args", "after": "args = list ( expr . args )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 5, 3, 21], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:list\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 3, 12, 3, 21], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "RxPY", "commit_sha": "743d3b5f05d9b7a56b4eaf12c9bd6aa3039501e8", "parent_sha": "f038686d5bc443ef682785d7772622e9a5da8070", "file_path": "rx/testing/reactivetest.py", "project_url": "https://github.com/mako-taco/RxPY", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ def is_prime(i):\n     if i <= 1:\n         return False\n     \n-    max = math.floor(math.sqrt(i))\n+    max = int(math.floor(math.sqrt(i)))\n     for j in range(2, max+1):\n         if not (i % j):\n             return False\n", "before": "max = math . floor ( math . sqrt ( i ) )", "after": "max = int ( math . floor ( math . sqrt ( i ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 11, 3, 35], [\"identifier:int\", \"T\"], 0], [\"Insert\", [\"call\", 3, 11, 3, 35], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 11, 3, 35], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "course-discovery", "commit_sha": "62d340380ea01faa274b32d3d5a89feea504a4c2", "parent_sha": "26a1bb4455cdf509f0bd449c43658c612b5af60d", "file_path": "course_discovery/apps/api/v1/views/courses.py", "project_url": "https://github.com/EDUlib/course-discovery", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -269,7 +269,7 @@ class CourseViewSet(CompressedCacheResponseMixin, viewsets.ModelViewSet):\n             data = {'mode': entitlement_type.slug, 'price': price}\n             serializer = CourseEntitlementSerializer(entitlement, data=data, partial=partial)\n             serializer.is_valid(raise_exception=True)\n-            return serializer.save(), entitlement.price != price\n+            return serializer.save(), entitlement.price != float(price)\n         else:\n             return (CourseEntitlement.objects.create(\n                 course=course,\n", "before": "return serializer . save ( ) , entitlement . price != price", "after": "return serializer . save ( ) , entitlement . price != float ( price )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 39, 3, 65], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:float\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:price\", 3, 60, 3, 65], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "RxPY", "commit_sha": "999e5ca4205741e66e5c365ddb0e5b31ec41715b", "parent_sha": "28798a6e8b32561c709b2d76a1724a470007343e", "file_path": "rx/linq/observable/timer.py", "project_url": "https://github.com/mako-taco/RxPY", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -46,7 +46,7 @@ def observable_timer_date_and_period(duetime, period, scheduler):\n                 now = scheduler.now()\n                 d[0] = d[0] + scheduler.to_timedelta(p)\n                 if d[0] <= now:\n-                    d[0] = now + p\n+                    d[0] = now + scheduler.to_timedelta(p)\n \n             observer.on_next(count[0])\n             count[0] += 1\n", "before": "d [ 0 ] = now + p", "after": "d [ 0 ] = now + scheduler . to_timedelta ( p )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 28, 3, 35], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"identifier:scheduler\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:to_timedelta\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"identifier:p\", 3, 34, 3, 35], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "RxPY", "commit_sha": "093ce5b6c991b37e9b533bd305e43922190842b3", "parent_sha": "d03e22803340b33479f0753e9aa564b7e298711b", "file_path": "rx/linq/observable/fromcallback.py", "project_url": "https://github.com/mako-taco/RxPY", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ class ObservableFromCallback(Observable):\n             arguments = list(args)\n             def subscribe(observer):\n                 def handler(*args):\n-                    results = args\n+                    results = list(args)\n                     if selector:\n                         try:\n                             results = selector(args)\n", "before": "results = args", "after": "results = list ( args )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 21, 3, 35], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:list\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:args\", 3, 31, 3, 35], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "2017-10-03-riverclub", "commit_sha": "fc98097b0eb67b895f57c41208f82499cbcdb8fa", "parent_sha": "3c28d16e4ca4a5fde52e46120d3ea408f8e57e08", "file_path": "bin/util.py", "project_url": "https://github.com/CTPUG/2017-10-03-riverclub", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -51,7 +51,7 @@ class Reporter(object):\n \n         if not self.messages:\n             return\n-        for m in self.messages:\n+        for m in sorted(self.messages):\n             print(m, file=stream)\n \n \n", "before": "for m in self . messages : print ( m , file = stream )", "after": "for m in sorted ( self . messages ) : print ( m , file = stream )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"for_statement\", 3, 9, 4, 34], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:sorted\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 3, 18, 3, 31], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "flower", "commit_sha": "9a2c0975f525495c14bff7cb40e733fc7fa11fe0", "parent_sha": "b571736a80aff3bc881eb346f7ccc541c78286cb", "file_path": "flower/views/tasks.py", "project_url": "https://github.com/Rocket-amphora/flower", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ class TasksDataTable(BaseHandler):\n         tasks = sorted(iter_tasks(app.events, search=search),\n                        key=lambda x: getattr(x[1], sort_by),\n                        reverse=sort_order)\n-        tasks = map(self.format_task, tasks)\n+        tasks = list(map(self.format_task, tasks))\n         filtered_tasks = []\n         i = 0\n         for _, task in tasks:\n", "before": "tasks = map ( self . format_task , tasks )", "after": "tasks = list ( map ( self . format_task , tasks ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 17, 3, 45], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 17, 3, 45], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 17, 3, 45], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "flower", "commit_sha": "b66706dcd4202c7573ba6cdee2a07b6186cbe088", "parent_sha": "3a59fc9b47ab0e5cf6d21f93e6a331c434c81764", "file_path": "flower/views/dashboard.py", "project_url": "https://github.com/Rocket-amphora/flower", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ class DashboardView(BaseHandler):\n             workers[name] = info\n \n         if json:\n-            self.write(dict(data=workers.values()))\n+            self.write(dict(data=list(workers.values())))\n         else:\n             self.render(\"dashboard.html\", workers=workers, broker=broker)\n \n", "before": "self . write ( dict ( data = workers . values ( ) ) )", "after": "self . write ( dict ( data = list ( workers . values ( ) ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 34, 3, 50], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 34, 3, 50], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 34, 3, 50], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "isida", "commit_sha": "45037e1d9a4f90f10c950a6fd7d533038b2bc834", "parent_sha": "7ccf390bccc2f57d17f1a47cc8cc3a919f7d0849", "file_path": "plugins/googleplus.py", "project_url": "https://github.com/cobrab11/isida", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -50,7 +50,7 @@ def define_message(room,jid,nick,type,text):\n \t\tif (room,'define') in cof: return\n \t\ttmppos = arr_semi_find(confbase, room)\n \t\tnowname = getResourse(confbase[tmppos])\n-\t\ttext = re.sub('^%s[,:]\\ ' % nowname, '', text.strip())\n+\t\ttext = re.sub('^%s[,:]\\ ' % re.escape(nowname), '', text.strip())\n \t\twhat = re.search([u'^(?:(?:\u0447\u0442\u043e \u0442\u0430\u043a\u043e\u0435)|(?:\u043a\u0442\u043e \u0442\u0430\u043a\u043e\u0439)) ([^?]+?)\\?$',u'(?:(?:\u0447\u0442\u043e \u0442\u0430\u043a\u043e\u0435)|(?:\u043a\u0442\u043e \u0442\u0430\u043a\u043e\u0439)) ([^?]+?)\\?'][s=='partial'], text, re.I+re.U+re.S)\n \t\tif what:\n \t\t\taccess_mode = get_level(room,nick)[0]\n", "before": "text = re . sub ( '^%s[,:]\\ ' % nowname , '' , text . strip ( ) )", "after": "text = re . sub ( '^%s[,:]\\ ' % re . escape ( nowname ) , '' , text . strip ( ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 17, 3, 38], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"identifier:re\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:escape\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"identifier:nowname\", 3, 31, 3, 38], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "isida", "commit_sha": "49f481090e6c7403c6cb51cf59c00cdde2c9748f", "parent_sha": "d700496812799465f77f10e8752ba45bc6dd28fd", "file_path": "plugins/google.py", "project_url": "https://github.com/cobrab11/isida", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -81,7 +81,7 @@ def translate(type, jid, nick,text):\n \t\t\t\turl = u'http://ajax.googleapis.com/ajax/services/language/translate?v=1.0&%s'.encode(\"utf-8\") % (query)\r\n \t\t\t\tsearch_results = urllib.urlopen(url)\r\n \t\t\t\tjson = simplejson.loads(search_results.read())\r\n-\t\t\t\tmsg = json['responseData']['translatedText']\r\n+\t\t\t\tmsg = rss_replace(json['responseData']['translatedText'])\r\n \t\t\telse: msg = u'\u041d\u0435\u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e \u0443\u043a\u0430\u0437\u0430\u043d \u044f\u0437\u044b\u043a \u0438\u043b\u0438 \u043d\u0435\u0442 \u0442\u0435\u043a\u0441\u0442\u0430 \u0434\u043b\u044f \u043f\u0435\u0440\u0435\u0432\u043e\u0434\u0430. tr list - \u0434\u043e\u0441\u0442\u0443\u043f\u043d\u044b\u0435 \u044f\u0437\u044b\u043a\u0438'\r\n \t\telse: msg = u'\u0424\u043e\u0440\u043c\u0430\u0442 \u043a\u043e\u043c\u0430\u043d\u0434\u044b: tr \u0441_\u043a\u0430\u043a\u043e\u0433\u043e \u043d\u0430_\u043a\u0430\u043a\u043e\u0439 \u0442\u0435\u043a\u0441\u0442'\r\n \tsend_msg(type, jid, nick, msg)\r\n", "before": "msg = json [ 'responseData' ] [ 'translatedText' ]", "after": "msg = rss_replace ( json [ 'responseData' ] [ 'translatedText' ] )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 5, 3, 49], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:rss_replace\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"subscript\", 3, 11, 3, 49], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "isida", "commit_sha": "1acb618a85450eef7c83b24da39817bed6675374", "parent_sha": "ea4016c987d9b7d815e657e49094346f2e4d619e", "file_path": "plugins/karma.py", "project_url": "https://github.com/cobrab11/isida", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ def karma_change(room,jid,nick,type,text,value):\n \t\tk_aff = get_affiliation(room,nick)\r\n \t\tk_acc = get_access(room,nick)[0]\r\n \t\tif k_acc < 0: return\r\n-\t\tif k_aff != 'none' or k_acc > 0 or karma_get_access(room,jid):\r\n+\t\tif k_aff != 'none' or k_acc > 0 or karma_get_access(room,getRoom(jid)):\r\n \t\t\tjid, karmajid = getRoom(jid), getRoom(get_access(room,text)[1])\r\n \t\t\tif karmajid == getRoom(selfjid): return\r\n \t\t\telif karmajid == 'None': msg = L('You can\\'t change karma in outdoor conference!')\r\n", "before": "if k_aff != 'none' or k_acc > 0 or karma_get_access ( room , jid ) : jid , karmajid = getRoom ( jid ) , getRoom ( get_access ( room , text ) [ 1 ] ) if karmajid == getRoom ( selfjid ) : return elif karmajid == 'None' : msg = L ( 'You can\\'t change karma in outdoor conference!' )", "after": "if k_aff != 'none' or k_acc > 0 or karma_get_access ( room , getRoom ( jid ) ) : jid , karmajid = getRoom ( jid ) , getRoom ( get_access ( room , text ) [ 1 ] ) if karmajid == getRoom ( selfjid ) : return elif karmajid == 'None' : msg = L ( 'You can\\'t change karma in outdoor conference!' )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 54, 3, 64], [\"call\", \"N0\"], 3], [\"Insert\", [\"argument_list\", 3, 54, 3, 64], [\"):)\", \"T\"], 4], [\"Insert\", \"N0\", [\"identifier:getRoom\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:jid\", 3, 60, 3, 63], 1], [\"Move\", \"N1\", [\"):)\", 3, 63, 3, 64], 2]]"}
{"project": "dosenet-raspberrypi", "commit_sha": "ee58c0afc0c5c64938694554e33428ebc819abfb", "parent_sha": "e53512543814089bae210b1732bb124ddbcbab39", "file_path": "GUI.py", "project_url": "https://github.com/ludicao/dosenet-raspberrypi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -79,7 +79,7 @@ def weather_plot(btn):\n     \n     def ok(btn):\n         user_file=app.getOptionBox(\"Files\")\n-        n_merge=app.getEntry(\"n\")\n+        n_merge=int(app.getEntry(\"n\"))\n         row_counter=0\n         results = csv.reader(open(user_file), delimiter=',')\n \n", "before": "n_merge = app . getEntry ( \"n\" )", "after": "n_merge = int ( app . getEntry ( \"n\" ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 17, 3, 34], [\"identifier:int\", \"T\"], 0], [\"Insert\", [\"call\", 3, 17, 3, 34], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 17, 3, 34], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "dosenet-raspberrypi", "commit_sha": "2dbc8a0d2ed7d0cfa264490b8ae9cd9cc7972145", "parent_sha": "e5559abce5377d468de3ce4e3adff766976fcfaf", "file_path": "weather_DAQ.py", "project_url": "https://github.com/ludicao/dosenet-raspberrypi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -138,7 +138,7 @@ class weather_DAQ(object):\n                 row_counter+=1\n \n             ndata = len(degrees_list)\n-            nsum_data = int(ndata/n_merge)\n+            nsum_data = int(ndata/int(n_merge))\n \n             for i in range(nsum_data):\n                 itemp = degrees_list[i*n_merge:(i+1)*n_merge]\n", "before": "nsum_data = int ( ndata / n_merge )", "after": "nsum_data = int ( ndata / int ( n_merge ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 29, 3, 42], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:int\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:n_merge\", 3, 35, 3, 42], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "InstaPy", "commit_sha": "967856b48a0c4d836cc7ba1d78428fd340e58c8b", "parent_sha": "9c7f432df39b81192377d6fc0de8099f6256ddf5", "file_path": "instapy/util.py", "project_url": "https://github.com/anyulled/InstaPy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -926,7 +926,7 @@ def highlight_print(username=None, message=None, priority=None, level=None, logg\n \n \n     if show_logs == True:\n-        print(\"\\n{}\".format(upper_char * ceil(output_len/len(upper_char))))\n+        print(\"\\n{}\".format(upper_char * int(ceil(output_len/len(upper_char)))))\n \n     if level == \"info\":\n         logger.info(message)\n", "before": "print ( \"\\n{}\" . format ( upper_char * ceil ( output_len / len ( upper_char ) ) ) )", "after": "print ( \"\\n{}\" . format ( upper_char * int ( ceil ( output_len / len ( upper_char ) ) ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 42, 3, 74], [\"identifier:int\", \"T\"], 0], [\"Insert\", [\"call\", 3, 42, 3, 74], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 42, 3, 74], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "InstaPy", "commit_sha": "b8aa167b0ae05f07e276f9004317585167ee4b3d", "parent_sha": "3e31df0d02c035a62334ff0ad90229fa72929114", "file_path": "instapy/util.py", "project_url": "https://github.com/anyulled/InstaPy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -926,7 +926,7 @@ def highlight_print(username=None, message=None, priority=None, level=None, logg\n \n \n     if show_logs == True:\n-        print(\"\\n{}\".format(upper_char * ceil(output_len/len(upper_char))))\n+        print(\"\\n{}\".format(upper_char * int(ceil(output_len/len(upper_char)))))\n \n     if level == \"info\":\n         logger.info(message)\n", "before": "print ( \"\\n{}\" . format ( upper_char * ceil ( output_len / len ( upper_char ) ) ) )", "after": "print ( \"\\n{}\" . format ( upper_char * int ( ceil ( output_len / len ( upper_char ) ) ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 42, 3, 74], [\"identifier:int\", \"T\"], 0], [\"Insert\", [\"call\", 3, 42, 3, 74], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 42, 3, 74], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "isida", "commit_sha": "1f390ba54f2c406e4a2b503788df338cd6a14e3c", "parent_sha": "eaf1aed834a8c2fdcdda406281314235f02185af", "file_path": "plugins/invite.py", "project_url": "https://github.com/cobrab11/isida", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,7 +16,7 @@ def call_body(type, jid, nick, text):\n \t\t\twhojid = getRoom(str(fnd[0][0]))\n \t\t\tis_found = 0\n \t\t\tfor tmp in megabase:\n-\t\t\t\tif tmp[0] == jid and tmp[4] == whojid:\n+\t\t\t\tif tmp[0] == jid and getRoom(tmp[4]) == whojid:\n \t\t\t\t\tis_found = 1\n \t\t\t\t\tbreak\n \t\t\tif is_found:\n", "before": "if tmp [ 0 ] == jid and tmp [ 4 ] == whojid : is_found = 1 break", "after": "if tmp [ 0 ] == jid and getRoom ( tmp [ 4 ] ) == whojid : is_found = 1 break", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 26, 3, 42], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"identifier:getRoom\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"subscript\", 3, 26, 3, 32], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "folium", "commit_sha": "154f0a52827223175295d77f7bdd94ca9df6f8e5", "parent_sha": "8f1cef296e49eb438f0e7c9201f0f4c6d776f030", "file_path": "folium/folium.py", "project_url": "https://github.com/rdd9999/folium", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -243,7 +243,7 @@ class Map(object):\n \n         data_string = ''\n         for i, layer in enumerate(self.added_layers):\n-            name = layer.keys()[0]\n+            name = list(layer.keys())[0]\n             data_string+='\\\"'\n             data_string+=name\n             data_string+='\\\"'\n", "before": "name = layer . keys ( ) [ 0 ]", "after": "name = list ( layer . keys ( ) ) [ 0 ]", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 20, 3, 32], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 20, 3, 32], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 20, 3, 32], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "InstaPy", "commit_sha": "56930b67d866a7834e83a2437e9e3019d93a844f", "parent_sha": "708f0c580fd40126aaaaf9084da0aa903f7fde9d", "file_path": "instapy/instapy.py", "project_url": "https://github.com/anyulled/InstaPy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -295,7 +295,7 @@ class InstaPy:\n             # Proxy for chrome\n             if self.proxy_address and self.proxy_port:\n                 prox = Proxy()\n-                proxy = \":\".join([self.proxy_address, self.proxy_port])\n+                proxy = \":\".join([self.proxy_address, str(self.proxy_port)])\n                 prox.proxy_type = ProxyType.MANUAL\n                 prox.http_proxy = proxy\n                 prox.socks_proxy = proxy\n", "before": "proxy = \":\" . join ( [ self . proxy_address , self . proxy_port ] )", "after": "proxy = \":\" . join ( [ self . proxy_address , str ( self . proxy_port ) ] )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"list\", 3, 34, 3, 71], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 3, 55, 3, 70], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "flutterfuck", "commit_sha": "877839a48a3a2805b08627ddac2e2bea95621259", "parent_sha": "c33f8f1f90d8ead489491edf74fb10fd71692009", "file_path": "willie/modules/wikipedia.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ def mw_snippet(server, query):\n \n     # For some reason, the API gives the page *number* as the key, so we just\n     # grab the first page number in the results.\n-    snippet = snippet[snippet.keys()[0]]\n+    snippet = snippet[list(snippet.keys())[0]]\n \n     return snippet['extract']\n \n", "before": "snippet = snippet [ snippet . keys ( ) [ 0 ] ]", "after": "snippet = snippet [ list ( snippet . keys ( ) ) [ 0 ] ]", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 23, 3, 37], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 23, 3, 37], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 23, 3, 37], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "flutterfuck", "commit_sha": "8db788b497027baa0ca2495e3b5b76b87b8d2268", "parent_sha": "923621fc685336f94a85149fbe0a4e20e93e3348", "file_path": "willie/modules/github.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -158,7 +158,7 @@ def findIssue(bot, trigger):\n         else:\n             return bot.reply('What are you searching for?')\n     else:\n-        URL = 'https://api.github.com/legacy/issues/search/%s/open/%s' % (gitAPI[1], trigger.group(2))\n+        URL = 'https://api.github.com/legacy/issues/search/%s/open/%s' % (gitAPI[1], web.quote(trigger.group(2)))\n \n     try:\n         raw = web.get(URL)\n", "before": "else : URL = 'https://api.github.com/legacy/issues/search/%s/open/%s' % ( gitAPI [ 1 ] , trigger . group ( 2 ) )", "after": "else : URL = 'https://api.github.com/legacy/issues/search/%s/open/%s' % ( gitAPI [ 1 ] , web . quote ( trigger . group ( 2 ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 86, 3, 102], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 86, 3, 102], [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N0\", [\"identifier:web\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:quote\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"call\", 3, 86, 3, 102], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "sopel-extras", "commit_sha": "02d3a1a77856f0229394c0925b2d07c0d4ffa200", "parent_sha": "1ac7102a4b97e17b957148a6c498cec4e2f61515", "file_path": "bookie.py", "project_url": "https://github.com/CoRD-Dev/sopel-extras", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -166,7 +166,7 @@ def api_bmark(bot, trigger, found_match=None):\n                                        bot.config.bookie.api_key )\n     if title:\n         data = {u'url': match,\n-                u'is_private': bot.config.bookie.private,\n+                u'is_private': int(bot.config.bookie.private),\n                 u'description': title.encode('utf-8')}\n         bot.debug('bookie', 'submitting %s with title %s to %s with data %s' % (match,\n                                                                                 repr(title),\n", "before": "data = { u'url' : match , u'is_private' : bot . config . bookie . private , u'description' : title . encode ( 'utf-8' ) }", "after": "data = { u'url' : match , u'is_private' : int ( bot . config . bookie . private ) , u'description' : title . encode ( 'utf-8' ) }", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"pair\", 3, 17, 3, 57], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:int\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 3, 32, 3, 57], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "flutterfuck", "commit_sha": "8518ecbb9709dc9960a1df28dabf1ce3b7cf3dd4", "parent_sha": "b0328980ad4c20fdd733d9967e136ac97d64a6cf", "file_path": "willie/test_tools.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -128,7 +128,7 @@ def get_example_test(tested_func, msg, results, privmsg, admin,\n         for _i in range(repeat):\n             wrapper = MockWillieWrapper(bot, origin)\n             tested_func(wrapper, trigger)\n-            wrapper.output = filter(isnt_ignored, wrapper.output)\n+            wrapper.output = list(filter(isnt_ignored, wrapper.output))\n             assert len(wrapper.output) == len(results)\n             for result, output in zip(results, wrapper.output):\n                 if type(output) is bytes:\n", "before": "wrapper . output = filter ( isnt_ignored , wrapper . output )", "after": "wrapper . output = list ( filter ( isnt_ignored , wrapper . output ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 30, 3, 66], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 30, 3, 66], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 30, 3, 66], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "flutterfuck", "commit_sha": "0a2467f5262998826c21b13aa6a83934001ca170", "parent_sha": "beed2e7843114b62cbb6582daf45faad98501603", "file_path": "willie/modules/unicode_info.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ def codepoint(bot, trigger):\n     # Get the hex value for the code point, and drop the 0x from the front\n     point = str(hex(ord(u'' + arg)))[2:]\n     # Make the hex 4 characters long with preceding 0s, and all upper case\n-    point = point.rjust(4, '0').upper()\n+    point = point.rjust(4, str('0')).upper()\n     try:\n         name = unicodedata.name(arg)\n     except ValueError:\n", "before": "point = point . rjust ( 4 , '0' ) . upper ( )", "after": "point = point . rjust ( 4 , str ( '0' ) ) . upper ( )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 24, 3, 32], [\"call\", \"N0\"], 3], [\"Insert\", [\"argument_list\", 3, 24, 3, 32], [\"):)\", \"T\"], 4], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"string:'0'\", 3, 28, 3, 31], 1], [\"Move\", \"N1\", [\"):)\", 3, 31, 3, 32], 2]]"}
{"project": "pokeminer", "commit_sha": "c9098620d8026ed0402c4c07dc61a765d7c45cfd", "parent_sha": "e8f92c2a5c8e4ea98f28f7263de527ea1d35c503", "file_path": "example.py", "project_url": "https://github.com/pogosandbox/pokeminer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -486,7 +486,7 @@ def main():\n             pid = str(poke.pokemon.PokemonId)\n             label = (\n                         '<div style=\\'position:float; top:0;left:0;\\'><small><a href=\\'http://www.pokemon.com/us/pokedex/'+pid+'\\' target=\\'_blank\\' title=\\'View in Pokedex\\'>#'+pid+'</a></small> - <b>'+pokemonsJSON[poke.pokemon.PokemonId - 1]['Name']+'</b></div>'\n-                        '<center class=\"label-countdown\" data-disappears-at=\"'+disappear_timestamp+'\">'+disappears_at+'</center>'\n+                        '<center class=\"label-countdown\" data-disappears-at=\"'+ str(disappear_timestamp)+'\">'+disappears_at+'</center>'\n                     )\n             if args.china:\n                 poke.Latitude, poke.Longitude = transform_from_wgs_to_gcj(Location(poke.Latitude, poke.Longitude))\n", "before": "label = ( '<div style=\\'position:float; top:0;left:0;\\'><small><a href=\\'http://www.pokemon.com/us/pokedex/' + pid + '\\' target=\\'_blank\\' title=\\'View in Pokedex\\'>#' + pid + '</a></small> - <b>' + pokemonsJSON [ poke . pokemon . PokemonId - 1 ] [ 'Name' ] + '</b></div>' '<center class=\"label-countdown\" data-disappears-at=\"' + disappear_timestamp + '\">' + disappears_at + '</center>' )", "after": "label = ( '<div style=\\'position:float; top:0;left:0;\\'><small><a href=\\'http://www.pokemon.com/us/pokedex/' + pid + '\\' target=\\'_blank\\' title=\\'View in Pokedex\\'>#' + pid + '</a></small> - <b>' + pokemonsJSON [ poke . pokemon . PokemonId - 1 ] [ 'Name' ] + '</b></div>' '<center class=\"label-countdown\" data-disappears-at=\"' + str ( disappear_timestamp ) + '\">' + disappears_at + '</center>' )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"binary_operator\", 2, 25, 3, 99], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:disappear_timestamp\", 3, 80, 3, 99], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "django-floppyforms", "commit_sha": "ba43f3abd29027b33820b03118eaaa004b78b678", "parent_sha": "57d86dc80e80b94c40501fe97b1d89c517930a43", "file_path": "floppyforms/widgets.py", "project_url": "https://github.com/mrjmad/django-floppyforms", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -630,7 +630,7 @@ class SelectDateWidget(forms.Widget):\n         context['year_choices'] = [(i, i) for i in self.years]\n         context['year_val'] = year_val\n \n-        context['month_choices'] = MONTHS.items()\n+        context['month_choices'] = list(MONTHS.items())\n         context['month_val'] = month_val\n \n         context['day_choices'] = [(i, i) for i in range(1, 32)]\n", "before": "context [ 'month_choices' ] = MONTHS . items ( )", "after": "context [ 'month_choices' ] = list ( MONTHS . items ( ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 36, 3, 50], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 36, 3, 50], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 36, 3, 50], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "django-floppyforms", "commit_sha": "6911d97ac4552f037a00e5aae96853e9a058b464", "parent_sha": "eb96438ec8307dca4b9df432e7757498867e9e43", "file_path": "setup.py", "project_url": "https://github.com/mrjmad/django-floppyforms", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,7 +16,7 @@ def find_version(*file_paths):\n     version_match = re.search(r\"^__version__ = ['\\\"]([^'\\\"]*)['\\\"]\",\n                               version_file, re.M)\n     if version_match:\n-        return version_match.group(1)\n+        return str(version_match.group(1))\n     raise RuntimeError(\"Unable to find version string.\")\n \n \n", "before": "return version_match . group ( 1 )", "after": "return str ( version_match . group ( 1 ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 16, 3, 38], [\"identifier:str\", \"T\"], 0], [\"Insert\", [\"call\", 3, 16, 3, 38], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 38], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "tardis", "commit_sha": "28abd012d5178a58f6e90875788f6381c1c5bce1", "parent_sha": "0aef95ee9e59d8aff1775124088bd77ee2bb6c92", "file_path": "tardis/tests/test_tardis_full.py", "project_url": "https://github.com/vg3095/tardis", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -70,7 +70,7 @@ class TestSimpleRun():\n         if self.model.runner.virt_logging > 0:\n             virt_type = np.ndarray\n         else:\n-            virt_type = None\n+            virt_type = type(None)\n \n \n         props_required_by_modeltohdf5 = dict([\n", "before": "virt_type = None", "after": "virt_type = type ( None )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 13, 3, 29], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:type\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"none:None\", 3, 25, 3, 29], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "tardis", "commit_sha": "48f111f1d8272add9e85ed16aeb8c73493d436ff", "parent_sha": "a8d2a812ca4e22be2079e5450e16ff84f2dac444", "file_path": "tardis/tests/integration_tests/test_integration.py", "project_url": "https://github.com/vg3095/tardis", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -36,7 +36,7 @@ class TestIntegration(object):\n         # A quick hack to download and cache atom data according to requirement\n         # of setup. This will be cleaned up after new atomic data is available.\n         # Read the name of atomic data required:\n-        atom_data_name = yaml.load(self.config_file)['atom_data']\n+        atom_data_name = yaml.load(open(self.config_file))['atom_data']\n \n         # Download and cache the atom data file\n         atom_data_filepath = download_file(\"{url}/{name}\".format(\n", "before": "atom_data_name = yaml . load ( self . config_file ) [ 'atom_data' ]", "after": "atom_data_name = yaml . load ( open ( self . config_file ) ) [ 'atom_data' ]", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 35, 3, 53], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 35, 3, 53], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 35, 3, 53], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:open\", \"T\"], 0], [\"Move\", \"N0\", [\"argument_list\", 3, 35, 3, 53], 1]]"}
{"project": "cclib", "commit_sha": "920d80d2a9ce8d277467d65243f42a470588ea22", "parent_sha": "231e9512af3e71fb32b941a2af9ef45b5aa1858b", "file_path": "src/cclib/parser/gaussianparser.py", "project_url": "https://github.com/chemistry-scripts/cclib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -273,7 +273,7 @@ class Gaussian(logfileparser.Logfile):\n                 parameters = []\n                 for ig in range(ngauss):\n                     line = inputfile.next()\n-                    parameters.append(map(self.float, line.split()))\n+                    parameters.append(list(map(self.float, line.split())))\n                 for iss, ss in enumerate(subshells):\n                     contractions = []\n                     for param in parameters:\n", "before": "parameters . append ( map ( self . float , line . split ( ) ) )", "after": "parameters . append ( list ( map ( self . float , line . split ( ) ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 39, 3, 68], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 39, 3, 68], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 39, 3, 68], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "cclib", "commit_sha": "78a482182d7488962aa2d329c8b6c4696815891a", "parent_sha": "c72e399aff7a047e795547b7d5d8b04398d66133", "file_path": "src/cclib/parser/gamessparser.py", "project_url": "https://github.com/chemistry-scripts/cclib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -86,7 +86,7 @@ class GAMESS(Logfile):\n #  FINAL ENERGY IS     -379.7594673378 AFTER   9 ITERATIONS\r\n # ...so take the number after the \"IS\"\r\n                 temp = line.split()\r\n-                self.scfenergies.append(temp[temp.index(\"IS\")+1])\r\n+                self.scfenergies.append(float(temp[temp.index(\"IS\")+1]))\r\n \r\n             if line.find(\"MAXIMUM GRADIENT\")>0:\r\n                 if not hasattr(self,\"geovalues\"):\r\n", "before": "self . scfenergies . append ( temp [ temp . index ( \"IS\" ) + 1 ] )", "after": "self . scfenergies . append ( float ( temp [ temp . index ( \"IS\" ) + 1 ] ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 40, 3, 66], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 40, 3, 66], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 40, 3, 66], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:float\", \"T\"], 0], [\"Move\", \"N0\", [\"argument_list\", 3, 40, 3, 66], 1]]"}
{"project": "cclib", "commit_sha": "e00e821c9984038c15d9cb9a6db3d4e13a770cb6", "parent_sha": "a0c8f163a43fb05407a29b584a11c025d621bc8a", "file_path": "src/cclib/bridge/cclib2openbabel.py", "project_url": "https://github.com/chemistry-scripts/cclib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -23,7 +23,7 @@ def makeopenbabel(atomcoords, atomnos, charge=0, mult=1):\n     for i in range(len(atomnos)):\n         # Note that list(atomcoords[i]) is not equivalent!!!\n         coords = atomcoords[i].tolist()\n-        atomno = atomnos[i]\n+        atomno = int(atomnos[i])\n         obatom = ob.OBAtom()\n         obatom.SetAtomicNum(atomno)\n         obatom.SetVector(*coords)\n", "before": "atomno = atomnos [ i ]", "after": "atomno = int ( atomnos [ i ] )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 28], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:int\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"subscript\", 3, 18, 3, 28], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "asm3", "commit_sha": "d6a4a9b045a6c9e254bd3daea28e5c4c8cb65c73", "parent_sha": "acaa0f203aa5ce4acb3b7eaebeb1c91e2411d349", "file_path": "src/code.py", "project_url": "https://github.com/bobintetley/asm3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -700,7 +700,7 @@ class media(ASMEndpoint):\n             if len(m) == 0: self.notfound()\n             m = m[0]\n             if not m[\"MEDIANAME\"].endswith(\"html\"): continue\n-            content = asm3.dbfs.get_string(dbo, m[\"MEDIANAME\"])\n+            content = asm3.utils.bytes2str(asm3.dbfs.get_string(dbo, m[\"MEDIANAME\"]))\n             contentpdf = asm3.utils.html_to_pdf(content, BASE_URL, MULTIPLE_DATABASES and dbo.database or \"\")\n             asm3.utils.send_email(dbo, post[\"from\"], emailadd, post[\"cc\"], post[\"bcc\"], m[\"MEDIANOTES\"], post[\"body\"], \"html\", [ (\"document.pdf\", \"application/pdf\", contentpdf ) ])\n             if post.boolean(\"addtolog\"):\n", "before": "content = asm3 . dbfs . get_string ( dbo , m [ \"MEDIANAME\" ] )", "after": "content = asm3 . utils . bytes2str ( asm3 . dbfs . get_string ( dbo , m [ \"MEDIANAME\" ] ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 23, 3, 64], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 23, 3, 64], [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:bytes2str\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"call\", 3, 23, 3, 64], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:asm3\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:utils\", \"T\"], 2]]"}
{"project": "dcos-e2e", "commit_sha": "3ee9e91b691ab248861a4bfabf6275b56c200da6", "parent_sha": "d2005ac1c95f92d5652fc84449045760b183b9c7", "file_path": "src/cli/_mac_network.py", "project_url": "https://github.com/dcos/dcos-e2e", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -105,7 +105,7 @@ def create_mac_network(configuration_dst: Path) -> None:\n     temporary_extract_dst = Path(TemporaryDirectory().name).resolve()\n     tar_archive = BytesIO(b''.join((i for i in raw_stream)))\n     open_tar = tarfile.open(mode='r:', fileobj=tar_archive)\n-    open_tar.extractall(path=temporary_extract_dst)\n+    open_tar.extractall(path=str(temporary_extract_dst))\n     configuration_src = temporary_extract_dst / 'docker-for-mac.ovpn'\n     copy(src=str(configuration_src), dst=str(configuration_dst))\n \n", "before": "open_tar . extractall ( path = temporary_extract_dst )", "after": "open_tar . extractall ( path = str ( temporary_extract_dst ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 25, 3, 51], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:temporary_extract_dst\", 3, 30, 3, 51], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "OpenTPU", "commit_sha": "fca2c7d98ee085b8c1f159b11857127764131bf9", "parent_sha": "2b4f39ea3affd79af5d2e6b7bade33befdd7aa69", "file_path": "gen_nn.py", "project_url": "https://github.com/UCSBarchlab/OpenTPU", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -6,7 +6,7 @@ args = None\n def gen_one_hot():\n     one_hot = np.zeros((8, 8))\n     for i in xrange(8):\n-        one_hot[i, i] = 1\n+        one_hot[i, i] = np.int8(1)\n     return one_hot\n \n def gen_nn(path, shape, lower=None, upper=None):\n", "before": "one_hot [ i , i ] = 1", "after": "one_hot [ i , i ] = np . int8 ( 1 )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 26], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"identifier:np\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:int8\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"integer:1\", 3, 25, 3, 26], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "GenomonSV", "commit_sha": "6f1a21b9038e3bf2f9ebb1162dfce640159acc8f", "parent_sha": "47b3ccac1c045b24e1dcb99fa0ca3febf268bd6e", "file_path": "genomon_sv/filterFunction.py", "project_url": "https://github.com/Genomon-Project/GenomonSV", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -179,7 +179,7 @@ def filterNonMatchControl(inputFilePath, outputFilePath, controlFile, matchedNor\n             # get the records for control junction data for the current position\n             tabixErrorFlag = 0\n             try:\n-                records = tabixfile.fetch(F[0], int(F[1]) - controlPanel_check_margin, int(F[2]) + controlPanel_check_margin)\n+                records = tabixfile.fetch(F[0], max(int(F[1]) - controlPanel_check_margin, 0), int(F[2]) + controlPanel_check_margin)\n             except Exception as inst:\n                 # print >> sys.stderr, \"%s: %s\" % (type(inst), inst.args)\n                 tabixErrorMsg = str(inst.args)\n", "before": "records = tabixfile . fetch ( F [ 0 ] , int ( F [ 1 ] ) - controlPanel_check_margin , int ( F [ 2 ] ) + controlPanel_check_margin )", "after": "records = tabixfile . fetch ( F [ 0 ] , max ( int ( F [ 1 ] ) - controlPanel_check_margin , 0 ) , int ( F [ 2 ] ) + controlPanel_check_margin )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 42, 3, 126], [\"call\", \"N0\"], 3], [\"Insert\", [\"argument_list\", 3, 42, 3, 126], [\",:,\", \"T\"], 4], [\"Insert\", \"N0\", [\"identifier:max\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"binary_operator\", 3, 49, 3, 86], 1], [\"Move\", \"N1\", [\",:,\", 3, 86, 3, 87], 2], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4]]"}
{"project": "uberserver", "commit_sha": "5efda3e38d4db8df5ad8d63ca2a3b624a6a735ee", "parent_sha": "7b199750b982505250a9071dffab92b0c3f9e590", "file_path": "tasserver/LegacyChannels.py", "project_url": "https://github.com/lunixbochs/uberserver", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -72,7 +72,7 @@ class Parser:\n \t\t\t\tchanops.append(str(op.getAttribute('name')))\r\n \t\t\t\t\r\n \t\t\towner = str(channel.getAttribute('founder')) or None\r\n-\t\t\tname = channel.getAttribute('name')\r\n+\t\t\tname = str(channel.getAttribute('name'))\r\n \t\t\t\r\n \t\t\ttopic = None\r\n \t\t\tif name in topics:\r\n", "before": "name = channel . getAttribute ( 'name' )", "after": "name = str ( channel . getAttribute ( 'name' ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 11, 3, 39], [\"identifier:str\", \"T\"], 0], [\"Insert\", [\"call\", 3, 11, 3, 39], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 11, 3, 39], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "TaskPaper-Workflow", "commit_sha": "8362be5b58ea33fe927319f7b269a8ff53bd3b2a", "parent_sha": "3f2cb737b3e5dced6fc891b5e3498fba53990ae9", "file_path": "python/add_task_to_taskpaper.py", "project_url": "https://github.com/krid78/TaskPaper-Workflow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -276,7 +276,7 @@ def main():\n     # add_task_to_tpfile(tpfile, theline.project, theline.task)\n \n     tell_tp3_to_save_open_files(scriptbase)\n-    theline = OneLine(options.text[0])\n+    theline = OneLine(unicode(options.text[0], 'utf8'))\n     logger.info(\"theline: %s\", theline)\n     tpf = TaskPaperFileHandler(theline.file, taskfolder)\n     logger.info(\"tpf: %s\", tpf)\n", "before": "theline = OneLine ( options . text [ 0 ] )", "after": "theline = OneLine ( unicode ( options . text [ 0 ] , 'utf8' ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 22, 3, 39], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 22, 3, 39], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 22, 3, 39], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:unicode\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Move\", \"N1\", [\"(:(\", 3, 22, 3, 23], 0], [\"Move\", \"N1\", [\"subscript\", 3, 23, 3, 38], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:'utf8'\", \"T\"], 3], [\"Move\", \"N1\", [\"):)\", 3, 38, 3, 39], 4]]"}
{"project": "weblyzard_api", "commit_sha": "c43bdc1ec48b7e98d2185da2ede73482a4d35973", "parent_sha": "825e6cd894cfa56eff1ed08c36666c351130b748", "file_path": "src/python/weblyzard_api/client/wlt_api_client.py", "project_url": "https://github.com/weblyzard/weblyzard_api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ class WltApiClient(object):\n-        url = '/'.join([self.base_url, self.version, self.TOKEN_ENDPOINT])\n+        url = '/'.join([self.base_url, str(self.version), self.TOKEN_ENDPOINT])\n         r = requests.get(url, auth=(username, password))\n         if r.status_code == 200:\n             return r.content\n", "before": "url = '/' . join ( [ self . base_url , self . version , self . TOKEN_ENDPOINT ] )", "after": "url = '/' . join ( [ self . base_url , str ( self . version ) , self . TOKEN_ENDPOINT ] )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"list\", 0, 24, 0, 74], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 0, 40, 0, 52], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "OPTALG", "commit_sha": "f0f91b9527d87be631d5d61fb0db7872ced7d1a3", "parent_sha": "b5f6868a2936e6082d1d72399d00f1164e67bb9f", "file_path": "tests/test_opt_solvers.py", "project_url": "https://github.com/ttinoco/OPTALG", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -66,7 +66,7 @@ class TestOptSolvers(unittest.TestCase):\n         x = np.random.randn(n)\n         \n         for x_bad in [np.inf, np.nan]:\n-            x[n/2] = x_bad\n+            x[int(n/2)] = x_bad\n             bad_prob = opt.opt_solver.QuadProblem(H,g,A,b,l,u,x=x)\n             self.assertRaises(opt.opt_solver.opt_solver_error.OptSolverError_Ipopt, Ipopt.solve, bad_prob)\n             self.assertEqual(Ipopt.get_status(), 'error')\n", "before": "x [ n / 2 ] = x_bad", "after": "x [ int ( n / 2 ) ] = x_bad", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"subscript\", 3, 13, 3, 19], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:int\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"binary_operator\", 3, 15, 3, 18], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "sipa", "commit_sha": "3cf6094ad9d2b1d86e8b3dc4c4966b6f85bacb24", "parent_sha": "42c33888c9723d94fa9cc09f64b3eb50066b55f8", "file_path": "sipa/initialization.py", "project_url": "https://github.com/agdsn/sipa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -94,7 +94,7 @@ def init_env_and_config(app):\n     app.config.from_pyfile(os.path.realpath(\"sipa/default_config.py\"))\n     # if local config file exists, load everything into local space.\n     if 'SIPA_CONFIG_FILE' not in os.environ:\n-        os.environ['SIPA_CONFIG_FILE'] = \"config.py\"\n+        os.environ['SIPA_CONFIG_FILE'] = os.path.realpath(\"config.py\")\n     try:\n         app.config.from_envvar('SIPA_CONFIG_FILE', silent=True)\n     except IOError:\n", "before": "os . environ [ 'SIPA_CONFIG_FILE' ] = \"config.py\"", "after": "os . environ [ 'SIPA_CONFIG_FILE' ] = os . path . realpath ( \"config.py\" )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 53], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:realpath\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"string:\\\"config.py\\\"\", 3, 42, 3, 53], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:path\", \"T\"], 2]]"}
{"project": "sipa", "commit_sha": "1987be4edd81203d1a01f65c433c007746b748aa", "parent_sha": "621c02a049a3cc6a469155e2efd8547fc157768b", "file_path": "sipa/blueprints/register.py", "project_url": "https://github.com/agdsn/sipa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -236,7 +236,7 @@ def data(reg_state: RegisterState):\n     elif form.is_submitted():\n         flash_formerrors(form)\n     else:\n-        form.member_begin_date.data = reg_state.move_in_date\n+        form.member_begin_date.data = max(reg_state.move_in_date, date.today())\n \n     return render_template('register/form.html', title=gettext('Konto erstellen'), form=form,\n                            links={\n", "before": "else : form . member_begin_date . data = reg_state . move_in_date", "after": "else : form . member_begin_date . data = max ( reg_state . move_in_date , date . today ( ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"assignment\", 2, 5, 3, 61], [\"call\", \"N0\"], 4], [\"Insert\", \"N0\", [\"identifier:max\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 3, 39, 3, 61], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N3\", [\"identifier:date\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:today\", \"T\"], 2], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"):)\", \"T\"], 1]]"}
{"project": "django-avatar", "commit_sha": "c9c2e06fa1f5258157d8d3c88972496ef2eadabd", "parent_sha": "7c59dec843da987897a9966dcf671bb75e7d9d0d", "file_path": "avatar/models.py", "project_url": "https://github.com/tbabej/django-avatar", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -26,7 +26,7 @@ avatar_storage = get_storage_class(settings.AVATAR_STORAGE)()\n def avatar_file_path(instance=None, filename=None, size=None, ext=None):\n     tmppath = [settings.AVATAR_STORAGE_DIR]\n     if settings.AVATAR_USERID_HAS_USERDIRNAMES:\n-        tmppath.append(instance.user_id)\n+        tmppath.append(str(instance.user_id))\n     elif settings.AVATAR_HASH_USERDIRNAMES:\n         tmp = hashlib.md5(get_username(instance.user)).hexdigest()\n         tmppath.extend([tmp[0], tmp[1], get_username(instance.user)])\n", "before": "tmppath . append ( instance . user_id )", "after": "tmppath . append ( str ( instance . user_id ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 23, 3, 41], [\"(:(\", \"T\"], 0], [\"Insert\", [\"argument_list\", 3, 23, 3, 41], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 23, 3, 41], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Move\", \"N0\", [\"argument_list\", 3, 23, 3, 41], 1]]"}
{"project": "pants", "commit_sha": "185a4f8456f261634011c4542b64557e55c03d7f", "parent_sha": "1f680bababfef0c67c287dc17a4f66230a583c01", "file_path": "src/python/twitter/pants/targets/sources.py", "project_url": "https://github.com/square/pants", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -88,7 +88,7 @@ class SourceRoot(object):\n \n   @staticmethod\n   def _register_relative_to_build_file(build_file_dir, rel_source_root_dir, *allowed_target_types):\n-    source_root_dir = os.path.join(build_file_dir, rel_source_root_dir)\n+    source_root_dir = os.path.relpath(os.path.join(build_file_dir, rel_source_root_dir), get_buildroot())\n     SourceRoot._register(source_root_dir, *allowed_target_types)\n \n   @staticmethod\n", "before": "source_root_dir = os . path . join ( build_file_dir , rel_source_root_dir )", "after": "source_root_dir = os . path . relpath ( os . path . join ( build_file_dir , rel_source_root_dir ) , get_buildroot ( ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 23, 3, 72], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 23, 3, 72], [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:relpath\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"call\", 3, 23, 3, 72], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"call\", \"N3\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4], [\"Insert\", \"N2\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:path\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:get_buildroot\", \"T\"], 0], [\"Insert\", \"N3\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"):)\", \"T\"], 1]]"}
{"project": "katal", "commit_sha": "7712d5bfb0fecda259299e044c94268cc5b5b0f7", "parent_sha": "4f63301eaa44b863df2dc75050e3528f1b1f3a93", "file_path": "katal/katal.py", "project_url": "https://github.com/suizokukan/katal", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -753,7 +753,7 @@ def action__target_kill(_filename):\n \n         filename_hashid = None\n         for db_record in db_cursor.execute('SELECT * FROM dbfiles'):\n-            if db_record[\"name\"] == _filename:\n+            if db_record[\"name\"] == os.path.join(normpath(TARGET_PATH), _filename):\n                 filename_hashid = db_record[\"hashid\"]\n \n         if filename_hashid is None:\n", "before": "if db_record [ \"name\" ] == _filename : filename_hashid = db_record [ \"hashid\" ]", "after": "if db_record [ \"name\" ] == os . path . join ( normpath ( TARGET_PATH ) , _filename ) : filename_hashid = db_record [ \"hashid\" ]", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 46], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:join\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"call\", \"N4\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Move\", \"N2\", [\"identifier:_filename\", 3, 37, 3, 46], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4], [\"Insert\", \"N3\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:path\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:normpath\", \"T\"], 0], [\"Insert\", \"N4\", [\"argument_list\", \"N5\"], 1], [\"Insert\", \"N5\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N5\", [\"identifier:TARGET_PATH\", \"T\"], 1], [\"Insert\", \"N5\", [\"):)\", \"T\"], 2]]"}
{"project": "pants", "commit_sha": "112eb58de89c8b8f76d61754a90831c463ce4536", "parent_sha": "33e2b0c47bb30080575f44ef3082a4b6f65414ae", "file_path": "tests/python/pants_test/base_test.py", "project_url": "https://github.com/square/pants", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -84,7 +84,7 @@ class BaseTest(unittest2.TestCase):\n \n   def setUp(self):\n     self.real_build_root = BuildRoot().path\n-    self.build_root = mkdtemp(suffix='_BUILD_ROOT')\n+    self.build_root = os.path.realpath(mkdtemp(suffix='_BUILD_ROOT'))\n     BuildRoot().path = self.build_root\n     self.create_file('pants.ini')\n     self.build_file_parser = BuildFileParser(self.build_root)\n", "before": "self . build_root = mkdtemp ( suffix = '_BUILD_ROOT' )", "after": "self . build_root = os . path . realpath ( mkdtemp ( suffix = '_BUILD_ROOT' ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 23, 3, 52], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 23, 3, 52], [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:realpath\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"call\", 3, 23, 3, 52], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:path\", \"T\"], 2]]"}
{"project": "databroker", "commit_sha": "3152620c43b97f1be802039a7f694728e49e3a57", "parent_sha": "9d7b7305fbeffb67741cde1b281294c762d93dc7", "file_path": "metadataStore/commands.py", "project_url": "https://github.com/bluesky/databroker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -143,7 +143,7 @@ def insert_end_run(begin_run_event, time, reason=None, uid=None):\n     if uid is None:\n-        uid = uuid.uuid4()\n+        uid = str(uuid.uuid4())\n     begin_run = EndRunEvent(begin_run_event=begin_run_event, reason=reason,\n                             time=time, time_as_datetime=__todatetime(time),\n                             uid=uid)\n", "before": "uid = uuid . uuid4 ( )", "after": "uid = str ( uuid . uuid4 ( ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 1, 15, 1, 27], [\"identifier:str\", \"T\"], 0], [\"Insert\", [\"call\", 1, 15, 1, 27], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 1, 15, 1, 27], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "databroker", "commit_sha": "9d4dd81b3f3574503206da43187f3de7497fef98", "parent_sha": "964e1ceca13ead07ca30cd737f0566f9e73b782c", "file_path": "dataportal/muxer/data_muxer.py", "project_url": "https://github.com/bluesky/databroker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -561,7 +561,7 @@ class DataMuxer(object):\n         return result\n \n     def __getitem__(self, source_name):\n-        if source_name not in self.col_info.keys() + ['time']:\n+        if source_name not in list(self.col_info.keys()) + ['time']:\n             raise KeyError(\"No data from a source called '{0}' has been \"\n                            \"added.\".format(source_name))\n         # Unlike output from binning functions, this is indexed\n", "before": "if source_name not in self . col_info . keys ( ) + [ 'time' ] : raise KeyError ( \"No data from a source called '{0}' has been \" \"added.\" . format ( source_name ) )", "after": "if source_name not in list ( self . col_info . keys ( ) ) + [ 'time' ] : raise KeyError ( \"No data from a source called '{0}' has been \" \"added.\" . format ( source_name ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 31, 3, 51], [\"identifier:list\", \"T\"], 0], [\"Insert\", [\"call\", 3, 31, 3, 51], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 31, 3, 51], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "databroker", "commit_sha": "33d9741019af6cc4924bc2dcdc88b1ec005dc931", "parent_sha": "a545b9233c438d586c0c2b4b1eaa54d7625953ae", "file_path": "databroker/tests/test_broker.py", "project_url": "https://github.com/bluesky/databroker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -64,7 +64,7 @@ def test_uid_list_multiple_headers(db, RE):\n     RE.subscribe(db.insert)\n     uids = RE(pchain(count([det]), count([det])))\n     headers = db[uids]\n-    assert uids == [h['start']['uid'] for h in headers]\n+    assert uids == tuple([h['start']['uid'] for h in headers])\n \n \n @py3\n", "before": "assert uids == [ h [ 'start' ] [ 'uid' ] for h in headers ]", "after": "assert uids == tuple ( [ h [ 'start' ] [ 'uid' ] for h in headers ] )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 56], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:tuple\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"list_comprehension\", 3, 20, 3, 56], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "pdfminer", "commit_sha": "8e4c0c88e3c0c17251ed337cb9272036985f13e2", "parent_sha": "6ca9ac543497135250b780413a31d7f697e1f2dd", "file_path": "pdfminer/pdfpage.py", "project_url": "https://github.com/metachris/pdfminer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ class PDFPage(object):\n             self.cropbox = resolve1(self.attrs['CropBox'])\n         else:\n             self.cropbox = self.mediabox\n-        self.rotate = (self.attrs.get('Rotate', 0)+360) % 360\n+        self.rotate = (int_value(self.attrs.get('Rotate', 0))+360) % 360\n         self.annots = self.attrs.get('Annots')\n         self.beads = self.attrs.get('B')\n         if 'Contents' in self.attrs:\n", "before": "self . rotate = ( self . attrs . get ( 'Rotate' , 0 ) + 360 ) % 360", "after": "self . rotate = ( int_value ( self . attrs . get ( 'Rotate' , 0 ) ) + 360 ) % 360", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 24, 3, 51], [\"identifier:int_value\", \"T\"], 0], [\"Insert\", [\"call\", 3, 24, 3, 51], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 24, 3, 51], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "PyNMRSTAR", "commit_sha": "d8cc046b276ae2adf1fa4d58582bf7b11b31b1f7", "parent_sha": "de9f88c095dfc3012167df4acfab41af3cbbb950", "file_path": "bmrb.py", "project_url": "https://github.com/uwbmrb/PyNMRSTAR", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -522,7 +522,7 @@ def _tag_key(x, schema=None):\n         # Generate an arbitrary sort order for tags that aren't in the\n         #  schema but make sure that they always come after tags in the\n         #   schema\n-        return len(_get_schema(schema).schema_order) + hash(x)\n+        return len(_get_schema(schema).schema_order) + abs(hash(x))\n \n #############################################\n #                Classes                    #\n", "before": "return len ( _get_schema ( schema ) . schema_order ) + hash ( x )", "after": "return len ( _get_schema ( schema ) . schema_order ) + abs ( hash ( x ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 56, 3, 63], [\"identifier:abs\", \"T\"], 0], [\"Insert\", [\"call\", 3, 56, 3, 63], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 56, 3, 63], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "bot", "commit_sha": "92e9d7b4bf606b8c6e5bcdd88133d10d5f4308da", "parent_sha": "a6477a73c17f84d70f554675f817af311a044be7", "file_path": "bot.py", "project_url": "https://github.com/trackmastersteve/bot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -148,7 +148,7 @@ def main():\n         \n         # Change nickname if current nickname is already in use.\n         if ircmsg.find('Nickname is already in use') != -1:\n-            botnick = \"abot\" + random.randint(10000,99999)\n+            botnick = \"abot\" + str(random.randint(10000,99999))\n             ircsock.send(bytes(\"NICK \"+ botnick +\"\\n\", \"UTF-8\"))\n         \n         # Join 'channel' and msg 'admin' after you are fully connected to server.\n", "before": "botnick = \"abot\" + random . randint ( 10000 , 99999 )", "after": "botnick = \"abot\" + str ( random . randint ( 10000 , 99999 ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"call\", 3, 32, 3, 59], [\"identifier:str\", \"T\"], 0], [\"Insert\", [\"call\", 3, 32, 3, 59], [\"argument_list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 32, 3, 59], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "SymPortal_framework", "commit_sha": "8f0355c7cb50394a2e0cbd51c6f3bd5cf71a3ac4", "parent_sha": "76bc40e07b3ba13fb6fce174ebe662d8eac8a2f5", "file_path": "plotting.py", "project_url": "https://github.com/SymPortal/SymPortal_framework", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -538,7 +538,7 @@ class PreMedSeqPlotter:\n \n     def _curate_output_count_table(self, rel_abund_df):\n         self.smp_uid_to_smp_name_dict = {\n-            uid:name for uid, name in\n+            uid:str(name) for uid, name in\n             zip(rel_abund_df.index.values.tolist(), rel_abund_df['sample_name'].values.tolist())}\n         df = rel_abund_df.drop(columns='sample_name')\n         return df.astype('float')\n", "before": "self . smp_uid_to_smp_name_dict = { uid : name for uid , name in zip ( rel_abund_df . index . values . tolist ( ) , rel_abund_df [ 'sample_name' ] . values . tolist ( ) ) }", "after": "self . smp_uid_to_smp_name_dict = { uid : str ( name ) for uid , name in zip ( rel_abund_df . index . values . tolist ( ) , rel_abund_df [ 'sample_name' ] . values . tolist ( ) ) }", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"pair\", 3, 13, 3, 21], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:name\", 3, 17, 3, 21], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "SymPortal_framework", "commit_sha": "3f4ad18e9b788dad61ba059eb4c9d7ac965639ac", "parent_sha": "302dec3b0abda70acaebaabf885cf6723b6572b5", "file_path": "plotting.py", "project_url": "https://github.com/SymPortal/SymPortal_framework", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -418,7 +418,7 @@ class TypeStackedBarPlotter:\n         sp_output_df = sp_output_df.iloc[:index_to_drop_from]\n \n         # now make a dict of sample id to sample name so that we can work with uids\n-        self.smp_uid_to_smp_name_dict = {int(smp_uid): smp_name for smp_uid, smp_name in zip(sp_output_df.iloc[3:, 0], sp_output_df.iloc[3:, 1])}\n+        self.smp_uid_to_smp_name_dict = {int(smp_uid): str(smp_name) for smp_uid, smp_name in zip(sp_output_df.iloc[3:, 0], sp_output_df.iloc[3:, 1])}\n \n         # now make a dict of of type id to type name so that we can also work eith uids for the types\n         # as there could be types with identical names\n", "before": "self . smp_uid_to_smp_name_dict = { int ( smp_uid ) : smp_name for smp_uid , smp_name in zip ( sp_output_df . iloc [ 3 : , 0 ] , sp_output_df . iloc [ 3 : , 1 ] ) }", "after": "self . smp_uid_to_smp_name_dict = { int ( smp_uid ) : str ( smp_name ) for smp_uid , smp_name in zip ( sp_output_df . iloc [ 3 : , 0 ] , sp_output_df . iloc [ 3 : , 1 ] ) }", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"pair\", 3, 42, 3, 64], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:smp_name\", 3, 56, 3, 64], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "gitcher", "commit_sha": "0725559ca8cd434b71074731d99d5a4a1307d6af", "parent_sha": "c253090718c58ec94ff30fbea51e436370190895", "file_path": "gitcher/prof.py", "project_url": "https://github.com/glezseoane/gitcher", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ class Prof(object):\n         return self.profname, self.name, self.email, signkey_str, signpref_str\n \n     def __hash__(self):\n-        return hash((self.name + self.email + self.signkey +\n+        return hash((self.name + self.email + str(self.signkey) +\n                      str(self.signpref)))\n \n     def __eq__(self, other):\n", "before": "return hash ( ( self . name + self . email + self . signkey + str ( self . signpref ) ) )", "after": "return hash ( ( self . name + self . email + str ( self . signkey ) + str ( self . signpref ) ) )", "sstub_pattern": "ADD_FUNCTION_AROUND_EXPRESSION", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 22, 3, 59], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"attribute\", 3, 47, 3, 59], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "pyrollbar", "commit_sha": "6bed32b0f2a4f4b2e436bdb94d5a248956f2ead9", "parent_sha": "b83e3eaee956edf869e0ae2d80cdf220e0591698", "file_path": "rollbar/__init__.py", "project_url": "https://github.com/uploadcare/pyrollbar", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -889,7 +889,7 @@ def _build_werkzeug_request_data(request):\n     }\n \n     if request.get_json():\n-        request_data['body'] = json.dumps(_scrub_request_params(request.json))\n+        request_data['body'] = json.dumps(_scrub_obj(request.json))\n \n     return request_data\n \n", "before": "request_data [ 'body' ] = json . dumps ( _scrub_request_params ( request . json ) )", "after": "request_data [ 'body' ] = json . dumps ( _scrub_obj ( request . json ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:_scrub_request_params\", 3, 43, 3, 64], \"_scrub_obj\"]]"}
{"project": "jinja2", "commit_sha": "e6c0630249c052f953686a7c8e155e5c5b4b075c", "parent_sha": "d7d663f612c02e7a48d33f6383527a9d7b1f6ae5", "file_path": "jinja2/environment.py", "project_url": "https://github.com/silkapp/jinja2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1069,7 +1069,7 @@ class TemplateStream(six.Iterator):\n         close = False\n         if isinstance(fp, six.string_types):\n-            fp = file(fp, 'w')\n+            fp = open(fp, 'w')\n             close = True\n         try:\n             if encoding is not None:\n", "before": "fp = file ( fp , 'w' )", "after": "fp = open ( fp , 'w' )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:file\", 2, 18, 2, 22], \"open\"]]"}
{"project": "Cactus", "commit_sha": "684a0677a093757e524f49d6aa39f734afe15a70", "parent_sha": "cd5f714aa56c8a5179de9882ae5dfa655be3b6d5", "file_path": "cactus/config/fallback.py", "project_url": "https://github.com/crate/Cactus", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,4 +28,4 @@ class ConfigFallback(object):\n \n     def write(self):\n         if self.cnf:\n-            logger.warn(\"Using config fallback, discarding config values: [%s]\", ', '.join(self.cnf.keys()))\n+            logger.warning(\"Using config fallback, discarding config values: [%s]\", ', '.join(self.cnf.keys()))\n", "before": "logger . warn ( \"Using config fallback, discarding config values: [%s]\" , ', ' . join ( self . cnf . keys ( ) ) )", "after": "logger . warning ( \"Using config fallback, discarding config values: [%s]\" , ', ' . join ( self . cnf . keys ( ) ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:warn\", 3, 20, 3, 24], \"warning\"]]"}
{"project": "SleekXMPP", "commit_sha": "85fd14f47f0911e2242b8c52e8545eab08e09d03", "parent_sha": "d0bba87cdd6eba3d21c72c36ad15340b8db64c85", "file_path": "sleekxmpp/plugins/xep_0027/gpg.py", "project_url": "https://github.com/mayflower/SleekXMPP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ def _extract_data(data, kind):\n         if not begin_headers and 'BEGIN PGP %s' % kind in line:\n             begin_headers = True\n             continue\n-        if begin_headers and line.stripped() == '':\n+        if begin_headers and line.strip() == '':\n             begin_data = True\n             continue\n         if 'END PGP %s' % kind in line:\n", "before": "if begin_headers and line . stripped ( ) == '' : begin_data = True continue", "after": "if begin_headers and line . strip ( ) == '' : begin_data = True continue", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:stripped\", 3, 35, 3, 43], \"strip\"]]"}
{"project": "django-taggit", "commit_sha": "3dd19708b795b19be40c337cc75e27bd961b49c4", "parent_sha": "b6f863102ed0383e9c9d9dd6233cf5cf3ebcb6f1", "file_path": "taggit/tests/tests.py", "project_url": "https://github.com/sprintly/django-taggit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,7 +52,7 @@ class BaseTaggingTest(object):\n         return form_str\n \n     def assert_form_renders(self, form, html):\n-        self.assertEqual(str(form), self._get_form_str(html))\n+        self.assertHTMLEqual(str(form), self._get_form_str(html))\n \n class BaseTaggingTestCase(TestCase, BaseTaggingTest):\n     pass\n", "before": "self . assertEqual ( str ( form ) , self . _get_form_str ( html ) )", "after": "self . assertHTMLEqual ( str ( form ) , self . _get_form_str ( html ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:assertEqual\", 3, 14, 3, 25], \"assertHTMLEqual\"]]"}
{"project": "ooi", "commit_sha": "91b910e3e845b5a6cfb98d12d1cf725a9a297b41", "parent_sha": "59272482f666052a938d03b96d061a9dc7d86730", "file_path": "ooi/api/__init__.py", "project_url": "https://github.com/IFCA/ooi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -90,7 +90,7 @@ def validate(class_id, schemas, term=None):\n                 if len(s) != 0:\n                     mismatched_schemas = [(scheme, d[scheme])\n                                           for scheme in dict(s).keys()]\n-                    raise exception.OCCISchemaOcurrencesMismatch(\n+                    raise exception.OCCISchemaOccurrencesMismatch(\n                         mismatched_schemas=mismatched_schemas)\n \n             def term_validation():\n", "before": "raise exception . OCCISchemaOcurrencesMismatch ( mismatched_schemas = mismatched_schemas )", "after": "raise exception . OCCISchemaOccurrencesMismatch ( mismatched_schemas = mismatched_schemas )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:OCCISchemaOcurrencesMismatch\", 3, 37, 3, 65], \"OCCISchemaOccurrencesMismatch\"]]"}
{"project": "cloud-bdii-provider", "commit_sha": "7e89ad86112a65c697cd2d841ca97b53eb42cd73", "parent_sha": "f85e7537850cfc2ae3ad23e0645f989c6b4aa5db", "file_path": "cloud_info/providers/openstack.py", "project_url": "https://github.com/alvarolopez/cloud-bdii-provider", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -154,7 +154,7 @@ class OpenStackProvider(providers.BaseProvider):\n                                        OpenStackProvider.occify(image.id))\n             })\n \n-            for name, value in image.metadata.iteritems():\n+            for name, value in image.metadata.items():\n                 aux_img[name] = value\n \n             # XXX could probably be move to the mako template\n", "before": "for name , value in image . metadata . iteritems ( ) : aux_img [ name ] = value", "after": "for name , value in image . metadata . items ( ) : aux_img [ name ] = value", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:iteritems\", 3, 47, 3, 56], \"items\"]]"}
{"project": "flask-oauthlib", "commit_sha": "71b09c7fbb131dfc87a26ffc581cded5a3945b89", "parent_sha": "2c485048c3bc578d3df0ee149dcbae05baa06e5b", "file_path": "flask_oauthlib/contrib/bindings.py", "project_url": "https://github.com/underdogio/flask-oauthlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -249,7 +249,7 @@ class GrantCacheBinding(object):\n         kwargs = self.cache.get(grant.key)\n         if kwargs:\n             log.debug(\"Grant Token found with key {0}\".format(grant.key))\n-            for k, v in kwargs.iteritems():\n+            for k, v in kwargs.items():\n                 setattr(grant, k, v)\n             return grant\n         log.debug(\"Grant Token not found with key {0}\".format(grant.key))\n", "before": "for k , v in kwargs . iteritems ( ) : setattr ( grant , k , v )", "after": "for k , v in kwargs . items ( ) : setattr ( grant , k , v )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:iteritems\", 3, 32, 3, 41], \"items\"]]"}
{"project": "splinter", "commit_sha": "c171d82c5b2bf919dd0ab257d172e33e467b2333", "parent_sha": "73dd938d688e0cacbce252d0cb18045f379f54a5", "file_path": "tests/test_zopetestbrowser.py", "project_url": "https://github.com/underdogio/splinter", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,4 +31,4 @@ class ZopeTestBrowserDriverTest(BaseBrowserTests, unittest.TestCase):\n     @raises(NotImplementedError)\n     def test_cant_switch_to_frame(self):\n         \"zope.testbrowser should not be able to switch to frames\"\n-        self.browser.switch_to_frame('frame_123')\n+        self.browser.get_iframe('frame_123')\n", "before": "self . browser . switch_to_frame ( 'frame_123' )", "after": "self . browser . get_iframe ( 'frame_123' )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:switch_to_frame\", 3, 22, 3, 37], \"get_iframe\"]]"}
{"project": "alipay-python-sdk", "commit_sha": "83448ecd1a61133c64dba02f7c631b829bd461e0", "parent_sha": "f44362567581628503a626d55ee7da28764fefd5", "file_path": "src/alipay/__init__.py", "project_url": "https://github.com/bowenpay/alipay-python-sdk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -20,7 +20,7 @@ class Alipay(object):\n \n     def _generate_sign(self, params):\n         src = '&'.join(['%s=%s' % (key, value) for key,\n-                        value in sorted(params.iteritems())]) + self.key\n+                        value in sorted(params.items())]) + self.key\n         return md5(src).hexdigest()\n \n     def _check_params(self, params, names):\n", "before": "src = '&' . join ( [ '%s=%s' % ( key , value ) for key , value in sorted ( params . iteritems ( ) ) ] ) + self . key", "after": "src = '&' . join ( [ '%s=%s' % ( key , value ) for key , value in sorted ( params . items ( ) ) ] ) + self . key", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:iteritems\", 3, 48, 3, 57], \"items\"]]"}
{"project": "SleekXMPP", "commit_sha": "9cbc29149f4a5437bc9f54f124895278b558b25d", "parent_sha": "7a15d14c939dbc9ecc9822c81da55bdb648dcbdb", "file_path": "sleekxmpp/componentxmpp.py", "project_url": "https://github.com/mayflower/SleekXMPP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ class ComponentXMPP(basexmpp, XMLStream):\n \tdef incoming_filter(self, xmlobj):\n \t\tif xmlobj.tag.startswith('{jabber:client}'):\n \t\t\txmlobj.tag = xmlobj.tag.replace('jabber:client', 'jabber:component:accept')\n-\t\t\tfor child in xmlobj.children():\n+\t\t\tfor child in xmlobj.getchildren():\n \t\t\t\tchild = self.incoming_filter(child)\n \t\treturn xmlobj\n \n", "before": "for child in xmlobj . children ( ) : child = self . incoming_filter ( child )", "after": "for child in xmlobj . getchildren ( ) : child = self . incoming_filter ( child )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:children\", 3, 24, 3, 32], \"getchildren\"]]"}
{"project": "blink-qt", "commit_sha": "ebe4c8d1abf1fac4f48423cb5de9152746fd8697", "parent_sha": "051cf3d9ffd0b47bc88a58fb5cc3110e1b571a7c", "file_path": "blink/widgets/labels.py", "project_url": "https://github.com/kogmbh/blink-qt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -271,7 +271,7 @@ class ElidedLabel(QLabel):\n             gradient.setColorAt(1-50.0/label_width, self.palette().color(self.foregroundRole()))\n             gradient.setColorAt(1.0, Qt.transparent)\n             painter.setPen(QPen(QBrush(gradient), 1.0))\n-        painter.drawText(self.rect(), Qt.TextSingleLine | int(self.alignment()), self.text())\n+        painter.drawText(self.contentsRect(), Qt.TextSingleLine | int(self.alignment()), self.text())\n \n \n class StateColor(QColor):\n", "before": "painter . drawText ( self . rect ( ) , Qt . TextSingleLine | int ( self . alignment ( ) ) , self . text ( ) )", "after": "painter . drawText ( self . contentsRect ( ) , Qt . TextSingleLine | int ( self . alignment ( ) ) , self . text ( ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:rect\", 3, 31, 3, 35], \"contentsRect\"]]"}
{"project": "blink-qt", "commit_sha": "4731941c02d95a77ef00233bd936b56eba40102c", "parent_sha": "8802cece5889e152bb6e49648f4f5d221dd2d06f", "file_path": "blink/filetransferwindow.py", "project_url": "https://github.com/kogmbh/blink-qt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -105,7 +105,7 @@ class FileTransferWindow(base_class, ui_class):\n \n     def _AH_OpenContainingFolder(self):\n         item = self.listview.selectedIndexes()[0].data(Qt.UserRole)\n-        QDesktopServices.openUrl(QUrl.fromLocalFile(os.path.basename(item.filename)))\n+        QDesktopServices.openUrl(QUrl.fromLocalFile(os.path.dirname(item.filename)))\n \n     def _AH_CancelTransfer(self):\n         item = self.listview.selectedIndexes()[0].data(Qt.UserRole)\n", "before": "QDesktopServices . openUrl ( QUrl . fromLocalFile ( os . path . basename ( item . filename ) ) )", "after": "QDesktopServices . openUrl ( QUrl . fromLocalFile ( os . path . dirname ( item . filename ) ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:basename\", 3, 61, 3, 69], \"dirname\"]]"}
{"project": "blink-qt", "commit_sha": "40c7d7a3c3f6475148cb2772ae05acb7cd916eef", "parent_sha": "6c5de3c55f2ca789d52aec7e7b46ee31ca267375", "file_path": "blink/filetransferwindow.py", "project_url": "https://github.com/kogmbh/blink-qt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -119,7 +119,7 @@ class FileTransferWindow(base_class, ui_class):\n \n     def _AH_RetryTransfer(self):\n         item = self.listview.selectedIndexes()[0].data(Qt.UserRole)\n-        item.connect()\n+        item.retry()\n \n     def _AH_RemoveEntry(self):\n         item = self.listview.selectedIndexes()[0].data(Qt.UserRole)\n", "before": "item . connect ( )", "after": "item . retry ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:connect\", 3, 14, 3, 21], \"retry\"]]"}
{"project": "librosa", "commit_sha": "fd84ed9c1945c54e5daa1c7619d02c01e8c8998f", "parent_sha": "b9a5f7d2bf056e397ee527425c41d214265ca59c", "file_path": "librosa/display.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -59,7 +59,7 @@ def specshow(X, sr=22050, hop_length=64, x_axis=None, y_axis=None, nx_ticks=5, n\n     axes = plt.imshow(X, **kwargs)\n \n     if y_axis is 'log':\n-        ax = plt.axes()\n+        ax = plt.gca()\n \n         # Non-uniform imshow doesn't like aspect\n         del kwargs['aspect']\n", "before": "ax = plt . axes ( )", "after": "ax = plt . gca ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:axes\", 3, 18, 3, 22], \"gca\"]]"}
{"project": "trac", "commit_sha": "ae96ccbdf7864f56e0bdaa2744ecc89679ca041a", "parent_sha": "46edadb639496e8f07d3e97fee93a2557ba6579a", "file_path": "trac/web/api.py", "project_url": "https://github.com/arielnetworks/trac", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -265,7 +265,7 @@ class Request(object):\n             import md5\n             m = md5.new()\n             for elt in extra:\n-                m.update(str(elt))\n+                m.update(repr(elt))\n             extra = m.hexdigest()\n         etag = 'W\"%s/%d/%s\"' % (self.authname, timesecs, extra)\n         inm = self.get_header('If-None-Match')\n", "before": "m . update ( str ( elt ) )", "after": "m . update ( repr ( elt ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:str\", 3, 26, 3, 29], \"repr\"]]"}
{"project": "trac", "commit_sha": "555dd9186ec3c55bbc956b8e652d5d1a3bf25d8e", "parent_sha": "e41ed3e2fa490b3b14d439331d1703a1556c87db", "file_path": "trac/versioncontrol/web_ui/browser.py", "project_url": "https://github.com/arielnetworks/trac", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -282,7 +282,7 @@ class BrowserModule(Component):\n         # ---- TODO: the following should be removed in milestone:0.11\n         match = IMG_RE.search(path)\n         if formatter.flavor != 'oneliner' and match:\n-            return html.IMG(src=formatter.href.file(path, format='raw'),\n+            return html.IMG(src=formatter.href.browser(path, format='raw'),\n                             alt=label, title='Warning: direct image links are '\n                             'deprecated, use [[Image(source:...)]] instead)')\n         # ----\n", "before": "return html . IMG ( src = formatter . href . file ( path , format = 'raw' ) , alt = label , title = 'Warning: direct image links are ' 'deprecated, use [[Image(source:...)]] instead)' )", "after": "return html . IMG ( src = formatter . href . browser ( path , format = 'raw' ) , alt = label , title = 'Warning: direct image links are ' 'deprecated, use [[Image(source:...)]] instead)' )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:file\", 3, 48, 3, 52], \"browser\"]]"}
{"project": "MultiQC", "commit_sha": "b1c60661fdd55725c21ebf8253bc882a50bcf414", "parent_sha": "252a2ce71b5db9985c75dbd7b1cbb9beb5190db7", "file_path": "multiqc/modules/samblaster/samblaster.py", "project_url": "https://github.com/JAX-GM/MultiQC", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ class MultiqcModule(BaseMultiqcModule):\n             log.debug(\"Could not find any data in {}\".format(config.analysis_dir))\n             raise UserWarning\n \n-        log.debug(\"Found {} reports\".format(len(self.samblaster_data)))\n+        log.info(\"Found {} reports\".format(len(self.samblaster_data)))\n \n     def parse_samblaster(self, f):\n         \"\"\" Go through log file looking for samblaster output \"\"\"\n", "before": "log . debug ( \"Found {} reports\" . format ( len ( self . samblaster_data ) ) )", "after": "log . info ( \"Found {} reports\" . format ( len ( self . samblaster_data ) ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:debug\", 3, 13, 3, 18], \"info\"]]"}
{"project": "MultiQC", "commit_sha": "69d1a7e3553d9038f3c8535e54929260fc1cb62a", "parent_sha": "0d980be003f44fbbfd9b8a913dd8fe619104836f", "file_path": "multiqc/modules/skewer/skewer.py", "project_url": "https://github.com/JAX-GM/MultiQC", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -61,7 +61,7 @@ class MultiqcModule(BaseMultiqcModule):\n             log.debug(\"Could not find any data in {}\".format(config.analysis_dir))\n             raise UserWarning\n \n-        log.debug(\"Found {} reports\".format(len(self.skewer_data)))\n+        log.info(\"Found {} reports\".format(len(self.skewer_data)))\n \n     def parse_skewer_log(self, f):\n         \"\"\" Go through log file looking for skewer output \"\"\"\n", "before": "log . debug ( \"Found {} reports\" . format ( len ( self . skewer_data ) ) )", "after": "log . info ( \"Found {} reports\" . format ( len ( self . skewer_data ) ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:debug\", 3, 13, 3, 18], \"info\"]]"}
{"project": "busido", "commit_sha": "39d4fbc6bc1ebab0e31a8d20d7bc32392111329e", "parent_sha": "876cdf3150fce3e60fe5fa5712d740ee715e609c", "file_path": "gtfs/views.py", "project_url": "https://github.com/semion/busido", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,7 +34,7 @@ def get_bounded_stops(request):\n def get_stop_data(request):\n     stop_id = request.REQUEST.get('stop_id')\n \n-    now = datetime.utcnow()\n+    now = datetime.now()\n     dep_time_seconds = now.hour * 60 * 60 + now.minute * 60 + now.second\n \n     filter_kwargs = {'stop_id': stop_id,\n", "before": "now = datetime . utcnow ( )", "after": "now = datetime . now ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:utcnow\", 3, 20, 3, 26], \"now\"]]"}
{"project": "rq", "commit_sha": "60c27d5a2768a34a42f19ab92f3278bcf17e468d", "parent_sha": "1ae5a12a81f05534540035a67e6754f55d2dc37f", "file_path": "tests/test_worker.py", "project_url": "https://github.com/dronedeploy/rq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -353,7 +353,7 @@ class TestWorker(RQTestCase):\n \n     def test_suspend_with_duration(self):\n         q = Queue()\n-        for _ in xrange(5):\n+        for _ in range(5):\n             q.enqueue(do_nothing)\n \n         w = Worker([q])\n", "before": "for _ in xrange ( 5 ) : q . enqueue ( do_nothing )", "after": "for _ in range ( 5 ) : q . enqueue ( do_nothing )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:xrange\", 3, 18, 3, 24], \"range\"]]"}
{"project": "django-make-app", "commit_sha": "acd814433d1021aa8783362521b0bd151fdfc9d2", "parent_sha": "e42d3bf31e7c66dc741a96de79daef0ba76f74a1", "file_path": "django_make_app/io_utils.py", "project_url": "https://github.com/illagrenan/django-make-app", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -12,7 +12,7 @@ from yapf.yapflib.yapf_api import FormatFile\n \n def read_yaml_file(filename):\n     with io.open(filename, mode='r', encoding='utf-8') as the_file:\n-        return yaml.load(the_file)\n+        return yaml.safe_load(the_file)\n \n \n def optimize_code(filename):\n", "before": "return yaml . load ( the_file )", "after": "return yaml . safe_load ( the_file )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:load\", 3, 21, 3, 25], \"safe_load\"]]"}
{"project": "tribler", "commit_sha": "16f65defc9043c41177d3af160ccf7888927dd2a", "parent_sha": "1468c1d7d5cdffc97b3936269447e141c44b1010", "file_path": "Tribler/Core/Upgrade/db_upgrader.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -528,7 +528,7 @@ DROP TABLE IF EXISTS MetaDataTypes;\n         # TODO(emilon): It would be nice to drop the corrupted torrent data from the store as a bonus.\n         self.status_update_func(\"Registering recovered torrents...\")\n         try:\n-            for infoshash_str, torrent_data in self.torrent_store.itervalues():\n+            for infoshash_str, torrent_data in self.torrent_store.iteritems():\n                 self.status_update_func(\"> %s\" % infoshash_str)\n                 torrentdef = TorrentDef.load_from_memory(torrent_data)\n                 if torrentdef.is_finalized():\n", "before": "for infoshash_str , torrent_data in self . torrent_store . itervalues ( ) : self . status_update_func ( \"> %s\" % infoshash_str ) torrentdef = TorrentDef . load_from_memory ( torrent_data ) if torrentdef . is_finalized ( ) : ", "after": "for infoshash_str , torrent_data in self . torrent_store . iteritems ( ) : self . status_update_func ( \"> %s\" % infoshash_str ) torrentdef = TorrentDef . load_from_memory ( torrent_data ) if torrentdef . is_finalized ( ) : ", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:itervalues\", 3, 67, 3, 77], \"iteritems\"]]"}
{"project": "tribler", "commit_sha": "8563e144e00f7ee88060c6277071ff72063e80a3", "parent_sha": "63baa8ef052781c100b5f5e4b3b154838dbb13aa", "file_path": "Tribler/community/privatesocial/community.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -162,7 +162,7 @@ class SocialCommunity(Community):\n         encrypted_message = self.dispersy.crypto.encrypt(key, message_str)\n         \n         # get overlapping connections\n-        overlapping_candidates = self.get_tbs_which_overlap(self.yield_taste_buddies(), [keyhash,])\n+        overlapping_candidates = self.filter_overlap(self.yield_taste_buddies(), [keyhash,])\n \n         meta = self.get_meta_message(u\"encrypted\")\n         message = meta.impl(authentication=(self._my_member,),\n", "before": "overlapping_candidates = self . get_tbs_which_overlap ( self . yield_taste_buddies ( ) , [ keyhash , ] )", "after": "overlapping_candidates = self . filter_overlap ( self . yield_taste_buddies ( ) , [ keyhash , ] )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:get_tbs_which_overlap\", 3, 39, 3, 60], \"filter_overlap\"]]"}
{"project": "cerbero", "commit_sha": "b98e6666486fb31f1a9689e685d492ecae2c2b78", "parent_sha": "3bd22069f9500f90067465ed345f0862b4d56379", "file_path": "cerbero/build/source.py", "project_url": "https://github.com/protonpopsicle/cerbero", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -78,7 +78,7 @@ class Tarball (Source):\n     def __init__(self):\n         Source.__init__(self)\n         if not self.url:\n-            raise FatalError(_(\"'url' attribute is missing in the recipe\"))\n+            raise InvalidRecipeError(_(\"'url' attribute is missing in the recipe\"))\n         self.url = self.url % {'version': self.version, 'name': self.name}\n         self.filename = os.path.basename(self.url)\n         self.download_path = os.path.join(self.repo_dir, self.filename)\n", "before": "raise FatalError ( _ ( \"'url' attribute is missing in the recipe\" ) )", "after": "raise InvalidRecipeError ( _ ( \"'url' attribute is missing in the recipe\" ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:FatalError\", 3, 19, 3, 29], \"InvalidRecipeError\"]]"}
{"project": "ansible-bender", "commit_sha": "06b86ed01d83976833d139eac251b9176509057e", "parent_sha": "d593e4cee9d862d4f8895be11b51328b8baf8a6d", "file_path": "ansible_bender/utils.py", "project_url": "https://github.com/TomasTomecek/ansible-bender", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,7 +31,7 @@ def graceful_get(d, *keys, default=None):\n         try:\n             response = response[k]\n         except (KeyError, AttributeError, TypeError) as ex:\n-            logger.error(\"can't obtain %s: %s\", k, ex)\n+            logger.debug(\"can't obtain %s: %s\", k, ex)\n             return default\n     return response\n \n", "before": "logger . error ( \"can't obtain %s: %s\" , k , ex )", "after": "logger . debug ( \"can't obtain %s: %s\" , k , ex )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:error\", 3, 20, 3, 25], \"debug\"]]"}
{"project": "notify", "commit_sha": "49124b73cf5ab2bae24c8e06dbe654aa5cd567ed", "parent_sha": "6244d744f70349f16fa7ba639879642d7cea33e4", "file_path": "utils/notifications_utils/logging.py", "project_url": "https://github.com/govau/notify", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -185,5 +185,5 @@ class JSONFormatter(BaseJSONFormatter):\n         try:\n             log_record['message'] = log_record['message'].format(**log_record)\n         except KeyError as e:\n-            logger.exception(\"JSONFormatter: failed to format log message: {} not found\".format(e))\n+            logger.warning(\"JSONFormatter: failed to format log message: {} not found\".format(e))\n         return log_record\n", "before": "logger . exception ( \"JSONFormatter: failed to format log message: {} not found\" . format ( e ) )", "after": "logger . warning ( \"JSONFormatter: failed to format log message: {} not found\" . format ( e ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:exception\", 3, 20, 3, 29], \"warning\"]]"}
{"project": "cc-utils", "commit_sha": "b8aae7b5520f6cd06059520935cabbf58f8de0b7", "parent_sha": "d3432c7471e82cfc6032c605b4ee2339daed36bf", "file_path": "doc/lib/sphinxutil.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -55,7 +55,7 @@ class SphinxUtilsMixin(object):\n         section_node = nodes.section(ids=[ids])\n \n         par_node, messages = self.create_paragraph(content)\n-        title_node = self._get_subtitle_node(title)\n+        title_node = self.create_subtitle(title)\n         section_node += title_node\n         section_node += par_node\n         return section_node, messages\n", "before": "title_node = self . _get_subtitle_node ( title )", "after": "title_node = self . create_subtitle ( title )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:_get_subtitle_node\", 3, 27, 3, 45], \"create_subtitle\"]]"}
{"project": "cc-utils", "commit_sha": "da933e1254535da3b6fcfd531fc54abe54fc40ea", "parent_sha": "63c8cfd9a42db90ddc436f8999d55642b961c4c7", "file_path": "concourse/steps/scan_container_images.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ class MailRecipients(object):\n \n     def add_protecode_results(self, results: typing.Iterable[UploadResult]):\n         for result in results:\n-            if not self.result_filter(component=result.component):\n+            if not self._result_filter(component=result.component):\n                 continue\n             self._protecode_results.append(result)\n \n", "before": "if not self . result_filter ( component = result . component ) : continue", "after": "if not self . _result_filter ( component = result . component ) : continue", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:result_filter\", 3, 25, 3, 38], \"_result_filter\"]]"}
{"project": "cc-utils", "commit_sha": "768da24c105e39f6810c55ff93c8dac6ebf1f6f1", "parent_sha": "01b9b28aac8e093d3a4545c3fe1fb64b16f6f6fa", "file_path": "model/gardenlinux_cache.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ class GardenlinuxCacheConfig(NamedModelElement):\n     def ingress_host(self, cfg_factory):\n         cluster_domain = cluster_domain_from_kubernetes_config(\n             cfg_factory,\n-            self.kubernetes_cluster_config(),\n+            self.kubernetes_config_name(),\n         )\n         return f'{GARDENLINUX_CACHE_SUBDOMAIN_LABEL}.{cluster_domain}'\n \n", "before": "cluster_domain = cluster_domain_from_kubernetes_config ( cfg_factory , self . kubernetes_cluster_config ( ) , )", "after": "cluster_domain = cluster_domain_from_kubernetes_config ( cfg_factory , self . kubernetes_config_name ( ) , )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:kubernetes_cluster_config\", 3, 18, 3, 43], \"kubernetes_config_name\"]]"}
{"project": "cc-utils", "commit_sha": "c924ed4a25bc9a7ba866d1a0fd36299352ef0950", "parent_sha": "69b7c21fa5898abf9928b27b4dfe2332535eeeaa", "file_path": "model/concourse.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -143,7 +143,7 @@ class ConcourseUAM(NamedModelElement):\n \n     def password(self) -> str:\n         if local_user := self.local_user():\n-            return local_user.password()\n+            return local_user.passwd()\n \n     def role(self) -> str:\n         return self.raw.get('role')\n", "before": "return local_user . password ( )", "after": "return local_user . passwd ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:password\", 3, 31, 3, 39], \"passwd\"]]"}
{"project": "WMAS", "commit_sha": "f286173cfef6dd52aaf4f9ce65c69df14b5208c8", "parent_sha": "be4f5f904688e261dbdb3c313df44fb5bd8b8f9a", "file_path": "progress-events/tests/submissions/Samsung/resources/no-content-length.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1,5 +1,5 @@\n def main(request, response):\n-    response.headers.extend([('Transfer-Encoding', 'chunked'),\n+    response.headers.update([('Transfer-Encoding', 'chunked'),\n                              ('Content-Type', 'text/html'),\n                              ('Connection', 'keep-alive')])\n     response.write_status_headers()\n", "before": "response . headers . extend ( [ ( 'Transfer-Encoding' , 'chunked' ) , ( 'Content-Type' , 'text/html' ) , ( 'Connection' , 'keep-alive' ) ] )", "after": "response . headers . update ( [ ( 'Transfer-Encoding' , 'chunked' ) , ( 'Content-Type' , 'text/html' ) , ( 'Connection' , 'keep-alive' ) ] )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:extend\", 1, 22, 1, 28], \"update\"]]"}
{"project": "XBMC-Songza-Plugin", "commit_sha": "01093add21e414a9aa4f3d45426a6cf9a94c0668", "parent_sha": "47453ce0b3cf80e836320faae8a7a0ef1a2f1b0b", "file_path": "resources/lib/functions.py", "project_url": "https://github.com/djcode/XBMC-Songza-Plugin", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -19,6 +19,6 @@ def get_params():\n     return param\n \t\n def add_dir(name, url=''):\n-    li = xbmcgui.ListItem(str(name))\n+    li = xbmcgui.ListItem(unicode(name))\n     return xbmcplugin.addDirectoryItem(int(sys.argv[1]), sys.argv[0]+str(url), li, isFolder=True)\n     \n\\ No newline at end of file\n", "before": "li = xbmcgui . ListItem ( str ( name ) )", "after": "li = xbmcgui . ListItem ( unicode ( name ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:str\", 3, 27, 3, 30], \"unicode\"]]"}
{"project": "WMAS", "commit_sha": "6664646ba2571011f908219b047b40753ddf0ca2", "parent_sha": "3e5e627bcae154b114633462d97731638f0deff6", "file_path": "tools/webdriver/webdriver/client.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -600,7 +600,7 @@ class Element(object):\n                 \"value\": selector}\n \n         elem = self.send_element_command(\"POST\", \"element\", body)\n-        return self.session.element(elem)\n+        return self.session._element(elem)\n \n     @command\n     def click(self):\n", "before": "return self . session . element ( elem )", "after": "return self . session . _element ( elem )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:element\", 3, 29, 3, 36], \"_element\"]]"}
{"project": "FreeCAD_assembly3", "commit_sha": "2121abacfe9d69f1247c37a0f00cc43782ca3dc2", "parent_sha": "49625d3b0ca3cd035c79fca4f1535766acdbfba8", "file_path": "constraint.py", "project_url": "https://github.com/realthunder/FreeCAD_assembly3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1013,7 +1013,7 @@ class BaseCascade(BaseMulti):\n                 params = props + [e1,e2]\n             else:\n                 params = props + [e2,e1]\n-            solver.system.checkRedendancy(obj,prevInfo,partInfo)\n+            solver.system.checkRedundancy(obj,prevInfo,partInfo)\n             h = func(*params,group=solver.group)\n             if isinstance(h,(list,tuple)):\n                 ret += list(h)\n", "before": "solver . system . checkRedendancy ( obj , prevInfo , partInfo )", "after": "solver . system . checkRedundancy ( obj , prevInfo , partInfo )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:checkRedendancy\", 3, 27, 3, 42], \"checkRedundancy\"]]"}
{"project": "calefaction", "commit_sha": "12d0f3be9b2a7c0607128c8ebcd2baf56472489b", "parent_sha": "0c46e7f0c4fe5ce959686e4c82ab93be06e182ac", "file_path": "calefaction/eve/universe.py", "project_url": "https://github.com/earwig/calefaction", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -409,7 +409,7 @@ class Universe:\n         self._load()\n         if tid not in self._types:\n-            return _DummyKillable(self)\n+            return _DummyType(self)\n         return _Type(self, tid, self._types[tid])\n \n     def killable(self, kid):\n", "before": "return _DummyKillable ( self )", "after": "return _DummyType ( self )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:_DummyKillable\", 2, 20, 2, 34], \"_DummyType\"]]"}
{"project": "pyMaid", "commit_sha": "effbaa7f5dfaf9622a04f6b4d1d1353b3093627e", "parent_sha": "48ec96ae71398d0f84fb29cda477b49b17cd8e9c", "file_path": "pymaid/tests/test_pymaid.py", "project_url": "https://github.com/schlegelp/pyMaid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -938,9 +938,9 @@ class TestTiles(unittest.TestCase):\n     def test_tiles(self):\n         from pymaid import tiles\n         # Generate the job\n-        job = tiles.LoadTiles([119000, 119500, 36000, 36500, 4050],\n-                              stack_id=5,\n-                              coords='PIXEL')\n+        job = tiles.TileLoader([119000, 119500, 36000, 36500, 4050],\n+                               stack_id=5,\n+                               coords='PIXEL')\n         # Load, stich and crop the required EM image tiles\n         job.load_in_memory()\n         # Render image\n", "before": "job = tiles . LoadTiles ( [ 119000 , 119500 , 36000 , 36500 , 4050 ] , stack_id = 5 , coords = 'PIXEL' )", "after": "job = tiles . TileLoader ( [ 119000 , 119500 , 36000 , 36500 , 4050 ] , stack_id = 5 , coords = 'PIXEL' )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:LoadTiles\", 3, 21, 3, 30], \"TileLoader\"]]"}
{"project": "pyMaid", "commit_sha": "5d4f14f338cf15d49b45fc9a6292a996701ea6e1", "parent_sha": "d39bab4479847a74efa781c43b4c581c982fe7ac", "file_path": "pymaid/core.py", "project_url": "https://github.com/schlegelp/pyMaid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -300,7 +300,7 @@ class CatmaidNeuron(navis.TreeNeuron):\n         \"\"\"Implement division for coordinates (nodes, connectors).\"\"\"\n         # Exclude missing radii from division\n         is_missing = self.nodes.radius == -1\n-        n = super().__mul__(other)\n+        n = super().__truediv__(other)\n         n.nodes.loc[is_missing, 'radius'] = -1\n \n         return n\n", "before": "n = super ( ) . __mul__ ( other )", "after": "n = super ( ) . __truediv__ ( other )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:__mul__\", 3, 21, 3, 28], \"__truediv__\"]]"}
{"project": "pyMaid", "commit_sha": "20f7f3aa18320e7a49dbb84d4a8e72795959085e", "parent_sha": "580a99fefeed74a6f31be460686c0b2b9ce85b9b", "file_path": "pymaid/user_stats.py", "project_url": "https://github.com/schlegelp/pyMaid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -313,7 +313,7 @@ def get_time_invested(x, remote_instance=None, minimum_actions=10, treenodes=Tru\n             connector_ids += n.connectors.connector_id.tolist()\n \n     # Get node details\n-    node_details = fetch.get_node_user_details(\n+    node_details = fetch.get_node_details(\n         node_ids + connector_ids, remote_instance=remote_instance )\n \n     # Dataframe for creation (i.e. the actual generation of the nodes)\n", "before": "node_details = fetch . get_node_user_details ( node_ids + connector_ids , remote_instance = remote_instance )", "after": "node_details = fetch . get_node_details ( node_ids + connector_ids , remote_instance = remote_instance )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:get_node_user_details\", 3, 26, 3, 47], \"get_node_details\"]]"}
{"project": "pyMaid", "commit_sha": "4aa564080b5a44bcf3cdbf6e8e9f883d11aa524c", "parent_sha": "51035bcbf3cedc882f8722630dd2cdd2b707cd19", "file_path": "pymaid/cache.py", "project_url": "https://github.com/schlegelp/pyMaid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -192,7 +192,7 @@ def wipe_and_retry(function):\n \n             # Execute function the first time (make sure no new data is added\n             # if exception is raised)\n-            res = no_cache_on_error(function)(*args, **kwargs)\n+            res = undo_on_error(function)(*args, **kwargs)\n         except:\n             # If caching is on, try the function without caching\n             if rm.caching:\n", "before": "res = no_cache_on_error ( function ) ( * args , ** kwargs )", "after": "res = undo_on_error ( function ) ( * args , ** kwargs )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:no_cache_on_error\", 3, 19, 3, 36], \"undo_on_error\"]]"}
{"project": "pyMaid", "commit_sha": "01cd02c9014b259f3979906c1de91a03e1d10fbb", "parent_sha": "e9e294103acef1ab1766e4fe7a6979a974a896ae", "file_path": "pymaid/tests/test_pymaid.py", "project_url": "https://github.com/schlegelp/pyMaid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -946,7 +946,7 @@ class TestTiles(unittest.TestCase):\n                               stack_id=5,\n                               coords='PIXEL')\n         # Load, stich and crop the required EM image tiles\n-        job.generate_img()\n+        job.load_in_memory()\n         # Render image\n         ax = job.render_im(slider=False, figsize=(12, 12))\n         # Add treenodes\n", "before": "coords = 'PIXEL' ) job . generate_img ( )", "after": "coords = 'PIXEL' ) job . load_in_memory ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:generate_img\", 3, 13, 3, 25], \"load_in_memory\"]]"}
{"project": "pyMaid", "commit_sha": "8e8913035d24be026092cdc31210d507d74c9f69", "parent_sha": "62b18a3c3f622bd073aaa037f4b976336ebc6a0c", "file_path": "pymaid/rmaid.py", "project_url": "https://github.com/schlegelp/pyMaid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -442,7 +442,7 @@ def neuron2r(neuron, convert_to_um=False):\n         nlist.rownames = neuron.skeleton_id.tolist()\n \n         df = robjects.DataFrame({'pid': robjects.IntVector([1] * neuron.shape[0]),\n-                                 'skid': robjects.IntVector(neuron.skeleton_id.tolist()),\n+                                 'skid': robjects.StrVector(neuron.skeleton_id.tolist()),\n                                  'name': robjects.StrVector(neuron.neuron_name.tolist())\n                                  })\n         df.rownames = neuron.skeleton_id.tolist()\n", "before": "df = robjects . DataFrame ( { 'pid' : robjects . IntVector ( [ 1 ] * neuron . shape [ 0 ] ) , 'skid' : robjects . IntVector ( neuron . skeleton_id . tolist ( ) ) , 'name' : robjects . StrVector ( neuron . neuron_name . tolist ( ) ) } )", "after": "df = robjects . DataFrame ( { 'pid' : robjects . IntVector ( [ 1 ] * neuron . shape [ 0 ] ) , 'skid' : robjects . StrVector ( neuron . skeleton_id . tolist ( ) ) , 'name' : robjects . StrVector ( neuron . neuron_name . tolist ( ) ) } )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:IntVector\", 3, 51, 3, 60], \"StrVector\"]]"}
{"project": "bluesteel", "commit_sha": "c87f0ce30ef162504102549b40eebe21ac2bab53", "parent_sha": "eeb6a6bbca74026236dae5dfbabc66f851193802", "file_path": "app/logic/bluesteelworker/download/core/Worker.py", "project_url": "https://github.com/imvu/bluesteel", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -237,7 +237,7 @@ def process_update_worker_files(bootstrap_urls, settings, session):\n     log.info('Downloading remote Worker files.')\n     resp_f = session.get(bootstrap_urls['worker_download_url'], {})\n     if resp_f['succeed'] and resp_f['type'] == 'application/zip':\n-        zip_ext = ZipFile(io.StringIO(resp_f['content']))\n+        zip_ext = ZipFile(io.BytesIO(resp_f['content']))\n         tmp_zip_folder = str(os.path.join(get_cwd(), os.sep.join(settings['tmp_path']), '..', 'worker_zip'))\n         tmp_zip_folder = os.path.normpath(tmp_zip_folder)\n \n", "before": "zip_ext = ZipFile ( io . StringIO ( resp_f [ 'content' ] ) )", "after": "zip_ext = ZipFile ( io . BytesIO ( resp_f [ 'content' ] ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:StringIO\", 3, 30, 3, 38], \"BytesIO\"]]"}
{"project": "gmail", "commit_sha": "86d79f9593c2dfeba404c391f65e3f80e44e42dc", "parent_sha": "ebab36b36337a6417d166b47529350ef2e7b3e83", "file_path": "gmail/gmail.py", "project_url": "https://github.com/girishramnani/gmail", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -141,7 +141,7 @@ class Gmail():\n         self.imap.uid('COPY', uid, to_mailbox)\n \n     def fetch_multiple_messages(self, messages):\n-        fetch_str =  ','.join(messages.items())\n+        fetch_str =  ','.join(messages.keys())\n         response, results = self.imap.uid('FETCH', fetch_str, '(BODY.PEEK[] FLAGS X-GM-THRID X-GM-MSGID X-GM-LABELS)')\n         for index in xrange(len(results) - 1):\n             raw_message = results[index]\n", "before": "fetch_str = ',' . join ( messages . items ( ) )", "after": "fetch_str = ',' . join ( messages . keys ( ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:items\", 3, 40, 3, 45], \"keys\"]]"}
{"project": "angr", "commit_sha": "adfb62a6aaf6710dac3f6f1282f8ee4ad7cafe27", "parent_sha": "f60af0399c409c5e9461b50f5480614d80ee6080", "file_path": "simuvex/s_ccall.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -487,7 +487,7 @@ def amd64g_calculate_condition(state, cond, cc_op, cc_dep1, cc_dep2, cc_ndep):\n \treturn pc_calculate_condition(state, cond, cc_op, cc_dep1, cc_dep2, cc_ndep, platform='AMD64')\n \n def amd64g_calculate_rflags_all(state, cc_op, cc_dep1, cc_dep2, cc_ndep):\n-\treturn pc_calculate_rflags_all(state, cc_op, cc_dep1, cc_dep2, cc_ndep, platform='AMD64')\n+\treturn pc_calculate_rdata_all(state, cc_op, cc_dep1, cc_dep2, cc_ndep, platform='AMD64')\n \n def amd64g_calculate_rflags_c(state, cc_op, cc_dep1, cc_dep2, cc_ndep):\n \treturn pc_calculate_rdata_c(state, cc_op, cc_dep1, cc_dep2, cc_ndep, platform='AMD64')\n", "before": "return pc_calculate_rflags_all ( state , cc_op , cc_dep1 , cc_dep2 , cc_ndep , platform = 'AMD64' )", "after": "return pc_calculate_rdata_all ( state , cc_op , cc_dep1 , cc_dep2 , cc_ndep , platform = 'AMD64' )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:pc_calculate_rflags_all\", 3, 9, 3, 32], \"pc_calculate_rdata_all\"]]"}
{"project": "angr", "commit_sha": "94d9104f4ff7c375dfb300f8c8a9f0b5bb5656c4", "parent_sha": "52820c9a82f730eb5857dab8379c5bb2a1178bf7", "file_path": "angr/analyses/cfg.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -252,7 +252,7 @@ class CFG(Analysis, CFGBase):\n                     for addr in ex[:-1]:\n                         s += \"0x%x\" % addr if addr is not None else \"None\" + \", \"\n                     s += \"] %s)\" % (\"0x%x\" % ex[-1] if ex[-1] is not None else None)\n-                    l.warning(\"Key %s does not exist. Create a PathTerminator instead.\", s)\n+                    l.debug(\"Key %s does not exist. Create a PathTerminator instead.\", s)\n \n                 target_bbl = self._bbl_dict[ex]\n                 cfg.add_edge(basic_block, target_bbl, jumpkind=jumpkind)\n", "before": "l . warning ( \"Key %s does not exist. Create a PathTerminator instead.\" , s )", "after": "l . debug ( \"Key %s does not exist. Create a PathTerminator instead.\" , s )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:warning\", 3, 23, 3, 30], \"debug\"]]"}
{"project": "angr", "commit_sha": "2620ee651be1b355fb58f6f266fb398b45ca250e", "parent_sha": "8863853a20cf71471b596bb86c4aa96ceaaf0554", "file_path": "angr/call_stack.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -46,7 +46,7 @@ class CallFrame(object):\n             # Try to convert the ret_addr to an integer\n             try:\n                 if self.ret_addr.symbolic:\n-                    l.warning('CallStack does not support symbolic return addresses for performance concerns.')\n+                    l.debug('CallStack does not support symbolic return addresses for performance concerns.')\n                     self.ret_addr = None\n                 else:\n                     self.ret_addr = state.se.any_int(self.ret_addr)\n", "before": "l . warning ( 'CallStack does not support symbolic return addresses for performance concerns.' )", "after": "l . debug ( 'CallStack does not support symbolic return addresses for performance concerns.' )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:warning\", 3, 23, 3, 30], \"debug\"]]"}
{"project": "pyoidc", "commit_sha": "49a37501352c01dff96d74c0daeedf4fbd749978", "parent_sha": "3d5cfd91a128f7f26a09621f98e2ff318e06c7c6", "file_path": "src/oic/oic/provider.py", "project_url": "https://github.com/qaavi/pyoidc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -439,7 +439,7 @@ class Provider(AProvider):\n             try:\n                 resq = self._parse_openid_request(http_req.text)\n             except Exception as err:\n-                logger.err(\n+                logger.error(\n                     '{} encountered while parsing fetched request'.format(err))\n                 return self._redirect_authz_error(\n                     \"invalid_openid_request_object\", redirect_uri)\n", "before": "logger . err ( '{} encountered while parsing fetched request' . format ( err ) )", "after": "logger . error ( '{} encountered while parsing fetched request' . format ( err ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:err\", 3, 24, 3, 27], \"error\"]]"}
{"project": "pyoidc", "commit_sha": "6d4b7849a292f1bd21ad85ed8c669e643338ebe5", "parent_sha": "49a37501352c01dff96d74c0daeedf4fbd749978", "file_path": "src/oic/oic/provider.py", "project_url": "https://github.com/qaavi/pyoidc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -444,7 +444,7 @@ class Provider(AProvider):\n                 return self._redirect_authz_error(\n                     \"invalid_openid_request_object\", redirect_uri)\n \n-            logger.debig('Fetched request: {}'.format(resq))\n+            logger.debug('Fetched request: {}'.format(resq))\n             areq[\"request\"] = resq\n \n         # The \"request\" in areq case is handled by .verify()\n", "before": "logger . debig ( 'Fetched request: {}' . format ( resq ) )", "after": "logger . debug ( 'Fetched request: {}' . format ( resq ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:debig\", 3, 20, 3, 25], \"debug\"]]"}
{"project": "pyoidc", "commit_sha": "567ed082f7463cbfbbeb94dd4c4d5b6970d5af23", "parent_sha": "270570e112ece3fabc697335e48b8b2b99e9e9b6", "file_path": "src/oic/oic/provider.py", "project_url": "https://github.com/qaavi/pyoidc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1665,7 +1665,7 @@ class Provider(AProvider):\n         except Exception as err:\n             message = traceback.format_exception(*sys.exc_info())\n             logger.error(message)\n-            resp = Response(message, content=\"html/text\")\n+            resp = BadRequest(message, content=\"html/text\")\n \n         return resp\n \n", "before": "resp = Response ( message , content = \"html/text\" )", "after": "resp = BadRequest ( message , content = \"html/text\" )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:Response\", 3, 20, 3, 28], \"BadRequest\"]]"}
{"project": "angr", "commit_sha": "46ceb0467a70cc08657e9bc41b183d0c17870b2a", "parent_sha": "996edb772bf419830ce9471b60673a674e5688d0", "file_path": "simuvex/procedures/cgc/random.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,6 +15,6 @@ class random(simuvex.SimProcedure):\n \n \t\tif self.state.satisfiable(extra_constraints=[count!=0]):\n \t\t\tself.state.store_mem(buf, self.state.se.BV('random_%d' % rand_count.next(), self.state.se.max_int(count*8)), size=count)\n-\t\tself.state.store(rnd_bytes, count)\n+\t\tself.state.store_mem(rnd_bytes, count)\n \n \t\treturn r\n", "before": "self . state . store ( rnd_bytes , count )", "after": "self . state . store_mem ( rnd_bytes , count )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:store\", 3, 14, 3, 19], \"store_mem\"]]"}
{"project": "angr", "commit_sha": "43bdcb8291c04822f04024ff3d99c47414af5059", "parent_sha": "2836dc04563aa2f3335ae6200f787e6ea2a5c8bb", "file_path": "angr/analyses/cfg_base.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -375,7 +375,7 @@ class CFGBase(Analysis):\n                                 itstate >>= 8\n \n         if it_counter != 0:\n-            l.error('Basic block ends before calculated IT block (%#x)', addr)\n+            l.debug('Basic block ends before calculated IT block (%#x)', addr)\n \n         THUMB_BRANCH_INSTRUCTIONS = ('beq', 'bne', 'bcs', 'bhs', 'bcc', 'blo', 'bmi', 'bpl', 'bvs',\n                                      'bvc', 'bhi', 'bls', 'bge', 'blt', 'bgt', 'ble', 'cbz', 'cbnz')\n", "before": "l . error ( 'Basic block ends before calculated IT block (%#x)' , addr )", "after": "l . debug ( 'Basic block ends before calculated IT block (%#x)' , addr )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:error\", 3, 15, 3, 20], \"debug\"]]"}
{"project": "angr", "commit_sha": "26d02a073308a34d47d680b9d3948ee4200cbece", "parent_sha": "da15c89923b34491afa1e8a7aa5c6180130e969b", "file_path": "angr/path_history.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -176,7 +176,7 @@ class HistoryIter(TreeIter):\n class AddrIter(TreeIter):\n \tdef __reversed__(self):\n \t\tfor hist in self._iter_nodes():\n-\t\t\tfor a in iter(hist._addrs):\n+\t\t\tfor a in reversed(hist._addrs):\n \t\t\t\tyield a\n \n class RunstrIter(TreeIter):\n", "before": "for a in iter ( hist . _addrs ) : yield a", "after": "for a in reversed ( hist . _addrs ) : yield a", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:iter\", 3, 13, 3, 17], \"reversed\"]]"}
{"project": "yasso07ui", "commit_sha": "e900edb0d9e70ce8b13711213f6436bcfca62735", "parent_sha": "8ca0fa5f78f3780b7a4f83f9e2e36889356ad5da", "file_path": "yasso.py", "project_url": "https://github.com/JariLiski/yasso07ui", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -717,7 +717,7 @@ class Yasso(HasTraits):\n ########################\n \n     def _new_data_file_event_fired(self):\n-        filename = open_file()\n+        filename = save_file()\n         if filename != '':\n             try:\n                 f=open(filename, 'w')\n", "before": "filename = open_file ( )", "after": "filename = save_file ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:open_file\", 3, 20, 3, 29], \"save_file\"]]"}
{"project": "bzzz", "commit_sha": "178e3f1c9711aa0ea55a57359ed9c5f44cc82045", "parent_sha": "5e4a5c3865362b5fd513b304d7e8fb4bffb13007", "file_path": "hx711_vincent.py", "project_url": "https://github.com/bernardarzur/bzzz", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -45,7 +45,7 @@ class HX711:\n             for i in range(0, 8):\n                 self.pSCK.value(True)\n                 octet <<= 1\n-                bitLu = self.pOUt()\n+                bitLu = self.pOut()\n                 if bitLu: octet += 1\n                 self.pSCK.value(False)\n \n", "before": "bitLu = self . pOUt ( )", "after": "bitLu = self . pOut ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:pOUt\", 3, 30, 3, 34], \"pOut\"]]"}
{"project": "bzzz", "commit_sha": "0d80f4078727c6026dca19da6b631d0db3041e9e", "parent_sha": "178e3f1c9711aa0ea55a57359ed9c5f44cc82045", "file_path": "hx711_vincent.py", "project_url": "https://github.com/bernardarzur/bzzz", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -45,7 +45,7 @@ class HX711:\n             for i in range(0, 8):\n                 self.pSCK.value(True)\n                 octet <<= 1\n-                bitLu = self.pOut()\n+                bitLu = self.pOUT()\n                 if bitLu: octet += 1\n                 self.pSCK.value(False)\n \n", "before": "bitLu = self . pOut ( )", "after": "bitLu = self . pOUT ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:pOut\", 3, 30, 3, 34], \"pOUT\"]]"}
{"project": "ottertune", "commit_sha": "30664b4c37505a2fa717ba7a427adbc6748d43ca", "parent_sha": "96e7cbc7bec0a52a2a4da649f3dae783a46d047f", "file_path": "server/website/website/tasks/async_tasks.py", "project_url": "https://github.com/master-MR-han/ottertune", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -319,7 +319,7 @@ def configuration_recommendation(target_data):\n     i = 0\n     while i < TOP_NUM_CONFIG:\n         try:\n-            item = q.get()\n+            item = q.get_nowait()\n             # Tensorflow get broken if we use the training data points as\n             # starting points for GPRGD. We add a small bias for the\n             # starting points. GPR_EPS default value is 0.001\n", "before": "item = q . get ( )", "after": "item = q . get_nowait ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:get\", 3, 22, 3, 25], \"get_nowait\"]]"}
{"project": "SentEval", "commit_sha": "2572460d9667e2f1d56be7e35082b275761901b6", "parent_sha": "d4353853d6fbd72876f658062b77ab1f5e371265", "file_path": "senteval/tools/relatedness.py", "project_url": "https://github.com/vrindaprabhu/SentEval", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -50,7 +50,7 @@ class RelatednessPytorch(object):\n         self.loss_fn = nn.MSELoss()\n \n         if torch.cuda.is_available():\n-            self.model = self.model.coda()\n+            self.model = self.model.cuda()\n             self.loss_fn = self.loss_fn.cuda()\n \n         self.loss_fn.size_average = False\n", "before": "self . model = self . model . coda ( )", "after": "self . model = self . model . cuda ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:coda\", 3, 37, 3, 41], \"cuda\"]]"}
{"project": "mitmproxy", "commit_sha": "5746472426d3928497e9c8f85664a46598a044af", "parent_sha": "4339b8e7fa1140b9138a023e7e61d78cefe6bb02", "file_path": "libmproxy/protocol2/http.py", "project_url": "https://github.com/aisier/mitmproxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -469,7 +469,7 @@ class HttpLayer(Layer):\n \n     def validate_request(self, request):\n         if request.form_in == \"absolute\" and request.scheme != \"http\":\n-            self.send_resplonse(make_error_response(400, \"Invalid request scheme: %s\" % request.scheme))\n+            self.send_response(make_error_response(400, \"Invalid request scheme: %s\" % request.scheme))\n             raise HttpException(\"Invalid request scheme: %s\" % request.scheme)\n \n         expected_request_forms = {\n", "before": "self . send_resplonse ( make_error_response ( 400 , \"Invalid request scheme: %s\" % request . scheme ) )", "after": "self . send_response ( make_error_response ( 400 , \"Invalid request scheme: %s\" % request . scheme ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:send_resplonse\", 3, 18, 3, 32], \"send_response\"]]"}
{"project": "autogamess", "commit_sha": "e0aa1ac62871d7e3950c80b509a92081c6955131", "parent_sha": "d760d4d437cb765f99afb24777c7dff03f15a133", "file_path": "autogamess/hes2raman.py", "project_url": "https://github.com/Cavenfish/autogamess", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -55,7 +55,7 @@ def hes2raman(hesfile, datfile):\n     f.close()\n \n     #checks if they are in file\n-    if check_if_in(datfile, ctr_f(s,grab), ctr_f(e,grab)):\n+    if check_if_exists(datfile, ctr_f(s,grab), ctr_f(e,grab)):\n         raise ValueError()\n \n     #Define start and end indexes\n", "before": "if check_if_in ( datfile , ctr_f ( s , grab ) , ctr_f ( e , grab ) ) : raise ValueError ( )", "after": "if check_if_exists ( datfile , ctr_f ( s , grab ) , ctr_f ( e , grab ) ) : raise ValueError ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:check_if_in\", 3, 8, 3, 19], \"check_if_exists\"]]"}
{"project": "autogamess", "commit_sha": "613e44181d8d3111740328267daf908578da3efb", "parent_sha": "be0f57e3eb8265402e9ed95c633a31cbe57aa844", "file_path": "autogamess/opt2hes.py", "project_url": "https://github.com/Cavenfish/autogamess", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -100,7 +100,7 @@ def opt2hes(optfile, logfile):\n         #ie: 'Si' instead of the GAMESS way 'SI'\n         if (len(coord.split(' ')[1]) > 1) and (index == -1):\n             old    = coord.split(' ')[1][1]\n-            new    = coord.split(' ')[1][1].upper()\n+            new    = coord.split(' ')[1][1].lower()\n             coord  = coord.replace(old, new)\n             index  = ctr_f(coord.split('.0')[0].replace(' ',''), temp)\n \n", "before": "new = coord . split ( ' ' ) [ 1 ] [ 1 ] . upper ( )", "after": "new = coord . split ( ' ' ) [ 1 ] [ 1 ] . lower ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:upper\", 3, 45, 3, 50], \"lower\"]]"}
{"project": "openeats-api", "commit_sha": "49b4bb5f3e0a94acea1177d2d493576231616d8a", "parent_sha": "4624b38f266733bbb3f479ea7255305704ff5e8f", "file_path": "v1/common/tests/test_permission.py", "project_url": "https://github.com/open-eats/openeats-api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ class PermissionTest(TestCase):\n         )\n         request = self.factory.post('/admin')\n         request.user = AnonymousUser()\n-        self.assertFalse(\n+        self.assertTrue(\n             IsOwnerOrReadOnly().has_permission(request, None)\n         )\n \n", "before": "self . assertFalse ( IsOwnerOrReadOnly ( ) . has_permission ( request , None ) )", "after": "self . assertTrue ( IsOwnerOrReadOnly ( ) . has_permission ( request , None ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:assertFalse\", 3, 14, 3, 25], \"assertTrue\"]]"}
{"project": "mitmproxy", "commit_sha": "74a560019080b22c8f578860654ec071141b7ca7", "parent_sha": "ed5e6855652cd3a41579f700d2fb81169c60c3ea", "file_path": "test/test_tcp.py", "project_url": "https://github.com/aisier/mitmproxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -277,7 +277,7 @@ class TestClientCipherListError(test.ServerTestBase):\n class TestSSLDisconnect(test.ServerTestBase):\n     class handler(tcp.BaseHandler):\n         def handle(self):\n-            self.close()\n+            self.finish()\n     ssl = dict(\n         cert = tutils.test_data.path(\"data/server.crt\"),\n         key = tutils.test_data.path(\"data/server.key\"),\n", "before": "self . close ( )", "after": "self . finish ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:close\", 3, 18, 3, 23], \"finish\"]]"}
{"project": "autodynatrace", "commit_sha": "012d6771e639fd2bcd3d22cb3e0b48441e44bcb4", "parent_sha": "afbc9fe52ad56c268029896bc9edc3cc214f6917", "file_path": "autodynatrace/wrappers/django/middlewares.py", "project_url": "https://github.com/dlopes7/autodynatrace", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -37,7 +37,7 @@ class DynatraceMiddleware(MiddlewareClass):\n             tracer.start()\n \n         except Exception:\n-            logger.debug(\"Error tracing request\", exc_info=True)\n+            logger.error(\"Error tracing request\", exc_info=True)\n \n     def process_view(self, request, view_func, *args, **kwargs):\n         name = func_name(view_func)\n", "before": "except Exception : logger . debug ( \"Error tracing request\" , exc_info = True )", "after": "except Exception : logger . error ( \"Error tracing request\" , exc_info = True )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:debug\", 3, 20, 3, 25], \"error\"]]"}
{"project": "funcx-web-service", "commit_sha": "00fa4ae245dc3fc07dca15cda106b1aa5155ee19", "parent_sha": "93f445db38a4e02e00e235ab659b669e5276d6d9", "file_path": "routes/funcx.py", "project_url": "https://github.com/funcx-faas/funcx-web-service", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -509,7 +509,7 @@ def get_stats_from_forwarder(forwarder_address=\"http://34.207.74.221:8080\"):\n                         'code': r.status_code,\n                         'reason': 'Forwarder did not respond with liveness stats'}\n         else:\n-            response = r.json()\n+            response = r.body()\n             app.logger.debug(f'Got response from forwarder: {response}')\n \n     except Exception as e:\n", "before": "response = r . json ( )", "after": "response = r . body ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:json\", 3, 26, 3, 30], \"body\"]]"}
{"project": "funcx-web-service", "commit_sha": "0cac9ad5eeb4f463f6028eb9ba872fc8400bb297", "parent_sha": "00fa4ae245dc3fc07dca15cda106b1aa5155ee19", "file_path": "routes/funcx.py", "project_url": "https://github.com/funcx-faas/funcx-web-service", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -509,7 +509,7 @@ def get_stats_from_forwarder(forwarder_address=\"http://34.207.74.221:8080\"):\n                         'code': r.status_code,\n                         'reason': 'Forwarder did not respond with liveness stats'}\n         else:\n-            response = r.body()\n+            response = r.text()\n             app.logger.debug(f'Got response from forwarder: {response}')\n \n     except Exception as e:\n", "before": "response = r . body ( )", "after": "response = r . text ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:body\", 3, 26, 3, 30], \"text\"]]"}
{"project": "funcx-web-service", "commit_sha": "b50f47e88880621f28ece924fe548e4fc6d43108", "parent_sha": "b6390b04ce33a389a87662b925ff3ea53e2defe9", "file_path": "routes/funcx.py", "project_url": "https://github.com/funcx-faas/funcx-web-service", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -370,7 +370,7 @@ def batch_status(user_name):\n \n     return jsonify({'response' : 'batch',\n                     'request' : request.json,\n-                    'request_j' : request.ge_json(force=True),\n+                    'request_j' : request.get_json(force=True),\n                     'request_data': request.data,\n     })\n \n", "before": "return jsonify ( { 'response' : 'batch' , 'request' : request . json , 'request_j' : request . ge_json ( force = True ) , 'request_data' : request . data , } )", "after": "return jsonify ( { 'response' : 'batch' , 'request' : request . json , 'request_j' : request . get_json ( force = True ) , 'request_data' : request . data , } )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:ge_json\", 3, 43, 3, 50], \"get_json\"]]"}
{"project": "funcx-web-service", "commit_sha": "78a1ad803a03d6923582552313e275c1124bb983", "parent_sha": "295a3a3e2b58c139cda21f4b0e147e83498db630", "file_path": "models/utils.py", "project_url": "https://github.com/funcx-faas/funcx-web-service", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -12,7 +12,7 @@ from errors import *\n class db_invocation_logger(object):\n \n     def __init__(self):\n-        self.conn, self.cur = get_db_connect()\n+        self.conn, self.cur = get_db_connection()\n \n     def log(self, user_id, task_id, function_id, endpoint_id, deferred=False):\n         try:\n", "before": "self . conn , self . cur = get_db_connect ( )", "after": "self . conn , self . cur = get_db_connection ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:get_db_connect\", 3, 31, 3, 45], \"get_db_connection\"]]"}
{"project": "OpenNMT-entmax", "commit_sha": "4927512709e754ecf8de70c47065a492190017a0", "parent_sha": "f43ac713e6fb0fb089ceeb145fc77f7acd7cb9c7", "file_path": "train.py", "project_url": "https://github.com/deep-spin/OpenNMT-entmax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -395,7 +395,7 @@ def build_optim(model, checkpoint):\n     # Importantly, this method does not yet load the optimizer state, as\n     # essentially it builds a new optimizer with empty optimizer state and\n     # parameters from the model.\n-    optim.set_parameters(model.parameters())\n+    optim.set_parameters(model.named_parameters())\n     print(\n         \"Stage 1: Keys after executing optim.set_parameters\" +\n         \"(model.parameters())\")\n", "before": "optim . set_parameters ( model . parameters ( ) )", "after": "optim . set_parameters ( model . named_parameters ( ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:parameters\", 3, 32, 3, 42], \"named_parameters\"]]"}
{"project": "OpenNMT-entmax", "commit_sha": "6a63d0a8b3850455596d8edf93489037fbc5718d", "parent_sha": "23fe7c379839ee3c4efd0fd4788ffc993b239aad", "file_path": "onmt/io/IO.py", "project_url": "https://github.com/deep-spin/OpenNMT-entmax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -18,7 +18,7 @@ def set_logger(script):\n     root_logger = logging.getLogger()\n     root_logger.setLevel(logging.DEBUG)\n \n-    file_handler = logging.fileHandler(script + \".logs\")\n+    file_handler = logging.FileHandler(script + \".logs\")\n     file_handler.setFormatter(log_format)\n     root_logger.addHandler(file_handler)\n \n", "before": "file_handler = logging . fileHandler ( script + \".logs\" )", "after": "file_handler = logging . FileHandler ( script + \".logs\" )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:fileHandler\", 3, 28, 3, 39], \"FileHandler\"]]"}
{"project": "OpenNMT-entmax", "commit_sha": "c48e943074cdb950f564ab03f85ca2c8dd18eefa", "parent_sha": "0ecec8b4c16fdec7d8ce2646a0ea47ab6535d308", "file_path": "onmt/Loss.py", "project_url": "https://github.com/deep-spin/OpenNMT-entmax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -192,7 +192,7 @@ class NMTLossCompute(LossComputeBase):\n             log_likelihood = torch.gather(scores.data, 1, tdata.unsqueeze(1))\n             tmp_ = self.one_hot.repeat(gtruth.size(0), 1)\n             tmp_.scatter_(1, tdata.unsqueeze(1), self.confidence)\n-            if mask.dim() > 0:\n+            if mask.numel() > 0:\n                 log_likelihood.index_fill_(0, mask, 0)\n                 tmp_.index_fill_(0, mask, 0)\n             gtruth = Variable(tmp_, requires_grad=False)\n", "before": "if mask . dim ( ) > 0 : log_likelihood . index_fill_ ( 0 , mask , 0 ) tmp_ . index_fill_ ( 0 , mask , 0 )", "after": "if mask . numel ( ) > 0 : log_likelihood . index_fill_ ( 0 , mask , 0 ) tmp_ . index_fill_ ( 0 , mask , 0 )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:dim\", 3, 21, 3, 24], \"numel\"]]"}
{"project": "OpenNMT-entmax", "commit_sha": "25abfafcff4a66a4af05956e2652b5c79cd76785", "parent_sha": "bebc4cc41d5344c405a2d4ee2d15c59ecf0fee6e", "file_path": "onmt/translate/translation_server.py", "project_url": "https://github.com/deep-spin/OpenNMT-entmax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -214,7 +214,7 @@ class ServerModel:\n         timer.start()\n         self.out_file = io.StringIO()\n         try:\n-            self.translator = make_translator(self.opt,\n+            self.translator = build_translator(self.opt,\n                                               report_score=False,\n                                               out_file=self.out_file)\n         except RuntimeError as e:\n", "before": "self . translator = make_translator ( self . opt , report_score = False , out_file = self . out_file )", "after": "self . translator = build_translator ( self . opt , report_score = False , out_file = self . out_file )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:make_translator\", 3, 31, 3, 46], \"build_translator\"]]"}
{"project": "OpenNMT-entmax", "commit_sha": "6f758e5f81cbba318275f3501e85c6fb72d33a1c", "parent_sha": "df7b9cee57727648be4403c2864c0b6cdc86a7e0", "file_path": "onmt/utils/cnn_factory.py", "project_url": "https://github.com/deep-spin/OpenNMT-entmax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ class GatedConv(nn.Module):\n         self.conv = onmt.modules.WeightNormConv2d(\n             input_size, 2 * input_size, kernel_size=(width, 1), stride=(1, 1),\n             padding=(width // 2 * (1 - nopad), 0))\n-        init.xavier_uniform(self.conv.weight, gain=(4 * (1 - dropout))**0.5)\n+        init.xavier_uniform_(self.conv.weight, gain=(4 * (1 - dropout))**0.5)\n         self.dropout = nn.Dropout(dropout)\n \n     def forward(self, x_var):\n", "before": "init . xavier_uniform ( self . conv . weight , gain = ( 4 * ( 1 - dropout ) ) ** 0.5 )", "after": "init . xavier_uniform_ ( self . conv . weight , gain = ( 4 * ( 1 - dropout ) ) ** 0.5 )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:xavier_uniform\", 3, 14, 3, 28], \"xavier_uniform_\"]]"}
{"project": "QCG-PilotJob", "commit_sha": "2a362926491f8b18ed6072f8444b4b3adaf04000", "parent_sha": "03aa2f51bc5b218ea2b2a69195f9c8aa31310911", "file_path": "src/qcg/appscheduler/resources.py", "project_url": "https://github.com/vecma-project/QCG-PilotJob", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -520,7 +520,7 @@ class Resources:\n             self.__systemAllocation = None\n \n         for node in self.__nodes:\n-            self.__systemAllocation = node.allocate(1)\n+            self.__systemAllocation = node.allocateExact(1)\n \n             if self.__systemAllocation:\n                 break\n", "before": "self . __systemAllocation = node . allocate ( 1 )", "after": "self . __systemAllocation = node . allocateExact ( 1 )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:allocate\", 3, 44, 3, 52], \"allocateExact\"]]"}
{"project": "python_planet", "commit_sha": "9dfceb12bd63af121f35bf230642bfe56d1adb11", "parent_sha": "f0c73a7570b01e8aaadc04ee29be13a4991b690e", "file_path": "planet/extensions/tasks.py", "project_url": "https://github.com/haobin12358/python_planet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -864,7 +864,7 @@ def expired_scene_association():\n @celery.task(name='event_expired_revert')\n def event_expired_revert():\n     \"\"\"\u8fc7\u671f\u6d3b\u52a8\u5546\u54c1\u8fd4\u8fd8\u5e93\u5b58\"\"\"\n-    current_app.logger.error('>>> \u6d3b\u52a8\u5546\u54c1\u5230\u671f\u8fd4\u56de\u5e93\u5b58\u68c0\u6d4b <<< ')\n+    current_app.logger.info('>>> \u6d3b\u52a8\u5546\u54c1\u5230\u671f\u8fd4\u56de\u5e93\u5b58\u68c0\u6d4b <<< ')\n     from planet.control.COrder import COrder\n     corder = COrder()\n     today = date.today()\n", "before": "current_app . logger . error ( '>>> \u6d3b\u52a8\u5546\u54c1\u5230\u671f\u8fd4\u56de\u5e93\u5b58\u68c0\u6d4b <<< ') ", "after": "current_app . logger . info ( '>>> \u6d3b\u52a8\u5546\u54c1\u5230\u671f\u8fd4\u56de\u5e93\u5b58\u68c0\u6d4b <<< ') ", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:error\", 3, 24, 3, 29], \"info\"]]"}
{"project": "QCG-PilotJob", "commit_sha": "80a9837f1702629a49253bd6646636fa5ccbe9db", "parent_sha": "a4709989403d1d3aaf61c53b785e9aa52c4bf7f0", "file_path": "src/qcg/appscheduler/api/manager.py", "project_url": "https://github.com/vecma-project/QCG-PilotJob", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -455,7 +455,7 @@ class Manager:\n-        self.wait4(self.list().names())\n+        self.wait4(self.list().keys())\n \n \n     def isStatusFinished(self, status):\n", "before": "self . wait4 ( self . list ( ) . names ( ) )", "after": "self . wait4 ( self . list ( ) . keys ( ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:names\", 0, 32, 0, 37], \"keys\"]]"}
{"project": "shop-db2", "commit_sha": "07e7464e09344648f2ef1b70312520e83b747938", "parent_sha": "e66e3ab4956984cee2edbbbedde02ca8bb368d2d", "file_path": "shopdb/routes/login.py", "project_url": "https://github.com/g3n35i5/shop-db2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -62,7 +62,7 @@ def login():\n     d_user = convert_minimal(user, fields)[0]\n \n     # Create a token.\n-    exp = datetime.datetime.now() + datetime.timedelta(minutes=60)\n+    exp = datetime.datetime.utcnow() + datetime.timedelta(minutes=60)\n     token = jwt.encode({'user': d_user, 'exp': exp}, app.config['SECRET_KEY'])\n \n     # Return the result.\n", "before": "exp = datetime . datetime . now ( ) + datetime . timedelta ( minutes = 60 )", "after": "exp = datetime . datetime . utcnow ( ) + datetime . timedelta ( minutes = 60 )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:now\", 3, 29, 3, 32], \"utcnow\"]]"}
{"project": "pyfpdf", "commit_sha": "c4247af251a77d02240219333547059a224d67aa", "parent_sha": "effb2278dcbe07ed6093bfa08dbd6318a45e5df9", "file_path": "tests/cover/common.py", "project_url": "https://github.com/scott1028/pyfpdf", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -212,7 +212,7 @@ def check_result(settings, args):\n         else:\n             log(\"HASHERROR\")\n     else:\n-        startbyext(args[\"fn\"])\n+        start_by_ext(args[\"fn\"])\n \n def testmain(fn, testfunc):\n     si = read_cover_info(fn)\n", "before": "else : startbyext ( args [ \"fn\" ] )", "after": "else : start_by_ext ( args [ \"fn\" ] )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:startbyext\", 3, 9, 3, 19], \"start_by_ext\"]]"}
{"project": "sympy", "commit_sha": "d9e062e26862b7ff600047aff2581e8f9da35feb", "parent_sha": "d77a1bbde9a8c00087b23125af67e72e0012aeee", "file_path": "sympy/simplify/cse_main.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -236,7 +236,7 @@ def get_subset_candidates(self, argset, restrict_to_funcset=None):\n         iarg = iter(argset)\n \n-        indices = set(\n+        indices = OrderedSet(\n             fi for fi in self.arg_to_funcset[next(iarg)])\n \n         if restrict_to_funcset is not None:\n", "before": "indices = set ( fi for fi in self . arg_to_funcset [ next ( iarg ) ] )", "after": "indices = OrderedSet ( fi for fi in self . arg_to_funcset [ next ( iarg ) ] )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:set\", 2, 19, 2, 22], \"OrderedSet\"]]"}
{"project": "osc", "commit_sha": "a8def0f4333db840c6e536d07a0e0664e5e1795f", "parent_sha": "51e6fca88fb778baf7d8f7f918d20fdc08c76f7c", "file_path": "osc/build.py", "project_url": "https://github.com/lethliel/osc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -665,7 +665,7 @@ def main(apiurl, opts, argv):\n     rpmlist_prefers = []\n     if prefer_pkgs:\n         print('Evaluating preferred packages')\n-        for name, path in prefer_pkgs.tems():\n+        for name, path in prefer_pkgs.items():\n             if bi.has_dep(name):\n                 # We remove a preferred package from the buildinfo, so that the\n                 # fetcher doesn't take care about them.\n", "before": "for name , path in prefer_pkgs . tems ( ) : if bi . has_dep ( name ) : ", "after": "for name , path in prefer_pkgs . items ( ) : if bi . has_dep ( name ) : ", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:tems\", 3, 39, 3, 43], \"items\"]]"}
{"project": "sympy", "commit_sha": "d1e6bc3219d04161e86d1380135990df87f7f1c9", "parent_sha": "5505a7dae28cf08b316782dc41b576a23b7b65db", "file_path": "sympy/physics/mechanics/essential.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1293,7 +1293,7 @@ def dt(self, expr, order=1):\n         if order%1 != 0 or order < 0:\n             raise ValueError(\"Unsupported value of order entered\")\n         if isinstance(expr, Vector):\n-            outvec = S(0)\n+            outvec = Vector(0)\n             for i, v in enumerate(expr.args):\n                 if v[1] == self:\n                     outvec += Vector([(self.express(v[0]).diff(t), self)])\n", "before": "outvec = S ( 0 )", "after": "outvec = Vector ( 0 )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:S\", 3, 22, 3, 23], \"Vector\"]]"}
{"project": "sympy", "commit_sha": "38ce196f49c828410364b5444ddb1c0c7d987176", "parent_sha": "dda630f81d37c4fc765ca64729d939e5dcf2631e", "file_path": "sympy/tensor/tensor.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1977,7 +1977,7 @@ def get_free_indices(self):  # type: () -> List[TensorIndex]\n \n     @abstractmethod\n     def _replace_indices(self, repl):  # type: (Dict[TensorIndex, TensorIndex]) -> TensExpr\n-        raise NotImplemented(\"abstract method\")\n+        raise NotImplementedError(\"abstract method\")\n \n     def fun_eval(self, *index_tuples):\n         deprecate_fun_eval()\n", "before": "raise NotImplemented ( \"abstract method\" )", "after": "raise NotImplementedError ( \"abstract method\" )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:NotImplemented\", 3, 15, 3, 29], \"NotImplementedError\"]]"}
{"project": "electrum", "commit_sha": "b3e880b58707884afc7cacfb18372aab08863cff", "parent_sha": "cd6832df2ee9f09c973485f13f7e6abfd64dd62d", "file_path": "lib/commands.py", "project_url": "https://github.com/you21979/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -286,7 +286,7 @@ class Commands:\n \n \n     def setlabel(self, key, label):\n-        self.wallet.set_labels(key, label)\n+        self.wallet.set_label(key, label)\n \n             \n \n", "before": "self . wallet . set_labels ( key , label )", "after": "self . wallet . set_label ( key , label )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:set_labels\", 3, 21, 3, 31], \"set_label\"]]"}
{"project": "RxPY", "commit_sha": "5f4865265af37be4e77f5a0975f581d9e50c7de7", "parent_sha": "4cb7de1a51b57d7ec08b55d4dc6d885269bad0f2", "file_path": "RxPY/rx/linq/observable_time.py", "project_url": "https://github.com/mako-taco/RxPY", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -81,7 +81,7 @@ class ObservableTime(Observable, metaclass=ObservableMeta):\n                     if d <= now:\n                         d = now + p\n                 \n-                observer.on_ext(count)\n+                observer.on_next(count)\n                 count += 1\n                 self(d)\n             \n", "before": "observer . on_ext ( count )", "after": "observer . on_next ( count )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:on_ext\", 3, 26, 3, 32], \"on_next\"]]"}
{"project": "sympy", "commit_sha": "a81b5c00bd71c055866de59d3590ff20aca2349b", "parent_sha": "f684bd393650952a40cae72231a2450507d22060", "file_path": "sympy/solvers/recurr.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -814,7 +814,7 @@ def rsolve(f, y, init=None):\n                 else:\n                     raise ValueError(\"Integer or term expected, got '%s'\" % k)\n \n-            eq = solution.limit(n, i) - v\n+            eq = solution.subs(n, i) - v\n             if eq.has(S.NaN):\n                 eq = solution.limit(n, i) - v\n             equations.append(eq)\n", "before": "eq = solution . limit ( n , i ) - v", "after": "eq = solution . subs ( n , i ) - v", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:limit\", 3, 27, 3, 32], \"subs\"]]"}
{"project": "suitcase", "commit_sha": "391482f9f5825f659ef19c07aa44217c3ef6b117", "parent_sha": "1eacd24a3e8164cd7bb35e3c679fd8626aba2126", "file_path": "suitcase/tests/test_hdf5.py", "project_url": "https://github.com/ronpandolfi/suitcase", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -59,7 +59,7 @@ def test_filter_fields():\n     temperature_ramp.run()\n     hdr = db[-1]\n     unwanted_fields = ['point_det']\n-    out = hdf5.export(hdr, unwanted_fields)\n+    out = hdf5.filter_fields(hdr, unwanted_fields)\n     assert len(out)==0\n \n \n", "before": "out = hdf5 . export ( hdr , unwanted_fields )", "after": "out = hdf5 . filter_fields ( hdr , unwanted_fields )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:export\", 3, 16, 3, 22], \"filter_fields\"]]"}
{"project": "RxPY", "commit_sha": "5bc203ac58d32c9e3d4f2fc83814e3a845c8b1f3", "parent_sha": "a0842a77d8d9d842bd26c505a07a9b08ad52d461", "file_path": "rx/backpressure/controlledsubject.py", "project_url": "https://github.com/mako-taco/RxPY", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,7 +41,7 @@ class ControlledSubject(Observable):\n \n         if not self.requested_count:\n             if self.enable_queue:\n-                self.queue.push(value)\n+                self.queue.append(value)\n         else:\n             if self.requested_count != -1:\n", "before": "self . queue . push ( value )", "after": "self . queue . append ( value )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:push\", 3, 28, 3, 32], \"append\"]]"}
{"project": "dosenet-raspberrypi", "commit_sha": "8bd49ef313fdc83d8db0df98ee71ef49ba49f7c7", "parent_sha": "f94d01260cb4c60501de3bc031397c017841e75c", "file_path": "weather_DAQ.py", "project_url": "https://github.com/ludicao/dosenet-raspberrypi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -189,7 +189,7 @@ class weather_DAQ(object):\n                 global row_counter\n                 for r in results:\n                     if row_counter>0:\n-                        times.appned(dateutil.parser.parse(r[0]))\n+                        times.append(dateutil.parser.parse(r[0]))\n                         pressure_list.append(float(r[2]))\n                 \n                     row_counter+=1\n", "before": "times . appned ( dateutil . parser . parse ( r [ 0 ] ) )", "after": "times . append ( dateutil . parser . parse ( r [ 0 ] ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:appned\", 3, 31, 3, 37], \"append\"]]"}
{"project": "bokeh", "commit_sha": "f90eae161dd9212c9899c98048ed6a5724785d13", "parent_sha": "a7fec51ba1cb88f44005e86dbce4136745267d8d", "file_path": "bokeh/server/tornado.py", "project_url": "https://github.com/suqi/bokeh", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -164,7 +164,7 @@ class BokehTornado(TornadoApplication):\n \n     @gen.coroutine\n     def _cleanup(self):\n-        log.warn(\"Shutdown: cleaning up\")\n+        log.debug(\"Shutdown: cleaning up\")\n         self._executor.shutdown(wait=False)\n         self._clients.clear()\n \n", "before": "log . warn ( \"Shutdown: cleaning up\" )", "after": "log . debug ( \"Shutdown: cleaning up\" )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:warn\", 3, 13, 3, 17], \"debug\"]]"}
{"project": "flutterfuck", "commit_sha": "54c5948f3d36d194c19b0e020f49db5af383428a", "parent_sha": "8cd247a1ea0d3b9ac79f1108d7eb84a19ce17cce", "file_path": "willie/modules/url.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -75,7 +75,7 @@ def setup(bot=None):\n     else:\n         exclude = bot.memory['url_exclude']\n         if regexes:\n-            exclude.append(regexes)\n+            exclude.extend(regexes)\n         bot.memory['url_exclude'] = exclude\n \n     # Ensure that url_callbacks and last_seen_url are in memory\n", "before": "exclude . append ( regexes )", "after": "exclude . extend ( regexes )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:append\", 3, 21, 3, 27], \"extend\"]]"}
{"project": "flutterfuck", "commit_sha": "c7041d13837cc5e6281185883397c4567d595145", "parent_sha": "9ac8831210db3fa0e3592c7388ff15f62e42309d", "file_path": "willie/tools.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -548,7 +548,7 @@ def get_timezone(db=None, config=None, zone=None, nick=None, channel=None):\n     if zone:\n         tz = check(zone)\n         if not tz:\n-            tz = check(db.get_channel_or_nick_value(zone, 'timezone'))\n+            tz = check(db.get_nick_or_channel_value(zone, 'timezone'))\n     if not tz and nick:\n         tz = check(db.get_nick_value(nick, 'timezone'))\n     if not tz and channel:\n", "before": "tz = check ( db . get_channel_or_nick_value ( zone , 'timezone' ) )", "after": "tz = check ( db . get_nick_or_channel_value ( zone , 'timezone' ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:get_channel_or_nick_value\", 3, 27, 3, 52], \"get_nick_or_channel_value\"]]"}
{"project": "flutterfuck", "commit_sha": "6ce5676a448d74d7b89d4c26cd7cb7ba39a7b2d2", "parent_sha": "00875e3a17cc843a988efa059eda83f3b10b87f2", "file_path": "willie/modules/weather.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -132,7 +132,7 @@ def weather(bot, trigger):\n                            'Give me a location, like .weather London, or tell me where you live by saying .setlocation London, for example.')\n     else:\n         location = location.strip()\n-        woeid = bot.db.get_channel_value(location, 'woeid')\n+        woeid = bot.db.get_nick_value(location, 'woeid')\n         if woeid is None:\n             first_result = woeid_search(location)\n             if first_result is not None:\n", "before": "woeid = bot . db . get_channel_value ( location , 'woeid' )", "after": "woeid = bot . db . get_nick_value ( location , 'woeid' )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:get_channel_value\", 3, 24, 3, 41], \"get_nick_value\"]]"}
{"project": "flutterfuck", "commit_sha": "b9a5cc7d798c419bd1f3770aa600cd92fff75889", "parent_sha": "ae8535a78d6c5818be231cc7692923677a0bb3f3", "file_path": "willie/modules/github.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -203,5 +203,5 @@ def issue_info(bot, trigger, match=None):\n     except (KeyError):\n         bot.say('The API says this is an invalid issue. Please report this if you know it\\'s a correct link!')\n         return NOLIMIT\n-    bot.reply('[#%s]\\x02title:\\x02 %s \\x02|\\x02 %s' % (data['number'], data['title'], body))\n+    bot.say('[#%s]\\x02title:\\x02 %s \\x02|\\x02 %s' % (data['number'], data['title'], body))\n \n", "before": "bot . reply ( '[#%s]\\x02title:\\x02 %s \\x02|\\x02 %s' % ( data [ 'number' ] , data [ 'title' ] , body ) )", "after": "bot . say ( '[#%s]\\x02title:\\x02 %s \\x02|\\x02 %s' % ( data [ 'number' ] , data [ 'title' ] , body ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:reply\", 3, 9, 3, 14], \"say\"]]"}
{"project": "easybuild-easyconfigs", "commit_sha": "150f521f7c0f7caeafb922c54106b5fa15ccf856", "parent_sha": "e26d0cb01fd4c713df0e31c57dddaf845c90748e", "file_path": "easybuild/easyblocks/i/imkl.py", "project_url": "https://github.com/schiotz/easybuild-easyconfigs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -81,7 +81,7 @@ class Imkl(IntelBase):\n         \"\"\"Overwritten from Application to add extra txt\"\"\"\n         txt = IntelBase.make_module_extra(self)\n         txt += \"prepend-path\\t%s\\t\\t%s\\n\" % ('INTEL_LICENSE_FILE', self.license)\n-        if self.getCfg('m32'):\n+        if self.getcfg('m32'):\n             txt += \"prepend-path\\t%s\\t\\t$root/%s\\n\" % ('NLSPATH', 'idb/32/locale/%l_%t/%N')\n         else:\n             txt += \"prepend-path\\t%s\\t\\t$root/%s\\n\" % ('NLSPATH', 'idb/intel64/locale/%l_%t/%N')\n", "before": "if self . getCfg ( 'm32' ) : txt += \"prepend-path\\t%s\\t\\t$root/%s\\n\" % ( 'NLSPATH' , 'idb/32/locale/%l_%t/%N' ) else : txt += \"prepend-path\\t%s\\t\\t$root/%s\\n\" % ( 'NLSPATH' , 'idb/intel64/locale/%l_%t/%N' )", "after": "if self . getcfg ( 'm32' ) : txt += \"prepend-path\\t%s\\t\\t$root/%s\\n\" % ( 'NLSPATH' , 'idb/32/locale/%l_%t/%N' ) else : txt += \"prepend-path\\t%s\\t\\t$root/%s\\n\" % ( 'NLSPATH' , 'idb/intel64/locale/%l_%t/%N' )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:getCfg\", 3, 17, 3, 23], \"getcfg\"]]"}
{"project": "django-floppyforms", "commit_sha": "8d0fe30fadc4834348c0f697b097f4753c7f9d84", "parent_sha": "50d696afc2b9a9fd5b0c846619c07c1d14fcc577", "file_path": "floppyforms/tests/fields.py", "project_url": "https://github.com/mrjmad/django-floppyforms", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -7,5 +7,5 @@ class IntegerFieldTests(FloppyFormsTestCase):\n     def test_parse_int(self):\n         int_field = forms.IntegerField()\n         result = int_field.clean('15')\n-        self.assertTrue(15, result)\n+        self.assertEqual(15, result)\n         self.assertIsInstance(result, int)\n", "before": "self . assertTrue ( 15 , result )", "after": "self . assertEqual ( 15 , result )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:assertTrue\", 3, 14, 3, 24], \"assertEqual\"]]"}
{"project": "tardis", "commit_sha": "6e2f40954fb48fec48b3f35637b22242f45a80cf", "parent_sha": "5b6bfbf96210c245c6e66428c9f94bffd368c130", "file_path": "tardis/plasma/properties/radiative_properties.py", "project_url": "https://github.com/vg3095/tardis", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -160,7 +160,7 @@ class LTEJBlues(ProcessingPlasmaProperty):\n         h = const.h.cgs.value\n         c = const.c.cgs.value\n         df = pd.DataFrame(1, index=nu.index, columns=beta_rad.index)\n-        df = df.multiply(nu, axis='index') * beta_rad\n+        df = df.mul(nu, axis='index') * beta_rad\n         exponential = (np.exp(h * df) - 1)**(-1)\n         remainder = (2 * (h * nu.values ** 3) /\n             (c ** 2))\n", "before": "df = df . multiply ( nu , axis = 'index' ) * beta_rad", "after": "df = df . mul ( nu , axis = 'index' ) * beta_rad", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:multiply\", 3, 17, 3, 25], \"mul\"]]"}
{"project": "tardis", "commit_sha": "d56e35cfda3e3cda1df9bba8e1b4197da9752584", "parent_sha": "6e2f40954fb48fec48b3f35637b22242f45a80cf", "file_path": "tardis/plasma/properties/radiative_properties.py", "project_url": "https://github.com/vg3095/tardis", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -164,5 +164,5 @@ class LTEJBlues(ProcessingPlasmaProperty):\n         exponential = (np.exp(h * df) - 1)**(-1)\n         remainder = (2 * (h * nu.values ** 3) /\n             (c ** 2))\n-        j_blues = exponential.multiply(remainder, axis=0)\n+        j_blues = exponential.mul(remainder, axis=0)\n         return pd.DataFrame(j_blues, index=lines.index, columns=beta_rad.index)\n", "before": "j_blues = exponential . multiply ( remainder , axis = 0 )", "after": "j_blues = exponential . mul ( remainder , axis = 0 )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:multiply\", 3, 31, 3, 39], \"mul\"]]"}
{"project": "cclib", "commit_sha": "95d345fb9052b6a6b6e41052e5cbb8b100463de3", "parent_sha": "fb22cff1de784f4c3cffa398f7d57b56b52da31c", "file_path": "src/cclib/parser/gaussianparser.py", "project_url": "https://github.com/chemistry-scripts/cclib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -380,7 +380,7 @@ class Gaussian(logfileparser.Logfile):\n                 parts = line[36:].split()\r\n                 self.etenergies.append(utils.convertor(self.float(parts[0]),\"eV\",\"cm-1\"))\r\n                 self.etoscs.append(self.float(parts[4].split(\"=\")[1]))\r\n-                self.etsyms.append(line[21:36].split())\r\n+                self.etsyms.append(line[21:36].strip())\r\n                 \r\n                 line = inputfile.next()\r\n \r\n", "before": "self . etsyms . append ( line [ 21 : 36 ] . split ( ) )", "after": "self . etsyms . append ( line [ 21 : 36 ] . strip ( ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:split\", 3, 48, 3, 53], \"strip\"]]"}
{"project": "blinkpy", "commit_sha": "6d002fc8b00b74a0b2ca11952ded82f286de9d4f", "parent_sha": "72283406772ef851c7f2a2c56dc0f0eefcdd5c2e", "file_path": "blinkpy/blinkpy.py", "project_url": "https://github.com/fronzbot/blinkpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -294,7 +294,7 @@ class Blink():\n         self._video_count = 0\n         self._all_videos = {}\n         self._summary = None\n-        self.record_dates = list()\n+        self.record_dates = dict()\n \n     @property\n     def camera_thumbs(self):\n", "before": "self . record_dates = list ( )", "after": "self . record_dates = dict ( )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:list\", 3, 29, 3, 33], \"dict\"]]"}
{"project": "tvm", "commit_sha": "ab3e88acb908c091e4027b897892b471dfd14f79", "parent_sha": "3d27729245c0e2bb46f12095e99e7e84ea0aa638", "file_path": "python/tvm/driver/tvmc/common.py", "project_url": "https://github.com/neo-ai/tvm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -280,7 +280,7 @@ def target_from_cli(target):\n     extra_targets = []\n \n-    if os.path.exists(target):\n+    if os.path.isfile(target):\n         with open(target) as target_file:\n             logger.debug(\"target input is a path: %s\", target)\n             target = \"\".join(target_file.readlines())\n", "before": "if os . path . exists ( target ) : with open ( target ) as target_file : logger . debug ( \"target input is a path: %s\" , target ) target = \"\" . join ( target_file . readlines ( ) )", "after": "if os . path . isfile ( target ) : with open ( target ) as target_file : logger . debug ( \"target input is a path: %s\" , target ) target = \"\" . join ( target_file . readlines ( ) )", "sstub_pattern": "WRONG_FUNCTION_NAME", "edit_script": "[[\"Update\", [\"identifier:exists\", 2, 16, 2, 22], \"isfile\"]]"}
{"project": "jinja2", "commit_sha": "56e20cf5c11339459e0ad5d528243504478ed4e2", "parent_sha": "69ddc5854d8a61dcbfb0bae1121ff855cb8bcf75", "file_path": "jinja/datastructure.py", "project_url": "https://github.com/silkapp/jinja2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -588,7 +588,7 @@ class TemplateStream(object):\n                     if c_size >= size:\n                         raise StopIteration()\n             except StopIteration:\n-                if not size:\n+                if not c_size:\n                     raise\n             return u''.join(buf)\n \n", "before": "StopIteration : if not size : raise", "after": "StopIteration : if not c_size : raise", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:size\", 3, 24, 3, 28], \"c_size\"]]"}
{"project": "django-taggit", "commit_sha": "fdb758eff40e3012fb16dc3eb8ec48720a003f70", "parent_sha": "2eef4b47f3c5ede21c322d82da64faeff5960fc4", "file_path": "taggit/managers.py", "project_url": "https://github.com/sprintly/django-taggit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -174,7 +174,7 @@ class _TaggableManager(models.Manager):\n         tag_objs = set(tags) - str_tags\n         # If str_tags has 0 elements Django actually optimizes that to not do a\n         # query.  Malcolm is very smart.\n-        if len(tag_objs) > 0:\n+        if len(str_tags) > 0:\n             # Assuming tags are [foo, bar]: do an insensitive regexp search for\n             # (^foo$|^bar$). This is necessary b/c mysql will match accents on\n             # characters with IN syntax. ie: vid\u00e9o == video\n", "before": "if len ( tag_objs ) > 0 : ", "after": "if len ( str_tags ) > 0 : ", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:tag_objs\", 3, 16, 3, 24], \"str_tags\"]]"}
{"project": "TracBlockdiag", "commit_sha": "49043c0e5116f1e793bab6a9406ae0a95a01081f", "parent_sha": "5cd4d2ba772fced1928e10c99610cffcc49a4afb", "file_path": "tracblockdiag/cache.py", "project_url": "https://github.com/arielnetworks/TracBlockdiag", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -51,7 +51,7 @@ class GC(object):\n             for key in cache.keys():\n                 entry = cache.get(key, None)\n                 if entry is not None and is_obsolete(entry, self.expire_time):\n-                    cache.pop(entry, None)\n+                    cache.pop(key, None)\n         finally:\n             self.lock.release()\n \n", "before": "cache . pop ( entry , None )", "after": "cache . pop ( key , None )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:entry\", 3, 31, 3, 36], \"key\"]]"}
{"project": "dexy", "commit_sha": "4fdc9d37ad7ae229226c658ea042218b23f96256", "parent_sha": "06275290c977b193ef0705cc1668311dbe5b59e8", "file_path": "dexy/plugins/idio_filters.py", "project_url": "https://github.com/mojavelinux/dexy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -74,7 +74,7 @@ class IdioFilter(PygmentsFilter):\n             formatted_lines = composer.format(lines, lexer, formatter)\n \n             if add_new_docs:\n-                new_doc_name = \"%s--%s%s\" % (self.artifact.key.replace(\"|\", \"--\"), k, self.artifact.ext)\n+                new_doc_name = \"%s--%s%s\" % (self.artifact.key.replace(\"|\", \"--\"), s, self.artifact.ext)\n                 doc = self.add_doc(new_doc_name, formatted_lines)\n \n             if not self.artifact.ext in self.IMAGE_OUTPUT_EXTENSIONS:\n", "before": "new_doc_name = \"%s--%s%s\" % ( self . artifact . key . replace ( \"|\" , \"--\" ) , k , self . artifact . ext )", "after": "new_doc_name = \"%s--%s%s\" % ( self . artifact . key . replace ( \"|\" , \"--\" ) , s , self . artifact . ext )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:k\", 3, 84, 3, 85], \"s\"]]"}
{"project": "pyjade", "commit_sha": "3d51a4758d4c689eed236fda303bfb1c4adc8624", "parent_sha": "7abacefbe99ebb482fbe6e419cba9fbbb0997ca8", "file_path": "pyjade/runtime.py", "project_url": "https://github.com/underdogio/pyjade", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -72,7 +72,7 @@ def iteration(obj, num_keys):\n       2. If the object's values are iterable (and not string-like):\n          a. If the number of keys matches the cardinality of the object's\n             values, return the object as-is.\n-         b. If the number of keys is one less than the cardinality of\n+         b. If the number of keys is one more than the cardinality of\n             values, return a list of [v(0), v(1), ... v(n), index]\n \n       3. Else the object's values are not iterable, or are string like:\n", "before": "values , return the object as - is . b . If the number of keys is one less than the cardinality of", "after": "values , return the object as - is . b . If the number of keys is one more than the cardinality of", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:less\", 3, 42, 3, 46], \"more\"]]"}
{"project": "flask-oauthlib", "commit_sha": "ae9f946b2b2739bb352961c200b2e4eeaba67044", "parent_sha": "89b0295a0539add095b0b67d2d52c352b0975428", "file_path": "flask_oauthlib/client.py", "project_url": "https://github.com/underdogio/flask-oauthlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -323,7 +323,7 @@ class OAuthRemoteApp(object):\n         if attr:\n             return attr\n         if default is not False and not self.app_key:\n-            return attr\n+            return default\n         app = self.oauth.app or current_app\n         config = app.config[self.app_key]\n         if default is not False:\n", "before": "return attr", "after": "return default", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:attr\", 3, 20, 3, 24], \"default\"]]"}
{"project": "nupic", "commit_sha": "55e34bdfb1756ab0832546ae425851be9320a927", "parent_sha": "5e1bcea8cd1a8031914dcd21b5536d3ccc3435df", "file_path": "nupic/algorithms/anomaly.py", "project_url": "https://github.com/newicon/nupic", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ class Anomaly(object):\n       self._likelihood = AnomalyLikelihood() # probabilistic anomaly\n \n \n-  def computeAnomalyScore(self, activeColumns, prevPredictedColumnsi, value=None, timestamp=None):\n+  def computeAnomalyScore(self, activeColumns, prevPredictedColumns, value=None, timestamp=None):\n", "before": "def computeAnomalyScore ( self , activeColumns , prevPredictedColumnsi , value = None , timestamp = None ) : ", "after": "def computeAnomalyScore ( self , activeColumns , prevPredictedColumns , value = None , timestamp = None ) : ", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:prevPredictedColumnsi\", 3, 48, 3, 69], \"prevPredictedColumns\"]]"}
{"project": "nixops", "commit_sha": "148afbb3363dbbd20eb52f3922c0121d00592852", "parent_sha": "06473aaed0f61edb63acb7409ac899c93edc27c0", "file_path": "nixops/backends/ec2.py", "project_url": "https://github.com/zalora/nixops", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -173,7 +173,7 @@ class EC2State(MachineState):\n             'require': [\n                 RawValue(\"<nixos/modules/virtualisation/amazon-config.nix>\")\n             ],\n-            ('deployment', 'ec2', 'blockDeviceMapping'): blockDeviceMapping,\n+            ('deployment', 'ec2', 'blockDeviceMapping'): block_device_mapping,\n         }\n \n     def get_physical_backup_spec(self, backupid):\n", "before": "blockDeviceMapping ,", "after": "block_device_mapping ,", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:blockDeviceMapping\", 3, 58, 3, 76], \"block_device_mapping\"]]"}
{"project": "lstm-char-cnn-tensorflow", "commit_sha": "58f9dee20368d381b0c2c81f449cf39661d9076b", "parent_sha": "6a7e765936752172cc4c175e86a38041ce909f98", "file_path": "batch_loader.py", "project_url": "https://github.com/arita37/lstm-char-cnn-tensorflow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -156,7 +156,7 @@ class BatchLoader(object):\n             for idx in xrange(min(len(chars), max_word_length)):\n               output_char[word_num][idx] = chars[idx]\n \n-            if len(char) == max_word_length:\n+            if len(chars) == max_word_length:\n               chars[-1] = char2idx['}']\n             word_num += 1\n \n", "before": "if len ( char ) == max_word_length : chars [ - 1 ] = char2idx [ '}' ]", "after": "if len ( chars ) == max_word_length : chars [ - 1 ] = char2idx [ '}' ]", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:char\", 3, 20, 3, 24], \"chars\"]]"}
{"project": "stoq", "commit_sha": "db73d3303c3865375a868d236edba98259b7d646", "parent_sha": "915323b30aee5f1fb42f916dd622b8424d6d51ee", "file_path": "stoq/gui/wizards/purchase.py", "project_url": "https://github.com/bellini666/stoq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -120,7 +120,7 @@ class PurchasePaymentStep(BaseWizardStep):\n         if pg:\n             model = pg\n         else:\n-            method = AbstractPaymentGroupPurchaseOrder.METHOD_BILL\n+            method = AbstractPaymentGroup.METHOD_BILL\n             interval_type = INTERVALTYPE_MONTH\n             model = model.addFacet(IPaymentGroup, default_method=method,\n                                    intervals=1, \n", "before": "method = AbstractPaymentGroupPurchaseOrder . METHOD_BILL", "after": "method = AbstractPaymentGroup . METHOD_BILL", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:AbstractPaymentGroupPurchaseOrder\", 3, 22, 3, 55], \"AbstractPaymentGroup\"]]"}
{"project": "stoq", "commit_sha": "95d152ec12327a8380f1ddd8f16ebebceeb76dda", "parent_sha": "90252cc03f2c60d85c30b2c664e0810e15edeb9a", "file_path": "stoq/lib/parameters.py", "project_url": "https://github.com/bellini666/stoq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -412,7 +412,7 @@ class ParameterAccess(ClassInittableObject):\n         for obj in constants:\n             if self.get_parameter_by_field(obj.key, obj.type):\n                 continue\n-            if obj.type is int:\n+            if obj.type is bool:\n                 # Convert Bool to int here\n                 value = int(obj.initial)\n             else:\n", "before": "if obj . type is int : value = int ( obj . initial ) else : ", "after": "if obj . type is bool : value = int ( obj . initial ) else : ", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:int\", 3, 28, 3, 31], \"bool\"]]"}
{"project": "SleekXMPP", "commit_sha": "a18051c1649bb4cef8b6d0b82f798051d6b21215", "parent_sha": "5dc967a360484e411706d3712b686de625d90b10", "file_path": "sleekxmpp/plugins/xep_0050.py", "project_url": "https://github.com/mayflower/SleekXMPP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -82,7 +82,7 @@ class xep_0050(base.base_plugin):\n \t\tpointer = self.sessions[sessionid]['next']\n \t\tresults = self.xmpp['xep_0004'].makeForm('result')\n \t\tresults.fromXML(in_command.find('{jabber:x:data}x'))\n-\t\tpointer(results,sessioni)\n+\t\tpointer(results,sessionid)\n \t\tself.xmpp.send(self.makeCommand(xml.attrib['from'], in_command.attrib['node'], form=None, id=xml.attrib['id'], sessionid=sessionid, status='completed', actions=[]))\n \t\tdel self.sessions[in_command.get('sessionid')]\n \t\t\n", "before": "pointer ( results , sessioni )", "after": "pointer ( results , sessionid )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:sessioni\", 3, 19, 3, 27], \"sessionid\"]]"}
{"project": "stoq", "commit_sha": "72b80d7a467e4ca6e2e393f0e8374fe2ae96465f", "parent_sha": "49a9a596348e1826fb66ed3ed0e68eb3ab68482c", "file_path": "stoqlib/gui/dialogs/purchasedetails.py", "project_url": "https://github.com/bellini666/stoq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -95,7 +95,7 @@ class PurchaseDetailsDialog(BaseEditor):\n                        data_type=str, expand=True, searchable=True),\n                 Column('quantity_received_as_string',\n                        title=_('Quantity Received'),\n-                       data_type=float, width=150, editable=True,\n+                       data_type=str, width=150, editable=True,\n                        justify=gtk.JUSTIFY_RIGHT),\n                 Column('cost', title=_('Cost'), data_type=currency,\n                        editable=True, width=90),\n", "before": "Column ( 'quantity_received_as_string' , title = _ ( 'Quantity Received' ) , data_type = float , width = 150 , editable = True , justify = gtk . JUSTIFY_RIGHT ) ,", "after": "Column ( 'quantity_received_as_string' , title = _ ( 'Quantity Received' ) , data_type = str , width = 150 , editable = True , justify = gtk . JUSTIFY_RIGHT ) ,", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:float\", 3, 34, 3, 39], \"str\"]]"}
{"project": "blink-qt", "commit_sha": "e4d9d346b944dde42eb083de89b444c6c25a0ce9", "parent_sha": "38af9f5e8776f4b7c666ca2b4a41fba14fc752ca", "file_path": "blink/widgets/util.py", "project_url": "https://github.com/kogmbh/blink-qt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -8,7 +8,7 @@ from PyQt4.QtCore import QVariant\n \n \n class QtDynamicProperty(object):\n-    def __init__(self, name, type=str):\n+    def __init__(self, name, type=unicode):\n         self.name = name\n         self.type = type\n     def __get__(self, obj, objtype):\n", "before": "def __init__ ( self , name , type = str ) : self . name = name self . type = type", "after": "def __init__ ( self , name , type = unicode ) : self . name = name self . type = type", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:str\", 3, 35, 3, 38], \"unicode\"]]"}
{"project": "blink-qt", "commit_sha": "26e5268528788d3153de13257ca0ecf24eb4f1e2", "parent_sha": "c4217461e6c948b209c0ee5a3c3eb592a1d922e3", "file_path": "blink/widgets/labels.py", "project_url": "https://github.com/kogmbh/blink-qt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -17,7 +17,7 @@ class IconSelector(QLabel):\n     default_icon = QtDynamicProperty('default_icon',  unicode)\n \n     def __init__(self, parent=None):\n-        super(QLabel, self).__init__(parent)\n+        super(IconSelector, self).__init__(parent)\n         self.setMinimumSize(36, 36)\n         self.filename = None\n         self.default_icon = None\n", "before": "super ( QLabel , self ) . __init__ ( parent )", "after": "super ( IconSelector , self ) . __init__ ( parent )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:QLabel\", 3, 15, 3, 21], \"IconSelector\"]]"}
{"project": "librosa", "commit_sha": "8745433399602fe69b716d071e03c2b0bf3e720d", "parent_sha": "2837246ee720f5947373d32a117adc552e2fe924", "file_path": "librosa/util.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -20,7 +20,7 @@ def frame(y, frame_length=2048, hop_length=64):\n       - y : np.ndarray, ndim=1\n         Time series to frame\n \n-      - win_length : int > 0\n+      - frame_length : int > 0\n         Length of the frame in samples\n \n       - hop_length : int > 0\n", "before": "- win_length : int > 0", "after": "- frame_length : int > 0", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:win_length\", 3, 9, 3, 19], \"frame_length\"]]"}
{"project": "librosa", "commit_sha": "d762f7db343a0503a9ef1d55dffa55c4d39377e9", "parent_sha": "aa1ba133721253ae442bb57922e262f16eab9191", "file_path": "librosa/util/utils.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -948,7 +948,7 @@ def logic_match_events(output, events_from, events_to, left=True, right=True):\n         sorted_from_num = sorted_from[ind]\n \n         # Prevent oob from chosen index\n-        if middle_ind == len(matching_indices):\n+        if middle_ind == len(sorted_to):\n             middle_ind -= 1\n \n         # Permitted to look to the left\n", "before": "if middle_ind == len ( matching_indices ) : middle_ind -= 1", "after": "if middle_ind == len ( sorted_to ) : middle_ind -= 1", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:matching_indices\", 3, 30, 3, 46], \"sorted_to\"]]"}
{"project": "librosa", "commit_sha": "d482ea4b82cf3c592543f3f9c7f768720107c01c", "parent_sha": "d762f7db343a0503a9ef1d55dffa55c4d39377e9", "file_path": "librosa/util/utils.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -956,7 +956,7 @@ def logic_match_events(output, events_from, events_to, left=True, right=True):\n             left_ind = middle_ind - 1\n \n         # Permitted to look to right\n-        if middle_ind < len(matching_indices) - 1 and right:\n+        if middle_ind < len(sorted_to) - 1 and right:\n             right_ind = middle_ind + 1\n \n         # Check if left should be chosen\n", "before": "if middle_ind < len ( matching_indices ) - 1 and right : right_ind = middle_ind + 1", "after": "if middle_ind < len ( sorted_to ) - 1 and right : right_ind = middle_ind + 1", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:matching_indices\", 3, 29, 3, 45], \"sorted_to\"]]"}
{"project": "blink-qt", "commit_sha": "89e9c5362ec26bb10842adf8f1db40fb8f379b03", "parent_sha": "e0fb0bc1f7579ee9a97c153234585759f295968f", "file_path": "blink/history.py", "project_url": "https://github.com/kogmbh/blink-qt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -107,7 +107,7 @@ class HistoryEntry(object):\n             display_name = remote_identity.display_name\n         else:\n             display_name = contact.name\n-        match = self.phone_number_re.match(remote_uri)\n+        match = cls.phone_number_re.match(remote_uri)\n         if match:\n             remote_uri = match.group('number')\n         if display_name and display_name != remote_uri:\n", "before": "match = self . phone_number_re . match ( remote_uri )", "after": "match = cls . phone_number_re . match ( remote_uri )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:self\", 3, 17, 3, 21], \"cls\"]]"}
{"project": "pysolr", "commit_sha": "34625ca975bbbd1bd6609ca52193f2abc4a8c3ad", "parent_sha": "c49be48d459448532b5ad0f5057f4d13e8c9a4f1", "file_path": "pysolr.py", "project_url": "https://github.com/acdha/pysolr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -883,7 +883,7 @@ class Solr(object):\n \n             http://wiki.apache.org/solr/ExtractingRequestHandler\n \n-        The ExtractingRequestHandler has a very simply model: it extracts\n+        The ExtractingRequestHandler has a very simple model: it extracts\n         contents and metadata from the uploaded file and inserts it directly\n         into the index. This is rarely useful as it allows no way to store\n         additional data or otherwise customize the record. Instead, by default\n", "before": "ExtractingRequestHandler has a very simply model : it extracts", "after": "ExtractingRequestHandler has a very simple model : it extracts", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:simply\", 3, 49, 3, 55], \"simple\"]]"}
{"project": "django-voice", "commit_sha": "c933a88f5ffafe916c9721598ef3512745e1c999", "parent_sha": "279875de430e108ddfbc3bbb41eef4f52c02dc9e", "file_path": "djangovoice/views.py", "project_url": "https://github.com/linibou/django-voice", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ class FeedbackDetailView(DetailView):\n         feedback = self.get_object()\n \n         if feedback.private:\n-            if not request.user.is_staff and reuqesst.user != feedback.user:\n+            if not request.user.is_staff and request.user != feedback.user:\n                 return Http404\n \n         return super(FeedbackDetailView, self).get(request, *args, **kwargs)\n", "before": "if not request . user . is_staff and reuqesst . user != feedback . user : return Http404", "after": "if not request . user . is_staff and request . user != feedback . user : return Http404", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:reuqesst\", 3, 46, 3, 54], \"request\"]]"}
{"project": "mdtraj", "commit_sha": "92cc15e2dad141d0a882abf5bc26ec936ec5743c", "parent_sha": "d9a16a73f8f03084cd718fb5a1d29dfd506ba236", "file_path": "MDTraj/geometry/dihedral.py", "project_url": "https://github.com/Eigenstate/mdtraj", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -506,7 +506,7 @@ def compute_chi_all(trajectory, opt=True):\n \n     allresc_list = []\n     [allresc_list.append(x) for x in [residchis1,residchis2,residchis3,residchis4] if x.size]\n-    allcres = np.hstack(tuple(allresc_list))\n+    allresc = np.hstack(tuple(allresc_list))\n \n     allchis_list = []\n     [allchis_list.append(x) for x in [allchis1, allchis2, allchis3,allchis4] if x.size]\n", "before": "allcres = np . hstack ( tuple ( allresc_list ) )", "after": "allresc = np . hstack ( tuple ( allresc_list ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:allcres\", 3, 5, 3, 12], \"allresc\"]]"}
{"project": "MultiQC", "commit_sha": "c6183fc5b656e4324a42c1156bb5986fa74bd103", "parent_sha": "d8e3d9f74b5a5ba3f1fadb927677dc8b00a31de7", "file_path": "multiqc/modules/base_module.py", "project_url": "https://github.com/JAX-GM/MultiQC", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -310,7 +310,7 @@ class BaseMultiqcModule(object):\n             pass\n         \n         # Make a plot - interactive or flat\n-        if config.plots_force_flat or (not config.plots_force_interactive and len(plotsamples[0]) > 50):\n+        if config.plots_force_flat or (not config.plots_force_interactive and len(plotdata[0]) > 50):\n             return self.matplotlib_linegraph(plotdata, pconfig)\n         else:\n             return self.highcharts_linegraph(plotdata, pconfig)\n", "before": "if config . plots_force_flat or ( not config . plots_force_interactive and len ( plotsamples [ 0 ] ) > 50 ) : return self . matplotlib_linegraph ( plotdata , pconfig ) else : return self . highcharts_linegraph ( plotdata , pconfig )", "after": "if config . plots_force_flat or ( not config . plots_force_interactive and len ( plotdata [ 0 ] ) > 50 ) : return self . matplotlib_linegraph ( plotdata , pconfig ) else : return self . highcharts_linegraph ( plotdata , pconfig )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:plotsamples\", 3, 83, 3, 94], \"plotdata\"]]"}
{"project": "mdtraj", "commit_sha": "dcb3ae4d7ffeb97936b69cbe3daa9a14190b49e3", "parent_sha": "ee7a784ceaa7bb2e27c01f5f702f74f86f1c3919", "file_path": "MDTraj/trajectory.py", "project_url": "https://github.com/Eigenstate/mdtraj", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -61,7 +61,7 @@ def _assert_files_exist(filenames):\n-    if isinstance(filenames, str):\n+    if isinstance(filenames, basestring):\n         filenames = [filenames]\n     for fn in filenames:\n         if not (os.path.exists(fn) and os.path.isfile(fn)):\n", "before": "if isinstance ( filenames , str ) : filenames = [ filenames ]", "after": "if isinstance ( filenames , basestring ) : filenames = [ filenames ]", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:str\", 0, 30, 0, 33], \"basestring\"]]"}
{"project": "mdtraj", "commit_sha": "9280a2d89725b1429c40faa611dc665daab68063", "parent_sha": "cdf94b8865d825b69250ff5215084d46ca2f472c", "file_path": "MDTraj/geometry/dihedral.py", "project_url": "https://github.com/Eigenstate/mdtraj", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -119,7 +119,7 @@ def compute_dihedrals(traj, indices, periodic=True, opt=True):\n     if opt and _geometry._processor_supports_sse41():\n         _geometry._dihedral(xyz, quartets, out)\n     else:\n-        _dihedral(traj, triplets, periodic, out)\n+        _dihedral(traj, quartets, periodic, out)\n     return out\n \n \n", "before": "_dihedral ( traj , triplets , periodic , out )", "after": "_dihedral ( traj , quartets , periodic , out )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:triplets\", 3, 25, 3, 33], \"quartets\"]]"}
{"project": "qal", "commit_sha": "73619b421047cc1a3922504b83f69227c7ed6a70", "parent_sha": "944244460fc016484b99dd941db2733ed3179c0e", "file_path": "qal/sql/xml.py", "project_url": "https://github.com/OptimalBPM/qal", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -268,7 +268,7 @@ class SQL_XML(XML_Translation):\n                         else:\n                             _curr_child = xml_find_non_text_child(_curr_node)\n                             if (_curr_child):\n-                                _obj.__dict__[_curr_itemkey] = self._parse_class_xml_node(_curr_child, currtype[0], _obj)  \n+                                _obj.__dict__[_curr_itemkey] = self._parse_class_xml_node(_curr_node, currtype[0], _obj)\n                \n                   \n         if self._resources and hasattr(_obj, 'resource_uuid') and _obj.resource_uuid != None and _obj.resource_uuid != '':\n", "before": "_obj . __dict__ [ _curr_itemkey ] = self . _parse_class_xml_node ( _curr_child , currtype [ 0 ] , _obj )", "after": "_obj . __dict__ [ _curr_itemkey ] = self . _parse_class_xml_node ( _curr_node , currtype [ 0 ] , _obj )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:_curr_child\", 3, 91, 3, 102], \"_curr_node\"]]"}
{"project": "django-secure-auth", "commit_sha": "3b0ec12c26837233cfb1528d65aeb05c23c584c4", "parent_sha": "d0991578dd04c8e9f5be7ac9e589277fdc093e6b", "file_path": "secureauth/forms.py", "project_url": "https://github.com/LPgenerator/django-secure-auth", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,7 +38,7 @@ class BasicForm(forms.Form):\n         try:\n             model_class.objects.get(user=self.request.user)\n             self.fields.pop(field_name)\n-        except UserAuthQuestion.DoesNotExist:\n+        except model_class.DoesNotExist:\n             pass\n \n     def clean_current_password(self):\n", "before": "try : model_class . objects . get ( user = self . request . user ) self . fields . pop ( field_name ) except UserAuthQuestion . DoesNotExist : pass", "after": "try : model_class . objects . get ( user = self . request . user ) self . fields . pop ( field_name ) except model_class . DoesNotExist : pass", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:UserAuthQuestion\", 3, 16, 3, 32], \"model_class\"]]"}
{"project": "rq", "commit_sha": "105b95e9b8eaa20bbd9b1a47742ffef71d2bd694", "parent_sha": "de1cd8a83c8f1da732921d7b4536371f8b6e06b9", "file_path": "tests/test_registry.py", "project_url": "https://github.com/dronedeploy/rq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -141,7 +141,7 @@ class TestFinishedJobRegistry(RQTestCase):\n class TestDeferredRegistry(RQTestCase):\n \n     def setUp(self):\n-        super(TestRegistry, self).setUp()\n+        super(TestDeferredRegistry, self).setUp()\n         self.registry = DeferredJobRegistry(connection=self.testconn)\n \n     def test_add(self):\n", "before": "super ( TestRegistry , self ) . setUp ( )", "after": "super ( TestDeferredRegistry , self ) . setUp ( )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:TestRegistry\", 3, 15, 3, 27], \"TestDeferredRegistry\"]]"}
{"project": "SleekXMPP", "commit_sha": "b68e7bed403924dc4ebf7294854d4892c48ce0ab", "parent_sha": "4be6482ff3278612365863575dceeda9fd9a88c3", "file_path": "sleekxmpp/basexmpp.py", "project_url": "https://github.com/mayflower/SleekXMPP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -245,7 +245,7 @@ class BaseXMPP(XMLStream):\n         \"\"\"Create a Presence stanza associated with this stream.\"\"\"\n         return Presence(self, *args, **kwargs)\n \n-    def make_iq(self, id=0, ifrom=None, ito=None, type=None, query=None):\n+    def make_iq(self, id=0, ifrom=None, ito=None, itype=None, query=None):\n", "before": "def make_iq ( self , id = 0 , ifrom = None , ito = None , type = None , query = None ) : ", "after": "def make_iq ( self , id = 0 , ifrom = None , ito = None , itype = None , query = None ) : ", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:type\", 3, 51, 3, 55], \"itype\"]]"}
{"project": "SleekXMPP", "commit_sha": "ad032e5ed77cfd1ec354e68e49d755e004408d0e", "parent_sha": "45412fd404157d4afc1d08eb5b785b94a55e957c", "file_path": "sleekxmpp/clientxmpp.py", "project_url": "https://github.com/mayflower/SleekXMPP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -183,7 +183,7 @@ class ClientXMPP(BaseXMPP):\n \n                     picked = random.randint(0, intmax)\n                     for item in items:\n-                        if picked <= priority:\n+                        if picked <= item:\n                             address = addresses[item]\n                             break\n \n", "before": "if picked <= priority : address = addresses [ item ] break", "after": "if picked <= item : address = addresses [ item ] break", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:priority\", 3, 38, 3, 46], \"item\"]]"}
{"project": "tribler", "commit_sha": "22c16d4edd4812a4c72b8bcf825b49a7277dd3bd", "parent_sha": "298224980980346619b974504299456ddb394df3", "file_path": "Tribler/Utilities/Instance2Instance.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -23,7 +23,7 @@ except ImportError as e:\n class Instance2InstanceServer(Thread):\n \n     def __init__(self, i2iport, connhandler, timeout=300.0):\n-        super(Thread, self).__init__()\n+        super(Instance2InstanceServer, self).__init__()\n         self._logger = logging.getLogger(self.__class__.__name__)\n \n         name = 'Instance2Instance' + self.getName()\n", "before": "super ( Thread , self ) . __init__ ( )", "after": "super ( Instance2InstanceServer , self ) . __init__ ( )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:Thread\", 3, 15, 3, 21], \"Instance2InstanceServer\"]]"}
{"project": "tribler", "commit_sha": "4da5c20750b6a9aebaeea6fa3ca4e5455504f6e8", "parent_sha": "770957cebd1fc2d90be14a004503662fb4ca3d49", "file_path": "Tribler/Core/Utilities/network_utils.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ def check_random_port(port, socket_type=\"all\"):\n         if _test_port(_family, socket.SOCK_DGRAM, port):\n             is_port_working = _test_port(_family, socket.SOCK_STREAM, port)\n     else:\n-        is_port_working = _test_port(_family, socket_type, port)\n+        is_port_working = _test_port(_family, _sock_type, port)\n \n     return is_port_working\n \n", "before": "is_port_working = _test_port ( _family , socket_type , port )", "after": "is_port_working = _test_port ( _family , _sock_type , port )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:socket_type\", 3, 47, 3, 58], \"_sock_type\"]]"}
{"project": "python-ivi", "commit_sha": "bad9998810363102192bf624b2e6da659dd1ddaf", "parent_sha": "0fe6d7d5aaf9ebc97085f73e25b0f3051ba996b6", "file_path": "ivi/interface/linuxgpib.py", "project_url": "https://github.com/ianrrees/python-ivi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ class LinuxGpibInstrument:\n         if num < 0:\n             num = 512\n         \n-        return self.gpib.read(len)\n+        return self.gpib.read(num)\n     \n     def ask_raw(self, data, num=-1):\n         \"Write then read binary data\"\n", "before": "return self . gpib . read ( len )", "after": "return self . gpib . read ( num )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:len\", 3, 31, 3, 34], \"num\"]]"}
{"project": "tribler", "commit_sha": "04abad829ba0a811a4ed268e11d8ca753a69d4b0", "parent_sha": "2662e47d1e389dcb40368bd49854aefc98da013a", "file_path": "Tribler/community/privatesearch/script.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -101,7 +101,7 @@ class SearchScript(ScenarioScriptBase):\n             if os.path.isdir(dirpath):\n                 try:\n                     if int(dirname) != self._my_name:\n-                        scenario_fp = open(os.path.join(dir, 'data/bartercast.log'))\n+                        scenario_fp = open(os.path.join(dirpath, 'data/bartercast.log'))\n                         for line in scenario_fp:\n                             commands = line.split()\n                             if int(commands[0]) > 1:\n", "before": "scenario_fp = open ( os . path . join ( dir , 'data/bartercast.log' ) )", "after": "scenario_fp = open ( os . path . join ( dirpath , 'data/bartercast.log' ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:dir\", 3, 57, 3, 60], \"dirpath\"]]"}
{"project": "cini", "commit_sha": "a56e12e3663934c394f66fff3906ab961d1c7d3a", "parent_sha": "d528cf029966725d2f3bb89896b10db625a329c7", "file_path": "cini/models.py", "project_url": "https://github.com/gisce/cini", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,7 +41,7 @@ class Base(object):\n-        raise NotImplemented\n+        raise NotImplementedError\n \n \n class Linea(Base):\n", "before": "raise NotImplemented", "after": "raise NotImplementedError", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:NotImplemented\", 0, 15, 0, 29], \"NotImplementedError\"]]"}
{"project": "python-openid", "commit_sha": "8b6d87a5a95552814265911c9d449932c39db768", "parent_sha": "f2a5af11cc77bc097c77d56f582a91f12c9196ad", "file_path": "association.py", "project_url": "https://github.com/ziima/python-openid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -90,7 +90,7 @@ class DiffieHelmanAssociator(object):\n             'openid.session_type':'DH-SHA1',\n             'openid.dh_modulus': to_b64(long2a(p)),\n             'openid.dh_gen': to_b64(long2a(g)),\n-            'openid.dh_consumer_public': to_b64(long2a(pow(p, priv_key, p))),\n+            'openid.dh_consumer_public': to_b64(long2a(pow(g, priv_key, p))),\n             }\n \n         body = urllib.urlencode(args)\n", "before": "to_b64 ( long2a ( pow ( p , priv_key , p ) ) ) ,", "after": "to_b64 ( long2a ( pow ( g , priv_key , p ) ) ) ,", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:p\", 3, 60, 3, 61], \"g\"]]"}
{"project": "python-openid", "commit_sha": "892aa3b7fb2277e08a3482389333f4d98b6e6fb3", "parent_sha": "b549669d23e390834abd32f437cc9a74e41700dc", "file_path": "openid/consumer/interface.py", "project_url": "https://github.com/ziima/python-openid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -51,7 +51,7 @@ class OpenIDProxy(object):\n         dictionary from full parameter name (ie, including the\n         'openid.' prefix) to the parameter value, both unescaped from\n         whatever urlencoding was applied to them.  Used in\n-        processServerRrsponse.\"\"\"\n+        processServerResponse.\"\"\"\n         raise NotImplementedError\n \n     def getCheckAuthParams(self):\n", "before": "urlencoding was applied to them . Used in processServerRrsponse . \"\"\" raise NotImplementedError", "after": "urlencoding was applied to them . Used in processServerResponse . \"\"\" raise NotImplementedError", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:processServerRrsponse\", 3, 9, 3, 30], \"processServerResponse\"]]"}
{"project": "wukong-contrib", "commit_sha": "416533e09568a13ee916b7e9c342163a29e34dd0", "parent_sha": "2f3c3b67857d5d7722b2999bbac511c473e6f372", "file_path": "Weather.py", "project_url": "https://github.com/wzpan/wukong-contrib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ class Plugin(AbstractPlugin):\n             'key': key,\n             'location': location\n         }\n-        esult = requests.get(api, params=body, timeout=3)\n+        result = requests.get(api, params=body, timeout=3)\n         res = json.loads(result.text, encoding='utf-8')\n         return res\n \n", "before": "esult = requests . get ( api , params = body , timeout = 3 )", "after": "result = requests . get ( api , params = body , timeout = 3 )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:esult\", 3, 9, 3, 14], \"result\"]]"}
{"project": "MHWorldData", "commit_sha": "47443511f0a6d3a87c46fea906808ecb95454f07", "parent_sha": "436d53ce4ec84cf7f79f148b5b7be8b4d8142091", "file_path": "mhdata/io/csv/functions.py", "project_url": "https://github.com/gatheringhallstudios/MHWorldData", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -36,7 +36,7 @@ def validate_csv(obj_list, filename):\n         print(\"Warning: Some keys in CSV are not trimmed: \" + filename)\n     if warn_value_rows:\n         print(\"Warning: Some values in CSV are not trimmed: \"\n-            + filename + \" rows: \" + \", \".join(idx))\n+            + filename + \" rows: \" + \", \".join(warn_value_rows))\n \n \n def save_csv(obj_list, location):\n", "before": "print ( \"Warning: Some values in CSV are not trimmed: \" + filename + \" rows: \" + \", \" . join ( idx ) )", "after": "print ( \"Warning: Some values in CSV are not trimmed: \" + filename + \" rows: \" + \", \" . join ( warn_value_rows ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:idx\", 3, 48, 3, 51], \"warn_value_rows\"]]"}
{"project": "stx-config", "commit_sha": "ceb2ae16b799832496a0d2801f79276a2926d374", "parent_sha": "4abb322fb06dcac3c44b81662a2d1ca842955049", "file_path": "sysinv/sysinv/sysinv/sysinv/api/controllers/v1/host.py", "project_url": "https://github.com/openstack/stx-config", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2442,7 +2442,7 @@ class HostController(rest.RestController):\n \n         # tell conductor to delete the barbican entry associated with this host (if present)\n         pecan.request.rpcapi.delete_barbican_secret(pecan.request.context,\n-                                                    host.uuid)\n+                                                    ihost.uuid)\n \n         # Notify patching to drop the host\n         if ihost.hostname is not None:\n", "before": "pecan . request . rpcapi . delete_barbican_secret ( pecan . request . context , host . uuid )", "after": "pecan . request . rpcapi . delete_barbican_secret ( pecan . request . context , ihost . uuid )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:host\", 3, 53, 3, 57], \"ihost\"]]"}
{"project": "cc-utils", "commit_sha": "00ea52aff973fe92012abb57945dd1ca37c59cad", "parent_sha": "9a8206606965800344c87e14d23e77b0db63e53d", "file_path": "concourse/pipelines/enumerator.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -103,7 +103,7 @@ class MappingfileDefinitionEnumerator(DefinitionEnumerator):\n                         # XXX un-hardcode\n                         repo_hostname='github.com',\n                         branch='master',\n-                        raw_definition=definitions\n+                        raw_definitions=definitions\n                     )\n \n     def _enumerate_pipeline_definitions(self, directories):\n", "before": "raw_definition = definitions", "after": "raw_definitions = definitions", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:raw_definition\", 3, 25, 3, 39], \"raw_definitions\"]]"}
{"project": "kmeans-anchor-boxes", "commit_sha": "4135fc75f9ff499a5e3b7a35d699e84bdbbea5e3", "parent_sha": "bbd99821df4fbf49474610b21c4e9ed5f0016b7a", "file_path": "kmeans.py", "project_url": "https://github.com/lars76/kmeans-anchor-boxes", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ def translate_boxes(boxes):\n     for row in range(new_boxes.shape[0]):\n         new_boxes[row][2] = np.abs(new_boxes[row][2] - new_boxes[row][0])\n         new_boxes[row][3] = np.abs(new_boxes[row][3] - new_boxes[row][1])\n-    return np.delete(boxes, [0, 1], axis=1)\n+    return np.delete(new_boxes, [0, 1], axis=1)\n \n \n def kmeans(boxes, k, dist=np.median):\n", "before": "return np . delete ( boxes , [ 0 , 1 ] , axis = 1 )", "after": "return np . delete ( new_boxes , [ 0 , 1 ] , axis = 1 )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:boxes\", 3, 22, 3, 27], \"new_boxes\"]]"}
{"project": "cc-utils", "commit_sha": "7e11afb076e1eafa8418b80c2e6954bbca6d4cab", "parent_sha": "6c2cfa443c839bf72ad7c69654efa9db0649368a", "file_path": "checkmarx/model.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -86,7 +86,7 @@ class ScanResponse:\n     owningTeamId: str\n \n     def status_value(self):\n-        return ScanStatusValues(selt.status.id)\n+        return ScanStatusValues(self.status.id)\n \n \n @dataclasses.dataclass\n", "before": "return ScanStatusValues ( selt . status . id )", "after": "return ScanStatusValues ( self . status . id )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:selt\", 3, 33, 3, 37], \"self\"]]"}
{"project": "cc-utils", "commit_sha": "0bc78e81a0a3d6a3b7c9305feb89b83ba4808259", "parent_sha": "433d521d62a2a2e323b9f50e632a57faade816d0", "file_path": "github/codeowners.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -106,7 +106,7 @@ class CodeOwnerEntryResolver(object):\n                 warning('invalid codeowners-entry: {e}'.format(codeowner_entry))\n                 continue\n             if not codeowner_entry.startswith('@'):\n-                yield codeowners_entry # plain email address\n+                yield codeowner_entry # plain email address\n             elif not '/' in codeowner_entry:\n                 email_addr = self._determine_email_address(codeowner_entry[1:])\n                 if email_addr:\n", "before": "yield codeowners_entry", "after": "yield codeowner_entry", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:codeowners_entry\", 3, 23, 3, 39], \"codeowner_entry\"]]"}
{"project": "cc-utils", "commit_sha": "1f2c22be0204213956b2c0a2a3c1f7828755f9d2", "parent_sha": "98ef69217e4be6d6303e9e8f6598a1a155a146b0", "file_path": "protecode/util.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -126,7 +126,7 @@ def upload_grouped_images(\n             try:\n                 label = resource.find_label(name=sdo.labels.ScanLabelName.BINARY_SCAN.value)\n                 return label.value.policy is sdo.labels.ScanPolicy.SCAN\n-            except ValueError:\n+            except AttributeError:\n                 # label was not present, return default\n                 return True\n \n", "before": "try : label = resource . find_label ( name = sdo . labels . ScanLabelName . BINARY_SCAN . value ) return label . value . policy is sdo . labels . ScanPolicy . SCAN except ValueError : return True", "after": "try : label = resource . find_label ( name = sdo . labels . ScanLabelName . BINARY_SCAN . value ) return label . value . policy is sdo . labels . ScanPolicy . SCAN except AttributeError : return True", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:ValueError\", 3, 20, 3, 30], \"AttributeError\"]]"}
{"project": "cc-utils", "commit_sha": "75f1bdaacf57215157d0dc41c3e9ead117bb66a2", "parent_sha": "c9d62e7a91b95fcc5091065bd004c667ee0c9f80", "file_path": "test/model/factory_test.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -197,7 +197,7 @@ class ConfigFactoryCfgDirDeserialisationTest(unittest.TestCase, ConfigFactorySmo\n         return filename\n \n     def test_absent_directory_causes_failure(self):\n-        with self.assertRaises(Failure):\n+        with self.assertRaises(ValueError):\n             ConfigFactory.from_cfg_dir(cfg_dir='should not exist')\n \n     def test_absent_cfg_types_file_causes_failure(self):\n", "before": "with self . assertRaises ( Failure ) : ConfigFactory . from_cfg_dir ( cfg_dir = 'should not exist' )", "after": "with self . assertRaises ( ValueError ) : ConfigFactory . from_cfg_dir ( cfg_dir = 'should not exist' )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:Failure\", 3, 32, 3, 39], \"ValueError\"]]"}
{"project": "cc-utils", "commit_sha": "6077ada0c40910d2732b60eb25ec4976b8b6d306", "parent_sha": "5d6df3c38854496be844b5d2a2fac094c975e0ec", "file_path": "oci/client.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -123,7 +123,7 @@ def _image_name(image_reference: str):\n     if ':' in image_reference or '@' in image_reference:\n         return _split_image_reference(image_reference=image_reference)[1]\n     else:\n-        return image_referece\n+        return image_reference\n \n \n def base_api_url(\n", "before": "return image_referece", "after": "return image_reference", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:image_referece\", 3, 16, 3, 30], \"image_reference\"]]"}
{"project": "jabbercat", "commit_sha": "e63d1e80f6b97208c61b2a22c7431aff6ff37e73", "parent_sha": "d4af2a7f8d31f88c3bd8a4b4ecf91337a6466fe4", "file_path": "mlxcqt/main.py", "project_url": "https://github.com/jabbercat/jabbercat", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -746,7 +746,7 @@ class MainWindow(Qt.QMainWindow):\n         if join_info is not None:\n             account, mucjid, nick = join_info\n             mlxc.tasks.manager.start(\n-                self.join_muc(first_account, mucjid, nick)\n+                self.join_muc(account, mucjid, nick)\n             )\n \n     @utils.asyncify\n", "before": "mlxc . tasks . manager . start ( self . join_muc ( first_account , mucjid , nick ) )", "after": "mlxc . tasks . manager . start ( self . join_muc ( account , mucjid , nick ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:first_account\", 3, 31, 3, 44], \"account\"]]"}
{"project": "WMAS", "commit_sha": "0b91af90b6e9bd2932d4ab80ab6fe0f429003bd3", "parent_sha": "dcda413dc629781f75684101e9f8ec7d122fa30b", "file_path": "network-error-logging/support/lock.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,7 +31,7 @@ def lock(request, report_id):\n def unlock(request, report_id):\n   with request.server.stash.lock:\n     lock_holder = request.server.stash.take(key=_LOCK_KEY)\n-    if lock_holder != request_id:\n+    if lock_holder != report_id:\n       # Return the lock holder to the stash\n       request.server.stash.put(key=_LOCK_KEY, value=lock_holder)\n       return (503, [], \"Cannot release lock held by %s\" % lock_holder)\n", "before": "if lock_holder != request_id : request . server . stash . put ( key = _LOCK_KEY , value = lock_holder ) return ( 503 , [ ] , \"Cannot release lock held by %s\" % lock_holder )", "after": "if lock_holder != report_id : request . server . stash . put ( key = _LOCK_KEY , value = lock_holder ) return ( 503 , [ ] , \"Cannot release lock held by %s\" % lock_holder )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:request_id\", 3, 23, 3, 33], \"report_id\"]]"}
{"project": "WMAS", "commit_sha": "103351a9017b9813468a5d44b7d7ee3912e58c3e", "parent_sha": "f6226a1aef263c6ce5ef928e096be33c80e7a40c", "file_path": "wptrunner/browsers/chrome.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -75,7 +75,7 @@ class ChromeBrowser(Browser):\n         self.server.start(block=False)\n \n     def stop(self, force=False):\n-        self.server.stop(force=Force)\n+        self.server.stop(force=force)\n \n     def pid(self):\n         return self.server.pid\n", "before": "self . server . stop ( force = Force )", "after": "self . server . stop ( force = force )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:Force\", 3, 32, 3, 37], \"force\"]]"}
{"project": "WMAS", "commit_sha": "02ce380f33c0ddbb955a2ba38f394c5d98b1ea86", "parent_sha": "d31bf6abadd145f71168752ce014b20260687c05", "file_path": "webdriver/tests/get_window_rect.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -102,7 +102,7 @@ def test_handle_prompt_missing_value(session, create_dialog):\n \n     response = get_window_rect(session)\n \n-    assert_error(result, \"unexpected alert open\")\n+    assert_error(response, \"unexpected alert open\")\n     assert_dialog_handled(session, \"dismiss #1\")\n \n     create_dialog(\"confirm\", text=\"dismiss #2\", result_var=\"dismiss2\")\n", "before": "assert_error ( result , \"unexpected alert open\" )", "after": "assert_error ( response , \"unexpected alert open\" )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:result\", 3, 18, 3, 24], \"response\"]]"}
{"project": "rllab-curriculum", "commit_sha": "87c3e666db6dc8b0c71e6f1887f09f2003ad1ac8", "parent_sha": "81247e42e458108b184a97e9e698021dff1463f0", "file_path": "sandbox/carlos_snn/bonus_evaluators/grid_bonus_evaluator.py", "project_url": "https://github.com/florensacc/rllab-curriculum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -212,7 +212,7 @@ class GridBonusEvaluator(object):\n \n         # if self.survival_bonus:\n         avg_survival_bonus = np.mean([len(path['rewards']) for path in paths])\n-        logger.record_tabular('AvgPath_SurviBonus', avg_grid_count_bonus)\n+        logger.record_tabular('AvgPath_SurviBonus', avg_survival_bonus)\n \n         avg_grid_bonus = np.mean([np.sum(self.predict(path)) for path in paths])\n         logger.record_tabular('AvgPathGridBonus', avg_grid_bonus)\n", "before": "logger . record_tabular ( 'AvgPath_SurviBonus' , avg_grid_count_bonus )", "after": "logger . record_tabular ( 'AvgPath_SurviBonus' , avg_survival_bonus )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:avg_grid_count_bonus\", 3, 53, 3, 73], \"avg_survival_bonus\"]]"}
{"project": "gello", "commit_sha": "affd8c1e65435817689985a79c0d2f399754d8da", "parent_sha": "9f8ce0e67e5da66cb8d26d01edc9a132bdfe8738", "file_path": "app/tasks/update_jira_pull_request_issue_labels.py", "project_url": "https://github.com/DataDog/gello", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -47,4 +47,4 @@ class UpdateJiraPullRequestIssueLabels(GitHubBaseTask):\n         self.payload = payload\n         self.set_scope_data()\n         pull_request = PullRequest.query.filter_by(jira_project_key=project_key, github_pull_request_id=pull_request_id).first()\n-        self._jira_service.update_issue_labels(project_key=project_key, issue_key=issue.jira_issue_key, label_names=label_names)\n+        self._jira_service.update_issue_labels(project_key=project_key, issue_key=pull_request.jira_issue_key, label_names=label_names)\n", "before": "self . _jira_service . update_issue_labels ( project_key = project_key , issue_key = issue . jira_issue_key , label_names = label_names )", "after": "self . _jira_service . update_issue_labels ( project_key = project_key , issue_key = pull_request . jira_issue_key , label_names = label_names )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:issue\", 3, 83, 3, 88], \"pull_request\"]]"}
{"project": "pygreynoise", "commit_sha": "f73507c542ed5c3567e135997d625cc5d64412ee", "parent_sha": "36fd8b98b18ea6b75e0f31b1fbcb9a508b29ee2e", "file_path": "src/greynoise/util.py", "project_url": "https://github.com/GreyNoise-Intelligence/pygreynoise", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -99,7 +99,7 @@ def load_config():\n             config_parser.set(\"greynoise\", \"timeout\", timeout)\n \n     if \"GREYNOISE_PROXY\" in os.environ:\n-        api_server = os.environ[\"GREYNOISE_PROXY\"]\n+        proxy = os.environ[\"GREYNOISE_PROXY\"]\n         LOGGER.debug(\n             \"Proxy found in environment variable: %s\",\n             proxy,\n", "before": "api_server = os . environ [ \"GREYNOISE_PROXY\" ]", "after": "proxy = os . environ [ \"GREYNOISE_PROXY\" ]", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:api_server\", 3, 9, 3, 19], \"proxy\"]]"}
{"project": "ltiauthenticator", "commit_sha": "6be0fa8fb91dfd1d22ddaf376f1fbc65c88c66f4", "parent_sha": "6d4db95289d58eaff51c494b08d416769dec0711", "file_path": "ltiauthenticator/__init__.py", "project_url": "https://github.com/jupyterhub/ltiauthenticator", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -138,7 +138,7 @@ class LTIAuthenticator(Authenticator):\n             hops = [h.strip() for h in handler.request.headers['x-forwarded-proto'].split(',')]\n             protocol = hops[0]\n         else:\n-            protocol = self.request.protocol\n+            protocol = handler.request.protocol\n \n         launch_url = protocol + \"://\" + handler.request.host + handler.request.uri\n \n", "before": "else : protocol = self . request . protocol", "after": "else : protocol = handler . request . protocol", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:self\", 3, 24, 3, 28], \"handler\"]]"}
{"project": "mybuild", "commit_sha": "d94216eed57cfb3ae4f9e597e93bfe6d0ac10b49", "parent_sha": "16bf69ca991ad6b13677ba8006b068dd1338aee3", "file_path": "mylang/runtime.py", "project_url": "https://github.com/abusalimov/mybuild", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -47,7 +47,7 @@ def __objtype_new_meth(objtype):\n         raise TypeError(\"'{cls}' objects cannot be used in \"\n                         \"'object {{...}}' expression \"\n                         \"(missing '__my_new__' method)\"\n-                        .format(cls=type(obj)))\n+                        .format(cls=type(objtype)))\n \n def __fixup_name(closure, name):\n     closure.__name__ = name\n", "before": "raise TypeError ( \"'{cls}' objects cannot be used in \" \"'object {{...}}' expression \" \"(missing '__my_new__' method)\" . format ( cls = type ( obj ) ) )", "after": "raise TypeError ( \"'{cls}' objects cannot be used in \" \"'object {{...}}' expression \" \"(missing '__my_new__' method)\" . format ( cls = type ( objtype ) ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:obj\", 3, 42, 3, 45], \"objtype\"]]"}
{"project": "pyMaid", "commit_sha": "53d8139891bf82958ef510433cab0015790491ae", "parent_sha": "2960cec6517f95871e43c1af0b3353f7858dd653", "file_path": "pymaid.py", "project_url": "https://github.com/schlegelp/pyMaid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -399,7 +399,7 @@ def get_3D_skeleton ( skids, remote_instance = None , connector_flag = 1, tag_fl\n             if skid not in threads_closed:\r\n                 print('Did not close thread for skid',skid)     \r\n     else:\r\n-        print('\\n Success! %i of %i skeletons retrieved.' % ( len(threads_close) , len( to_retrieve ) ) )\r\n+        print('\\n Success! %i of %i skeletons retrieved.' % ( len(threads_closed) , len( to_retrieve ) ) )\r\n \r\n     \r\n     return (sk_data)\r\n", "before": "print ( '\\n Success! %i of %i skeletons retrieved.' % ( len ( threads_close ) , len ( to_retrieve ) ) )", "after": "print ( '\\n Success! %i of %i skeletons retrieved.' % ( len ( threads_closed ) , len ( to_retrieve ) ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:threads_close\", 3, 67, 3, 80], \"threads_closed\"]]"}
{"project": "pyMaid", "commit_sha": "10c78042c93f598f50a8eb760a71088f72809c6e", "parent_sha": "1d45f4926d11b60384e53845453790eedac06c05", "file_path": "pymaid/connectivity.py", "project_url": "https://github.com/schlegelp/pyMaid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1269,7 +1269,7 @@ def sparseness(x, which='LTS'):\n \n     .. math::\n \n-        S = \\\\Bigg\\\\{ \\\\frac{1}{N} \\\\sum^M_{i=1} \\\\Big[ \\\\frac{r_i - \\\\overline{r}}{\\\\sigma_r} \\\\Big] ^4  \\\\Bigg\\\\} - 3\n+        S = \\\\Bigg\\\\{ \\\\frac{1}{N} \\\\sum^N_{i=1} \\\\Big[ \\\\frac{r_i - \\\\overline{r}}{\\\\sigma_r} \\\\Big] ^4  \\\\Bigg\\\\} - 3\n \n     where :math:`N` is the number of observations, :math:`r_i` the value of\n     observation :math:`i`, and :math:`\\\\overline{r}` and\n", "before": "math : : S = \\ Bigg \\ { \\ frac { 1 } { N } \\ sum ^ M_ { i = 1 } \\ Big [ \\ frac { r_i - \\ overline { r } } { \\ sigma_r } \\ Big ] ^ 4 \\ Bigg \\ } - 3", "after": "math : : S = \\ Bigg \\ { \\ frac { 1 } { N } \\ sum ^ N_ { i = 1 } \\ Big [ \\ frac { r_i - \\ overline { r } } { \\ sigma_r } \\ Big ] ^ 4 \\ Bigg \\ } - 3", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:M_\", 3, 42, 3, 44], \"N_\"]]"}
{"project": "pyMaid", "commit_sha": "9c6b98303670c9285224eba34c37d41f0a0c64c7", "parent_sha": "b60f9ef39644e66a2ed42d15fd1506b5a6d079fb", "file_path": "pymaid/fetch.py", "project_url": "https://github.com/schlegelp/pyMaid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -242,7 +242,7 @@ class CatmaidInstance:\n             relative = arg_str[1:] if arg_str.startswith('/') else arg_str\r\n             url = requests.compat.urljoin(url + joiner, relative)\r\n         if GET:\r\n-            url += '?{}'.format(urllib.parse.urlencode(kwargs))\r\n+            url += '?{}'.format(urllib.parse.urlencode(GET))\r\n         return url\r\n \r\n     def _get_catmaid_version(self, **GET):\r\n", "before": "url += '?{}' . format ( urllib . parse . urlencode ( kwargs ) )", "after": "url += '?{}' . format ( urllib . parse . urlencode ( GET ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:kwargs\", 3, 56, 3, 62], \"GET\"]]"}
{"project": "sigir-erd-14-server", "commit_sha": "18a3c7cf66f40965c640b8aaa538ba54627803a4", "parent_sha": "0700e827231cdcd4af799cc25d070a229e16426a", "file_path": "run_server.py", "project_url": "https://github.com/aolieman/sigir-erd-14-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -120,7 +120,7 @@ def redecode_utf8(unicode_s):\n     try:\n         return unicode_s.encode('latin1').decode('utf8')\n     except UnicodeError:\n-        return s\n+        return unicode_s\n \n \n if __name__ == '__main__':    \n", "before": "return s", "after": "return unicode_s", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:s\", 3, 16, 3, 17], \"unicode_s\"]]"}
{"project": "icfpc2014-tbd", "commit_sha": "7fdb2006009dd42487da953eeb80aa038a6ce914", "parent_sha": "1a3bfb02cb7ed8ed47694c61cce7f192089606e2", "file_path": "yole_scratch/gcc_ast_test.py", "project_url": "https://github.com/Vlad-Shcherbina/icfpc2014-tbd", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ rtn\n ldc 0\n-gt\n+cgt\n sel 5 7\n rtn\n ldc 1\n", "before": "gt", "after": "cgt", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:gt\", 1, 1, 1, 3], \"cgt\"]]"}
{"project": "CU-CS5525-PythonCompiler", "commit_sha": "c3def21703bae06d5dcb7488e2cac42aa537550d", "parent_sha": "408a3afd5cdadff79fb8c41478c649fe6c4f3b2b", "file_path": "instr_select.py", "project_url": "https://github.com/asayler/CU-CS5525-PythonCompiler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -231,7 +231,7 @@ class InstrSelectVisitor(Visitor):\n             offset += WORDLEN\n         instrs += [Call86(n.node.name)]\n         instrs += [Move86(EAX, target)]\n-        if(cntargs > 0):\n+        if(offset > 0):\n             instrs += [Add86(Const86(offset), ESP)]\n         return instrs\n \n", "before": "if ( cntargs > 0 ) : instrs += [ Add86 ( Const86 ( offset ) , ESP ) ]", "after": "if ( offset > 0 ) : instrs += [ Add86 ( Const86 ( offset ) , ESP ) ]", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:cntargs\", 3, 12, 3, 19], \"offset\"]]"}
{"project": "mybuild", "commit_sha": "b71b2ea126a0e0182dba92548b65a79a76f0d15c", "parent_sha": "d8352b826d99da9362fcc7774eab0b3f64dade86", "file_path": "mybuild/core.py", "project_url": "https://github.com/abusalimov/mybuild", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -72,7 +72,7 @@ class ModuleType(type):\n         return cls._factory_call(domain, instance_node)\n \n     def _factory_call(cls, *args, **kwargs):\n-        return super(ModuleType, _cls).__call__(*args, **kwargs)\n+        return super(ModuleType, cls).__call__(*args, **kwargs)\n \n     def __repr__(cls):\n         try:\n", "before": "return super ( ModuleType , _cls ) . __call__ ( * args , ** kwargs )", "after": "return super ( ModuleType , cls ) . __call__ ( * args , ** kwargs )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:_cls\", 3, 34, 3, 38], \"cls\"]]"}
{"project": "mybuild", "commit_sha": "046464f5cedb81b60e2c4cc4f77016f3f114a219", "parent_sha": "dd2399f057043c4066fda5eabb2199b3cf4ce9b9", "file_path": "mybuild/core.py", "project_url": "https://github.com/abusalimov/mybuild", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -124,7 +124,7 @@ class Module(with_meta(ModuleType)):\n         \"\"\"Consumes keyword arguments.\"\"\"\n         super(Module, _self).__init__()\n \n-    def __repr__(_self):\n+    def __repr__(self):\n         return repr(self._optuple)\n \n \n", "before": "def __repr__ ( _self ) : return repr ( self . _optuple )", "after": "def __repr__ ( self ) : return repr ( self . _optuple )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:_self\", 3, 18, 3, 23], \"self\"]]"}
{"project": "skill-youtube-play", "commit_sha": "f68ce4b3e0c2120d0843733c05a8f3a687391fed", "parent_sha": "f0769d9d60a2012d23d1a367ca05c3041779f978", "file_path": "audio_skill.py", "project_url": "https://github.com/JarbasAl/skill-youtube-play", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -26,7 +26,7 @@ class AudioServiceB(AudioService):\n \n     def play(self, tracks=None, utterance=''):\n         utterance = utterance or self.backend\n-        super(AudioService_B, self).play(tracks, utterance)\n+        super(AudioServiceB, self).play(tracks, utterance)\n \n     def shutdown(self):\n         self.emitter.remove('mycroft.audio.service.track_info_reply',\n", "before": "super ( AudioService_B , self ) . play ( tracks , utterance )", "after": "super ( AudioServiceB , self ) . play ( tracks , utterance )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:AudioService_B\", 3, 15, 3, 29], \"AudioServiceB\"]]"}
{"project": "hotspotter", "commit_sha": "c8edebd4cd80fc61cd2c4d387d0dff9f0f05004f", "parent_sha": "370fdfb2c7efffa77e43fbfa4e0a55f17d90e486", "file_path": "hotspotter/front/DrawManager.py", "project_url": "https://github.com/Erotemic/hotspotter", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -357,7 +357,7 @@ class DrawManager(AbstractManager):\n             transImg = Affine2D()\n \n         (cw,ch) = cm.cx2_chip_size(cx) # This is not ok, because the size disagrees with roi after rotation\n-        if feat_xy_bit or fpts_ell_bit or qfsel != None:\n+        if feat_xy_bit or fpts_ell_bit or fsel != None:\n             fpts = cm.get_fpts(cx)\n             if in_image_bit:\n                 theta = cm.cx2_theta[cx]\n", "before": "if feat_xy_bit or fpts_ell_bit or qfsel != None : fpts = cm . get_fpts ( cx ) if in_image_bit : theta = cm . cx2_theta [ cx ]", "after": "if feat_xy_bit or fpts_ell_bit or fsel != None : fpts = cm . get_fpts ( cx ) if in_image_bit : theta = cm . cx2_theta [ cx ]", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:qfsel\", 3, 43, 3, 48], \"fsel\"]]"}
{"project": "palabra", "commit_sha": "644e3904a5021ddd774ade5432a472a523a860a5", "parent_sha": "28309b1fa7be661e30b82a2e3441f257e45ad960", "file_path": "palabralib/editor.py", "project_url": "https://github.com/svisser/palabra", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -117,7 +117,7 @@ class CellPropertiesDialog(gtk.Dialog):\n             p.set_size_request(196, -1)\n             align = gtk.Alignment(0, 0)\n             align.add(p)\n-            self.previews.append(align)\n+            self.previews.append(p)\n             p.display(self.grid)\n             for k in DEFAULTS_CELL:\n                 p.view.properties[k] = properties[k]\n", "before": "self . previews . append ( align )", "after": "self . previews . append ( p )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:align\", 3, 34, 3, 39], \"p\"]]"}
{"project": "eniric", "commit_sha": "010a35746df3fa221201e1aa0f2aa5cbba49727a", "parent_sha": "8a6e106512a7bf3b8ed8cca88255dcace1ffb2dd", "file_path": "eniric/plotting_functions.py", "project_url": "https://github.com/jason-neal/eniric", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1399,7 +1399,7 @@ def plot_paper_plots():\n     for star in spectral_types:\n         for band in bands:\n             for vel in vsini:\n-                for resolution in R:\n+                for res in R:\n                     for smpl in sampling:\n                         id_string = \"{0:s}-{1:s}-{2:.01f}-{3:s}-{4:2.01f}\".format(star, band, float(vel),\n                                                                                   res, float(smpl))\n", "before": "for resolution in R : for smpl in sampling : id_string = \"{0:s}-{1:s}-{2:.01f}-{3:s}-{4:2.01f}\" . format ( star , band , float ( vel ) , res , float ( smpl ) )", "after": "for res in R : for smpl in sampling : id_string = \"{0:s}-{1:s}-{2:.01f}-{3:s}-{4:2.01f}\" . format ( star , band , float ( vel ) , res , float ( smpl ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:resolution\", 3, 21, 3, 31], \"res\"]]"}
{"project": "cobbler", "commit_sha": "7bd876711dd8bc462d45895044f6de8fa8ddda4c", "parent_sha": "f9c18fd3df9a84087f0695b070b681655064624a", "file_path": "cobbler/utils.py", "project_url": "https://github.com/akesling/cobbler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -160,7 +160,7 @@ def find_kickstart(url):\n     x = url.lower()\n     for y in [\"http://\",\"nfs://\",\"ftp://\",\"/\"]:\n        if x.startswith(y):\n-           if x.startswith(\"/\") and not os.path.isfile(x):\n+           if x.startswith(\"/\") and not os.path.isfile(url):\n                return None\n            return url\n     return None\n", "before": "if x . startswith ( \"/\" ) and not os . path . isfile ( x ) : return None", "after": "if x . startswith ( \"/\" ) and not os . path . isfile ( url ) : return None", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:x\", 3, 56, 3, 57], \"url\"]]"}
{"project": "angr", "commit_sha": "deda59af8f038ac9312ec1224867bc2f0c1440f8", "parent_sha": "c9dc6cdbc9fa06f0e97ed4ed7c5d56c79307ea6c", "file_path": "simuvex/procedures/syscalls/__init__.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ class SimStateSystem(simuvex.SimStatePlugin):\n \t\t# TODO: error handling\n \t\t# TODO: symbolic support\n \t\tfd = self.state.make_concrete_int(fd)\n-\t\tlength = self.state.make_concrete_int(fd)\n+\t\tlength = self.state.make_concrete_int(length)\n \t\treturn self.files[fd].write(content, length, pos)\n \n \t@simuvex.helpers.concretize_args\n", "before": "length = self . state . make_concrete_int ( fd )", "after": "length = self . state . make_concrete_int ( length )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:fd\", 3, 41, 3, 43], \"length\"]]"}
{"project": "angr", "commit_sha": "13f0dc7dcf717af33c16e200d1980a924b248d08", "parent_sha": "12173a28e5d68842804702004bfe6677f3a6e9cb", "file_path": "simuvex/s_cc.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -233,7 +233,7 @@ class SimCCCdecl(SimCC):\n     @staticmethod\n     def _match(p, args, sp_delta):\n         if isinstance(p.arch, ArchX86) and sp_delta == 0:\n-            any_reg_args = any([a for a in args if isinstance(a, SimStackArg)])\n+            any_reg_args = any([a for a in args if isinstance(a, SimRegArg)])\n \n             if not any_reg_args:\n                 return True\n", "before": "any_reg_args = any ( [ a for a in args if isinstance ( a , SimStackArg ) ] )", "after": "any_reg_args = any ( [ a for a in args if isinstance ( a , SimRegArg ) ] )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:SimStackArg\", 3, 66, 3, 77], \"SimRegArg\"]]"}
{"project": "angr", "commit_sha": "a4dbd1879f2c4dd128d6b49cfd68d5bfbbab8cd7", "parent_sha": "67f8b5ddba58e9f199c16a7422ead37e72100d1b", "file_path": "simuvex/plugins/inspect.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -144,7 +144,7 @@ class SimInspector(SimStatePlugin):\n         l.debug(\"Event %s (%s) firing...\", event_type, when)\n         for k,v in kwargs.iteritems():\n             if k not in inspect_attributes:\n-                raise ValueError(\"Invalid inspect attribute %s passed in. Should be one of: %s\" % (k, event_types))\n+                raise ValueError(\"Invalid inspect attribute %s passed in. Should be one of: %s\" % (k, inspect_attributes))\n             #l.debug(\"... %s = %r\", k, v)\n             l.debug(\"... setting %s\", k)\n             setattr(self, k, v)\n", "before": "raise ValueError ( \"Invalid inspect attribute %s passed in. Should be one of: %s\" % ( k , event_types ) )", "after": "raise ValueError ( \"Invalid inspect attribute %s passed in. Should be one of: %s\" % ( k , inspect_attributes ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:event_types\", 3, 103, 3, 114], \"inspect_attributes\"]]"}
{"project": "angr", "commit_sha": "f6ba4246a79a7cb51bfdf005aa84130c09dc3d62", "parent_sha": "b3a19317c04ff55c531f14e9669cde53e30cecd3", "file_path": "simuvex/storage/memory.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -332,7 +332,7 @@ class SimMemory(SimStatePlugin):\n                 if name in stn_map:\n                     return (((stn_map[name] + self.load('ftop')) & 7) << 3) + self.state.arch.registers['fpu_regs'][0], 8\n                 elif name in tag_map:\n-                    return ((stn_map[name] + self.load('ftop')) & 7) + self.state.arch.registers['fpu_tags'][0], 1\n+                    return ((tag_map[name] + self.load('ftop')) & 7) + self.state.arch.registers['fpu_tags'][0], 1\n \n             return self.state.arch.registers[name]\n         elif name[0] == '*':\n", "before": "return ( ( stn_map [ name ] + self . load ( 'ftop' ) ) & 7 ) + self . state . arch . registers [ 'fpu_tags' ] [ 0 ] , 1", "after": "return ( ( tag_map [ name ] + self . load ( 'ftop' ) ) & 7 ) + self . state . arch . registers [ 'fpu_tags' ] [ 0 ] , 1", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:stn_map\", 3, 30, 3, 37], \"tag_map\"]]"}
{"project": "echronos-sandbox", "commit_sha": "49445cfdcd0046eae43171f177abac7c99c74d7d", "parent_sha": "2ec667790c721ac0218a5a06257fc3015eeb5336", "file_path": "prj/app/prj.py", "project_url": "https://github.com/schnommus/echronos-sandbox", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -844,7 +844,7 @@ might not be available on the PATH search path for executables.\")\n                     subprocess.check_call([\"splint\", \"-DUINT8_C(x)=(uint8_t)(x)\", \"-DUINT8_MAX=255\",\n                                            \"-DUINT32_C(x)=(uint32_t)(x)\", \"-DUINT32_MAX=0xFFFFFFFF\", \"+quiet\",\n                                            \"+charintliteral\"] + include_path_options + [c_file])\n-                except suprocess.CalledProcessError:\n+                except subprocess.CalledProcessError:\n                     print(\"Static analysis of '{}' with splint failed\".format(c_file))\n                     return 2\n \n", "before": "except suprocess . CalledProcessError : print ( \"Static analysis of '{}' with splint failed\" . format ( c_file ) )", "after": "except subprocess . CalledProcessError : print ( \"Static analysis of '{}' with splint failed\" . format ( c_file ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:suprocess\", 3, 24, 3, 33], \"subprocess\"]]"}
{"project": "fitbit-googlefit", "commit_sha": "d455e77b9a6a19afd98c4eb305a4caf147b0b76c", "parent_sha": "a77151ef5789816d161ae98ee4f8dd27efeb0dd8", "file_path": "helpers.py", "project_url": "https://github.com/lightmaster/fitbit-googlefit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,7 +52,7 @@ def UpdateFitbitCredentials(fitbitClient, credentials, filepath=fitbitCredsFile)\n \t\t\tdump = True\n \tif dump:\n \t\tlogging.debug(\"Updating Fitbit credentials\")\n-\t\tjson.dump(credentials, open(filename, 'w'))\n+\t\tjson.dump(credentials, open(filepath, 'w'))\n \n def GetGoogleClient(filepath):\n", "before": "json . dump ( credentials , open ( filename , 'w' ) )", "after": "json . dump ( credentials , open ( filepath , 'w' ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:filename\", 3, 31, 3, 39], \"filepath\"]]"}
{"project": "SentEval", "commit_sha": "7b9deae500dc2978eb9e4ecec2e9c8be4caaa977", "parent_sha": "6b452819c8cd633b5647fbbfbdd74d27cd39236e", "file_path": "examples/models.py", "project_url": "https://github.com/vrindaprabhu/SentEval", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -47,7 +47,7 @@ class BLSTMEncoder(nn.Module):\n         sent_output = nn.utils.rnn.pad_packed_sequence(sent_output)[0]\n         \n         # Un-sort by length\n-        idx_unsort = torch.from_numpy(idx_unsort).cuda() if self.use_cuda else torch.from_numpy(idx_sort)\n+        idx_unsort = torch.from_numpy(idx_unsort).cuda() if self.use_cuda else torch.from_numpy(idx_unsort)\n         sent_output = sent_output.index_select(1, Variable(idx_unsort))\n         \n         # Pooling\n", "before": "idx_unsort = torch . from_numpy ( idx_unsort ) . cuda ( ) if self . use_cuda else torch . from_numpy ( idx_sort )", "after": "idx_unsort = torch . from_numpy ( idx_unsort ) . cuda ( ) if self . use_cuda else torch . from_numpy ( idx_unsort )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:idx_sort\", 3, 97, 3, 105], \"idx_unsort\"]]"}
{"project": "autogamess", "commit_sha": "4ac1c841c32f94079b8a0ef1998484a2088dce8d", "parent_sha": "030bf6f28d51e34103568c9d617405cacdfb64a3", "file_path": "autogamess/data_finder.py", "project_url": "https://github.com/Cavenfish/autogamess", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -184,7 +184,7 @@ def raman(filename):\n \n     ram = {}\n     for a,b in zip(temp1[modes:],temp2[modes:]):\n-        if b not in freq:\n+        if b not in ram:\n             ram[b] = [a]\n         else:\n             ram[b] += [a]\n", "before": "if b not in freq : ram [ b ] = [ a ] else : ram [ b ] += [ a ]", "after": "if b not in ram : ram [ b ] = [ a ] else : ram [ b ] += [ a ]", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:freq\", 3, 21, 3, 25], \"ram\"]]"}
{"project": "netpyne", "commit_sha": "49cfe368a6b6b65f9db35d780da491ecf4e373b8", "parent_sha": "14c95800d5867bde22e16b13b1852f7d347a1faa", "file_path": "netpyne/analysis/interactive.py", "project_url": "https://github.com/rodriguez-facundo/netpyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -498,7 +498,7 @@ def iplotSpikeHist(include = ['allCells', 'eachPop'], legendLabels = [], timeRan\n         s = fig.line(histoT, histoCount, line_width=2.0, name=str(subset), color=color)\n \n         if overlay:\n-           legendItems.append((str(subset), [s]))\n+           legendItems.append((str(label), [s]))\n     \n     if overlay:\n         legend = Legend(items=legendItems, location=(10,0))\n", "before": "legendItems . append ( ( str ( subset ) , [ s ] ) )", "after": "legendItems . append ( ( str ( label ) , [ s ] ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:subset\", 3, 36, 3, 42], \"label\"]]"}
{"project": "netpyne", "commit_sha": "0ee068dededd7d8d8c2b1316aa3daf30c9b69482", "parent_sha": "9cdf2a0905897ffd8812afe6947f3e0aa78085d9", "file_path": "netpyne/cell/compartCell.py", "project_url": "https://github.com/rodriguez-facundo/netpyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -57,7 +57,7 @@ class CompartCell (Cell):\n     def __str__ (self):\n         try:\n             gid, cty, cmo = self.gid, self.tags['cellType'], self.tags['cellModel'] # only use if these exist\n-            return 'compartCell_%s_%s_%d'%(cty, cty, gid)\n+            return 'compartCell_%s_%s_%d'%(cty, cmo, gid)\n         except: return 'compartCell%d'%self.gid\n \n     def __repr__ (self):\n", "before": "return 'compartCell_%s_%s_%d' % ( cty , cty , gid )", "after": "return 'compartCell_%s_%s_%d' % ( cty , cmo , gid )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:cty\", 3, 49, 3, 52], \"cmo\"]]"}
{"project": "autogamess", "commit_sha": "976dfad28fa26f03d79922e5ee6bf2cdfd5feb3e", "parent_sha": "a79712b22fb888919ea965f65ce8b1f899aeffcc", "file_path": "autogamess/data_finder.py", "project_url": "https://github.com/Cavenfish/autogamess", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -224,7 +224,7 @@ def hessian(filename):\n             infr[b] += [a]\n     #Store Imaginary IR intensity data in dictionary\n     for a,b in zip(temp3[0:imodes],temp2[0:imodes]):\n-        if b not in freq:\n+        if b not in infr:\n             infr[b] = [a]\n         else:\n             infr[b] += [a]\n", "before": "if b not in freq : infr [ b ] = [ a ] else : infr [ b ] += [ a ]", "after": "if b not in infr : infr [ b ] = [ a ] else : infr [ b ] += [ a ]", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:freq\", 3, 21, 3, 25], \"infr\"]]"}
{"project": "catt-qt", "commit_sha": "b795ef486b5cdbb3a7d4758a8e5acd978423db3f", "parent_sha": "6874eb92d805b90b62106276debbe784da18d86c", "file_path": "cattqt/cattqt.py", "project_url": "https://github.com/soreau/catt-qt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -764,7 +764,7 @@ class App(QMainWindow):\n         if self.combo_box.currentIndex() == device.index:\n             self.play_button.setEnabled(True)\n             self.stop_button.setEnabled(True)\n-        d.disconnect_volume = round(device.cast.status.volume_level * 100)\n+        device.disconnect_volume = round(device.cast.status.volume_level * 100)\n         if self.reconnect_volume == -1:\n             if last_volume != round(device.cast.status.volume_level * 100):\n                 d.volume(last_volume / 100)\n", "before": "d . disconnect_volume = round ( device . cast . status . volume_level * 100 )", "after": "device . disconnect_volume = round ( device . cast . status . volume_level * 100 )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:d\", 3, 9, 3, 10], \"device\"]]"}
{"project": "pyAudioProcessing", "commit_sha": "b38316e0557b8cf1d53d4f1c8c3709f3e2e8a18d", "parent_sha": "31b3ae3865ac7fafe5274bf7664415f01afe0c9f", "file_path": "pyAudioProcessing/extract_features.py", "project_url": "https://github.com/jsingh811/pyAudioProcessing", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -63,7 +63,7 @@ def get_features(folder_path, feature_names):\n         for sub_inx in range(len(files)):\n             class_file_feats[class_names[inx]][files[sub_inx]] = {\n                 \"features\": list(features[inx][sub_inx]),\n-                \"feature_names\": feat_names[sub_inx]\n+                \"feature_names\": feat_names[inx]\n             }\n \n     return class_file_feats\n", "before": "class_file_feats [ class_names [ inx ] ] [ files [ sub_inx ] ] = { \"features\" : list ( features [ inx ] [ sub_inx ] ) , \"feature_names\" : feat_names [ sub_inx ] }", "after": "class_file_feats [ class_names [ inx ] ] [ files [ sub_inx ] ] = { \"features\" : list ( features [ inx ] [ sub_inx ] ) , \"feature_names\" : feat_names [ inx ] }", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:sub_inx\", 3, 45, 3, 52], \"inx\"]]"}
{"project": "pyAudioProcessing", "commit_sha": "becfd6ba31e948c8f32bfbedd3226cfa7cc3fc53", "parent_sha": "4caf802b783026923986269a4ce804689f433888", "file_path": "pyAudioProcessing/features/audioFeatureExtraction.py", "project_url": "https://github.com/jsingh811/pyAudioProcessing", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -243,7 +243,7 @@ def dirWavFeatureExtraction(dirName, mt_win, mt_step, st_win, st_step, feats,\n-    Same as WavFeatureExtraction, but instead of a single dir it\n+    Same as dirWavFeatureExtraction, but instead of a single dir it\n     takes a list of paths as input and returns a list of feature matrices.\n     EXAMPLE:\n     [features, classNames] =\n", "before": "WavFeatureExtraction , but instead of a single dir it", "after": "dirWavFeatureExtraction , but instead of a single dir it", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:WavFeatureExtraction\", 0, 13, 0, 33], \"dirWavFeatureExtraction\"]]"}
{"project": "echronos-sandbox", "commit_sha": "886593787814dfa48555de5479c6af4039907556", "parent_sha": "09c705440ba5cdb7cd619f3d3f4f037bc1939eab", "file_path": "x.py", "project_url": "https://github.com/schnommus/echronos-sandbox", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -384,7 +384,7 @@ def main():\n         'tasks': tasks,\n         'integrate': integrate,\n         # Tempalte management\n-        'gen-tag': gen_tag,\n+        'gen-tag': _gen_tag,\n     }\n \n     # create the top-level parser\n", "before": "gen_tag ,", "after": "_gen_tag ,", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:gen_tag\", 3, 20, 3, 27], \"_gen_tag\"]]"}
{"project": "funcx-web-service", "commit_sha": "a0086b9dbb776dec6658273e9e78ed2b98903e4f", "parent_sha": "165940e156213fdb388de007244802479ef78462", "file_path": "routes/funcx.py", "project_url": "https://github.com/funcx-faas/funcx-web-service", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -96,7 +96,7 @@ def auth_and_launch(user_id, function_uuid, endpoints, input_data, app, token, s\n         task_id = str(uuid.uuid4())\n         task_header = f\"{task_id};{container_uuid};{serializer}\"\n \n-        for ep in endpoint:\n+        for ep in endpoints:\n             redis_task_queue = RedisQueue(f\"task_{ep}\",\n                                           hostname=app.config['REDIS_HOST'],\n                                           port=app.config['REDIS_PORT'])\n", "before": "for ep in endpoint : redis_task_queue = RedisQueue ( f\"task_{ep}\" , hostname = app . config [ 'REDIS_HOST' ] , port = app . config [ 'REDIS_PORT' ] )", "after": "for ep in endpoints : redis_task_queue = RedisQueue ( f\"task_{ep}\" , hostname = app . config [ 'REDIS_HOST' ] , port = app . config [ 'REDIS_PORT' ] )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:endpoint\", 3, 19, 3, 27], \"endpoints\"]]"}
{"project": "OpenNMT-entmax", "commit_sha": "438cc09dd481ea20111f8e6acad5fd6259c33fec", "parent_sha": "f512ea5929d812418cb300d9dde84716c9d42e8d", "file_path": "onmt/utils/report_manager.py", "project_url": "https://github.com/deep-spin/OpenNMT-entmax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -8,7 +8,7 @@ import onmt\n \n def build_report_manager(opt):\n     if opt.tensorboard:\n-        from tensorboard import SummaryWriter\n+        from tensorboardX import SummaryWriter\n         writer = SummaryWriter(opt.tensorboard_log_dir\n                                + datetime.now().strftime(\"/%b-%d_%H-%M-%S\"),\n                                comment=\"Unmt\")\n", "before": "from tensorboard import SummaryWriter", "after": "from tensorboardX import SummaryWriter", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:tensorboard\", 3, 14, 3, 25], \"tensorboardX\"]]"}
{"project": "OpenNMT-entmax", "commit_sha": "288974b8e70f7978d93956291aaa15707d6b770c", "parent_sha": "66153f0587144480cb1cf9b2aeeca78972f157e7", "file_path": "onmt/modules/GlobalAttention.py", "project_url": "https://github.com/deep-spin/OpenNMT-entmax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -118,7 +118,7 @@ class GlobalAttention(nn.Module):\n         a_t = self.score(input, context)\n         \n         if self.mask is not None:\n-            attention_scores.data.masked_fill_(self.mask, -float('inf'))\n+            a_t.data.masked_fill_(self.mask, -float('inf'))\n             \n         # Softmax to normalize attention weights \n         align_vector = self.sm(a_t)\n", "before": "attention_scores . data . masked_fill_ ( self . mask , - float ( 'inf' ) )", "after": "a_t . data . masked_fill_ ( self . mask , - float ( 'inf' ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:attention_scores\", 3, 13, 3, 29], \"a_t\"]]"}
{"project": "procbridge-python", "commit_sha": "d3a37240977b9ea8fe8f8e98f3cbc39ac435d2a0", "parent_sha": "492fd671ebe6b6bf213f1d98e5b0f1d4acd1abc7", "file_path": "procbridge/protocol.py", "project_url": "https://github.com/gongzhang/procbridge-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -94,7 +94,7 @@ def write_request(s: socket.socket, method: str, payload: Any):\n     write_socket(s, StatusCode.REQUEST, body)\n \n \n-def write_good_response(s: socket.socket, payload: dict):\n+def write_good_response(s: socket.socket, payload: Any):\n     body = {}\n     if payload is not None:\n         body[Keys.PAYLOAD.value] = payload\n", "before": "def write_good_response ( s : socket . socket , payload : dict ) : body = { } if payload is not None : body [ Keys . PAYLOAD . value ] = payload", "after": "def write_good_response ( s : socket . socket , payload : Any ) : body = { } if payload is not None : body [ Keys . PAYLOAD . value ] = payload", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:dict\", 3, 52, 3, 56], \"Any\"]]"}
{"project": "python_planet", "commit_sha": "efc1aab8e171e094c058857db8220ae2e9db7ffb", "parent_sha": "1663a9eaa5785e7371bacc624507a996511a6045", "file_path": "planet/control/CUser.py", "project_url": "https://github.com/haobin12358/python_planet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1082,7 +1082,7 @@ class CUser(SUser, BASEAPPROVAL):\n \n         ui_list = UserIntegral.query.filter_(\n             UserIntegral.USid == request.user.id, UserIntegral.UItype == uifilter\n-        ).order_by(UserInvitation.createtime.desc()).all_with_page()\n+        ).order_by(UserIntegral.createtime.desc()).all_with_page()\n         for ui in ui_list:\n             ui.fields = ['UIintegral', 'createtime']\n             ui.fill('uiaction', UserIntegralAction(ui.UIaction).zh_value)\n", "before": "ui_list = UserIntegral . query . filter_ ( UserIntegral . USid == request . user . id , UserIntegral . UItype == uifilter ) . order_by ( UserInvitation . createtime . desc ( ) ) . all_with_page ( )", "after": "ui_list = UserIntegral . query . filter_ ( UserIntegral . USid == request . user . id , UserIntegral . UItype == uifilter ) . order_by ( UserIntegral . createtime . desc ( ) ) . all_with_page ( )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:UserInvitation\", 3, 20, 3, 34], \"UserIntegral\"]]"}
{"project": "wagtail-whoosh", "commit_sha": "5772c3ecd21588edb7e0045011bffb418a23d294", "parent_sha": "fb73f5606565912ec337756fd81189dafcc1e3d2", "file_path": "wagtail_whoosh/backend.py", "project_url": "https://github.com/wagtail/wagtail-whoosh", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -190,7 +190,7 @@ class WhooshSearchQueryCompiler(BaseSearchQueryCompiler):\n         for field in model.get_search_fields():\n             if isinstance(field, RelatedFields):\n                 for sub_field in field.fields:\n-                    yield '{0}__{1}'.format(field.field_name, _get_field_mapping(field))\n+                    yield '{0}__{1}'.format(field.field_name, _get_field_mapping(sub_field))\n             else:\n                 yield _get_field_mapping(field)\n \n", "before": "yield '{0}__{1}' . format ( field . field_name , _get_field_mapping ( field ) )", "after": "yield '{0}__{1}' . format ( field . field_name , _get_field_mapping ( sub_field ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:field\", 3, 82, 3, 87], \"sub_field\"]]"}
{"project": "sympy", "commit_sha": "2460021c94b330dee5106a6b4a550dd3fc0ef4bf", "parent_sha": "e18dd7b85119db1892dcf9b086873e94baa76a2d", "file_path": "sympy/ntheory/egyptian_fraction.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -103,7 +103,7 @@ def egyptian_fraction(r, algorithm=\"Greedy\"):\n \n     .. [1] https://en.wikipedia.org/wiki/Egyptian_fraction\n     .. [2] https://en.wikipedia.org/wiki/Greedy_algorithm_for_Egyptian_fractions\n-    .. [3] http://www.ics.uci.edu/~eppstein/numth/egypt/conflict.html\n+    .. [3] https://www.ics.uci.edu/~eppstein/numth/egypt/conflict.html\n     .. [4] http://ami.ektf.hu/uploads/papers/finalpdf/AMI_42_from129to134.pdf\n \n", "before": "http :  // www . ics . uci . edu / ~ eppstein / numth / egypt / conflict . html", "after": "https :  // www . ics . uci . edu / ~ eppstein / numth / egypt / conflict . html", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:http\", 3, 12, 3, 16], \"https\"]]"}
{"project": "sympy", "commit_sha": "db9a7dd37172d8a522c785928764ae22617542ff", "parent_sha": "35e4bef5bd7f4287a9c32a139b0cf89905151618", "file_path": "sympy/matrices/matrices.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1335,7 +1335,7 @@ def jordan_form(self, calc_transform=True, **kwargs):\n \n         def dps(expr):\n             C = log(10)/log(2)\n-            return max(1, int(round(int(max_prec) / C - 1)))\n+            return max(1, int(round(int(expr) / C - 1)))\n \n         if has_floats:\n             max_prec = 0\n", "before": "return max ( 1 , int ( round ( int ( max_prec ) / C - 1 ) ) )", "after": "return max ( 1 , int ( round ( int ( expr ) / C - 1 ) ) )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:max_prec\", 3, 41, 3, 49], \"expr\"]]"}
{"project": "sympy", "commit_sha": "dd8a7d262e04bb50fbb066d92e4bce36cff9eb02", "parent_sha": "b95ffadae8cfad3acf15fada28140373c896b766", "file_path": "sympy/utilities/lambdify.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -466,7 +466,7 @@ def _get_namespace(m):\n     \"\"\"\n     This is used by _lambdify to parse its arguments.\n     \"\"\"\n-    if isinstance(m, str):\n+    if isinstance(m, string_types):\n         _import(m)\n         return MODULES[m][0]\n     elif isinstance(m, dict):\n", "before": "if isinstance ( m , str ) : _import ( m ) return MODULES [ m ] [ 0 ] elif isinstance ( m , dict ) : ", "after": "if isinstance ( m , string_types ) : _import ( m ) return MODULES [ m ] [ 0 ] elif isinstance ( m , dict ) : ", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:str\", 3, 22, 3, 25], \"string_types\"]]"}
{"project": "sympy", "commit_sha": "ba64bff3499765629cb241e1d5456392949438e5", "parent_sha": "80855cf664436a8a9a3b7b948f70f1be5826f239", "file_path": "sympy/printing/pretty/tests/test_pretty.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -6321,7 +6321,7 @@ def test_pretty_print_tensor_expr():\n \n \n def test_pretty_print_tensor_partial_deriv():\n-    from sympy.tensor.operators import PartialDerivative\n+    from sympy.tensor.toperators import PartialDerivative\n     from sympy.tensor.tensor import TensorIndexType, tensor_indices, tensorhead\n \n     L = TensorIndexType(\"L\")\n", "before": "from sympy . tensor . operators import PartialDerivative", "after": "from sympy . tensor . toperators import PartialDerivative", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:operators\", 3, 23, 3, 32], \"toperators\"]]"}
{"project": "sympy", "commit_sha": "bcb62507e86a6b711d5d0a259d6069b61da24541", "parent_sha": "84e90a22677cc83230bc3e4e650c5d02599c63e5", "file_path": "sympy/geometry/tests/test_polygon.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -218,7 +218,7 @@ def test_polygon():\n     assert t3.inradius == t3.incircle.radius == x1**2/((2 + sqrt(2))*Abs(x1))\n \n     # Exradius\n-    assert t1.exradii[t.sides[2]] == 5*sqrt(2)/2\n+    assert t1.exradii[t1.sides[2]] == 5*sqrt(2)/2\n \n     # Circumcircle\n     assert t1.circumcircle.center == Point(2.5, 2.5)\n", "before": "assert t1 . exradii [ t . sides [ 2 ] ] == 5 * sqrt ( 2 ) / 2", "after": "assert t1 . exradii [ t1 . sides [ 2 ] ] == 5 * sqrt ( 2 ) / 2", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:t\", 3, 23, 3, 24], \"t1\"]]"}
{"project": "sympy", "commit_sha": "7e7e7764f9102cb2996c97d9dad9b348ada92c89", "parent_sha": "31af3c4eab3e21eb74eccfce47af6544a4ffdeae", "file_path": "sympy/calculus/util.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ def continuous_domain(f, symbol, domain):\n             else:\n                 sings = Intersection(solveset(1/f, symbol), domain)\n \n-    except BaseException:\n+    except NotImplementedError:\n         raise NotImplementedError(\n             \"Methods for determining the continuous domains\"\n             \" of this function have not been developed.\")\n", "before": "BaseException : raise NotImplementedError ( \"Methods for determining the continuous domains\" \" of this function have not been developed.\" )", "after": "NotImplementedError : raise NotImplementedError ( \"Methods for determining the continuous domains\" \" of this function have not been developed.\" )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:BaseException\", 3, 12, 3, 25], \"NotImplementedError\"]]"}
{"project": "osc", "commit_sha": "58532bbac787b4be9c0ccb1530f33e9a136b6e99", "parent_sha": "d338254bb7ee260e2be96d2345547c59adfa83ad", "file_path": "osc/commandline.py", "project_url": "https://github.com/lethliel/osc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2031,7 +2031,7 @@ Please submit there instead, or use --nodevelproject to force direct submission.\n                     try:\n                         show_project_meta(apiurl, project)\n                         print('No results for {0}'.format(project))\n-                    except TypeError:\n+                    except HTTPError:\n                         print('Project {0} does not exist'.format(project))\n                 else:\n                     print('No results')\n", "before": "try : show_project_meta ( apiurl , project ) print ( 'No results for {0}' . format ( project ) ) except TypeError : print ( 'Project {0} does not exist' . format ( project ) ) else : print ( 'No results' )", "after": "try : show_project_meta ( apiurl , project ) print ( 'No results for {0}' . format ( project ) ) except HTTPError : print ( 'Project {0} does not exist' . format ( project ) ) else : print ( 'No results' )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:TypeError\", 3, 28, 3, 37], \"HTTPError\"]]"}
{"project": "sympy", "commit_sha": "4e624b2de52a1795830da80caf653a6521b52197", "parent_sha": "dcb8cdd5b66bf6c0c197866c56097951dfef0fc6", "file_path": "sympy/ntheory/generate.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -358,7 +358,7 @@ def primerange(a, b):\n \n         If the range exists in the default sieve, the values will\n         be returned from there; otherwise values will be returned\n-        but will not modifiy the sieve.\n+        but will not modify the sieve.\n \n         Notes\n         =====\n", "before": "but will not modifiy the sieve . Notes", "after": "but will not modify the sieve . Notes", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:modifiy\", 3, 22, 3, 29], \"modify\"]]"}
{"project": "sympy", "commit_sha": "8b23468fc488ec5453eb00b78932fcbc8840a4f6", "parent_sha": "2c7721a7a328bdbbca1a5053a37ec09d0057a96d", "file_path": "sympy/printing/tests/test_mathml.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -941,7 +941,7 @@ def test_print_basic():\n \n \n def test_mat_delim_print():\n-    aexpr = Matrix([[1, 2], [3, 4]])\n+    expr = Matrix([[1, 2], [3, 4]])\n     assert mathml(expr, printer='presentation', mat_delim='[') == '<mfenced close=\"]\" open=\"[\"><mtable><mtr><mtd><mn>1</mn></mtd><mtd><mn>2</mn></mtd></mtr><mtr><mtd><mn>3</mn></mtd><mtd><mn>4</mn></mtd></mtr></mtable></mfenced>'\n     assert mathml(expr, printer='presentation', mat_delim='(') == '<mfenced><mtable><mtr><mtd><mn>1</mn></mtd><mtd><mn>2</mn></mtd></mtr><mtr><mtd><mn>3</mn></mtd><mtd><mn>4</mn></mtd></mtr></mtable></mfenced>'\n     assert mathml(expr, printer='presentation', mat_delim='') == '<mtable><mtr><mtd><mn>1</mn></mtd><mtd><mn>2</mn></mtd></mtr><mtr><mtd><mn>3</mn></mtd><mtd><mn>4</mn></mtd></mtr></mtable>'\n", "before": "aexpr = Matrix ( [ [ 1 , 2 ] , [ 3 , 4 ] ] )", "after": "expr = Matrix ( [ [ 1 , 2 ] , [ 3 , 4 ] ] )", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:aexpr\", 3, 5, 3, 10], \"expr\"]]"}
{"project": "sympy", "commit_sha": "b478e4b48303c3f5c6921fdb26abfb2ca59bfcc3", "parent_sha": "f3eda77a33ad81e9892d2b663cc013e874f8a905", "file_path": "sympy/solvers/pde.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -578,7 +578,7 @@ def pde_1st_linear_constant_coeff(eq, func, order, match, solvefun):\n         f(x, y) = \\left. \\left[F(\\eta) + \\frac{1}{a^2 + b^2}\n         \\int\\limits^{a x + b y} G\\left(\\frac{a \\xi + b \\eta}{a^2 + b^2},\n         \\frac{- a \\eta + b \\xi}{a^2 + b^2} \\right)\n-        e^{\\frac{a \\xi}{a^2 + b^2}}\\, d\\xi\\right]\n+        e^{\\frac{c \\xi}{a^2 + b^2}}\\, d\\xi\\right]\n         e^{- \\frac{c \\xi}{a^2 + b^2}}\n         \\right|_{\\substack{\\eta=- a y + b x\\\\ \\xi=a x + b y }}\n \n", "before": "eft . l eft [ F ( e ta ) + f rac { 1 } { a ^ 2 + b ^ 2 } i nt l imits ^ { a x + b y } G l eft ( f rac { a x i + b e ta } { a ^ 2 + b ^ 2 } , f rac { - a e ta + b x i } { a ^ 2 + b ^ 2 } r ight ) e ^ { f rac { a x i } { a ^ 2 + b ^ 2 } } , d x i r ight ]", "after": "eft . l eft [ F ( e ta ) + f rac { 1 } { a ^ 2 + b ^ 2 } i nt l imits ^ { a x + b y } G l eft ( f rac { a x i + b e ta } { a ^ 2 + b ^ 2 } , f rac { - a e ta + b x i } { a ^ 2 + b ^ 2 } r ight ) e ^ { f rac { c x i } { a ^ 2 + b ^ 2 } } , d x i r ight ]", "sstub_pattern": "CHANGE_IDENTIFIER_USED", "edit_script": "[[\"Update\", [\"identifier:a\", 3, 18, 3, 19], \"c\"]]"}
{"project": "jinja2", "commit_sha": "91e206ae581b2675779ff733fa480ee76ac9a1e5", "parent_sha": "fa7f9eaca9400168a9b029fef865ea4f5399dce4", "file_path": "jinja/parser.py", "project_url": "https://github.com/silkapp/jinja2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1108,7 +1108,7 @@ class Parser(object):\n                 assert False, \"unexpected token %r\" % self.stream.current\n \n         if test is not None:\n-            msg = isinstance(test, StateTest) and ': ' + test.message or ''\n+            msg = isinstance(test, StateTest) and ': ' + test.msg or ''\n             raise TemplateSyntaxError('unexpected end of stream' + msg,\n                                       self.stream.lineno, self.filename)\n \n", "before": "msg = isinstance ( test , StateTest ) and ': ' + test . message or ''", "after": "msg = isinstance ( test , StateTest ) and ': ' + test . msg or ''", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:message\", 3, 63, 3, 70], \"msg\"]]"}
{"project": "dexy", "commit_sha": "e546734f9f59fbf85f80574014cf5c1643eb4f32", "parent_sha": "d48dc522753b291c2e346206e86791f06e6be101", "file_path": "handlers/word_press_handler.py", "project_url": "https://github.com/mojavelinux/dexy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ class WordPressHandler(BlogHandler):\n         api.metaWeblog.editPost(\n             post_id, \n             self.blog_conf[\"user\"], \n-            self.blof_conf[\"pass\"], \n+            self.blog_conf[\"pass\"], \n             self.content_dict(api, input_text), \n             self.post_conf['publish']\n         )\n", "before": "api . metaWeblog . editPost ( post_id , self . blog_conf [ \"user\" ] , self . blof_conf [ \"pass\" ] , self . content_dict ( api , input_text ) , self . post_conf [ 'publish' ] )", "after": "api . metaWeblog . editPost ( post_id , self . blog_conf [ \"user\" ] , self . blog_conf [ \"pass\" ] , self . content_dict ( api , input_text ) , self . post_conf [ 'publish' ] )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:blof_conf\", 3, 18, 3, 27], \"blog_conf\"]]"}
{"project": "lstm-char-cnn-tensorflow", "commit_sha": "576091596115f40d92dbd42b2b39598335518abc", "parent_sha": "d66e2f1f96042c413ac59c40d90e904367266098", "file_path": "models/LSTMTDNN.py", "project_url": "https://github.com/arita37/lstm-char-cnn-tensorflow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -149,7 +149,7 @@ class LSTMTDNN(Model):\n         self.cell = rnn_cell.BasicLSTMCell(self.rnn_size)\n         self.stacked_cell = rnn_cell.MultiRNNCell([self.cell] * self.layer_depth)\n \n-        outputs, _ = rnn.rnn(self.cell,\n+        outputs, _ = rnn.rnn(self.stacked_cell,\n                              self.cnn_outputs,\n                              dtype=tf.float32)\n \n", "before": "outputs , _ = rnn . rnn ( self . cell , self . cnn_outputs , dtype = tf . float32 )", "after": "outputs , _ = rnn . rnn ( self . stacked_cell , self . cnn_outputs , dtype = tf . float32 )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:cell\", 3, 35, 3, 39], \"stacked_cell\"]]"}
{"project": "blink-qt", "commit_sha": "dee55690a89af6c6a5fa84262271190e8dee940f", "parent_sha": "ddcefdf5e24bae73cef028844b513f4883066bf7", "file_path": "blink/sessions.py", "project_url": "https://github.com/kogmbh/blink-qt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -189,7 +189,7 @@ class SessionWidget(base_class, ui_class):\n         self.mute_button.hide()\n         self.address_label.setText(session.name or session.uri)\n         self.stream_info_label.session_type = session.type\n-        self.stream_info_label.session_type = session.codec_info\n+        self.stream_info_label.codec_info = session.codec_info\n         self.latency_label.value = session.latency\n         self.packet_loss_label.value = session.packet_loss\n         self.tls_label.setVisible(bool(session.tls))\n", "before": "self . stream_info_label . session_type = session . codec_info", "after": "self . stream_info_label . codec_info = session . codec_info", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:session_type\", 3, 32, 3, 44], \"codec_info\"]]"}
{"project": "blink-qt", "commit_sha": "244d09bd75aca01283d25aea36b7b7e494d05c2d", "parent_sha": "a6c0a0c522edd7d21d51c11fb3ee1cd3218b8a33", "file_path": "blink/mainwindow.py", "project_url": "https://github.com/kogmbh/blink-qt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -649,7 +649,7 @@ class MainWindow(base_class, ui_class):\n     def _NH_SIPAccountManagerDidRemoveAccount(self, notification):\n         account = notification.data.account\n         action = (action for action in self.accounts_menu.actions() if action.data().toPyObject() is account).next()\n-        self.account_menu.removeAction(action)\n+        self.accounts_menu.removeAction(action)\n         if isinstance(account, Account) and account.enabled and account.message_summary.enabled:\n             action = (action for action in self.voicemail_menu.actions() if action.data().toPyObject()[0] is account).next()\n             self.voicemail_menu.removeAction(action)\n", "before": "self . account_menu . removeAction ( action )", "after": "self . accounts_menu . removeAction ( action )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:account_menu\", 3, 14, 3, 26], \"accounts_menu\"]]"}
{"project": "stoq", "commit_sha": "677d7b41df44ae69b4c8da945a9c4f619052a621", "parent_sha": "970d65dadd0a0e9b8045f0dfced21cac852b5c83", "file_path": "stoq/gui/purchase/purchase.py", "project_url": "https://github.com/bellini666/stoq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -183,7 +183,7 @@ class PurchaseApp(SearchableAppWindow):\n             msg += _(u\"Warning: there are %d order(s) with \"\n                      \"status different than pending that \"\n                      \"will not be included\") % invalid_qty\n-        if yesno(msg, gtk.RESPONSE_YES, _(u\"Cancel\"), _(u\"Confirm\")):\n+        if yesno(msg, gtk.RESPONSE_NO, _(u\"Cancel\"), _(u\"Confirm\")):\n             return\n         for item in valid_orders:\n             order = PurchaseOrder.get(item.id, connection=self.conn)\n", "before": "if yesno ( msg , gtk . RESPONSE_YES , _ ( u\"Cancel\" ) , _ ( u\"Confirm\" ) ) : return", "after": "if yesno ( msg , gtk . RESPONSE_NO , _ ( u\"Cancel\" ) , _ ( u\"Confirm\" ) ) : return", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:RESPONSE_YES\", 3, 27, 3, 39], \"RESPONSE_NO\"]]"}
{"project": "PyMonopoly", "commit_sha": "73423fd428faff9d01a3cbbe8e16637ca5555ab0", "parent_sha": "acdba15e19ab5e3a7f5f54f10ac2a38bc3ee67ac", "file_path": "LIB/modules/ScreenData.py", "project_url": "https://github.com/Kycko/PyMonopoly", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -532,7 +532,7 @@ class MainScreen():\n             objects_to_move = [self.pics['gamebackground'], self.objects['gamefield'], self.objects['game_log']]\n             if 'trade_summary' in self.objects.keys():\n                 objects_to_move += [self.objects['trade_summary']]\n-            objects_to_move += [cell for cell in self.menuitems.values() if cell.type == 'onboard_select_cell']\n+            objects_to_move += [cell for cell in self.menuitems.values() if cell.group == 'onboard_select_cell']\n             objects_to_move += [cell.step_indicator for cell in self.objects['gamefield'].cells]\n             objects_to_move += [self.menuitems[key] for key in ('exit', 'show_menu', 'volume_level', 'music', 'sounds')]\n             objects_to_move += [self.labels[key] for key in ('volume_level', 'music', 'sounds')]\n", "before": "objects_to_move += [ cell for cell in self . menuitems . values ( ) if cell . type == 'onboard_select_cell' ]", "after": "objects_to_move += [ cell for cell in self . menuitems . values ( ) if cell . group == 'onboard_select_cell' ]", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:type\", 3, 82, 3, 86], \"group\"]]"}
{"project": "mdtraj", "commit_sha": "e76f5b873c22f5605fd152e613f454329883fd9d", "parent_sha": "24e0196905932e72c7b4299b0c5f5c0c6ef92aca", "file_path": "setup.py", "project_url": "https://github.com/Eigenstate/mdtraj", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -216,7 +216,7 @@ class CompilerDetection(object):\n     def _print_compiler_version(self, cc):\n         print(\"C compiler:\")\n         if self.msvc:\n-            cc.spawn(cc.compiler)\n+            cc.spawn(cc.cc)\n         else:\n             cc.spawn(cc.compiler + ['-v'])\n \n", "before": "cc . spawn ( cc . compiler )", "after": "cc . spawn ( cc . cc )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:compiler\", 3, 25, 3, 33], \"cc\"]]"}
{"project": "tekka", "commit_sha": "33d10bec9f8597e7f480fb7ce94371d2542b3fb4", "parent_sha": "c5bc2df3fe88ea98f3cde91fff8f6493cdd77b7a", "file_path": "tekka/lib/output_window.py", "project_url": "https://github.com/sushi-irc/tekka", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ class OutputWindow(gtk.ScrolledWindow):\n \t\tgtk.ScrolledWindow.__init__(self)\n \n \t\tself.set_properties(\n-\t\t\thscrollbar_policy = gtk.POLICY_NEVER,\n+\t\t\thscrollbar_policy = gtk.POLICY_AUTOMATIC,\n \t\t\tvscrollbar_policy = gtk.POLICY_AUTOMATIC,\n \t\t\t\t  shadow_type = gtk.SHADOW_ETCHED_IN )\n \n", "before": "self . set_properties ( hscrollbar_policy = gtk . POLICY_NEVER , vscrollbar_policy = gtk . POLICY_AUTOMATIC , shadow_type = gtk . SHADOW_ETCHED_IN )", "after": "self . set_properties ( hscrollbar_policy = gtk . POLICY_AUTOMATIC , vscrollbar_policy = gtk . POLICY_AUTOMATIC , shadow_type = gtk . SHADOW_ETCHED_IN )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:POLICY_NEVER\", 3, 28, 3, 40], \"POLICY_AUTOMATIC\"]]"}
{"project": "tribler", "commit_sha": "3f3cb933686ecc0023b0c8cc887f1587caead55b", "parent_sha": "0160eff481e08feaad0c4f1ebb46d311c470bfb2", "file_path": "Tribler/Core/dispersy/trigger.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -157,7 +157,7 @@ class TriggerPacket(Trigger):\n                 assert isinstance(packet[1], str)\n         if pattern == self._pattern:\n             self._packets.extend(packets)\n-            if __debug__: dprint(\"extend existing trigger with \", len(packets), \" packets (now has \", len(self.packets), \" packets)\")\n+            if __debug__: dprint(\"extend existing trigger with \", len(packets), \" packets (now has \", len(self._packets), \" packets)\")\n             return True\n         else:\n             return False\n", "before": "dprint ( \"extend existing trigger with \" , len ( packets ) , \" packets (now has \" , len ( self . packets ) , \" packets)\" )", "after": "dprint ( \"extend existing trigger with \" , len ( packets ) , \" packets (now has \" , len ( self . _packets ) , \" packets)\" )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:packets\", 3, 112, 3, 119], \"_packets\"]]"}
{"project": "tribler", "commit_sha": "f108bb2ce677e456499d75912fb6e40b47bf19dc", "parent_sha": "515db622d45b1d733656c0e514bab481afe94321", "file_path": "Tribler/Community/channel/conversion.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -189,7 +189,7 @@ class ChannelConversion(BinaryConversion):\n                 \"modification-on-mid\":modification_on.authentication.member.mid,\n                 \"modification-on-global-time\":modification_on.distribution.global_time}\n         \n-        latest_modification = message.payload.latest_modification\n+        latest_modification = message.payload.latest_modification_packet\n         if latest_modification:\n             message = latest_modification.load_message()\n             dict[\"latest-modification-mid\"] = message.authentication.member.mid\n", "before": "latest_modification = message . payload . latest_modification", "after": "latest_modification = message . payload . latest_modification_packet", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:latest_modification\", 3, 47, 3, 66], \"latest_modification_packet\"]]"}
{"project": "SleekXMPP", "commit_sha": "7ba6d5e02daced34960a11506b4600ba096a9570", "parent_sha": "ea48bb5ac58aa186c18c42c83e21a6a636bd22a9", "file_path": "sleekxmpp/clientxmpp.py", "project_url": "https://github.com/mayflower/SleekXMPP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -384,7 +384,7 @@ class ClientXMPP(BaseXMPP):\n         self.set_jid(response.xml.find('{%s}bind/{%s}jid' % (bind_ns,\n                                                              bind_ns)).text)\n         self.bound = True\n-        log.info(\"Node set to: %s\" % self.boundjid.fulljid)\n+        log.info(\"Node set to: %s\" % self.boundjid.full)\n         session_ns = 'urn:ietf:params:xml:ns:xmpp-session'\n         if \"{%s}session\" % session_ns not in self.features or self.bindfail:\n             log.debug(\"Established Session\")\n", "before": "log . info ( \"Node set to: %s\" % self . boundjid . fulljid )", "after": "log . info ( \"Node set to: %s\" % self . boundjid . full )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:fulljid\", 3, 52, 3, 59], \"full\"]]"}
{"project": "tribler", "commit_sha": "4c66d7c95c9fb758d30b5a68c3e2256bd3a8c3a3", "parent_sha": "028067e3da3399b26da6a7add9fda3d101a44933", "file_path": "Tribler/community/channel/community.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -328,7 +328,7 @@ class ChannelCommunity(Community):\n                     channel_data = {u'channel': self,\n                                     u'name': message.payload.name,\n                                     u'description': message.payload.description}\n-                    self.tribler_session.uch.notify(SIGNAL_CHANNEL, SIGNAL_ON_CREATED, None, channel_data)\n+                    self.tribler_session.notifier.notify(SIGNAL_CHANNEL, SIGNAL_ON_CREATED, None, channel_data)\n         else:\n             for message in messages:\n                 self._channel_id = self._master_member.mid\n", "before": "self . tribler_session . uch . notify ( SIGNAL_CHANNEL , SIGNAL_ON_CREATED , None , channel_data )", "after": "self . tribler_session . notifier . notify ( SIGNAL_CHANNEL , SIGNAL_ON_CREATED , None , channel_data )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:uch\", 3, 42, 3, 45], \"notifier\"]]"}
{"project": "pylinac", "commit_sha": "26b7ea7b20e0fd9784597f604cc373eca243e81e", "parent_sha": "5bb5ed700f67ecc05b1492fdcbeef84d01309470", "file_path": "pylinac/picketfence.py", "project_url": "https://github.com/midamo/pylinac", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -348,7 +348,7 @@ class Overlay:\n             if self.settings.orientation == orientations['UD']:\n                 r = Rectangle(self.image.shape[1], rect_width, center=(self.image.center.x, mlc.center.y))\n             else:\n-                r = Rectangle(rect_width, self.image.shape[0], center=(mlc.center.y, self.image.center.y))\n+                r = Rectangle(rect_width, self.image.shape[0], center=(mlc.center.x, self.image.center.y))\n             r.add_to_axes(axes.axes, edgecolor='none', fill=True, alpha=0.1, facecolor=color)\n \n \n", "before": "r = Rectangle ( rect_width , self . image . shape [ 0 ] , center = ( mlc . center . y , self . image . center . y ) )", "after": "r = Rectangle ( rect_width , self . image . shape [ 0 ] , center = ( mlc . center . x , self . image . center . y ) )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:y\", 3, 83, 3, 84], \"x\"]]"}
{"project": "hyperdock", "commit_sha": "1e3c9318b803662657ef32c6f505c4aa4a08733c", "parent_sha": "f6a180678f433f85ff9c20108a9c6886cb2a8d4e", "file_path": "hyperdock/common/utils.py", "project_url": "https://github.com/ErikGartner/hyperdock", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -20,7 +20,7 @@ def try_key(dictionary, default, *keys):\n         return default\n \n \n-def setup_logging(level=logging.DEBUG):\n+def setup_logging(level=logging.INFO):\n     \"\"\"\n     Setups the format string and config for the Python logging module.\n     \"\"\"\n", "before": "def setup_logging ( level = logging . DEBUG ) : \"\"\"\n     Setups the format string and config for the Python logging module.\n     \"\"\"", "after": "def setup_logging ( level = logging . INFO ) : \"\"\"\n     Setups the format string and config for the Python logging module.\n     \"\"\"", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:DEBUG\", 3, 33, 3, 38], \"INFO\"]]"}
{"project": "ptt-web-crawler", "commit_sha": "701ea651bb1c7c3cd5c761909f08ba841f5d3a6a", "parent_sha": "61b704e8e08110d85ab9477dc32b20a695761eb8", "file_path": "ptt_web_crawler/ptt_web_crawler/pipelines.py", "project_url": "https://github.com/afunTW/ptt-web-crawler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,7 +41,7 @@ class PttWebCrawlerPipeline(object):\n             end_date = datetime.strftime(end_date, '%Y%m%d')\n             runtime_file = begin_date + '_' + end_date + '.json'\n         elif spider.pages:\n-            begin_page, end_page = spider.crawl_index\n+            begin_page, end_page = spider.pages\n             runtime_file = '{}_page_{}_{}.json'.format(spider.board, begin_page, end_page)\n         else:\n             runtime_file = datetime.now().strftime('%Y%m%d') + '.json'\n", "before": "elif spider . pages : begin_page , end_page = spider . crawl_index", "after": "elif spider . pages : begin_page , end_page = spider . pages", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:crawl_index\", 3, 43, 3, 54], \"pages\"]]"}
{"project": "cc-utils", "commit_sha": "bedb8703a1b8c2d848a1dcdb33c17445de95578b", "parent_sha": "bbcbf50142fc213988d10fcf071b9dc1b04cf2b0", "file_path": "protecode/util.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ def upload_grouped_images(\n     parallel_jobs=8,\n     cve_threshold=7,\n     ignore_if_triaged=True,\n-    processing_mode=ProcessingMode.UPLOAD_IF_CHANGED,\n+    processing_mode=ProcessingMode.RESCAN,\n     image_reference_filter=(lambda component, container_image: True),\n     reference_group_ids=(),\n ):\n", "before": "processing_mode = ProcessingMode . UPLOAD_IF_CHANGED ,", "after": "processing_mode = ProcessingMode . RESCAN ,", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:UPLOAD_IF_CHANGED\", 3, 36, 3, 53], \"RESCAN\"]]"}
{"project": "cc-utils", "commit_sha": "360bf7a79af6e261c76219af3e853d55d73eb973", "parent_sha": "61da7d42b2552584b2f5c723aa5525ef6a77b9c9", "file_path": "protecode/client.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -130,7 +130,7 @@ class ProtecodeApi(object):\n \n     @check_http_code\n     def _patch(self, *args, **kwargs):\n-        return self._request(requests.put, *args, **kwargs)\n+        return self._request(requests.patch, *args, **kwargs)\n \n     def upload(self, application_name, group_id, data, custom_attribs={}) -> AnalysisResult:\n         url = self._routes.upload(file_name=application_name)\n", "before": "return self . _request ( requests . put , * args , ** kwargs )", "after": "return self . _request ( requests . patch , * args , ** kwargs )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:put\", 3, 39, 3, 42], \"patch\"]]"}
{"project": "cc-utils", "commit_sha": "32c32924a5fcbfaad362ca02620fe7033cb7b508", "parent_sha": "6ac5c0629c92bf914017cffc0bedc435f5ab73ff", "file_path": "ctx.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -167,7 +167,7 @@ def configure_default_logging():\n             'console': {\n                 'class': 'logging.StreamHandler',\n                 'formatter': 'default',\n-                'level': logging.DEBUG,\n+                'level': logging.INFO,\n                 'stream': 'ext://sys.stdout',\n             },\n         },\n", "before": "{ 'class' : 'logging.StreamHandler' , 'formatter' : 'default' , 'level' : logging . DEBUG , 'stream' : 'ext://sys.stdout' , } ,", "after": "{ 'class' : 'logging.StreamHandler' , 'formatter' : 'default' , 'level' : logging . INFO , 'stream' : 'ext://sys.stdout' , } ,", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:DEBUG\", 3, 34, 3, 39], \"INFO\"]]"}
{"project": "cc-utils", "commit_sha": "d3731140d3fbcba0ade9091f242c81a335132f32", "parent_sha": "0f5fd00af32d3692f0cd49e02bb6d991855bb345", "file_path": "concourse/steps/scan_container_images.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -51,7 +51,7 @@ class MailRecipients(object):\n             return self._recipients\n         raise NotImplementedError()\n \n-    def add_protecode_results(self, results: typing.Iterable[typing.tuple[UploadResult, int]]):\n+    def add_protecode_results(self, results: typing.Iterable[typing.Tuple[UploadResult, int]]):\n         for result in results:\n             if not self._result_filter(component=result[0].component):\n                 continue\n", "before": "def add_protecode_results ( self , results : typing . Iterable [ typing . tuple [ UploadResult , int ] ] ) : for result in results : if not self . _result_filter ( component = result [ 0 ] . component ) : continue", "after": "def add_protecode_results ( self , results : typing . Iterable [ typing . Tuple [ UploadResult , int ] ] ) : for result in results : if not self . _result_filter ( component = result [ 0 ] . component ) : continue", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:tuple\", 3, 69, 3, 74], \"Tuple\"]]"}
{"project": "cc-utils", "commit_sha": "3c277fd6856233d646bc40bef198c04e0cdf4239", "parent_sha": "c5b490d66bcfe3a6ef34627513f621d400601297", "file_path": "ccc/github.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -259,7 +259,7 @@ def _get_single_repo(component: cm.Component):\n     if source.type is not cm.SourceType.GIT:\n         raise NotImplementedError\n \n-    if source.access.type is not cm.AcessType.GITHUB:\n+    if source.access.type is not cm.AccessType.GITHUB:\n         raise NotImplementedError\n \n     return source\n", "before": "if source . access . type is not cm . AcessType . GITHUB : raise NotImplementedError", "after": "if source . access . type is not cm . AccessType . GITHUB : raise NotImplementedError", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:AcessType\", 3, 37, 3, 46], \"AccessType\"]]"}
{"project": "cc-utils", "commit_sha": "51cf58799de6f2ed34070c69eb76fcecca2b1260", "parent_sha": "20a3d5866d89ffd92c42c08c75e54c7ad9bd19a8", "file_path": "http_requests.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ def mount_default_adapter(\n     connection_pool_cache_size=32, # requests-library default\n     max_pool_size=32, # requests-library default\n     flags=AdapterFlag.CACHE|AdapterFlag.RETRY,\n-    retryable_methods_whitelist=Retry.DEFAULT_METHOD_WHITELIST,\n+    retryable_methods_whitelist=Retry.DEFAULT_ALLOWED_METHODS,\n ):\n     if AdapterFlag.CACHE in flags:\n         adapter_constructor = cachecontrol.CacheControlAdapter\n", "before": "retryable_methods_whitelist = Retry . DEFAULT_METHOD_WHITELIST ,", "after": "retryable_methods_whitelist = Retry . DEFAULT_ALLOWED_METHODS ,", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:DEFAULT_METHOD_WHITELIST\", 3, 39, 3, 63], \"DEFAULT_ALLOWED_METHODS\"]]"}
{"project": "cc-utils", "commit_sha": "1683fd71ceae6d5cbf41d4f79080bc66b429ec7c", "parent_sha": "05d91312f02dc586b1c8ae6c1859cfe46b7a150b", "file_path": "cli/gardener_ci/productutil.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -46,7 +46,7 @@ def upload_product_images(\n     processing_mode: CliHint(\n         choices=list(ProcessingMode),\n         type=ProcessingMode,\n-    )=ProcessingMode.UPLOAD_IF_CHANGED,\n+    )=ProcessingMode.RESCAN,\n     protecode_group_id: int=5,\n     parallel_jobs: int=4,\n     cve_threshold: int=7,\n", "before": "processing_mode : CliHint ( choices = list ( ProcessingMode ) , type = ProcessingMode , ) = ProcessingMode . UPLOAD_IF_CHANGED , protecode_group_id : int = 5 ,", "after": "processing_mode : CliHint ( choices = list ( ProcessingMode ) , type = ProcessingMode , ) = ProcessingMode . RESCAN , protecode_group_id : int = 5 ,", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:UPLOAD_IF_CHANGED\", 3, 22, 3, 39], \"RESCAN\"]]"}
{"project": "cc-utils", "commit_sha": "b5d43c2ed0a9138f0a18f82ce42ca877ec5ef789", "parent_sha": "b24585fa5080400766eb9d6bf54550595ecc2435", "file_path": "product/scanning.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -142,7 +142,7 @@ class ProtecodeUtil(object):\n     def __init__(\n             self,\n             protecode_api: ProtecodeApi,\n-            processing_mode: ProcessingMode=ProcessingMode.UPLOAD_IF_CHANGED,\n+            processing_mode: ProcessingMode=ProcessingMode.RESCAN,\n             group_id: int=None,\n             reference_group_ids=(),\n     ):\n", "before": "def __init__ ( self , protecode_api : ProtecodeApi , processing_mode : ProcessingMode = ProcessingMode . UPLOAD_IF_CHANGED , group_id : int = None , reference_group_ids = ( ) , ) : ", "after": "def __init__ ( self , protecode_api : ProtecodeApi , processing_mode : ProcessingMode = ProcessingMode . RESCAN , group_id : int = None , reference_group_ids = ( ) , ) : ", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:UPLOAD_IF_CHANGED\", 3, 60, 3, 77], \"RESCAN\"]]"}
{"project": "cc-utils", "commit_sha": "73bf06e0229310c8cb96570c628eecd3557eb37c", "parent_sha": "11a92ce2601ab9449055085185decef8d9abef69", "file_path": "product/v2.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -113,7 +113,7 @@ def download_component_descriptor_v2(\n     ctx_repo_base_url: str,\n     absent_ok: bool=False,\n     cache_dir: str=None,\n-    validation_mode: cm.ValidationMode=cm.ValidationMode.WARN,\n+    validation_mode: cm.ValidationMode=cm.ValidationMode.NONE,\n ):\n     target_ref = _target_oci_ref_from_ctx_base_url(\n         component_name=component_name,\n", "before": "validation_mode : cm . ValidationMode = cm . ValidationMode . WARN ,", "after": "validation_mode : cm . ValidationMode = cm . ValidationMode . NONE ,", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:WARN\", 3, 58, 3, 62], \"NONE\"]]"}
{"project": "cc-utils", "commit_sha": "d5edc0c02d69df3f63c34cd1eeb4e1646a8fe01d", "parent_sha": "ece167ed44477a6e31c655fd216f77afa4c9ab5d", "file_path": "model/concourse.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -109,7 +109,7 @@ class ConcourseConfig(NamedModelElement):\n         try:\n             response = session.get(concourse_url)\n             response.raise_for_status()\n-        except requests.exceptions.HTTPError:\n+        except requests.exceptions.RequestException:\n             ci.util.warning(f'Could not determine version of Concourse running at {concourse_url}')\n             return None\n \n", "before": "try : response = session . get ( concourse_url ) response . raise_for_status ( ) except requests . exceptions . HTTPError : ci . util . warning ( f'Could not determine version of Concourse running at {concourse_url}' ) return None", "after": "try : response = session . get ( concourse_url ) response . raise_for_status ( ) except requests . exceptions . RequestException : ci . util . warning ( f'Could not determine version of Concourse running at {concourse_url}' ) return None", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:HTTPError\", 3, 36, 3, 45], \"RequestException\"]]"}
{"project": "cc-utils", "commit_sha": "01cefb112425c3eac712954813556ba7528e6230", "parent_sha": "9f18fd2c9b1b42cd7a0fe1a5935267a6302d8dc1", "file_path": "cli/gardener_ci/productutil_v2.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,7 +34,7 @@ def _raw_image_dep_to_v2(raw: dict):\n   name = raw['name']\n   version = raw['version']\n   img_ref = raw['image_reference']\n-  img_rel = cm.ResourceRelation(raw.get('relation', cm.ResourceRelation.LOCAL))\n+  img_rel = cm.ResourceRelation(raw.get('relation', cm.ResourceRelation.EXTERNAL))\n \n   return cm.Resource(\n     name=name,\n", "before": "img_rel = cm . ResourceRelation ( raw . get ( 'relation' , cm . ResourceRelation . LOCAL ) )", "after": "img_rel = cm . ResourceRelation ( raw . get ( 'relation' , cm . ResourceRelation . EXTERNAL ) )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:LOCAL\", 3, 73, 3, 78], \"EXTERNAL\"]]"}
{"project": "WMAS", "commit_sha": "dfe2b1ce939ce7b80a64d079655cfa14451e9960", "parent_sha": "273e3f0f687ba234f0669e88a5ce339ab01429a8", "file_path": "webdriver/tests/delete_session/delete.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,5 +25,5 @@ def test_delete_session_with_dismissed_beforeunload_prompt(session):\n     assert_success(response)\n \n     # A beforeunload prompt has to be automatically dismissed, and the session deleted\n-    with pytest.raises(error.SessionNotCreatedException):\n+    with pytest.raises(error.InvalidSessionIdException):\n         session.alert.text\n", "before": "with pytest . raises ( error . SessionNotCreatedException ) : session . alert . text", "after": "with pytest . raises ( error . InvalidSessionIdException ) : session . alert . text", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:SessionNotCreatedException\", 3, 30, 3, 56], \"InvalidSessionIdException\"]]"}
{"project": "jabbercat", "commit_sha": "56cf823358a9142e3f95b986ed923ea2cf63cec4", "parent_sha": "033107f47c573e97dab1733e7dcd9332ca3d852e", "file_path": "jabbercat/main.py", "project_url": "https://github.com/jabbercat/jabbercat", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -546,7 +546,7 @@ class MainWindow(Qt.QMainWindow):\n         self._activate_conversation_page(page)\n \n     def _current_conversation_page_changed(self, new_index: int):\n-        page = self.ui.conversations_view.widget(new_index)\n+        page = self.ui.conversation_pages.widget(new_index)\n         if not page:\n             logger.warning(\"page changed to nonexistant widget: %d\",\n                            new_index)\n", "before": "page = self . ui . conversations_view . widget ( new_index )", "after": "page = self . ui . conversation_pages . widget ( new_index )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:conversations_view\", 3, 24, 3, 42], \"conversation_pages\"]]"}
{"project": "kaggle-carvana-2017", "commit_sha": "1a65f8a7b362a8b5b6e6e64016dcd423ce5040c0", "parent_sha": "64ad3793335fe84470537de173b737dec5b22d84", "file_path": "predict_multithreaded.py", "project_url": "https://github.com/killthekitten/kaggle-carvana-2017", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -50,7 +50,7 @@ def data_loader(q, ):\n             img = img_to_array(load_img(filename))\n             x_batch.append(img)\n \n-        x_batch = preprocess_input(np.array(x_batch, np.float32), mode=args.preprocess_input)\n+        x_batch = preprocess_input(np.array(x_batch, np.float32), mode=args.preprocessing_function)\n         padded_x = np.zeros((batch_size, 1280, 1920, 3))\n         padded_x[:, :, 1:-1, :] = x_batch\n         q.put((filenames_batch, padded_x))\n", "before": "x_batch = preprocess_input ( np . array ( x_batch , np . float32 ) , mode = args . preprocess_input )", "after": "x_batch = preprocess_input ( np . array ( x_batch , np . float32 ) , mode = args . preprocessing_function )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:preprocess_input\", 3, 77, 3, 93], \"preprocessing_function\"]]"}
{"project": "WMAS", "commit_sha": "82d91c54b37f4b2d36dd218bd0e6cc9c6426fd7d", "parent_sha": "7330eed66bbb4a4e62e931e7028cae6af88b796a", "file_path": "tools/webdriver/webdriver/transport.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -63,7 +63,7 @@ class HTTPWireProtocol(object):\n         self._timeout = timeout\n \n     def url(self, suffix):\n-        return urlparse.urljoin(self.path_prefix, suffix)\n+        return urlparse.urljoin(self.url_prefix, suffix)\n \n     def send(self, method, url, body=None, headers=None):\n", "before": "return urlparse . urljoin ( self . path_prefix , suffix )", "after": "return urlparse . urljoin ( self . url_prefix , suffix )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:path_prefix\", 3, 38, 3, 49], \"url_prefix\"]]"}
{"project": "WMAS", "commit_sha": "10d1ebb28c00cecf175d4c8f1ceae3bca7897285", "parent_sha": "44574b4c62b5d1606722924c63bf239dbd1c4842", "file_path": "wptrunner/executors/pytestrunner/fixtures.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -103,5 +103,5 @@ class Session(object):\n         if exclude is None:\n             exclude = []\n-        wins = [w for w in self.client.window_handles if w not in exclude]\n+        wins = [w for w in self.client.handles if w not in exclude]\n         return set(wins)\n", "before": "wins = [ w for w in self . client . window_handles if w not in exclude ]", "after": "wins = [ w for w in self . client . handles if w not in exclude ]", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:window_handles\", 2, 40, 2, 54], \"handles\"]]"}
{"project": "rllab-curriculum", "commit_sha": "a2262c1f16a1b7515710a6917048188709277940", "parent_sha": "0505a6c724b9d28f157f75ce3a807e4b5cdd48c6", "file_path": "sandbox/adam/parallel/batch_polopt.py", "project_url": "https://github.com/florensacc/rllab-curriculum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -218,7 +218,7 @@ class ParallelBatchPolopt(RLAlgorithm):\n             #     np.concatenate(dgnstc_data[\"returns\"])\n             # )\n \n-            mgr_objs.barrer_dgnstc.wait()\n+            mgr_objs.barrier_dgnstc.wait()\n \n             if par_data.rank == 0:\n                 num_traj = sum(shareds.num_traj)\n", "before": "mgr_objs . barrer_dgnstc . wait ( )", "after": "mgr_objs . barrier_dgnstc . wait ( )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:barrer_dgnstc\", 3, 22, 3, 35], \"barrier_dgnstc\"]]"}
{"project": "tweet_scrapper", "commit_sha": "a0c52eddafce4797814e22009e8ad7dde90597af", "parent_sha": "82b02e73b7b44495d069a3b1d65e518bd535226e", "file_path": "tweetscrape/search_tweets.py", "project_url": "https://github.com/5hirish/tweet_scrapper", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -97,7 +97,7 @@ class TweetScrapperSearch(TweetScrapper):\n         logger.info(\"Search:|{0}|\".format(search_query))\n \n         if latest_tweets:\n-            self.__twitter_request_params__['f'] = 'tweets'\n+            self.__twitter_search_init_params__['f'] = 'tweets'\n         self.__twitter_search_init_params__['q'] = search_query\n \n         self.update_request_url(self.__twitter_search_init_url__)\n", "before": "self . __twitter_request_params__ [ 'f' ] = 'tweets'", "after": "self . __twitter_search_init_params__ [ 'f' ] = 'tweets'", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:__twitter_request_params__\", 3, 18, 3, 44], \"__twitter_search_init_params__\"]]"}
{"project": "mybuild", "commit_sha": "f30ff806a1242c5b5ce64441893f4618676f9b2f", "parent_sha": "111a5d86b570a4c1602a5a84a945194c73e76302", "file_path": "nsloader/yamlfile.py", "project_url": "https://github.com/abusalimov/mybuild", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ class YamlFileLoader(SourceFileLoader):\n \n         except IOError:\n             raise ImportError(\"IO error while reading a stream\")\n-        except yaml.YamlError as e:\n+        except yaml.YAMLError as e:\n             raise e  # XXX convert into SyntaxError\n \n         else:\n", "before": "except yaml . YamlError as e : raise e", "after": "except yaml . YAMLError as e : raise e", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:YamlError\", 3, 21, 3, 30], \"YAMLError\"]]"}
{"project": "pyMaid", "commit_sha": "80ba3150d70f0bb2a7b100e2b286ca262f68ccf0", "parent_sha": "3c859fe7e711d0f3f9e0786eb0272c093635eba0", "file_path": "pymaid/core.py", "project_url": "https://github.com/schlegelp/pyMaid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -501,7 +501,7 @@ class CatmaidNeuron(navis.TreeNeuron):\n         self._nodes = skeleton.nodes\n         self._connectors = skeleton.connectors\n         self._tags = skeleton.tags\n-        self._neuron_name = skeleton.neuron_name\n+        self._name = skeleton.neuron_name\n         self.date_retrieved = datetime.datetime.now().isoformat()\n \n         # Delete outdated attributes\n", "before": "self . _neuron_name = skeleton . neuron_name", "after": "self . _name = skeleton . neuron_name", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:_neuron_name\", 3, 14, 3, 26], \"_name\"]]"}
{"project": "pyMaid", "commit_sha": "0de1579f0dcd0ec7e28a54e9050d811c5599df6e", "parent_sha": "0441a61d859f80daf6544ee4c84a17f06bd151a0", "file_path": "pymaid/b3d.py", "project_url": "https://github.com/schlegelp/pyMaid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -226,7 +226,7 @@ class handler:\n         cu.bevel_resolution = 5\n         cu.bevel_depth = 0.007\n \n-        for s in x.slabs:\n+        for s in x.segments:\n             newSpline = cu.splines.new('POLY')\n             coords = x.nodes.set_index('treenode_id').ix[s][\n                 ['x', 'y', 'z']].as_matrix()\n", "before": "for s in x . slabs : newSpline = cu . splines . new ( 'POLY' ) coords = x . nodes . set_index ( 'treenode_id' ) . ix [ s ] [ [ 'x' , 'y' , 'z' ] ] . as_matrix ( )", "after": "for s in x . segments : newSpline = cu . splines . new ( 'POLY' ) coords = x . nodes . set_index ( 'treenode_id' ) . ix [ s ] [ [ 'x' , 'y' , 'z' ] ] . as_matrix ( )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:slabs\", 3, 20, 3, 25], \"segments\"]]"}
{"project": "pyMaid", "commit_sha": "646421af08fc7977dd9ac5fc1fe23e59f55e11e7", "parent_sha": "37cfc584da63101b4d4463408ea498874b406ad5", "file_path": "pymaid/tests/test_pymaid.py", "project_url": "https://github.com/schlegelp/pyMaid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -988,7 +988,7 @@ class TestUserStats(unittest.TestCase):\n     def test_team_contributions(self):\n         ds = self.n.downsample(20, inplace=False)\n         ul = pymaid.get_user_list().set_index('id')\n-        teams = {'test_team' : [ul.loc[u, 'login'] for u in ds.nodes.creator.unique()]}\n+        teams = {'test_team' : [ul.loc[u, 'login'] for u in ds.nodes.creator_id.unique()]}\n         self.assertIsInstance(pymaid.get_team_contributions(teams,\n                                                             neurons=ds,\n                                                             remote_instance=self.rm),\n", "before": "teams = { 'test_team' : [ ul . loc [ u , 'login' ] for u in ds . nodes . creator . unique ( ) ] }", "after": "teams = { 'test_team' : [ ul . loc [ u , 'login' ] for u in ds . nodes . creator_id . unique ( ) ] }", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:creator\", 3, 70, 3, 77], \"creator_id\"]]"}
{"project": "pyMaid", "commit_sha": "8cd107b6dd6f84fbdcfeeac7e2ad430d38aa19e1", "parent_sha": "acfe2e7e17dee7b0ef788606e000ff3842b957b1", "file_path": "pymaid/plotting.py", "project_url": "https://github.com/schlegelp/pyMaid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1844,7 +1844,7 @@ def plot1d(x, ax=None, color=None, **kwargs):\n         # Order this neuron's segments by topology\n         breaks = [topology[0]] + \\\n             [n for i, n in enumerate(topology) if n in bp or n in term]\n-        segs = [([s for s in n.segments if s[0] == end][0][-1], end)\n+        segs = [([s for s in n.small_segments if s[0] == end][0][-1], end)\n                 for end in breaks[1:]]\n \n         # Now get distances for each segment\n", "before": "segs = [ ( [ s for s in n . segments if s [ 0 ] == end ] [ 0 ] [ - 1 ] , end ) for end in breaks [ 1 : ] ]", "after": "segs = [ ( [ s for s in n . small_segments if s [ 0 ] == end ] [ 0 ] [ - 1 ] , end ) for end in breaks [ 1 : ] ]", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:segments\", 3, 32, 3, 40], \"small_segments\"]]"}
{"project": "pylint", "commit_sha": "29445fb9c72847be677b819475bfb7a3a950cbee", "parent_sha": "08fdeb80dcdf4c38b3cf012b6b9dd746fde46dac", "file_path": "checkers/base.py", "project_url": "https://github.com/wubob/pylint", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -974,7 +974,7 @@ class NameChecker(_BasicChecker):\n             if len(all_groups) < 2:\n                 continue\n             groups = collections.defaultdict(list)\n-            min_warnings = sys.maxint\n+            min_warnings = sys.maxsize\n             for group in six.itervalues(all_groups):\n                 groups[len(group)].append(group)\n                 min_warnings = min(len(group), min_warnings)\n", "before": "min_warnings = sys . maxint", "after": "min_warnings = sys . maxsize", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:maxint\", 3, 32, 3, 38], \"maxsize\"]]"}
{"project": "tensorflow-extenteten", "commit_sha": "9912974a283912acd31fa4ee85de2fb44c2cf862", "parent_sha": "e40d0b5ae27401acbb3db6b0e19f5ea5164be151", "file_path": "nn/model.py", "project_url": "https://github.com/raviqqe/tensorflow-extenteten", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ class Model(metaclass=abc.ABCMeta):\n     return NotImplemented\n \n   @abc.astractmethod\n-  def train(self, *input_tensors) -> tf.Tensor: # scalar loss\n+  def train(self, *input_tensors) -> tf.Operation: # training operation\n     return NotImplemented\n \n   @abc.astractmethod\n", "before": "def train ( self , * input_tensors ) -> tf . Tensor : return NotImplemented", "after": "def train ( self , * input_tensors ) -> tf . Operation : return NotImplemented", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:Tensor\", 3, 41, 3, 47], \"Operation\"]]"}
{"project": "flask-mongoengine", "commit_sha": "239a045a02d5bacfcb7de9c7e63beb4100e59057", "parent_sha": "ed27f468d05ef211b5309107277818551b24292a", "file_path": "flaskext/mongoengine/wtf/orm.py", "project_url": "https://github.com/anemitz/flask-mongoengine", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -155,7 +155,7 @@ class ModelConverter():\n             'validators': [],\n             'filters': [],\n         }\n-        form_class = model_form(field.document, field_args={})\n+        form_class = model_form(field.document_type_obj, field_args={})\n         return f.FormField(form_class, **kwargs)\n \n     @converts('ReferenceField')\n", "before": "form_class = model_form ( field . document , field_args = { } )", "after": "form_class = model_form ( field . document_type_obj , field_args = { } )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:document\", 3, 39, 3, 47], \"document_type_obj\"]]"}
{"project": "angr", "commit_sha": "308a2e46c6785ad6e76c218ad06f910e3e5e182b", "parent_sha": "3ff63951ed2f08698ba51c0627e614351e929f2e", "file_path": "angr/analyses/cdg.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -36,7 +36,7 @@ class CDG(Analysis):\n         # Debugging purpose\n         if hasattr(self._cfg, \"get_irsb\"):\n             # FIXME: We should not use get_any_irsb in such a real setting...\n-            self._entry = self._cfg.get_any_irsb(self._binary.entry)\n+            self._entry = self._cfg.get_any_irsb(self._p.entry)\n \n         self.construct()\n \n", "before": "self . _entry = self . _cfg . get_any_irsb ( self . _binary . entry )", "after": "self . _entry = self . _cfg . get_any_irsb ( self . _p . entry )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:_binary\", 3, 55, 3, 62], \"_p\"]]"}
{"project": "angr", "commit_sha": "9568e0ee8de486aa6f1b55f1b45a767c915833f1", "parent_sha": "396724d1e186d64dba6de9f3e6d6e8dede51e265", "file_path": "simuvex/s_irstmt.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -117,7 +117,7 @@ class SimIRStmt(object):\n             data_ao = SimActionObject(data.expr, reg_deps=data.reg_deps(), tmp_deps=data.tmp_deps())\n             addr_ao = SimActionObject(addr.expr, reg_deps=addr.reg_deps(), tmp_deps=addr.tmp_deps())\n             size_ao = SimActionObject(data.size_bits())\n-            r = SimActionData(self.state, SimActionData.TMP, SimActionData.WRITE, data=data_ao, size=size_ao, addr=addr_ao)\n+            r = SimActionData(self.state, SimActionData.MEM, SimActionData.WRITE, data=data_ao, size=size_ao, addr=addr_ao)\n             self.actions.append(r)\n \n     def _handle_Exit(self, stmt):\n", "before": "r = SimActionData ( self . state , SimActionData . TMP , SimActionData . WRITE , data = data_ao , size = size_ao , addr = addr_ao )", "after": "r = SimActionData ( self . state , SimActionData . MEM , SimActionData . WRITE , data = data_ao , size = size_ao , addr = addr_ao )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:TMP\", 3, 57, 3, 60], \"MEM\"]]"}
{"project": "angr", "commit_sha": "7ba675f32907d8a9e42d7758c13f3054768c7530", "parent_sha": "41b865073c66e6d1daf11835af71782436880a66", "file_path": "angr/artifacts/function.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -284,7 +284,7 @@ class Function(object):\n         return list(self._ret_sites)\n \n     def clear_transition_graph(self):\n-        self.blocks = { self._projects.factory.block(self._addr) }\n+        self.blocks = { self._project.factory.block(self._addr) }\n         self._transition_graph = networkx.DiGraph()\n         self._transition_graph.add_node(self._addr)\n         self._local_transition_graph = None\n", "before": "self . blocks = { self . _projects . factory . block ( self . _addr ) }", "after": "self . blocks = { self . _project . factory . block ( self . _addr ) }", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:_projects\", 3, 30, 3, 39], \"_project\"]]"}
{"project": "OWASP-Nettacker", "commit_sha": "d6503e15ca89ec1461d912f3c26f3447df9ab165", "parent_sha": "0d0f95acf27c4e1796bee5799213f714d5ae66a8", "file_path": "core/color.py", "project_url": "https://github.com/susantaroy2002/OWASP-Nettacker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -8,7 +8,7 @@ os_name = compatible.os_name()\n \n def finish():\n     if 'linux' in os_name or os_name == 'darwin':\n-        sys.std.write('\\033[0m')\n+        sys.stdout.write('\\033[0m')\n     else:\n         import ctypes\n         std_out_handle = ctypes.windll.kernel32.GetStdHandle(-11)\n", "before": "sys . std . write ( '\\033[0m' )", "after": "sys . stdout . write ( '\\033[0m' )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:std\", 3, 13, 3, 16], \"stdout\"]]"}
{"project": "ottertune", "commit_sha": "50c2d4dcb2ae5b9a015a4b54a9e42174589b7b2b", "parent_sha": "92a219eae91733db03bc3583e721be8f97dca00f", "file_path": "server/analysis/cluster.py", "project_url": "https://github.com/master-MR-han/ottertune", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -500,7 +500,8 @@ class DetK(KSelection):\n                     else a(k - 1, Nd) + (1 - a(k - 1, Nd)) / 6\n             Sks[i] = sum([np.linalg.norm(model.cluster_centers_[j] - c) ** 2\n                           for j in range(K)\n-                          for c in X[model.sample_labels_ == j]])\n+                          for c in X[model.cluster_labels_ == j]])\n+                          #for c in X[model.sample_labels_ == j]])\n             if K == 1:\n                 Fs[i] = 1\n             elif Sks[i - 1] == 0:\n", "before": "Sks [ i ] = sum ( [ np . linalg . norm ( model . cluster_centers_ [ j ] - c ) ** 2 for j in range ( K ) for c in X [ model . sample_labels_ == j ] ] )", "after": "Sks [ i ] = sum ( [ np . linalg . norm ( model . cluster_centers_ [ j ] - c ) ** 2 for j in range ( K ) for c in X [ model . cluster_labels_ == j ] ] )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:sample_labels_\", 3, 44, 3, 58], \"cluster_labels_\"]]"}
{"project": "litex-buildenv", "commit_sha": "d73027ffeff4ce66c84d51fe5b92ea6648b126f5", "parent_sha": "dd7a139ff411ed7442b93a8ebd271602b4aee34b", "file_path": "targets/opsis_base.py", "project_url": "https://github.com/jimmo/litex-buildenv", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -116,7 +116,7 @@ class _CRG(Module):\n         self.specials += AsyncResetSynchronizer(self.cd_base50, self.cd_sys.rst | ~dcm_base50_locked)\n         platform.add_period_constraint(self.cd_base50.clk, 20)\n \n-        self.comb += self.cd_encoder.clk.eq(self.cd_encoder.clk)\n+        self.comb += self.cd_encoder.clk.eq(self.cd_sys.clk)\n         self.specials += AsyncResetSynchronizer(self.cd_encoder, self.cd_sys.rst)\n \n \n", "before": "self . comb += self . cd_encoder . clk . eq ( self . cd_encoder . clk )", "after": "self . comb += self . cd_encoder . clk . eq ( self . cd_sys . clk )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:cd_encoder\", 3, 50, 3, 60], \"cd_sys\"]]"}
{"project": "msglite", "commit_sha": "24da1853b7901bda107783a4c9c5a7f2be09dadc", "parent_sha": "9f5f098f2f6e82b58bff12b6220a0138edc8982f", "file_path": "extract_msg/validation.py", "project_url": "https://github.com/alephdata/msglite", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ def get_email_details(instance, stream):\n \n def string_FE(instance):\n     temp = '001E'\n-    if instance.manProperties.has_key('340D0003'):\n+    if instance.mainProperties.has_key('340D0003'):\n         temp = '001F' if instance.mainProperties['340D0003'].value & 0x40000 else '001E'\n     tempnot = '001F' if temp == '001E' else '001E'\n     confirmation = all(not x[-1].endswith(tempnot) for x in instance.listDir())\n", "before": "if instance . manProperties . has_key ( '340D0003' ) : temp = '001F' if instance . mainProperties [ '340D0003' ] . value & 0x40000 else '001E'", "after": "if instance . mainProperties . has_key ( '340D0003' ) : temp = '001F' if instance . mainProperties [ '340D0003' ] . value & 0x40000 else '001E'", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:manProperties\", 3, 17, 3, 30], \"mainProperties\"]]"}
{"project": "OpenNMT-entmax", "commit_sha": "75529e02c47758466b9827ceba8c348814154b13", "parent_sha": "065875b6b9defd7a1e7a48d0626a20908420d2f5", "file_path": "onmt/translate/Translation.py", "project_url": "https://github.com/deep-spin/OpenNMT-entmax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -113,7 +113,7 @@ class Translation(object):\n \n         if len(self.pred_sents) > 1:\n             print('\\nBEST HYP:')\n-            for score, sent in zip(self.pred_score, self.pred_sents):\n+            for score, sent in zip(self.pred_scores, self.pred_sents):\n                 output += \"[{:.4f}] {}\\n\".format(score, sent)\n \n         return output\n", "before": "for score , sent in zip ( self . pred_score , self . pred_sents ) : output += \"[{:.4f}] {}\\n\" . format ( score , sent )", "after": "for score , sent in zip ( self . pred_scores , self . pred_sents ) : output += \"[{:.4f}] {}\\n\" . format ( score , sent )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:pred_score\", 3, 41, 3, 51], \"pred_scores\"]]"}
{"project": "OpenNMT-entmax", "commit_sha": "de25e9b0d690fe7554816cacb177016d4ba6612b", "parent_sha": "9649d28dd5c2ba66554a3d83f97d242cf284c871", "file_path": "train.py", "project_url": "https://github.com/deep-spin/OpenNMT-entmax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -118,7 +118,7 @@ def make_valid_data_iter(valid_dataset, opt):\n     return onmt.io.OrderedIterator(\n-                dataset=valid_dataset, batch_size=opt.batch_size,\n+                dataset=valid_dataset, batch_size=opt.max_generator_batches,\n                 device=opt.gpuid[0] if opt.gpuid else -1,\n                 train=False, sort=True)\n \n", "before": "return onmt . io . OrderedIterator ( dataset = valid_dataset , batch_size = opt . batch_size , device = opt . gpuid [ 0 ] if opt . gpuid else - 1 , train = False , sort = True )", "after": "return onmt . io . OrderedIterator ( dataset = valid_dataset , batch_size = opt . max_generator_batches , device = opt . gpuid [ 0 ] if opt . gpuid else - 1 , train = False , sort = True )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:batch_size\", 1, 55, 1, 65], \"max_generator_batches\"]]"}
{"project": "OpenNMT-entmax", "commit_sha": "f79f8041bf415979cd78ee264c14089467735faa", "parent_sha": "4d17982b812810b76c6d102bec2f1a761252405f", "file_path": "onmt/trainer.py", "project_url": "https://github.com/deep-spin/OpenNMT-entmax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -195,7 +195,7 @@ class Trainer(object):\n                                 logger.info('GpuRank %d: gather valid stat \\\n                                             step %d' % (self.gpu_rank, step))\n                             valid_stats = self._maybe_gather_stats(valid_stats)\n-                            if self.gpu_verbos_level > 0:\n+                            if self.gpu_verbose_level > 0:\n                                 logger.info('GpuRank %d: report stat step %d'\n                                             % (self.gpu_rank, step))\n                             self._report_step(self.optim.learning_rate,\n", "before": "if self . gpu_verbos_level > 0 : logger . info ( 'GpuRank %d: report stat step %d' % ( self . gpu_rank , step ) )", "after": "if self . gpu_verbose_level > 0 : logger . info ( 'GpuRank %d: report stat step %d' % ( self . gpu_rank , step ) )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:gpu_verbos_level\", 3, 37, 3, 53], \"gpu_verbose_level\"]]"}
{"project": "OpenNMT-entmax", "commit_sha": "60ced2334fae2e8163abe2eeb70252b4df677ecf", "parent_sha": "d60f1e9796fe3915bb378eaf7f1ef89ac378fb2e", "file_path": "onmt/IO.py", "project_url": "https://github.com/deep-spin/OpenNMT-entmax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -305,7 +305,7 @@ class ONMTDataset(torchtext.data.Dataset):\n             return alignment\n \n         fields[\"src_map\"] = torchtext.data.Field(\n-            use_vocab=False, tensor_type=torch.FloatTensor,\n+            use_vocab=False, tensor_type=torch.LongTensor,\n             postprocessing=make_src, sequential=False)\n \n         def make_tgt(data, _):\n", "before": "fields [ \"src_map\" ] = torchtext . data . Field ( use_vocab = False , tensor_type = torch . FloatTensor , postprocessing = make_src , sequential = False )", "after": "fields [ \"src_map\" ] = torchtext . data . Field ( use_vocab = False , tensor_type = torch . LongTensor , postprocessing = make_src , sequential = False )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:FloatTensor\", 3, 48, 3, 59], \"LongTensor\"]]"}
{"project": "OpenNMT-entmax", "commit_sha": "a1e572558388bdf9523c888c25e2f767731e31e6", "parent_sha": "9f4b4d77caf553d317af9b7bba4e7a9634253bf0", "file_path": "onmt/ModelConstructor.py", "project_url": "https://github.com/deep-spin/OpenNMT-entmax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -67,7 +67,7 @@ def make_encoder(opt, embeddings):\n         return MeanEncoder(opt.enc_layers, embeddings)\n     else:\n         # \"rnn\" or \"brnn\"\n-        return RNNEncoder(opt.rnn_type, opt.brnn, opt.dec_layers,\n+        return RNNEncoder(opt.rnn_type, opt.brnn, opt.enc_layers,\n                           opt.rnn_size, opt.dropout, embeddings)\n \n \n", "before": "else : return RNNEncoder ( opt . rnn_type , opt . brnn , opt . dec_layers , opt . rnn_size , opt . dropout , embeddings )", "after": "else : return RNNEncoder ( opt . rnn_type , opt . brnn , opt . enc_layers , opt . rnn_size , opt . dropout , embeddings )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:dec_layers\", 3, 55, 3, 65], \"enc_layers\"]]"}
{"project": "openCEM", "commit_sha": "70794c76eb85d0d6257ca415f0112ffdf776d1da", "parent_sha": "4478d90d6c5253013ef4c861a281b5d3305f966b", "file_path": "cemo/multi.py", "project_url": "https://github.com/openCEMorg/openCEM", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -827,7 +827,7 @@ group by zones,all_tech;\" : [zones,all_tech] hyb_cap_initial;\n             # Carry forward operating capacity to next Inv period\n             opcap = json_carry_forward_cap(inst)\n             if y != self.Years[-1]:\n-                with open(self.tmpdir + 'gen_cap_op' + str(y) + '.json',\n+                with open(self.wrkdir + 'gen_cap_op' + str(y) + '.json',\n                           'w') as op:\n                     json.dump(opcap, op)\n             # Dump simulation result in JSON forma\n", "before": "with open ( self . tmpdir + 'gen_cap_op' + str ( y ) + '.json' , 'w' ) as op : json . dump ( opcap , op )", "after": "with open ( self . wrkdir + 'gen_cap_op' + str ( y ) + '.json' , 'w' ) as op : json . dump ( opcap , op )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:tmpdir\", 3, 32, 3, 38], \"wrkdir\"]]"}
{"project": "python_planet", "commit_sha": "2f2ab430c5af857c63c10e209acb5d8d449b6580", "parent_sha": "cd2219ff5cb85fd4fc390e7bbe914e81570ea6c5", "file_path": "planet/control/COrder.py", "project_url": "https://github.com/haobin12358/python_planet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1965,7 +1965,7 @@ class COrder(CPay, CCoupon):\n                 '\u6d3b\u52a8\u51cf\u514d': order_part.OPsubTotal - order_part.OPsubTrueTotal if order_main.OMfrom == OrderFrom.magic_box.value else 0,\n                 '\u4ed8\u6b3e\u65f6\u95f4': getattr(order_pay, 'OPaytime', ''),\n                 '\u552e\u540e\u4e2d': order_main.OMinRefund or order_part.OPisinORA,\n-                '\u6536\u8d27\u4eba': order_main.OMrecvPhone,\n+                '\u6536\u8d27\u4eba': order_main.OMrecvName,\n                 '\u6536\u8d27\u7535\u8bdd': order_main.OMrecvPhone,\n                 '\u5730\u5740': order_main.OMrecvAddress,\n                 '\u6765\u6e90(\u6d3b\u52a8)': OrderFrom(order_main.OMfrom).zh_value,\n", "before": "main.OMrec v Phone, ", "after": "main.OMrec v Name, ", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:Phone,\", 3, 41, 3, 52], \"Name,\"]]"}
{"project": "mopidy-youtube", "commit_sha": "98e8b15f5e4d66f437a6f5691e2ba5af4e703427", "parent_sha": "f1268189d6adf120657d6fe43b6962a4a72218f9", "file_path": "mopidy_youtube/youtube.py", "project_url": "https://github.com/natumbri/mopidy-youtube", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -279,7 +279,7 @@ class Playlist(Entry):\n             page = ''\n             while page is not None and len(all_videos) < self.playlist_max_videos:\n                 try:\n-                    max_results = min(self.max_videos - len(all_videos), 50)\n+                    max_results = min(self.playlist_max_videos - len(all_videos), 50)\n                     if api_enabled:\n                         data = API.list_playlistitems(self.id, page, max_results)\n                     else:\n", "before": "max_results = min ( self . max_videos - len ( all_videos ) , 50 )", "after": "max_results = min ( self . playlist_max_videos - len ( all_videos ) , 50 )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:max_videos\", 3, 44, 3, 54], \"playlist_max_videos\"]]"}
{"project": "shop-db2", "commit_sha": "c9c11e2cdf182e4a223394290500d1a088e0f367", "parent_sha": "35e3a4a7725c2fe87df7135adbc8a6557236eb38", "file_path": "shopdb/exceptions.py", "project_url": "https://github.com/g3n35i5/shop-db2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -6,7 +6,7 @@ from sqlalchemy.exc import DontWrapMixin\n class BaseException(Exception, DontWrapMixin):\n     @classmethod\n     def create_response(self):\n-        return jsonify(result=self.type, message=self.code), self.code\n+        return jsonify(result=self.type, message=self.message), self.code\n \n \n class NothingHasChanged(BaseException):\n", "before": "return jsonify ( result = self . type , message = self . code ) , self . code", "after": "return jsonify ( result = self . type , message = self . message ) , self . code", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:code\", 3, 55, 3, 59], \"message\"]]"}
{"project": "python_planet", "commit_sha": "2c0252a804b068a06f3e2549cce21aa92f5f85c0", "parent_sha": "3be4888c776bedfeead5b5d6a754c1cdb0bfd597", "file_path": "planet/control/CPlay.py", "project_url": "https://github.com/haobin12358/python_planet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2004,7 +2004,7 @@ class CPlay():\n         db.session.add(makeover)\n \n         # \u94b1\u8fdb\u5165\u65b0\u9886\u961f\u8d26\u6237\n-        guide = User.query.filter_by(USid=makeover.MOassignor, isdelete=False).first()\n+        guide = User.query.filter_by(USid=makeover.MOsuccessor, isdelete=False).first()\n         if not guide:\n             # \u5bfc\u6e38\u4e0d\u5b58\u5728\uff0c\u94b1\u8fdb\u5165\u5e73\u53f0\u8d26\u6237\n             current_app.logger.info('\u5bfc\u6e38 {} \u5df2\u5220\u9664, {} \u6b63\u5728\u627f\u63a5\u6d3b\u52a8'.format(play.PLcreate, makeover.MOsuccessor))\n", "before": "guide = User . query . filter_by ( USid = makeover . MOassignor , isdelete = False ) . first ( )", "after": "guide = User . query . filter_by ( USid = makeover . MOsuccessor , isdelete = False ) . first ( )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:MOassignor\", 3, 52, 3, 62], \"MOsuccessor\"]]"}
{"project": "python_planet", "commit_sha": "639ff0a4e550f69530b570cf0704ff62250fb189", "parent_sha": "78b0c0966b26bc692f1e698ea5c50f7bb392ee74", "file_path": "planet/control/CMaterialFeedback.py", "project_url": "https://github.com/haobin12358/python_planet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -99,7 +99,7 @@ class CMaterialFeedback():\n             UserMaterialFeedback.query.filter(\n                 UserMaterialFeedback.UMFid != umfid,\n                                               UserMaterialFeedback.isdelete == false(),\n-                                              UserMaterialFeedback.UMFstatus != UserMaterialFeedbackStatus.refuse.value,\n+                                              UserMaterialFeedback.UMFstatus != UserMaterialFeedbackStatus.reject.value,\n                                               UserMaterialFeedback.TSOid == umf.TSOid).update(\n                 {'UMFstatus': UserMaterialFeedbackStatus.refund.value})\n \n", "before": "UserMaterialFeedback . query . filter ( UserMaterialFeedback . UMFid != umfid , UserMaterialFeedback . isdelete == false ( ) , UserMaterialFeedback . UMFstatus != UserMaterialFeedbackStatus . refuse . value , UserMaterialFeedback . TSOid == umf . TSOid ) . update ( { 'UMFstatus' : UserMaterialFeedbackStatus . refund . value } )", "after": "UserMaterialFeedback . query . filter ( UserMaterialFeedback . UMFid != umfid , UserMaterialFeedback . isdelete == false ( ) , UserMaterialFeedback . UMFstatus != UserMaterialFeedbackStatus . reject . value , UserMaterialFeedback . TSOid == umf . TSOid ) . update ( { 'UMFstatus' : UserMaterialFeedbackStatus . refund . value } )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:refuse\", 3, 108, 3, 114], \"reject\"]]"}
{"project": "QCG-PilotJob", "commit_sha": "0753c86ea36e6dc81c83dbc7f112be54e5291976", "parent_sha": "bc66c918cb2b2a37e4a2d4fc912fd548e374f081", "file_path": "qcg/appscheduler/api/job.py", "project_url": "https://github.com/vecma-project/QCG-PilotJob", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -230,7 +230,7 @@ class Jobs:\n-        self.__list[jName] = { 'idx': self.jobIdx, 'data': jData }\n+        self.__list[jName] = { 'idx': self.__jobIdx, 'data': jData }\n         self.__jobIdx += 1\n \n \n", "before": "self . __list [ jName ] = { 'idx' : self . jobIdx , 'data' : jData }", "after": "self . __list [ jName ] = { 'idx' : self . __jobIdx , 'data' : jData }", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:jobIdx\", 0, 44, 0, 50], \"__jobIdx\"]]"}
{"project": "QCG-PilotJob", "commit_sha": "5bdebeff91a52be8331e2993eb1cbdf95098cfcf", "parent_sha": "c1e04657895c43ea0984ead1874bea23de19be76", "file_path": "src/qcg/appscheduler/environment.py", "project_url": "https://github.com/vecma-project/QCG-PilotJob", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -115,7 +115,7 @@ class SlurmEnvironment(Environment):\n         hostfile = os.path.join(job.wdPath, \".%s.hostfile\" % job.job.name)\n         with open(hostfile, 'w') as f:\n             for node in job.allocation.nodeAllocations:\n-                for i in range(0, node.cores):\n+                for i in range(0, node.ncores):\n                     f.write(\"%s\\n\" % node.node.name)\n \n         job.env.update({\n", "before": "for i in range ( 0 , node . cores ) : f . write ( \"%s\\n\" % node . node . name )", "after": "for i in range ( 0 , node . ncores ) : f . write ( \"%s\\n\" % node . node . name )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:cores\", 3, 40, 3, 45], \"ncores\"]]"}
{"project": "sympy", "commit_sha": "3b63435bb87ca27b85f354c51a973ba7e85014ba", "parent_sha": "8640afb7840ace390323d21de220fa00f458afba", "file_path": "sympy/core/function.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1414,7 +1414,7 @@ def doit(self, **hints):\n         if hints.get('deep', True):\n             expr = expr.doit(**hints)\n         hints['evaluate'] = True\n-        return self.func(expr, *self.variables, **hints)\n+        return self.func(expr, *self.variable_count, **hints)\n \n     @_sympifyit('z0', NotImplementedError)\n     def doit_numerically(self, z0):\n", "before": "return self . func ( expr , * self . variables , ** hints )", "after": "return self . func ( expr , * self . variable_count , ** hints )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:variables\", 3, 38, 3, 47], \"variable_count\"]]"}
{"project": "osc", "commit_sha": "12ffb4e3c4e9cf4476a0460d01b774a23b521db4", "parent_sha": "41adda44f61649949bc35254857aae050749f078", "file_path": "osc/conf.py", "project_url": "https://github.com/lethliel/osc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -710,7 +710,7 @@ def add_section(filename, url, user, passwd):\n     cp = get_configParser(filename)\n     try:\n         cp.add_section(url)\n-    except OscConfigParser.ConfigParser.DuplicateSectionError:\n+    except OscConfigParser.configparser.DuplicateSectionError:\n         # Section might have existed, but was empty\n         pass\n     if config['use_keyring'] and GENERIC_KEYRING:\n", "before": "try : cp . add_section ( url ) except OscConfigParser . ConfigParser . DuplicateSectionError : pass", "after": "try : cp . add_section ( url ) except OscConfigParser . configparser . DuplicateSectionError : pass", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:ConfigParser\", 3, 28, 3, 40], \"configparser\"]]"}
{"project": "osc", "commit_sha": "47af622031029ea4e1f242bfc33ff49539cc13d0", "parent_sha": "474dcf6843256fb5b8b3e9a720978da1fea884d0", "file_path": "osc/commandline.py", "project_url": "https://github.com/lethliel/osc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -7241,7 +7241,7 @@ Please submit there instead, or use --nodevelproject to force direct submission.\n             if searchresult:\n                 for result in searchresult.findall('owner'):\n                     for role in roles:\n-                        delPerson(apiurl, result.get('project'), result.get('package'), opts.add, role)\n+                        delPerson(apiurl, result.get('project'), result.get('package'), opts.delete, role)\n             else:\n                 for role in roles:\n                     delPerson(apiurl, prj, pac, opts.delete, role)\n", "before": "delPerson ( apiurl , result . get ( 'project' ) , result . get ( 'package' ) , opts . add , role )", "after": "delPerson ( apiurl , result . get ( 'project' ) , result . get ( 'package' ) , opts . delete , role )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:add\", 3, 94, 3, 97], \"delete\"]]"}
{"project": "sympy", "commit_sha": "de8382884c851b3fd7127715f002e71df2e86413", "parent_sha": "39dd613fdc8352d0b7769159de053440483299df", "file_path": "sympy/sets/tests/test_setexpr.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -189,7 +189,7 @@ def test_Interval_inf():\n     set_if = SetExpr(Interval(-oo, 5))\n     set_fi = SetExpr(Interval(0, oo))\n     set_ii = SetExpr(Interval(-oo, oo))\n-    fs_ni = SetExpr(FiniteSet(S.NetgativeInfinity))\n+    fs_ni = SetExpr(FiniteSet(S.NegativeInfinity))\n     fs_pi = SetExpr(FiniteSet(S.Infinity))\n \n     assert set_ff + neinf == fs_ni\n", "before": "fs_ni = SetExpr ( FiniteSet ( S . NetgativeInfinity ) )", "after": "fs_ni = SetExpr ( FiniteSet ( S . NegativeInfinity ) )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:NetgativeInfinity\", 3, 33, 3, 50], \"NegativeInfinity\"]]"}
{"project": "travel", "commit_sha": "36869972501caeab0c8a21de374d1b4a73f9ea9d", "parent_sha": "50461c11049729934f0b851a32bae4c83a19ddd4", "file_path": "poke/models.py", "project_url": "https://github.com/elanius/travel", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -26,4 +26,4 @@ class Ticket(models.Model):\n \tis_return = models.BooleanField(default=False)\n \n \tdef __unicode__(self):\n-\t\treturn \"%s - %s\" % (self.pasanger.name, self.routes.date.strftime(\"%d %b (%a)\"))\n+\t\treturn \"%s - %s\" % (self.pasanger.name, self.route.date.strftime(\"%d %b (%a)\"))\n", "before": "return \"%s - %s\" % ( self . pasanger . name , self . routes . date . strftime ( \"%d %b (%a)\" ) )", "after": "return \"%s - %s\" % ( self . pasanger . name , self . route . date . strftime ( \"%d %b (%a)\" ) )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:routes\", 3, 48, 3, 54], \"route\"]]"}
{"project": "django-connectwise", "commit_sha": "c19acbe32051ab7e3d0493f7e80d9372b0c00b7f", "parent_sha": "bb2f0a2218a699963804e87ed556299f5fb90ab5", "file_path": "djconnectwise/tests/test_sync.py", "project_url": "https://github.com/trinitonesounds/django-connectwise", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -50,7 +50,7 @@ class TestCompanySynchronizer(TestCase):\n         company_post_update = Company.objects \\\n                                      .get(id=api_company['id'])\n \n-        self.assertNotEquals(company_pre_update.identifier,\n+        self.assertNotEquals(company_pre_update.company_identifier,\n                              identifier)\n         self._assert_fields(company_post_update, api_company)\n \n", "before": "self . assertNotEquals ( company_pre_update . identifier , identifier )", "after": "self . assertNotEquals ( company_pre_update . company_identifier , identifier )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:identifier\", 3, 49, 3, 59], \"company_identifier\"]]"}
{"project": "GPflowOpt", "commit_sha": "ec4ea0fe7c2777f38a1a955524d08dea4fc8bef0", "parent_sha": "4cd283d32e1de4d7ec59b54c4baf6286c13aad5a", "file_path": "testing/test_optimizers.py", "project_url": "https://github.com/nknudde/GPflowOpt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -179,7 +179,7 @@ class TestBayesianOptimizer(_TestOptimizer, unittest.TestCase):\n     def test_failsafe(self):\n         X, Y = self.optimizer.acquisition.data[0], self.optimizer.acquisition.data[1]\n         # Provoke cholesky faillure\n-        self.optimizer.acquisition._optimize_restarts = 1\n+        self.optimizer.acquisition.optimize_restarts = 1\n         self.optimizer.acquisition.models[0].likelihood.variance.transform = GPflow.transforms.Identity()\n         self.optimizer.acquisition.models[0].likelihood.variance = -5.0\n         self.optimizer.acquisition.models[0]._needs_recompile = True\n", "before": "self . optimizer . acquisition . _optimize_restarts = 1", "after": "self . optimizer . acquisition . optimize_restarts = 1", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:_optimize_restarts\", 3, 36, 3, 54], \"optimize_restarts\"]]"}
{"project": "dosenet-raspberrypi", "commit_sha": "c21e66d3e179edf05a6f42962b9bac9e305950b3", "parent_sha": "8d1ed57646af4115eeaad6e1481aafa5a7e09ac5", "file_path": "weather_DAQ.py", "project_url": "https://github.com/ludicao/dosenet-raspberrypi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ class weather_DAQ(object):\n         if len(timelist)>=self.n_merge:\n             queue.append(timelist[int((self.n_merge)/2)])\n             print('Queue time: {}'.format(timelist[int((self.n_merge)/2)]))\n-            self.timelist=[]\n+            self.time_list=[]\n         if len(queue)>self.maxdata:\n             queue.popleft()\n         \n", "before": "self . timelist = [ ]", "after": "self . time_list = [ ]", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:timelist\", 3, 18, 3, 26], \"time_list\"]]"}
{"project": "performance", "commit_sha": "2b50a63b5b922dd00e0a2572b7424793213ee649", "parent_sha": "7eeb14cbbf1e9444b130a8596b547a18bc89f381", "file_path": "scripts/bench_revisions.py", "project_url": "https://github.com/willingc/performance", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -210,7 +210,7 @@ class Benchmark(object):\n             for filename in self.outputs:\n                 print(\"Tested: %s\" % filename)\n \n-            for filename in self.uplodaded:\n+            for filename in self.uploaded:\n                 print(\"Tested and uploaded: %s\" % filename)\n \n \n", "before": "for filename in self . uplodaded : print ( \"Tested and uploaded: %s\" % filename )", "after": "for filename in self . uploaded : print ( \"Tested and uploaded: %s\" % filename )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:uplodaded\", 3, 34, 3, 43], \"uploaded\"]]"}
{"project": "performance", "commit_sha": "9ef4f80ebf5edff4abff86878b20be6a21d05a07", "parent_sha": "f0969965211f0b125b295f0853e3a0e3fae72c9a", "file_path": "performance/compile.py", "project_url": "https://github.com/willingc/performance", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -467,7 +467,7 @@ class BenchmarkRevision(Application):\n \n         if self.uploaded:\n             self.logger.error(\"Benchmark result uploaded and written into %s\"\n-                              % self.filename)\n+                              % self.upload_filename)\n         else:\n             self.logger.error(\"Benchmark result written into %s\"\n                               % self.filename)\n", "before": "self . logger . error ( \"Benchmark result uploaded and written into %s\" % self . filename )", "after": "self . logger . error ( \"Benchmark result uploaded and written into %s\" % self . upload_filename )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:filename\", 3, 38, 3, 46], \"upload_filename\"]]"}
{"project": "flutterfuck", "commit_sha": "60c01f8aabde09cb285e62b5de3e124835b5a7c0", "parent_sha": "7eabed9fc5c04789f09528010bba73713574d15b", "file_path": "sopel/loader.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -142,7 +142,7 @@ def clean_callable(func, config):\n     nick = config.core.nick\n     prefix = config.core.prefix\n-    help_prefix = config.core.prefix\n+    help_prefix = config.core.help_prefix\n     func._docs = {}\n     doc = trim_docstring(func.__doc__)\n     example = None\n", "before": "help_prefix = config . core . prefix", "after": "help_prefix = config . core . help_prefix", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:prefix\", 2, 31, 2, 37], \"help_prefix\"]]"}
{"project": "flutterfuck", "commit_sha": "331d7ab88183014ba5a09f139126ba2a2cf98559", "parent_sha": "9d30586f96cd0df857cac077cff495fb231d0911", "file_path": "willie/irc.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -224,7 +224,7 @@ class Bot(asynchat.async_chat):\n     def initiate_connect(self, host, port):\n         stderr('Connecting to %s:%s...' % (host, port))\n         source_address = ((self.config.core.bind_host, 0)\n-                          if self.config.core.bind_address else None)\n+                          if self.config.core.bind_host else None)\n         self.set_socket(socket.create_connection((host, port),\n                         source_address=source_address))\n         if self.config.core.use_ssl and has_ssl:\n", "before": "source_address = ( ( self . config . core . bind_host , 0 ) if self . config . core . bind_address else None )", "after": "source_address = ( ( self . config . core . bind_host , 0 ) if self . config . core . bind_host else None )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:bind_address\", 3, 47, 3, 59], \"bind_host\"]]"}
{"project": "ykdl", "commit_sha": "1f504e335ea041c434104e10bbb9cf2da390fe84", "parent_sha": "2a77b57e9abef806ebc9f660891967a328d73ec7", "file_path": "you_get/extractors/bilibili.py", "project_url": "https://github.com/YU-zreo/ykdl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ class BiliBili(EmbedExtractor):\n         assert self.url\n \n         if re.search('live', self.url):\n-            self.video_url.append(('biliorig', self.url))\n+            self.video_info.append(('biliorig', self.url))\n             return\n \n         html = get_content(self.url)\n", "before": "self . video_url . append ( ( 'biliorig' , self . url ) )", "after": "self . video_info . append ( ( 'biliorig' , self . url ) )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:video_url\", 3, 18, 3, 27], \"video_info\"]]"}
{"project": "python-freshdesk", "commit_sha": "61b6fac236a92d450d860c98d5b9bae81f9cc6f1", "parent_sha": "930ccdd56e181d63d387efc2252b1fc3dc5fb296", "file_path": "freshdesk/v2/models.py", "project_url": "https://github.com/alkivi-sas/python-freshdesk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -51,7 +51,7 @@ class Ticket(FreshdeskModel):\n \n class Group(FreshdeskModel):\n     def __str__(self):\n-        return self.body\n+        return self.name\n \n     def __repr__(self):\n         return '<Group \\'{}\\'>'.format(self.name)\n", "before": "return self . body", "after": "return self . name", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:body\", 3, 21, 3, 25], \"name\"]]"}
{"project": "tvm", "commit_sha": "a14a048f663558d11c64e488dd8c4b2c4355ffcf", "parent_sha": "17dda3c77bd5d010916aafaf63cebf9c8c66e0d6", "file_path": "python/tvm/driver/tvmc/compiler.py", "project_url": "https://github.com/neo-ai/tvm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -107,7 +107,7 @@ def drive_compile(args):\n         None,\n         args.model_format,\n         args.tuning_records,\n-        args.tensor_layout,\n+        args.desired_layout,\n     )\n \n     if dumps:\n", "before": "args . tensor_layout ,", "after": "args . desired_layout ,", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:tensor_layout\", 3, 14, 3, 27], \"desired_layout\"]]"}
{"project": "tvm", "commit_sha": "982ae7d4c00bcf4fe44f3f1069835e74524741fe", "parent_sha": "74436afa5c18a289c3cb29890dd021682664a40b", "file_path": "python/tvm/driver/tvmc/compiler.py", "project_url": "https://github.com/neo-ai/tvm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -127,7 +127,7 @@ def drive_compile(args):\n         None,\n         args.tuning_records,\n         args.desired_layout,\n-        args.disabled_pass,\n+        args.disable_pass,\n     )\n \n     if dumps:\n", "before": "args . disabled_pass ,", "after": "args . disable_pass ,", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:disabled_pass\", 3, 14, 3, 27], \"disable_pass\"]]"}
{"project": "tape", "commit_sha": "c4476bd5fc70876df4dd66cea6d087f8242a6ac6", "parent_sha": "8c74e80c092c6e2119fe0f70854d0dc882aa8d42", "file_path": "tape_pytorch/models/contact_predictor.py", "project_url": "https://github.com/songlab-cal/tape", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -239,7 +239,7 @@ class ResNetEncoder(nn.Module):\n         if chunks is not None:\n             assert isinstance(chunks, int)\n             chunk_size = (len(self.layer1) + chunks - 1) // chunks\n-            for start in range(0, len(self.modules), chunk_size):\n+            for start in range(0, len(self.layer1), chunk_size):\n                 x = checkpoint(self.run_function(start, chunk_size), x, input_mask)\n         else:\n             for module in self.layer1:\n", "before": "for start in range ( 0 , len ( self . modules ) , chunk_size ) : x = checkpoint ( self . run_function ( start , chunk_size ) , x , input_mask )", "after": "for start in range ( 0 , len ( self . layer1 ) , chunk_size ) : x = checkpoint ( self . run_function ( start , chunk_size ) , x , input_mask )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:modules\", 3, 44, 3, 51], \"layer1\"]]"}
{"project": "macsyfinder", "commit_sha": "90b9234ebaa1c559491bfe15f29f8a6f1a9f097c", "parent_sha": "5cacdd97bd7906993faccfeb95e70dbdd5279759", "file_path": "macsypy/gene.py", "project_url": "https://github.com/gem-pasteur/macsyfinder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -165,7 +165,7 @@ class ModelGene:\n             s += \"\\nmulti_system\"\n         if self._exchangeables:\n             s += \"\\n    exchangeables: \"\n-            for h in self.homologs:\n+            for h in self.exchangeables:\n                 s += h.name + \", \"\n             s = s[:-2]\n         return s\n", "before": "for h in self . homologs : s += h . name + \", \"", "after": "for h in self . exchangeables : s += h . name + \", \"", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:homologs\", 3, 27, 3, 35], \"exchangeables\"]]"}
{"project": "macsyfinder", "commit_sha": "f8ef117135444a6ba2b1da9b392e5eaa74027030", "parent_sha": "3f9ae9dd3ee371d2c728dba2277dda1dc5fceb8c", "file_path": "tests/test_macsydata.py", "project_url": "https://github.com/gem-pasteur/macsyfinder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,7 +35,7 @@ class TestMacsydata(MacsyTest):\n     def tearDown(self):\n         macsydata.RemoteModelIndex.remote_exists = self._remote_exists\n         try:\n-            shutil.rmtree(self.tmp_dir)\n+            shutil.rmtree(self.tmpdir)\n         except:\n             pass\n         # some function in macsydata script suppress the traceback\n", "before": "shutil . rmtree ( self . tmp_dir )", "after": "shutil . rmtree ( self . tmpdir )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:tmp_dir\", 3, 32, 3, 39], \"tmpdir\"]]"}
{"project": "GenomonSV", "commit_sha": "1862ae533fb058e0cb90d60a8c1a7d668fa06dc7", "parent_sha": "44c901a1bc21856a0eeef8f526faec641e697f34", "file_path": "lib/genomonSV/run.py", "project_url": "https://github.com/Genomon-Project/GenomonSV", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -216,7 +216,7 @@ def genomonSV_merge(args):\n \n     ####################\n     # load config files\n-    controlConf = config.control_yaml_config_parse(args.junctionFilePath)\n+    controlConf = config.control_yaml_config_parse(args.controlPathInfoFile)\n \n     outputFilePath = args.outputFilePath\n \n", "before": "controlConf = config . control_yaml_config_parse ( args . junctionFilePath )", "after": "controlConf = config . control_yaml_config_parse ( args . controlPathInfoFile )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:junctionFilePath\", 3, 57, 3, 73], \"controlPathInfoFile\"]]"}
{"project": "uberserver", "commit_sha": "1b92eaafedb49fb361fab02d76755d969edda3fc", "parent_sha": "50f39786b21e3233af22cae6218d10afc75cfd6e", "file_path": "LegacyBans.py", "project_url": "https://github.com/lunixbochs/uberserver", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -50,7 +50,7 @@ class BanHandler:\n \t\t\r\n \t\tentry = None\r\n \t\tif username:\r\n-\t\t\tentry = session.query(Ban).filter(Ban.username==username).first()\r\n+\t\t\tentry = session.query(Ban).filter(Ban.Username==username).first()\r\n \t\tif not entry and userid: # ban priority is username > userid > ip # skips these if statements when we find a ban\r\n \t\t\tentry = session.query(Ban).filter(Ban.userID==userid).first()\r\n \t\tif not entry and ip:\r\n", "before": "entry = session . query ( Ban ) . filter ( Ban . username == username ) . first ( )", "after": "entry = session . query ( Ban ) . filter ( Ban . Username == username ) . first ( )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:username\", 3, 42, 3, 50], \"Username\"]]"}
{"project": "FX-BT-Scripts", "commit_sha": "0f185464022243f83b04c034992d73f86162cf46", "parent_sha": "bbe932577d37c00843cdfaec6b691632cc152a8c", "file_path": "dl_bt_dukascopy.py", "project_url": "https://github.com/FX31337/FX-BT-Scripts", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -289,7 +289,7 @@ def download(self):\n                     print(\"Error: %s, reason: %s. Retrying (%i)..\" % (err.code, err.reason, i));\n                     i += 1\n                 except IOError as err:\n-                    print(\"Error: %s, reason: %s. Retrying (%i)..\" % (err.code, err.reason, i));\n+                    print(\"Error: %s, reason: %s. Retrying (%i)..\" % (err.errno, err.reason, i));\n                     i += 1\n                 except socket.timeout as err:\n                     print(\"Network error: %s. Retrying (%i)..\" % (err.strerror, i));\n", "before": "except IOError as err : print ( \"Error: %s, reason: %s. Retrying (%i)..\" % ( err . code , err . reason , i ) )", "after": "except IOError as err : print ( \"Error: %s, reason: %s. Retrying (%i)..\" % ( err . errno , err . reason , i ) )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:code\", 3, 75, 3, 79], \"errno\"]]"}
{"project": "FX-BT-Scripts", "commit_sha": "576901de03459541f8730836aa7d61d67ddffd38", "parent_sha": "0f185464022243f83b04c034992d73f86162cf46", "file_path": "dl_bt_dukascopy.py", "project_url": "https://github.com/FX31337/FX-BT-Scripts", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -289,7 +289,7 @@ def download(self):\n                     print(\"Error: %s, reason: %s. Retrying (%i)..\" % (err.code, err.reason, i));\n                     i += 1\n                 except IOError as err:\n-                    print(\"Error: %s, reason: %s. Retrying (%i)..\" % (err.errno, err.reason, i));\n+                    print(\"Error: %s, reason: %s. Retrying (%i)..\" % (err.errno, err.strerror, i));\n                     i += 1\n                 except socket.timeout as err:\n                     print(\"Network error: %s. Retrying (%i)..\" % (err.strerror, i));\n", "before": "except IOError as err : print ( \"Error: %s, reason: %s. Retrying (%i)..\" % ( err . errno , err . reason , i ) )", "after": "except IOError as err : print ( \"Error: %s, reason: %s. Retrying (%i)..\" % ( err . errno , err . strerror , i ) )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:reason\", 3, 86, 3, 92], \"strerror\"]]"}
{"project": "weblyzard_api", "commit_sha": "e42dd4fcc5dda128bf5d38329cfb1ec37f3860c2", "parent_sha": "85d55feb23fa56dff3473cf71c0ece7375d08d3f", "file_path": "src/python/weblyzard_api/client/skb_rest_client.py", "project_url": "https://github.com/weblyzard/weblyzard_api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -155,7 +155,7 @@ class SKBRESTClient(object):\n             assert 'entityType' in entity\n         if len(entity_list) < 1:\n             return None\n-        urlpath = self.ENTITY_PATH\n+        urlpath = self.ENTITY_BATCH_PATH\n         if force_update:\n             urlpath = u'{}?force_update'.format(urlpath)\n         response = requests.post('{}/{}'.format(self.url,\n", "before": "urlpath = self . ENTITY_PATH", "after": "urlpath = self . ENTITY_BATCH_PATH", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:ENTITY_PATH\", 3, 24, 3, 35], \"ENTITY_BATCH_PATH\"]]"}
{"project": "mfcobol-export", "commit_sha": "d443f6b9d328c166f0d8a6c416f6f4bf5f299e8d", "parent_sha": "bf13b400be192bb2b96722c6b01446e9669222b0", "file_path": "export-microfocus-cobol.py", "project_url": "https://github.com/miracle2k/mfcobol-export", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -715,7 +715,7 @@ def json_exporter(records, output):\n def bytes_exporter(records, output):\n     for index, (record, _) in enumerate(records):\n         print('')\n-        print(\"%s: %s\" % (record.type, repr(record.bytes)[1:]))\n+        print(\"%s: %s\" % (record.type_display, repr(record.bytes)[1:]))\n \n \n if __name__ == \"__main__\":\n", "before": "print ( \"%s: %s\" % ( record . type , repr ( record . bytes ) [ 1 : ] ) )", "after": "print ( \"%s: %s\" % ( record . type_display , repr ( record . bytes ) [ 1 : ] ) )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:type\", 3, 34, 3, 38], \"type_display\"]]"}
{"project": "pypore", "commit_sha": "5836c8ebba070d7336909c989ee70bcbdd79e0ca", "parent_sha": "9e6665c07196e89a3c6f1fd3b3f47b2cefa23f54", "file_path": "src/pyporegui/eventanalysis.py", "project_url": "https://github.com/parkin/pypore", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -450,7 +450,7 @@ The current namespace should include:\n \n-        namespace = {'np': np, 'pg': pg, 'ed': ed, 'currentPlot': self.event_finding_tab.plotwid}\n+        namespace = {'np': np, 'pg': pg, 'ed': ed, 'currentPlot': self.event_finding_tab.plot_widget}\n         self.console = pgc.ConsoleWidget(namespace=namespace, text=text)\n         \n         frame = QtGui.QSplitter()\n", "before": "namespace = { 'np' : np , 'pg' : pg , 'ed' : ed , 'currentPlot' : self . event_finding_tab . plotwid }", "after": "namespace = { 'np' : np , 'pg' : pg , 'ed' : ed , 'currentPlot' : self . event_finding_tab . plot_widget }", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:plotwid\", 1, 90, 1, 97], \"plot_widget\"]]"}
{"project": "driftscan", "commit_sha": "10e2a25fe414ae43d286133362e051cbf532bdc9", "parent_sha": "2ec485d8d0cb52c8a331f415186efe71a2e81648", "file_path": "drift/core/beamtransfer.py", "project_url": "https://github.com/radiocosmology/driftscan", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1001,7 +1001,7 @@ class BeamTransfer(object):\n                     # Find the pseudo-inverse of the beam matrix and save to disk.\n                     try:\n                         ibeam = la.pinv(beam)\n-                    except la.LinAngError as e:\n+                    except la.LinAlgError as e:\n                         raise Exception(\"pinv failure: m = %d, fi = %d\" % (mi,fi)).with_traceback(e.__traceback__)\n \n                     dset_ibsvd[fi, :, :, :nmodes] = ibeam.reshape(\n", "before": "try : ibeam = la . pinv ( beam ) except la . LinAngError as e : raise Exception ( \"pinv failure: m = %d, fi = %d\" % ( mi , fi ) ) . with_traceback ( e . __traceback__ )", "after": "try : ibeam = la . pinv ( beam ) except la . LinAlgError as e : raise Exception ( \"pinv failure: m = %d, fi = %d\" % ( mi , fi ) ) . with_traceback ( e . __traceback__ )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:LinAngError\", 3, 31, 3, 42], \"LinAlgError\"]]"}
{"project": "openbci", "commit_sha": "11eddd410e6b90f74f0981991c64669663b3e644", "parent_sha": "4f5254eecf15864b2b4d0698d63a3b0efa859e04", "file_path": "utils/tagger_gui/end_frame.py", "project_url": "https://github.com/BrainTech/openbci", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -37,6 +37,6 @@ class EndFrame(QtGui.QFrame):\n \n     def finish_action_elier_frame(self):\n         self.elier_frame[0].finish_frame_action()\n-        self.elier_frame.remove(self.next_frame[0])\n+        self.elier_frame.remove(self.elier_frame[0])\n         self.set_off()\n         self.finish_signal.emit()\n", "before": "self . elier_frame . remove ( self . next_frame [ 0 ] )", "after": "self . elier_frame . remove ( self . elier_frame [ 0 ] )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:next_frame\", 3, 38, 3, 48], \"elier_frame\"]]"}
{"project": "dnstwister", "commit_sha": "0a0ad86f0979ff2db017156684d807af33fa1faa", "parent_sha": "d32fcfe34c78c5caf0b42d7a496a1c54e63af565", "file_path": "dnstwister/views/www/search.py", "project_url": "https://github.com/thisismyrobot/dnstwister", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -70,7 +70,7 @@ def search_post():\n     # Handle malformed domains data by redirecting to GET page.\n     if qry_domains is None:\n         app.logger.info(\n-            'No valid domains in POST dict {}'.format(flask.request.args)\n+            'No valid domains in POST dict {}'.format(flask.request.form)\n         )\n         return flask.redirect('/error/2')\n \n", "before": "app . logger . info ( 'No valid domains in POST dict {}' . format ( flask . request . args ) )", "after": "app . logger . info ( 'No valid domains in POST dict {}' . format ( flask . request . form ) )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:args\", 3, 69, 3, 73], \"form\"]]"}
{"project": "pcircle", "commit_sha": "c67b411447c1ad7d7164e1b6337535f781818085", "parent_sha": "9ae4438d70a782e1c06b4a750dc6cdf1d2ead480", "file_path": "pcircle/fcp.py", "project_url": "https://github.com/olcf/pcircle", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -488,7 +488,7 @@ class FCP(BaseTask):\n \n         if self.verify:\n             # use src path here\n-            ck = ChunkSum(work.src, offset=work.offset, length=work.length,\n+            ck = ChunkSum(work.dest, offset=work.offset, length=work.length,\n                           digest=m.hexdigest())\n             self.chunksums.append(ck)\n \n", "before": "ck = ChunkSum ( work . src , offset = work . offset , length = work . length , digest = m . hexdigest ( ) )", "after": "ck = ChunkSum ( work . dest , offset = work . offset , length = work . length , digest = m . hexdigest ( ) )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:src\", 3, 32, 3, 35], \"dest\"]]"}
{"project": "Pyglet", "commit_sha": "eb408224ff2a9d9a792e928198b4e1541cdc98e0", "parent_sha": "fc9a1a8752192ba596befb383ea8d493d6ddbbce", "file_path": "pyglet/text/layout.py", "project_url": "https://github.com/adamlwgriffiths/Pyglet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2166,7 +2166,7 @@ class IncrementalTextLayout(ScrollableTextLayout, event.EventDispatcher):\n             `line` : int\n                 Line index.\n \n-        :type: int\n+        :rtype: int\n", "before": "Line index . : type : int", "after": "Line index . : rtype : int", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:type\", 3, 10, 3, 14], \"rtype\"]]"}
{"project": "common_crawl", "commit_sha": "97d07a2a572272d2ccddf5ec114612ae14f10291", "parent_sha": "3c01220e53a0426135307ecfbc57c1ad48b9df9a", "file_path": "common_crawl/css_select.py", "project_url": "https://github.com/openvenues/common_crawl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -19,7 +19,7 @@ class CSSSelectJob(CommonCrawlJob):\n             # Fail early if no valid extensions are supplied\n             raise ValueError(\"Must specify at least one selector\")\n \n-        self.selectors = self.options.selectors\n+        self.selectors = self.options.selector\n \n         if self.options.parse_only:\n             self.strainer = SoupStrainer(self.options.selector)\n", "before": "self . selectors = self . options . selectors", "after": "self . selectors = self . options . selector", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:selectors\", 3, 39, 3, 48], \"selector\"]]"}
{"project": "MPBNP", "commit_sha": "a013b130fe5b126af7d65822d55e6f0fd0565f01", "parent_sha": "eecb11b57a1ba613b9c3873fb5faabe598b3bc7f", "file_path": "crp/gaussian.py", "project_url": "https://github.com/AusterweilLab/MPBNP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -169,7 +169,7 @@ class CollapsedGibbs(BaseSampler):\n \n             if self.device_type == cl.device_type.CPU:\n                 self.prg.normal_1d_logpost_loopy(self.queue, self.obs.shape, None,\n-                                                 d_labels, self.d_ob, d_uniq_label, d_mu, d_ss, d_n, \n+                                                 d_labels, self.d_obs, d_uniq_label, d_mu, d_ss, d_n, \n                                                  np.int32(uniq_labels.shape[0]), d_hyper_param, d_rand,\n                                                  d_logpost.data)\n             else:\n", "before": "self . prg . normal_1d_logpost_loopy ( self . queue , self . obs . shape , None , d_labels , self . d_ob , d_uniq_label , d_mu , d_ss , d_n , np . int32 ( uniq_labels . shape [ 0 ] ) , d_hyper_param , d_rand , d_logpost . data )", "after": "self . prg . normal_1d_logpost_loopy ( self . queue , self . obs . shape , None , d_labels , self . d_obs , d_uniq_label , d_mu , d_ss , d_n , np . int32 ( uniq_labels . shape [ 0 ] ) , d_hyper_param , d_rand , d_logpost . data )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:d_ob\", 3, 65, 3, 69], \"d_obs\"]]"}
{"project": "gloopy", "commit_sha": "497ff6626246eb613c29d587b0971f03ea76c21f", "parent_sha": "99154d35e69508b31aaa75a68d9b706d04e956ae", "file_path": "gloopy/shapes/ring.py", "project_url": "https://github.com/tartley/gloopy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,6 +34,6 @@ def TriRings(basic_shape, radius, number):\n     ring = Ring(basic_shape, radius, number)\n     multi.add(ring, orientation=Orientation(Vector.x_axis))\n     multi.add(ring, orientation=Orientation(Vector.y_axis))\n-    multi.add(ring, orientation=Orientation(Vector.x_axis, Vector.x_axis))\n+    multi.add(ring, orientation=Orientation(Vector.z_axis, Vector.x_axis))\n     return multi\n \n", "before": "multi . add ( ring , orientation = Orientation ( Vector . x_axis , Vector . x_axis ) )", "after": "multi . add ( ring , orientation = Orientation ( Vector . z_axis , Vector . x_axis ) )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:x_axis\", 3, 52, 3, 58], \"z_axis\"]]"}
{"project": "SymPortal_framework", "commit_sha": "5f81549d8aff1f658e1c9948ea17487d5da013f3", "parent_sha": "9d470151678e3c644bfddc5d34ec52d1a6ae633f", "file_path": "main.py", "project_url": "https://github.com/SymPortal/SymPortal_framework", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -203,7 +203,7 @@ def main():\n \n     elif args.between_sample_distances:\n         data_sub_collection_run.generate_within_clade_UniFrac_distances_samples(\n-            dataSubmission_str=args.between_type_distances, num_processors=args.num_proc,\n+            dataSubmission_str=args.between_sample_distances, num_processors=args.num_proc,\n             method='mothur', bootstrap_value=args.bootstrap)\n \n     elif args.print_output_no_types:\n", "before": "args . between_sample_distances : data_sub_collection_run . generate_within_clade_UniFrac_distances_samples ( dataSubmission_str = args . between_type_distances , num_processors = args . num_proc , method = 'mothur' , bootstrap_value = args . bootstrap )", "after": "args . between_sample_distances : data_sub_collection_run . generate_within_clade_UniFrac_distances_samples ( dataSubmission_str = args . between_sample_distances , num_processors = args . num_proc , method = 'mothur' , bootstrap_value = args . bootstrap )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:between_type_distances\", 3, 37, 3, 59], \"between_sample_distances\"]]"}
{"project": "NiceLib", "commit_sha": "75bb6af8b8a6c0c3d99cf104050163b8b4a23fb6", "parent_sha": "f741b70fb00e1a3d049d738943b934d08c04d749", "file_path": "nicelib/nicelib.py", "project_url": "https://github.com/mabuchilab/NiceLib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -503,7 +503,7 @@ class BufOutArgHandler(ArgHandler):\n             return None\n         string = ffi.string(c_arg[0])\n \n-        free_buf = self.sig.args['free_buf']\n+        free_buf = self.sig.flags['free_buf']\n         if free_buf:\n             free_buf(c_arg[0])\n         return string\n", "before": "free_buf = self . sig . args [ 'free_buf' ]", "after": "free_buf = self . sig . flags [ 'free_buf' ]", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:args\", 3, 29, 3, 33], \"flags\"]]"}
{"project": "SymPortal_framework", "commit_sha": "c76b230502bb4b3501d7c1305155728722698bdd", "parent_sha": "0d5c00788ce0181013efa14271a8bd5ac0cb10ab", "file_path": "symportal_utils.py", "project_url": "https://github.com/SymPortal/SymPortal_framework", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -579,7 +579,7 @@ class MothurAnalysis:\n                 [self.exec_path, self.mothur_batch_file_path],\n                 stdout=subprocess.PIPE, stderr=subprocess.PIPE\n             )\n-            for line in decode_utf8_binary_to_list(self.latest_completed_process_command.stdout):\n+            for line in decode_utf8_binary_to_list(self.latest_completed_process_summary.stdout):\n                 print(line)\n \n     def _pcr_make_and_write_mothur_batch_file(self):\n", "before": "for line in decode_utf8_binary_to_list ( self . latest_completed_process_command . stdout ) : print ( line )", "after": "for line in decode_utf8_binary_to_list ( self . latest_completed_process_summary . stdout ) : print ( line )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:latest_completed_process_command\", 3, 57, 3, 89], \"latest_completed_process_summary\"]]"}
{"project": "SymPortal_framework", "commit_sha": "fd771f30ab2c0e24e2038f44920811bbb5a2b829", "parent_sha": "4d09dd4961c27a3cf344fce80b1e7434b4b7e444", "file_path": "distance.py", "project_url": "https://github.com/SymPortal/SymPortal_framework", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1173,7 +1173,7 @@ class BaseBrayCurtisDistPCoACreator:\n                 else:\n                     if sqrt:\n                         temp_at_string.append(\n-                            self.clade_within_clade_distances_dict_no_sqrt[frozenset({obj_outer.id, obj_inner.id})])\n+                            self.clade_within_clade_distances_dict_sqrt[frozenset({obj_outer.id, obj_inner.id})])\n                     else:\n                         temp_at_string.append(\n                             self.clade_within_clade_distances_dict_no_sqrt[frozenset({obj_outer.id, obj_inner.id})])\n", "before": "sqrt : temp_at_string . append ( self . clade_within_clade_distances_dict_no_sqrt [ frozenset ( { obj_outer . id , obj_inner . id } ) ] )", "after": "sqrt : temp_at_string . append ( self . clade_within_clade_distances_dict_sqrt [ frozenset ( { obj_outer . id , obj_inner . id } ) ] )", "sstub_pattern": "CHANGE_ATTRIBUTE_USED", "edit_script": "[[\"Update\", [\"identifier:clade_within_clade_distances_dict_no_sqrt\", 3, 34, 3, 75], \"clade_within_clade_distances_dict_sqrt\"]]"}
{"project": "Cactus", "commit_sha": "d56678013f4249f1853cc440995b4a2bdac7f55d", "parent_sha": "2e0d8faf8aaf2f23aa1bfad3f3351e1158f780e7", "file_path": "cactus/tests/test_bootstrap.py", "project_url": "https://github.com/crate/Cactus", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -49,7 +49,7 @@ class BaseTestArchiveBootstrap(object):\n         self.skeleton_path = \"cactus/skeleton\"\n         self.archive_path = os.path.join(self.test_dir, \"archive\")\n \n-        with open(self.archive_path, \"w\") as f:\n+        with open(self.archive_path, \"wb\") as f:\n             self.make_archive(f)\n \n     def make_archive(self, f):\n", "before": "with open ( self . archive_path , \"w\" ) as f : self . make_archive ( f )", "after": "with open ( self . archive_path , \"wb\" ) as f : self . make_archive ( f )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"w\\\"\", 3, 38, 3, 41], \"\\\"wb\\\"\"]]"}
{"project": "dexy", "commit_sha": "14391bae0f128b72eba50ceb28264dc1b6b87656", "parent_sha": "37de3edd61ece014d682dd39c0a8d9fd90ad8f7f", "file_path": "handlers/subprocess.py", "project_url": "https://github.com/mojavelinux/dexy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -183,7 +183,7 @@ class LatexHandler(DexyHandler):\n         \n         # Detect which LaTeX compiler we have...\n         latex_bin = None\n-        for e in [\"texlive\", \"pdflatex\"]:\n+        for e in [\"latex\", \"pdflatex\"]:\n             latex_bin, s = pexpect.run(\"/usr/bin/env which %s\" % e, withexitstatus = True) \n             if s == 0:\n                 self.log.info(\"%s LaTeX FOUND at %s\" % (e, latex_bin))\n", "before": "for e in [ \"texlive\" , \"pdflatex\" ] : latex_bin , s = pexpect . run ( \"/usr/bin/env which %s\" % e , withexitstatus = True ) if s == 0 : self . log . info ( \"%s LaTeX FOUND at %s\" % ( e , latex_bin ) )", "after": "for e in [ \"latex\" , \"pdflatex\" ] : latex_bin , s = pexpect . run ( \"/usr/bin/env which %s\" % e , withexitstatus = True ) if s == 0 : self . log . info ( \"%s LaTeX FOUND at %s\" % ( e , latex_bin ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"texlive\\\"\", 3, 19, 3, 28], \"\\\"latex\\\"\"]]"}
{"project": "trac", "commit_sha": "86a91f7b68b72f1871f8466287b5bd798f465dd3", "parent_sha": "a4b60951b46f5f1d940c8779a32631254c838fcf", "file_path": "trac/perm.py", "project_url": "https://github.com/arielnetworks/trac", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -113,7 +113,7 @@ class PermissionCache:\n         perms = []\n         users = ['anonymous']\n         if username != 'anonymous':\n-            users += [username, 'autenticated']\n+            users += [username, 'authenticated']\n         while 1:\n             num_users = len(users)\n             num_perms = len(perms)\n", "before": "users += [ username , 'autenticated' ]", "after": "users += [ username , 'authenticated' ]", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'autenticated'\", 3, 33, 3, 47], \"'authenticated'\"]]"}
{"project": "SleekXMPP", "commit_sha": "7d59a8a0ad8284308740e6fbb5a4f0a9ab37301b", "parent_sha": "8da387a38aa90069cdcb44df2a36ccea303b62c8", "file_path": "sleekxmpp/plugins/xep_0054/vcard_temp.py", "project_url": "https://github.com/mayflower/SleekXMPP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -107,7 +107,7 @@ class XEP_0054(BasePlugin):\n             self.api['set_vcard'](jid=iq['from'], args=iq['vcard_temp'])\n             return\n         elif iq['type'] == 'get':\n-            vcard = self.api['get_vard'](iq['from'].bare)\n+            vcard = self.api['get_vcard'](iq['from'].bare)\n             if isinstance(vcard, Iq):\n                 vcard.send()\n             else:\n", "before": "self . api [ 'get_vard' ] ( iq [ 'from' ] . bare )", "after": "self . api [ 'get_vcard' ] ( iq [ 'from' ] . bare )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'get_vard'\", 3, 30, 3, 40], \"'get_vcard'\"]]"}
{"project": "SleekXMPP", "commit_sha": "b20dc9fe2b7c6652a6e600f2e0aedb470c049887", "parent_sha": "648b03f81172829cae65f6ac9fc551e049310501", "file_path": "sleekxmpp/jid.py", "project_url": "https://github.com/mayflower/SleekXMPP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -228,7 +228,7 @@ def _validate_domain(domain):\n \n             for char in label:\n                 if char in ILLEGAL_CHARS:\n-                    raise InvalidJID('Domain contains illegar characters')\n+                    raise InvalidJID('Domain contains illegal characters')\n \n             if '-' in (label[0], label[-1]):\n                 raise InvalidJID('Domain started or ended with -')\n", "before": "raise InvalidJID ( 'Domain contains illegar characters' )", "after": "raise InvalidJID ( 'Domain contains illegal characters' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'Domain contains illegar characters'\", 3, 38, 3, 74], \"'Domain contains illegal characters'\"]]"}
{"project": "ooi", "commit_sha": "3e4868bd130088c127260d0be65d6b139523173b", "parent_sha": "fe4a9be74449c69e8aed3fc51fadf18c63a102a6", "file_path": "ooi/api/compute.py", "project_url": "https://github.com/IFCA/ooi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -111,7 +111,7 @@ class Controller(ooi.api.base.Controller):\n         validator.validate(scheme)\n \n         attrs = obj.get(\"attributes\", {})\n-        name = attrs.get(\"occi.core.title\", \"OCCI VM\")\n+        name = attrs.get(\"occi.core.title\", \"OCCI_VM\")\n         image = obj[\"schemes\"][templates.OpenStackOSTemplate.scheme][0]\n         flavor = obj[\"schemes\"][templates.OpenStackResourceTemplate.scheme][0]\n         user_data = None\n", "before": "name = attrs . get ( \"occi.core.title\" , \"OCCI VM\" )", "after": "name = attrs . get ( \"occi.core.title\" , \"OCCI_VM\" )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"OCCI VM\\\"\", 3, 45, 3, 54], \"\\\"OCCI_VM\\\"\"]]"}
{"project": "cloud-bdii-provider", "commit_sha": "593cc462a6d30f0c1c0af63adeee0d9362e5941f", "parent_sha": "119985a21a55e3fd746b3a17628b9b19ee43c3b6", "file_path": "cloud_bdii/core.py", "project_url": "https://github.com/alvarolopez/cloud-bdii-provider", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -259,7 +259,7 @@ def parse_opts():\n \n     parser.add_argument(\n         '--template-extension',\n-        default='ldif',\n+        default='json',\n         help=('Extension to use for the templates'))\n \n     parser.add_argument(\n", "before": "parser . add_argument ( '--template-extension' , default = 'ldif' , help = ( 'Extension to use for the templates' ) )", "after": "parser . add_argument ( '--template-extension' , default = 'json' , help = ( 'Extension to use for the templates' ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'ldif'\", 3, 17, 3, 23], \"'json'\"]]"}
{"project": "cloud-bdii-provider", "commit_sha": "2d1d4566754df8545e7f63c0a1a3918df79e8cdb", "parent_sha": "f450ddb97800f92b5189fc57c228af1793d2013e", "file_path": "cloud_bdii/core.py", "project_url": "https://github.com/alvarolopez/cloud-bdii-provider", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -262,7 +262,7 @@ def parse_opts():\n \n     parser.add_argument(\n         '--template-dir',\n-        default='/etc/cloud-info-provider/templates',\n+        default='/etc/cloud-info-provider-indigo/templates',\n         help=('Path to the directory containing the needed templates'))\n \n     parser.add_argument(\n", "before": "parser . add_argument ( '--template-dir' , default = '/etc/cloud-info-provider/templates' , help = ( 'Path to the directory containing the needed templates' ) )", "after": "parser . add_argument ( '--template-dir' , default = '/etc/cloud-info-provider-indigo/templates' , help = ( 'Path to the directory containing the needed templates' ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'/etc/cloud-info-provider/templates'\", 3, 17, 3, 53], \"'/etc/cloud-info-provider-indigo/templates'\"]]"}
{"project": "nixops", "commit_sha": "aa04015a24c9615856ddf11d1a721a4aff2f4161", "parent_sha": "01905cd596376be849d467f45f53641b2e5f8e8b", "file_path": "charon/backends/ec2.py", "project_url": "https://github.com/zalora/nixops", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -204,7 +204,7 @@ class EC2State(MachineState):\n                     break\n             \n         if not secret_access_key:\n-            raise Exception(\"please set $EC2_SECRET_KEY or $AWS_SECRET_ACCESS_KEY, or add the key for \u2018{0}\u2019 to ~/ec2-keys\"\n+            raise Exception(\"please set $EC2_SECRET_KEY or $AWS_SECRET_ACCESS_KEY, or add the key for \u2018{0}\u2019 to ~/.ec2-keys\"\n                             .format(self._access_key_id))\n \n         self._conn = boto.ec2.connect_to_region(\n", "before": "raise Exception ( \"please set $EC2_SECRET_KEY or $AWS_SECRET_ACCESS_KEY, or add the key for \u2018{0}\u2019 to ~/ec2-keys\" . format ( self . _access_key_id ) )", "after": "raise Exception ( \"please set $EC2_SECRET_KEY or $AWS_SECRET_ACCESS_KEY, or add the key for \u2018{0}\u2019 to ~/.ec2-keys\" . format ( self . _access_key_id ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"please set $EC2_SECRET_KEY or $AWS_SECRET_ACCESS_KEY, or add the key for \\u2018{0}\\u2019 to ~/ec2-keys\\\"\", 3, 29, 3, 127], \"\\\"please set $EC2_SECRET_KEY or $AWS_SECRET_ACCESS_KEY, or add the key for \\u2018{0}\\u2019 to ~/.ec2-keys\\\"\"]]"}
{"project": "cassette", "commit_sha": "05c9ad844632c738e59d2b52b94ba71b7c296177", "parent_sha": "3f2019584473251c5d833185493af7203d4fbc64", "file_path": "cassette/tests/test_cassette.py", "project_url": "https://github.com/underdogio/cassette", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -229,7 +229,7 @@ class TestCassette(TestCase):\n             \"param\": \"1\",\n         }\n \n-        url = \"/get?\"\n+        url = \"get?\"\n         url += _encode_params(param)\n         r = self.check_urllib2_flow(url=url)\n         self.assertEqual(r.json[\"args\"][\"param\"], \"1\")\n", "before": "url = \"/get?\"", "after": "url = \"get?\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"/get?\\\"\", 3, 15, 3, 22], \"\\\"get?\\\"\"]]"}
{"project": "flask-wtf", "commit_sha": "c6649f378261c62bd06f43afddb9c8b772ce88ab", "parent_sha": "65ab8c316d2e7e9f1ea30c60dc567bd76f2a5796", "file_path": "tests/test_recaptcha.py", "project_url": "https://github.com/underdogio/flask-wtf", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,7 +33,7 @@ class TestRecaptcha(TestCase):\n \n     def test_recaptcha(self):\n         response = self.client.get('/')\n-        assert b'//www.google.com/recaptcha/api/' in response.data\n+        assert b'//www.google.com/recaptcha/api.js' in response.data\n \n     def test_invalid_recaptcha(self):\n         response = self.client.post('/', data={})\n", "before": "assert b'//www.google.com/recaptcha/api/' in response . data", "after": "assert b'//www.google.com/recaptcha/api.js' in response . data", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:b'//www.google.com/recaptcha/api/'\", 3, 16, 3, 50], \"b'//www.google.com/recaptcha/api.js'\"]]"}
{"project": "flask-oauthlib", "commit_sha": "65bdbd1edf51d6ede63b1edaf9c82e306ec41914", "parent_sha": "32cf2e7767d25d2820cf27f62be0e8b987ad82bf", "file_path": "tests/oauth2/test_oauth2.py", "project_url": "https://github.com/underdogio/flask-oauthlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -227,7 +227,7 @@ class TestRefreshToken(OAuthSuite):\n         args = (data.get('scope').replace(' ', '+'),\n                 data.get('refresh_token'))\n         url = ('/oauth/token?grant_type=refresh_token'\n-               '&scope=%s&refresh_token=%s&username=admin')\n+               '&scope=%s&refresh_token=%s')\n         url = url % args\n         rv = self.client.get(url, headers={\n             'Authorization': 'Basic %s' % auth_code,\n", "before": "url = ( '/oauth/token?grant_type=refresh_token' '&scope=%s&refresh_token=%s&username=admin' )", "after": "url = ( '/oauth/token?grant_type=refresh_token' '&scope=%s&refresh_token=%s' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'&scope=%s&refresh_token=%s&username=admin'\", 3, 16, 3, 59], \"'&scope=%s&refresh_token=%s'\"]]"}
{"project": "flask-oauthlib", "commit_sha": "6479a7900fe89eb38e336c0e530f4b6d4bed4f91", "parent_sha": "cfad30a99627fb1518dd61f96e61ae12f73163be", "file_path": "example/dropbox.py", "project_url": "https://github.com/underdogio/flask-oauthlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ def authorized():\n     resp = dropbox.authorized_response()\n     if resp is None:\n         return 'Access denied: reason=%s error=%s' % (\n-            request.args['error_reason'],\n+            request.args['error'],\n             request.args['error_description']\n         )\n     session['dropbox_token'] = (resp['access_token'], '')\n", "before": "return 'Access denied: reason=%s error=%s' % ( request . args [ 'error_reason' ] , request . args [ 'error_description' ] )", "after": "return 'Access denied: reason=%s error=%s' % ( request . args [ 'error' ] , request . args [ 'error_description' ] )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'error_reason'\", 3, 26, 3, 40], \"'error'\"]]"}
{"project": "splinter", "commit_sha": "03344fedd96c0e7812afeb97aeb289548ca753f0", "parent_sha": "e15f666ad25da970ffcb9ce123006c832d9935a8", "file_path": "tests/test_spynner.py", "project_url": "https://github.com/underdogio/splinter", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -7,7 +7,7 @@ class SpynnerTest(BaseBrowserTests, unittest.TestCase):\n \n     @classmethod\n     def setUpClass(cls):\n-        cls.browser = Browser('phantomjs')\n+        cls.browser = Browser('spynner')\n \n     def setUp(self):\n         self.browser.visit(EXAMPLE_APP)\n", "before": "cls . browser = Browser ( 'phantomjs' )", "after": "cls . browser = Browser ( 'spynner' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'phantomjs'\", 3, 31, 3, 42], \"'spynner'\"]]"}
{"project": "splinter", "commit_sha": "ec77aac7849bcfe8948c5137689dee9f63ee647a", "parent_sha": "8ef779346df8eb9a8af840816d03c6ef4d996ad7", "file_path": "tests/test_zopetestbrowser.py", "project_url": "https://github.com/underdogio/splinter", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -45,5 +45,5 @@ class ZopeTestBrowserDriverTest(BaseBrowserTests, unittest.TestCase):\n \n     @raises(NotImplementedError)\n     def test_can_change_field_value_by_type(self):\n-        \"zope.testbrowser does not support type_keys from selenium\"\n+        \"zope.testbrowser won't support type method because it doesn't interact with Javascritp, and this is the meaning of that method\"\n         self.browser.type('query',' with type method')\n", "before": "\"zope.testbrowser does not support type_keys from selenium\"", "after": "\"zope.testbrowser won't support type method because it doesn't interact with Javascritp, and this is the meaning of that method\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"zope.testbrowser does not support type_keys from selenium\\\"\", 3, 9, 3, 68], \"\\\"zope.testbrowser won't support type method because it doesn't interact with Javascritp, and this is the meaning of that method\\\"\"]]"}
{"project": "collective.documentviewer", "commit_sha": "5063bf065f71069ba6b313b77fc98e205eb888bc", "parent_sha": "f5b142b866d7c2e636d281e8b6820bd8b79a90b7", "file_path": "collective/documentviewer/upgrades.py", "project_url": "https://github.com/25th-floor/collective.documentviewer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ def upgrade_to_1_2(context):\n     # run 1.1 upgrade again since we change the control panel again\n     upgrade_to_1_1(context)\n \n-    types = getToolByName(context, 'portal_catalog')\n+    types = getToolByName(context, 'portal_types')\n     old_display = 'dvpdf-album-view'\n \n     logger.info('fixing group view name')\n", "before": "types = getToolByName ( context , 'portal_catalog' )", "after": "types = getToolByName ( context , 'portal_types' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'portal_catalog'\", 3, 36, 3, 52], \"'portal_types'\"]]"}
{"project": "nixops", "commit_sha": "81b758c660f57d0e6b99c648399a98d3b963f3de", "parent_sha": "e258034c682ee481003b986136bb7af8c25d79bf", "file_path": "nixops/backends/ec2.py", "project_url": "https://github.com/zalora/nixops", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -635,7 +635,7 @@ class EC2State(MachineState):\n                 else:\n                     self.log(\"associating IP address \u2018{0}\u2019...\".format(defn.elastic_ipv4))\n                     addresses[0].associate(self.vm_id)\n-                    self.log_start(\"waiting for address to be associated with this machine...\")\n+                    self.log_start(\"waiting for address to be associated with this machine... \")\n                     instance.update()\n                     while True:\n                         self.log_continue(\"({0}) \".format(instance.ip_address))\n", "before": "self . log_start ( \"waiting for address to be associated with this machine...\" )", "after": "self . log_start ( \"waiting for address to be associated with this machine... \" )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"waiting for address to be associated with this machine...\\\"\", 3, 36, 3, 95], \"\\\"waiting for address to be associated with this machine... \\\"\"]]"}
{"project": "nixops", "commit_sha": "492c4e0beac85344c6d919181c80a49dca7078ec", "parent_sha": "04698936d734bd821914b9010df7847b3bdfee2e", "file_path": "nixops/backends/hetzner.py", "project_url": "https://github.com/zalora/nixops", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -123,7 +123,7 @@ class HetznerState(MachineState):\n \n         if install:\n             self.log_start(\"partitioning disks...\")\n-            out = self.run_command(\"nixpart -\", capture_stdout=True,\n+            out = self.run_command(\"nixpart -p -\", capture_stdout=True,\n                                    stdin_string=self.partitions)\n             self.fs_info = '\\n'.join(out.splitlines()[1:-1])\n         else:\n", "before": "out = self . run_command ( \"nixpart -\" , capture_stdout = True , stdin_string = self . partitions )", "after": "out = self . run_command ( \"nixpart -p -\" , capture_stdout = True , stdin_string = self . partitions )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"nixpart -\\\"\", 3, 36, 3, 47], \"\\\"nixpart -p -\\\"\"]]"}
{"project": "nixops", "commit_sha": "98bd33179c932bbbc354224099971122a8a15627", "parent_sha": "e31f02655319e57b43eddc1cefaa07ca7dc4cd5d", "file_path": "nixops/backends/virtualbox.py", "project_url": "https://github.com/zalora/nixops", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -205,7 +205,7 @@ class VirtualBoxState(MachineState):\n                             [\"nix-build\"]\n                             + self.depl._eval_flags(self.depl.nix_exprs) +\n                             [\"--arg\", \"checkConfigurationOptions\", \"false\",\n-                             \"-A\", \"nodes.{0}.config.deployment.virtualbox.disks.{1}.baseImage\".format(self.name, disk_name),\n+                             \"-A\", 'nodes.\"{0}\".config.deployment.virtualbox.disks.{1}.baseImage'.format(self.name, disk_name),\n                              \"-o\", \"{0}/vbox-image-{1}\".format(self.depl.tempdir, self.name)],\n                             capture_stdout=True).rstrip()\n                     self._logged_exec([\"VBoxManage\", \"clonehd\", base_image, disk_path])\n", "before": "+ self . depl . _eval_flags ( self . depl . nix_exprs ) + [ \"--arg\" , \"checkConfigurationOptions\" , \"false\" , \"-A\" , \"nodes.{0}.config.deployment.virtualbox.disks.{1}.baseImage\" . format ( self . name , disk_name ) , \"-o\" , \"{0}/vbox-image-{1}\" . format ( self . depl . tempdir , self . name ) ] ,", "after": "+ self . depl . _eval_flags ( self . depl . nix_exprs ) + [ \"--arg\" , \"checkConfigurationOptions\" , \"false\" , \"-A\" , 'nodes.\"{0}\".config.deployment.virtualbox.disks.{1}.baseImage' . format ( self . name , disk_name ) , \"-o\" , \"{0}/vbox-image-{1}\" . format ( self . depl . tempdir , self . name ) ] ,", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"nodes.{0}.config.deployment.virtualbox.disks.{1}.baseImage\\\"\", 3, 36, 3, 96], \"'nodes.\\\"{0}\\\".config.deployment.virtualbox.disks.{1}.baseImage'\"]]"}
{"project": "nixops", "commit_sha": "a9785dd23071d122b91a0a99f75fcd17b33c2c9a", "parent_sha": "f7a9558e4add6b5db361c508ce7a55ad0d10ddd0", "file_path": "nixops/backends/virtualbox.py", "project_url": "https://github.com/zalora/nixops", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -205,7 +205,7 @@ class VirtualBoxState(MachineState):\n                             [\"nix-build\"]\n                             + self.depl._eval_flags(self.depl.nix_exprs) +\n                             [\"--arg\", \"checkConfigurationOptions\", \"false\",\n-                             \"-A\", 'nodes.\"{0}\".config.deployment.virtualbox.disks.{1}.baseImage'.format(self.name, disk_name),\n+                             \"-A\", \"nodes.{0}.config.deployment.virtualbox.disks.{1}.baseImage\".format(self.name, disk_name),\n                              \"-o\", \"{0}/vbox-image-{1}\".format(self.depl.tempdir, self.name)],\n                             capture_stdout=True).rstrip()\n                     self._logged_exec([\"VBoxManage\", \"clonehd\", base_image, disk_path])\n", "before": "+ self . depl . _eval_flags ( self . depl . nix_exprs ) + [ \"--arg\" , \"checkConfigurationOptions\" , \"false\" , \"-A\" , 'nodes.\"{0}\".config.deployment.virtualbox.disks.{1}.baseImage' . format ( self . name , disk_name ) , \"-o\" , \"{0}/vbox-image-{1}\" . format ( self . depl . tempdir , self . name ) ] ,", "after": "+ self . depl . _eval_flags ( self . depl . nix_exprs ) + [ \"--arg\" , \"checkConfigurationOptions\" , \"false\" , \"-A\" , \"nodes.{0}.config.deployment.virtualbox.disks.{1}.baseImage\" . format ( self . name , disk_name ) , \"-o\" , \"{0}/vbox-image-{1}\" . format ( self . depl . tempdir , self . name ) ] ,", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'nodes.\\\"{0}\\\".config.deployment.virtualbox.disks.{1}.baseImage'\", 3, 36, 3, 98], \"\\\"nodes.{0}.config.deployment.virtualbox.disks.{1}.baseImage\\\"\"]]"}
{"project": "nixops", "commit_sha": "dcdb8ed8bbdaea9b90750db28fd01c01dca34034", "parent_sha": "da100c44964746817160b0e46c70cdeafbcae8bc", "file_path": "nixops/backends/ec2.py", "project_url": "https://github.com/zalora/nixops", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -184,7 +184,7 @@ class EC2State(MachineState):\n                     val[_sd_to_xvd(dev)] = { 'disk': Function(\"pkgs.lib.mkStrict\", snap, call=True)}\n             val = { ('deployment', 'ec2', 'blockDeviceMapping'): val }\n         else:\n-            val = RawValue(\"{} # No backup found for id '{0}'\".format(backupid))\n+            val = RawValue(\"{{}} # No backup found for id '{0}'\".format(backupid))\n         return Function(\"{ config, pkgs, ... }\", val)\n \n \n", "before": "else : val = RawValue ( \"{} # No backup found for id '{0}'\" . format ( backupid ) )", "after": "else : val = RawValue ( \"{{}} # No backup found for id '{0}'\" . format ( backupid ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"{} # No backup found for id '{0}'\\\"\", 3, 28, 3, 63], \"\\\"{{}} # No backup found for id '{0}'\\\"\"]]"}
{"project": "nixops", "commit_sha": "a2718b65615ec4a71a0f819db5fa675632e62f34", "parent_sha": "267c400fd4e11766a0ccfa0f539745935ea3df15", "file_path": "nixops/util.py", "project_url": "https://github.com/zalora/nixops", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -217,7 +217,7 @@ def attr_property(name, default, type=str):\n     return property(get, set)\n \n \n-def create_key_pair(key_name=\"NixOps auto-generated key\", type=\"dsa\"):\n+def create_key_pair(key_name=\"NixOps auto-generated key\", type=\"ecdsa\"):\n     key_dir = tempfile.mkdtemp(prefix=\"nixops-tmp\")\n     res = subprocess.call([\"ssh-keygen\", \"-t\", type, \"-f\", key_dir + \"/key\", \"-N\", '', \"-C\", key_name],\n                           stdout=devnull)\n", "before": "def create_key_pair ( key_name = \"NixOps auto-generated key\" , type = \"dsa\" ) : key_dir = tempfile . mkdtemp ( prefix = \"nixops-tmp\" ) res = subprocess . call ( [ \"ssh-keygen\" , \"-t\" , type , \"-f\" , key_dir + \"/key\" , \"-N\" , '' , \"-C\" , key_name ] , stdout = devnull )", "after": "def create_key_pair ( key_name = \"NixOps auto-generated key\" , type = \"ecdsa\" ) : key_dir = tempfile . mkdtemp ( prefix = \"nixops-tmp\" ) res = subprocess . call ( [ \"ssh-keygen\" , \"-t\" , type , \"-f\" , key_dir + \"/key\" , \"-N\" , '' , \"-C\" , key_name ] , stdout = devnull )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"dsa\\\"\", 3, 64, 3, 69], \"\\\"ecdsa\\\"\"]]"}
{"project": "nixops", "commit_sha": "e6dfd68cab8a283308cba122d2923faf3c4f05df", "parent_sha": "cb11e898d982163a80a77dff9695c1b5acceece9", "file_path": "nixops/backends/virtualbox.py", "project_url": "https://github.com/zalora/nixops", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -168,7 +168,7 @@ class VirtualBoxState(MachineState):\n         if not self.vm_id:\n             self.log(\"creating VirtualBox VM...\")\n             vm_id = \"nixops-{0}-{1}\".format(self.depl.uuid, self.name)\n-            self._logged_exec([\"VBoxManage\", \"createvm\", \"--name\", vm_id, \"--ostype\", \"Linux\", \"--register\"])\n+            self._logged_exec([\"VBoxManage\", \"createvm\", \"--name\", vm_id, \"--ostype\", \"Linux_64\", \"--register\"])\n             self.vm_id = vm_id\n             self.state = self.STOPPED\n \n", "before": "self . _logged_exec ( [ \"VBoxManage\" , \"createvm\" , \"--name\" , vm_id , \"--ostype\" , \"Linux\" , \"--register\" ] )", "after": "self . _logged_exec ( [ \"VBoxManage\" , \"createvm\" , \"--name\" , vm_id , \"--ostype\" , \"Linux_64\" , \"--register\" ] )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"Linux\\\"\", 3, 87, 3, 94], \"\\\"Linux_64\\\"\"]]"}
{"project": "nixops", "commit_sha": "c2c205016c9d82def66b66878f4667a50972090c", "parent_sha": "77b2c66bec4d0b3b0eeababe9358e69a15591808", "file_path": "nixops/backends/virtualbox.py", "project_url": "https://github.com/zalora/nixops", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -168,7 +168,7 @@ class VirtualBoxState(MachineState):\n         if not self.vm_id:\n             self.log(\"creating VirtualBox VM...\")\n             vm_id = \"nixops-{0}-{1}\".format(self.depl.uuid, self.name)\n-            self._logged_exec([\"VBoxManage\", \"createvm\", \"--name\", vm_id, \"--ostype\", \"Linux_64\", \"--register\"])\n+            self._logged_exec([\"VBoxManage\", \"createvm\", \"--name\", vm_id, \"--ostype\", \"Linux26_64\", \"--register\"])\n             self.vm_id = vm_id\n             self.state = self.STOPPED\n \n", "before": "self . _logged_exec ( [ \"VBoxManage\" , \"createvm\" , \"--name\" , vm_id , \"--ostype\" , \"Linux_64\" , \"--register\" ] )", "after": "self . _logged_exec ( [ \"VBoxManage\" , \"createvm\" , \"--name\" , vm_id , \"--ostype\" , \"Linux26_64\" , \"--register\" ] )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"Linux_64\\\"\", 3, 87, 3, 97], \"\\\"Linux26_64\\\"\"]]"}
{"project": "django-fsm", "commit_sha": "649d2205c59e39c7a945342dbe06cea1cb2e8ffa", "parent_sha": "c2fb380a2f4ea53d48cb80b0e08660cfc2658221", "file_path": "django_fsm/__init__.py", "project_url": "https://github.com/yunojuno/django-fsm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -245,7 +245,7 @@ class FSMFieldMixin(object):\n         state_choices = kwargs.pop('state_choices', None)\n         choices = kwargs.get('choices', None)\n         if state_choices is not None and choices is not None:\n-            raise ValueError('Use one of choices or state_choces value')\n+            raise ValueError('Use one of choices or state_choices value')\n \n         if state_choices is not None:\n             choices = []\n", "before": "raise ValueError ( 'Use one of choices or state_choces value' )", "after": "raise ValueError ( 'Use one of choices or state_choices value' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'Use one of choices or state_choces value'\", 3, 30, 3, 72], \"'Use one of choices or state_choices value'\"]]"}
{"project": "shipyard", "commit_sha": "00379aa14033a9b54a9295fab461e78f7f630045", "parent_sha": "8ae225596f9124f7b8cf5cb25f5f36346ced2fd6", "file_path": "agent/views.py", "project_url": "https://github.com/mayflower/shipyard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -101,7 +101,7 @@ def images(request):\n     image_data = json.loads(request.body)\n     for i in image_data:\n         image, created = Image.objects.get_or_create(host=host,\n-                image_id=i.get('ID'))\n+                image_id=i.get('Id'))\n         image.repository = i.get('RepoTags')[0]\n         image.meta = json.dumps(image_data)\n         image.save()\n", "before": "image , created = Image . objects . get_or_create ( host = host , image_id = i . get ( 'ID' ) )", "after": "image , created = Image . objects . get_or_create ( host = host , image_id = i . get ( 'Id' ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'ID'\", 3, 32, 3, 36], \"'Id'\"]]"}
{"project": "stoq", "commit_sha": "753516ac84735e0ffa989beab341a8cdf516b3bb", "parent_sha": "f7f3b1ef62f15271ecc63a2e11e3d69292d28ae5", "file_path": "stoq/gui/application.py", "project_url": "https://github.com/bellini666/stoq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -133,7 +133,7 @@ class AppWindow(BaseAppWindow):\n         release_date = stoq.release_date\n         about.set_comments('Release Date: %s' %\n                            datetime.datetime(*release_date).strftime('%x'))\n-        about.set_copyright('Copyright (C) 2005 Async Open Source')\n+        about.set_copyright('Copyright (C) 2005, 2006 Async Open Source')\n \n         # Logo\n         icon_file = environ.find_resource('pixmaps', 'stoq_logo.png')\n", "before": "about . set_copyright ( 'Copyright (C) 2005 Async Open Source' )", "after": "about . set_copyright ( 'Copyright (C) 2005, 2006 Async Open Source' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'Copyright (C) 2005 Async Open Source'\", 3, 29, 3, 67], \"'Copyright (C) 2005, 2006 Async Open Source'\"]]"}
{"project": "gsutil", "commit_sha": "53f056d5305eabd95225c2f32617f366f9c5aeec", "parent_sha": "7f462da53f4a135f0ee44552beb8d158445c46d6", "file_path": "gslib/aclhelpers.py", "project_url": "https://github.com/zalora/gsutil", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -69,7 +69,7 @@ class AclChange(object):\n           'AllUsers': '^(AllUsers|All)$',\n           'Email': r'^.+@.+\\..+$',\n           'Id': r'^[0-9A-Fa-f]{64}$',\n-          'Domain': r'^[^@]+\\..+$',\n+          'Domain': r'^[^@]+\\.[^@]+$',\n           }\n       for type_string, regex in re_map.items():\n         if re.match(regex, text, re.IGNORECASE):\n", "before": "'Domain' : r'^[^@]+\\..+$' ,", "after": "'Domain' : r'^[^@]+\\.[^@]+$' ,", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:r'^[^@]+\\\\..+$'\", 3, 21, 3, 35], \"r'^[^@]+\\\\.[^@]+$'\"]]"}
{"project": "gsutil", "commit_sha": "e3226faeabc7e424442484355e27ed2861adcc59", "parent_sha": "a7a36ea6fbcd115ac373ffc3d4eb696825a78b25", "file_path": "gslib/tests/test_setmeta.py", "project_url": "https://github.com/zalora/gsutil", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -80,7 +80,7 @@ class TestSetMeta(testcase.GsUtilIntegrationTestCase):\n     def _Check1():\n       stdout = self.RunGsUtil(['ls', '-L', suri(objuri)], return_stdout=True)\n       stdout = stdout.decode('utf-8')\n-      self.assertIn(u'x-goog-meta-dessert:\\t\\tsouffl\u00e9', stdout)\n+      self.assertIn(u'x-goog-meta-dessert:\\tsouffl\u00e9', stdout)\n     _Check1()\n \n   def test_disallowed_header(self):\n", "before": "self . assertIn ( u'x-goog-meta-dessert:\\t\\tsouffl\u00e9',   tdout) ", "after": "self . assertIn ( u'x-goog-meta-dessert:\\tsouffl\u00e9',   tdout) ", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:u'x-goog-meta-dessert:\\\\t\\\\tsouffl\\u00e9',\", 3, 21, 3, 56], \"u'x-goog-meta-dessert:\\\\tsouffl\\u00e9',\"]]"}
{"project": "flask-oauthlib", "commit_sha": "7e0dcfa75bf44422bd191056af0e2b569e57a316", "parent_sha": "069b2f47adf9ea2df7f4e6894efe6573675dcb6e", "file_path": "flask_oauthlib/client.py", "project_url": "https://github.com/underdogio/flask-oauthlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -310,7 +310,7 @@ class OAuthRemoteApp(object):\n \n     @cached_property\n     def access_token_method(self):\n-        return self._get_property('access_token_method', 'GET')\n+        return self._get_property('access_token_method', 'POST')\n \n     @cached_property\n     def content_type(self):\n", "before": "return self . _get_property ( 'access_token_method' , 'GET' )", "after": "return self . _get_property ( 'access_token_method' , 'POST' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'GET'\", 3, 58, 3, 63], \"'POST'\"]]"}
{"project": "flask-oauthlib", "commit_sha": "78979c6a46472b933696f8a110b05726e7cd0f4b", "parent_sha": "32e799bf795f9e49f7bb85c0262b5af29a0fd9a4", "file_path": "example/github.py", "project_url": "https://github.com/underdogio/flask-oauthlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ def authorized():\n     resp = github.authorized_response()\n     if resp is None:\n         return 'Access denied: reason=%s error=%s' % (\n-            request.args['error_reason'],\n+            request.args['error'],\n             request.args['error_description']\n         )\n     session['github_token'] = (resp['access_token'], '')\n", "before": "return 'Access denied: reason=%s error=%s' % ( request . args [ 'error_reason' ] , request . args [ 'error_description' ] )", "after": "return 'Access denied: reason=%s error=%s' % ( request . args [ 'error' ] , request . args [ 'error_description' ] )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'error_reason'\", 3, 26, 3, 40], \"'error'\"]]"}
{"project": "librosa", "commit_sha": "4c8c5c2c47786ef95096512e4df3360193241a7a", "parent_sha": "49964152d714228c34fdcc7448ec9cb3f17a335c", "file_path": "librosa/core.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -614,7 +614,7 @@ def magphase(D):\n \n @cache\n def cqt(y, sr=22050, hop_length=512, fmin=None, n_bins=84,\n-        bins_per_octave=12, tuning=None, resolution=2, res_type='sinc_fastest',\n+        bins_per_octave=12, tuning=None, resolution=2, res_type='sinc_best',\n         aggregate=None, norm=2):\n", "before": "def cqt ( y , sr = 22050 , hop_length = 512 , fmin = None , n_bins = 84 , bins_per_octave = 12 , tuning = None , resolution = 2 , res_type = 'sinc_fastest' , aggregate = None , norm = 2 ) : ", "after": "def cqt ( y , sr = 22050 , hop_length = 512 , fmin = None , n_bins = 84 , bins_per_octave = 12 , tuning = None , resolution = 2 , res_type = 'sinc_best' , aggregate = None , norm = 2 ) : ", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'sinc_fastest'\", 3, 65, 3, 79], \"'sinc_best'\"]]"}
{"project": "librosa", "commit_sha": "bb02a94308ad1e8fe8ac7f335408abfc298316ae", "parent_sha": "53722e45c5149d544098766433e58beee8418571", "file_path": "librosa/util/utils.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -110,7 +110,7 @@ def valid_audio(y, mono=True):\n     ------\n     ValueError\n         If `y` fails to meet the following criteria:\n-            - `typebryce(y)` is `np.ndarray`\n+            - `type(y)` is `np.ndarray`\n             - `mono == True` and `y.ndim` is not 1\n             - `mono == False` and `y.ndim` is not 1 or 2\n             - `np.isfinite(y).all()` is not True\n", "before": "following criteria : - `typebryce(y)` is `np.ndarray`", "after": "following criteria : - `type(y)` is `np.ndarray`", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:`typebryce(y)`\", 3, 15, 3, 29], \"`type(y)`\"]]"}
{"project": "librosa", "commit_sha": "6ac27ed17e8290a4d0cf27ca5d6643794c3d6530", "parent_sha": "9955ebd675ee53514b7fef87ddaa85073b632e9b", "file_path": "librosa/core/audio.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -199,7 +199,7 @@ def to_mono(y):\n \n \n @cache\n-def resample(y, orig_sr, target_sr, res_type='sinc_fastest', fix=True,\n+def resample(y, orig_sr, target_sr, res_type='sinc_best', fix=True,\n              scipy_resample=False, **kwargs):\n", "before": "def resample ( y , orig_sr , target_sr , res_type = 'sinc_fastest' , fix = True , scipy_resample = False , ** kwargs ) : ", "after": "def resample ( y , orig_sr , target_sr , res_type = 'sinc_best' , fix = True , scipy_resample = False , ** kwargs ) : ", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'sinc_fastest'\", 3, 46, 3, 60], \"'sinc_best'\"]]"}
{"project": "librosa", "commit_sha": "e7d0fb6eba60db495771b23244b3bf4a34f2e996", "parent_sha": "2b4e246c38819b0d127c1104c9a06382abebd7d5", "file_path": "librosa/feature/utils.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -305,7 +305,7 @@ def sync(data, frames, aggregate=None, pad=True):\n     >>> librosa.display.specshow(librosa.logamplitude(cqt_med_sub**2,\n     ...                                               ref_power=np.max))\n     >>> plt.colorbar(format='%+2.0f dB')\n-    >>> plt.title('Sub-beat syncrhonous CQT power, '\n+    >>> plt.title('Sub-beat synchronous CQT power, '\n     ...           'shape={:s}'.format(cqt_med_sub.shape))\n     >>> plt.tight_layout()\n \n", "before": "plt . title ( 'Sub-beat syncrhonous CQT power, ' . . . 'shape={:s}' . format ( cqt_med_sub . shape ) )", "after": "plt . title ( 'Sub-beat synchronous CQT power, ' . . . 'shape={:s}' . format ( cqt_med_sub . shape ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'Sub-beat syncrhonous CQT power, '\", 3, 19, 3, 53], \"'Sub-beat synchronous CQT power, '\"]]"}
{"project": "stoq", "commit_sha": "18e8f9a9e64adfe1e9a42e183f4208bce4f6c965", "parent_sha": "432621154dfceef71f8dbd89125f707b1c5c11bf", "file_path": "stoqlib/gui/editors.py", "project_url": "https://github.com/bellini666/stoq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -83,7 +83,7 @@ class BaseEditorSlave(SlaveDelegate):\n         action needs to be executed when cancelling in the dialog. \"\"\"\n         return False\n \n-    def before_delete_items(self):\n+    def before_delete_items(self, items):\n         \"\"\"Redefine this when you need to remove data on database\n", "before": "cancelling in the dialog . \"\"\"\n         return False\n \n     def before_delete_items(self):\n         \"\"\" Redefine this when you need to remove data on database", "after": "cancelling in the dialog . \"\"\"\n         return False\n \n     def before_delete_items(self, items):\n         \"\"\" Redefine this when you need to remove data on database", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"\\\"\\\"\\n         return False\\n \\n     def before_delete_items(self):\\n         \\\"\\\"\\\"\", 0, 68, 4, 12], \"\\\"\\\"\\\"\\n         return False\\n \\n     def before_delete_items(self, items):\\n         \\\"\\\"\\\"\"]]"}
{"project": "blink-qt", "commit_sha": "01f56d5cd6148f3d7352d7ca48a379a1f5e77f42", "parent_sha": "569ee2b495024cd1a78af39727873bce58b9af6c", "file_path": "blink/presence.py", "project_url": "https://github.com/kogmbh/blink-qt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -374,7 +374,7 @@ class PresenceSubscriptionHandler(object):\n                 icon_url = unicode(service.icon) if service.icon else None\n \n                 if icon_url:\n-                    url, token, icon_hash = icon_url.partition('blink-icon')\n+                    url, token, icon_hash = icon_url.partition('#blink-icon')\n                     if token:\n                         if contact.icon and icon_hash == contact.icon.etag:\n                             # Fast path, icon hasn't changed\n", "before": "url , token , icon_hash = icon_url . partition ( 'blink-icon' )", "after": "url , token , icon_hash = icon_url . partition ( '#blink-icon' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'blink-icon'\", 3, 64, 3, 76], \"'#blink-icon'\"]]"}
{"project": "django-fsm", "commit_sha": "02190d27f180857ae9db380160a2ae9b405888c2", "parent_sha": "92b5bcd911b4abf89de833c9e5b87a616dd24fad", "file_path": "django_fsm/db/fields/fsmfield.py", "project_url": "https://github.com/yunojuno/django-fsm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,7 +25,7 @@ class FSMMeta(object):\n         if found == 0:\n             raise TypeError(\"No FSMField found in model\")\n         elif found > 1:\n-            raise TypeError(\"More than one FSMField found in model, please specify field name in transition decorator\")\n+            raise TypeError(\"More than one FSMField found in model\")\n         return fields[0]\n \n     @staticmethod\n", "before": "raise TypeError ( \"More than one FSMField found in model, please specify field name in transition decorator\" )", "after": "raise TypeError ( \"More than one FSMField found in model\" )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"More than one FSMField found in model, please specify field name in transition decorator\\\"\", 3, 29, 3, 119], \"\\\"More than one FSMField found in model\\\"\"]]"}
{"project": "django-fsm", "commit_sha": "96aa9b8e0323e729b8f17d44eb85baf3f50c89c9", "parent_sha": "0137b709088c98b874aeddc83cb29c20f130e60a", "file_path": "django_fsm/db/fields/fsmfield.py", "project_url": "https://github.com/yunojuno/django-fsm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -115,7 +115,7 @@ def transition(field=None, source='*', target=None, save=False, conditions=[]):\n     if field is None:\n-        warnings.warn(\"Non explicid field transition support going to be removed\", DeprecationWarning, stacklevel=2)\n+        warnings.warn(\"Non explicit field transition support going to be removed\", DeprecationWarning, stacklevel=2)\n     \n     # pylint: disable=C0111\n     def inner_transition(func):        \n", "before": "warnings . warn ( \"Non explicid field transition support going to be removed\" , DeprecationWarning , stacklevel = 2 )", "after": "warnings . warn ( \"Non explicit field transition support going to be removed\" , DeprecationWarning , stacklevel = 2 )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"Non explicid field transition support going to be removed\\\"\", 1, 23, 1, 82], \"\\\"Non explicit field transition support going to be removed\\\"\"]]"}
{"project": "librosa", "commit_sha": "fbfe6fc548f3892bcb3002bcc19b446947365d2f", "parent_sha": "846f598ff5e9af10c1db33943146bbe244c9f4ee", "file_path": "librosa/display.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -46,7 +46,7 @@ def specshow(X, sr=22050, hop_length=64, x_axis=None, y_axis=None, fmin=None, fm\n     kwargs['origin']        = kwargs.get('origin',          'lower')\n     kwargs['interpolation'] = kwargs.get('interpolation',   'nearest')\n \n-    kwargs['cmap']          = kwargs.get('cmap',            'Purples')\n+    kwargs['cmap']          = kwargs.get('cmap',            'OrRd')\n \n     axes = plt.imshow(X, **kwargs)\n \n", "before": "kwargs [ 'cmap' ] = kwargs . get ( 'cmap' , 'Purples' )", "after": "kwargs [ 'cmap' ] = kwargs . get ( 'cmap' , 'OrRd' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'Purples'\", 3, 61, 3, 70], \"'OrRd'\"]]"}
{"project": "librosa", "commit_sha": "b2a9474d2fab919a85e6566dfff636deb57162cd", "parent_sha": "5a9fdf82a7f35e5e901642f5051b21f2825fa72c", "file_path": "librosa/core.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -523,7 +523,7 @@ def note_to_midi(note):\n     Omap = {'#': 1, '': 0, 'b': -1, '!': -1}\n     \n     try:\n-        match = re.match('^(?P<note>[A-Ga-g])(?P<offset>[#b!]?)(?P<octave>[+-]?\\d+)$', note)\n+        match = re.match(r'^(?P<note>[A-Ga-g])(?P<offset>[#b!]?)(?P<octave>[+-]?\\d+)$', note)\n         \n         pitch = match.group('note').upper()\n         offset = Omap[match.group('offset')]\n", "before": "match = re . match ( '^(?P<note>[A-Ga-g])(?P<offset>[#b!]?)(?P<octave>[+-]?\\d+)$' , note )", "after": "match = re . match ( r'^(?P<note>[A-Ga-g])(?P<offset>[#b!]?)(?P<octave>[+-]?\\d+)$' , note )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'^(?P<note>[A-Ga-g])(?P<offset>[#b!]?)(?P<octave>[+-]?\\\\d+)$'\", 3, 26, 3, 86], \"r'^(?P<note>[A-Ga-g])(?P<offset>[#b!]?)(?P<octave>[+-]?\\\\d+)$'\"]]"}
{"project": "pysolr", "commit_sha": "17e9e7739da6f4d6798f8c9a774da8df9c2ff4b7", "parent_sha": "ee28b39324fa21a99842d297e313c1759d8adbd2", "file_path": "tests/test_client.py", "project_url": "https://github.com/acdha/pysolr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -301,7 +301,7 @@ class SolrTestCase(unittest.TestCase, SolrTestCaseMixin):\n \n     def test__send_request_to_bad_path(self):\n         # Test a non-existent URL:\n-        self.solr.url = 'http://127.0.0.1:567898/wahtever'\n+        self.solr.url = 'http://127.0.0.1:56789/wahtever'\n         self.assertRaises(SolrError, self.solr._send_request, 'get', 'select/?q=doc&wt=json')\n \n     def test_send_request_to_bad_core(self):\n", "before": "self . solr . url = 'http://127.0.0.1:567898/wahtever'", "after": "self . solr . url = 'http://127.0.0.1:56789/wahtever'", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'http://127.0.0.1:567898/wahtever'\", 3, 25, 3, 59], \"'http://127.0.0.1:56789/wahtever'\"]]"}
{"project": "ipython-sql", "commit_sha": "5174e5aff7d591f9e390bad6db0a752bc754020a", "parent_sha": "7f7e163d79e0652e352772734328ef99c85168e6", "file_path": "src/sql/run.py", "project_url": "https://github.com/KarolTx/ipython-sql", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -20,7 +20,7 @@ class ResultSet(list):\n     def __init__(self, sqlaproxy, sql, config):\n         self.keys = sqlaproxy.keys()\n         self.sql = sql\n-        self.limit = config.get('limit')\n+        self.limit = config.get('autolimit')\n         style_name = config.get('style', 'DEFAULT')\n         self.style = prettytable.__dict__[style_name.upper()]\n         if sqlaproxy.returns_rows:\n", "before": "self . limit = config . get ( 'limit' )", "after": "self . limit = config . get ( 'autolimit' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'limit'\", 3, 33, 3, 40], \"'autolimit'\"]]"}
{"project": "CloudBot", "commit_sha": "3522245b7a0b6b2109e344bd42720151361d17a6", "parent_sha": "c6fcdf56e2c260862334cdc41de4007f70f30b9a", "file_path": "cloudbot/util/pyexec.py", "project_url": "https://github.com/MrW24/CloudBot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ def eval_py(code, paste_multiline=True):\n     if \"Traceback (most recent call last):\" in output:\n         status = \"Python error: \"\n     else:\n-        status = \"Code executed sucessfully: \"\n+        status = \"Code executed successfully: \"\n \n     if \"\\n\" in output and paste_multiline:\n         return status + web.paste(output, 'py')\n", "before": "status = \"Code executed sucessfully: \"", "after": "status = \"Code executed successfully: \"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"Code executed sucessfully: \\\"\", 3, 18, 3, 47], \"\\\"Code executed successfully: \\\"\"]]"}
{"project": "CloudBot", "commit_sha": "aba7085a646db2f404bab7b639e71f1590685d40", "parent_sha": "68b9e26c78750a50c603f5c6ff32d6c5f402ad52", "file_path": "plugins/reddit.py", "project_url": "https://github.com/MrW24/CloudBot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -18,7 +18,7 @@ short_url = \"http://redd.it/{}\"\n \n \n def format_output(item, show_url=False):\n-    \"\"\" takes a reddit post and returns a formatted sting \"\"\"\n+    \"\"\" takes a reddit post and returns a formatted string \"\"\"\n     item[\"title\"] = formatting.truncate(item[\"title\"], 70)\n     item[\"link\"] = short_url.format(item[\"id\"])\n \n", "before": "\"\"\" takes a reddit post and returns a formatted sting \"\"\"", "after": "\"\"\" takes a reddit post and returns a formatted string \"\"\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"\\\"\\\" takes a reddit post and returns a formatted sting \\\"\\\"\\\"\", 3, 5, 3, 62], \"\\\"\\\"\\\" takes a reddit post and returns a formatted string \\\"\\\"\\\"\"]]"}
{"project": "RaspberryEcho", "commit_sha": "6dba38a1db357282fd242fbab5feb9a9fd447ed5", "parent_sha": "bdb02727fbca03d91df6acb1d2d1cbcc00db8d39", "file_path": "auth_web.py", "project_url": "https://github.com/ShawnsonDFW/RaspberryEcho", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -32,7 +32,7 @@ class Start(object):\n \t\turl = \"https://api.amazon.com/auth/o2/token\"\n \t\tr = requests.post(url, data = payload)\n \t\tresp = r.json()\n-\t\tline = 'refresh_token = {}'.format(resp['refresh_token'])\n+\t\tline = 'refresh_token = \"{}\"'.format(resp['refresh_token'])\n \t\twith open(\"creds.py\", 'a') as f:\n \t\t\tf.write(line)\n \t\treturn \"Success!, refresh token has been added to your creds file, you may now reboot the Pi <br>{}\".format(resp['refresh_token'])\n", "before": "line = 'refresh_token = {}' . format ( resp [ 'refresh_token' ] )", "after": "line = 'refresh_token = \"{}\"' . format ( resp [ 'refresh_token' ] )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'refresh_token = {}'\", 3, 10, 3, 30], \"'refresh_token = \\\"{}\\\"'\"]]"}
{"project": "mdtraj", "commit_sha": "535780f6117223ef0230cd6d88afd5f1dbc6508b", "parent_sha": "7f03d58595da406567409b0d414b125cac840118", "file_path": "MDTraj/geometry/distance.py", "project_url": "https://github.com/Eigenstate/mdtraj", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -61,7 +61,7 @@ def compute_distances(traj, atom_pairs, periodic=True, opt=True):\n-    xyz = ensure_type(traj.xyz, dtype=np.float32, ndim=3, name='taj.xyz', shape=(None, None, 3), warn_on_cast=False)\n+    xyz = ensure_type(traj.xyz, dtype=np.float32, ndim=3, name='traj.xyz', shape=(None, None, 3), warn_on_cast=False)\n     pairs = ensure_type(np.asarray(atom_pairs), dtype=np.int32, ndim=2, name='atom_pairs', shape=(None, 2), warn_on_cast=False)\n \n     if periodic is True and traj._have_unitcell:\n", "before": "xyz = ensure_type ( traj . xyz , dtype = np . float32 , ndim = 3 , name = 'taj.xyz' , shape = ( None , None , 3 ) , warn_on_cast = False )", "after": "xyz = ensure_type ( traj . xyz , dtype = np . float32 , ndim = 3 , name = 'traj.xyz' , shape = ( None , None , 3 ) , warn_on_cast = False )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'taj.xyz'\", 0, 64, 0, 73], \"'traj.xyz'\"]]"}
{"project": "htcondenser", "commit_sha": "29b11f6388b437e46bd9d8df564d55647c65c9e1", "parent_sha": "c39fad301e89d1b5400d3a869a020b982d0f4e43", "file_path": "htcondenser/core/common.py", "project_url": "https://github.com/kreczko/htcondenser", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ def check_dir_create(directory):\n     if not os.path.isdir(directory):\n         if os.path.abspath(directory).startswith('/hdfs'):\n-            check_call(['hadoop', 'fs', '-mkdir', '-p', os.path.abspath(directory).replace('/hdfs', '/')])\n+            check_call(['hadoop', 'fs', '-mkdir', '-p', os.path.abspath(directory).replace('/hdfs', '')])\n         else:\n             os.makedirs(directory)\n \n", "before": "check_call ( [ 'hadoop' , 'fs' , '-mkdir' , '-p' , os . path . abspath ( directory ) . replace ( '/hdfs' , '/' ) ] )", "after": "check_call ( [ 'hadoop' , 'fs' , '-mkdir' , '-p' , os . path . abspath ( directory ) . replace ( '/hdfs' , '' ) ] )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'/'\", 2, 101, 2, 104], \"''\"]]"}
{"project": "librosa", "commit_sha": "a92172a370b8273ddd8453ac9f8a61d03d9a5fce", "parent_sha": "1682f6984b636dc8813b185d1079d9355898979e", "file_path": "librosa/effects.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -239,7 +239,7 @@ def time_stretch(y, rate):\n     return y_stretch\n \n \n-def pitch_shift(y, sr, n_steps, bins_per_octave=12, res_type='kaiser_fast'):\n+def pitch_shift(y, sr, n_steps, bins_per_octave=12, res_type='kaiser_best'):\n", "before": "def pitch_shift ( y , sr , n_steps , bins_per_octave = 12 , res_type = 'kaiser_fast' ) : ", "after": "def pitch_shift ( y , sr , n_steps , bins_per_octave = 12 , res_type = 'kaiser_best' ) : ", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'kaiser_fast'\", 3, 62, 3, 75], \"'kaiser_best'\"]]"}
{"project": "PyMonopoly", "commit_sha": "0c012102e75ac25037c5f3326aa411601794ea77", "parent_sha": "8ebe95e4da63e4f0021a6d92d706563f0ce1388f", "file_path": "LIB/modules/GlobalFuncs.py", "project_url": "https://github.com/Kycko/PyMonopoly", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ def check_files():\n             create_init_file(FILE)\n def create_init_file(type):\n     if type == 'stats':\n-        data = ['0\\n' if x<3 else 'None 0 01.01.01 black\\n' for x in range(10)]\n+        data = ['0\\n' if x<3 else 'None 0 01.01.01 0\\n' for x in range(10)]\n         data = data + data\n     elif type == 'settings':\n         data = ('0\\n', 'Player 1\\n', '255\\n', '30\\n', '30\\n', '1\\n', '1\\n', '1\\n', '1\\n', '1.0\\n', '1\\n')\n", "before": "data = [ '0\\n' if x < 3 else 'None 0 01.01.01 black\\n' for x in range ( 10 ) ]", "after": "data = [ '0\\n' if x < 3 else 'None 0 01.01.01 0\\n' for x in range ( 10 ) ]", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'None 0 01.01.01 black\\\\n'\", 3, 35, 3, 60], \"'None 0 01.01.01 0\\\\n'\"]]"}
{"project": "qal", "commit_sha": "7a18e1e30ee65247b7a9169d27bad5c044567a90", "parent_sha": "15e96811eb05f6fa4bd11ae908d8c2fab162bd06", "file_path": "qal/dal/conversions.py", "project_url": "https://github.com/OptimalBPM/qal", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -104,7 +104,7 @@ def python_type_to_SQL_type(_python_type):\n     elif (_python_type == int):\n         return \"integer\"    \n     elif (_python_type == datetime):\n-        return \"timestamp\"\n+        return \"datetime\"\n     elif (_python_type == bool):\n         return \"boolean\"\n     else:\n", "before": "return \"timestamp\"", "after": "return \"datetime\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"timestamp\\\"\", 3, 16, 3, 27], \"\\\"datetime\\\"\"]]"}
{"project": "balcazapy", "commit_sha": "8f4cafc399cff0357e2f42e6efb8d7558fc640c0", "parent_sha": "10335ab9704507c18ec6805495cc3729a6a867e3", "file_path": "python/balcaza/t2types.py", "project_url": "https://github.com/jongiddy/balcazapy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -128,7 +128,7 @@ class IntegerType(T2FlowType):\n         if isinstance(inputType, IntegerType):\n             return self.integerValidator(inputType)\n         if isinstance(inputType, StringType):\n-            script = \"output = Integer.parseInt(String.trim(input));\\n\"\n+            script = \"output = Integer.parseInt(input.trim());\\n\"\n         elif isinstance(inputType, NumberType):\n             script = \"output = input.intValue();\\n\"\n         else:\n", "before": "script = \"output = Integer.parseInt(String.trim(input));\\n\"", "after": "script = \"output = Integer.parseInt(input.trim());\\n\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"output = Integer.parseInt(String.trim(input));\\\\n\\\"\", 3, 22, 3, 72], \"\\\"output = Integer.parseInt(input.trim());\\\\n\\\"\"]]"}
{"project": "mdtraj", "commit_sha": "fdd4965f60224664078eaf7e99b128c3b1ff4d2b", "parent_sha": "fdec410ae98f8d73085143799a1ab37a1a8bcec0", "file_path": "mdtraj/tests/test_trajectory.py", "project_url": "https://github.com/Eigenstate/mdtraj", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -586,7 +586,7 @@ def test_force_overwrite():\n                 fn = 'temp-2%s' % ext\n                 open(fn, 'w').close()\n                 assert_raises_regex(IOError,\n-                                    r'File {} exists.*'.format(fn),\n+                                    r'\"?{}\"?.*exists.*'.format(fn),\n                                     lambda: t_ref.save(fn, force_overwrite=False))\n             test_1.description = 'test_force_overwrite (1): %s' % ext\n             test_2.description = 'test_force_overwrite (2): %s' % ext\n", "before": "assert_raises_regex ( IOError , r'File {} exists.*' . format ( fn ) , lambda : t_ref . save ( fn , force_overwrite = False ) )", "after": "assert_raises_regex ( IOError , r'\"?{}\"?.*exists.*' . format ( fn ) , lambda : t_ref . save ( fn , force_overwrite = False ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:r'File {} exists.*'\", 3, 37, 3, 56], \"r'\\\"?{}\\\"?.*exists.*'\"]]"}
{"project": "qal", "commit_sha": "8172d4fef1cfd41afe0bc02bb9e62e9d40a1730a", "parent_sha": "7d829a63461a684daf3bf8450c998eef196b3f96", "file_path": "qal/sql/sql_utils.py", "project_url": "https://github.com/OptimalBPM/qal", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -182,7 +182,7 @@ def db_specific_datatype(value, DB):\n             result = unenumerate(['TEXT', 'VARCHAR', 'VARCHAR2(4000)', 'VARCHAR(3100)', 'varchar(max)'], DB)\n             \n     elif (value.lower() == \"float\"):\n-        result = unenumerate(['DOUBLE', 'double', 'FLOAT', 'Double', 'float'], DB)    \n+        result = unenumerate(['DOUBLE', 'double precision', 'FLOAT', 'Double', 'float'], DB)    \n     \n     elif (value.lower() == \"serial\"):\n         result = unenumerate(['INTEGER AUTO_INCREMENT', 'serial', 'integer','INT GENERATED ALWAYS AS IDENTITY', 'int IDENTITY(1,1)'], DB)\n", "before": "result = unenumerate ( [ 'DOUBLE' , 'double' , 'FLOAT' , 'Double' , 'float' ] , DB )", "after": "result = unenumerate ( [ 'DOUBLE' , 'double precision' , 'FLOAT' , 'Double' , 'float' ] , DB )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'double'\", 3, 41, 3, 49], \"'double precision'\"]]"}
{"project": "reportlab", "commit_sha": "50d5b94dc4b19a1e4a0de078cab4e7ddc7ea99d2", "parent_sha": "e4040f1d52373fae3fa0774f3af62831749e9fd1", "file_path": "reportlab/test/test_platypus_paraparser.py", "project_url": "https://github.com/eduardocereto/reportlab", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -72,7 +72,7 @@ class ParaParserTestCase(unittest.TestCase):\n         \"Numeric entities should be unescaped by parser\"\n         txt = u\"Hello &#169; copyright\"\n         fragList = ParaParser().parse(txt, self.style)[1]\n-        self.assertEquals(map(lambda x:x.text, fragList), [u'Hello ',u'\\xc2\\xa9',u' copyright'])\n+        self.assertEquals(map(lambda x:x.text, fragList), [u'Hello ',u'\\xa9',u' copyright'])\n \n     def testEscapedUnicode(self):\n         \"Escaped high-bit stuff should go straight through\"\n", "before": "self . assertEquals ( map ( lambda x : x . text , fragList ) , [ u'Hello ' , u'\\xc2\\xa9' , u' copyright' ] )", "after": "self . assertEquals ( map ( lambda x : x . text , fragList ) , [ u'Hello ' , u'\\xa9' , u' copyright' ] )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:u'\\\\xc2\\\\xa9'\", 3, 70, 3, 81], \"u'\\\\xa9'\"]]"}
{"project": "rq", "commit_sha": "7198b4568a2188a42b5079165f0917dc35d00845", "parent_sha": "0de225ec62fffc1f008fdee10e32afe45f7067a9", "file_path": "rq/worker.py", "project_url": "https://github.com/dronedeploy/rq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -392,7 +392,7 @@ class Worker(object):\n \n         did_perform_work = False\n         self.register_birth()\n-        self.log.info(\"RQ worker {0!r} started, version %s\".format(self.key, VERSION))\n+        self.log.info(\"RQ worker {0!r} started, version {1}\".format(self.key, VERSION))\n         self.set_state(WorkerStatus.STARTED)\n \n         try:\n", "before": "self . log . info ( \"RQ worker {0!r} started, version %s\" . format ( self . key , VERSION ) )", "after": "self . log . info ( \"RQ worker {0!r} started, version {1}\" . format ( self . key , VERSION ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"RQ worker {0!r} started, version %s\\\"\", 3, 23, 3, 60], \"\\\"RQ worker {0!r} started, version {1}\\\"\"]]"}
{"project": "mdtraj", "commit_sha": "0083a460baab10441cd76bacf217d5113e331eb9", "parent_sha": "36fadd2a7f2c4b4e2b31ad2ca95cee289dc235a5", "file_path": "mdtraj/core/topology.py", "project_url": "https://github.com/Eigenstate/mdtraj", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -641,7 +641,7 @@ class Topology(object):\n \n     @property\n     def n_residues(self):\n-        \"Get the number of residues in the Topology\"\n+        \"\"\"Get the number of residues in the Topology. \"\"\"\n         return len(self._residues)\n \n     def atom(self, index):\n", "before": "\"Get the number of residues in the Topology\"", "after": "\"\"\"Get the number of residues in the Topology. \"\"\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"Get the number of residues in the Topology\\\"\", 3, 9, 3, 53], \"\\\"\\\"\\\"Get the number of residues in the Topology. \\\"\\\"\\\"\"]]"}
{"project": "rq", "commit_sha": "1795e1ee531b95ba9235ae645703a954453db2bf", "parent_sha": "cd0230cae315d3dfc5ee3d8983f50388da323830", "file_path": "rq/job.py", "project_url": "https://github.com/dronedeploy/rq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -407,7 +407,7 @@ class Job(object):\n \n         self.created_at = to_date(as_text(obj.get('created_at')))\n         self.origin = as_text(obj.get('origin'))\n-        self.description = (as_text(obj.get('description')).decode('unicode_escape')\n+        self.description = (as_text(obj.get('description')).decode('utf-8')\n                             if obj.get('description') else None)\n         self.enqueued_at = to_date(as_text(obj.get('enqueued_at')))\n         self.ended_at = to_date(as_text(obj.get('ended_at')))\n", "before": "self . description = ( as_text ( obj . get ( 'description' ) ) . decode ( 'unicode_escape' ) if obj . get ( 'description' ) else None )", "after": "self . description = ( as_text ( obj . get ( 'description' ) ) . decode ( 'utf-8' ) if obj . get ( 'description' ) else None )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'unicode_escape'\", 3, 68, 3, 84], \"'utf-8'\"]]"}
{"project": "tribler", "commit_sha": "5ca98daae24931266333bfc26d110bb4dbf90923", "parent_sha": "0edf17039bb849bfc347e14388c5f96692f6c963", "file_path": "Tribler/Video/VLCWrapper.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -57,7 +57,7 @@ class VLCWrapper:\n             os.chdir(os.path.join(self.installdir,'vlc'))\r\n     \r\n         # Arno: 2007-05-11: Don't ask me why but without the \"--verbose=0\" vlc will ignore the key redef.\r\n-        params = [\"--verbose=2\"]\r\n+        params = [\"--verbose=0\"]\r\n         \r\n", "before": "params = [ \"--verbose=2\" ]", "after": "params = [ \"--verbose=0\" ]", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"--verbose=2\\\"\", 3, 19, 3, 32], \"\\\"--verbose=0\\\"\"]]"}
{"project": "tribler", "commit_sha": "39a4d7833985524847511f1896770d788040a25e", "parent_sha": "a63717714d4014f74e902c4207df0089a0a2c1e8", "file_path": "Tribler/Lang/lang.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -84,7 +84,7 @@ class Lang:\n         if (label == 'version'):\n             return version_id\n         if (label == 'build'):\n-            return \"Build 13892\"\n+            return \"Build 13893\"\n         if (label == 'build_date'):\n             return \"Nov 30, 2009\"\n         # see if it exists in 'user.lang'\n", "before": "return \"Build 13892\"", "after": "return \"Build 13893\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"Build 13892\\\"\", 3, 20, 3, 33], \"\\\"Build 13893\\\"\"]]"}
{"project": "Topologist", "commit_sha": "105081514d2b22a036bedfa9099df2eb65f14482", "parent_sha": "edc4cc7bd737993275e37a9aa11a628f3c0284c4", "file_path": "modules/generator.py", "project_url": "https://github.com/KenNewcomb/Topologist", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -59,7 +59,7 @@ def GROMACSAngles(angles, settings):\n \toutput_file.append(\"[ angles ]\")\n \toutput_file.append(\";\\ti\\tj\\tk\\tfunc\\tangle\\tforce.c\")\n \tfor angle in angles:\n-\t\toutput_file.append(\";\\t{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\".format(angle.atom1.index, angle.atom2.index, angle.atom3.index, 1, settings.getAngle(angle.atom1, angle.atom2, angle.atom3), settings.getAngleConstant(angle.atom1, angle.atom2, angle.atom3)))\n+\t\toutput_file.append(\"\\t{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\".format(angle.atom1.index, angle.atom2.index, angle.atom3.index, 1, settings.getAngle(angle.atom1, angle.atom2, angle.atom3), settings.getAngleConstant(angle.atom1, angle.atom2, angle.atom3)))\n \toutput_file.append(\"\")\n \n def GROMACSSystem(settings):\n", "before": "output_file . append ( \";\\t{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\" . format ( angle . atom1 . index , angle . atom2 . index , angle . atom3 . index , 1 , settings . getAngle ( angle . atom1 , angle . atom2 , angle . atom3 ) , settings . getAngleConstant ( angle . atom1 , angle . atom2 , angle . atom3 ) ) )", "after": "output_file . append ( \"\\t{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\" . format ( angle . atom1 . index , angle . atom2 . index , angle . atom3 . index , 1 , settings . getAngle ( angle . atom1 , angle . atom2 , angle . atom3 ) , settings . getAngleConstant ( angle . atom1 , angle . atom2 , angle . atom3 ) ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\";\\\\t{0}\\\\t{1}\\\\t{2}\\\\t{3}\\\\t{4}\\\\t{5}\\\"\", 3, 22, 3, 55], \"\\\"\\\\t{0}\\\\t{1}\\\\t{2}\\\\t{3}\\\\t{4}\\\\t{5}\\\"\"]]"}
{"project": "mwhois", "commit_sha": "541700015564cd42b14405aefa60ae64a1c55dd5", "parent_sha": "11b147bea8148707af49c06dc7acac21195da181", "file_path": "src/whomap.py", "project_url": "https://github.com/jrosco/mwhois", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -110,7 +110,7 @@ class WhoisServerMap(object):\n                                'nu': ['whois.nic.nu', '', 'not found', '', CONST.CCTLD_STANDARD],\n                                'nz': ['whois.srs.net.nz', '', '220 Available', '', CONST.CCTLD_STANDARD],\n                                'org': ['whois.publicinterestregistry.net', 'whois.domain.com', 'NOT FOUND',\n-                                       'WHOIS LIMIT EXCEEDED', CONST.TLD_STANDARD],\n+                                       'WHOIS LIMI|Lookup refused', CONST.TLD_STANDARD],\n                                'pl': ['whois.dns.pl', '', 'No information available', '', CONST.CCTLD_STANDARD],\n                                'pm': ['whois.nic.pm', '', '', '', CONST.CCTLD_STANDARD],\n                                'pr': ['whois.uprr.pr', '', '', '', CONST.CCTLD_STANDARD],\n", "before": "'org' : [ 'whois.publicinterestregistry.net' , 'whois.domain.com' , 'NOT FOUND' , 'WHOIS LIMIT EXCEEDED' , CONST . TLD_STANDARD ] ,", "after": "'org' : [ 'whois.publicinterestregistry.net' , 'whois.domain.com' , 'NOT FOUND' , 'WHOIS LIMI|Lookup refused' , CONST . TLD_STANDARD ] ,", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'WHOIS LIMIT EXCEEDED'\", 3, 40, 3, 62], \"'WHOIS LIMI|Lookup refused'\"]]"}
{"project": "RateMon", "commit_sha": "07d57576c9f0389b2cdc3087f7b5980d2cd14b0b", "parent_sha": "30a52457d1d35b9963867ef5c81662a091b8c112", "file_path": "ratemon/RateMonitor.py", "project_url": "https://github.com/cms-tsg-fog/RateMon", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -700,7 +700,7 @@ class RateMonitor:\n         # index_dir: The full path to the index.html file\n         # png_dir:   The relative path from the index.html file to the png_dir\n         try:\n-            htmlFile = open(index_dir+\"/index.html\",\"wb\")\n+            htmlFile = open(index_dir+\"/index.html\",\"w\")\n             htmlFile.write(\"<!DOCTYPE html>\\n\")\n             htmlFile.write(\"<html>\\n\")\n             htmlFile.write(\"<style>.image { float:left; margin: 5px; clear:justify; font-size: 6px; font-family: Verdana, Arial, sans-serif; text-align: center;}</style>\\n\")\n", "before": "htmlFile = open ( index_dir + \"/index.html\" , \"wb\" )", "after": "htmlFile = open ( index_dir + \"/index.html\" , \"w\" )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"wb\\\"\", 3, 53, 3, 57], \"\\\"w\\\"\"]]"}
{"project": "RateMon", "commit_sha": "3e377338deeb939b62b8e0a76522a6c2ac23d86a", "parent_sha": "8a0f0e9118fd1e1340a34761c567b418c1545c69", "file_path": "ratemon/RateMonitor.py", "project_url": "https://github.com/cms-tsg-fog/RateMon", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -700,7 +700,7 @@ class RateMonitor:\n         # index_dir: The full path to the index.html file\n         # png_dir:   The relative path from the index.html file to the png_dir\n         try:\n-            htmlFile = open(index_dir+\"/index.html\",\"wb\")\n+            htmlFile = open(index_dir+\"/index.html\",\"w\")\n             htmlFile.write(\"<!DOCTYPE html>\\n\")\n             htmlFile.write(\"<html>\\n\")\n             htmlFile.write(\"<style>.image { float:left; margin: 5px; clear:justify; font-size: 6px; font-family: Verdana, Arial, sans-serif; text-align: center;}</style>\\n\")\n", "before": "htmlFile = open ( index_dir + \"/index.html\" , \"wb\" )", "after": "htmlFile = open ( index_dir + \"/index.html\" , \"w\" )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"wb\\\"\", 3, 53, 3, 57], \"\\\"w\\\"\"]]"}
{"project": "tribler", "commit_sha": "a78c39092fc513aa1a23f34a7ebf03a29e9d8de0", "parent_sha": "d0e84e5b8e14683c6cf8990ce46c9fa896b6b2c5", "file_path": "Tribler/Main/vwxGUI/list_details.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -459,7 +459,7 @@ class TorrentDetails(AbstractDetails):\n         self.updateTrackersTab()\n \n     def OnUploadThumbsButtonClick(self, event):\n-        type_str = \"Pictures|*.png;*.jpeg;*.jpg | PNG files (*.png)|*.png | JPEG files (*.jpeg, *jpg)|*.jpeg;*.jpg\"\n+        type_str = \"Pictures (*.png, *.jpeg, *jpg)|*.png;*.jpeg;*.jpg\"\n         dialog = wx.FileDialog(self, \"Upload Thumbnails\", wildcard=type_str,\n             style=wx.FD_OPEN | wx.FD_FILE_MUST_EXIST | wx.FD_MULTIPLE)\n         extra_info = {'thumbnail-tempdir': None, 'thumbnail-file-list': []}\n", "before": "type_str = \"Pictures|*.png;*.jpeg;*.jpg | PNG files (*.png)|*.png | JPEG files (*.jpeg, *jpg)|*.jpeg;*.jpg\"", "after": "type_str = \"Pictures (*.png, *.jpeg, *jpg)|*.png;*.jpeg;*.jpg\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"Pictures|*.png;*.jpeg;*.jpg | PNG files (*.png)|*.png | JPEG files (*.jpeg, *jpg)|*.jpeg;*.jpg\\\"\", 3, 20, 3, 116], \"\\\"Pictures (*.png, *.jpeg, *jpg)|*.png;*.jpeg;*.jpg\\\"\"]]"}
{"project": "py-util", "commit_sha": "e0a8d0e0e9772e2634da29aecd824dabbc2b8f3b", "parent_sha": "164ea75279dd7dabd49bd95a38bcba82273a60d8", "file_path": "s/bin/gits.py", "project_url": "https://github.com/nathants/py-util", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -47,7 +47,7 @@ def _git_reset_head():\n @argh.named('d')\n def diff():\n     \"\"\"\n-    git diff for all repos in your search_dirs\n+    git diff for all files in the current repo\n     \"\"\"\n     with s.shell.climb_git_root():\n         _git_reset_head()\n", "before": "\"\"\"\n     git diff for all repos in your search_dirs\n     \"\"\"", "after": "\"\"\"\n     git diff for all files in the current repo\n     \"\"\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"\\\"\\\"\\n     git diff for all repos in your search_dirs\\n     \\\"\\\"\\\"\", 2, 5, 4, 8], \"\\\"\\\"\\\"\\n     git diff for all files in the current repo\\n     \\\"\\\"\\\"\"]]"}
{"project": "py-util", "commit_sha": "fba14a3731f169400f499a3bc04b689620dcd4c1", "parent_sha": "5296296152d6bb8e6b351bd13191c8f8cc5c0cda", "file_path": "s/data.py", "project_url": "https://github.com/nathants/py-util", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -124,4 +124,4 @@ def freeze(value):\n         return _ImmutableSeq(freeze(x) for x in value)\n     elif isinstance(value, set):\n         return _ImmutableSet(freeze(x) for x in value)\n-    raise ValueError('{} ({}) not immutalizable'.format(value, type(value)))\n+    raise ValueError('not immutalizable: {} ({})'.format(value, type(value)))\n", "before": "raise ValueError ( '{} ({}) not immutalizable' . format ( value , type ( value ) ) )", "after": "raise ValueError ( 'not immutalizable: {} ({})' . format ( value , type ( value ) ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'{} ({}) not immutalizable'\", 3, 22, 3, 49], \"'not immutalizable: {} ({})'\"]]"}
{"project": "tribler", "commit_sha": "8098cd8b887ab455a7b161d1112aa820072c563b", "parent_sha": "a69a22f0f280767b8a698a585e5ab2867dda278e", "file_path": "Tribler/Core/CacheDB/SqliteCacheDBHandler.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -542,7 +542,7 @@ class TorrentDBHandler(BasicDBHandler):\n                     sql_insert_files = \"INSERT OR IGNORE INTO TorrentFiles (torrent_id, path, length) VALUES (?,?,?)\"\n                     self._db.executemany(sql_insert_files, insert_files)\n             except:\n-                self._logger.error(\"Could not create a TorrentDef instance %s %s %s %s %s %s\", infohash, timestamp, name, files, trackers, extra_info)\n+                self._logger.error(\"Could not create a TorrentDef instance %r %r %r %r %r %r\", infohash, timestamp, name, files, trackers, extra_info)\n                 print_exc()\n \n     def addInfohash(self, infohash):\n", "before": "except : self . _logger . error ( \"Could not create a TorrentDef instance %s %s %s %s %s %s\" , infohash , timestamp , name , files , trackers , extra_info )", "after": "except : self . _logger . error ( \"Could not create a TorrentDef instance %r %r %r %r %r %r\" , infohash , timestamp , name , files , trackers , extra_info )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"Could not create a TorrentDef instance %s %s %s %s %s %s\\\"\", 3, 36, 3, 94], \"\\\"Could not create a TorrentDef instance %r %r %r %r %r %r\\\"\"]]"}
{"project": "tribler", "commit_sha": "19b41c3de4a65c5d92f44d09dfe12b41494f3b44", "parent_sha": "462b298a3ee8cab8b87e883116f4f25677286f42", "file_path": "Tribler/TrackerChecking/TorrentChecking.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -314,7 +314,7 @@ class TorrentChecking(Thread):\n         last_check = response['last_check']\n \n         # the torrent status logic, TODO: do it in other way\n-        self._logger.debug(\"TorrentChecking: Update result %d/%d for %s\", seeders, leechers, bin2str(infohash))\n+        self._logger.debug(\"TorrentChecking: Update result %s/%s for %s\", seeders, leechers, bin2str(infohash))\n \n         torrent_id = self._torrentdb.getTorrentID(infohash)\n         retries = self._torrentdb.getTorrentCheckRetries(torrent_id)\n", "before": "self . _logger . debug ( \"TorrentChecking: Update result %d/%d for %s\" , seeders , leechers , bin2str ( infohash ) )", "after": "self . _logger . debug ( \"TorrentChecking: Update result %s/%s for %s\" , seeders , leechers , bin2str ( infohash ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"TorrentChecking: Update result %d/%d for %s\\\"\", 3, 28, 3, 73], \"\\\"TorrentChecking: Update result %s/%s for %s\\\"\"]]"}
{"project": "py-util", "commit_sha": "6489b6a080f7f08b291921d598e818f9ba6e933d", "parent_sha": "4f75fe6ce7db138b57af1484be9cad4233a3b52b", "file_path": "s/shell.py", "project_url": "https://github.com/nathants/py-util", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -69,7 +69,7 @@ def _get_log_or_print(should_log):\n         if should_log:\n             # TODO this is dumb\n             import s.log\n-            if hasattr(s.log.setup, ''):\n+            if hasattr(s.log.setup, '_cached_value'):\n                 logging.info(x)\n             else:\n                 print(x)\n", "before": "if hasattr ( s . log . setup , '' ) : logging . info ( x ) else : print ( x )", "after": "if hasattr ( s . log . setup , '_cached_value' ) : logging . info ( x ) else : print ( x )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:''\", 3, 37, 3, 39], \"'_cached_value'\"]]"}
{"project": "tribler", "commit_sha": "b158e2b6be2fe1253c393c3d790634ebd7434477", "parent_sha": "6ca794c50c4e8d43097349b82eba2f2c0ff16ddb", "file_path": "Tribler/community/tunnel/Socks5/server.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ class SocksUDPConnection(DatagramProtocol):\n                     self._logger.debug(\n                         \"Circuit is not ready, dropping %d bytes to %s\", len(request.payload), request.destination)\n                 else:\n-                    self._logger.debug(\"Sending data over circuit destined for %s:%d\", *request.destination)\n+                    self._logger.debug(\"Sending data over circuit destined for %r:%r\", *request.destination)\n                     circuit.tunnel_data(request.destination, request.payload)\n             else:\n                 self._logger.debug(\"No support for fragmented data, dropping\")\n", "before": "else : self . _logger . debug ( \"Sending data over circuit destined for %s:%d\" , * request . destination )", "after": "else : self . _logger . debug ( \"Sending data over circuit destined for %r:%r\" , * request . destination )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"Sending data over circuit destined for %s:%d\\\"\", 3, 40, 3, 86], \"\\\"Sending data over circuit destined for %r:%r\\\"\"]]"}
{"project": "python-ivi", "commit_sha": "3ee389c49019b522a093ea948165e3b6695365d3", "parent_sha": "4efa4ae4f7d469760d087d985b2530b4d196b7f8", "file_path": "ivi/ivi.py", "project_url": "https://github.com/ianrrees/python-ivi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1649,7 +1649,7 @@ class Driver(DriverOperation, DriverIdentity, DriverUtility):\n             # ASRL::COM1,9600,8n1::INSTR\n             # ASRL::/dev/ttyUSB0,9600::INSTR\n             # ASRL::/dev/ttyUSB0,9600,8n1::INSTR\n-            m = re.match('^(?P<prefix>(?P<type>TCPIP|USB|GPIB|ASRL)\\d*)(::(?P<arg1>[^\\s:]+))?(::(?P<arg2>[^\\s:]+(\\[.+\\])?))?(::(?P<arg3>[^\\s:]+))?(::(?P<suffix>INSTR))?$', resource, re.I)\n+            m = re.match('^(?P<prefix>(?P<type>TCPIP|USB|GPIB|ASRL)\\d*)(::(?P<arg1>[^\\s:]+))?(::(?P<arg2>[^\\s:]+(\\[.+\\])?))?(::(?P<arg3>[^\\s:]+))?(::(?P<suffix>INSTR))$', resource, re.I)\n             if m is None:\n                 raise IOException('Invalid resource string')\n             \n", "before": "m = re . match ( '^(?P<prefix>(?P<type>TCPIP|USB|GPIB|ASRL)\\d*)(::(?P<arg1>[^\\s:]+))?(::(?P<arg2>[^\\s:]+(\\[.+\\])?))?(::(?P<arg3>[^\\s:]+))?(::(?P<suffix>INSTR))?$' , resource , re . I )", "after": "m = re . match ( '^(?P<prefix>(?P<type>TCPIP|USB|GPIB|ASRL)\\d*)(::(?P<arg1>[^\\s:]+))?(::(?P<arg2>[^\\s:]+(\\[.+\\])?))?(::(?P<arg3>[^\\s:]+))?(::(?P<suffix>INSTR))$' , resource , re . I )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'^(?P<prefix>(?P<type>TCPIP|USB|GPIB|ASRL)\\\\d*)(::(?P<arg1>[^\\\\s:]+))?(::(?P<arg2>[^\\\\s:]+(\\\\[.+\\\\])?))?(::(?P<arg3>[^\\\\s:]+))?(::(?P<suffix>INSTR))?$'\", 3, 26, 3, 171], \"'^(?P<prefix>(?P<type>TCPIP|USB|GPIB|ASRL)\\\\d*)(::(?P<arg1>[^\\\\s:]+))?(::(?P<arg2>[^\\\\s:]+(\\\\[.+\\\\])?))?(::(?P<arg3>[^\\\\s:]+))?(::(?P<suffix>INSTR))$'\"]]"}
{"project": "sendsay-api-python", "commit_sha": "22fc643c4e52fc7ec08659d79a06ad1d086129cf", "parent_sha": "9f805913ecddc43b7c8f890e10e6f6ddfeedf6f2", "file_path": "test/__init__.py", "project_url": "https://github.com/sendsay-ru/sendsay-api-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ class SendsayTestCase(unittest.TestCase):\n             self.kwargs['login'] = os.environ['SENDSAY_LOGIN']\n             self.kwargs['password'] = os.environ['SENDSAY_PASSWORD']\n         except KeyError:\n-            raise Exception(\"SENDSAY_LOGIN and SENDSAY_PASSWORD doesn't exists in environmental variables.\")\n+            raise Exception(\"SENDSAY_LOGIN and SENDSAY_PASSWORD should be exists in environmental variables.\")\n \n         if 'SENDSAY_SUBLOGIN' in os.environ:\n             self.kwargs['sublogin'] = os.environ['SENDSAY_SUBLOGIN']\n", "before": "except KeyError : raise Exception ( \"SENDSAY_LOGIN and SENDSAY_PASSWORD doesn't exists in environmental variables.\" )", "after": "except KeyError : raise Exception ( \"SENDSAY_LOGIN and SENDSAY_PASSWORD should be exists in environmental variables.\" )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"SENDSAY_LOGIN and SENDSAY_PASSWORD doesn't exists in environmental variables.\\\"\", 3, 29, 3, 108], \"\\\"SENDSAY_LOGIN and SENDSAY_PASSWORD should be exists in environmental variables.\\\"\"]]"}
{"project": "cerbero", "commit_sha": "bd6d6b3ef6a946df3d7657c97015b0e18a1d4cbe", "parent_sha": "4fb3394aefcd8de5868fc2bef5f9dd4ea64dc949", "file_path": "cerbero/packages/packagemaker.py", "project_url": "https://github.com/protonpopsicle/cerbero", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,7 +41,7 @@ class OSXPackage(PackagerBase):\n         PackagerBase.__init__(self, config, package, store)\n \n     def pack(self, output_dir, devel=True, force=False, version=None,\n-             target='0.15'):\n+             target='10.5'):\n         output_dir = os.path.realpath(output_dir)\n         if not os.path.exists(output_dir):\n             os.makedirs(output_dir)\n", "before": "def pack ( self , output_dir , devel = True , force = False , version = None , target = '0.15' ) : output_dir = os . path . realpath ( output_dir ) if not os . path . exists ( output_dir ) : os . makedirs ( output_dir )", "after": "def pack ( self , output_dir , devel = True , force = False , version = None , target = '10.5' ) : output_dir = os . path . realpath ( output_dir ) if not os . path . exists ( output_dir ) : os . makedirs ( output_dir )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'0.15'\", 3, 21, 3, 27], \"'10.5'\"]]"}
{"project": "pylinac", "commit_sha": "29acc38de2435b0a1811d8321ef0593a38954b25", "parent_sha": "04300114ecc66ad87044aeaed70e2aeba74cdaed", "file_path": "tests/test_flatsym.py", "project_url": "https://github.com/midamo/pylinac", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -95,7 +95,7 @@ class UnitTests(unittest.TestCase):\n         prof = self.img._get_profile('x', 'auto')\n \n         # varian\n-        for method in ('varian', 'point_difference'):\n+        for method in ('varian', 'point difference'):\n             symmetry, lt_edge, rt_edge, max_idx = self.img._get_symmetry(prof, method)\n             self.assertAlmostEqual(symmetry, 3.08, delta=0.01)\n             self.assertAlmostEqual(lt_edge, 393, delta=3)\n", "before": "for method in ( 'varian' , 'point_difference' ) : symmetry , lt_edge , rt_edge , max_idx = self . img . _get_symmetry ( prof , method ) self . assertAlmostEqual ( symmetry , 3.08 , delta = 0.01 ) self . assertAlmostEqual ( lt_edge , 393 , delta = 3 )", "after": "for method in ( 'varian' , 'point difference' ) : symmetry , lt_edge , rt_edge , max_idx = self . img . _get_symmetry ( prof , method ) self . assertAlmostEqual ( symmetry , 3.08 , delta = 0.01 ) self . assertAlmostEqual ( lt_edge , 393 , delta = 3 )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'point_difference'\", 3, 34, 3, 52], \"'point difference'\"]]"}
{"project": "pylinac", "commit_sha": "4ab6c373d75caaca4fb4e10f65ed2beb282622a2", "parent_sha": "324c5e120f657f33cb53bf0ed2fca20f1eaec8ba", "file_path": "tests/_test_all_starshots.py", "project_url": "https://github.com/midamo/pylinac", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -232,7 +232,7 @@ class TestImageBank(TestCase):\n                         future = exec.submit(run_star, filepath)\n                         futures.append(future)\n             for future in concurrent.futures.as_completed(futures):\n-                if future.result() != 'Sucess':\n+                if future.result() != 'Success':\n                     print(future.result())\n         end = time.time() - start\n         print('Processing of {} files took {}s'.format(len(futures), end))\n", "before": "if future . result ( ) != 'Sucess' : print ( future . result ( ) )", "after": "if future . result ( ) != 'Success' : print ( future . result ( ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'Sucess'\", 3, 39, 3, 47], \"'Success'\"]]"}
{"project": "tribler", "commit_sha": "eca83c712711ee4373b47bca409df390c2c1e466", "parent_sha": "36fa827fb0089730aed6e1d45d6d97c6eca841b1", "file_path": "Tribler/Core/RequestPolicy.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -68,7 +68,7 @@ class CommonRequestPolicy(AbstractRequestPolicy):\n     def isCrawler(self, permid):\n         \"\"\"\n         @param permid The permid of the sending peer.\n-        @return Whether of not the specified permid is a superpeer.\n+        @return Whether of not the specified permid is a crawler.\n         \"\"\"\n         return permid in self.session.lm.crawler_db.getCrawlers()\n \n", "before": "\"\"\"\n         @param permid The permid of the sending peer.\n         @return Whether of not the specified permid is a superpeer.\n         \"\"\"", "after": "\"\"\"\n         @param permid The permid of the sending peer.\n         @return Whether of not the specified permid is a crawler.\n         \"\"\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"\\\"\\\"\\n         @param permid The permid of the sending peer.\\n         @return Whether of not the specified permid is a superpeer.\\n         \\\"\\\"\\\"\", 1, 9, 4, 12], \"\\\"\\\"\\\"\\n         @param permid The permid of the sending peer.\\n         @return Whether of not the specified permid is a crawler.\\n         \\\"\\\"\\\"\"]]"}
{"project": "addon-sdk", "commit_sha": "2a952ceb6dfe39c3f0e20cf01b4a0e42c1e12d48", "parent_sha": "3650333be81a5a59bd9c7a7415a3e8e96264f7ab", "file_path": "python-lib/cuddlefish/tests/test_init.py", "project_url": "https://github.com/nmaier/addon-sdk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -45,7 +45,7 @@ class TestInit(unittest.TestCase):\n         init_run = initializer(None, [\"init\"], out, err)\n         out, err = out.getvalue(), err.getvalue()\n         self.failIfEqual(init_run,0)\n-        self.assertTrue(\"This tool must be run in an empty directory.\" in err)\n+        self.assertTrue(\"This command must be run in an empty directory.\" in err)\n \n     def test_initializer(self):\n         self.run_init_in_subdir(\"tmp_addon_sample\",self.do_test_init)\n", "before": "self . assertTrue ( \"This tool must be run in an empty directory.\" in err )", "after": "self . assertTrue ( \"This command must be run in an empty directory.\" in err )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"This tool must be run in an empty directory.\\\"\", 3, 25, 3, 71], \"\\\"This command must be run in an empty directory.\\\"\"]]"}
{"project": "addon-sdk", "commit_sha": "41e7b92e378783fd0c1080f57576793ccd01cf9f", "parent_sha": "7dd29a0002d979967e3db6148408d9ce4ff5316f", "file_path": "python-lib/cuddlefish/tests/test_server.py", "project_url": "https://github.com/nmaier/addon-sdk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ class UnprivilegedServerTests(unittest.TestCase):\n         self.assertEqual(self.request(''), '404 Not Found')\n \n     def test_ensure_index_returned_on_root_path(self):\n-        self.assertTrue('<html>' in self.request('/'))\n+        self.assertTrue('<html' in self.request('/'))\n \n if __name__ == '__main__':\n     unittest.main()\n", "before": "self . assertTrue ( '<html>' in self . request ( '/' ) )", "after": "self . assertTrue ( '<html' in self . request ( '/' ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'<html>'\", 3, 25, 3, 33], \"'<html'\"]]"}
{"project": "cerbero", "commit_sha": "af30b771eec96819d5cc56cee30f108f202dc3f2", "parent_sha": "eb20b358483c01fb4766bf07e01ae7bfed1bb247", "file_path": "cerbero/build/build.py", "project_url": "https://github.com/protonpopsicle/cerbero", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -228,7 +228,7 @@ class Autotools (MakefilesBase):\n         # Only use --disable-maintainer mode for real autotools based projects\n         if os.path.exists(os.path.join(self.make_dir, 'configure.in')) or\\\n                 os.path.exists(os.path.join(self.make_dir, 'configure.ac')):\n-            self.configure_tpl += \" --disable-maintainer-mode\"\n+            self.configure_tpl += \" --disable-maintainer-mode --disable-silent-rules \"\n \n         if self.autoreconf:\n             shell.call(self.autoreconf_sh, self.make_dir)\n", "before": "self . configure_tpl += \" --disable-maintainer-mode\"", "after": "self . configure_tpl += \" --disable-maintainer-mode --disable-silent-rules \"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\" --disable-maintainer-mode\\\"\", 3, 35, 3, 63], \"\\\" --disable-maintainer-mode --disable-silent-rules \\\"\"]]"}
{"project": "tstoolbox", "commit_sha": "5f19c304ce9582077df8fb2227d04fdee67f1330", "parent_sha": "002360e55b4b2c5d2e084ec37ac4440061e982af", "file_path": "tstoolbox/tsutils.py", "project_url": "https://github.com/timcera/tstoolbox", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -680,7 +680,7 @@ def open_local(filein):\n         return gzip.open(filein, 'rb')\n     if ext in ['.bz', '.bz2']:\n         return bz2.BZ2File(filein, 'rb')\n-    return open(filein, 'rb')\n+    return open(filein, 'r')\n \n \n def memory_optimize(tsd):\n", "before": "return open ( filein , 'rb' )", "after": "return open ( filein , 'r' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'rb'\", 3, 25, 3, 29], \"'r'\"]]"}
{"project": "tstoolbox", "commit_sha": "fc4018f86d878a806ad0dd07f960eb00b5676781", "parent_sha": "2dfac2bdcb1c305fdf3db6072246ed32155a72a7", "file_path": "tests/test_replace.py", "project_url": "https://github.com/timcera/tstoolbox", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ from . import capture\n class TestReplace(TestCase):\n     def setUp(self):\n         dindex = pd.date_range('2011-01-01T00:00:00', periods=26, freq='H')\n-        self.ats = pd.np.ones((26)).astype('float64')\n+        self.ats = pd.np.ones((26)).astype('float32')\n         self.ats = pd.DataFrame(self.ats,\n                                 index=dindex,\n                                 columns=['Value_with_missing_replace'])\n", "before": "self . ats = pd . np . ones ( ( 26 ) ) . astype ( 'float64' )", "after": "self . ats = pd . np . ones ( ( 26 ) ) . astype ( 'float32' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'float64'\", 3, 44, 3, 53], \"'float32'\"]]"}
{"project": "tribler", "commit_sha": "efe9f35d75173c5866aac0d2de3ec1004695f5ee", "parent_sha": "0f1cd0b89667f9a0933d4f99c020544202ecae61", "file_path": "Tribler/Main/vwxGUI/list_body.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1147,7 +1147,7 @@ class AbstractListBody():\n                 wx.CallLater(1000, self.Revert, revertList)\n \n         self.done = done\n-        self._logger.debug(\"List created %s rows of %s took %s done:\", len(self.vSizer.GetChildren()), len(self.data), time() - t1, self.done, time())\n+        self._logger.debug(\"List created %s rows of %s took %s done: %s %s\", len(self.vSizer.GetChildren()), len(self.data), time() - t1, self.done, time())\n \n     def HasItem(self, key):\n         return key in self.items\n", "before": "self . _logger . debug ( \"List created %s rows of %s took %s done:\" , len ( self . vSizer . GetChildren ( ) ) , len ( self . data ) , time ( ) - t1 , self . done , time ( ) )", "after": "self . _logger . debug ( \"List created %s rows of %s took %s done: %s %s\" , len ( self . vSizer . GetChildren ( ) ) , len ( self . data ) , time ( ) - t1 , self . done , time ( ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"List created %s rows of %s took %s done:\\\"\", 3, 28, 3, 70], \"\\\"List created %s rows of %s took %s done: %s %s\\\"\"]]"}
{"project": "tribler", "commit_sha": "441b08d7ccfdd1da4418a5d40d81e1d7309bd931", "parent_sha": "123d5e8159b6f7c99a6e1f32e59d078e3c2efb01", "file_path": "Tribler/Main/vwxGUI/SearchGridManager.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -491,7 +491,7 @@ class TorrentManager:\n \n                 self.bundle_mode = None\n                 self.searchkeywords = [kw for kw in wantkeywords if kw != '']\n-                self._logger.debug(\"TorrentSearchGridManager: keywords: %s ;time:% %s\", self.searchkeywords, time())\n+                self._logger.debug(\"TorrentSearchGridManager: keywords: %s; time: %s\", self.searchkeywords, time())\n \n                 self.filteredResults = 0\n \n", "before": "self . _logger . debug ( \"TorrentSearchGridManager: keywords: %s ;time:% %s\" , self . searchkeywords , time ( ) )", "after": "self . _logger . debug ( \"TorrentSearchGridManager: keywords: %s; time: %s\" , self . searchkeywords , time ( ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"TorrentSearchGridManager: keywords: %s ;time:% %s\\\"\", 3, 36, 3, 87], \"\\\"TorrentSearchGridManager: keywords: %s; time: %s\\\"\"]]"}
{"project": "Sentaku", "commit_sha": "feb032ad9ffe8099477e25ede67bd7b20def90bf", "parent_sha": "b19b0f33191bc94b9f4e4fc1fe723c65b94a7311", "file_path": "src/sentaku/implementation_handling.py", "project_url": "https://github.com/RedHatQE/Sentaku", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ class AttributeBasedImplementations(Mapping):\n         attribute_name = self.attribute_mapping[key]\n         result = getattr(self.holder, attribute_name, _NOT_GIVEN)\n         if result is _NOT_GIVEN:\n-            raise LookupError('{holder:r} has no attribute {name}'.format(\n+            raise LookupError('{holder!r} has no attribute {name}'.format(\n                 holder=self.holder,\n                 name=attribute_name,\n             ))\n", "before": "raise LookupError ( '{holder:r} has no attribute {name}' . format ( holder = self . holder , name = attribute_name , ) )", "after": "raise LookupError ( '{holder!r} has no attribute {name}' . format ( holder = self . holder , name = attribute_name , ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'{holder:r} has no attribute {name}'\", 3, 31, 3, 67], \"'{holder!r} has no attribute {name}'\"]]"}
{"project": "bt", "commit_sha": "56c54445b02257d95eaa6b124bdcf81118a71688", "parent_sha": "cc218c951f5e2ceecfa8133328d9bae4cb9d6859", "file_path": "bt/core.py", "project_url": "https://github.com/vfilimonov/bt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -334,7 +334,7 @@ class StrategyBase(Node):\n     @property\n     def fees(self):\n         \"\"\"\n-        TimeSeries of unallocated capital.\n+        TimeSeries of fees.\n         \"\"\"\n         # no stale check needed\n         return self._fees\n", "before": "\"\"\"\n         TimeSeries of unallocated capital.\n         \"\"\"", "after": "\"\"\"\n         TimeSeries of fees.\n         \"\"\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"\\\"\\\"\\n         TimeSeries of unallocated capital.\\n         \\\"\\\"\\\"\", 2, 9, 4, 12], \"\\\"\\\"\\\"\\n         TimeSeries of fees.\\n         \\\"\\\"\\\"\"]]"}
{"project": "CloudBot", "commit_sha": "d717292c135c9919ea4abf0b6ee227a5a293e93a", "parent_sha": "7b1cc2ff0e4cbfeb1ad8cb29dffc937d74266250", "file_path": "plugins/misc.py", "project_url": "https://github.com/MrW24/CloudBot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ def onjoin(paraml, conn=None, bot=None):\n # system info command\n @hook.command(autohelp=False)\n def system(inp):\n-    \".system -- retrieves information about the host system\"\n+    \".system -- Retrieves information about the host system.\"\n     python_version = platform.python_version()\n     os = platform.platform(aliased=True)\n     cpu = platform.machine()\n", "before": "\".system -- retrieves information about the host system\"", "after": "\".system -- Retrieves information about the host system.\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\".system -- retrieves information about the host system\\\"\", 3, 5, 3, 61], \"\\\".system -- Retrieves information about the host system.\\\"\"]]"}
{"project": "MATRIX", "commit_sha": "09774be9469e09f2611dcaf7e5341633156e70d3", "parent_sha": "be20eba7e483acce66d008bd1690e9d21a1db080", "file_path": "Execution/fabfile.py", "project_url": "https://github.com/cryptobiu/MATRIX", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -70,7 +70,7 @@ def run_protocol(config_file, args, executable_name, working_directory):\n         elif len(data['CloudProviders']) > 1:\n             regions = data['CloudProviders']['aws']['regions'] + data['CloudProviders']['scaleway']['regions']\n         elif 'servers' in data['CloudProviders']:\n-            regions = data['CloudProviders']['aws']['servers']['regions']\n+            regions = data['CloudProviders']['servers']['servers']['regions']\n         else:\n             regions = []\n \n", "before": "data [ 'CloudProviders' ] [ 'aws' ] [ 'servers' ] [ 'regions' ]", "after": "data [ 'CloudProviders' ] [ 'servers' ] [ 'servers' ] [ 'regions' ]", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'aws'\", 3, 46, 3, 51], \"'servers'\"]]"}
{"project": "pxm-manifest-specification", "commit_sha": "277b552f3d3a38b84c92f9045ce96affd2a26666", "parent_sha": "76fa4838e566e81cbd3ea9dc5fb14273cc123b17", "file_path": "create-manifest.py", "project_url": "https://github.com/mapbox/pxm-manifest-specification", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ class CustomType():\n                     assert datetime.datetime.strptime(value, '%Y')\n \n                 if re.fullmatch('^[0-9]{4}-[0-9]{2}-[0-9]{2}$', value):\n-                    assert datetime.datetime.strptime(value, '%Y%m%d')\n+                    assert datetime.datetime.strptime(value, '%Y-%m-%d')\n \n                 return value\n", "before": "assert datetime . datetime . strptime ( value , '%Y%m%d' )", "after": "assert datetime . datetime . strptime ( value , '%Y-%m-%d' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'%Y%m%d'\", 3, 62, 3, 70], \"'%Y-%m-%d'\"]]"}
{"project": "MacDaily", "commit_sha": "8f3998bf50bbb4465fa19699f4e2573fcdc2fca1", "parent_sha": "0ad2f8b3d165278a1b544eb9ec2dac37f1ac2386", "file_path": "src/api/help.py", "project_url": "https://github.com/JarryShaw/MacDaily", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -21,7 +21,7 @@ def help_(argv=None):\n     args = parse_args(argv)\n \n     if args.command is None:\n-        pth = os.path.join(ROOT, 'man/macdaily.1')\n+        pth = os.path.join(ROOT, 'man/macdaily.8')\n         os.execlp('man', 'man', pth)\n \n     command = args.command.strip().lower()\n", "before": "pth = os . path . join ( ROOT , 'man/macdaily.1' )", "after": "pth = os . path . join ( ROOT , 'man/macdaily.8' )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'man/macdaily.1'\", 3, 34, 3, 50], \"'man/macdaily.8'\"]]"}
{"project": "CloudBot", "commit_sha": "6bd692f34ac805e8e3e8e8624d2f39d2c2998e9a", "parent_sha": "ba6c2ae2c8041dcad85386b46a3afe05e73e040f", "file_path": "plugins/seen.py", "project_url": "https://github.com/MrW24/CloudBot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ def seen(inp, nick='', chan='', db=None, input=None):\n     if inp.lower() == nick.lower():\n         return \"Have you looked in a mirror lately?\"\n \n-    if not re.match(\"^[A-Za-z0-9_|.-\\]\\[]*$\", inp.lower()):\n+    if not re.match(\"^[A-Za-z0-9_|.\\-\\]\\[]*$\", inp.lower()):\n         return \"I can't look up that name, its impossible to use!\"\n \n     if not db_ready:\n", "before": "if not re . match ( \"^[A-Za-z0-9_|.-\\]\\[]*$\" , inp . lower ( ) ) : return \"I can't look up that name, its impossible to use!\"", "after": "if not re . match ( \"^[A-Za-z0-9_|.\\-\\]\\[]*$\" , inp . lower ( ) ) : return \"I can't look up that name, its impossible to use!\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"^[A-Za-z0-9_|.-\\\\]\\\\[]*$\\\"\", 3, 21, 3, 45], \"\\\"^[A-Za-z0-9_|.\\\\-\\\\]\\\\[]*$\\\"\"]]"}
{"project": "CloudBot", "commit_sha": "7474904e974d5b7e8ddfede7ae48135e7a420427", "parent_sha": "a5d5845faf37621fdffaecbfc130b7d2b5c19b1f", "file_path": "plugins/lmgtfy.py", "project_url": "https://github.com/MrW24/CloudBot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -6,7 +6,7 @@ from util import hook, web, http\n def lmgtfy(inp):\n     \"\"\"lmgtfy [phrase] - Posts a google link for the specified phrase\"\"\"\n \n-    link = \"http://lmgtfy.com/?q={}\".format(http.quote_plus(inp))\n+    link = u\"http://lmgtfy.com/?q={}\".format(http.quote_plus(inp))\n \n     try:\n         return web.isgd(link)\n", "before": "link = \"http://lmgtfy.com/?q={}\" . format ( http . quote_plus ( inp ) )", "after": "link = u\"http://lmgtfy.com/?q={}\" . format ( http . quote_plus ( inp ) )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"http://lmgtfy.com/?q={}\\\"\", 3, 12, 3, 37], \"u\\\"http://lmgtfy.com/?q={}\\\"\"]]"}
{"project": "CloudBot", "commit_sha": "df1023da55f88d9dffa05ca6456b4f896a0930c0", "parent_sha": "954ff2ad00728049b97d79a707d19dcda27b8d3d", "file_path": "plugins/minecraft_wiki.py", "project_url": "https://github.com/MrW24/CloudBot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,6 +24,6 @@ def mcwiki(inp):\n             summary = \" \".join(p.text_content().splitlines())\n             summary = re.sub(\"\\[\\d+\\]\", \"\", summary)\n             summary = text.truncate_str(summary, 200)\n-            return \"{} :: {}\".format(summary, url)\n+            return u\"{} :: {}\".format(summary, url)\n \n     return \"Unknown Error.\"\n", "before": "return \"{} :: {}\" . format ( summary , url )", "after": "return u\"{} :: {}\" . format ( summary , url )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"{} :: {}\\\"\", 3, 20, 3, 30], \"u\\\"{} :: {}\\\"\"]]"}
{"project": "ansible-bender", "commit_sha": "f3ba0e84c30704aa193088ce35225516441794d3", "parent_sha": "2a151cf3508f3a1e1de998914b80ebce43d8f8c4", "file_path": "ansible_bender/cli.py", "project_url": "https://github.com/TomasTomecek/ansible-bender", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -350,7 +350,7 @@ class CLI:\n         if log_lines:\n             print(\"\\n\".join(log_lines))\n         else:\n-            print(\"Sorry, the latest build has not got any log lines\")\n+            print(f\"There are no logs for build {build_id}\")\n \n     def _inspect(self):\n         build_id = self.args.BUILD_ID\n", "before": "print ( \"Sorry, the latest build has not got any log lines\" )", "after": "print ( f\"There are no logs for build {build_id}\" )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"Sorry, the latest build has not got any log lines\\\"\", 3, 19, 3, 70], \"f\\\"There are no logs for build {build_id}\\\"\"]]"}
{"project": "ptt-web-crawler", "commit_sha": "7a97e18fc59b3d560b2ea4e1ae945c142e5c30c4", "parent_sha": "b73ca084092b6ac7c2084170d1583f88686079a2", "file_path": "ptt_web_crawler/ptt_web_crawler/spiders/ptt_web_spider.py", "project_url": "https://github.com/afunTW/ptt-web-crawler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -215,7 +215,7 @@ class PttWebSpider(scrapy.Spider):\n \n         try:\n             ip = main_content.find(text=re.compile(u'\u203b \u767c\u4fe1\u7ad9:'))\n-            ip = re.search(r'[0-9]*.[0-9]*.[0-9]*.[0-9]*', ip).group()\n+            ip = re.search(r'[0-9]*\\.[0-9]*\\.[0-9]*\\.[0-9]*', ip).group()\n         except:\n             ip = \"None\"\n \n", "before": "ip = re . search ( r'[0-9]*.[0-9]*.[0-9]*.[0-9]*' , ip ) . group ( )", "after": "ip = re . search ( r'[0-9]*\\.[0-9]*\\.[0-9]*\\.[0-9]*' , ip ) . group ( )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:r'[0-9]*.[0-9]*.[0-9]*.[0-9]*'\", 3, 28, 3, 58], \"r'[0-9]*\\\\.[0-9]*\\\\.[0-9]*\\\\.[0-9]*'\"]]"}
{"project": "MHWorldData", "commit_sha": "1e53b2db6e7ed3824f6320547f4542c3db1d5494", "parent_sha": "5eea4aa3513a735b659b64d94b915eeb305c87ff", "file_path": "mhdata/build/sql.py", "project_url": "https://github.com/gatheringhallstudios/MHWorldData", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -133,7 +133,7 @@ def build_monsters(session : sqlalchemy.orm.Session, mhdata):\n \n             if 'alt' in weaknesses:\n                 monster.has_alt_weakness = True\n-                for key, value in weaknesses['normal'].items():\n+                for key, value in weaknesses['alt'].items():\n                     setattr(monster, 'alt_weakness_'+key, value)\n \n         # Save language data\n", "before": "for key , value in weaknesses [ 'normal' ] . items ( ) : setattr ( monster , 'alt_weakness_' + key , value )", "after": "for key , value in weaknesses [ 'alt' ] . items ( ) : setattr ( monster , 'alt_weakness_' + key , value )", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'normal'\", 3, 46, 3, 54], \"'alt'\"]]"}
{"project": "pegleg", "commit_sha": "c05f0ea5d971d7b2df7957e832ca504c221a78b2", "parent_sha": "2ea774a7442480a7d3c200d225e5a36a2ae8d912", "file_path": "tests/unit/test_utils.py", "project_url": "https://github.com/airshipit/pegleg", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -20,7 +20,7 @@ import random\n import uuid\n \n \n-def rand_name(name='', prefix='armada'):\n+def rand_name(name='', prefix='pegleg'):\n", "before": "def rand_name ( name = '' , prefix = 'armada' ) : ", "after": "def rand_name ( name = '' , prefix = 'pegleg' ) : ", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'armada'\", 3, 31, 3, 39], \"'pegleg'\"]]"}
{"project": "notify", "commit_sha": "c672ad0f37eeec83f9083b660b11d0f68815fc90", "parent_sha": "35ec0a2fa0e8a550aaae9157809d5f945eecde44", "file_path": "admin/app/main/views/service_settings.py", "project_url": "https://github.com/govau/notify", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -476,7 +476,7 @@ def service_set_sms_prefix(service_id):\n         'on' if current_service['prefix_sms'] else 'off'\n     ))\n \n-    form.enabled.label.text = 'Start all text messages with \u2018{}:\u2019'.format(current_service['name'])\n+    form.enabled.label.text = 'Start all text messages with \u2018{}\u2019:'.format(current_service['name'])\n \n     if form.validate_on_submit():\n         service_api_client.update_service(\n", "before": "form . enabled . label . text = 'Start all text messages with \u2018{}:\u2019'.for m at(cur r ent_service['na m e'])  ", "after": "form . enabled . label . text = 'Start all text messages with \u2018{}\u2019:'.for m at(cur r ent_service['na m e'])  ", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:'Start all text messages with \\u2018{}:\\u2019'.for\", 3, 31, 3, 71], \"'Start all text messages with \\u2018{}\\u2019:'.for\"]]"}
{"project": "qats", "commit_sha": "4ec0ddcc52051b34b878a6dc94b0f8df6cc8ac3e", "parent_sha": "6a15292022fd4be94da773122de3a638698c0bf3", "file_path": "qats/app/gui.py", "project_url": "https://github.com/dnvgl/qats", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -989,7 +989,7 @@ class Qats(QMainWindow):\n               \"Its main objective is to ease self-check, quality assurance and reporting.<br><br>\" \\\n               \"Import qats Python package and use the API when you need advanced features or want to extend it's \" \\\n               \"functionality.<br><br>\" \\\n-              \"Feature requests, technical queries and bug reports should be directed to the developers on \" \\\n+              \"Please send feature requests, technical queries and bug reports to the developers on \" \\\n               \"<a href='https://github.com/dnvgl/qats/issues'>Github</a>.<br><br>\" \\\n               \"ENJOY!\"\n \n", "before": "\"Its main objective is to ease self-check, quality assurance and reporting.<br><br>\" \"Import qats Python package and use the API when you need advanced features or want to extend it's \" \"functionality.<br><br>\" \"Feature requests, technical queries and bug reports should be directed to the developers on \" \"<a href='https://github.com/dnvgl/qats/issues'>Github</a>.<br><br>\" \"ENJOY!\"", "after": "\"Its main objective is to ease self-check, quality assurance and reporting.<br><br>\" \"Import qats Python package and use the API when you need advanced features or want to extend it's \" \"functionality.<br><br>\" \"Please send feature requests, technical queries and bug reports to the developers on \" \"<a href='https://github.com/dnvgl/qats/issues'>Github</a>.<br><br>\" \"ENJOY!\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"Feature requests, technical queries and bug reports should be directed to the developers on \\\"\", 3, 15, 3, 109], \"\\\"Please send feature requests, technical queries and bug reports to the developers on \\\"\"]]"}
{"project": "qats", "commit_sha": "a6aaae95b830640cd6920cc04cf5b4cf3c26527f", "parent_sha": "7c927a545deb750fbbacdcf6cbf36079f6e06e83", "file_path": "test/test_rainflow.py", "project_url": "https://github.com/dnvgl/qats", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -54,7 +54,7 @@ class TestRainflowCounting(unittest.TestCase):\n         \"\"\"\n         # load irregular 3-hour time series test rebin and mesh\n         tsfile = os.path.join(os.path.dirname(__file__), '..', 'data', 'simo_p_out.ts')\n-        self.irreg_series = TsDB.fromfile(tsfile).get(name='tension_2_qs').x\n+        self.irreg_series = TsDB.fromfile(tsfile).get(name='Tension_2_qs').x\n \n     def test_reversals(self):\n         \"\"\"\n", "before": "\"\"\"\n         # load irregular 3-hour time series test rebin and mesh\n         tsfile = os.path.join(os.path.dirname(__file__), '..', 'data', 'simo_p_out.ts')\n         self.irreg_series = TsDB.fromfile(tsfile).get(name='tension_2_qs').x\n \n     def test_reversals(self):\n         \"\"\"", "after": "\"\"\"\n         # load irregular 3-hour time series test rebin and mesh\n         tsfile = os.path.join(os.path.dirname(__file__), '..', 'data', 'simo_p_out.ts')\n         self.irreg_series = TsDB.fromfile(tsfile).get(name='Tension_2_qs').x\n \n     def test_reversals(self):\n         \"\"\"", "sstub_pattern": "CHANGE_STRING_LITERAL", "edit_script": "[[\"Update\", [\"string:\\\"\\\"\\\"\\n         # load irregular 3-hour time series test rebin and mesh\\n         tsfile = os.path.join(os.path.dirname(__file__), '..', 'data', 'simo_p_out.ts')\\n         self.irreg_series = TsDB.fromfile(tsfile).get(name='tension_2_qs').x\\n \\n     def test_reversals(self):\\n         \\\"\\\"\\\"\", 0, 9, 6, 12], \"\\\"\\\"\\\"\\n         # load irregular 3-hour time series test rebin and mesh\\n         tsfile = os.path.join(os.path.dirname(__file__), '..', 'data', 'simo_p_out.ts')\\n         self.irreg_series = TsDB.fromfile(tsfile).get(name='Tension_2_qs').x\\n \\n     def test_reversals(self):\\n         \\\"\\\"\\\"\"]]"}
{"project": "s3cmd", "commit_sha": "a845140fd7f3dc0301299faa376e1fb750f7ec4e", "parent_sha": "23d133a2f715dc684b31604ce2d4525ebd50213c", "file_path": "S3/Exceptions.py", "project_url": "https://github.com/slackhq/s3cmd", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ class S3Error (S3Exception):\n         if response.has_key(\"headers\"):\n             for header in response[\"headers\"]:\n                 debug(\"HttpHeader: %s: %s\" % (header, response[\"headers\"][header]))\n-        if response.has_key(\"data\"):\n+        if response.has_key(\"data\") and response[\"data\"]:\n             tree = getTreeFromXml(response[\"data\"])\n             error_node = tree\n             if not error_node.tag == \"Error\":\n", "before": "if response . has_key ( \"data\" ) : tree = getTreeFromXml ( response [ \"data\" ] ) error_node = tree if not error_node . tag == \"Error\" : ", "after": "if response . has_key ( \"data\" ) and response [ \"data\" ] : tree = getTreeFromXml ( response [ \"data\" ] ) error_node = tree if not error_node . tag == \"Error\" : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 46], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 36], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"subscript\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:response\", \"T\"], 0], [\"Insert\", \"N1\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:\\\"data\\\"\", \"T\"], 2], [\"Insert\", \"N1\", [\"]:]\", \"T\"], 3]]"}
{"project": "trac", "commit_sha": "a46c0665e7a54d605327fc86bf0287924690ed0a", "parent_sha": "381d415d2e4f9f19b5e21c4a0d773699e49a0366", "file_path": "trac/util.py", "project_url": "https://github.com/arielnetworks/trac", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -162,8 +162,8 @@ def shorten_line(text, maxlen = 75):\n     if not text:\n         return ''\n     i = text.find('[[BR]]')\n-    if i < maxlen:\n-\t    shortline = text[:i]+' ...'\n+    if i > -1 and i < maxlen:\n+        shortline = text[:i]+' ...'\n     elif len(text) < maxlen:\n         shortline = text\n     else:\n", "before": "if i < maxlen : shortline = text [ : i ] + ' ...' elif len ( text ) < maxlen : shortline = text else : ", "after": "if i > - 1 and i < maxlen : shortline = text [ : i ] + ' ...' elif len ( text ) < maxlen : shortline = text else : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 7, 10], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 18], 2], [\"Insert\", \"N1\", [\"identifier:i\", \"T\"], 0], [\"Insert\", \"N1\", [\">:>\", \"T\"], 1], [\"Insert\", \"N1\", [\"unary_operator\", \"N2\"], 2], [\"Insert\", \"N2\", [\"-:-\", \"T\"], 0], [\"Insert\", \"N2\", [\"integer:1\", \"T\"], 1]]"}
{"project": "django-session-security", "commit_sha": "37f6c5f87c3a560cf67a7b428a2fd3b6aefb972e", "parent_sha": "7a6eba351ce4c3f9d94fe50a8d65afbc2173f3c9", "file_path": "session_security/middleware.py", "project_url": "https://github.com/precond/django-session-security", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,7 +35,7 @@ class SessionSecurityMiddleware(object):\n         self.update_last_activity(request, now)\n \n         delta = now - get_last_activity(request.session)\n-        if delta.seconds >= EXPIRE_AFTER:\n+        if delta.seconds >= EXPIRE_AFTER and delta.days >= 0:\n             logout(request)\n         elif request.path not in PASSIVE_URLS:\n             set_last_activity(request.session, now)\n", "before": "if delta . seconds >= EXPIRE_AFTER : logout ( request ) elif request . path not in PASSIVE_URLS : set_last_activity ( request . session , now )", "after": "if delta . seconds >= EXPIRE_AFTER and delta . days >= 0 : logout ( request ) elif request . path not in PASSIVE_URLS : set_last_activity ( request . session , now )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 52], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 41], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\">=:>=\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:delta\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:days\", \"T\"], 2]]"}
{"project": "dexy", "commit_sha": "65d1c5c7ee307b78dc18011893e48e744bb353bb", "parent_sha": "170a7d465e84db581de26f38e4c7a82269c82800", "file_path": "dexy/data.py", "project_url": "https://github.com/mojavelinux/dexy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -174,7 +174,7 @@ class Generic(Data):\n         \"\"\"\n         Attempts to load data using a JSON parser, returning whatever objects are defined in the JSON.\n         \"\"\"\n-        if self._data:\n+        if self._data and isinstance(self._data, basestring):\n             return dexy.utils.parse_json(self._data)\n         else:\n             with open(self.storage.data_file(), \"r\") as f:\n", "before": "if self . _data : return dexy . utils . parse_json ( self . _data ) else : with open ( self . storage . data_file ( ) , \"r\" ) as f : ", "after": "if self . _data and isinstance ( self . _data , basestring ) : return dexy . utils . parse_json ( self . _data ) else : with open ( self . storage . data_file ( ) , \"r\" ) as f : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 59], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 12, 3, 22], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:isinstance\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:basestring\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4], [\"Insert\", \"N3\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:_data\", \"T\"], 2]]"}
{"project": "gitinspector", "commit_sha": "88c01e62ed4b0e62597960eda88da412e10c5375", "parent_sha": "f4c3285cb89f63ef06d5672e99dc1ecf7666d7c1", "file_path": "changes.py", "project_url": "https://github.com/hugorodgerbrown/gitinspector", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -116,7 +116,7 @@ class Changes:\n \t\t\t\t\tfilediff = FileDiff(i)\n \t\t\t\t\tcommit.add_filediff(filediff)\n \n-\t\tif interval.has_interval():\n+\t\tif interval.has_interval() and len(self.commits) > 0:\n \t\t\tinterval.set_ref(self.commits[0].sha)\n \n \tdef get_commits(self):\n", "before": "if interval . has_interval ( ) : interval . set_ref ( self . commits [ 0 ] . sha )", "after": "if interval . has_interval ( ) and len ( self . commits ) > 0 : interval . set_ref ( self . commits [ 0 ] . sha )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 3, 4, 41], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 6, 3, 29], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\">:>\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:commits\", \"T\"], 2]]"}
{"project": "django-devserver", "commit_sha": "4a9e8f76de6b9003d495f6f784a1706a6c14355a", "parent_sha": "99d9a0fe63ed954d7f90653c8a8948a64483509d", "file_path": "devserver/modules/cache.py", "project_url": "https://github.com/nealtodd/django-devserver", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ class CacheSummaryModule(DevServerModule):\n         hits = stats.get_total_hits('cache')\n         misses = stats.get_total_misses_for_function('cache', cache.get) + stats.get_total_misses_for_function('cache', cache.get_many)\n \n-        if calls:\n+        if calls and (hits or misses):\n             ratio = int(hits / float(misses + hits) * 100)\n         else:\n             ratio = 100\n", "before": "if calls : ratio = int ( hits / float ( misses + hits ) * 100 ) else : ratio = 100", "after": "if calls and ( hits or misses ) : ratio = int ( hits / float ( misses + hits ) * 100 ) else : ratio = 100", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 24], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:calls\", 3, 12, 3, 17], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"parenthesized_expression\", \"N1\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"boolean_operator\", \"N2\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:hits\", \"T\"], 0], [\"Insert\", \"N2\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:misses\", \"T\"], 2]]"}
{"project": "django-devserver", "commit_sha": "c96f993bda2c553a2afb5a1c9214b7806594bb6b", "parent_sha": "a0084289693f666cb46dcd10e58203c9c9859348", "file_path": "devserver/modules/sql.py", "project_url": "https://github.com/nealtodd/django-devserver", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -81,7 +81,7 @@ class DatabaseStatTracker(DatabaseStatTracker):\n \n             if self.logger and (not settings.DEVSERVER_SQL_MIN_DURATION\n                     or duration > settings.DEVSERVER_SQL_MIN_DURATION):\n-                if self.cursor.rowcount >= 0:\n+                if self.cursor.rowcount >= 0 and message is not None:\n                     self.logger.debug('Found %s matching rows', self.cursor.rowcount, duration=duration)\n \n             if not (debug_toolbar or django_settings.DEBUG):\n", "before": "if self . cursor . rowcount >= 0 : self . logger . debug ( 'Found %s matching rows' , self . cursor . rowcount , duration = duration )", "after": "if self . cursor . rowcount >= 0 and message is not None : self . logger . debug ( 'Found %s matching rows' , self . cursor . rowcount , duration = duration )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 4, 105], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 45], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:message\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 2], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 3]]"}
{"project": "stoq", "commit_sha": "7217df409f230b6b230cc0741f9a84ebfd397d5a", "parent_sha": "93c45112a83eaee5dfe056c17e2669670702fb9e", "file_path": "stoqlib/gui/base/editors.py", "project_url": "https://github.com/bellini666/stoq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -169,7 +169,7 @@ class BaseEditor(BaseEditorSlave):\n         if self.title:\n             return self.title\n         if model:\n-            if self.model_name:\n+            if self.model_name and not self.edit_mode:\n                 return _('Add %s') % self.model_name\n             model_attr = self.get_title_model_attribute(model)\n             return _('Edit \"%s\" Details') % model_attr\n", "before": "if self . model_name : return _ ( 'Add %s' ) % self . model_name", "after": "if self . model_name and not self . edit_mode : return _ ( 'Add %s' ) % self . model_name", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 53], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 16, 3, 31], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 1], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:edit_mode\", \"T\"], 2]]"}
{"project": "blink-qt", "commit_sha": "0e7148b5fb7a2ec9fe32ceed0a099a3ec8d400b5", "parent_sha": "3cb4f90bde4c3ceb7da1507e373de24ef9bf39ad", "file_path": "blink/logging.py", "project_url": "https://github.com/kogmbh/blink-qt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -106,7 +106,7 @@ class LogManager(object):\n         self._siptrace_packet_count = 0\n         self.event_queue = EventQueue(handler=self._process_notification, name='Log handling')\n         self.event_queue.start()\n-        while settings.logs.trace_notifications and self.notification_queue.notifications:\n+        while settings.logs.trace_notifications and self.notification_queue and self.notification_queue.notifications:\n             notification = self.notification_queue.notifications.popleft()\n             self.handle_notification(notification)\n         self.notification_queue = None\n", "before": "while settings . logs . trace_notifications and self . notification_queue . notifications : notification = self . notification_queue . notifications . popleft ( ) self . handle_notification ( notification )", "after": "while settings . logs . trace_notifications and self . notification_queue and self . notification_queue . notifications : notification = self . notification_queue . notifications . popleft ( ) self . handle_notification ( notification )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 15, 3, 90], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", [\"boolean_operator\", 3, 15, 3, 90], [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 15, 3, 48], 0], [\"Move\", \"N0\", [\"and:and\", 3, 49, 3, 52], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:notification_queue\", \"T\"], 2]]"}
{"project": "gsutil", "commit_sha": "0f57b26863e4a48386d16d8ee13573061145fdfe", "parent_sha": "41aaaddeb61eff9d5adf70a75271dae0324cb545", "file_path": "gslib/commands/rm.py", "project_url": "https://github.com/zalora/gsutil", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -212,7 +212,7 @@ class RmCommand(Command):\n     # perform requests with sequential function calls in current process.\n     self.Apply(_RemoveFunc, name_expansion_iterator, _RemoveExceptionHandler)\n \n-    if not self.everything_removed_okay:\n+    if not self.everything_removed_okay and not continue_on_error:\n       raise CommandException('Some files could not be removed.')\n \n     # If this was a gsutil rm -r command covering any bucket subdirs,\n", "before": "if not self . everything_removed_okay : raise CommandException ( 'Some files could not be removed.' )", "after": "if not self . everything_removed_okay and not continue_on_error : raise CommandException ( 'Some files could not be removed.' )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 8, 3, 40], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 12, 3, 40], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"identifier:continue_on_error\", \"T\"], 1]]"}
{"project": "django-voice", "commit_sha": "f055fbb38ce2b334fd06e3f831185fc06e58ffde", "parent_sha": "d62c4127973ff6d3a524b053d16fa8031bd0d12e", "file_path": "djangovoice/views.py", "project_url": "https://github.com/linibou/django-voice", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -90,7 +90,7 @@ class FeedbackListView(ListView):\n             f_filters.update(dict(private=False))\n             f_showpriv = True\n \n-        if f_showpriv:\n+        if f_showpriv and self.request.user.is_authenticated():\n             # Show everyone's public discussions and user's own private discussions\n             queryset = self.model.objects.filter(Q(**f_filters) | Q(user=self.request.user, private=True)).order_by('-vote_score', '-created')\n         else:\n", "before": "if f_showpriv : queryset = self . model . objects . filter ( Q ( ** f_filters ) | Q ( user = self . request . user , private = True ) ) . order_by ( '-vote_score' , '-created' ) else : ", "after": "if f_showpriv and self . request . user . is_authenticated ( ) : queryset = self . model . objects . filter ( Q ( ** f_filters ) | Q ( user = self . request . user , private = True ) ) . order_by ( '-vote_score' , '-created' ) else : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 14], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:f_showpriv\", 3, 12, 3, 22], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:is_authenticated\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"):)\", \"T\"], 1], [\"Insert\", \"N4\", [\"attribute\", \"N5\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:user\", \"T\"], 2], [\"Insert\", \"N5\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N5\", [\".:.\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:request\", \"T\"], 2]]"}
{"project": "PyMonopoly", "commit_sha": "e00e8b0267e08c810cedb0b22c000954fa7c7e98", "parent_sha": "bc70f13a7e72b2ee7e5516cc5faf6d913a54095d", "file_path": "LIB/modules/MenuItems.py", "project_url": "https://github.com/Kycko/PyMonopoly", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -188,7 +188,7 @@ class Tooltip():\n             ##--- Buy cost\n             if self.number != 20:\n                 color = self.choose_color(0, cell_state + bool(CELL.owner))\n-                if CELL.owner:\n+                if CELL.group in range(9) and CELL.owner:\n                     text = Globals.TRANSLATION[97]\n                     price = str(CELL.build_cost)\n                 else:\n", "before": "if CELL . owner : text = Globals . TRANSLATION [ 97 ] price = str ( CELL . build_cost ) else : ", "after": "if CELL . group in range ( 9 ) and CELL . owner : text = Globals . TRANSLATION [ 97 ] price = str ( CELL . build_cost ) else : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 6, 22], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 20, 3, 30], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"call\", \"N3\"], 2], [\"Insert\", \"N2\", [\"identifier:CELL\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:group\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:range\", \"T\"], 0], [\"Insert\", \"N3\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"integer:9\", \"T\"], 1], [\"Insert\", \"N4\", [\"):)\", \"T\"], 2]]"}
{"project": "tekka", "commit_sha": "3e94321ab9e42be12fb285eb0277adc950a22fd9", "parent_sha": "3ffba3c5a6cedfb9f813e56548a5520c6b887d29", "file_path": "commands.py", "project_url": "https://github.com/sushi-irc/tekka", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -528,7 +528,7 @@ def parseInput(text):\n \t\tif text[0] == \"/\":\n \t\t\ttext = text[1:]\n \n-\t\tif not channelTab.joined:\n+\t\tif channelTab.is_channel() and not channelTab.joined:\n \t\t\twarnNotJoined(channelTab)\n \n \t\tcom.sendMessage(serverTab.name, channelTab.name, text)\n", "before": "if not channelTab . joined : warnNotJoined ( channelTab )", "after": "if channelTab . is_channel ( ) and not channelTab . joined : warnNotJoined ( channelTab )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 3, 4, 29], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"not_operator\", 3, 6, 3, 27], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"identifier:channelTab\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:is_channel\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"):)\", \"T\"], 1]]"}
{"project": "tribler", "commit_sha": "71df447557ae3779748cac47203f3464c3fa3abc", "parent_sha": "dc0dcbc474945c9482744833a26447b58f862014", "file_path": "Tribler/Main/vwxGUI/list.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -122,7 +122,7 @@ class RemoteSearchManager(BaseManager):\n             self.oldkeywords = keywords\n \n     def NewResult(self, keywords):\n-        if self.oldkeywords == keywords:\n+        if self and self.list and self.oldkeywords == keywords:\n             self.list.NewResult()\n \n     def refresh(self, remote=False):\n", "before": "if self . oldkeywords == keywords : self . list . NewResult ( )", "after": "if self and self . list and self . oldkeywords == keywords : self . list . NewResult ( )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 34], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"boolean_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 40], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 2], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:list\", \"T\"], 2]]"}
{"project": "tribler", "commit_sha": "e7c414192c209e8aa741833a15bd6fd183e74d6e", "parent_sha": "bbdac9598ef0740175da2e5d534542e19901aab7", "file_path": "Tribler/Main/vwxGUI/list_details.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2443,7 +2443,7 @@ class VideoplayerExpandedPanel(wx.lib.scrolledpanel.ScrolledPanel):\n             return\n \n         for index, control in enumerate(self.links):\n-            if control.fileindex == fileindex:\n+            if control and control.fileindex == fileindex:\n                 control.SetForegroundColour(self.fg_colour)\n                 if index + 1 < len(self.links):\n                     control_next = self.links[index + 1]\n", "before": "if control . fileindex == fileindex : control . SetForegroundColour ( self . fg_colour ) if index + 1 < len ( self . links ) : control_next = self . links [ index + 1 ]", "after": "if control and control . fileindex == fileindex : control . SetForegroundColour ( self . fg_colour ) if index + 1 < len ( self . links ) : control_next = self . links [ index + 1 ]", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 57], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:control\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 46], 2]]"}
{"project": "tribler", "commit_sha": "f239d6bb74256b07679e13eb66c0bc356269a657", "parent_sha": "da68751da26a1c112be50f3b23cb62f10a2d659a", "file_path": "Tribler/Core/dispersy/member.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -99,7 +99,7 @@ class Member(Parameterized1Singleton):\n                     if sync_with_database:\n                         database.execute(u\"UPDATE member SET public_key = ? WHERE id = ?\", (buffer(public_key), self._database_id))\n \n-                if not self._private_key:\n+                if not self._private_key and private_key:\n                     assert private_key\n                     assert ec_check_private_bin(private_key), private_key.encode(\"HEX\")\n                     self._private_key = private_key\n", "before": "if not self . _private_key : assert private_key assert ec_check_private_bin ( private_key ) , private_key . encode ( \"HEX\" ) self . _private_key = private_key", "after": "if not self . _private_key and private_key : assert private_key assert ec_check_private_bin ( private_key ) , private_key . encode ( \"HEX\" ) self . _private_key = private_key", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 20, 3, 41], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 24, 3, 41], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:private_key\", \"T\"], 2]]"}
{"project": "tribler", "commit_sha": "ef981578d19e1a6a9562c14a3df36d1130dd443b", "parent_sha": "a9014ff35984eeeebcce12bf851298faf13d5128", "file_path": "Tribler/Core/RemoteTorrentHandler.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -440,7 +440,7 @@ class MagnetRequester(Requester):\n \n     @pass_when_stopped\n     def _do_request(self):\n-        while self._pending_request_queue:\n+        while self._pending_request_queue and self.running:\n             if len(self._running_requests) >= self.MAX_CONCURRENT:\n                 self._logger.debug(u\"max concurrency %s reached, request later\", self.MAX_CONCURRENT)\n                 return\n", "before": "while self . _pending_request_queue : if len ( self . _running_requests ) >= self . MAX_CONCURRENT : self . _logger . debug ( u\"max concurrency %s reached, request later\" , self . MAX_CONCURRENT ) return", "after": "while self . _pending_request_queue and self . running : if len ( self . _running_requests ) >= self . MAX_CONCURRENT : self . _logger . debug ( u\"max concurrency %s reached, request later\" , self . MAX_CONCURRENT ) return", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"while_statement\", 3, 9, 6, 23], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 15, 3, 42], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:running\", \"T\"], 2]]"}
{"project": "tribler", "commit_sha": "3a7ca0ce29f667bacf410146731735c9f9d1163a", "parent_sha": "22be65836b704bf10581b50f159ec12c06eb720d", "file_path": "Tribler/Core/DownloadState.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -123,7 +123,7 @@ class DownloadState(Serializable):\n \n                             index += 1\n                 self.haveslice = haveslice\n-                if have == len(haveslice):\n+                if have == len(haveslice) and self.status == DLSTATUS_DOWNLOADING:\n                     # we have all pieces of the selected files\n                     self.status = DLSTATUS_SEEDING\n                     self.progress = 1.0\n", "before": "if have == len ( haveslice ) : self . status = DLSTATUS_SEEDING self . progress = 1.0", "after": "if have == len ( haveslice ) and self . status == DLSTATUS_DOWNLOADING : self . status = DLSTATUS_SEEDING self . progress = 1.0", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 6, 40], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 42], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:DLSTATUS_DOWNLOADING\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:status\", \"T\"], 2]]"}
{"project": "pycocoevalcap", "commit_sha": "612ce6b9a94fad7a229e5f0a463f1917c08eafcd", "parent_sha": "b7135ddeb847d4fec716cb3d5f333be53133e571", "file_path": "pycocoevalcap/cider/cider_scorer.py", "project_url": "https://github.com/salaniz/pycocoevalcap", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -150,7 +150,7 @@ class CiderScorer(object):\n                     # vrama91 : added clipping\n                     val[n] += min(vec_hyp[n][ngram], vec_ref[n][ngram]) * vec_ref[n][ngram]\n \n-                if norm_hyp[n] != 0:\n+                if (norm_hyp[n] != 0) and (norm_ref[n] != 0):\n                     val[n] /= (norm_hyp[n]*norm_ref[n])\n \n                 assert(not math.isnan(val[n]))\n", "before": "if norm_hyp [ n ] != 0 : val [ n ] /= ( norm_hyp [ n ] * norm_ref [ n ] )", "after": "if ( norm_hyp [ n ] != 0 ) and ( norm_ref [ n ] != 0 ) : val [ n ] /= ( norm_hyp [ n ] * norm_ref [ n ] )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 4, 56], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"parenthesized_expression\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"parenthesized_expression\", \"N2\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"comparison_operator\", 3, 20, 3, 36], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"comparison_operator\", \"N3\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"subscript\", \"N4\"], 0], [\"Insert\", \"N3\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N3\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:norm_ref\", \"T\"], 0], [\"Insert\", \"N4\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:n\", \"T\"], 2], [\"Insert\", \"N4\", [\"]:]\", \"T\"], 3]]"}
{"project": "django-pg-bulk-update", "commit_sha": "656aa8dec481a12b3551ff7d8fed14e6a70f2d17", "parent_sha": "a0fbda776489efd6d0ea683a0b79e9106ffc23e9", "file_path": "src/django_pg_bulk_update/query.py", "project_url": "https://github.com/M1hacka/django-pg-bulk-update", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -315,7 +315,7 @@ def _get_default_fds(model, existing_fds):\n     result = []\n \n     for f in get_model_fields(model, concrete=True):\n-        if f not in existing_fields and not isinstance(f, AutoField):\n+        if f not in existing_fields and not isinstance(f, AutoField) and f.has_default():\n             desc = FieldDescriptor(f.name)\n             desc.set_prefix('def')\n             result.append(desc)\n", "before": "if f not in existing_fields and not isinstance ( f , AutoField ) : desc = FieldDescriptor ( f . name ) desc . set_prefix ( 'def' ) result . append ( desc )", "after": "if f not in existing_fields and not isinstance ( f , AutoField ) and f . has_default ( ) : desc = FieldDescriptor ( f . name ) desc . set_prefix ( 'def' ) result . append ( desc )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 41, 3, 69], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 45, 3, 69], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"identifier:f\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:has_default\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"):)\", \"T\"], 1]]"}
{"project": "rllab-curriculum", "commit_sha": "87e29116debd07ca88f5cde8683c68fe511cf0f2", "parent_sha": "f73b9dd954c5b9cd26f5a25048727610c15e0b87", "file_path": "sandbox/tuomas/mddpg/algos/vddpg.py", "project_url": "https://github.com/florensacc/rllab-curriculum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1136,7 +1136,7 @@ class VDDPG(OnlineAlgorithm, Serializable):\n             #env_stats = env.log_stats(epoch, paths)\n             self.last_statistics.update(env_stats)\n \n-        if hasattr(env, 'plot_paths'):\n+        if hasattr(env, 'plot_paths') and self.env_plot_settings is not None:\n             img_file = os.path.join(snapshot_dir,\n                                     'env_itr_%05d.png' % epoch)\n \n", "before": "if hasattr ( env , 'plot_paths' ) : img_file = os . path . join ( snapshot_dir , 'env_itr_%05d.png' % epoch )", "after": "if hasattr ( env , 'plot_paths' ) and self . env_plot_settings is not None : img_file = os . path . join ( snapshot_dir , 'env_itr_%05d.png' % epoch )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 5, 64], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 38], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 2], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 3], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:env_plot_settings\", \"T\"], 2]]"}
{"project": "sentiment-analysis", "commit_sha": "a7e0ec248d9b51d9586cd0b7bf4965d6da5d4489", "parent_sha": "189b5d071a3d9aa28d80c83ad5fe93506cc95f90", "file_path": "experiment.py", "project_url": "https://github.com/timvandermeij/sentiment-analysis", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -97,7 +97,7 @@ def main(argv):\n     ]\n \n     for algorithm in algorithms:\n-        if algorithm['disabled']:\n+        if 'disabled' in algorithm and algorithm['disabled']:\n             continue\n         if filter and filter not in algorithm['name'].lower() and filter not in algorithm['class_name'].__name__.lower():\n             continue\n", "before": "if algorithm [ 'disabled' ] : continue", "after": "if 'disabled' in algorithm and algorithm [ 'disabled' ] : continue", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 21], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"subscript\", 3, 12, 3, 33], 2], [\"Insert\", \"N1\", [\"string:'disabled'\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:algorithm\", \"T\"], 2]]"}
{"project": "palabra", "commit_sha": "b5225e6361370b0a389f57a9f669ef209aa98ffe", "parent_sha": "e8092fbdec8a90db8872c8f29d283cf1f683d30d", "file_path": "palabralib/editor.py", "project_url": "https://github.com/svisser/palabra", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -155,7 +155,7 @@ class WordWidget(gtk.DrawingArea):\n             self.editor.set_overlay(None)\n             return\n         word = self.words[offset][0]\n-        if event.type == gtk.gdk._2BUTTON_PRESS:\n+        if event.button == 1 and event.type == gtk.gdk._2BUTTON_PRESS:\n             self.editor.insert(word)\n             self.selection = None\n             self.editor.set_overlay(None)\n", "before": "if event . type == gtk . gdk . _2BUTTON_PRESS : self . editor . insert ( word ) self . selection = None self . editor . set_overlay ( None )", "after": "if event . button == 1 and event . type == gtk . gdk . _2BUTTON_PRESS : self . editor . insert ( word ) self . selection = None self . editor . set_overlay ( None )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 42], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 48], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:1\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:event\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:button\", \"T\"], 2]]"}
{"project": "angr", "commit_sha": "a6fb44eca986bab5c84ee86ab5a18cbbd55907b1", "parent_sha": "c16e5712ef79ad15dd8e83651079b5f4cbe290b5", "file_path": "angr/project.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -244,7 +244,7 @@ class Project(object):    # pylint: disable=R0904,\n             mode = self.default_analysis_mode\n \n         memory_backer = self.ld.memory\n-        if simuvex.o.ABSTRACT_MEMORY in add_options:\n+        if add_options is not None and simuvex.o.ABSTRACT_MEMORY in add_options:\n             # Adjust the memory backer when using abstract memory\n             if memory_backer is not None:\n                 memory_backer = {'global': memory_backer}\n", "before": "if simuvex . o . ABSTRACT_MEMORY in add_options : if memory_backer is not None : memory_backer = { 'global' : memory_backer }", "after": "if add_options is not None and simuvex . o . ABSTRACT_MEMORY in add_options : if memory_backer is not None : memory_backer = { 'global' : memory_backer }", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 58], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 52], 2], [\"Insert\", \"N1\", [\"identifier:add_options\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 2], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 3]]"}
{"project": "angr", "commit_sha": "b0af3e504b57fe52c11c55795a9bf985e564f7e6", "parent_sha": "bbb379b273eadc565281046b4e6258c53baef947", "file_path": "angr/analyses/cfg_base.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -117,7 +117,7 @@ class CFGBase(object):\n \n         for n in self.graph.nodes_iter():\n             cond = n.looping_times == 0\n-            if anyaddr:\n+            if anyaddr and n.size is not None:\n                 cond = cond and (addr >= n.addr and addr < n.addr + n.size)\n             else:\n                 cond = cond  and (addr == n.addr)\n", "before": "if anyaddr : cond = cond and ( addr >= n . addr and addr < n . addr + n . size ) else : cond = cond and ( addr == n . addr )", "after": "if anyaddr and n . size is not None : cond = cond and ( addr >= n . addr and addr < n . addr + n . size ) else : cond = cond and ( addr == n . addr )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 50], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:anyaddr\", 3, 16, 3, 23], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 2], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 3], [\"Insert\", \"N2\", [\"identifier:n\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:size\", \"T\"], 2]]"}
{"project": "angr", "commit_sha": "1660980c3db212d17f367c8f87ae3cc9b25873ac", "parent_sha": "d5b52b512b362d49196654f8644847929907b1ba", "file_path": "identifier/identify.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -242,7 +242,7 @@ class Identifier(object):\n             # match!\n             return f\n \n-        if len(func_info.stack_args) == 2 and func_info.var_args:\n+        if len(func_info.stack_args) == 2 and func_info.var_args and len(function.graph.nodes()) < 5:\n             match = Functions[\"fdprintf\"]()\n             l.warning(\"%#x assuming fd printf for var_args func with 2 args although we don't really know\", function.addr)\n             return match\n", "before": "if len ( func_info . stack_args ) == 2 and func_info . var_args : match = Functions [ \"fdprintf\" ] ( ) l . warning ( \"%#x assuming fd printf for var_args func with 2 args although we don't really know\" , function . addr ) return match", "after": "if len ( func_info . stack_args ) == 2 and func_info . var_args and len ( function . graph . nodes ( ) ) < 5 : match = Functions [ \"fdprintf\" ] ( ) l . warning ( \"%#x assuming fd printf for var_args func with 2 args although we don't really know\" , function . addr ) return match", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 12, 3, 65], [\"boolean_operator\", 3, 12, 3, 65], 0], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 65], [\"and:and\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 65], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"call\", \"N1\"], 0], [\"Insert\", \"N0\", [\"<:<\", \"T\"], 1], [\"Insert\", \"N0\", [\"integer:5\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"call\", \"N3\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N3\", [\"argument_list\", \"N5\"], 1], [\"Insert\", \"N4\", [\"attribute\", \"N6\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:nodes\", \"T\"], 2], [\"Insert\", \"N5\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N5\", [\"):)\", \"T\"], 1], [\"Insert\", \"N6\", [\"identifier:function\", \"T\"], 0], [\"Insert\", \"N6\", [\".:.\", \"T\"], 1], [\"Insert\", \"N6\", [\"identifier:graph\", \"T\"], 2]]"}
{"project": "angr", "commit_sha": "eadfb4834111406c6573d30191eb0edafed01519", "parent_sha": "d00aa6c5393ac8aaf9d61e197df6533667782b3b", "file_path": "angr/analyses/cfg_base.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -753,7 +753,7 @@ class CFGBase(Analysis):\n                         continue\n                     target_addr = edges[0][1].addr\n                     target_func = self.kb.functions.function(addr=target_addr)\n-                    if target_func.returning is False:\n+                    if target_func is not None and target_func.returning is False:\n                         edges_to_remove.append((src, dst))\n \n             for src, dst in edges_to_remove:\n", "before": "if target_func . returning is False : edges_to_remove . append ( ( src , dst ) )", "after": "if target_func is not None and target_func . returning is False : edges_to_remove . append ( ( src , dst ) )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 21, 4, 59], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 24, 3, 54], 2], [\"Insert\", \"N1\", [\"identifier:target_func\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 2], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 3]]"}
{"project": "angr", "commit_sha": "620f23cb326779437f0198658325927673e43e36", "parent_sha": "1ed488eefd7fb73ee5ea33d0197bdcc2162f7f17", "file_path": "angr/analyses/cfg_base.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -499,7 +499,7 @@ class CFGBase(Analysis):\n \n                     all_endpoints_returning.append(call_target_func.returning)\n \n-            if all([i is False for _, i in all_endpoints_returning]):\n+            if all_endpoints_returning and all([i is False for _, i in all_endpoints_returning]):\n                 # All target functions that this function calls is not returning\n                 func.returning = False\n                 changes['functions_do_not_return'].append(func)\n", "before": "if all ( [ i is False for _ , i in all_endpoints_returning ] ) : func . returning = False changes [ 'functions_do_not_return' ] . append ( func )", "after": "if all_endpoints_returning and all ( [ i is False for _ , i in all_endpoints_returning ] ) : func . returning = False changes [ 'functions_do_not_return' ] . append ( func )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 64], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:all_endpoints_returning\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 69], 2]]"}
{"project": "mitmproxy", "commit_sha": "de65aebfdf011f1cf68c554ed79326621c328c10", "parent_sha": "6f86741574ca38b11ecb2c196ce636aea3f25b63", "file_path": "mitmproxy/dump.py", "project_url": "https://github.com/aisier/mitmproxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ class DumpMaster(flow.FlowMaster):\n         self.options = self.options  # type: Options\n         self.set_stream_large_bodies(options.stream_large_bodies)\n \n-        if not self.options.no_server:\n+        if not self.options.no_server and server:\n             print(\"Proxy server listening at http://{}\".format(server.address))\n \n         if self.server and self.options.http2 and not tcp.HAS_ALPN:  # pragma: no cover\n", "before": "if not self . options . no_server : print ( \"Proxy server listening at http://{}\" . format ( server . address ) )", "after": "if not self . options . no_server and server : print ( \"Proxy server listening at http://{}\" . format ( server . address ) )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 12, 3, 38], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 16, 3, 38], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:server\", \"T\"], 2]]"}
{"project": "funcx-web-service", "commit_sha": "37569d1e1f0bfecf5b00a1e4e5edabdc0b4c3c43", "parent_sha": "1294681e8797bea1cefc85a375905b4bf218a9d1", "file_path": "models/utils.py", "project_url": "https://github.com/funcx-faas/funcx-web-service", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -240,7 +240,7 @@ def resolve_function(user_id, function_uuid):\n         cur.execute(query, (function_id,))\n         r = cur.fetchone()\n \n-        if 'container_uuid' in r:\n+        if r and 'container_uuid' in r:\n             container_uuid = r['container_uuid']\n \n     except Exception as e:\n", "before": "if 'container_uuid' in r : container_uuid = r [ 'container_uuid' ]", "after": "if r and 'container_uuid' in r : container_uuid = r [ 'container_uuid' ]", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 49], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:r\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 33], 2]]"}
{"project": "QCG-PilotJob", "commit_sha": "b2d2b3d1e7593eb3666f61a9a9794b94077efb2a", "parent_sha": "9b710692469d91a1eef99212e86f724c44c7c357", "file_path": "src/qcg/appscheduler/executionjob.py", "project_url": "https://github.com/vecma-project/QCG-PilotJob", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -102,7 +102,7 @@ class ExecutionJob:\n         if self.jobExecution.env is not None:\n             self.env.update(self.jobExecution.env)\n \n-        if hasattr(self.__executor, 'zmq_address'):\n+        if hasattr(self.__executor, 'zmq_address') and self.__executor.zmq_address:\n             self.env.update({\n                 'QCG_PM_ZMQ_ADDRESS': self.__executor.zmq_address\n             })\n", "before": "if hasattr ( self . __executor , 'zmq_address' ) : self . env . update ( { 'QCG_PM_ZMQ_ADDRESS' : self . __executor . zmq_address } )", "after": "if hasattr ( self . __executor , 'zmq_address' ) and self . __executor . zmq_address : self . env . update ( { 'QCG_PM_ZMQ_ADDRESS' : self . __executor . zmq_address } )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 15], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 51], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:zmq_address\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:__executor\", \"T\"], 2]]"}
{"project": "sympy", "commit_sha": "3d6d26bb303bdb075937f3bbff5407101c90e4ed", "parent_sha": "4bd1361015ec6c0aec3d7291d0570583812aaaa2", "file_path": "sympy/matrices/matrices.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1130,7 +1130,7 @@ def eigenvals(self, error_when_incomplete=True, **flags):\n \n         # make sure the algebraic multiplicty sums to the\n         # size of the matrix\n-        if error_when_incomplete and sum(m for m in eigs.values()) != self.cols:\n+        if error_when_incomplete and type(eigs)==dict and sum(m for m in eigs.values()) != self.cols:\n             raise MatrixError(\"Could not compute eigenvalues for {}\".format(self))\n \n         return eigs\n", "before": "if error_when_incomplete and sum ( m for m in eigs . values ( ) ) != self . cols : raise MatrixError ( \"Could not compute eigenvalues for {}\" . format ( self ) )", "after": "if error_when_incomplete and type ( eigs ) == dict and sum ( m for m in eigs . values ( ) ) != self . cols : raise MatrixError ( \"Could not compute eigenvalues for {}\" . format ( self ) )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 80], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 80], [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:error_when_incomplete\", 3, 12, 3, 33], 0], [\"Move\", \"N0\", [\"and:and\", 3, 34, 3, 37], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:dict\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:type\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:eigs\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "osc", "commit_sha": "73048d1159ef76008e78bc286201dae4d4ecf425", "parent_sha": "b2493a25ae211f66356d65da67204ad757737de6", "file_path": "osc/commandline.py", "project_url": "https://github.com/lethliel/osc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1410,7 +1410,7 @@ Please submit there instead, or use --nodevelproject to force direct submission.\n             user = conf.get_apiurl_usr(apiurl)\n             myreqs = [ i for i in reqs if i.state.who == user ]\n             repl = 'y'\n-            if len(myreqs) > 0:\n+            if len(myreqs) > 0 and not opts.yes:\n                 print('You already created the following submit request: %s.' % \\\n                       ', '.join([i.reqid for i in myreqs ]))\n                 repl = raw_input('Supersede the old requests? (y/n/c) ')\n", "before": "if len ( myreqs ) > 0 : print ( 'You already created the following submit request: %s.' % ', ' . join ( [ i . reqid for i in myreqs ] ) ) repl = raw_input ( 'Supersede the old requests? (y/n/c) ' )", "after": "if len ( myreqs ) > 0 and not opts . yes : print ( 'You already created the following submit request: %s.' % ', ' . join ( [ i . reqid for i in myreqs ] ) ) repl = raw_input ( 'Supersede the old requests? (y/n/c) ' )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 73], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 31], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 1], [\"Insert\", \"N2\", [\"identifier:opts\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:yes\", \"T\"], 2]]"}
{"project": "sympy", "commit_sha": "80fe2073973ca501c89c88d01beebfe8fb7ce7cc", "parent_sha": "f00bced73e8f348ab3c49260ca944fce92b02959", "file_path": "sympy/core/power.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -693,7 +693,7 @@ def _eval_evalf(self, prec):\n         base = base._evalf(prec)\n         if not exp.is_Integer:\n             exp = exp._evalf(prec)\n-        if (exp < 0) is True and base.is_number and base.is_real is False:\n+        if exp.is_real and (exp < 0) is True and base.is_number and base.is_real is False:\n             base = base.conjugate() / (base * base.conjugate())._evalf(prec)\n             exp = -exp\n             return self.func(base, exp).expand()\n", "before": "if ( exp < 0 ) is True and base . is_number and base . is_real is False : base = base . conjugate ( ) / ( base * base . conjugate ( ) ) . _evalf ( prec ) exp = - exp return self . func ( base , exp ) . expand ( )", "after": "if exp . is_real and ( exp < 0 ) is True and base . is_number and base . is_real is False : base = base . conjugate ( ) / ( base * base . conjugate ( ) ) . _evalf ( prec ) exp = - exp return self . func ( base , exp ) . expand ( )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 48], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 29], 2], [\"Insert\", \"N1\", [\"identifier:exp\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:is_real\", \"T\"], 2]]"}
{"project": "electrum", "commit_sha": "e2a25964795f80fc343f21c70eaa21c97a1d3f35", "parent_sha": "bd96815eb31f581e846a6f9072378219d90a4240", "file_path": "lib/verifier.py", "project_url": "https://github.com/you21979/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -289,7 +289,7 @@ class WalletVerifier(threading.Thread):\n \n     def path(self):\n         wdir = self.config.get('blockchain_headers_path', user_dir())\n-        if not os.path.exists( wdir ): os.mkdir(wdir)\n+        if wdir and not os.path.exists( wdir ): os.mkdir(wdir)\n         return os.path.join( wdir, 'blockchain_headers')\n \n     def init_headers_file(self):\n", "before": "if not os . path . exists ( wdir ) : os . mkdir ( wdir )", "after": "if wdir and not os . path . exists ( wdir ) : os . mkdir ( wdir )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 3, 54], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:wdir\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"not_operator\", 3, 12, 3, 38], 2]]"}
{"project": "sympy", "commit_sha": "2174ce43eb9ac7f43e9217273ca80e7d86cc3ff5", "parent_sha": "7b82ce274fe78ab841c898a9a57f8bd86e767087", "file_path": "sympy/geometry/ellipse.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -140,7 +140,7 @@ def __new__(\n \n         if eccentricity is not None:\n-            if eccentricity > 1:\n+            if eccentricity.is_real == True and eccentricity > 1:\n                 raise GeometryError(\"eccentricity of ellipse/circle can only be less than 1\")\n             elif hradius is None:\n                 hradius = vradius / sqrt(1 - eccentricity**2)\n", "before": "if eccentricity > 1 : raise GeometryError ( \"eccentricity of ellipse/circle can only be less than 1\" ) elif hradius is None : hradius = vradius / sqrt ( 1 - eccentricity ** 2 )", "after": "if eccentricity . is_real == True and eccentricity > 1 : raise GeometryError ( \"eccentricity of ellipse/circle can only be less than 1\" ) elif hradius is None : hradius = vradius / sqrt ( 1 - eccentricity ** 2 )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 2, 13, 5, 62], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 2, 16, 2, 32], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"true:True\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:eccentricity\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:is_real\", \"T\"], 2]]"}
{"project": "sympy", "commit_sha": "c1222ca77ce3d26e946a82808224e32a3e6255ce", "parent_sha": "00812c9ac1cbe4e0779d3ca2fa5fca5d69ad3792", "file_path": "sympy/geometry/ellipse.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -156,7 +156,7 @@ def __new__(\n         if (hradius.is_complex is True and hradius.is_real is False) or (vradius.is_complex is True and vradius.is_real is False):\n             raise GeometryError(\"Eccentricity of ellipse/circle should lie between [0, 1)\")\n \n-        if hradius !=0 and vradius == 0:\n+        if hradius.is_real and hradius !=0 and vradius == 0:\n             raise GeometryError(\"Eccentricity of ellipse/circle should lie between [0, 1)\")\n \n         if (hradius.isreal is True and hradius<0) or (vradius.isreal is True and vradius<0):\n", "before": "if hradius != 0 and vradius == 0 : raise GeometryError ( \"Eccentricity of ellipse/circle should lie between [0, 1)\" )", "after": "if hradius . is_real and hradius != 0 and vradius == 0 : raise GeometryError ( \"Eccentricity of ellipse/circle should lie between [0, 1)\" )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 40], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 23], 2], [\"Insert\", \"N1\", [\"identifier:hradius\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:is_real\", \"T\"], 2]]"}
{"project": "sympy", "commit_sha": "a927b13f1e6f423f22b2f7d5bf0f5a4e8ac1b258", "parent_sha": "1cf85d1bd6bfa2c5f9d2642e0e9d7a0f70c9f317", "file_path": "sympy/series/limitseq.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -242,5 +242,5 @@ def limit_seq(expr, n=None, trials=5):\n         # Maybe the absolute value is easier to deal with (though not if\n         # it has a Sum). If it tends to 0, the limit is 0.\n         elif not expr.has(Sum):\n-            if _limit_seq(Abs(expr.xreplace({n: n_})), n_, trials).is_zero:\n+            if _limit_seq(Abs(expr.xreplace({n: n_})), n_, trials) is not None and _limit_seq(Abs(expr.xreplace({n: n_})), n_, trials).is_zero:\n                 return S.Zero\n", "before": "if _limit_seq ( Abs ( expr . xreplace ( { n : n_ } ) ) , n_ , trials ) . is_zero : return S . Zero", "after": "if _limit_seq ( Abs ( expr . xreplace ( { n : n_ } ) ) , n_ , trials ) is not None and _limit_seq ( Abs ( expr . xreplace ( { n : n_ } ) ) , n_ , trials ) . is_zero : return S . Zero", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 30], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 16, 3, 75], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 2], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 3], [\"Insert\", \"N2\", [\"identifier:_limit_seq\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"call\", \"N4\"], 1], [\"Insert\", \"N3\", [\",:,\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:n_\", \"T\"], 3], [\"Insert\", \"N3\", [\",:,\", \"T\"], 4], [\"Insert\", \"N3\", [\"identifier:trials\", \"T\"], 5], [\"Insert\", \"N3\", [\"):)\", \"T\"], 6], [\"Insert\", \"N4\", [\"identifier:Abs\", \"T\"], 0], [\"Insert\", \"N4\", [\"argument_list\", \"N5\"], 1], [\"Insert\", \"N5\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N5\", [\"call\", \"N6\"], 1], [\"Insert\", \"N5\", [\"):)\", \"T\"], 2], [\"Insert\", \"N6\", [\"attribute\", \"N7\"], 0], [\"Insert\", \"N6\", [\"argument_list\", \"N8\"], 1], [\"Insert\", \"N7\", [\"identifier:expr\", \"T\"], 0], [\"Insert\", \"N7\", [\".:.\", \"T\"], 1], [\"Insert\", \"N7\", [\"identifier:xreplace\", \"T\"], 2], [\"Insert\", \"N8\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N8\", [\"dictionary\", \"N9\"], 1], [\"Insert\", \"N8\", [\"):)\", \"T\"], 2], [\"Insert\", \"N9\", [\"{:{\", \"T\"], 0], [\"Insert\", \"N9\", [\"pair\", \"N10\"], 1], [\"Insert\", \"N9\", [\"}:}\", \"T\"], 2], [\"Insert\", \"N10\", [\"identifier:n\", \"T\"], 0], [\"Insert\", \"N10\", [\":::\", \"T\"], 1], [\"Insert\", \"N10\", [\"identifier:n_\", \"T\"], 2]]"}
{"project": "course-discovery", "commit_sha": "cd0087e11134407402dc4859c3eca945d58065eb", "parent_sha": "fdbb8375046f0ee740a946c3ced1d53364ac113b", "file_path": "course_discovery/apps/api/serializers.py", "project_url": "https://github.com/EDUlib/course-discovery", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1601,7 +1601,7 @@ class AffiliateWindowSerializer(serializers.ModelSerializer):\n \n     def get_custom6(self, obj):\n         weeks = obj.course_run.weeks_to_complete\n-        if weeks > 0:\n+        if weeks and weeks > 0:\n             return '{} {}'.format(weeks, 'week' if weeks == 1 else 'weeks')\n         return ''\n \n", "before": "if weeks > 0 : return '{} {}' . format ( weeks , 'week' if weeks == 1 else 'weeks' )", "after": "if weeks and weeks > 0 : return '{} {}' . format ( weeks , 'week' if weeks == 1 else 'weeks' )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 76], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:weeks\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 21], 2]]"}
{"project": "isida", "commit_sha": "9c94a9cf27215f55a8ae8fb4847aeabd94623ac9", "parent_sha": "2c91f9b36cbd364ef904d6a20fdd789af3e07b87", "file_path": "plugins/bash.py", "project_url": "https://github.com/cobrab11/isida", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -5,7 +5,7 @@ def bash_org_ru(type, jid, nick, text):\n \ttry: url = u'http://bash.org.ru/quote/'+str(int(text))\r\n \texcept: url = u'http://bash.org.ru/random'\r\n \tbody = html_encode(urllib.urlopen(url).read())\r\n-\tif body.count('<div class=\"vote\">') > 1: msg = u'\u0426\u0438\u0442\u0430\u0442\u0430 \u043d\u0435 \u043d\u0430\u0439\u0434\u0435\u043d\u0430!'\r\n+\tif body.count('<div class=\"vote\">') > 1 and url.count('quote'): msg = u'\u0426\u0438\u0442\u0430\u0442\u0430 \u043d\u0435 \u043d\u0430\u0439\u0434\u0435\u043d\u0430!'\r\n \telse:\r\n \t\tbody = body.split('<div class=\"vote\">')[1].split('<div class=\"q\">')[0]\r\n \t\tmsg = u'http://bash.org.ru/quote/'+str(get_tag(body, 'a'))+u' '+replacer(body[body.find('[:||||:]'):].replace('</div>', '\\n').replace('[:||||:]', '::: ').replace('</a>\\n', ''))\r\n", "before": "if body . count ( '<div class=\"vote\">' ) > 1 : msg = u'\u0426\u0438\u0442\u0430\u0442\u0430 \u043d\u0435 \u043d\u0430\u0439\u0434\u0435\u043d\u0430!' else : body = body . split ( '<div class=\"vote\">' ) [ 1 ] . split ( '<div class=\"q\">' ) [ 0 ] msg = u'http://bash.org.ru/quote/' + str ( get_tag ( body , 'a' ) ) + u' ' + replacer ( body [ body . find ( '[:||||:]' ) : ] . replace ( '</div>' , '\\n' ) . replace ( '[:||||:]' , '::: ' ) . replace ( '</a>\\n' , '' ) )", "after": "if body . count ( '<div class=\"vote\">' ) > 1 and url . count ( 'quote' ) : msg = u'\u0426\u0438\u0442\u0430\u0442\u0430 \u043d\u0435 \u043d\u0430\u0439\u0434\u0435\u043d\u0430!' else : body = body . split ( '<div class=\"vote\">' ) [ 1 ] . split ( '<div class=\"q\">' ) [ 0 ] msg = u'http://bash.org.ru/quote/' + str ( get_tag ( body , 'a' ) ) + u' ' + replacer ( body [ body . find ( '[:||||:]' ) : ] . replace ( '</div>' , '\\n' ) . replace ( '[:||||:]' , '::: ' ) . replace ( '</a>\\n' , '' ) )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 2, 6, 179], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 5, 3, 41], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"identifier:url\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:count\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"string:'quote'\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "tardis", "commit_sha": "b9900f07496ad5e123cbbe9c2e9480c28c3d141f", "parent_sha": "ff9f9545a5b215f60d840ebb948719c172cc294c", "file_path": "tardis/plasma/standard_plasmas.py", "project_url": "https://github.com/vg3095/tardis", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -75,7 +75,7 @@ class LegacyPlasmaArray(BasePlasma):\n             raise NotImplementedError('Sorry ' + ionization_mode +\n                 ' not implemented yet.')\n \n-        if nlte_config is not None:\n+        if nlte_config is not None and nlte_config.species:\n             plasma_modules += nlte_properties\n         else:\n             plasma_modules += non_nlte_properties\n", "before": "if nlte_config is not None : plasma_modules += nlte_properties else : plasma_modules += non_nlte_properties", "after": "if nlte_config is not None and nlte_config . species : plasma_modules += nlte_properties else : plasma_modules += non_nlte_properties", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 50], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 35], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:nlte_config\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:species\", \"T\"], 2]]"}
{"project": "tvm", "commit_sha": "4c0e8cd0d6262ba365c21f9ef4c05fd7f09d9bb7", "parent_sha": "c62e33143d961a94c60a7bfe684a1bc1642ab71d", "file_path": "python/tvm/relay/frontend/tensorflow.py", "project_url": "https://github.com/neo-ai/tvm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1227,7 +1227,7 @@ def _fused_batch_norm():\n             attr['data_format'] = attr['data_format'].decode(\"utf-8\")\n             if attr['data_format'] == 'NCHW':\n                 axis = 1\n-        if 'U' in attr:\n+        if 'U' in attr and attr['U'].name != attr['T'].name:\n             need_cast = True\n             inputs[0] = _op.cast(inputs[0], dtype=attr['U'].name)\n         # Check if mean and variance are empty\n", "before": "if 'U' in attr : need_cast = True inputs [ 0 ] = _op . cast ( inputs [ 0 ] , dtype = attr [ 'U' ] . name )", "after": "if 'U' in attr and attr [ 'U' ] . name != attr [ 'T' ] . name : need_cast = True inputs [ 0 ] = _op . cast ( inputs [ 0 ] , dtype = attr [ 'U' ] . name )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 5, 66], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 23], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 2], [\"Insert\", \"N2\", [\"subscript\", \"N4\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:name\", \"T\"], 2], [\"Insert\", \"N3\", [\"subscript\", \"N5\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:name\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:attr\", \"T\"], 0], [\"Insert\", \"N4\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N4\", [\"string:'U'\", \"T\"], 2], [\"Insert\", \"N4\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N5\", [\"identifier:attr\", \"T\"], 0], [\"Insert\", \"N5\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N5\", [\"string:'T'\", \"T\"], 2], [\"Insert\", \"N5\", [\"]:]\", \"T\"], 3]]"}
{"project": "edx-platform", "commit_sha": "f47ab30c3f930244fa44efad0e90fb22c86f90c7", "parent_sha": "24f85bf202376aa4c59feb39e3b0c3ea2bdbb4ff", "file_path": "common/djangoapps/xmodule_modifiers.py", "project_url": "https://github.com/easy-edx/edx-platform", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ def add_histogram(get_html, module):\n         if settings.MITX_FEATURES.get('ENABLE_LMS_MIGRATION'):\n             [filepath, filename] = module.definition.get('filename','')\n             osfs = module.system.filestore\n-            if osfs.exists(filename):\n+            if filename is not None and osfs.exists(filename):\n                 filepath = filename\t# if original, unmangled filename exists then use it (github doesn't like symlinks)\n             data_dir = osfs.root_path.rsplit('/')[-1]\n             edit_link = \"https://github.com/MITx/%s/tree/master/%s\" % (data_dir,filepath)\n", "before": "if osfs . exists ( filename ) : filepath = filename", "after": "if filename is not None and osfs . exists ( filename ) : filepath = filename", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 120], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 37], 2], [\"Insert\", \"N1\", [\"identifier:filename\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 2], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 3]]"}
{"project": "macsyfinder", "commit_sha": "ab72e924575aabf0fd569fe15a5d964d2d594ee1", "parent_sha": "a864902bd4f9a2162d43d18d61d5c59c1c6473ce", "file_path": "macsypy/config.py", "project_url": "https://github.com/gem-pasteur/macsyfinder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -148,7 +148,7 @@ class Config:\n         config_files_values = self._config_file_2_dict(defaults, config_files, previous_run=previous_run)\n         args_dict = {k: v for k, v in vars(parsed_args).items() if not k.startswith('__')}\n         if previous_run:\n-            if 'sequence_db' in args_dict:\n+            if 'sequence_db' in args_dict and args_dict['sequence_db']:\n                 _log.warning(f\"ignore sequence_db '{parsed_args.sequence_db}' use sequence_db \"\n                              f\"from previous_run '{args_dict['previous_run']}'.\")\n                 del args_dict['sequence_db']\n", "before": "if 'sequence_db' in args_dict : _log . warning ( f\"ignore sequence_db '{parsed_args.sequence_db}' use sequence_db \" f\"from previous_run '{args_dict['previous_run']}'.\" ) del args_dict [ 'sequence_db' ]", "after": "if 'sequence_db' in args_dict and args_dict [ 'sequence_db' ] : _log . warning ( f\"ignore sequence_db '{parsed_args.sequence_db}' use sequence_db \" f\"from previous_run '{args_dict['previous_run']}'.\" ) del args_dict [ 'sequence_db' ]", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 45], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 42], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"subscript\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:args_dict\", \"T\"], 0], [\"Insert\", \"N1\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'sequence_db'\", \"T\"], 2], [\"Insert\", \"N1\", [\"]:]\", \"T\"], 3]]"}
{"project": "weblyzard_api", "commit_sha": "6e439110fd3dee763d7161909033499c00caa304", "parent_sha": "730d8b9747ebffffa131b543d8484bf3384f881c", "file_path": "src/python/weblyzard_api/xml_content/parsers/json_10.py", "project_url": "https://github.com/weblyzard/weblyzard_api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -160,7 +160,7 @@ class JSONParserBase(object):\n         if 'content' in json_document and 'sentences' in json_document:\n             raise MalformedJSONException(\n                     \"If 'sentences' is set, 'content' must not be set.\")\n-        if not json_document['content_type'] in cls.SUPPORTED_CONTENT_TYPES:\n+        if 'content_type' in json_document and not json_document['content_type'] in cls.SUPPORTED_CONTENT_TYPES:\n             raise UnsupportedValueException(\"content_type %s is not supported. Supported are %s\" % \n                                             (json_document['content_type'], \n                                              cls.SUPPORTED_CONTENT_TYPES))\n", "before": "if not json_document [ 'content_type' ] in cls . SUPPORTED_CONTENT_TYPES : raise UnsupportedValueException ( \"content_type %s is not supported. Supported are %s\" % ( json_document [ 'content_type' ] , cls . SUPPORTED_CONTENT_TYPES ) )", "after": "if 'content_type' in json_document and not json_document [ 'content_type' ] in cls . SUPPORTED_CONTENT_TYPES : raise UnsupportedValueException ( \"content_type %s is not supported. Supported are %s\" % ( json_document [ 'content_type' ] , cls . SUPPORTED_CONTENT_TYPES ) )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 75], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"not_operator\", 3, 12, 3, 76], 2], [\"Insert\", \"N1\", [\"string:'content_type'\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:json_document\", \"T\"], 2]]"}
{"project": "weblyzard_api", "commit_sha": "102023f0ab07b21df08a9957a09f6f6bccfcd6c7", "parent_sha": "7a72c764631d5f1f2b1586e623a8cdfe3a93b478", "file_path": "src/python/weblyzard_api/model/document.py", "project_url": "https://github.com/weblyzard/weblyzard_api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -166,7 +166,7 @@ class Document(object):\n             if 'partitions' in parsed_content else {}\n \n         metadata = parsed_content['header'] \\\n-            if 'header' in parsed_content else {}\n+            if 'header' in parsed_content and parsed_content['header'] is not None else {}\n \n         if not len(metadata):\n             metadata = parsed_content['metadata'] \\\n", "before": "if 'partitions' in parsed_content else { } metadata = parsed_content [ 'header' ] if 'header' in parsed_content else { } if not len ( metadata ) : metadata = parsed_content [ 'metadata' ]", "after": "if 'partitions' in parsed_content else { } metadata = parsed_content [ 'header' ] if 'header' in parsed_content and parsed_content [ 'header' ] is not None else { } if not len ( metadata ) : metadata = parsed_content [ 'metadata' ]", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"conditional_expression\", 2, 20, 3, 50], [\"subscript\", \"N0\"], 0], [\"Insert\", [\"conditional_expression\", 2, 20, 3, 50], [\"boolean_operator\", \"N1\"], 3], [\"Insert\", \"N0\", [\"identifier:parsed_content\", \"T\"], 0], [\"Insert\", \"N0\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'header'\", \"T\"], 2], [\"Insert\", \"N0\", [\"]:]\", \"T\"], 3], [\"Move\", \"N1\", [\"comparison_operator\", 3, 16, 3, 42], 0], [\"Insert\", \"N1\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N1\", [\"comparison_operator\", \"N2\"], 2], [\"Move\", \"N2\", [\"subscript\", 2, 20, 2, 44], 0], [\"Insert\", \"N2\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N2\", [\"not:not\", \"T\"], 2], [\"Insert\", \"N2\", [\"none:None\", \"T\"], 3]]"}
{"project": "weblyzard_api", "commit_sha": "7c7866e69b8f8b0c796094e9185551f43b8a332b", "parent_sha": "6a06b811ade039a2825de49c39080a5bbb460868", "file_path": "src/python/weblyzard_api/client/rdf.py", "project_url": "https://github.com/weblyzard/weblyzard_api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -106,7 +106,7 @@ def parse_language_tagged_string(value):\n     lang = None\n-    if value[0] == value[-1] == '\"':\n+    if len(value) >1 and value[0] == value[-1] == '\"':\n         value = value[1:-1]\n     if len(value) > 6 and value[-6] == '@':\n         lang = value[-5:]\n", "before": "if value [ 0 ] == value [ - 1 ] == '\"' : value = value [ 1 : - 1 ]", "after": "if len ( value ) > 1 and value [ 0 ] == value [ - 1 ] == '\"' : value = value [ 1 : - 1 ]", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 1, 5, 2, 28], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 1, 8, 1, 36], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\">:>\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:1\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:value\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "weblyzard_api", "commit_sha": "fe591edfc5c69db64f7f4c98aebe8b93d994ff92", "parent_sha": "95cb53f19ebfc93906a9e67c726c95dbdb2c443e", "file_path": "src/python/weblyzard_api/client/skb_rest_client.py", "project_url": "https://github.com/weblyzard/weblyzard_api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -323,7 +323,7 @@ class SKBRESTClient(object):\n                     property_name='owl:sameAs',\n                     entity_type=entity_type\n                 )\n-                if sameas_match is not None:\n+                if sameas_match is not None and len(sameas_match):\n                     logger.info(\n                         u'Identified entity {} through sameAs match.'.format(uri))\n                     return sameas_match[0]['uri']\n", "before": "if sameas_match is not None : logger . info ( u'Identified entity {} through sameAs match.' . format ( uri ) ) return sameas_match [ 0 ] [ 'uri' ]", "after": "if sameas_match is not None and len ( sameas_match ) : logger . info ( u'Identified entity {} through sameAs match.' . format ( uri ) ) return sameas_match [ 0 ] [ 'uri' ]", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 6, 50], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 44], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:sameas_match\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "weblyzard_api", "commit_sha": "23f564478a6f5a28736b9ab421f3bc7934eb5dde", "parent_sha": "fc01b5ef86dfaa41ffca8bf382d84482f2fe715e", "file_path": "src/python/weblyzard_api/client/jesaja_ng.py", "project_url": "https://github.com/weblyzard/weblyzard_api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -106,7 +106,7 @@ class JesajaNg(MultiRESTClient):\n                 'Cannot compute keywords - unknown matview {}'.format(matview_id))\n \n         endpoint = f'get_nek_annotations/{matview_id}'\n-        if num_keywords is not None:\n+        if num_keywords is not None and num_keywords > 0:\n             endpoint = f'{endpoint}?num_keywords={num_keywords}'\n \n         return self.request(endpoint, documents)\n", "before": "if num_keywords is not None : endpoint = f'{endpoint}?num_keywords={num_keywords}'", "after": "if num_keywords is not None and num_keywords > 0 : endpoint = f'{endpoint}?num_keywords={num_keywords}'", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 65], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 36], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:num_keywords\", \"T\"], 0], [\"Insert\", \"N1\", [\">:>\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2]]"}
{"project": "gzipstream", "commit_sha": "6eef616fbe8694c0db508ea6857c6c668436ce1c", "parent_sha": "2840ab11423abb3c57e00a4fcc454c12382d83a2", "file_path": "gzipstream/gzipstreamfile.py", "project_url": "https://github.com/Smerity/gzipstream", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -46,7 +46,7 @@ class GzipStreamFile(object):\n     # TODO: This should work in large chunks rather than a byte at a time\n     chars = []\n     c = self.read(1)\n-    while c != '\\n':\n+    while c and c != '\\n':\n       chars.append(c)\n       c = self.read(1)\n     chars.append(c)\n", "before": "while c != '\\n' : chars . append ( c ) c = self . read ( 1 )", "after": "while c and c != '\\n' : chars . append ( c ) c = self . read ( 1 )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"while_statement\", 3, 5, 5, 23], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:c\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 11, 3, 20], 2]]"}
{"project": "pants", "commit_sha": "51791cd221c8f696beb14332d91b145dad7c3b7e", "parent_sha": "eb23af42cd8eec44d242bc17781e959007e28fd3", "file_path": "src/python/twitter/pants/targets/internal.py", "project_url": "https://github.com/square/pants", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -62,7 +62,7 @@ class InternalTarget(Target):\n     def invert(target):\n       if target not in visited:\n         visited.add(target)\n-        if target.internal_dependencies:\n+        if hasattr(target, 'internal_dependencies') and target.internal_dependencies:\n           for internal_dependency in target.internal_dependencies:\n             if isinstance(internal_dependency, InternalTarget):\n               inverted_deps[internal_dependency].add(target)\n", "before": "if target . internal_dependencies : for internal_dependency in target . internal_dependencies : if isinstance ( internal_dependency , InternalTarget ) : inverted_deps [ internal_dependency ] . add ( target )", "after": "if hasattr ( target , 'internal_dependencies' ) and target . internal_dependencies : for internal_dependency in target . internal_dependencies : if isinstance ( internal_dependency , InternalTarget ) : inverted_deps [ internal_dependency ] . add ( target )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 61], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 12, 3, 40], 2], [\"Insert\", \"N1\", [\"identifier:hasattr\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:target\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"string:'internal_dependencies'\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "Pyglet", "commit_sha": "7b2c45728b5dddb4b83c3e8a5da63457ffbe4e64", "parent_sha": "39ca0927c4039be7cf0fcae4b4e9371ccd92a11c", "file_path": "pyglet/text/runlist.py", "project_url": "https://github.com/adamlwgriffiths/Pyglet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -289,7 +289,8 @@ class RunIterator(AbstractRunIterator):\n         self.start, self.end, self.value = self.next()\n \n     def __getitem__(self, index):\n-        while index >= self.end:\n+        while index >= self.end and index > self.start:\n+            # condition has special case for 0-length run (fixes issue 471)\n             self.start, self.end, self.value = self.next()\n         return self.value\n \n", "before": "while index >= self . end : self . start , self . end , self . value = self . next ( )", "after": "while index >= self . end and index > self . start : self . start , self . end , self . value = self . next ( )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"while_statement\", 3, 9, 4, 59], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 15, 3, 32], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:index\", \"T\"], 0], [\"Insert\", \"N1\", [\">:>\", \"T\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 2], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:start\", \"T\"], 2]]"}
{"project": "Pyglet", "commit_sha": "4cee421dd8e33c828a7ab9092e5bc85ac7fa76f8", "parent_sha": "3a47f5b3bc85ca8562b51b12dc2a02a88e655329", "file_path": "pyglet/window/xlib/__init__.py", "project_url": "https://github.com/adamlwgriffiths/Pyglet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1071,7 +1071,7 @@ class XlibWindow(BaseWindow):\n         elif ev.type == xlib.KeyRelease:\n             if symbol:\n                 self.dispatch_event('on_key_release', symbol, modifiers)\n-                if _can_detect_autorepeat:\n+                if _can_detect_autorepeat and symbol in self.pressed_keys:\n                     self.pressed_keys.remove(symbol)\n \n     @XlibEventHandler(xlib.KeyPress)\n", "before": "if _can_detect_autorepeat : self . pressed_keys . remove ( symbol )", "after": "if _can_detect_autorepeat and symbol in self . pressed_keys : self . pressed_keys . remove ( symbol )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 4, 53], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:_can_detect_autorepeat\", 3, 20, 3, 42], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:symbol\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 2], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:pressed_keys\", \"T\"], 2]]"}
{"project": "PyNMRSTAR", "commit_sha": "3b68e6ce5eb68d82b425aaa90a487b77590f6181", "parent_sha": "c51e98faf550e2813c9f1b225e23c3dce9a26818", "file_path": "pynmrstar/saveframe.py", "project_url": "https://github.com/uwbmrb/PyNMRSTAR", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -148,7 +148,7 @@ class Saveframe(object):\n                         else:\n                             tag_value = None\n                             if kwargs['default_values']:\n-                                if item['default value'] != \"?\":\n+                                if item['default value'] != \"?\" and item['default value'] != '':\n                                     tag_value = item['default value']\n                             # Unconditional add\n                             if kwargs['all_tags']:\n", "before": "if item [ 'default value' ] != \"?\" : tag_value = item [ 'default value' ]", "after": "if item [ 'default value' ] != \"?\" and item [ 'default value' ] != '' : tag_value = item [ 'default value' ]", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 33, 4, 70], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 36, 3, 64], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"subscript\", \"N2\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:''\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:item\", \"T\"], 0], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N2\", [\"string:'default value'\", \"T\"], 2], [\"Insert\", \"N2\", [\"]:]\", \"T\"], 3]]"}
{"project": "NiceLib", "commit_sha": "96df426ceff80d3061cf5a6895dae7df64521c5a", "parent_sha": "28071b2c6cf3b8ca5ecd10882eae7d2a2debe798", "file_path": "nicelib/process.py", "project_url": "https://github.com/mabuchilab/NiceLib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -257,7 +257,7 @@ class Parser(object):\n             except EndOfStreamError:\n                 break\n \n-            if update_cb:\n+            if update_cb and self.out:\n                 update_cb(self.out[-1].line, self.last_line)\n \n         for macro in self.all_macros.values():\n", "before": "if update_cb : update_cb ( self . out [ - 1 ] . line , self . last_line )", "after": "if update_cb and self . out : update_cb ( self . out [ - 1 ] . line , self . last_line )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 61], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:update_cb\", 3, 16, 3, 25], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:out\", \"T\"], 2]]"}
{"project": "udapi-python", "commit_sha": "4308479b2930b5a672bfcd15e587a16934ebf7cd", "parent_sha": "ed6ffdef5d062495381d71d460abe38a48f43d84", "file_path": "udapi/block/ud/markbugs.py", "project_url": "https://github.com/udapi/udapi-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -47,7 +47,7 @@ class MarkBugs(Block):\n \n     def log(self, node, short_msg, long_msg):\n         \"\"\"Log node.address() + long_msg and add ToDo=short_msg to node.misc.\"\"\"\n-        if self.skip_re.search(short_msg):\n+        if self.skip_re is not None and self.skip_re.search(short_msg):\n             return\n         logging.debug('node %s %s: %s', node.address(), short_msg, long_msg)\n         if node.misc['Bug']:\n", "before": "if self . skip_re . search ( short_msg ) : return", "after": "if self . skip_re is not None and self . skip_re . search ( short_msg ) : return", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 19], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 42], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 2], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 3], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:skip_re\", \"T\"], 2]]"}
{"project": "SymPortal_framework", "commit_sha": "78c4ea31922b3a08eddfc119890c014a62f61c2a", "parent_sha": "1bff7f49b9d3c0ad557bf8edcc72c6b938d21f5e", "file_path": "symportal_utils.py", "project_url": "https://github.com/SymPortal/SymPortal_framework", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -436,7 +436,7 @@ class MothurAnalysis:\n     def _make_new_fasta_no_multi_match_lines(self, scrapped_fasta_as_list):\n         new_scrapped_fasta = []\n         for i in range(0, len(scrapped_fasta_as_list), 2):\n-            if not 'multipleMatches' in scrapped_fasta_as_list[i]:\n+            if not 'multipleMatches' in scrapped_fasta_as_list[i] and len(scrapped_fasta_as_list[i + 1]) > 1:\n                 new_scrapped_fasta.extend([scrapped_fasta_as_list[i], scrapped_fasta_as_list[i + 1]])\n         return new_scrapped_fasta\n \n", "before": "if not 'multipleMatches' in scrapped_fasta_as_list [ i ] : new_scrapped_fasta . extend ( [ scrapped_fasta_as_list [ i ] , scrapped_fasta_as_list [ i + 1 ] ] )", "after": "if not 'multipleMatches' in scrapped_fasta_as_list [ i ] and len ( scrapped_fasta_as_list [ i + 1 ] ) > 1 : new_scrapped_fasta . extend ( [ scrapped_fasta_as_list [ i ] , scrapped_fasta_as_list [ i + 1 ] ] )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 16, 3, 66], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 66], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\">:>\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:1\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"subscript\", \"N4\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:scrapped_fasta_as_list\", \"T\"], 0], [\"Insert\", \"N4\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N4\", [\"binary_operator\", \"N5\"], 2], [\"Insert\", \"N4\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N5\", [\"identifier:i\", \"T\"], 0], [\"Insert\", \"N5\", [\"+:+\", \"T\"], 1], [\"Insert\", \"N5\", [\"integer:1\", \"T\"], 2]]"}
{"project": "urdfpy", "commit_sha": "b779c5fef4ebe6f7e565a223bbd1b5607a679b32", "parent_sha": "0c0ce97315149d4321f2d5d73d10662f82c5f814", "file_path": "urdfpy/urdf.py", "project_url": "https://github.com/mmatl/urdfpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -805,7 +805,7 @@ class URDF(URDFType):\n \n                 pose = child_pose.dot(pose)\n \n-                if link_to_pose[parent] is not None:\n+                if parent in link_to_pose and link_to_pose[parent] is not None:\n                     pose = link_to_pose[parent].dot(pose)\n                     break\n \n", "before": "if link_to_pose [ parent ] is not None : pose = link_to_pose [ parent ] . dot ( pose ) break", "after": "if parent in link_to_pose and link_to_pose [ parent ] is not None : pose = link_to_pose [ parent ] . dot ( pose ) break", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 5, 26], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 52], 2], [\"Insert\", \"N1\", [\"identifier:parent\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:link_to_pose\", \"T\"], 2]]"}
{"project": "odoo-celery", "commit_sha": "87f6ffde59dd3b678bfc278b9522e037a52b3e69", "parent_sha": "d4ef637bb731c6bdf430b8c54f298ef997975ecc", "file_path": "celery/models/celery_task.py", "project_url": "https://github.com/novacode-nl/odoo-celery", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -216,7 +216,7 @@ class CeleryTask(models.Model):\n                 else:\n                     res = getattr(model_obj.with_env(env), method)(task_uuid, **kwargs)\n \n-                if not bool(res):\n+                if res != False and not bool(res):\n                     msg = \"No result/return value for Task UUID: %s. Ensure the task-method returns a value.\" % task_uuid\n                     logger.error(msg)\n                     raise CeleryTaskNoResultError(msg)\n", "before": "if not bool ( res ) : msg = \"No result/return value for Task UUID: %s. Ensure the task-method returns a value.\" % task_uuid logger . error ( msg ) raise CeleryTaskNoResultError ( msg )", "after": "if res != False and not bool ( res ) : msg = \"No result/return value for Task UUID: %s. Ensure the task-method returns a value.\" % task_uuid logger . error ( msg ) raise CeleryTaskNoResultError ( msg )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 6, 55], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"not_operator\", 3, 20, 3, 33], 2], [\"Insert\", \"N1\", [\"identifier:res\", \"T\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"false:False\", \"T\"], 2]]"}
{"project": "configparser", "commit_sha": "884b8e6833b60b1e4ff5942b8501ef343cbd6ea3", "parent_sha": "ae86f34217edad9ceef24f513b89ddfe59822806", "file_path": "src/backports/configparser/__init__.py", "project_url": "https://github.com/jaraco/configparser", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -684,7 +684,7 @@ class RawConfigParser(MutableMapping):\n-        if PY2 and isinstance(filenames, bytes):\n+        if PY2 and isinstance(filenames, bytes) and sys.py3kwarning:\n             # we allow for a little unholy magic for Python 2 so that\n             # people not using unicode_literals can still use the library\n             # conveniently\n", "before": "if PY2 and isinstance ( filenames , bytes ) : ", "after": "if PY2 and isinstance ( filenames , bytes ) and sys . py3kwarning : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 0, 12, 0, 48], [\"boolean_operator\", 0, 12, 0, 48], 0], [\"Insert\", [\"boolean_operator\", 0, 12, 0, 48], [\"and:and\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 0, 12, 0, 48], [\"attribute\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:sys\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:py3kwarning\", \"T\"], 2]]"}
{"project": "udapi-python", "commit_sha": "df098c35fbb5f81338ccfaf8cfbac9f3e85fdee8", "parent_sha": "a977dcfd6a843758bf669db5c05480a18fd97268", "file_path": "udapi/core/node.py", "project_url": "https://github.com/udapi/udapi-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -386,7 +386,7 @@ class Node(object):\n \n     def is_descendant_of(self, node):\n         \"\"\"Is the current node a descendant of the node given as argument?\"\"\"\n-        if node._children:\n+        if node and node._children:\n             climber = self._parent\n             while climber:\n                 if climber is node:\n", "before": "if node . _children : climber = self . _parent while climber : if climber is node : ", "after": "if node and node . _children : climber = self . _parent while climber : if climber is node : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 36], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:node\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 12, 3, 26], 2]]"}
{"project": "erpnext-v7", "commit_sha": "281b07cdb6ab15068a1174255c7119258359e654", "parent_sha": "44194502033393157ee1c9dad484e4a05e81590e", "file_path": "erpnext/patches/v7_0/create_warehouse_nestedset.py", "project_url": "https://github.com/YefriTavarez/erpnext-v7", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ def check_is_warehouse_associated_with_company():\n def make_warehouse_nestedset(company=None):\n \tvalidate_parent_account_for_warehouse(company)\n \tstock_account_group = get_stock_account_group(company.name)\n-\tif not stock_account_group:\n+\tif not stock_account_group and cint(frappe.defaults.get_global_default(\"auto_accounting_for_stock\")):\n \t\treturn\n \n \tif company:\n", "before": "if not stock_account_group : return", "after": "if not stock_account_group and cint ( frappe . defaults . get_global_default ( \"auto_accounting_for_stock\" ) ) : return", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 5, 3, 28], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:stock_account_group\", 3, 9, 3, 28], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:cint\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"call\", \"N3\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N3\", [\"argument_list\", \"N5\"], 1], [\"Insert\", \"N4\", [\"attribute\", \"N6\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:get_global_default\", \"T\"], 2], [\"Insert\", \"N5\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N5\", [\"string:\\\"auto_accounting_for_stock\\\"\", \"T\"], 1], [\"Insert\", \"N5\", [\"):)\", \"T\"], 2], [\"Insert\", \"N6\", [\"identifier:frappe\", \"T\"], 0], [\"Insert\", \"N6\", [\".:.\", \"T\"], 1], [\"Insert\", \"N6\", [\"identifier:defaults\", \"T\"], 2]]"}
{"project": "vjezd", "commit_sha": "cf15999df843751760eabe1f16a8f6385dee531b", "parent_sha": "9e4e58ef30f2ac2880d96ea1f868fbd22c1daf18", "file_path": "vjezd/ports/__init__.py", "project_url": "https://github.com/blami/vjezd", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -103,7 +103,7 @@ def close_ports():\n     logger.debug('Closing ports')\n     for p in ports:\n-        if ports[p].is_open():\n+        if ports[p] and ports[p].is_open():\n             ports[p].close()\n \n \n", "before": "if ports [ p ] . is_open ( ) : ports [ p ] . close ( )", "after": "if ports [ p ] and ports [ p ] . is_open ( ) : ports [ p ] . close ( )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 2, 9, 3, 29], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"subscript\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 2, 12, 2, 30], 2], [\"Insert\", \"N1\", [\"identifier:ports\", \"T\"], 0], [\"Insert\", \"N1\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:p\", \"T\"], 2], [\"Insert\", \"N1\", [\"]:]\", \"T\"], 3]]"}
{"project": "erpnext-v7", "commit_sha": "f06796941790c1879b25de826e58656982e3893c", "parent_sha": "8f494265ba97896536731810016897106adc9774", "file_path": "setup/doctype/sales_browser_control/sales_browser_control.py", "project_url": "https://github.com/YefriTavarez/erpnext-v7", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -131,7 +131,7 @@ class DocType:\n \n     r = eval(args)\n     \n-    if r['lft'] == 0:\n+    if r['lft'] == 0 and r['action'] != 'Create':\n       n = sql(\"select lft,rgt from `tab%s` where name = '%s'\"%(r['node_title'],r['nm']))\n       r['lft'] = n[0][0]\n", "before": "if r [ 'lft' ] == 0 : n = sql ( \"select lft,rgt from `tab%s` where name = '%s'\" % ( r [ 'node_title' ] , r [ 'nm' ] ) ) r [ 'lft' ] = n [ 0 ] [ 0 ]", "after": "if r [ 'lft' ] == 0 and r [ 'action' ] != 'Create' : n = sql ( \"select lft,rgt from `tab%s` where name = '%s'\" % ( r [ 'node_title' ] , r [ 'nm' ] ) ) r [ 'lft' ] = n [ 0 ] [ 0 ]", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 5, 25], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 21], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"subscript\", \"N2\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'Create'\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:r\", \"T\"], 0], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N2\", [\"string:'action'\", \"T\"], 2], [\"Insert\", \"N2\", [\"]:]\", \"T\"], 3]]"}
{"project": "xos-1", "commit_sha": "085d088f1bdf7fae1067e9dbea2d87d8866c3f02", "parent_sha": "74470737ff8c02001301d5d3d4bd6e241ffc3ac4", "file_path": "xos/synchronizers/openstack/steps/sync_images.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ class SyncImages(OpenStackSyncStep):\n         if os.path.exists(images_path):\n             for f in os.listdir(images_path):\n                 filename = os.path.join(images_path, f)\n-                if os.path.isfile(filename):\n+                if os.path.isfile(filename) and filename.endswith(\".img\"):\n                     available_images[f] = filename\n \n         logger.info(\"SyncImages: available_images = %s\" % str(available_images))\n", "before": "if os . path . isfile ( filename ) : available_images [ f ] = filename", "after": "if os . path . isfile ( filename ) and filename . endswith ( \".img\" ) : available_images [ f ] = filename", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 4, 51], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 20, 3, 44], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"identifier:filename\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:endswith\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"string:\\\".img\\\"\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "snabb-api-backend", "commit_sha": "52537af2ea5ef888abf0512397763a4f51e0ce1c", "parent_sha": "7f8dc9b142fe4d270810ac48df5e54202dfea82e", "file_path": "snabb/quote/serializers.py", "project_url": "https://github.com/SnabbHQ/snabb-api-backend", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -54,7 +54,7 @@ class TaskSerializer(serializers.ModelSerializer):\n     dispatching_meta = serializers.SerializerMethodField('get_task_details')\n \n     def get_task_details(self, obj):\n-        if obj.task_onfleet_id:\n+        if obj.task_onfleet_id and obj.task_detail is not None:\n             details = obj.task_detail\n             response = {}\n \n", "before": "if obj . task_onfleet_id : details = obj . task_detail response = { }", "after": "if obj . task_onfleet_id and obj . task_detail is not None : details = obj . task_detail response = { }", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 5, 26], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 12, 3, 31], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 2], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 3], [\"Insert\", \"N2\", [\"identifier:obj\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:task_detail\", \"T\"], 2]]"}
{"project": "NIPAP", "commit_sha": "9760b78ed19f84fc9cb9c694507fd44d22f64432", "parent_sha": "bd62fe8681869a99df5ddf9efbec3c34226e8fba", "file_path": "nipap-cli/nipap_cli/command.py", "project_url": "https://github.com/fredsod/NIPAP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -136,7 +136,7 @@ class Command:\n                 # and set children to the option argument\n                 self.children = { 'argument': key_val['argument'] }\n \n-            if option_parsing and p == key_name:\n+            if option_parsing and p == key_name and key_name in self.children:\n                 del self.children[key_name]\n \n \n", "before": "if option_parsing and p == key_name : del self . children [ key_name ]", "after": "if option_parsing and p == key_name and key_name in self . children : del self . children [ key_name ]", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 16, 3, 48], [\"boolean_operator\", 3, 16, 3, 48], 0], [\"Insert\", [\"boolean_operator\", 3, 16, 3, 48], [\"and:and\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 16, 3, 48], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:key_name\", \"T\"], 0], [\"Insert\", \"N0\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:children\", \"T\"], 2]]"}
{"project": "Cura", "commit_sha": "556431b984616ebfed89f43ea0975e58081d7f70", "parent_sha": "f55c35df6eb93f22423a250ad9816945cc4b41d5", "file_path": "cura/Settings/MachineManager.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -461,7 +461,7 @@ class MachineManager(QObject):\n \n     @pyqtProperty(str, notify=activeQualityChanged)\n     def activeQualityName(self):\n-        if self._active_container_stack:\n+        if self._active_container_stack and self._global_container_stack:\n             quality = self._global_container_stack.findContainer({\"type\": \"quality_changes\"})\n             if quality and quality != self._empty_quality_changes_container:\n                 return quality.getName()\n", "before": "if self . _active_container_stack : quality = self . _global_container_stack . findContainer ( { \"type\" : \"quality_changes\" } ) if quality and quality != self . _empty_quality_changes_container : return quality . getName ( )", "after": "if self . _active_container_stack and self . _global_container_stack : quality = self . _global_container_stack . findContainer ( { \"type\" : \"quality_changes\" } ) if quality and quality != self . _empty_quality_changes_container : return quality . getName ( )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 41], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 12, 3, 40], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:_global_container_stack\", \"T\"], 2]]"}
{"project": "sympy", "commit_sha": "aad6ab95e78335813df0fb14f79ff2dcc626fdc1", "parent_sha": "bd8fc71a38de89b08f38a4c971569bf4d0cb9c58", "file_path": "sympy/simplify/simplify.py", "project_url": "https://github.com/grannydatasoup/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1293,7 +1293,7 @@ def clear_coefficients(expr):\n         c, expr = expr.as_coeff_Add()\n         rhs -= c\n     tmp = [(i, 1) for i in expr.free_symbols]\n-    if expr.subs(tmp) < 0:\n+    if expr.subs(tmp).is_real and expr.subs(tmp) < 0:\n         expr *= -1\n         rhs *= -1\n     return expr, (R, rhs)\n", "before": "if expr . subs ( tmp ) < 0 : expr *= - 1 rhs *= - 1", "after": "if expr . subs ( tmp ) . is_real and expr . subs ( tmp ) < 0 : expr *= - 1 rhs *= - 1", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 5, 18], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 26], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:is_real\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N3\", [\"identifier:expr\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:subs\", \"T\"], 2], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"identifier:tmp\", \"T\"], 1], [\"Insert\", \"N4\", [\"):)\", \"T\"], 2]]"}
{"project": "RatticWeb", "commit_sha": "8830d4df3bc416efb7b46c30279701c9e43644ae", "parent_sha": "c08ab6d292239c9b403a90aa559da73a19ec3622", "file_path": "staff/views.py", "project_url": "https://github.com/efornal/RatticWeb", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,7 +31,7 @@ def home(request):\n @staff_member_required\n def userdetail(request, uid):\n     user = get_object_or_404(User, pk=uid)\n-    if settings.LDAP_ENABLED:\n+    if settings.LDAP_ENABLED and not settings.USE_LDAP_GROUPS:\n         from django_auth_ldap.backend import LDAPBackend\n         popuser = LDAPBackend().populate_user(user.username)\n         if popuser is None:\n", "before": "if settings . LDAP_ENABLED : from django_auth_ldap . backend import LDAPBackend popuser = LDAPBackend ( ) . populate_user ( user . username ) if popuser is None : ", "after": "if settings . LDAP_ENABLED and not settings . USE_LDAP_GROUPS : from django_auth_ldap . backend import LDAPBackend popuser = LDAPBackend ( ) . populate_user ( user . username ) if popuser is None : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 6, 28], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 8, 3, 29], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 1], [\"Insert\", \"N2\", [\"identifier:settings\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:USE_LDAP_GROUPS\", \"T\"], 2]]"}
{"project": "Cura", "commit_sha": "89b601791d106780c7655371a34d1ef70a5c53cc", "parent_sha": "fa8b58844d6fd9146b1fa9060bb451ce4c51d7d3", "file_path": "cura/Settings/MachineManager.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ class MachineManager(QObject):\n         if active_machine_id != \"\":\n             # An active machine was saved, so restore it.\n             self.setActiveMachine(active_machine_id)\n-            if self._global_container_stack.getProperty(\"machine_extruder_count\", \"value\") > 1:\n+            if self._global_container_stack and self._global_container_stack.getProperty(\"machine_extruder_count\", \"value\") > 1:\n                 # Make sure _active_container_stack is properly initiated\n                 ExtruderManager.getInstance().setActiveExtruderIndex(0)\n \n", "before": "if self . _global_container_stack . getProperty ( \"machine_extruder_count\" , \"value\" ) > 1 : ExtruderManager . getInstance ( ) . setActiveExtruderIndex ( 0 )", "after": "if self . _global_container_stack and self . _global_container_stack . getProperty ( \"machine_extruder_count\" , \"value\" ) > 1 : ExtruderManager . getInstance ( ) . setActiveExtruderIndex ( 0 )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 5, 72], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 95], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:_global_container_stack\", \"T\"], 2]]"}
{"project": "RatticWeb", "commit_sha": "11782978d38df569e52c234b9efe6b626dd21673", "parent_sha": "beab45fbd1e50cbd622cff8ea8c608798970b9ae", "file_path": "staff/views.py", "project_url": "https://github.com/efornal/RatticWeb", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -135,7 +135,7 @@ class UpdateUser(UpdateView):\n \n     # If the password changed, set password to newpass\n     def form_valid(self, form):\n-        if form.cleaned_data['newpass'] is not None:\n+        if form.cleaned_data['newpass'] is not None and len(form.cleaned_data['newpass']) > 0:\n             form.instance.set_password(form.cleaned_data['newpass'])\n         # If user is having groups removed we want change advice for those\n         # groups\n", "before": "if form . cleaned_data [ 'newpass' ] is not None : form . instance . set_password ( form . cleaned_data [ 'newpass' ] )", "after": "if form . cleaned_data [ 'newpass' ] is not None and len ( form . cleaned_data [ 'newpass' ] ) > 0 : form . instance . set_password ( form . cleaned_data [ 'newpass' ] )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 69], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 52], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\">:>\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"subscript\", \"N4\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2], [\"Insert\", \"N4\", [\"attribute\", \"N5\"], 0], [\"Insert\", \"N4\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N4\", [\"string:'newpass'\", \"T\"], 2], [\"Insert\", \"N4\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N5\", [\"identifier:form\", \"T\"], 0], [\"Insert\", \"N5\", [\".:.\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:cleaned_data\", \"T\"], 2]]"}
{"project": "xadmin", "commit_sha": "8b4f56c9e7d06bd815340941f4b09674c2ee2308", "parent_sha": "2f341753e66311859946faf6ddc2459ed984fbcc", "file_path": "xadmin/plugins/quickform.py", "project_url": "https://github.com/zhqin9/xadmin", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -94,7 +94,7 @@ class QuickAddBtnPlugin(BaseAdminPlugin):\n         return not self.request.is_ajax()\n \n     def formfield_for_dbfield(self, formfield, db_field, **kwargs):\n-        if self.model in self.admin_site._registry and isinstance(db_field, (models.ForeignKey, models.ManyToManyField)):\n+        if formfield and self.model in self.admin_site._registry and isinstance(db_field, (models.ForeignKey, models.ManyToManyField)):\n             rel_model = get_model_from_relation(db_field)\n             if rel_model in self.admin_site._registry and self.has_model_perm(rel_model, 'add'):\n                 add_url = self.get_model_url(rel_model, 'add')\n", "before": "if self . model in self . admin_site . _registry and isinstance ( db_field , ( models . ForeignKey , models . ManyToManyField ) ) : rel_model = get_model_from_relation ( db_field ) if rel_model in self . admin_site . _registry and self . has_model_perm ( rel_model , 'add' ) : add_url = self . get_model_url ( rel_model , 'add' )", "after": "if formfield and self . model in self . admin_site . _registry and isinstance ( db_field , ( models . ForeignKey , models . ManyToManyField ) ) : rel_model = get_model_from_relation ( db_field ) if rel_model in self . admin_site . _registry and self . has_model_perm ( rel_model , 'add' ) : add_url = self . get_model_url ( rel_model , 'add' )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 121], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", \"N0\", [\"identifier:formfield\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 51], 2]]"}
{"project": "xadmin", "commit_sha": "cc901eedd566a5e5129942270fcac1fa08d474cb", "parent_sha": "8fdf42d4c6131acd0b994be6beda773311f4fbe5", "file_path": "xadmin/plugins/quickform.py", "project_url": "https://github.com/zhqin9/xadmin", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -94,7 +94,7 @@ class QuickAddBtnPlugin(BaseAdminPlugin):\n     #     return not self.request.is_ajax()\n \n     def formfield_for_dbfield(self, formfield, db_field, **kwargs):\n-        if self.model in self.admin_site._registry and isinstance(db_field, (models.ForeignKey, models.ManyToManyField)):\n+        if formfield and self.model in self.admin_site._registry and isinstance(db_field, (models.ForeignKey, models.ManyToManyField)):\n             rel_model = get_model_from_relation(db_field)\n             if rel_model in self.admin_site._registry and self.has_model_perm(rel_model, 'add'):\n                 add_url = self.get_model_url(rel_model, 'add')\n", "before": "if self . model in self . admin_site . _registry and isinstance ( db_field , ( models . ForeignKey , models . ManyToManyField ) ) : rel_model = get_model_from_relation ( db_field ) if rel_model in self . admin_site . _registry and self . has_model_perm ( rel_model , 'add' ) : add_url = self . get_model_url ( rel_model , 'add' )", "after": "if formfield and self . model in self . admin_site . _registry and isinstance ( db_field , ( models . ForeignKey , models . ManyToManyField ) ) : rel_model = get_model_from_relation ( db_field ) if rel_model in self . admin_site . _registry and self . has_model_perm ( rel_model , 'add' ) : add_url = self . get_model_url ( rel_model , 'add' )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 121], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", \"N0\", [\"identifier:formfield\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 51], 2]]"}
{"project": "pyload.plugins", "commit_sha": "5ce680890ba57c10ae8cd7a41be2666a35c96888", "parent_sha": "25df148175278a087399b11748afefc71d4e809c", "file_path": "module/AccountManager.py", "project_url": "https://github.com/vuolter/pyload.plugins", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -99,7 +99,7 @@ class AccountManager():\n             if line.startswith(\"#\"): continue\n             if line.startswith(\"version\"): continue\n             \n-            if line.endswith(\":\"):\n+            if line.endswith(\":\") and line.count(\":\") == 1:\n                 plugin = line[:-1]\n                 self.accounts[plugin] = {}\n                 \n", "before": "if line . endswith ( \":\" ) : plugin = line [ : - 1 ] self . accounts [ plugin ] = { }", "after": "if line . endswith ( \":\" ) and line . count ( \":\" ) == 1 : plugin = line [ : - 1 ] self . accounts [ plugin ] = { }", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 5, 43], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 34], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:1\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N3\", [\"identifier:line\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:count\", \"T\"], 2], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"string:\\\":\\\"\", \"T\"], 1], [\"Insert\", \"N4\", [\"):)\", \"T\"], 2]]"}
{"project": "soy", "commit_sha": "492dd2fd0f4d8f063132dc0dba856982e2221da9", "parent_sha": "bc60deb1fb4352df4221f5c7a8757eb3e5aeba44", "file_path": "soy/nlp/extractors/_word.py", "project_url": "https://github.com/summatic/soy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -283,7 +283,7 @@ class CohesionProbability:\n                     continue\n  \n                 l_words[word] = word_to_score[word]\n-                if (remove_subword) and (word[:-1] in l_words):\n+                if (remove_subword) and (droprate >= min_droprate) and  (word[:-1] in l_words):\n                     del l_words[word[:-1]]\n         \n         return l_words\n", "before": "if ( remove_subword ) and ( word [ : - 1 ] in l_words ) : del l_words [ word [ : - 1 ] ]", "after": "if ( remove_subword ) and ( droprate >= min_droprate ) and ( word [ : - 1 ] in l_words ) : del l_words [ word [ : - 1 ] ]", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 20, 3, 63], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", [\"boolean_operator\", 3, 20, 3, 63], [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"parenthesized_expression\", 3, 20, 3, 36], 0], [\"Move\", \"N0\", [\"and:and\", 3, 37, 3, 40], 1], [\"Insert\", \"N0\", [\"parenthesized_expression\", \"N1\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"comparison_operator\", \"N2\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:droprate\", \"T\"], 0], [\"Insert\", \"N2\", [\">=:>=\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:min_droprate\", \"T\"], 2]]"}
{"project": "django-localeurl", "commit_sha": "1e6af6b2d5921a06b8bc466fa412773b89fd953a", "parent_sha": "455fef10fdc3fb5008ccf9da03d5650f3142dd58", "file_path": "localeurl/utils.py", "project_url": "https://github.com/gonnado/django-localeurl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ def is_locale_independent(path):\n-    if path.startswith(settings.MEDIA_URL):\n+    if settings.MEDIA_URL and path.startswith(settings.MEDIA_URL):\n         return True\n     for path_re in LOCALE_INDEPENDENT_PATHS:\n         if path_re.search(path):\n", "before": "if path . startswith ( settings . MEDIA_URL ) : return True", "after": "if settings . MEDIA_URL and path . startswith ( settings . MEDIA_URL ) : return True", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 0, 5, 1, 20], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 0, 8, 0, 43], 2], [\"Insert\", \"N1\", [\"identifier:settings\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:MEDIA_URL\", \"T\"], 2]]"}
{"project": "h", "commit_sha": "7094a495653f87906d9d570221324c6cbc9520b2", "parent_sha": "06278fb932743e9bd7c71eecf220c89aaf8b17bb", "file_path": "gunicorn.conf.py", "project_url": "https://github.com/project-star/h", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ def post_fork(_server, _worker):\n     # Support back-ported SSL changes on Debian / Ubuntu\n     import _ssl\n     import gevent.hub\n-    if not hasattr(_ssl, '_sslwrap'):\n+    if hasattr(_ssl, 'SSLContext') and not hasattr(_ssl, '_sslwrap'):\n         gevent.hub.PYGTE279 = True\n \n     try:\n", "before": "if not hasattr ( _ssl , '_sslwrap' ) : gevent . hub . PYGTE279 = True", "after": "if hasattr ( _ssl , 'SSLContext' ) and not hasattr ( _ssl , '_sslwrap' ) : gevent . hub . PYGTE279 = True", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 4, 35], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"not_operator\", 3, 8, 3, 37], 2], [\"Insert\", \"N1\", [\"identifier:hasattr\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:_ssl\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"string:'SSLContext'\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "requests-html", "commit_sha": "7b63730e2b18c49e8241e27e3a3e96c198b96a5f", "parent_sha": "cba8a3acb84e3b2d683d2c6f51c2fcf797384c96", "file_path": "requests_html.py", "project_url": "https://github.com/wuqiangroy/requests-html", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -136,7 +136,7 @@ class HTML:\n             for link in self.find('a'):\n                 try:\n                     href = link.attrs['href']\n-                    if not href.startswith('#') and self.skip_anchors:\n+                    if not href.startswith('#') and self.skip_anchors and href not in ['javascript:;']:\n                         yield href\n                 except KeyError:\n                     pass\n", "before": "if not href . startswith ( '#' ) and self . skip_anchors : yield href", "after": "if not href . startswith ( '#' ) and self . skip_anchors and href not in [ 'javascript:;' ] : yield href", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 28, 3, 70], [\"boolean_operator\", 3, 28, 3, 70], 0], [\"Insert\", [\"boolean_operator\", 3, 28, 3, 70], [\"and:and\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 28, 3, 70], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:href\", \"T\"], 0], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 1], [\"Insert\", \"N0\", [\"in:in\", \"T\"], 2], [\"Insert\", \"N0\", [\"list\", \"N1\"], 3], [\"Insert\", \"N1\", [\"[:[\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'javascript:;'\", \"T\"], 1], [\"Insert\", \"N1\", [\"]:]\", \"T\"], 2]]"}
{"project": "kitsune", "commit_sha": "6c7977fab9a26a6c00a0bd17ad8f2b8b3d9f4615", "parent_sha": "d9cb90fb4f67d718bcf3a49a0ce22af3087b265d", "file_path": "kitsune/users/forms.py", "project_url": "https://github.com/skcrouch7/kitsune", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -460,7 +460,7 @@ def username_allowed(username):\n \n \n def _check_username(username):\n-    if not username_allowed(username):\n+    if username and not username_allowed(username):\n         msg = _('The user name you entered is inappropriate. Please pick '\n                 'another and consider that our helpers are other Firefox '\n                 'users just like you.')\n", "before": "if not username_allowed ( username ) : msg = _ ( 'The user name you entered is inappropriate. Please pick ' 'another and consider that our helpers are other Firefox ' 'users just like you.' )", "after": "if username and not username_allowed ( username ) : msg = _ ( 'The user name you entered is inappropriate. Please pick ' 'another and consider that our helpers are other Firefox ' 'users just like you.' )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 6, 40], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:username\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"not_operator\", 3, 8, 3, 38], 2]]"}
{"project": "semstr", "commit_sha": "7d7b35823157dc1d53c431d8504e25f30f3953ba", "parent_sha": "dbcbd227e3146f32b03c951acf900a4a333783bb", "file_path": "semstr/conversion/conllu.py", "project_url": "https://github.com/huji-nlp/semstr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -82,7 +82,8 @@ class ConlluConverter(DependencyConverter, convert.ConllConverter):\n         if self.is_flat(edge):  # Unanalyzable unit\n             dep_node.preterminal = edge.head.preterminal\n             dep_node.node = edge.head.node\n-        elif edge.rel == AUX:  # Attached aux as sibling of main predicate TODO update to UCCA guidelines v1.0.6\n+        elif edge.rel == AUX and edge.head.preterminal:  # Attached aux as sibling of main predicate\n+            # TODO update to UCCA guidelines v1.0.6\n             dep_node.preterminal = dep_node.node = l1.add_fnode(edge.head.preterminal, edge.rel)\n             edge.head.preterminal = l1.add_fnode(edge.head.preterminal, self.HEAD)\n         else:\n", "before": "if self . is_flat ( edge ) : dep_node . preterminal = edge . head . preterminal dep_node . node = edge . head . node elif edge . rel == AUX : dep_node . preterminal = dep_node . node = l1 . add_fnode ( edge . head . preterminal , edge . rel ) edge . head . preterminal = l1 . add_fnode ( edge . head . preterminal , self . HEAD ) else : ", "after": "if self . is_flat ( edge ) : dep_node . preterminal = edge . head . preterminal dep_node . node = edge . head . node elif edge . rel == AUX and edge . head . preterminal : dep_node . preterminal = dep_node . node = l1 . add_fnode ( edge . head . preterminal , edge . rel ) edge . head . preterminal = l1 . add_fnode ( edge . head . preterminal , self . HEAD ) else : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"elif_clause\", 3, 9, 5, 83], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 14, 3, 29], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:preterminal\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:edge\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:head\", \"T\"], 2]]"}
{"project": "semstr", "commit_sha": "f838b9f4fa607e163a9626bae7872d5de4b781c1", "parent_sha": "9105191c95087fe782aa15bf2c6bbc4271250837", "file_path": "semstr/conversion/dep.py", "project_url": "https://github.com/huji-nlp/semstr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -67,7 +67,7 @@ class DependencyConverter(FormatConverter):\n \n         @head.setter\n         def head(self, head):\n-            if self._head is not None:\n+            if self._head is not None and self in self._head.outgoing:\n                 self._head.outgoing.remove(self)\n             self._head = head\n             if head is not None:\n", "before": "if self . _head is not None : self . _head . outgoing . remove ( self )", "after": "if self . _head is not None and self in self . _head . outgoing : self . _head . outgoing . remove ( self )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 49], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 38], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:outgoing\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:_head\", \"T\"], 2]]"}
{"project": "spiderfoot", "commit_sha": "f183c396466c0f2ca289889bb55de491e29875ed", "parent_sha": "96e80b69bb4cf47bfb9625241bfd5870dd9070ad", "file_path": "modules/sfp_email.py", "project_url": "https://github.com/smicallef/spiderfoot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -93,7 +93,7 @@ class sfp_email(SpiderFootPlugin):\n \n             # Get the domain and strip potential ending .\n             mailDom = match.lower().split('@')[1].strip('.')\n-            if not self.getTarget().matches(mailDom):\n+            if not self.getTarget().matches(mailDom) and not self.getTarget().matches(match):\n                 self.sf.debug(\"External domain, so possible affiliate e-mail\")\n                 # Raw RIR data returning external e-mails generates way\n                 # too much noise.\n", "before": "if not self . getTarget ( ) . matches ( mailDom ) : self . sf . debug ( \"External domain, so possible affiliate e-mail\" )", "after": "if not self . getTarget ( ) . matches ( mailDom ) and not self . getTarget ( ) . matches ( match ) : self . sf . debug ( \"External domain, so possible affiliate e-mail\" )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 16, 3, 53], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 20, 3, 53], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"call\", \"N2\"], 1], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N3\", [\"call\", \"N5\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:matches\", \"T\"], 2], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"identifier:match\", \"T\"], 1], [\"Insert\", \"N4\", [\"):)\", \"T\"], 2], [\"Insert\", \"N5\", [\"attribute\", \"N6\"], 0], [\"Insert\", \"N5\", [\"argument_list\", \"N7\"], 1], [\"Insert\", \"N6\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N6\", [\".:.\", \"T\"], 1], [\"Insert\", \"N6\", [\"identifier:getTarget\", \"T\"], 2], [\"Insert\", \"N7\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N7\", [\"):)\", \"T\"], 1]]"}
{"project": "pritunl", "commit_sha": "83654438a812f0c87202c2ebe14fb617153cccb0", "parent_sha": "f9bd787439f1d01c6b643d841bb4f86de6996c64", "file_path": "pritunl/cache.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,7 +16,7 @@ class Cache:\n             lambda: {'subs': set(), 'msgs': collections.deque(maxlen=10)})\n \n     def _validate(self, value):\n-        if not isinstance(value, basestring):\n+        if value is not None and not isinstance(value, basestring):\n             raise TypeError('Value must be string')\n \n     def _check_ttl(self, key):\n", "before": "if not isinstance ( value , basestring ) : raise TypeError ( 'Value must be string' )", "after": "if value is not None and not isinstance ( value , basestring ) : raise TypeError ( 'Value must be string' )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 52], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"not_operator\", 3, 12, 3, 45], 2], [\"Insert\", \"N1\", [\"identifier:value\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 2], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 3]]"}
{"project": "pritunl", "commit_sha": "e9447becfb0fc41c47174b0dc860f9a9fc4b61bd", "parent_sha": "1a255b302b535f0c06eeda97639829bf96a10072", "file_path": "pritunl/handlers/admin.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -36,7 +36,7 @@ def admin_put(admin_id):\n \n         admin.username = username\n \n-    if 'password' in flask.request.json:\n+    if 'password' in flask.request.json and flask.request.json['password']:\n         password = flask.request.json['password']\n \n         if password != admin.password:\n", "before": "if 'password' in flask . request . json : password = flask . request . json [ 'password' ] if password != admin . password : ", "after": "if 'password' in flask . request . json and flask . request . json [ 'password' ] : password = flask . request . json [ 'password' ] if password != admin . password : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 6, 39], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 40], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"subscript\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'password'\", \"T\"], 2], [\"Insert\", \"N1\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:json\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:flask\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:request\", \"T\"], 2]]"}
{"project": "pritunl", "commit_sha": "9c5c5eb8f7d152939ac9403723e05b74973beb5f", "parent_sha": "a18a473f18ae198ba1bec04b8b675be7c3ae248c", "file_path": "pritunl/setup/host_fix.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1,7 +1,7 @@\n from pritunl import settings\n \n def setup_host_fix():\n-    if settings.app.license:\n+    if settings.app.license and settings.app.license_plan != \"premium\":\n         return\n \n     from pritunl import server\n", "before": "if settings . app . license : return", "after": "if settings . app . license and settings . app . license_plan != \"premium\" : return", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 4, 15], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 8, 3, 28], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:\\\"premium\\\"\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:license_plan\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:settings\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:app\", \"T\"], 2]]"}
{"project": "btcrelay", "commit_sha": "467c48af9c12bf828c2298afecbbf66d5acbbccf", "parent_sha": "13affe55791f6b9efb7ab9471df6b95294b8665f", "file_path": "fetchd/fetchd.py", "project_url": "https://github.com/Runur/btcrelay", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -215,7 +215,7 @@ def fetchHeaders(chunkStartNum, chunkSize, numChunk, feeVerifyTx, feeRecipient,\n         # CHUNK_RANGE is used when chunkSize>1 so that we ask for ETH if chunkStartNum ends in\n         # ????00, ????01, ????02 to ????04\n         if ((chunkSize == 1 and chunkStartNum % 100 == 0) or\n-            (chunkStartNum % 100 in CHUNK_RANGE)) and useWallet:\n+            (chunkSize == CHUNK_RANGE and chunkStartNum % 100 in CHUNK_RANGE)) and useWallet:\n             myWei = instance.balance_at(instance.address)\n             myBalance = myWei / 1e18\n             logger.info('myBalance ETH: %s' % myBalance)\n", "before": "if ( ( chunkSize == 1 and chunkStartNum % 100 == 0 ) or ( chunkStartNum % 100 in CHUNK_RANGE ) ) and useWallet : myWei = instance . balance_at ( instance . address ) myBalance = myWei / 1e18 logger . info ( 'myBalance ETH: %s' % myBalance )", "after": "if ( ( chunkSize == 1 and chunkStartNum % 100 == 0 ) or ( chunkSize == CHUNK_RANGE and chunkStartNum % 100 in CHUNK_RANGE ) ) and useWallet : myWei = instance . balance_at ( instance . address ) myBalance = myWei / 1e18 logger . info ( 'myBalance ETH: %s' % myBalance )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"parenthesized_expression\", 3, 13, 3, 49], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 14, 3, 48], 2], [\"Insert\", \"N1\", [\"identifier:chunkSize\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:CHUNK_RANGE\", \"T\"], 2]]"}
{"project": "pritunl", "commit_sha": "ed9ac0eabb40c9a9003ba879f4a77f57149747c6", "parent_sha": "4983a56ec2f0814778d2f9a1348047b1809c8a6d", "file_path": "pritunl/logger/formatter.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -7,7 +7,7 @@ import logging\n class LogFormatter(logging.Formatter):\n     def format(self, record):\n         formatted_record = logging.Formatter.format(self, record)\n-        if hasattr(record, 'data'):\n+        if hasattr(record, 'data') and record.data:\n             width = len(max(record.data, key=len))\n             for key, val in record.data.items():\n                 formatted_record += '\\n    %s = %r' % (key.ljust(width), val)\n", "before": "if hasattr ( record , 'data' ) : width = len ( max ( record . data , key = len ) ) for key , val in record . data . items ( ) : formatted_record += '\\n    %s = %r' % ( key . ljust ( width ) , val )", "after": "if hasattr ( record , 'data' ) and record . data : width = len ( max ( record . data , key = len ) ) for key , val in record . data . items ( ) : formatted_record += '\\n    %s = %r' % ( key . ljust ( width ) , val )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 78], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 35], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:record\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:data\", \"T\"], 2]]"}
{"project": "openstates", "commit_sha": "3e905a57af6fd9d108fb1d1fcd299259bab19352", "parent_sha": "1aacd494289adc1f0473627619d826a0da22d081", "file_path": "fiftystates/scrape/ms/bills.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -11,7 +11,7 @@ def _combine_lines(lines):\n     newlines = []\n     lastline = '.'\n     for line in lines:\n-        if lastline[-1] in '.,:':\n+        if lastline and lastline[-1] in '.,:':\n             newlines.append(line)\n             lastline = line\n         else:\n", "before": "if lastline [ - 1 ] in '.,:' : newlines . append ( line ) lastline = line else : ", "after": "if lastline and lastline [ - 1 ] in '.,:' : newlines . append ( line ) lastline = line else : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 14], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:lastline\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 33], 2]]"}
{"project": "openstates", "commit_sha": "1e6375259cd1e7b1c49b20093a8251e05ffa4b0e", "parent_sha": "da13a352be8d633a9826f50a8f386b8e34ee7c7b", "file_path": "fiftystates/scrape/tx/legislators.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -62,7 +62,7 @@ class TXLegislatorScraper(LegislatorScraper):\n                 if aspan:\n                     addrs[atype] = aspan[0].tail\n                     elem = aspan[0].getnext()\n-                    while elem.tag == 'br':\n+                    while elem and elem.tag == 'br':\n                         if elem.tail:\n                             addrs[atype] += \"\\n\" + elem.tail\n                         elem = elem.getnext()\n", "before": "while elem . tag == 'br' : if elem . tail : addrs [ atype ] += \"\\n\" + elem . tail elem = elem . getnext ( )", "after": "while elem and elem . tag == 'br' : if elem . tail : addrs [ atype ] += \"\\n\" + elem . tail elem = elem . getnext ( )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"while_statement\", 3, 21, 6, 46], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:elem\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 27, 3, 43], 2]]"}
{"project": "openstates", "commit_sha": "d516f1aa3ebc4fc66d10c9c1b101090a153c40e8", "parent_sha": "5c536c18f3bed7ba993d6857366f70a1a930c242", "file_path": "openstates/nv/bills.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -85,7 +85,7 @@ class NVBillScraper(BillScraper):\n \n                     primary, secondary = self.scrape_sponsors(page)\n \n-                    if primary[0] == 'By:':\n+                    if primary and primary[0] == 'By:':\n                         primary.pop(0)\n \n                         if primary[0] == 'ElectionsProceduresEthicsand':\n", "before": "if primary [ 0 ] == 'By:' : primary . pop ( 0 ) if primary [ 0 ] == 'ElectionsProceduresEthicsand' : ", "after": "if primary and primary [ 0 ] == 'By:' : primary . pop ( 0 ) if primary [ 0 ] == 'ElectionsProceduresEthicsand' : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 21, 6, 73], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:primary\", \"T\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 24, 3, 43], 2]]"}
{"project": "spyne", "commit_sha": "8e3325a0d3d20a5e0849b06756806ff3cd3777c7", "parent_sha": "11efe69c0af18b22dc92293c5a61ba303dd319e5", "file_path": "soaplib/serializers/clazz.py", "project_url": "https://github.com/duixteam/spyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -69,7 +69,7 @@ class ClassSerializer(object):\n \n         # Because namespaces are not getting output, explicitly set xmlns as an\n         # attribute. Otherwise .NET will reject the message.\n-        if None not in nsmap.nsmap:\n+        if None not in nsmap.nsmap and cls.get_namespace_id() in nsmap.nsmap:\n             xmlns = nsmap.nsmap[cls.get_namespace_id()]\n             element.set('xmlns', xmlns)\n         \n", "before": "if None not in nsmap . nsmap : xmlns = nsmap . nsmap [ cls . get_namespace_id ( ) ] element . set ( 'xmlns' , xmlns )", "after": "if None not in nsmap . nsmap and cls . get_namespace_id ( ) in nsmap . nsmap : xmlns = nsmap . nsmap [ cls . get_namespace_id ( ) ] element . set ( 'xmlns' , xmlns )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 5, 40], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 35], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N5\"], 1], [\"Insert\", \"N3\", [\"identifier:nsmap\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:nsmap\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:cls\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:get_namespace_id\", \"T\"], 2], [\"Insert\", \"N5\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N5\", [\"):)\", \"T\"], 1]]"}
{"project": "TreeNote", "commit_sha": "6e10d9fecaac327a3ce19d96687d5190cb5fd0d9", "parent_sha": "cd9c4d70b7001fc6d93b7b0c968022a917c7a2d6", "file_path": "treenote.py", "project_url": "https://github.com/project-renard-survey/TreeNote", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1286,7 +1286,7 @@ class MainWindow(QMainWindow):\n         indexes = self.selected_indexes()\n \n         def remove_if_parent(idx):\n-            if idx.parent() != QModelIndex():\n+            if idx.parent() != QModelIndex() and idx in indexes:\n                 if idx.parent() in indexes:\n                     indexes.remove(idx)\n                 else:\n", "before": "if idx . parent ( ) != QModelIndex ( ) : if idx . parent ( ) in indexes : indexes . remove ( idx ) else : ", "after": "if idx . parent ( ) != QModelIndex ( ) and idx in indexes : if idx . parent ( ) in indexes : indexes . remove ( idx ) else : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 22], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 45], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:idx\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:indexes\", \"T\"], 2]]"}
{"project": "openstates", "commit_sha": "4272caf590508356b15a2ef4971d0ef31446b18c", "parent_sha": "4fd8adec853c36fa349d200b7c0f4e7043ccc9a5", "file_path": "openstates/hi/bills.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -197,7 +197,7 @@ class HIBillScraper(BillScraper):\n                 \"type\" : billy_billtype\n             }\n \n-            if companion != None:\n+            if companion != None and companion.strip() != \"\":\n                 keywordargs[\"companion\"] = companion\n \n             b = Bill(session, chamber, name, title, **keywordargs)\n", "before": "if companion != None : keywordargs [ \"companion\" ] = companion", "after": "if companion != None and companion . strip ( ) != \"\" : keywordargs [ \"companion\" ] = companion", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 53], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 33], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:\\\"\\\"\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N3\", [\"identifier:companion\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:strip\", \"T\"], 2], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"):)\", \"T\"], 1]]"}
{"project": "spyne", "commit_sha": "35b38125fe218b5de6281b421a2983105676f248", "parent_sha": "c7cf50224beb224e8c173a4afba2f3db207b6261", "file_path": "spyne/protocol/html/_base.py", "project_url": "https://github.com/duixteam/spyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -162,7 +162,7 @@ class HtmlBase(ProtocolBase):\n         subprot = getattr(cls.Attributes, 'prot', None)\n         \"\"\":type : HtmlBase\"\"\"\n \n-        if subprot is not None:\n+        if subprot is not None and not (subprot is self):\n             if isinstance(subprot, HtmlBase):\n                 return subprot.to_parent(ctx, cls, inst, parent, name, **kwargs)\n             else:\n", "before": "if subprot is not None : if isinstance ( subprot , HtmlBase ) : return subprot . to_parent ( ctx , cls , inst , parent , name , ** kwargs ) else : ", "after": "if subprot is not None and not ( subprot is self ) : if isinstance ( subprot , HtmlBase ) : return subprot . to_parent ( ctx , cls , inst , parent , name , ** kwargs ) else : ", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 18], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 31], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"parenthesized_expression\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"comparison_operator\", \"N3\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:subprot\", \"T\"], 0], [\"Insert\", \"N3\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:self\", \"T\"], 2]]"}
{"project": "pyspider", "commit_sha": "e9263678801fe146dcd56518d87dff40e9cd289e", "parent_sha": "d6606964e184ab3328cb04e360475783eb5ca802", "file_path": "pyspider/scheduler/scheduler.py", "project_url": "https://github.com/atlas555/pyspider", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -574,7 +574,7 @@ class Scheduler(object):\n         schedule_age = _schedule.get('age', self.default_schedule['age'])\n         if _schedule.get('itag') and _schedule['itag'] != old_schedule.get('itag'):\n             restart = True\n-        elif schedule_age >= 0 and schedule_age + (old_task['lastcrawltime'] or 0) < now:\n+        elif 'lastcrawltime' in old_task and schedule_age >= 0 and schedule_age + (old_task['lastcrawltime'] or 0) < now:\n             restart = True\n         elif _schedule.get('force_update'):\n             restart = True\n", "before": "if _schedule . get ( 'itag' ) and _schedule [ 'itag' ] != old_schedule . get ( 'itag' ) : restart = True elif schedule_age >= 0 and schedule_age + ( old_task [ 'lastcrawltime' ] or 0 ) < now : restart = True elif _schedule . get ( 'force_update' ) : restart = True", "after": "if _schedule . get ( 'itag' ) and _schedule [ 'itag' ] != old_schedule . get ( 'itag' ) : restart = True elif 'lastcrawltime' in old_task and schedule_age >= 0 and schedule_age + ( old_task [ 'lastcrawltime' ] or 0 ) < now : restart = True elif _schedule . get ( 'force_update' ) : restart = True", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 14, 3, 89], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 14, 3, 31], 2], [\"Insert\", \"N1\", [\"string:'lastcrawltime'\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:old_task\", \"T\"], 2]]"}
{"project": "anki-addons-dae", "commit_sha": "0c3da119ff2d04f5e99e825d65399b768fc61c54", "parent_sha": "cff52ce439406f433373f2a38349b919bbd4f28d", "file_path": "chinese.py", "project_url": "https://github.com/glutanimate/anki-addons-dae", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -181,7 +181,7 @@ def onFocusLost(fact, field):\n     dstField = dstFields[idx]\n \n     try:\n-        if fact[dstField]:\n+        if fact[dstField] and fact[dstField] != \"<br />\":\n             return\n     except:\n         return\n", "before": "if fact [ dstField ] : return", "after": "if fact [ dstField ] and fact [ dstField ] != \"<br />\" : return", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 19], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"subscript\", 3, 12, 3, 26], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"subscript\", \"N2\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:\\\"<br />\\\"\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:fact\", \"T\"], 0], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:dstField\", \"T\"], 2], [\"Insert\", \"N2\", [\"]:]\", \"T\"], 3]]"}
{"project": "openobject-client-6.0", "commit_sha": "26d723313a0f5a8091f7875a2ab64a83efea0b6a", "parent_sha": "d8506f11fc094a97169381f74dec1bfcda252d77", "file_path": "bin/modules/gui/window/__init__.py", "project_url": "https://github.com/hunslater/openobject-client-6.0", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ class window(service.Service):\n \t\t\tspool = service.LocalService('spool')\n \t\t\tspool.publish('gui.window', win, {})\n \t\telif view_type=='tree':\n-\t\t\tif view_ids:\n+\t\t\tif view_ids and view_ids[0]:\n \t\t\t\tview_base =  rpc.session.rpc_exec_auth('/object', 'execute', 'ir.ui.view', 'read', [view_ids[0]], ['model', 'type'], context)[0]\n \t\t\t\tmodel = view_base['model']\n \t\t\t\tview = rpc.session.rpc_exec_auth('/object', 'execute', view_base['model'], 'fields_view_get', view_ids[0], view_base['type'],context)\n", "before": "if view_ids : view_base = rpc . session . rpc_exec_auth ( '/object' , 'execute' , 'ir.ui.view' , 'read' , [ view_ids [ 0 ] ] , [ 'model' , 'type' ] , context ) [ 0 ] model = view_base [ 'model' ] view = rpc . session . rpc_exec_auth ( '/object' , 'execute' , view_base [ 'model' ] , 'fields_view_get' , view_ids [ 0 ] , view_base [ 'type' ] , context )", "after": "if view_ids and view_ids [ 0 ] : view_base = rpc . session . rpc_exec_auth ( '/object' , 'execute' , 'ir.ui.view' , 'read' , [ view_ids [ 0 ] ] , [ 'model' , 'type' ] , context ) [ 0 ] model = view_base [ 'model' ] view = rpc . session . rpc_exec_auth ( '/object' , 'execute' , view_base [ 'model' ] , 'fields_view_get' , view_ids [ 0 ] , view_base [ 'type' ] , context )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 4, 6, 138], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:view_ids\", 3, 7, 3, 15], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"subscript\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:view_ids\", \"T\"], 0], [\"Insert\", \"N1\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N1\", [\"]:]\", \"T\"], 3]]"}
{"project": "openobject-client-6.0", "commit_sha": "1893b865cc14451810d27daece647aa476922574", "parent_sha": "96b465492117f10898b92836d17f7330bbc23f70", "file_path": "bin/printer/printer.py", "project_url": "https://github.com/hunslater/openobject-client-6.0", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -89,7 +89,7 @@ class Printer(object):\n         os.waitpid(pid, 0)\n \n     def _findPDFOpener(self):\n-        if os.uname()[0] == 'Darwin' :\n+        if os.name != 'nt' and os.uname()[0] == 'Darwin' :\n             def opener(fn):\n                 self.__opener( lambda: os.system('/usr/bin/open -a Preview ' + fn) )\n             return opener\n", "before": "if os . uname ( ) [ 0 ] == 'Darwin' : def opener ( fn ) : self . __opener ( lambda : os . system ( '/usr/bin/open -a Preview ' + fn ) ) return opener", "after": "if os . name != 'nt' and os . uname ( ) [ 0 ] == 'Darwin' : def opener ( fn ) : self . __opener ( lambda : os . system ( '/usr/bin/open -a Preview ' + fn ) ) return opener", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 26], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 37], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'nt'\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:name\", \"T\"], 2]]"}
{"project": "Crowdfunding-Backend", "commit_sha": "a9ba523b7b9be88850290a58d7158122cbc0931b", "parent_sha": "343a92653812794bf367316eff422bc895b51d7e", "file_path": "poliedro_donate/blueprints/paypal.py", "project_url": "https://github.com/poliedro-polimi/Crowdfunding-Backend", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -123,7 +123,7 @@ def execute_payment():\n                 raise braintreehttp.http_error.HttpError(r.text, r.status_code, r.headers)\n         except IOError as ioe:\n             ioe.body = body\n-            if isinstance(ioe, braintreehttp.http_error.HttpError):\n+            if isinstance(ioe, braintreehttp.http_error.HttpError) and json.loads(ioe.message).get(\"name\"):\n                 donation.transaction.state = json.loads(ioe.message)[\"name\"]\n             else:\n                 donation.transaction.state = str(ioe.__class__.__name__)\n", "before": "if isinstance ( ioe , braintreehttp . http_error . HttpError ) : donation . transaction . state = json . loads ( ioe . message ) [ \"name\" ] else : donation . transaction . state = str ( ioe . __class__ . __name__ )", "after": "if isinstance ( ioe , braintreehttp . http_error . HttpError ) and json . loads ( ioe . message ) . get ( \"name\" ) : donation . transaction . state = json . loads ( ioe . message ) [ \"name\" ] else : donation . transaction . state = str ( ioe . __class__ . __name__ )", "sstub_pattern": "MORE_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 73], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 67], 0], [\"Insert\", \"N0\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"call\", \"N4\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:get\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"string:\\\"name\\\"\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2], [\"Insert\", \"N4\", [\"attribute\", \"N5\"], 0], [\"Insert\", \"N4\", [\"argument_list\", \"N6\"], 1], [\"Insert\", \"N5\", [\"identifier:json\", \"T\"], 0], [\"Insert\", \"N5\", [\".:.\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:loads\", \"T\"], 2], [\"Insert\", \"N6\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N6\", [\"attribute\", \"N7\"], 1], [\"Insert\", \"N6\", [\"):)\", \"T\"], 2], [\"Insert\", \"N7\", [\"identifier:ioe\", \"T\"], 0], [\"Insert\", \"N7\", [\".:.\", \"T\"], 1], [\"Insert\", \"N7\", [\"identifier:message\", \"T\"], 2]]"}
{"project": "dexy", "commit_sha": "0e996eac07bba5392c490f554c98f80b98b71d4b", "parent_sha": "70b374884f92d07d8e3434db39ffba4b1627d610", "file_path": "handlers/subprocess.py", "project_url": "https://github.com/mojavelinux/dexy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -263,7 +263,7 @@ class VoiceHandler(DexyHandler):\n         elif e == \"espeak\":\n             command = \"/usr/bin/env espeak -f %s -w %s\" % (work_file, sound_file)\n         else:\n-            raise Exception(\"unknown tts command %s\" % e)\n+            raise Exception(\"unknown text-to-speech command %s\" % e)\n \n         self.log.info(command)\n         self.artifact.stdout = pexpect.run(command, cwd=self.artifact.artifacts_dir)\n", "before": "else : raise Exception ( \"unknown tts command %s\" % e )", "after": "else : raise Exception ( \"unknown text-to-speech command %s\" % e )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"unknown tts command %s\\\"\", 3, 29, 3, 53], \"\\\"unknown text-to-speech command %s\\\"\"]]"}
{"project": "SleekXMPP", "commit_sha": "41991b5982e6cfc9015eaf00663348ca6d4d3b2d", "parent_sha": "518eee05c224b00cf4622038290f5fb0c0d4e95b", "file_path": "sleekxmpp/plugins/xep_0153/vcard_avatar.py", "project_url": "https://github.com/mayflower/SleekXMPP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -87,7 +87,7 @@ class XEP_0153(BasePlugin):\n                 new_hash = hashlib.sha1(data).hexdigest()\n             self.api['set_hash'](self.xmpp.boundjid, args=new_hash)\n         except XMPPError:\n-            log.debug('Could not retrieve vCard for %s' % jid)\n+            log.debug('Could not retrieve vCard for %s' % self.xmpp.boundjid.bare)\n \n         self._allow_advertising.set()\n \n", "before": "except XMPPError : log . debug ( 'Could not retrieve vCard for %s' % jid )", "after": "except XMPPError : log . debug ( 'Could not retrieve vCard for %s' % self . xmpp . boundjid . bare )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 23, 3, 62], [\"attribute\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:bare\", \"T\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:boundjid\", \"T\"], 2], [\"Update\", [\"identifier:jid\", 3, 59, 3, 62], \"self\"], [\"Move\", \"N2\", [\"identifier:jid\", 3, 59, 3, 62], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:xmpp\", \"T\"], 2]]"}
{"project": "SleekXMPP", "commit_sha": "01e1878900f9206f7672b2f8a6fcfc28dbed5166", "parent_sha": "df9ad823360dd7fd8472d05d072bc4529819ddaa", "file_path": "sleekxmpp/util/sasl/mechanisms.py", "project_url": "https://github.com/mayflower/SleekXMPP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -111,7 +111,7 @@ class X_FACEBOOK_PLATFORM(Mech):\n                 b'api_key': self.credentials['api_key']\n             }\n \n-            resp = '&'.join(['%s=%s' % (k, v) for k, v in resp_data.items()])\n+            resp = '&'.join(['%s=%s' % (k.decode(\"utf-8\"), v.decode(\"utf-8\")) for k, v in resp_data.items()])\n             return bytes(resp)\n         return b''\n \n", "before": "resp = '&' . join ( [ '%s=%s' % ( k , v ) for k , v in resp_data . items ( ) ] )", "after": "resp = '&' . join ( [ '%s=%s' % ( k . decode ( \"utf-8\" ) , v . decode ( \"utf-8\" ) ) for k , v in resp_data . items ( ) ] )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"tuple\", 3, 40, 3, 46], [\"call\", \"N0\"], 1], [\"Insert\", [\"tuple\", 3, 40, 3, 46], [\"call\", \"N1\"], 4], [\"Insert\", [\"tuple\", 3, 40, 3, 46], [\"):)\", \"T\"], 5], [\"Insert\", \"N0\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N5\"], 1], [\"Move\", \"N2\", [\"identifier:k\", 3, 41, 3, 42], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"string:\\\"utf-8\\\"\", \"T\"], 1], [\"Move\", \"N3\", [\"):)\", 3, 45, 3, 46], 2], [\"Move\", \"N4\", [\"identifier:v\", 3, 44, 3, 45], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N5\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N5\", [\"string:\\\"utf-8\\\"\", \"T\"], 1], [\"Insert\", \"N5\", [\"):)\", \"T\"], 2]]"}
{"project": "SleekXMPP", "commit_sha": "94187d215a87a9acb61dba8d0d0b60fb397f93be", "parent_sha": "ef2f5d29788218f679cd878e4e25bbd61545fef4", "file_path": "sleekxmpp/util/sasl/mechanisms.py", "project_url": "https://github.com/mayflower/SleekXMPP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -541,7 +541,7 @@ else:\n \n                 resp = kerberos.authGSSClientResponse(self.gss)\n             except kerberos.GSSError as e:\n-                raise SASLCancelled('Kerberos error: %s' % e.message)\n+                raise SASLCancelled('Kerberos error: %s' % e)\n             if not resp:\n                 return b''\n             else:\n", "before": "except kerberos . GSSError as e : raise SASLCancelled ( 'Kerberos error: %s' % e . message )", "after": "except kerberos . GSSError as e : raise SASLCancelled ( 'Kerberos error: %s' % e )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"binary_operator\", 3, 37, 3, 69], [\"identifier:e\", 3, 60, 3, 61], 2], [\"Delete\", [\".:.\", 3, 61, 3, 62]], [\"Delete\", [\"identifier:message\", 3, 62, 3, 69]], [\"Delete\", [\"attribute\", 3, 60, 3, 69]]]"}
{"project": "nixops", "commit_sha": "3c9eaf5533aa7245247456a3516ab1a96cf9f3ad", "parent_sha": "07d3c77456f767b7b3729d19bce7c8b6410d22aa", "file_path": "charon/deployment.py", "project_url": "https://github.com/zalora/nixops", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -331,7 +331,7 @@ class Deployment:\n     def _get_free_machine_index(self):\n         index = 0\n         for m in self.machines.itervalues():\n-            if m.index != None and m.index <= index:\n+            if m.index != None and index <= m.index:\n                 index = m.index + 1\n         return index\n             \n", "before": "if m . index != None and m . index <= index : index = m . index + 1", "after": "if m . index != None and index <= m . index : index = m . index + 1", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 36, 3, 52], [\"identifier:index\", \"T\"], 0], [\"Insert\", [\"comparison_operator\", 3, 36, 3, 52], [\"<=:<=\", \"T\"], 1], [\"Delete\", [\"<=:<=\", 3, 44, 3, 46]], [\"Delete\", [\"identifier:index\", 3, 47, 3, 52]]]"}
{"project": "django-session-security", "commit_sha": "f86286267677b8ace03095563141c995d3664235", "parent_sha": "113394f040e6a69c0f02a45226915803b8cc57d4", "file_path": "session_security/settings.py", "project_url": "https://github.com/precond/django-session-security", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ def get_expire_after(request):\n         EXPIRE_AFTER_CUSTOM_SESSION_KEY\n     )\n \n-    if type(expire_after_value) == int and expire_after_value > 0:\n+    if isinstance(expire_after_value, int) and expire_after_value > 0:\n         return expire_after_value\n     else:\n         return EXPIRE_AFTER\n", "before": "if type ( expire_after_value ) == int and expire_after_value > 0 : return expire_after_value else : return EXPIRE_AFTER", "after": "if isinstance ( expire_after_value , int ) and expire_after_value > 0 : return expire_after_value else : return EXPIRE_AFTER", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 8, 3, 66], [\"call\", 3, 8, 3, 32], 0], [\"Update\", [\"identifier:type\", 3, 8, 3, 12], \"isinstance\"], [\"Insert\", [\"argument_list\", 3, 12, 3, 32], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 12, 3, 32], [\"identifier:int\", \"T\"], 3], [\"Delete\", [\"==:==\", 3, 33, 3, 35]], [\"Delete\", [\"identifier:int\", 3, 36, 3, 39]], [\"Delete\", [\"comparison_operator\", 3, 8, 3, 39]]]"}
{"project": "dexy", "commit_sha": "c2c89b3aa3cd3ad155e1d16b4f6baad8fb2684b5", "parent_sha": "ee6cb5ffb10435fe43750a0435bde968ed0642e8", "file_path": "dexy/filter.py", "project_url": "https://github.com/mojavelinux/dexy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -141,7 +141,7 @@ class Filter(dexy.plugin.Plugin):\n                 else:\n                     if set(i_output).isdisjoint(set(next_filter_accepts)):\n                         msg = \"Filter %s can't go after filter %s, no file extensions in common.\"\n-                        raise dexy.exceptions.UserFeedback(msg % (self.next_filter_alias, self.filter_alias))\n+                        raise dexy.exceptions.UserFeedback(msg % (self.next_filter.alias, self.alias))\n \n                     for e in i_output:\n                         if e in next_filter_accepts:\n", "before": "raise dexy . exceptions . UserFeedback ( msg % ( self . next_filter_alias , self . filter_alias ) )", "after": "raise dexy . exceptions . UserFeedback ( msg % ( self . next_filter . alias , self . alias ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"tuple\", 3, 66, 3, 109], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 67, 3, 89], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:alias\", \"T\"], 2], [\"Update\", [\"identifier:filter_alias\", 3, 96, 3, 108], \"alias\"], [\"Update\", [\"identifier:next_filter_alias\", 3, 72, 3, 89], \"next_filter\"]]"}
{"project": "pyjade", "commit_sha": "8aef6db0e8d11ea2fd059eb9d8c97e91025ac0c8", "parent_sha": "0bbe0bd1c3aac19a8563db0d0d318fdeabafe476", "file_path": "pyjade/lexer.py", "project_url": "https://github.com/underdogio/pyjade", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -279,7 +279,7 @@ class Lexer(object):\n                 return states[-1]\n \n             def interpolate(attr):\n-                attr, num = self.RE_ATTR_INTERPOLATE.subn(lambda matchobj:'%s+%s|string+%s'%(ns.quote,matchobj.group(1),ns.quote),attr)\n+                attr, num = self.RE_ATTR_INTERPOLATE.subn(lambda matchobj:'%s+%s+%s'%(ns.quote,matchobj.group(1),ns.quote),attr)\n                 return attr, (num>0)\n \n             self.consume(index+1)\n", "before": "attr , num = self . RE_ATTR_INTERPOLATE . subn ( lambda matchobj : '%s+%s|string+%s' % ( ns . quote , matchobj . group ( 1 ) , ns . quote ) , attr )", "after": "attr , num = self . RE_ATTR_INTERPOLATE . subn ( lambda matchobj : '%s+%s+%s' % ( ns . quote , matchobj . group ( 1 ) , ns . quote ) , attr )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'%s+%s|string+%s'\", 3, 75, 3, 92], \"'%s+%s+%s'\"]]"}
{"project": "splinter", "commit_sha": "81577733a73aa8a68b3a035c2a841fff0378dcc4", "parent_sha": "6c07e3e6f65c484d1d862ca265ad5863acc69257", "file_path": "splinter/driver/webdriver/__init__.py", "project_url": "https://github.com/underdogio/splinter", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -226,7 +226,7 @@ class BaseWebDriver(DriverAPI):\n         for name, value in field_values.items():\n             elements = self.find_by_name(name)\n             element = elements.first\n-            if element['type'] == 'text' or element['type'] == 'password' or element.tag_name == 'textarea':\n+            if element['type'] in ['text', 'password'] or element.tag_name == 'textarea':\n                 element.value = value\n             elif element['type'] == 'checkbox':\n                 if value:\n", "before": "if element [ 'type' ] == 'text' or element [ 'type' ] == 'password' or element . tag_name == 'textarea' : element . value = value elif element [ 'type' ] == 'checkbox' : if value : ", "after": "if element [ 'type' ] in [ 'text' , 'password' ] or element . tag_name == 'textarea' : element . value = value elif element [ 'type' ] == 'checkbox' : if value : ", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 16, 3, 108], [\"comparison_operator\", 3, 16, 3, 41], 0], [\"Insert\", [\"comparison_operator\", 3, 16, 3, 41], [\"in:in\", \"T\"], 1], [\"Insert\", [\"comparison_operator\", 3, 16, 3, 41], [\"list\", \"N0\"], 2], [\"Move\", \"N0\", [\"[:[\", 3, 52, 3, 53], 0], [\"Move\", \"N0\", [\"string:'text'\", 3, 35, 3, 41], 1], [\"Insert\", \"N0\", [\",:,\", \"T\"], 2], [\"Move\", \"N0\", [\"string:'password'\", 3, 64, 3, 74], 3], [\"Insert\", \"N0\", [\"]:]\", \"T\"], 4], [\"Delete\", [\"==:==\", 3, 32, 3, 34]], [\"Delete\", [\"or:or\", 3, 42, 3, 44]], [\"Delete\", [\"identifier:element\", 3, 45, 3, 52]], [\"Delete\", [\"string:'type'\", 3, 53, 3, 59]], [\"Delete\", [\"]:]\", 3, 59, 3, 60]], [\"Delete\", [\"subscript\", 3, 45, 3, 60]], [\"Delete\", [\"==:==\", 3, 61, 3, 63]], [\"Delete\", [\"comparison_operator\", 3, 45, 3, 74]], [\"Delete\", [\"boolean_operator\", 3, 16, 3, 74]]]"}
{"project": "flask-oauthlib", "commit_sha": "9e61643de4f0d37ea07d4649333ca34ddb347066", "parent_sha": "644988cc0aa5045d8bae875e8262ead341c3ee33", "file_path": "flask_oauthlib/client.py", "project_url": "https://github.com/underdogio/flask-oauthlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -563,7 +563,7 @@ class OAuthRemoteApp(object):\n             )\n         else:\n             raise OAuthException(\n-                'Unsupported access_token_method: ' %\n+                'Unsupported access_token_method: %s' %\n                 self.access_token_method\n             )\n \n", "before": "raise OAuthException ( 'Unsupported access_token_method: ' % self . access_token_method )", "after": "raise OAuthException ( 'Unsupported access_token_method: %s' % self . access_token_method )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'Unsupported access_token_method: '\", 3, 17, 3, 52], \"'Unsupported access_token_method: %s'\"]]"}
{"project": "carbon", "commit_sha": "a5cae9f32a9eb3303b9db1add1f68c429217fd18", "parent_sha": "19cf09af1cc62f48200839a15f6946d7dbe7506a", "file_path": "lib/carbon/writer.py", "project_url": "https://github.com/jfarrell/carbon", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ def writeCachedDataPoints():\n           raise Exception(\"No storage schema matched the metric '%s', check your storage-schemas.conf file.\")\n \n         dbDir = dirname(dbFilePath)\n-        os.system(\"mkdir -p '%s'\" % dbDir)\n+        os.system(\"mkdir -p -m 755 '%s'\" % dbDir)\n \n         log.creates(\"creating database file %s\" % dbFilePath)\n         whisper.create(dbFilePath, archiveConfig)\n", "before": "os . system ( \"mkdir -p '%s'\" % dbDir )", "after": "os . system ( \"mkdir -p -m 755 '%s'\" % dbDir )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"mkdir -p '%s'\\\"\", 3, 19, 3, 34], \"\\\"mkdir -p -m 755 '%s'\\\"\"]]"}
{"project": "albums", "commit_sha": "33e5278372ed8d76ec649e672cc21d9e3e1b3c94", "parent_sha": "b34ed8123cbbfacf63997476eb73a0f3c6b77240", "file_path": "parse.py", "project_url": "https://github.com/gto76/albums", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -81,7 +81,7 @@ def getCover(albumName, albumData):\n     if imageLink is None:\n         return\n     out = '<a href=\"https://www.youtube.com/results?search_query='\n-    out += albumName.replace('-', '').replace(' ', '+') + 'full+album\"> '\n+    out += albumName.replace('-', '').replace(' ', '+') + '+full+album\"> '\n     out += '<img src=\"' + imageLink\n     out += '\" alt=\"cover\" height=\"306\"/></a>\\n'\n     return out\n", "before": "out += albumName . replace ( '-' , '' ) . replace ( ' ' , '+' ) + 'full+album\"> '", "after": "out += albumName . replace ( '-' , '' ) . replace ( ' ' , '+' ) + '+full+album\"> '", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'full+album\\\"> '\", 3, 59, 3, 74], \"'+full+album\\\"> '\"]]"}
{"project": "django-devserver", "commit_sha": "1259c088b88f4c7a61a293b5182d1c08a8177d51", "parent_sha": "8557abbb90e38ea002be20508dc30b370307eb60", "file_path": "devserver/middleware.py", "project_url": "https://github.com/nealtodd/django-devserver", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -10,7 +10,7 @@ class DevServerMiddleware(object):\n         if settings.MEDIA_URL and request.build_absolute_uri().startswith(request.build_absolute_uri(settings.MEDIA_URL)):\n             return False\n         \n-        if settings.ADMIN_MEDIA_PREFIX and request.path.startswith(settings.ADMIN_MEDIA_PREFIX):\n+        if getattr(settings, 'ADMIN_MEDIA_PREFIX', None) and request.path.startswith(settings.ADMIN_MEDIA_PREFIX):\n             return False\n         \n         if request.path == '/favicon.ico':\n", "before": "if settings . ADMIN_MEDIA_PREFIX and request . path . startswith ( settings . ADMIN_MEDIA_PREFIX ) : return False", "after": "if getattr ( settings , 'ADMIN_MEDIA_PREFIX' , None ) and request . path . startswith ( settings . ADMIN_MEDIA_PREFIX ) : return False", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 96], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"identifier:getattr\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"identifier:settings\", 3, 12, 3, 20], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:'ADMIN_MEDIA_PREFIX'\", \"T\"], 3], [\"Insert\", \"N1\", [\",:,\", \"T\"], 4], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 5], [\"Insert\", \"N1\", [\"):)\", \"T\"], 6], [\"Delete\", [\".:.\", 3, 20, 3, 21]], [\"Delete\", [\"identifier:ADMIN_MEDIA_PREFIX\", 3, 21, 3, 39]], [\"Delete\", [\"attribute\", 3, 12, 3, 39]]]"}
{"project": "blink-qt", "commit_sha": "5c1ff76abe25b8278678e2d1609706e6b125ef66", "parent_sha": "70e2aebf95b14bb763d68af56c101ac45318a4be", "file_path": "blink/mainwindow.py", "project_url": "https://github.com/kogmbh/blink-qt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -141,7 +141,7 @@ class MainWindow(base_class, ui_class):\n \n     def contact_list_selection_changed(self, selected, deselected):\n         selected_items = self.contact_list.selectionModel().selectedIndexes()\n-        self.enable_call_buttons(len(selected_items)==1 and type(self.contact_model.data(selected_items[0])) is Contact)\n+        self.enable_call_buttons(len(selected_items)==1 and isinstance(self.contact_model.data(selected_items[0]), Contact))\n \n     def switch_main_view(self):\n         widget = self.main_view.currentWidget().sibling_panel\n", "before": "self . enable_call_buttons ( len ( selected_items ) == 1 and type ( self . contact_model . data ( selected_items [ 0 ] ) ) is Contact )", "after": "self . enable_call_buttons ( len ( selected_items ) == 1 and isinstance ( self . contact_model . data ( selected_items [ 0 ] ) , Contact ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 34, 3, 120], [\"call\", 3, 61, 3, 109], 2], [\"Update\", [\"identifier:type\", 3, 61, 3, 65], \"isinstance\"], [\"Insert\", [\"argument_list\", 3, 65, 3, 109], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 65, 3, 109], [\"identifier:Contact\", \"T\"], 3], [\"Delete\", [\"is:is\", 3, 110, 3, 112]], [\"Delete\", [\"identifier:Contact\", 3, 113, 3, 120]], [\"Delete\", [\"comparison_operator\", 3, 61, 3, 120]]]"}
{"project": "blink-qt", "commit_sha": "0a7f3ec4b5401f928bc9dd9caaa587dc024c3c60", "parent_sha": "db69878d30622eeab8af5e8dcd31483b279c54fc", "file_path": "blink/history.py", "project_url": "https://github.com/kogmbh/blink-qt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -133,7 +133,7 @@ class HistoryEntry(object):\n         if self.duration:\n             result += ' for '\n             if self.duration.days > 0 or self.duration.seconds > 3600:\n-                result += '%i hours, ' % (self.duration.days*3600*24 + int(self.duration.seconds/3600))\n+                result += '%i hours, ' % (self.duration.days*24 + int(self.duration.seconds/3600))\n             secs = self.duration.seconds % 3600\n             result += '%02i:%02i' % (int(secs/60), secs % 60)\n         if self.reason:\n", "before": "result += '%i hours, ' % ( self . duration . days * 3600 * 24 + int ( self . duration . seconds / 3600 ) )", "after": "result += '%i hours, ' % ( self . duration . days * 24 + int ( self . duration . seconds / 3600 ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"augmented_assignment\", 3, 17, 3, 104], [\"binary_operator\", 3, 43, 3, 103], 2], [\"Move\", [\"binary_operator\", 3, 43, 3, 103], [\"string:'%i hours, '\", 3, 27, 3, 39], 0], [\"Move\", [\"binary_operator\", 3, 43, 3, 103], [\"%:%\", 3, 40, 3, 41], 1], [\"Move\", [\"binary_operator\", 3, 43, 3, 103], [\"parenthesized_expression\", 3, 42, 3, 104], 2], [\"Move\", [\"parenthesized_expression\", 3, 42, 3, 104], [\"binary_operator\", 3, 43, 3, 69], 1], [\"Move\", [\"binary_operator\", 3, 43, 3, 69], [\"+:+\", 3, 70, 3, 71], 1], [\"Move\", [\"binary_operator\", 3, 43, 3, 69], [\"call\", 3, 72, 3, 103], 2], [\"Update\", [\"integer:3600\", 3, 62, 3, 66], \"24\"], [\"Delete\", [\"*:*\", 3, 66, 3, 67]], [\"Delete\", [\"integer:24\", 3, 67, 3, 69]], [\"Delete\", [\"binary_operator\", 3, 27, 3, 104]]]"}
{"project": "acme-tiny", "commit_sha": "be9c9002f7d24a5366005b3adebf7e6aeb964e6a", "parent_sha": "6492f8ed81c33a358122d93eb8efcfc455e641be", "file_path": "acme_tiny.py", "project_url": "https://github.com/nuxi/acme-tiny", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -112,7 +112,7 @@ def get_crt(account_key, csr, skip_check=False, log=LOGGER, CA=DEFAULT_CA):\n         token = re.sub(r\"[^A-Za-z0-9_\\-]\", \"_\", challenge['token'])\n         keyauthorization = \"{0}.{1}\".format(token, thumbprint)\n         record = _b64(hashlib.sha256(keyauthorization).digest())\n-        log.info('_acme-challenege.%s. 300 IN TXT %s' % (domain, record))\n+        log.info('_acme-challenge.%s. 300 IN TXT %s' % (domain, record))\n         pending[domain] = (challenge, token, keyauthorization, record)\n \n     log.info('Press enter to continue after updating DNS server')\n", "before": "log . info ( '_acme-challenege.%s. 300 IN TXT %s' % ( domain , record ) )", "after": "log . info ( '_acme-challenge.%s. 300 IN TXT %s' % ( domain , record ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'_acme-challenege.%s. 300 IN TXT %s'\", 3, 18, 3, 54], \"'_acme-challenge.%s. 300 IN TXT %s'\"]]"}
{"project": "PyMonopoly", "commit_sha": "4936d1c05b4c459514f2281f8a03514e02572cd9", "parent_sha": "1043e5512d0eafc5fe85cdecb85bc2a3a5b2b8a7", "file_path": "LIB/modules/GameObjects.py", "project_url": "https://github.com/Kycko/PyMonopoly", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -172,7 +172,7 @@ class FieldCell():\n             if self.owner:\n                 if self.buildings > -1:\n                     temp = self.rent_costs[self.buildings]\n-                    if monopolied_cell and self.group in range(9):\n+                    if monopolied_cell and not self.buildings and self.group in range(9):\n                         temp = temp * 2\n                 elif self.number in range(11, 20) + range(31, 40):\n                     if self.group in (3, 4, 7, 8):\n", "before": "if monopolied_cell and self . group in range ( 9 ) : temp = temp * 2", "after": "if monopolied_cell and not self . buildings and self . group in range ( 9 ) : temp = temp * 2", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 24, 3, 66], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N0\", [\"boolean_operator\", \"N1\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"and:and\", \"T\"], 1], [\"Move\", \"N1\", [\"comparison_operator\", 3, 44, 3, 66], 2], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:buildings\", \"T\"], 2]]"}
{"project": "PyMonopoly", "commit_sha": "2f59214de60f0ac19b7b02781f2000c45947a2b5", "parent_sha": "5476d7c8212b3b697f78b0dcbf11043259e9ec86", "file_path": "LIB/modules/MenuItems.py", "project_url": "https://github.com/Kycko/PyMonopoly", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -200,7 +200,7 @@ class Tooltip():\n                 for i in range(count):\n                     color = self.choose_color(i+1, cell_state)\n                     self.text.blit(font.render((Globals.TEMP_VARS['rentlabels'][i+start_string]), True, color), (0, 45+i*15))\n-                    if cell_state == 1 and i == 0 and Globals.main_scr.objects['gamefield'].groups_monopolies[CELL.group]:\n+                    if cell_state == 1 and i == 0 and Globals.main_scr.objects['gamefield'].groups_monopolies[CELL.group] not in (None, 'railroad'):\n                         string = '(x2) ' + str(2 * CELL.rent_costs[i])\n                     else:\n                         string = str(CELL.rent_costs[i])\n", "before": "if cell_state == 1 and i == 0 and Globals . main_scr . objects [ 'gamefield' ] . groups_monopolies [ CELL . group ] : string = '(x2) ' + str ( 2 * CELL . rent_costs [ i ] ) else : string = str ( CELL . rent_costs [ i ] )", "after": "if cell_state == 1 and i == 0 and Globals . main_scr . objects [ 'gamefield' ] . groups_monopolies [ CELL . group ] not in ( None , 'railroad' ) : string = '(x2) ' + str ( 2 * CELL . rent_costs [ i ] ) else : string = str ( CELL . rent_costs [ i ] )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 24, 3, 122], [\"comparison_operator\", \"N0\"], 2], [\"Move\", \"N0\", [\"subscript\", 3, 55, 3, 122], 0], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 1], [\"Insert\", \"N0\", [\"in:in\", \"T\"], 2], [\"Insert\", \"N0\", [\"tuple\", \"N1\"], 3], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:'railroad'\", \"T\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4]]"}
{"project": "qal", "commit_sha": "1ab60b23d206bbf3c5410873e0db7d83c06fbe35", "parent_sha": "fe0df73fd08ba9cb8fb42d2fe89ae2288cb8e604", "file_path": "qal/dal/dal.py", "project_url": "https://github.com/OptimalBPM/qal", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -135,7 +135,7 @@ class DatabaseAbstractionLayer(object):\n                                                      _pip_package=\"pyodbc\",\n                                                      _apt_package=\"None\",\n                                                      _win_package=None,\n-                                                     _import_comment=\"2014-04-16: \" +\n+                                                     _import_comment=\"Linux 2014-04-16: \" +\n                                                                      \"No apt package (python3-pyodbc)\"+\n                                                                      \" available at this time.\"))\n             import platform\n", "before": "_import_comment = \"2014-04-16: \" + \"No apt package (python3-pyodbc)\" + \" available at this time.\" ) ) import platform", "after": "_import_comment = \"Linux 2014-04-16: \" + \"No apt package (python3-pyodbc)\" + \" available at this time.\" ) ) import platform", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"2014-04-16: \\\"\", 3, 70, 3, 84], \"\\\"Linux 2014-04-16: \\\"\"]]"}
{"project": "qal", "commit_sha": "799148676934bf94aa6c8e7bcf034608f24bc432", "parent_sha": "066116a9527efc4dd8bbffa1780eb45c2f71a407", "file_path": "qal/dal/dal.py", "project_url": "https://github.com/OptimalBPM/qal", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ class Database_Abstraction_Layer(object):\n             \n     def read_resource_settings(self, _resource):\n         if _resource.type.upper() != 'RDBMS':\n-            raise Exception(\"read_resource_settings error: Wrong resource type - \" + _resource.type)\n+            raise Exception(\"DAL.read_resource_settings error: Wrong resource type - \" + _resource.type)\n         self.db_type =         string_to_db_type(_resource.data.get(\"db_type\"))\n         self.db_server =       _resource.data.get(\"server\")\n         self.db_databasename = _resource.data.get(\"database\")\n", "before": "raise Exception ( \"read_resource_settings error: Wrong resource type - \" + _resource . type )", "after": "raise Exception ( \"DAL.read_resource_settings error: Wrong resource type - \" + _resource . type )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"read_resource_settings error: Wrong resource type - \\\"\", 3, 29, 3, 83], \"\\\"DAL.read_resource_settings error: Wrong resource type - \\\"\"]]"}
{"project": "reportlab", "commit_sha": "dfb9e1eefa864ca6658488482be3868b75234b76", "parent_sha": "54cc6ce94e63f8f02ee61de3ee31e96e19ce86cf", "file_path": "reportlab/graphics/charts/axes0.py", "project_url": "https://github.com/eduardocereto/reportlab", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -325,7 +325,7 @@ class YCategoryAxis(Widget):\n \n     def configure(self, multiSeries):\n         self._catCount = len(multiSeries[0])\n-        self._barWidth = self._length / self._catCount\n+        self._barWidth = self._length / (self._catCount or 1)\n \n         \n     def scale(self, idx):\n", "before": "self . _barWidth = self . _length / self . _catCount", "after": "self . _barWidth = self . _length / ( self . _catCount or 1 )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 26, 3, 55], [\"parenthesized_expression\", \"N0\"], 2], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N0\", [\"boolean_operator\", \"N1\"], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2], [\"Move\", \"N1\", [\"attribute\", 3, 41, 3, 55], 0], [\"Insert\", \"N1\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:1\", \"T\"], 2]]"}
{"project": "MultiQC", "commit_sha": "5b5a7de40f9e1bc81c0c08b11e26b3fce4f848a9", "parent_sha": "b5c4142e7d46da1c8f206482e06eb30ea4eb8d21", "file_path": "multiqc/modules/base_module.py", "project_url": "https://github.com/JAX-GM/MultiQC", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -322,7 +322,7 @@ class BaseMultiqcModule(object):\n             data = [data]\n         \n         # Check we have a list of cats\n-        if type(cats) is not list or type(cats[0]) is not list:\n+        if type(cats) is not list or isinstance(cats[0], basestring): # not just type()==str as can be unicode\n             cats = [cats]\n         \n         # Check that we have cats at all - find them from the data\n", "before": "if type ( cats ) is not list or type ( cats [ 0 ] ) is not list : cats = [ cats ]", "after": "if type ( cats ) is not list or isinstance ( cats [ 0 ] , basestring ) : cats = [ cats ]", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 12, 3, 63], [\"call\", 3, 38, 3, 51], 2], [\"Update\", [\"identifier:type\", 3, 38, 3, 42], \"isinstance\"], [\"Insert\", [\"argument_list\", 3, 42, 3, 51], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 42, 3, 51], [\"identifier:basestring\", \"T\"], 3], [\"Delete\", [\"is:is\", 3, 52, 3, 54]], [\"Delete\", [\"not:not\", 3, 55, 3, 58]], [\"Delete\", [\"identifier:list\", 3, 59, 3, 63]], [\"Delete\", [\"comparison_operator\", 3, 38, 3, 63]]]"}
{"project": "mdtraj", "commit_sha": "0e3e56a888b2fac9e1265a41a1e2b882b45e2c6c", "parent_sha": "e41a92299990fa6586a8f35739653a1801e33c31", "file_path": "mdtraj/scripts/mdconvert.py", "project_url": "https://github.com/Eigenstate/mdtraj", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -207,7 +207,7 @@ def parse_args():\n                      ext(args.output)))\n \n     if args.atom_indices is not None and not os.path.isfile(args.atom_indices):\n-        parser.error('no such file: %s' % fn)\n+        parser.error('no such file: %s' % args.atom_indices)\n \n     if args.stride <= 0:\n         parser.error('stride must be positive')\n", "before": "parser . error ( 'no such file: %s' % fn )", "after": "parser . error ( 'no such file: %s' % args . atom_indices )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 22, 3, 45], [\"attribute\", \"N0\"], 2], [\"Update\", [\"identifier:fn\", 3, 43, 3, 45], \"args\"], [\"Move\", \"N0\", [\"identifier:fn\", 3, 43, 3, 45], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:atom_indices\", \"T\"], 2]]"}
{"project": "qal", "commit_sha": "c7f79b3a18fadc613340233077aecc4cbf844031", "parent_sha": "d0d9783dc59ec396eab1715d6d615bd0b4f51d89", "file_path": "qal/sql/utils.py", "project_url": "https://github.com/OptimalBPM/qal", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -154,7 +154,7 @@ def db_specific_datatype_parse_length(_value):\n     if (_value.find('(') > -1):\n         _strlength = _value.split('(', 1)[1].rsplit(')', 1)[0]\n         if ((_strlength.lower() != '') and (_strlength.isdigit() == False)):\n-            raise Exception(\"db_specific_datatype: Invalid syntax for datatype length:\" + value)\n+            raise Exception(\"db_specific_datatype: Invalid syntax for datatype length:\" + _value)\n     else:\n         _strlength = ''\n             \n", "before": "raise Exception ( \"db_specific_datatype: Invalid syntax for datatype length:\" + value )", "after": "raise Exception ( \"db_specific_datatype: Invalid syntax for datatype length:\" + _value )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"identifier:value\", 3, 91, 3, 96], \"_value\"]]"}
{"project": "qal", "commit_sha": "ee2a09f1bc31a44f2f47f580700e7ce41ed11b73", "parent_sha": "383eb33bd1ea61859a43b6826dea68cdea5e6931", "file_path": "qal/sql/utils.py", "project_url": "https://github.com/OptimalBPM/qal", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -232,7 +232,7 @@ def datatype_to_parameter(_db_type, _datatype):\n     \"\"\"Converts a python data type to the database-driver appropriate parameter substitution string\"\"\"\n     if _db_type == DB_MYSQL:\n         return \"%s\"\n-    elif (_datatype[:6].lower() == \"string\" or _datatype[:7].lower() == \"varchar\" or _datatype == \"timestamp\"):\n+    elif (_datatype[:6].lower() == \"string\" or _datatype[:7].lower() == \"varchar\" or _datatype in [\"timestamp\", \"datetime\"]):\n         return \"%s\"\n     elif (_datatype in [\"float\", \"integer\"]):\n         return \"%d\"\n", "before": "if _db_type == DB_MYSQL : return \"%s\" elif ( _datatype [ : 6 ] . lower ( ) == \"string\" or _datatype [ : 7 ] . lower ( ) == \"varchar\" or _datatype == \"timestamp\" ) : return \"%s\" elif ( _datatype in [ \"float\" , \"integer\" ] ) : return \"%d\"", "after": "if _db_type == DB_MYSQL : return \"%s\" elif ( _datatype [ : 6 ] . lower ( ) == \"string\" or _datatype [ : 7 ] . lower ( ) == \"varchar\" or _datatype in [ \"timestamp\" , \"datetime\" ] ) : return \"%s\" elif ( _datatype in [ \"float\" , \"integer\" ] ) : return \"%d\"", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 86, 3, 110], [\"in:in\", \"T\"], 1], [\"Insert\", [\"comparison_operator\", 3, 86, 3, 110], [\"list\", \"N0\"], 2], [\"Insert\", \"N0\", [\"[:[\", \"T\"], 0], [\"Move\", \"N0\", [\"string:\\\"timestamp\\\"\", 3, 99, 3, 110], 1], [\"Insert\", \"N0\", [\",:,\", \"T\"], 2], [\"Insert\", \"N0\", [\"string:\\\"datetime\\\"\", \"T\"], 3], [\"Insert\", \"N0\", [\"]:]\", \"T\"], 4], [\"Delete\", [\"==:==\", 3, 96, 3, 98]]]"}
{"project": "pylinac", "commit_sha": "9f6134c425701fcbb932616213f65f787f316235", "parent_sha": "13d9db74f94d367efd5d34e2164c4cd83ce3d5c4", "file_path": "pylinac/core/image.py", "project_url": "https://github.com/midamo/pylinac", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -289,7 +289,7 @@ class BaseImage:\n     def date_created(self, format=\"%A, %B %d, %Y\"):\n         date = None\n         try:\n-            date = datetime.strptime(self.metadata.InstanceCreationDate+self.metadata.InstanceCreationTime, \"%Y%m%d%H%M%S\")\n+            date = datetime.strptime(self.metadata.InstanceCreationDate+str(round(float(self.metadata.InstanceCreationTime))), \"%Y%m%d%H%M%S\")\n             date = date.strftime(format)\n         except AttributeError:\n             try:\n", "before": "date = datetime . strptime ( self . metadata . InstanceCreationDate + self . metadata . InstanceCreationTime , \"%Y%m%d%H%M%S\" )", "after": "date = datetime . strptime ( self . metadata . InstanceCreationDate + str ( round ( float ( self . metadata . InstanceCreationTime ) ) ) , \"%Y%m%d%H%M%S\" )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 38, 3, 107], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"call\", \"N2\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:round\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"call\", \"N4\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:float\", \"T\"], 0], [\"Insert\", \"N4\", [\"argument_list\", \"N5\"], 1], [\"Insert\", \"N5\", [\"(:(\", \"T\"], 0], [\"Move\", \"N5\", [\"attribute\", 3, 73, 3, 107], 1], [\"Insert\", \"N5\", [\"):)\", \"T\"], 2]]"}
{"project": "mdtraj", "commit_sha": "699712dff85f754ded9ebb8e9d6b9b79f87720de", "parent_sha": "ee2d61cd65d54739e78f4de134551b8809e3642d", "file_path": "mdtraj/formats/gro.py", "project_url": "https://github.com/Eigenstate/mdtraj", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -352,7 +352,7 @@ class GroTrajectoryFile(object):\n             comment += ', t= %s' % time\n \n         assert topology.n_atoms == coordinates.shape[0]\n-        lines = [comment, '  %d' % topology.n_atoms]\n+        lines = [comment, ' %d' % topology.n_atoms]\n         if box is None:\n             box = np.zeros((3,3))\n \n", "before": "lines = [ comment , '  %d' % topology . n_atoms ]", "after": "lines = [ comment , ' %d' % topology . n_atoms ]", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'  %d'\", 3, 27, 3, 33], \"' %d'\"]]"}
{"project": "tribler", "commit_sha": "7cbafee573f27ead2ae67279b215c12c38dcce36", "parent_sha": "6ab457b933148064a50e0e4583accc15547ce37e", "file_path": "Tribler/community/walktest/community.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -124,7 +124,7 @@ class WalktestCommunity(Community):\n         # wait for introduction-response\n         meta_response = self._meta_messages[u\"introduction-response\"]\n         footprint = meta_response.generate_footprint(payload=(identifier,))\n-        timeout = meta_response.delay + 5.0 # TODO why 5.0 margin\n+        timeout = meta_request.delay + meta_response.delay + 5.0 # TODO why 5.0 margin\n         self._dispersy.await_message(footprint, self.introduction_response_or_timeout, response_args=(destination, advice), timeout=timeout)\n \n         # release walk identifier some seconds after timeout expires\n", "before": "timeout = meta_response . delay + 5.0", "after": "timeout = meta_request . delay + meta_response . delay + 5.0", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 19, 3, 44], [\"binary_operator\", \"N0\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"+:+\", \"T\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 19, 3, 38], 2], [\"Insert\", \"N1\", [\"identifier:meta_request\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:delay\", \"T\"], 2]]"}
{"project": "py-util", "commit_sha": "d9df529a0cbc7a43ce26a1f78048eca889d84616", "parent_sha": "c45feb61f12678df34cdae0594ab14a7c97935de", "file_path": "s/exceptions.py", "project_url": "https://github.com/nathants/py-util", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -19,7 +19,7 @@ def update(fn_or_str, *exceptions, **kw):\n     try:\n         yield\n     except Exception as e:\n-        if type(e) in exceptions or not exceptions:\n+        if isinstance(e, exceptions) or not exceptions:\n             try:\n                 msg = e.args[0]\n             except:\n", "before": "if type ( e ) in exceptions or not exceptions : try : msg = e . args [ 0 ] except : ", "after": "if isinstance ( e , exceptions ) or not exceptions : try : msg = e . args [ 0 ] except : ", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 12, 3, 51], [\"call\", 3, 12, 3, 19], 0], [\"Update\", [\"identifier:type\", 3, 12, 3, 16], \"isinstance\"], [\"Insert\", [\"argument_list\", 3, 16, 3, 19], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 16, 3, 19], [\"identifier:exceptions\", \"T\"], 3], [\"Delete\", [\"in:in\", 3, 20, 3, 22]], [\"Delete\", [\"identifier:exceptions\", 3, 23, 3, 33]], [\"Delete\", [\"comparison_operator\", 3, 12, 3, 33]]]"}
{"project": "fabdeploy", "commit_sha": "d1af25a2738118ba888e0ad8cc58ea2c901bcdc5", "parent_sha": "b09c45d30b631399b6a016bf3043191d11a31ce9", "file_path": "webapp.py", "project_url": "https://github.com/oyanezm/fabdeploy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,5 +65,5 @@ class _WebApp(object):\n         \"\"\"\n         calls collect static files\n         \"\"\"\n-        config_path = (\"%(path)s/%(project_name)s/config/%(step)/\" % env)\n+        config_path = (\"%(path)s%(project_name)s/config/%(step)s/\" % env)\n         result = with_virtualenv_remote(\"cd %s;python manage.py collectstatic\" % config_path)\n", "before": "config_path = ( \"%(path)s/%(project_name)s/config/%(step)/\" % env )", "after": "config_path = ( \"%(path)s%(project_name)s/config/%(step)s/\" % env )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"%(path)s/%(project_name)s/config/%(step)/\\\"\", 3, 24, 3, 67], \"\\\"%(path)s%(project_name)s/config/%(step)s/\\\"\"]]"}
{"project": "CloudBot", "commit_sha": "f9ddfaaad5435f1c1d24aa112393448920b03856", "parent_sha": "378b5442189719d94845f01c92e95e7595880c93", "file_path": "plugins/feelings.py", "project_url": "https://github.com/MrW24/CloudBot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,5 +52,5 @@ def flirt(inp, nick=None, me=None, conn=None):\n     else:\n         target = inp\n \n-    out = 'insults %s... \"%s\"' % (target, random.choice(flirts))\n+    out = 'flirts with %s... \"%s\"' % (target, random.choice(flirts))\n     me(out)\n", "before": "out = 'insults %s... \"%s\"' % ( target , random . choice ( flirts ) )", "after": "out = 'flirts with %s... \"%s\"' % ( target , random . choice ( flirts ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'insults %s... \\\"%s\\\"'\", 3, 11, 3, 31], \"'flirts with %s... \\\"%s\\\"'\"]]"}
{"project": "scripts", "commit_sha": "eaa1003bb7aed7a4dd781d4d74d55503128a35dc", "parent_sha": "a56fd207b5bb9c9a1c2c3648cc5e81e6dd7978ed", "file_path": "search_google.py", "project_url": "https://github.com/intezer/scripts", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -64,7 +64,7 @@ class SearchHandler(idaapi.action_handler_t):\n         idaapi.action_handler_t.__init__(self)\n         \n     def activate(self, ctx):\n-        os.system(\"START http://www.google.com/search?q=\\\"\" + highlight[0] + \"\\\"\")\n+        os.system(\"START https://www.google.com/search?q=\\\"\" + highlight[0] + \"\\\"\")\n         \n         return 1\n         \n", "before": "os . system ( \"START http://www.google.com/search?q=\\\"\" + highlight [ 0 ] + \"\\\"\" )", "after": "os . system ( \"START https://www.google.com/search?q=\\\"\" + highlight [ 0 ] + \"\\\"\" )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"START http://www.google.com/search?q=\\\\\\\"\\\"\", 3, 19, 3, 60], \"\\\"START https://www.google.com/search?q=\\\\\\\"\\\"\"]]"}
{"project": "v2ray.fun", "commit_sha": "69cd7d842efadfef919174e7c0bddd78a1657316", "parent_sha": "110b3b347c1727ba535104c72a3729a44d812f9b", "file_path": "v2ray_util/util_core/utils.py", "project_url": "https://github.com/Jrohy/v2ray.fun", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -150,7 +150,7 @@ def gen_cert(domain):\n     if not os.path.exists(\"/root/.acme.sh/acme.sh\"):\n         os.system(\"curl https://get.acme.sh | sh\")\n \n-    get_ssl_cmd = \"bash /root/.acme.sh/acme.sh  --issue -d \" + domain + \"   --standalone  --keylength ec-256\"\n+    get_ssl_cmd = \"bash /root/.acme.sh/acme.sh  --issue -d \" + domain + \" --debug --standalone  --keylength ec-256\"\n \n     for name in service_name:\n         os.system(stop_cmd.format(name))\n", "before": "get_ssl_cmd = \"bash /root/.acme.sh/acme.sh  --issue -d \" + domain + \"   --standalone  --keylength ec-256\"", "after": "get_ssl_cmd = \"bash /root/.acme.sh/acme.sh  --issue -d \" + domain + \" --debug --standalone  --keylength ec-256\"", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"   --standalone  --keylength ec-256\\\"\", 3, 73, 3, 110], \"\\\" --debug --standalone  --keylength ec-256\\\"\"]]"}
{"project": "byextopopt", "commit_sha": "68ab55667b64755f01136616dfff5f65145b05a0", "parent_sha": "b9780bfc5de691ffefde612e343b930410f4c169", "file_path": "src/appearance.py", "project_url": "https://github.com/shapeforge/byextopopt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -111,7 +111,7 @@ class AppearanceCL(object):\n         source_pixels = self.source_size[0] * self.source_size[1]\n         target_pixels = self.target_size[0] * self.target_size[1]\n         patch_pixels = self.patch_size[0] * self.patch_size[1]\n-        self.const_occ = source_pixels / float(target_pixels * (patch_pixels ** 2))\n+        self.const_occ = source_pixels / float(target_pixels * (patch_pixels ** 2) * (patch_pixels ** 2))\n         # neighborhood matching (patchmatch)\n         self.nff_buf = cl.Buffer(self.cl_context, cl.mem_flags.READ_WRITE |\n                                  cl.mem_flags.COPY_HOST_PTR, hostbuf=self.nff)\n", "before": "self . const_occ = source_pixels / float ( target_pixels * ( patch_pixels ** 2 ) )", "after": "self . const_occ = source_pixels / float ( target_pixels * ( patch_pixels ** 2 ) * ( patch_pixels ** 2 ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"binary_operator\", 3, 48, 3, 83], [\"binary_operator\", 3, 48, 3, 83], 0], [\"Insert\", [\"binary_operator\", 3, 48, 3, 83], [\"*:*\", \"T\"], 1], [\"Insert\", [\"binary_operator\", 3, 48, 3, 83], [\"parenthesized_expression\", \"N0\"], 2], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N0\", [\"binary_operator\", \"N1\"], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:patch_pixels\", \"T\"], 0], [\"Insert\", \"N1\", [\"**:**\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:2\", \"T\"], 2]]"}
{"project": "pdkit", "commit_sha": "408bb7eafab9451837a8d5e5cdb7dd0e9be3a873", "parent_sha": "94df35aab094de2c2d438c71e14c3d6f22c588e6", "file_path": "pdkit/voice_processor.py", "project_url": "https://github.com/pdkit/pdkit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -61,7 +61,7 @@ class VoiceProcessor:\n         try:\n \n             # urllib.request.urlretrieve(\"https://raw.githubusercontent.com/Shahabks/myprosody/master/myprosody/dataset/essen/myspsolution.praat\", \"myspsolution.praat\")\n-            objects=run_file(os.getcwd() + \"/myspsolution.praat\", -20, 2, 0.3, \"yes\", self.file_name, './', 80, 400, 0.01, capture_output=True)\n+            objects=run_file(os.getcwd() + \"/pdkit/myspsolution.praat\", -20, 2, 0.3, \"yes\", self.file_name, './', 80, 400, 0.01, capture_output=True)\n             z1=str( objects[1])\n             z2=z1.strip().split()\n \n", "before": "objects = run_file ( os . getcwd ( ) + \"/myspsolution.praat\" , - 20 , 2 , 0.3 , \"yes\" , self . file_name , './' , 80 , 400 , 0.01 , capture_output = True )", "after": "objects = run_file ( os . getcwd ( ) + \"/pdkit/myspsolution.praat\" , - 20 , 2 , 0.3 , \"yes\" , self . file_name , './' , 80 , 400 , 0.01 , capture_output = True )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"/myspsolution.praat\\\"\", 3, 44, 3, 65], \"\\\"/pdkit/myspsolution.praat\\\"\"]]"}
{"project": "deepmesh", "commit_sha": "d8f38abbf46a8e949d9272b286f24844e59417fa", "parent_sha": "6922004f98831f05030e993a2a3559b50fc99337", "file_path": "utils/mesh_code.py", "project_url": "https://github.com/swing-research/deepmesh", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -180,7 +180,7 @@ def main_producer(i, Npoints, img_size, dirgroup_prefix):\n     Ntriang = len(tri.simplices)\n \n     # dirname = dirgroup_prefix + '_%dtri_%d' % (Ntriang, i)\n-    dirname = dirgroup_prefix + '_%d'%(Ntriang)\n+    dirname = '../'+dirgroup_prefix + '_%d'%(Ntriang)\n     if not os.path.exists(dirname):\n         try:\n             os.makedirs(dirname)\n", "before": "dirname = dirgroup_prefix + '_%d' % ( Ntriang )", "after": "dirname = '../' + dirgroup_prefix + '_%d' % ( Ntriang )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 15, 3, 48], [\"binary_operator\", \"N0\"], 0], [\"Insert\", \"N0\", [\"string:'../'\", \"T\"], 0], [\"Insert\", \"N0\", [\"+:+\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:dirgroup_prefix\", 3, 15, 3, 30], 2]]"}
{"project": "lorentz-embeddings", "commit_sha": "0b2a89d488b31f8533130bc97f09246b8f37334b", "parent_sha": "8f61950be8381f688ef86655e1c2390c1d5b9340", "file_path": "lorentz.py", "project_url": "https://github.com/theSage21/lorentz-embeddings", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ def exp_map(x, v):\n \n \n def set_dim0(x):\n-    dim0 = torch.sqrt(1 + torch.norm(x[:, 1:], dim=1))\n+    dim0 = torch.sqrt(1 + torch.norm(x[:, 1:], dim=1) ** 2)\n     x[:, 0] = dim0\n     return x\n \n", "before": "dim0 = torch . sqrt ( 1 + torch . norm ( x [ : , 1 : ] , dim = 1 ) )", "after": "dim0 = torch . sqrt ( 1 + torch . norm ( x [ : , 1 : ] , dim = 1 ) ** 2 )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 23, 3, 54], [\"binary_operator\", \"N0\"], 2], [\"Move\", \"N0\", [\"call\", 3, 27, 3, 54], 0], [\"Insert\", \"N0\", [\"**:**\", \"T\"], 1], [\"Insert\", \"N0\", [\"integer:2\", \"T\"], 2]]"}
{"project": "WMAS", "commit_sha": "71928c4691d89254260974e40bbdb55f6a6225ab", "parent_sha": "6ab48c2cc33256ca47fa3f52bfb37023a8cd426d", "file_path": "XMLHttpRequest/resources/chunked.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -10,7 +10,7 @@ def main(request, response):\n     response.write_status_headers()\n \n     for value in chunks:\n-        response.writer.write(\"%d\\r\\n\" % len(value))\n+        response.writer.write(\"%x\\r\\n\" % len(value))\n         response.writer.write(value)\n         response.writer.write(\"\\r\\n\")\n     response.writer.write(\"0\\r\\n\")\n", "before": "response . writer . write ( \"%d\\r\\n\" % len ( value ) )", "after": "response . writer . write ( \"%x\\r\\n\" % len ( value ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"%d\\\\r\\\\n\\\"\", 3, 31, 3, 39], \"\\\"%x\\\\r\\\\n\\\"\"]]"}
{"project": "WMAS", "commit_sha": "b651151c05fb95e24f13b17864624676cfbccbac", "parent_sha": "69ab442726d0f4e435aaddeb8e6fd5b5c5d4f983", "file_path": "tools/ci/tag_master.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -18,7 +18,7 @@ logger = logging.getLogger(__name__)\n \n \n def get_pr(repo, owner, sha):\n-    url = (\"https://api.github.com/search/issues?q=type:pr+is:merged+repo:%s/%s+%s\" %\n+    url = (\"https://api.github.com/search/issues?q=type:pr+is:merged+repo:%s/%s+sha:%s\" %\n            (repo, owner, sha))\n     try:\n         resp = urllib2.urlopen(url)\n", "before": "url = ( \"https://api.github.com/search/issues?q=type:pr+is:merged+repo:%s/%s+%s\" % ( repo , owner , sha ) )", "after": "url = ( \"https://api.github.com/search/issues?q=type:pr+is:merged+repo:%s/%s+sha:%s\" % ( repo , owner , sha ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"https://api.github.com/search/issues?q=type:pr+is:merged+repo:%s/%s+%s\\\"\", 3, 12, 3, 84], \"\\\"https://api.github.com/search/issues?q=type:pr+is:merged+repo:%s/%s+sha:%s\\\"\"]]"}
{"project": "WMAS", "commit_sha": "f37a6d8489f1726bca0dfb95cbf34ec27ee710fa", "parent_sha": "3d8d0ac4bc05cee28780e9e2516b77d9a7b5dc97", "file_path": "tools/manifest/sourcefile.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -227,7 +227,7 @@ class SourceFile(object):\n         rel_dir_tree = self.rel_path.split(os.path.sep)\n         return (rel_dir_tree[0] == \"webdriver\" and\n                 len(rel_dir_tree) > 1 and\n-                self.filename != \"__init__.py\" and\n+                self.filename not in (\"__init__.py\", \"conftest.py\") and\n                 fnmatch(self.filename, wd_pattern))\n \n     @property\n", "before": "return ( rel_dir_tree [ 0 ] == \"webdriver\" and len ( rel_dir_tree ) > 1 and self . filename != \"__init__.py\" and fnmatch ( self . filename , wd_pattern ) )", "after": "return ( rel_dir_tree [ 0 ] == \"webdriver\" and len ( rel_dir_tree ) > 1 and self . filename not in ( \"__init__.py\" , \"conftest.py\" ) and fnmatch ( self . filename , wd_pattern ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 17, 3, 47], [\"not:not\", \"T\"], 1], [\"Insert\", [\"comparison_operator\", 3, 17, 3, 47], [\"in:in\", \"T\"], 2], [\"Insert\", [\"comparison_operator\", 3, 17, 3, 47], [\"tuple\", \"N0\"], 3], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"string:\\\"__init__.py\\\"\", 3, 34, 3, 47], 1], [\"Insert\", \"N0\", [\",:,\", \"T\"], 2], [\"Insert\", \"N0\", [\"string:\\\"conftest.py\\\"\", \"T\"], 3], [\"Insert\", \"N0\", [\"):)\", \"T\"], 4], [\"Delete\", [\"!=:!=\", 3, 31, 3, 33]]]"}
{"project": "traffic-sign-detection-homework", "commit_sha": "fe1c03e8174596ec78b2ab9acb4e13ebfe3b6f8a", "parent_sha": "60c07148acc46621699cfb24638bb90a96be0cbb", "file_path": "data.py", "project_url": "https://github.com/soumith/traffic-sign-detection-homework", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -20,7 +20,7 @@ def initialize_data(folder):\n     test_zip = folder + '/test_images.zip'\n     if not os.path.exists(train_zip) or not os.path.exists(test_zip):\n         raise(RuntimeError(\"Could not find \" + train_zip + \" and \" + test_zip\n-              + ', please download them from https://www.kaggle.com/c/nyu-cv-fall-2017/data'))\n+              + ', please download them from https://www.kaggle.com/c/nyu-cv-fall-2017/data '))\n     # extract train_data.zip to train_data\n     train_folder = folder + '/train_images'\n     if not os.path.isdir(train_folder):\n", "before": "raise ( RuntimeError ( \"Could not find \" + train_zip + \" and \" + test_zip + ', please download them from https://www.kaggle.com/c/nyu-cv-fall-2017/data' ) )", "after": "raise ( RuntimeError ( \"Could not find \" + train_zip + \" and \" + test_zip + ', please download them from https://www.kaggle.com/c/nyu-cv-fall-2017/data ' ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:', please download them from https://www.kaggle.com/c/nyu-cv-fall-2017/data'\", 3, 17, 3, 93], \"', please download them from https://www.kaggle.com/c/nyu-cv-fall-2017/data '\"]]"}
{"project": "calefaction", "commit_sha": "a520f89074523e99c271af1932b99b0b201b6851", "parent_sha": "12c0ebe774054208f3610153214fca194f8dc68e", "file_path": "calefaction/eve/esi.py", "project_url": "https://github.com/earwig/calefaction", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -197,7 +197,7 @@ class EVESwaggerInterface:\n             result = resp.json() if resp.content else None\n         except (requests.RequestException, ValueError) as exc:\n             self._logger.exception(\"ESI request failed\")\n-            if hasattr(exc, \"response\") and (exc.response and\n+            if hasattr(exc, \"response\") and (exc.response is not None and\n                                              exc.response.status_code == 403):\n                 raise EVEAPIForbiddenError()\n             raise EVEAPIError()\n", "before": "if hasattr ( exc , \"response\" ) and ( exc . response and exc . response . status_code == 403 ) : raise EVEAPIForbiddenError ( )", "after": "if hasattr ( exc , \"response\" ) and ( exc . response is not None and exc . response . status_code == 403 ) : raise EVEAPIForbiddenError ( )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 46, 4, 77], [\"comparison_operator\", \"N0\"], 0], [\"Move\", \"N0\", [\"attribute\", 3, 46, 3, 58], 0], [\"Insert\", \"N0\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 2], [\"Insert\", \"N0\", [\"none:None\", \"T\"], 3]]"}
{"project": "CU-CS5525-PythonCompiler", "commit_sha": "c7f730c3daa7d9f80e56d9f3f307499a569b24af", "parent_sha": "76f43463101d218f107e9171476aed2111162e22", "file_path": "compile.py", "project_url": "https://github.com/asayler/CU-CS5525-PythonCompiler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -289,7 +289,7 @@ def compile_stmt(ast, value_mode='movl'):\n     elif isinstance(ast, CallFunc):\n         return ['call input']\n     elif isinstance(ast, Const):\n-        return [('%s %d, %%eax' % (value_mode, ast.value))]\n+        return [('%s $%d, %%eax' % (value_mode, ast.value))]\n     elif isinstance(ast, Name):\n         return [('%s -%d(%%ebp), %%eax' % (value_mode, stack_map[ast.name]))]\n     else:\n", "before": "return [ ( '%s %d, %%eax' % ( value_mode , ast . value ) ) ]", "after": "return [ ( '%s $%d, %%eax' % ( value_mode , ast . value ) ) ]", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'%s %d, %%eax'\", 3, 18, 3, 32], \"'%s $%d, %%eax'\"]]"}
{"project": "izpack-utils", "commit_sha": "4d464ab229509930b43380e36755afb2933eee24", "parent_sha": "5b7ccf4cd207e31974d57e92fc3a1507a2190b6a", "file_path": "izpack2exe/izpack2exe.py", "project_url": "https://github.com/jponge/izpack-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,7 +52,7 @@ def create_exe(settings):\n     config.write(';!@Install@!UTF-8!\\r\\n')\r\n     config.write('Title=\"IzPack\"\\r\\n')\r\n     config.write('Progress=\"yes\"\\r\\n')\r\n-    config.write('RunProgram=\"java -jar %s\"\\r\\n' % filename)\r\n+    config.write('ExecuteFile=\"%s\"\\r\\n' % filename)\r\n     config.write(';!@InstallEnd@!\\r\\n')\r\n     config.close()\r\n \r\n", "before": "config . write ( 'RunProgram=\"java -jar %s\"\\r\\n' % filename )", "after": "config . write ( 'ExecuteFile=\"%s\"\\r\\n' % filename )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'RunProgram=\\\"java -jar %s\\\"\\\\r\\\\n'\", 3, 18, 3, 49], \"'ExecuteFile=\\\"%s\\\"\\\\r\\\\n'\"]]"}
{"project": "Visual_Script", "commit_sha": "02feeb00d43a2c8f9ddbfaecbf21705a7a074c21", "parent_sha": "04c39ca1851b71de2907f9ea5429cf905473db4e", "file_path": "VisualScript/src/File/FileManager.py", "project_url": "https://github.com/NTUTVisualScript/Visual_Script", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -6,7 +6,7 @@ from VisualScript.src import WORKSPACE\n def new(info):\n     # Decode information\n     path = info['path']\n-    projectPath = path + info['project']\n+    projectPath = path + '/' + info['project']\n     if os.path.isdir(projectPath):\n         raise Exception('The directory is exist!')\n     suitePath = projectPath + '/' + info['suite']\n", "before": "projectPath = path + info [ 'project' ]", "after": "projectPath = path + '/' + info [ 'project' ]", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 19, 3, 41], [\"binary_operator\", \"N0\"], 0], [\"Insert\", [\"binary_operator\", 3, 19, 3, 41], [\"+:+\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:path\", 3, 19, 3, 23], 0], [\"Move\", \"N0\", [\"+:+\", 3, 24, 3, 25], 1], [\"Insert\", \"N0\", [\"string:'/'\", \"T\"], 2]]"}
{"project": "betaisbetterthanalpha", "commit_sha": "e73a1dcb3184e2ab52914d704566aa058c2e6fb0", "parent_sha": "08c1735684416859c80baff8fd4697816a8bb106", "file_path": "front/msg/op.py", "project_url": "https://github.com/bcho/betaisbetterthanalpha", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -4,4 +4,4 @@ __all__ = ['op']\n \n \n def op(operation, obj):\n-    return u'\u5df2\u7ecf\u6210\u529f%s%obj\u4e86' % (operation, obj)\n+    return u'\u5df2\u7ecf\u6210\u529f%s%s\u4e86' % (operation, obj)\n", "before": "return u'\u5df2\u7ecf\u6210\u529f%s%obj\u4e86' % (operat o ,  obj)   ", "after": "return u'\u5df2\u7ecf\u6210\u529f%s%s\u4e86' % (operat o ,  obj)   ", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:u'\\u5df2\\u7ecf\\u6210\\u529f%s%obj\\u4e86' % (operat\", 3, 12, 3, 36], \"u'\\u5df2\\u7ecf\\u6210\\u529f%s%s\\u4e86' % (operat\"]]"}
{"project": "arfit", "commit_sha": "e6cef115107e6da8642b1d6095479e89c9d616a5", "parent_sha": "f93fbf479e373a55eff4772f143d6b98c51cbd96", "file_path": "arfit/ar1_posterior.py", "project_url": "https://github.com/farr/arfit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -106,7 +106,7 @@ class AR1Posterior(object):\n         sigma = np.exp(p['lnsigma'])\n         tau = np.exp(p['lntau'])\n \n-        return 4.0*sigma*sigma*tau/(np.square(2.0*np.pi*tau*fs) + 1)\n+        return 4.0*sigma*sigma*tau*tau/(np.square(2.0*np.pi*tau*fs) + 1)\n \n     def log_prior(self, p):\n", "before": "return 4.0 * sigma * sigma * tau / ( np . square ( 2.0 * np . pi * tau * fs ) + 1 )", "after": "return 4.0 * sigma * sigma * tau * tau / ( np . square ( 2.0 * np . pi * tau * fs ) + 1 )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"binary_operator\", 3, 16, 3, 31], [\"binary_operator\", 3, 16, 3, 31], 0], [\"Insert\", [\"binary_operator\", 3, 16, 3, 31], [\"*:*\", \"T\"], 1], [\"Insert\", [\"binary_operator\", 3, 16, 3, 31], [\"identifier:tau\", \"T\"], 2]]"}
{"project": "CCR_NGS", "commit_sha": "1f08ae6fc883593d2da0d9445b52d89ccfa07393", "parent_sha": "58dc706a0b718f31ee38c69272995ad22c53a4e6", "file_path": "scripts/rnaseq_qc.py", "project_url": "https://github.com/seandavi/CCR_NGS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -229,7 +229,7 @@ def run_collect_rnaseq_metrics(input, output, params=None):\n     picard_params['output'] = output\n     \n     # Set up using the default arguments, specifying the input and output files since they are required!\n-    cmdline = \"--jar=%(jar_file)s --input=%(input)s --output=%(output)s --ref_flat=%(ref_flat)s --ref_file=%(ref_file)s CollectRnaSeqMetrics --minimum_length=%(minimum_length)s --chart_output=%(chart_output)%s --metric_accumulation_level=%(metric_accumulation_level)s --stop_after=%(stop_after)s\" % picard_params\n+    cmdline = \"--jar=%(jar_file)s --input=%(input)s --output=%(output)s --ref_flat=%(ref_flat)s --ref_file=%(ref_file)s CollectRnaSeqMetrics --minimum_length=%(minimum_length)s --chart_output=%(chart_output)s --metric_accumulation_level=%(metric_accumulation_level)s --stop_after=%(stop_after)s\" % picard_params\n \n     # args = parser.parse_args(cmdline.split())\n     \n", "before": "cmdline = \"--jar=%(jar_file)s --input=%(input)s --output=%(output)s --ref_flat=%(ref_flat)s --ref_file=%(ref_file)s CollectRnaSeqMetrics --minimum_length=%(minimum_length)s --chart_output=%(chart_output)%s --metric_accumulation_level=%(metric_accumulation_level)s --stop_after=%(stop_after)s\" % picard_params", "after": "cmdline = \"--jar=%(jar_file)s --input=%(input)s --output=%(output)s --ref_flat=%(ref_flat)s --ref_file=%(ref_file)s CollectRnaSeqMetrics --minimum_length=%(minimum_length)s --chart_output=%(chart_output)s --metric_accumulation_level=%(metric_accumulation_level)s --stop_after=%(stop_after)s\" % picard_params", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"--jar=%(jar_file)s --input=%(input)s --output=%(output)s --ref_flat=%(ref_flat)s --ref_file=%(ref_file)s CollectRnaSeqMetrics --minimum_length=%(minimum_length)s --chart_output=%(chart_output)%s --metric_accumulation_level=%(metric_accumulation_level)s --stop_after=%(stop_after)s\\\"\", 3, 15, 3, 297], \"\\\"--jar=%(jar_file)s --input=%(input)s --output=%(output)s --ref_flat=%(ref_flat)s --ref_file=%(ref_file)s CollectRnaSeqMetrics --minimum_length=%(minimum_length)s --chart_output=%(chart_output)s --metric_accumulation_level=%(metric_accumulation_level)s --stop_after=%(stop_after)s\\\"\"]]"}
{"project": "angr", "commit_sha": "3e6005c5111a7a651bc0a164db4a06d354d4c259", "parent_sha": "291ceda3e187bc890dbd10b5197429d8f118bb12", "file_path": "simuvex/s_ref.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,7 +14,7 @@ class SimRef(object):\n \t\tself.stmt_idx = stmt_idx\n \n \tdef __repr__(self):\n-\t\treturn \"(inst 0x%x, stmt %s)\" % (self.inst_addr, self.stmt_idx)\n+\t\treturn \"(inst 0x%x, stmt %d)\" % (self.inst_addr, self.stmt_idx)\n \n \t@abc.abstractmethod\n \tdef is_symbolic(self):\n", "before": "return \"(inst 0x%x, stmt %s)\" % ( self . inst_addr , self . stmt_idx )", "after": "return \"(inst 0x%x, stmt %d)\" % ( self . inst_addr , self . stmt_idx )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"(inst 0x%x, stmt %s)\\\"\", 3, 10, 3, 32], \"\\\"(inst 0x%x, stmt %d)\\\"\"]]"}
{"project": "angr", "commit_sha": "f133f673692dae89d767cf70360d7737a0d1a3fb", "parent_sha": "ac9db2d8e602ed00c36ae52b8ec5f680c4deee83", "file_path": "simuvex/s_path.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -110,4 +110,4 @@ class SimPath(SimRun):\n \t\treturn o\n \n \tdef __repr__(self):\n-\t\treturn \"<SimPath with %d runs>\" % self.length\n+\t\treturn \"<SimPath with %d runs>\" % (0 if not hasattr(self, 'length') else self.length)\n", "before": "return \"<SimPath with %d runs>\" % self . length", "after": "return \"<SimPath with %d runs>\" % ( 0 if not hasattr ( self , 'length' ) else self . length )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 10, 3, 48], [\"parenthesized_expression\", \"N0\"], 2], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N0\", [\"conditional_expression\", \"N1\"], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 0], [\"Insert\", \"N1\", [\"if:if\", \"T\"], 1], [\"Insert\", \"N1\", [\"not_operator\", \"N2\"], 2], [\"Insert\", \"N1\", [\"else:else\", \"T\"], 3], [\"Move\", \"N1\", [\"attribute\", 3, 37, 3, 48], 4], [\"Insert\", \"N2\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N2\", [\"call\", \"N3\"], 1], [\"Insert\", \"N3\", [\"identifier:hasattr\", \"T\"], 0], [\"Insert\", \"N3\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"identifier:self\", \"T\"], 1], [\"Insert\", \"N4\", [\",:,\", \"T\"], 2], [\"Insert\", \"N4\", [\"string:'length'\", \"T\"], 3], [\"Insert\", \"N4\", [\"):)\", \"T\"], 4]]"}
{"project": "pylint", "commit_sha": "2e57298846aeb72b589329f63af434bf9d74f398", "parent_sha": "5b63e55160977a6c9ddbb79e32feb21197f0a915", "file_path": "checkers/utils.py", "project_url": "https://github.com/wubob/pylint", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ def clobber_in_except(node):\n             if (stmts and\n                 not isinstance(stmts[0].ass_type(),\n                                (astng.Assign, astng.AugAssign, astng.ExceptHandler))):\n-                return (True, (name, 'outer scope (line %i)' % (stmts[0].lineno,)))\n+                return (True, (name, 'outer scope (line %s)' % (stmts[0].lineno,)))\n     return (False, None)\n \n \n", "before": "return ( True , ( name , 'outer scope (line %i)' % ( stmts [ 0 ] . lineno , ) ) )", "after": "return ( True , ( name , 'outer scope (line %s)' % ( stmts [ 0 ] . lineno , ) ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'outer scope (line %i)'\", 3, 38, 3, 61], \"'outer scope (line %s)'\"]]"}
{"project": "angr", "commit_sha": "85ad8533614e7fbd2171aa1fd1787e0ffcfb199a", "parent_sha": "736a79c37ac3533c2d98a67db22b122b69516e1b", "file_path": "angr/analyses/cfg.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -379,7 +379,7 @@ class CFG(Analysis, CFGBase):\n \n         # Create a temporary block\n         tmp_block = self._project.block(function_addr)\n-        num_instr = tmp_block.instructions() - 1\n+        num_instr = tmp_block.instructions - 1\n \n         symbolic_initial_state.ip = function_addr\n         path = self._project.exit_to(state=symbolic_initial_state)\n", "before": "num_instr = tmp_block . instructions ( ) - 1", "after": "num_instr = tmp_block . instructions - 1", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"binary_operator\", 3, 21, 3, 49], [\"attribute\", 3, 21, 3, 43], 0], [\"Delete\", [\"(:(\", 3, 43, 3, 44]], [\"Delete\", [\"):)\", 3, 44, 3, 45]], [\"Delete\", [\"argument_list\", 3, 43, 3, 45]], [\"Delete\", [\"call\", 3, 21, 3, 45]]]"}
{"project": "angr", "commit_sha": "52820c9a82f730eb5857dab8379c5bb2a1178bf7", "parent_sha": "21682551a2635fa16281b49a46b58b56e4662df7", "file_path": "angr/analyses/path_wrapper.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ class CallStack(object):\n         length = len(self._stack)\n \n         ret = ()\n-        for i in xrange(2 * (context_sensitivity_level - 1)):\n+        for i in xrange(2 * context_sensitivity_level):\n             index = length - i - 1\n             if index < 0:\n                 ret = (None, ) + ret\n", "before": "for i in xrange ( 2 * ( context_sensitivity_level - 1 ) ) : index = length - i - 1 if index < 0 : ret = ( None , ) + ret", "after": "for i in xrange ( 2 * context_sensitivity_level ) : index = length - i - 1 if index < 0 : ret = ( None , ) + ret", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"binary_operator\", 3, 25, 3, 60], [\"identifier:context_sensitivity_level\", 3, 30, 3, 55], 2], [\"Delete\", [\"(:(\", 3, 29, 3, 30]], [\"Delete\", [\"-:-\", 3, 56, 3, 57]], [\"Delete\", [\"integer:1\", 3, 58, 3, 59]], [\"Delete\", [\"binary_operator\", 3, 30, 3, 59]], [\"Delete\", [\"):)\", 3, 59, 3, 60]], [\"Delete\", [\"parenthesized_expression\", 3, 29, 3, 60]]]"}
{"project": "angr", "commit_sha": "4bfea69c910d9e931df0dbfabd0894872c0cc6db", "parent_sha": "c60841711e3c6cc06c8e4eba4d567b11189a397a", "file_path": "simuvex/s_type.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -371,7 +371,7 @@ class SimTypeFixedSizeArray(SimType):\n         return view._deeper(addr=view._addr + k * self.elem_type.size, ty=self.elem_type)\n \n     def extract(self, state, addr, concrete=False):\n-        return [self.elem_type.extract(state, addr + i*self.elem_type.size, concrete) for i in xrange(self.length)]\n+        return [self.elem_type.extract(state, addr + i*(self.elem_type.size/8), concrete) for i in xrange(self.length)]\n \n     def store(self, state, addr, values):\n         for i, val in enumerate(values):\n", "before": "return [ self . elem_type . extract ( state , addr + i * self . elem_type . size , concrete ) for i in xrange ( self . length ) ]", "after": "return [ self . elem_type . extract ( state , addr + i * ( self . elem_type . size / 8 ) , concrete ) for i in xrange ( self . length ) ]", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 54, 3, 75], [\"parenthesized_expression\", \"N0\"], 2], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N0\", [\"binary_operator\", \"N1\"], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2], [\"Move\", \"N1\", [\"attribute\", 3, 56, 3, 75], 0], [\"Insert\", \"N1\", [\"/:/\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:8\", \"T\"], 2]]"}
{"project": "suggester", "commit_sha": "2c79c3d5b6a5dae1855805f141129c1e7664c8da", "parent_sha": "e82a86c539700bddaa2b4b994603e326e1566359", "file_path": "suggester.py", "project_url": "https://github.com/kugoucode/suggester", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ def _find_matched_suggestions(index_data, search_query, limit, quality_multiplie\n     if not words:\n         return []\n     if use_prefix_search_for_all_words:\n-        words = [w + u'*' for w in words]\n+        words = [w + (u'' if w.endswith(u'*') else u'*') for w in words]\n     elif not (search_query.endswith(u' ') or words[-1].endswith(u'*')):\n         words[-1] = words[-1] + u'*'\n     suggestions = []\n", "before": "words = [ w + u'*' for w in words ]", "after": "words = [ w + ( u'' if w . endswith ( u'*' ) else u'*' ) for w in words ]", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 18, 3, 26], [\"parenthesized_expression\", \"N0\"], 2], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N0\", [\"conditional_expression\", \"N1\"], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:u''\", \"T\"], 0], [\"Insert\", \"N1\", [\"if:if\", \"T\"], 1], [\"Insert\", \"N1\", [\"call\", \"N2\"], 2], [\"Insert\", \"N1\", [\"else:else\", \"T\"], 3], [\"Insert\", \"N1\", [\"string:u'*'\", \"T\"], 4], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N3\", [\"identifier:w\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:endswith\", \"T\"], 2], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Move\", \"N4\", [\"string:u'*'\", 3, 22, 3, 26], 1], [\"Insert\", \"N4\", [\"):)\", \"T\"], 2]]"}
{"project": "angr", "commit_sha": "d8700ee1597e3d423aa1b8e5e84e8ff4b25667a0", "parent_sha": "4a38138a29fc7ff966e2ceacbc60c4c2a44c25f1", "file_path": "simuvex/procedures/libc___so___6/malloc.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ class malloc(simuvex.SimProcedure):\n             if size > plugin.max_variable_size:\n                 size = plugin.max_variable_size\n         else:\n-            size = sim_size.se.any_int() * 8\n+            size = self.state.se.any_int(sim_size) * 8\n \n         addr = plugin.heap_location\n         plugin.heap_location += size\n", "before": "size = sim_size . se . any_int ( ) * 8", "after": "size = self . state . se . any_int ( sim_size ) * 8", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"attribute\", 3, 20, 3, 39], [\".:.\", \"T\"], 1], [\"Move\", [\"argument_list\", 3, 39, 3, 41], [\"identifier:sim_size\", 3, 20, 3, 28], 1], [\"Insert\", [\"attribute\", 3, 20, 3, 31], [\"attribute\", \"N0\"], 0], [\"Move\", [\"attribute\", 3, 20, 3, 31], [\".:.\", 3, 31, 3, 32], 1], [\"Insert\", \"N0\", [\"identifier:self\", \"T\"], 0], [\"Move\", \"N0\", [\".:.\", 3, 28, 3, 29], 1], [\"Insert\", \"N0\", [\"identifier:state\", \"T\"], 2]]"}
{"project": "docker-cpu-miner", "commit_sha": "5128b152c75c25c2eb06be00536adcbbb19221fd", "parent_sha": "9a2fa946c2c77cdecb4d742f57e6dcb8513eefbf", "file_path": "cpuminer_driver.py", "project_url": "https://github.com/pbutenee/docker-cpu-miner", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -161,7 +161,7 @@ def main():\n \n             # Switch algorithm if it's worth while\n             if running_algorithm == None or running_algorithm != best_algorithm and \\\n-                (payrates[running_algorithm] or payrates[best_algorithm]/payrates[running_algorithm] >= 1.0 + PROFIT_SWITCH_THRESHOLD):\n+                (payrates[running_algorithm] == 0 or payrates[best_algorithm]/payrates[running_algorithm] >= 1.0 + PROFIT_SWITCH_THRESHOLD):\n \n                 # kill previous miner\n                 if cpuminer_thread != None:\n", "before": "if running_algorithm == None or running_algorithm != best_algorithm and ( payrates [ running_algorithm ] or payrates [ best_algorithm ] / payrates [ running_algorithm ] >= 1.0 + PROFIT_SWITCH_THRESHOLD ) : if cpuminer_thread != None : ", "after": "if running_algorithm == None or running_algorithm != best_algorithm and ( payrates [ running_algorithm ] == 0 or payrates [ best_algorithm ] / payrates [ running_algorithm ] >= 1.0 + PROFIT_SWITCH_THRESHOLD ) : if cpuminer_thread != None : ", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 18, 3, 134], [\"comparison_operator\", \"N0\"], 0], [\"Move\", \"N0\", [\"subscript\", 3, 18, 3, 45], 0], [\"Insert\", \"N0\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N0\", [\"integer:0\", \"T\"], 2]]"}
{"project": "angr", "commit_sha": "a42351356999096937128d1a5ce9710c1ffc38f0", "parent_sha": "9d07c591a0e63e35034d74e7d4cdba95115d2e0b", "file_path": "angr/path_group.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -357,7 +357,7 @@ class PathGroup(ana.Storable):\n             dir(type(self)) +\n             self.stashes.keys() +\n             ['mp_'+k for k in self.stashes.keys()] +\n-            ['any_'+k for k in self.stashes.keys()]\n+            ['one_'+k for k in self.stashes.keys()]\n         ))\n \n     #\n", "before": "dir ( type ( self ) ) + self . stashes . keys ( ) + [ 'mp_' + k for k in self . stashes . keys ( ) ] + [ 'any_' + k for k in self . stashes . keys ( ) ]", "after": "dir ( type ( self ) ) + self . stashes . keys ( ) + [ 'mp_' + k for k in self . stashes . keys ( ) ] + [ 'one_' + k for k in self . stashes . keys ( ) ]", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'any_'\", 3, 14, 3, 20], \"'one_'\"]]"}
{"project": "angr", "commit_sha": "8c19f2b5ec386bdb09fb921e0673d3f3246b6f42", "parent_sha": "151e713a1bb0615eb0e73e1e1b055846921ae681", "file_path": "angr/knowledge/function.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -481,7 +481,7 @@ class Function(object):\n             g.add_node(self.startpoint)\n         for src, dst, data in self.transition_graph.edges_iter(data=True):\n             if 'type' in data:\n-                if data['type']  == 'transition' and data['outside'] == False:\n+                if data['type']  == 'transition' and ('outside' not in data or data['outside'] == False):\n                     g.add_edge(src, dst, attr_dict=data)\n                 elif data['type'] == 'fake_return' and 'confirmed' in data:\n                     g.add_edge(src, dst, attr_dict=data)\n", "before": "if data [ 'type' ] == 'transition' and data [ 'outside' ] == False : g . add_edge ( src , dst , attr_dict = data ) elif data [ 'type' ] == 'fake_return' and 'confirmed' in data : g . add_edge ( src , dst , attr_dict = data )", "after": "if data [ 'type' ] == 'transition' and ( 'outside' not in data or data [ 'outside' ] == False ) : g . add_edge ( src , dst , attr_dict = data ) elif data [ 'type' ] == 'fake_return' and 'confirmed' in data : g . add_edge ( src , dst , attr_dict = data )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 20, 3, 78], [\"parenthesized_expression\", \"N0\"], 2], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N0\", [\"boolean_operator\", \"N1\"], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2], [\"Insert\", \"N1\", [\"comparison_operator\", \"N2\"], 0], [\"Insert\", \"N1\", [\"or:or\", \"T\"], 1], [\"Move\", \"N1\", [\"comparison_operator\", 3, 54, 3, 78], 2], [\"Insert\", \"N2\", [\"string:'outside'\", \"T\"], 0], [\"Insert\", \"N2\", [\"not:not\", \"T\"], 1], [\"Insert\", \"N2\", [\"in:in\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:data\", \"T\"], 3]]"}
{"project": "quaternions", "commit_sha": "be0a40d9b125e9162083426742ab0dfd3b6e8eb8", "parent_sha": "a0917773b343f73d1813716b34219e6471ff95fa", "file_path": "quaternions/general_quaternion.py", "project_url": "https://github.com/AmitAronovitch/quaternions", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ class GeneralQuaternion(object):\n \n     def __add__(self, p):\n         if not is_quaternion(p):\n-            raise QuaternionError('expected quaternion, got %s' % p)\n+            raise QuaternionError('expected quaternion, got %s' % p.__class__.__name__)\n         return GeneralQuaternion(self.qr + p.qr, self.qi + p.qi, self.qj + p.qj, self.qk + p.qk)\n \n     def __sub__(self, p):\n", "before": "raise QuaternionError ( 'expected quaternion, got %s' % p )", "after": "raise QuaternionError ( 'expected quaternion, got %s' % p . __class__ . __name__ )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 35, 3, 68], [\"attribute\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:__name__\", \"T\"], 2], [\"Move\", \"N1\", [\"identifier:p\", 3, 67, 3, 68], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:__class__\", \"T\"], 2]]"}
{"project": "zipline", "commit_sha": "cb7ee531116a5c56faa08f588e8e7908010e0b06", "parent_sha": "5160b11bc1a8360b0c794faf6ca5988f800e8f5e", "file_path": "zipline/testing/predicates.py", "project_url": "https://github.com/michaelballard7/zipline", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -358,7 +358,7 @@ def assert_dict_equal(result, expected, path=(), msg='', **kwargs):\n             assert_equal(\n                 resultv,\n                 expectedv,\n-                path=path + ('[%r]' % k,),\n+                path=path + ('[%r]' % (k,),),\n                 msg=msg,\n                 **kwargs\n             )\n", "before": "assert_equal ( resultv , expectedv , path = path + ( '[%r]' % k , ) , msg = msg , ** kwargs )", "after": "assert_equal ( resultv , expectedv , path = path + ( '[%r]' % ( k , ) , ) , msg = msg , ** kwargs )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 30, 3, 40], [\"tuple\", \"N0\"], 2], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:k\", 3, 39, 3, 40], 1], [\"Insert\", \"N0\", [\",:,\", \"T\"], 2], [\"Insert\", \"N0\", [\"):)\", \"T\"], 3]]"}
{"project": "zipline", "commit_sha": "0e246a2eee1d6e51eb2cab9a3782642d7a29d1f8", "parent_sha": "7896520bce05beaa9abaa47445ef089b74cb1ba5", "file_path": "zipline/utils/sentinel.py", "project_url": "https://github.com/michaelballard7/zipline", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,7 +33,7 @@ def sentinel(name, doc=None):\n         __name__ = name\n \n         def __new__(cls):\n-            raise TypeError(\"Can't construct new instances of %r\" % name)\n+            raise TypeError('cannot create %r instances' % name)\n \n         def __repr__(self):\n             return 'sentinel(%r)' % name\n", "before": "raise TypeError ( \"Can't construct new instances of %r\" % name )", "after": "raise TypeError ( 'cannot create %r instances' % name )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"Can't construct new instances of %r\\\"\", 3, 29, 3, 66], \"'cannot create %r instances'\"]]"}
{"project": "python_planet", "commit_sha": "3cc5bd8e51fa7de2888d2455c2153c33e594632e", "parent_sha": "f3b5fe658ccb2d19fac2108dc256b544e93a6f7d", "file_path": "planet/control/CApproval.py", "project_url": "https://github.com/haobin12358/python_planet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -766,7 +766,7 @@ class CApproval(BASEAPPROVAL):\n             # admin_model = Admin.query.filter_by_(ADid=ap.AVstartid).first()\n             content = GuessNumAwardApply.query.filter_by_(GNAAid=ap.AVcontent).first()\n             # if not (start_model or admin_model) or not content:\n-            if not start_mode or not content:\n+            if not start_model or not content:\n                 # ap_list.remove(ap)\n                 ap_remove_list.append(ap)\n                 continue\n", "before": "if not start_mode or not content : ap_remove_list . append ( ap ) continue", "after": "if not start_model or not content : ap_remove_list . append ( ap ) continue", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"identifier:start_mode\", 3, 20, 3, 30], \"start_model\"]]"}
{"project": "spacepaper", "commit_sha": "809c2dc0879eab3a7bffb1175842b501b6009667", "parent_sha": "9b612cd730a84a2b2fe6879c695efd9749526d9f", "file_path": "spacepaper.py", "project_url": "https://github.com/thewhiteh4t/spacepaper", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -125,7 +125,7 @@ def mny():\n def gen():\n \tglobal Year, Month, key\n \ttotal = calendar.monthrange(Year, Month)[1]\n-\tprint (G + '[+]' + C + 'Month/Year : ' + W + str(Month) + '/' + str(Year))\n+\tprint (G + '[+]' + C + ' Month/Year : ' + W + str(Month) + '/' + str(Year))\n \twith open ('website/js/spacepaper.js', 'w') as img:\n \t\timg.write(''' document.write(' ''')\n \t\tfor i in range(1,total):\n", "before": "print ( G + '[+]' + C + 'Month/Year : ' + W + str ( Month ) + '/' + str ( Year ) )", "after": "print ( G + '[+]' + C + ' Month/Year : ' + W + str ( Month ) + '/' + str ( Year ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'Month/Year : '\", 3, 25, 3, 40], \"' Month/Year : '\"]]"}
{"project": "freeipa-healthcheck", "commit_sha": "c94d3acfc8a3184682ddb996814c2a82b031bf75", "parent_sha": "e84dcc44e0a4abe87e5599879eac45710bed0546", "file_path": "src/ipahealthcheck/ipa/certs.py", "project_url": "https://github.com/freeipa/freeipa-healthcheck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -305,7 +305,7 @@ class IPACertfileExpirationCheck(IPAPlugin):\n             if now > notafter:\n                 result = Result(self, constants.ERROR,\n                                 key=id,\n-                                msg='Request id %s is expired: %s' % id)\n+                                msg='Request id %s is expired' % id)\n                 results.add(result)\n                 continue\n \n", "before": "result = Result ( self , constants . ERROR , key = id , msg = 'Request id %s is expired: %s' % id )", "after": "result = Result ( self , constants . ERROR , key = id , msg = 'Request id %s is expired' % id )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'Request id %s is expired: %s'\", 3, 37, 3, 67], \"'Request id %s is expired'\"]]"}
{"project": "sympy", "commit_sha": "08b35fd04ccade75dcdb30d56d4919c44af2ef08", "parent_sha": "84c125972ad535b2dfb245f8d311d347b45e5b8a", "file_path": "sympy/printing/octave.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -128,7 +128,7 @@ def _print_Mul(self, expr):\n         # print complex numbers nicely in Octave\n         if (expr.is_number and expr.is_imaginary and\n                 expr.as_coeff_Mul()[0].is_integer):\n-            return \"%si\" % self._print(-S.ImaginaryUnit*expr)\n+            return \"%s*i\" % self._print(-S.ImaginaryUnit*expr)\n \n         # cribbed from str.py\n         prec = precedence(expr)\n", "before": "return \"%si\" % self . _print ( - S . ImaginaryUnit * expr )", "after": "return \"%s*i\" % self . _print ( - S . ImaginaryUnit * expr )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"%si\\\"\", 3, 20, 3, 25], \"\\\"%s*i\\\"\"]]"}
{"project": "sympy", "commit_sha": "c00ec4c8bdd12c0db4d7e76e97475b9eebea0a1d", "parent_sha": "bff4b6b5a33f9766323303b909d1f6d072a17424", "file_path": "sympy/matrices/matrices.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1130,7 +1130,7 @@ def eigenvals(self, error_when_incomplete=True, **flags):\n \n         # make sure the algebraic multiplicty sums to the\n         # size of the matrix\n-        if error_when_incomplete and type(eigs)==dict and sum(m for m in eigs.values()) != self.cols:\n+        if error_when_incomplete and isinstance(eigs, dict) and sum(m for m in eigs.values()) != self.cols:\n             raise MatrixError(\"Could not compute eigenvalues for {}\".format(self))\n \n         return eigs\n", "before": "if error_when_incomplete and type ( eigs ) == dict and sum ( m for m in eigs . values ( ) ) != self . cols : raise MatrixError ( \"Could not compute eigenvalues for {}\" . format ( self ) )", "after": "if error_when_incomplete and isinstance ( eigs , dict ) and sum ( m for m in eigs . values ( ) ) != self . cols : raise MatrixError ( \"Could not compute eigenvalues for {}\" . format ( self ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 12, 3, 54], [\"call\", 3, 38, 3, 48], 2], [\"Update\", [\"identifier:type\", 3, 38, 3, 42], \"isinstance\"], [\"Insert\", [\"argument_list\", 3, 42, 3, 48], [\",:,\", \"T\"], 2], [\"Move\", [\"argument_list\", 3, 42, 3, 48], [\"identifier:dict\", 3, 50, 3, 54], 3], [\"Delete\", [\"==:==\", 3, 48, 3, 50]], [\"Delete\", [\"comparison_operator\", 3, 38, 3, 54]]]"}
{"project": "sympy", "commit_sha": "63f4ccc8439e2eb830398b37c4efd19923fd5563", "parent_sha": "2bb4a6943ab9a3e6e0c7d857ab8b2438b3c61426", "file_path": "sympy/functions/special/error_functions.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -778,7 +778,7 @@ def eval(cls, z):\n         elif z is S.One:\n             return S.Infinity\n \n-        if (isinstance(z, erf)) and z.args[0].is_real:\n+        if isinstance(z, erf) and z.args[0].is_real:\n             return z.args[0]\n \n         # Try to pull out factors of -1\n", "before": "if ( isinstance ( z , erf ) ) and z . args [ 0 ] . is_real : return z . args [ 0 ]", "after": "if isinstance ( z , erf ) and z . args [ 0 ] . is_real : return z . args [ 0 ]", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 12, 3, 54], [\"call\", 3, 13, 3, 31], 0], [\"Delete\", [\"(:(\", 3, 12, 3, 13]], [\"Delete\", [\"):)\", 3, 31, 3, 32]], [\"Delete\", [\"parenthesized_expression\", 3, 12, 3, 32]]]"}
{"project": "sympy", "commit_sha": "015036ef613de15708f5b7929e8bb6d8bc589eda", "parent_sha": "63f4ccc8439e2eb830398b37c4efd19923fd5563", "file_path": "sympy/functions/special/error_functions.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -783,7 +783,7 @@ def eval(cls, z):\n \n         # Try to pull out factors of -1\n         nz = z.extract_multiplicatively(-1)\n-        if nz is not None and ((isinstance(nz, erf)) and (nz.args[0]).is_real):\n+        if nz is not None and (isinstance(nz, erf) and (nz.args[0]).is_real):\n             return -nz.args[0]\n \n     def _eval_rewrite_as_erfcinv(self, z):\n", "before": "if nz is not None and ( ( isinstance ( nz , erf ) ) and ( nz . args [ 0 ] ) . is_real ) : return - nz . args [ 0 ]", "after": "if nz is not None and ( isinstance ( nz , erf ) and ( nz . args [ 0 ] ) . is_real ) : return - nz . args [ 0 ]", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 32, 3, 78], [\"call\", 3, 33, 3, 52], 0], [\"Delete\", [\"(:(\", 3, 32, 3, 33]], [\"Delete\", [\"):)\", 3, 52, 3, 53]], [\"Delete\", [\"parenthesized_expression\", 3, 32, 3, 53]]]"}
{"project": "osc", "commit_sha": "439dafbdc51c118fa0856c80a41d96773c7c7d08", "parent_sha": "d28cddfede1c5607db933582d51a18bc674a3766", "file_path": "osc/core.py", "project_url": "https://github.com/lethliel/osc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -393,7 +393,7 @@ class Serviceinfo:\n             r = run_external(cmd, shell=True)\n \n             if r != 0:\n-                print(\"Aborting: service call failed: \" + c)\n+                print(\"Aborting: service call failed: \" + cmd)\n                 # FIXME: addDownloadUrlService calls si.execute after \n                 #        updating _services.\n                 for filename in os.listdir(temp_dir):\n", "before": "print ( \"Aborting: service call failed: \" + c )", "after": "print ( \"Aborting: service call failed: \" + cmd )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"identifier:c\", 3, 59, 3, 60], \"cmd\"]]"}
{"project": "osc", "commit_sha": "f7eab473f051f511b957b7dd7f61f05a05c37288", "parent_sha": "bd3a6d2fc88504deceda9f90f9c2fd9f61a9a798", "file_path": "tests/test_prdiff.py", "project_url": "https://github.com/lethliel/osc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ UPSTREAM = 'some:project'\n BRANCH   = 'home:user:branches:' + UPSTREAM\n \n def rdiff_url(pkg, oldprj, newprj):\n-    return API_URL + 'source/%s/%s?unified=1&opackage=%s&oproject=%s&cmd=diff&expand=1&filelimit=0' % \\\n+    return API_URL + 'source/%s/%s?unified=1&opackage=%s&oproject=%s&cmd=diff&expand=1&tarlimit=0&filelimit=0' % \\\n         (newprj, pkg, pkg, oldprj.replace(':', '%3A'))\n \n def request_url(prj):\n", "before": "return API_URL + 'source/%s/%s?unified=1&opackage=%s&oproject=%s&cmd=diff&expand=1&filelimit=0' % ( newprj , pkg , pkg , oldprj . replace ( ':' , '%3A' ) )", "after": "return API_URL + 'source/%s/%s?unified=1&opackage=%s&oproject=%s&cmd=diff&expand=1&tarlimit=0&filelimit=0' % ( newprj , pkg , pkg , oldprj . replace ( ':' , '%3A' ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'source/%s/%s?unified=1&opackage=%s&oproject=%s&cmd=diff&expand=1&filelimit=0'\", 3, 22, 3, 100], \"'source/%s/%s?unified=1&opackage=%s&oproject=%s&cmd=diff&expand=1&tarlimit=0&filelimit=0'\"]]"}
{"project": "osc", "commit_sha": "2d29c35f46dead159ff4df2934a02d8bd6529e7e", "parent_sha": "f202fbd1117c6d0bf808cccb29f9940a9c300e8e", "file_path": "osc/core.py", "project_url": "https://github.com/lethliel/osc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -5171,7 +5171,7 @@ def get_prj_results(apiurl, prj, hide_legend=False, csv=False, status_filter=Non\n         row = ['_'] + ['/'.join(tg) for tg in targets]\n         r.append(';'.join(row))\n         for pac in pacs:\n-            row = [pac] + [status[pac][tg] for tg in targets]\n+            row = [pac] + [status[pac][tg] for tg in targets if tg in status[pac]]\n             r.append(';'.join(row))\n         return r\n \n", "before": "row = [ pac ] + [ status [ pac ] [ tg ] for tg in targets ]", "after": "row = [ pac ] + [ status [ pac ] [ tg ] for tg in targets if tg in status [ pac ] ]", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"list_comprehension\", 3, 27, 3, 62], [\"if_clause\", \"N0\"], 3], [\"Insert\", [\"list_comprehension\", 3, 27, 3, 62], [\"]:]\", \"T\"], 4], [\"Insert\", \"N0\", [\"if:if\", \"T\"], 0], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 1], [\"Insert\", \"N1\", [\"identifier:tg\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"subscript\", \"N2\"], 2], [\"Insert\", \"N2\", [\"identifier:status\", \"T\"], 0], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:pac\", \"T\"], 2], [\"Move\", \"N2\", [\"]:]\", 3, 61, 3, 62], 3]]"}
{"project": "osc", "commit_sha": "e662fd815b8b7603b169ed8084ee76bbe641f9a7", "parent_sha": "a8d0b948af6aeaec1d8f48b9726ad8a8f48e4222", "file_path": "osc/commandline.py", "project_url": "https://github.com/lethliel/osc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -5388,7 +5388,7 @@ Please submit there instead, or use --nodevelproject to force direct submission.\n                     elif not arg_repository:\n                         arg_repository = arg\n                     else:\n-                        raise oscerr.WrongArgs('unexpected argument: \\'%s\\'' % arg)\n+                        raise oscerr.WrongArgs('\\'%s\\' is neither a build description nor a supported arch' % arg)\n         else:\n             arg_repository, arg_arch, arg_descr = args\n \n", "before": "else : raise oscerr . WrongArgs ( 'unexpected argument: \\'%s\\'' % arg )", "after": "else : raise oscerr . WrongArgs ( '\\'%s\\' is neither a build description nor a supported arch' % arg )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'unexpected argument: \\\\'%s\\\\''\", 3, 48, 3, 77], \"'\\\\'%s\\\\' is neither a build description nor a supported arch'\"]]"}
{"project": "sympy", "commit_sha": "4c77e08292f47edb91ed264a1a01257857539b21", "parent_sha": "70e2e6e4c41eedd60a34071860a3eb10d19cf040", "file_path": "sympy/core/power.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -693,7 +693,7 @@ def _eval_evalf(self, prec):\n         base = base._evalf(prec)\n         if not exp.is_Integer:\n             exp = exp._evalf(prec)\n-        if exp.is_real and (exp < 0) is True and base.is_number and base.is_real is False:\n+        if exp.is_negative and base.is_number and base.is_real is False:\n             base = base.conjugate() / (base * base.conjugate())._evalf(prec)\n             exp = -exp\n             return self.func(base, exp).expand()\n", "before": "if exp . is_real and ( exp < 0 ) is True and base . is_number and base . is_real is False : base = base . conjugate ( ) / ( base * base . conjugate ( ) ) . _evalf ( prec ) exp = - exp return self . func ( base , exp ) . expand ( )", "after": "if exp . is_negative and base . is_number and base . is_real is False : base = base . conjugate ( ) / ( base * base . conjugate ( ) ) . _evalf ( prec ) exp = - exp return self . func ( base , exp ) . expand ( )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 12, 3, 64], [\"attribute\", 3, 12, 3, 23], 0], [\"Move\", [\"boolean_operator\", 3, 12, 3, 64], [\"and:and\", 3, 24, 3, 27], 1], [\"Update\", [\"identifier:is_real\", 3, 16, 3, 23], \"is_negative\"], [\"Delete\", [\"(:(\", 3, 28, 3, 29]], [\"Delete\", [\"identifier:exp\", 3, 29, 3, 32]], [\"Delete\", [\"<:<\", 3, 33, 3, 34]], [\"Delete\", [\"integer:0\", 3, 35, 3, 36]], [\"Delete\", [\"comparison_operator\", 3, 29, 3, 36]], [\"Delete\", [\"):)\", 3, 36, 3, 37]], [\"Delete\", [\"parenthesized_expression\", 3, 28, 3, 37]], [\"Delete\", [\"is:is\", 3, 38, 3, 40]], [\"Delete\", [\"true:True\", 3, 41, 3, 45]], [\"Delete\", [\"comparison_operator\", 3, 28, 3, 45]], [\"Delete\", [\"boolean_operator\", 3, 12, 3, 45]], [\"Delete\", [\"and:and\", 3, 46, 3, 49]]]"}
{"project": "sympy", "commit_sha": "c318d138fc24b77e9c417afcb21a341b41845743", "parent_sha": "937e60380f6229136c0d9dd53fe629f7d745d784", "file_path": "sympy/core/function.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1326,7 +1326,7 @@ def as_finite_diff(self, indep_vals=None, around=None):\n         if around == None: around = self.variables[0]\n         order = len(self.variables)\n         if indep_vals == None or not iterable(indep_vals):\n-            h = indep_vals or sympify('h')\n+            h = indep_vals or 1\n             indep_vals_l = [around - h*i for i in range((order+1)//2, 0, -1)]\n             indep_vals_r = [around + h*i for i in range(1, (order+1)//2 + 1)]\n             if order % 1 == 0:\n", "before": "h = indep_vals or sympify ( 'h' )", "after": "h = indep_vals or 1", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 17, 3, 43], [\"integer:1\", \"T\"], 2], [\"Delete\", [\"identifier:sympify\", 3, 31, 3, 38]], [\"Delete\", [\"(:(\", 3, 38, 3, 39]], [\"Delete\", [\"string:'h'\", 3, 39, 3, 42]], [\"Delete\", [\"):)\", 3, 42, 3, 43]], [\"Delete\", [\"argument_list\", 3, 38, 3, 43]], [\"Delete\", [\"call\", 3, 31, 3, 43]]]"}
{"project": "sympy", "commit_sha": "c03ca1e96f9cde2ff2b6a948d6b1838624dc36f8", "parent_sha": "c50e016fdfdd26701f73ffeeb6994694a8973b5a", "file_path": "sympy/core/power.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -871,7 +871,7 @@ def _eval_nseries(self, x, n, logx):\n                     cf = S.One/abs(cf)\n \n                 try:\n-                    dn = C.Order(rest/prefactor, x).getn()\n+                    dn = C.Order(1/prefactor, x).getn()\n                     if dn and dn < 0:\n                         pass\n                     else:\n", "before": "dn = C . Order ( rest / prefactor , x ) . getn ( )", "after": "dn = C . Order ( 1 / prefactor , x ) . getn ( )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 34, 3, 48], [\"integer:1\", \"T\"], 0], [\"Delete\", [\"identifier:rest\", 3, 34, 3, 38]]]"}
{"project": "sympy", "commit_sha": "c6ddc2067a729804b2df1e28dd9c95247d3334cb", "parent_sha": "378cb9c22dd0a8e961a165520849ea56ec97072c", "file_path": "sympy/solvers/diophantine.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1004,7 +1004,7 @@ def _diop_quadratic(var, coeff, t):\n                 for z0 in range(0, abs(_c)):\n                     # Check if the coefficients of y and x obtained are integers or not\n                     if (divisible(sqa*g*z0**2 + D*z0 + sqa*F, _c) and\n-                            divisible(e*sqc**g*z0**2 + E*z0 + e*sqc*F, _c)):\n+                            divisible(e*sqc*g*z0**2 + E*z0 + e*sqc*F, _c)):\n                         sol.add((solve_x(z0), solve_y(z0)))\n \n     # (3) Method used when B**2 - 4*A*C is a square, is described in p. 6 of the below paper\n", "before": "if ( divisible ( sqa * g * z0 ** 2 + D * z0 + sqa * F , _c ) and divisible ( e * sqc ** g * z0 ** 2 + E * z0 + e * sqc * F , _c ) ) : sol . add ( ( solve_x ( z0 ) , solve_y ( z0 ) ) )", "after": "if ( divisible ( sqa * g * z0 ** 2 + D * z0 + sqa * F , _c ) and divisible ( e * sqc * g * z0 ** 2 + E * z0 + e * sqc * F , _c ) ) : sol . add ( ( solve_x ( z0 ) , solve_y ( z0 ) ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 39, 3, 47], [\"binary_operator\", \"N0\"], 0], [\"Insert\", [\"binary_operator\", 3, 39, 3, 47], [\"*:*\", \"T\"], 1], [\"Move\", [\"binary_operator\", 3, 39, 3, 47], [\"identifier:g\", 3, 46, 3, 47], 2], [\"Move\", \"N0\", [\"identifier:e\", 3, 39, 3, 40], 0], [\"Move\", \"N0\", [\"*:*\", 3, 40, 3, 41], 1], [\"Move\", \"N0\", [\"identifier:sqc\", 3, 41, 3, 44], 2], [\"Delete\", [\"**:**\", 3, 44, 3, 46]], [\"Delete\", [\"binary_operator\", 3, 41, 3, 47]]]"}
{"project": "sympy", "commit_sha": "29a6e2ddebbeaa8867bd33dcad8b9c66feb6b270", "parent_sha": "0804e23d1be2ddd056790a899a8fdb2012bdd384", "file_path": "sympy/solvers/solvers.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1028,7 +1028,7 @@ def _sympified_list(w):\n         for e in fi.find(Abs):\n             if e.has(*symbols):\n                 raise NotImplementedError('solving %s when the argument '\n-                    'is not real or imaginary.' % fi)\n+                    'is not real or imaginary.' % e)\n \n         # arg\n         _arg = [a for a in fi.atoms(arg) if a.has(*symbols)]\n", "before": "raise NotImplementedError ( 'solving %s when the argument ' 'is not real or imaginary.' % fi )", "after": "raise NotImplementedError ( 'solving %s when the argument ' 'is not real or imaginary.' % e )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"identifier:fi\", 3, 51, 3, 53], \"e\"]]"}
{"project": "sympy", "commit_sha": "13213aa51c3fa0ba5c7c6105a2169b891ead2b45", "parent_sha": "0f0939e4fa0d18ad392a468c0082c75b1a868fd1", "file_path": "sympy/integrals/meijerint.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1681,7 +1681,7 @@ def tr(p):\n         # The antiderivative is most often expected to be defined\n         # in the neighborhood of  x = 0.\n         place = 0\n-        if b < 0 or f.subs(x, 0).has(nan, zoo):\n+        if (b < 0) == True or f.subs(x, 0).has(nan, zoo):\n             place = None\n         r = hyperexpand(r.subs(t, a*x**b), place=place)\n \n", "before": "if b < 0 or f . subs ( x , 0 ) . has ( nan , zoo ) : place = None", "after": "if ( b < 0 ) == True or f . subs ( x , 0 ) . has ( nan , zoo ) : place = None", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 17], [\"parenthesized_expression\", \"N0\"], 0], [\"Insert\", [\"comparison_operator\", 3, 12, 3, 17], [\"==:==\", \"T\"], 1], [\"Insert\", [\"comparison_operator\", 3, 12, 3, 17], [\"true:True\", \"T\"], 2], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 17], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2]]"}
{"project": "sympy", "commit_sha": "e76f5064781d57ddd46e65d2bb577cd485585bc4", "parent_sha": "1047aad15387be8c9ff2148231a2572aa289b497", "file_path": "sympy/matrices/matrices.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -4426,7 +4426,7 @@ def LUdecomposition_Simple(\n             L_{1, 0} & 1 & 0 & \\cdots & 0 \\\\\n             L_{2, 0} & L_{2, 1} & 1 & \\cdots & 0 \\\\\n             \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n-            L_{n-1, 0} & L_{n-1, 1} & L_{n-1, 2} & \\cdots & 1\n+            L_{m-1, 0} & L_{m-1, 1} & L_{m-1, 2} & \\cdots & 1\n             \\end{bmatrix}\n \n         .. math::\n", "before": "{ 1 , 0 } & 1 & 0 & c dots & 0 \\ L_ { 2 , 0 } & L_ { 2 , 1 } & 1 & c dots & 0 \\\n             \\ vdots & v dots & v dots & d dots & v dots \\ L_ { n - 1 , 0 } & L_ { n - 1 , 1 } & L_ { n - 1 , 2 } & c dots & 1 e nd { bmatrix }", "after": "{ 1 , 0 } & 1 & 0 & c dots & 0 \\ L_ { 2 , 0 } & L_ { 2 , 1 } & 1 & c dots & 0 \\\n             \\ vdots & v dots & v dots & d dots & v dots \\ L_ { m - 1 , 0 } & L_ { m - 1 , 1 } & L_ { m - 1 , 2 } & c dots & 1 e nd { bmatrix }", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"identifier:n\", 3, 42, 3, 43], \"m\"], [\"Update\", [\"identifier:n\", 3, 29, 3, 30], \"m\"], [\"Update\", [\"identifier:n\", 3, 16, 3, 17], \"m\"]]"}
{"project": "moto", "commit_sha": "ef8b6c1f28222a5718a80971073d4204babad260", "parent_sha": "1f618a3cb53d167b65c1d051c7a06011b417364f", "file_path": "moto/sqs/models.py", "project_url": "https://github.com/chellman-delphix/moto", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -122,7 +122,7 @@ class Queue(object):\n         self.last_modified_timestamp = now\n         self.maximum_message_size = 64 << 10\n         self.message_retention_period = 86400 * 4  # four days\n-        self.queue_arn = 'arn:aws:sqs:sqs.us-east-1:123456789012:%s' % self.name\n+        self.queue_arn = 'arn:aws:sqs:us-east-1:123456789012:%s' % self.name\n         self.receive_message_wait_time_seconds = 0\n \n     @classmethod\n", "before": "self . queue_arn = 'arn:aws:sqs:sqs.us-east-1:123456789012:%s' % self . name", "after": "self . queue_arn = 'arn:aws:sqs:us-east-1:123456789012:%s' % self . name", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'arn:aws:sqs:sqs.us-east-1:123456789012:%s'\", 3, 26, 3, 69], \"'arn:aws:sqs:us-east-1:123456789012:%s'\"]]"}
{"project": "pypcb", "commit_sha": "12ac0745e7de13e23eab78809ed4897879498ac2", "parent_sha": "e22b4db2d70a805449d46f7608fdf2e28e0f3be0", "file_path": "detector/componentDetector.py", "project_url": "https://github.com/KevinGay/pypcb", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,7 +25,7 @@ class componentDetector(object):\n     def __init__(self, component=\"ic\", mode=\"GPU\"):\n         self.componentClass = component\n         self.mode = mode\n-        self.modelpath = 'models/' + self.componentClass\n+        self.modelpath = './models/' + self.componentClass\n         self.model = os.path.join(self.modelpath, 'model_' + self.componentClass + '.caffemodel')\n         self.prototxt = os.path.join(self.modelpath, 'deploy.prototxt')\n         self.fullConvProto = os.path.join(self.modelpath, 'fullConv_' + self.componentClass + '.prototxt')\n", "before": "self . modelpath = 'models/' + self . componentClass", "after": "self . modelpath = './models/' + self . componentClass", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'models/'\", 3, 26, 3, 35], \"'./models/'\"]]"}
{"project": "isida", "commit_sha": "8979a2369f68f92d457c06dde095844c8b368c70", "parent_sha": "076291353325627ea632b16cb9ec28643a397ccd", "file_path": "plugins/karma.py", "project_url": "https://github.com/cobrab11/isida", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -115,7 +115,7 @@ def karma_change(room,jid,nick,type,text,value):\n \t\t\t\t\tcu_karmabase.execute('insert into karma values (?,?,?)',(room,karmajid,stat)).fetchall()\r\n \t\t\t\t\tmsg = u'\u0412\u044b \u0438\u0437\u043c\u0435\u043d\u0438\u043b\u0438 \u043a\u0430\u0440\u043c\u0443 '+text+u' \u0434\u043e '+karma_val(stat)+u'! \u0421\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0439 \u0440\u0430\u0437 \u043c\u043e\u0436\u043d\u043e \u0438\u0437\u043c\u0435\u043d\u0438\u0442\u044c \u0447\u0435\u0440\u0435\u0437: '+un_unix(karma_timeout[k_acc])\r\n \t\t\t\t\tkarma_base.commit()\r\n-\t\t\t\t\tpprint('karma change in'+room+' for '+text+' to '+str(stat))\r\n+\t\t\t\t\tpprint('karma change in '+room+' for '+text+' to '+str(stat))\r\n \t\t\t\telse: msg = u'\u0412\u044b \u043d\u0435\u0434\u0430\u0432\u043d\u043e \u043c\u0435\u043d\u044f\u043b\u0438 \u043a\u0430\u0440\u043c\u0443 '+text+u'! \u041d\u0430\u0434\u043e \u043f\u043e\u0434\u043e\u0436\u0434\u0430\u0442\u044c: '+un_unix(int(stat[0])+karma_timeout[k_acc]-karma_time)\r\n \t\t\t\tkarma_base.close()\r\n \t\telse: msg = u'\u0412\u0430\u043c \u043d\u0435\u043b\u044c\u0437\u044f \u043c\u0435\u043d\u044f\u0442\u044c \u043a\u0430\u0440\u043c\u0443 \u0443\u0447\u0430\u0441\u0442\u043d\u0438\u043a\u0430!'\r\n", "before": "pprint ( 'karma change in' + room + ' for ' + text + ' to ' + str ( stat ) )", "after": "pprint ( 'karma change in ' + room + ' for ' + text + ' to ' + str ( stat ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'karma change in'\", 3, 13, 3, 30], \"'karma change in '\"]]"}
{"project": "isida", "commit_sha": "d7b727dcd4490308c0798bbdbec301f74b287354", "parent_sha": "4e7a6f387f932c421af125dbdc6d2a507ce7da43", "file_path": "plugins/chat.py", "project_url": "https://github.com/cobrab11/isida", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,5 +53,5 @@ def getAnswer(text,room,type):\n \telse:\n \t\tansw = getSmartAnswer(text,room)\n \t\tANSW_PREV[room] = text.upper()\n-\tif type == 'groupchat' and tx == to_censore(tx): addAnswerToBase(text)\n+\tif type == 'groupchat' and text == to_censore(text): addAnswerToBase(text)\n \treturn answ\n", "before": "if type == 'groupchat' and tx == to_censore ( tx ) : addAnswerToBase ( text )", "after": "if type == 'groupchat' and text == to_censore ( text ) : addAnswerToBase ( text )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"identifier:tx\", 3, 29, 3, 31], \"text\"], [\"Update\", [\"identifier:tx\", 3, 46, 3, 48], \"text\"]]"}
{"project": "bokeh", "commit_sha": "a6d86e2bc5e6b2279b140de4d68a3175b8433c10", "parent_sha": "9a15d1d8d3b98a4925a5c58a33e95d7ac4bb9743", "file_path": "scripts/build_upload.py", "project_url": "https://github.com/suqi/bokeh", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -358,7 +358,7 @@ def upload_cdn(cdn_token, cdn_id):\n     content_type = \"text/css\"\n     for name in ('bokeh', 'bokeh-widgets'):\n         for suffix in ('css', 'min.css'):\n-            local_path = 'bokehjs/build/js/%s.%s' % (name, suffix)\n+            local_path = 'bokehjs/build/css/%s.%s' % (name, suffix)\n             cdn_path = 'bokeh/bokeh/%s/%s-%s.%s' % (subdir, name, version, suffix)\n             cdn_upload(local_path, cdn_path, content_type, cdn_token, cdn_id)\n \n", "before": "local_path = 'bokehjs/build/js/%s.%s' % ( name , suffix )", "after": "local_path = 'bokehjs/build/css/%s.%s' % ( name , suffix )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'bokehjs/build/js/%s.%s'\", 3, 26, 3, 50], \"'bokehjs/build/css/%s.%s'\"]]"}
{"project": "bokeh", "commit_sha": "e3bcb52e5f2370ff08a4179ded5b319881d06a7f", "parent_sha": "3703f70f58d3ec09db63b0a6713e7026aad325d6", "file_path": "bokeh/core/properties.py", "project_url": "https://github.com/suqi/bokeh", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -715,7 +715,7 @@ class HasProps(with_metaclass(MetaHasProps, object)):\n     # instead of models, and takes a doc to look up the refs in\n     def _json_record_references(doc, v, result, recurse):\n         if v is None: return\n-        if isinstance(v, dict) and set(v.keys()) == set(['id', 'type']):\n+        if isinstance(v, dict) and set(['id', 'type']).issubset(set(v.keys())):\n             if v['id'] not in result:\n                 model = doc.get_model_by_id(v['id'])\n                 HasProps._value_record_references(model, result, recurse)\n", "before": "if isinstance ( v , dict ) and set ( v . keys ( ) ) == set ( [ 'id' , 'type' ] ) : if v [ 'id' ] not in result : model = doc . get_model_by_id ( v [ 'id' ] ) HasProps . _value_record_references ( model , result , recurse )", "after": "if isinstance ( v , dict ) and set ( [ 'id' , 'type' ] ) . issubset ( set ( v . keys ( ) ) ) : if v [ 'id' ] not in result : model = doc . get_model_by_id ( v [ 'id' ] ) HasProps . _value_record_references ( model , result , recurse )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 72], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"call\", 3, 53, 3, 72], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:issubset\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"call\", 3, 36, 3, 49], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2], [\"Delete\", [\"==:==\", 3, 50, 3, 52]], [\"Delete\", [\"comparison_operator\", 3, 36, 3, 72]]]"}
{"project": "performance", "commit_sha": "aa59ec43489c89dd6c14bdf9c7b28d3362def39e", "parent_sha": "3c849b2c5cb45ef30b9a459b1a885a16ac91fa11", "file_path": "performance/venv.py", "project_url": "https://github.com/willingc/performance", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -198,5 +198,5 @@ def create_virtualenv():\n \n def exec_in_virtualenv(options):\n     venv_python = create_virtualenv()\n-    args = [venv_python] + sys.argv + [\"--inside-venv\"]\n+    args = [venv_python, \"-m\", \"performance\"] + sys.argv[1:] + [\"--inside-venv\"]\n     os.execv(args[0], args)\n", "before": "args = [ venv_python ] + sys . argv + [ \"--inside-venv\" ]", "after": "args = [ venv_python , \"-m\" , \"performance\" ] + sys . argv [ 1 : ] + [ \"--inside-venv\" ]", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 12, 3, 36], [\"subscript\", \"N0\"], 2], [\"Insert\", [\"list\", 3, 12, 3, 25], [\",:,\", \"T\"], 2], [\"Insert\", [\"list\", 3, 12, 3, 25], [\"string:\\\"-m\\\"\", \"T\"], 3], [\"Insert\", [\"list\", 3, 12, 3, 25], [\",:,\", \"T\"], 4], [\"Insert\", [\"list\", 3, 12, 3, 25], [\"string:\\\"performance\\\"\", \"T\"], 5], [\"Move\", \"N0\", [\"attribute\", 3, 28, 3, 36], 0], [\"Insert\", \"N0\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N0\", [\"slice\", \"N1\"], 2], [\"Insert\", \"N0\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N1\", [\"integer:1\", \"T\"], 0], [\"Insert\", \"N1\", [\":::\", \"T\"], 1]]"}
{"project": "DualisWatcher", "commit_sha": "bcfacb45d23074a128cd7328950959eb6b137af5", "parent_sha": "46a4bdaa80807f0d4decd47bb0ac5bc75b45427c", "file_path": "main.py", "project_url": "https://github.com/hollesse/DualisWatcher", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -83,7 +83,7 @@ def run_init():\n     print(\n           '  To set a cron-job for this program on your Unix-System:\\n'\n         + '    `crontab -e`\\n'\n-        + '    add `15 * * * * %s\\main.py`\\n'%(os.path.dirname(os.path.realpath(__file__)))\n+        + '    add `15 * * * * python3 %s/main.py`\\n'%(os.path.dirname(os.path.realpath(__file__)))\n         + '    save and done!'\n     )\n \n", "before": "print ( '  To set a cron-job for this program on your Unix-System:\\n' + '    `crontab -e`\\n' + '    add `15 * * * * %s\\main.py`\\n' % ( os . path . dirname ( os . path . realpath ( __file__ ) ) ) + '    save and done!' )", "after": "print ( '  To set a cron-job for this program on your Unix-System:\\n' + '    `crontab -e`\\n' + '    add `15 * * * * python3 %s/main.py`\\n' % ( os . path . dirname ( os . path . realpath ( __file__ ) ) ) + '    save and done!' )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'    add `15 * * * * %s\\\\main.py`\\\\n'\", 3, 11, 3, 46], \"'    add `15 * * * * python3 %s/main.py`\\\\n'\"]]"}
{"project": "DualisWatcher", "commit_sha": "ec49960d33aad94701ce318a233ab70dd95221eb", "parent_sha": "8d40778872ffb970efd2762ac72cb55404da4726", "file_path": "main.py", "project_url": "https://github.com/hollesse/DualisWatcher", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -83,7 +83,7 @@ def run_init():\n     print(\n           '  To set a cron-job for this program on your Unix-System:\\n'\n         + '    `crontab -e`\\n'\n-        + '    add `15 * * * * python3 %s/main.py`\\n'%(os.path.dirname(os.path.realpath(__file__)))\n+        + '    add `*/15 * * * * cd %s && python3 main.py`\\n'%(os.path.dirname(os.path.realpath(__file__)))\n         + '    save and done!'\n     )\n \n", "before": "print ( '  To set a cron-job for this program on your Unix-System:\\n' + '    `crontab -e`\\n' + '    add `15 * * * * python3 %s/main.py`\\n' % ( os . path . dirname ( os . path . realpath ( __file__ ) ) ) + '    save and done!' )", "after": "print ( '  To set a cron-job for this program on your Unix-System:\\n' + '    `crontab -e`\\n' + '    add `*/15 * * * * cd %s && python3 main.py`\\n' % ( os . path . dirname ( os . path . realpath ( __file__ ) ) ) + '    save and done!' )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'    add `15 * * * * python3 %s/main.py`\\\\n'\", 3, 11, 3, 54], \"'    add `*/15 * * * * cd %s && python3 main.py`\\\\n'\"]]"}
{"project": "bokeh", "commit_sha": "c7fbefcaa1636cb13f6e10b0b315a6edd96f2a16", "parent_sha": "00b5a99ca88e67607328f0b12a3b653aab4fc527", "file_path": "bokeh/resources.py", "project_url": "https://github.com/suqi/bokeh", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -51,7 +51,7 @@ def _get_cdn_urls(version=None, minified=True):\n \n     def mk_url(comp, tp):\n         _comp = '-' + comp if comp else ''\n-        return '%s/%s/bokeh-%s%s.%s' % (base_url, container, _comp, version, _min, tp)\n+        return '%s/%s/bokeh%s-%s%s.%s' % (base_url, container, _comp, version, _min, tp)\n \n     result = {\n         'js_files'  : [ mk_url(comp, 'js')  for comp in ['', 'widgets'] ],\n", "before": "return '%s/%s/bokeh-%s%s.%s' % ( base_url , container , _comp , version , _min , tp )", "after": "return '%s/%s/bokeh%s-%s%s.%s' % ( base_url , container , _comp , version , _min , tp )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'%s/%s/bokeh-%s%s.%s'\", 3, 16, 3, 37], \"'%s/%s/bokeh%s-%s%s.%s'\"]]"}
{"project": "sympy", "commit_sha": "61a19d6b7bd52c5e91bea8ec5674fce1f1ca8a90", "parent_sha": "15681fdd7356c6ea4b032e37cc15286badbe433e", "file_path": "sympy/physics/control/tests/test_lti.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -600,7 +600,7 @@ def test_Feedback_functions():\n     assert tf1 / (tf + tf1*tf2*tf3) == Feedback(tf1, tf2*tf3)\n     assert (tf1*tf2) / (tf + tf1*tf2) == Feedback(tf1*tf2, tf)\n     assert (tf1*tf2) / (tf + tf1*tf2*tf5) == Feedback(tf1*tf2, tf5)\n-    assert (tf1*tf2) / (tf + tf1*tf2*tf3*tf5) == Feedback(tf1*tf2, tf5*tf3)\n+    assert (tf1*tf2) / (tf + tf1*tf2*tf5*tf3) == Feedback(tf1*tf2, tf5*tf3)\n     assert tf4 / (TransferFunction(1, 1, p) + tf4*tf6) == Feedback(tf4, tf6)\n     assert tf5 / (tf + tf5) == Feedback(tf5, tf)\n \n", "before": "assert ( tf1 * tf2 ) / ( tf + tf1 * tf2 * tf3 * tf5 ) == Feedback ( tf1 * tf2 , tf5 * tf3 )", "after": "assert ( tf1 * tf2 ) / ( tf + tf1 * tf2 * tf5 * tf3 ) == Feedback ( tf1 * tf2 , tf5 * tf3 )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"identifier:tf5\", 3, 42, 3, 45], \"tf3\"], [\"Update\", [\"identifier:tf3\", 3, 38, 3, 41], \"tf5\"]]"}
{"project": "Stock-Data", "commit_sha": "7e35599beb32e7fcf61f650ee668a6e2457ff997", "parent_sha": "cec8813439b27d58f1580ab2ccadb8be2c6749f2", "file_path": "data.py", "project_url": "https://github.com/twigtheoracle/Stock-Data", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -36,7 +36,7 @@ class Data():\n \n     # gets a string that will allow me to query Alpha Vantage for data needed\n     def get_AV_query_string(self, stock):\n-        return_string = \"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=MSFT&outputsize=full&apikey=\" + key.get_AV_API_key()\n+        return_string = \"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=\" + stock + \"&outputsize=full&apikey=\" + key.get_AV_API_key()\n \n     # gets data from quandl and stores it in the object\n     def retrieve_data(self):\n", "before": "return_string = \"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=MSFT&outputsize=full&apikey=\" + key . get_AV_API_key ( )", "after": "return_string = \"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=\" + stock + \"&outputsize=full&apikey=\" + key . get_AV_API_key ( )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 25, 3, 146], [\"binary_operator\", \"N0\"], 0], [\"Insert\", [\"binary_operator\", 3, 25, 3, 146], [\"+:+\", \"T\"], 1], [\"Insert\", \"N0\", [\"binary_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"+:+\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:\\\"&outputsize=full&apikey=\\\"\", \"T\"], 2], [\"Update\", [\"string:\\\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=MSFT&outputsize=full&apikey=\\\"\", 3, 25, 3, 123], \"\\\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=\\\"\"], [\"Move\", \"N1\", [\"string:\\\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=MSFT&outputsize=full&apikey=\\\"\", 3, 25, 3, 123], 0], [\"Move\", \"N1\", [\"+:+\", 3, 124, 3, 125], 1], [\"Insert\", \"N1\", [\"identifier:stock\", \"T\"], 2]]"}
{"project": "ykdl", "commit_sha": "9854825ee769cb03c5dc0362630fca825ed57f36", "parent_sha": "da66e127b8afddbf5cbe0978a9bf39884f2c29bc", "file_path": "src/you_get/downloader/youtube.py", "project_url": "https://github.com/YU-zreo/ykdl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -95,7 +95,7 @@ def decrypt_signature(s):\n     elif len(s) == 82:\n         return s[36] + s[79:67:-1] + s[81] + s[66:40:-1] + s[33] + s[39:36:-1] + s[40] + s[35] + s[0] + s[67] + s[32:0:-1] + s[34]\n     else:\n-        raise Exception(u'Unable to decrypt signature, key length %d not supported; retrying might work' % (len(s)))\n+        raise Exception('Unable to decrypt signature, key length %d not supported; retrying might work' % (len(s)))\n \n def youtube_download_by_id(id, title = None, output_dir = '.', merge = True, info_only = False):\n     \n", "before": "else : raise Exception ( u'Unable to decrypt signature, key length %d not supported; retrying might work' % ( len ( s ) ) )", "after": "else : raise Exception ( 'Unable to decrypt signature, key length %d not supported; retrying might work' % ( len ( s ) ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:u'Unable to decrypt signature, key length %d not supported; retrying might work'\", 3, 25, 3, 105], \"'Unable to decrypt signature, key length %d not supported; retrying might work'\"]]"}
{"project": "ykdl", "commit_sha": "1b75cfcc473116d787e4f0908e58a020b90d8768", "parent_sha": "bfc85f8a49ee1eec0cf743664c3741d3303a7632", "file_path": "src/you_get/extractor/sina.py", "project_url": "https://github.com/YU-zreo/ykdl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -5,7 +5,7 @@ __all__ = ['sina_download', 'sina_download_by_vid', 'sina_download_by_vkey']\n from ..common import *\n \n def video_info(id):\n-    xml = get_content('http://v.iask.com/v_play.php?vid=%s' % id, decoded=True)\n+    xml = get_content('http://www.tucao.cc/api/sina.php?vid=%s' % id, decoded=True)\n     urls = re.findall(r'<url>(?:<!\\[CDATA\\[)?(.*?)(?:\\]\\]>)?</url>', xml)\n     name = match1(xml, r'<vname>(?:<!\\[CDATA\\[)?(.+?)(?:\\]\\]>)?</vname>')\n     vstr = match1(xml, r'<vstr>(?:<!\\[CDATA\\[)?(.+?)(?:\\]\\]>)?</vstr>')\n", "before": "xml = get_content ( 'http://v.iask.com/v_play.php?vid=%s' % id , decoded = True )", "after": "xml = get_content ( 'http://www.tucao.cc/api/sina.php?vid=%s' % id , decoded = True )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'http://v.iask.com/v_play.php?vid=%s'\", 3, 23, 3, 60], \"'http://www.tucao.cc/api/sina.php?vid=%s'\"]]"}
{"project": "ykdl", "commit_sha": "86c29abf6ee11996565bd4de710d56c254722a40", "parent_sha": "a498ebe2bfa3788d22ffb7547e50b05f4dd89b56", "file_path": "src/you_get/common.py", "project_url": "https://github.com/YU-zreo/ykdl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -715,7 +715,7 @@ def print_info(site_info, title, type, size):\n     print(\"Video Site:\", site_info)\n     print(\"Title:     \", tr(title))\n     print(\"Type:      \", type_info)\n-    print(\"Size:      \", round(size / 1048576, 2), \"MB (\" + str(size) + \" Bytes)\")\n+    print(\"Size:      \", round(size / 1048576, 2), \"MiB (\" + str(size) + \" Bytes)\")\n     print()\n \n def parse_host(host):\n", "before": "print ( \"Size:      \" , round ( size / 1048576 , 2 ) , \"MB (\" + str ( size ) + \" Bytes)\" )", "after": "print ( \"Size:      \" , round ( size / 1048576 , 2 ) , \"MiB (\" + str ( size ) + \" Bytes)\" )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"MB (\\\"\", 3, 52, 3, 58], \"\\\"MiB (\\\"\"]]"}
{"project": "sympy", "commit_sha": "ecd9b3e292ffb67fd76e08eb3284a04647fbeecf", "parent_sha": "4a4bf9b417f37a32455f3512b4f857169fd015ec", "file_path": "sympy/ntheory/factor_.py", "project_url": "https://github.com/fatData/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -55,7 +55,7 @@ def smoothness_p(n, m=-1, power=0, visual=None):\n \n     1. p**M is the base-p divisor of n\n     2. sm(p + m) is the smoothness of p + m (m = -1 by default)\n-    3. psm(p + n) is the power smoothness of p + m\n+    3. psm(p + m) is the power smoothness of p + m\n \n     The list is sorted according to smoothness (default) or by power smoothness\n     if power=1.\n", "before": "3. psm ( p + n ) is the power smoothness of p + m", "after": "3. psm ( p + m ) is the power smoothness of p + m", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"identifier:n\", 3, 16, 3, 17], \"m\"]]"}
{"project": "InstaPy", "commit_sha": "e4a7fb867c2417af9c9d55d8fc1a2c1a751fabb6", "parent_sha": "73d2f4c7e9eca2b6538fa51bfe7a24c58147b71e", "file_path": "instapy/instapy.py", "project_url": "https://github.com/anyulled/InstaPy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -468,7 +468,7 @@ class InstaPy:\n         if self.aborting:\n             return self\n \n-        self.dont_include = set(friends) or {}\n+        self.dont_include = set(friends) or set()\n \n         return self\n \n", "before": "self . dont_include = set ( friends ) or { }", "after": "self . dont_include = set ( friends ) or set ( )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 29, 3, 47], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:set\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1], [\"Delete\", [\"{:{\", 3, 45, 3, 46]], [\"Delete\", [\"}:}\", 3, 46, 3, 47]], [\"Delete\", [\"dictionary\", 3, 45, 3, 47]]]"}
{"project": "flutterfuck", "commit_sha": "0d99844dd048303204881aca9626bbcd0e1854fe", "parent_sha": "3a1f9b8894e1921c6ce42236149393056f5b1a86", "file_path": "sopel/modules/safety.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -156,7 +156,7 @@ def url_handler(bot, trigger):\n     if positives > 1:\n         # Possibly malicious URL detected!\n         confidence = '{}%'.format(round((positives / total) * 100))\n-        msg = 'link posted by %s is possibliy malicious ' % bold(trigger.nick)\n+        msg = 'link posted by %s is possibly malicious ' % bold(trigger.nick)\n         msg += '(confidence %s - %s/%s)' % (confidence, positives, total)\n         bot.say('[' + bold(color('WARNING', 'red')) + '] ' + msg)\n         if strict:\n", "before": "msg = 'link posted by %s is possibliy malicious ' % bold ( trigger . nick )", "after": "msg = 'link posted by %s is possibly malicious ' % bold ( trigger . nick )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'link posted by %s is possibliy malicious '\", 3, 15, 3, 58], \"'link posted by %s is possibly malicious '\"]]"}
{"project": "flutterfuck", "commit_sha": "359e42abbf5e6668797dde28a52a01ffe5c2b0f3", "parent_sha": "603cdcb15dbe2c64972a0dd7374fd5e4efac6b13", "file_path": "willie/modules/github.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -112,7 +112,7 @@ def add_traceback(bot, trigger):\n     try:\n         raw = web.post('https://api.github.com/repos/' + gitAPI[1] + '/issues/'\n                        + number + '/comments?access_token=' + gitAPI[0],\n-                       json.dumps({'body': '``\\n' + post + '\\n``'}))\n+                       json.dumps({'body': '``\\n' + post + '``'}))\n     except OSError:#HTTPError:\n         return bot.say('The GitHub API returned an error.')\n \n", "before": "raw = web . post ( 'https://api.github.com/repos/' + gitAPI [ 1 ] + '/issues/' + number + '/comments?access_token=' + gitAPI [ 0 ] , json . dumps ( { 'body' : '``\\n' + post + '\\n``' } ) )", "after": "raw = web . post ( 'https://api.github.com/repos/' + gitAPI [ 1 ] + '/issues/' + number + '/comments?access_token=' + gitAPI [ 0 ] , json . dumps ( { 'body' : '``\\n' + post + '``' } ) )", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:'\\\\n``'\", 3, 60, 3, 66], \"'``'\"]]"}
{"project": "Change-By-Us", "commit_sha": "a5365bca8b651083ff27191527c3abcddd94f316", "parent_sha": "ff8482098ceabeced670ebcb108acd1ec4853968", "file_path": "giveaminute/migrations/versions/011_change_default_charset_and_collation_to_utf8.py", "project_url": "https://github.com/cfa-nm/Change-By-Us", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ def upgrade(migrate_engine):\n     tbls = meta.tables.keys()\n     \n     for item in tbls:\n-        sql_update_table = \"alter table `%s` DEFAULT CHARACTER SET 'utf8' DEFAULT COLLATE 'utf8_general_ci'\" % item\n+        sql_update_table = \"alter table `%s` CHARACTER SET 'utf8' COLLATE 'utf8_general_ci'\" % item\n         migrate_engine.execute(sql_update_table)\n     \n     \n", "before": "sql_update_table = \"alter table `%s` DEFAULT CHARACTER SET 'utf8' DEFAULT COLLATE 'utf8_general_ci'\" % item", "after": "sql_update_table = \"alter table `%s` CHARACTER SET 'utf8' COLLATE 'utf8_general_ci'\" % item", "sstub_pattern": "CHANGE_BINARY_OPERAND", "edit_script": "[[\"Update\", [\"string:\\\"alter table `%s` DEFAULT CHARACTER SET 'utf8' DEFAULT COLLATE 'utf8_general_ci'\\\"\", 3, 28, 3, 109], \"\\\"alter table `%s` CHARACTER SET 'utf8' COLLATE 'utf8_general_ci'\\\"\"]]"}
{"project": "motor", "commit_sha": "14d8c85baaa5fee2a68642666c52b40acadaa468", "parent_sha": "79a2e50115773528934dd0f45cd71adf61d646ec", "file_path": "test/test_test.py", "project_url": "https://github.com/vokal/motor", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ class MotorTestTest(unittest.TestCase):\n         done()\n \n     def test_timeout(self):\n-        self.pause_delta = datetime.timedelta(seconds=10)\n+        self.pause_delta = datetime.timedelta(seconds=30)\n         self.assertRaises(Exception, self.pause)\n \n     def test_no_timeout(self):\n", "before": "self . pause_delta = datetime . timedelta ( seconds = 10 )", "after": "self . pause_delta = datetime . timedelta ( seconds = 30 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:10\", 3, 55, 3, 57], \"30\"]]"}
{"project": "TracBlockdiag", "commit_sha": "61c0f6bb3a2961ec8c85b46c371ac6e82a437a81", "parent_sha": "e20e0f5705b52869e9565b59ceea2a43fcd11565", "file_path": "tracblockdiag/cache.py", "project_url": "https://github.com/arielnetworks/TracBlockdiag", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -17,7 +17,7 @@ def compute_key(function, args, kwargs):\n     return hashlib.sha1(key).hexdigest()\n \n \n-def memoize(duration=30):\n+def memoize(duration=300):\n     def _memoize(function):\n         def __memoize(*args, **kwargs):\n             gc()\n", "before": "def memoize ( duration = 30 ) : def _memoize ( function ) : def __memoize ( * args , ** kwargs ) : gc ( )", "after": "def memoize ( duration = 300 ) : def _memoize ( function ) : def __memoize ( * args , ** kwargs ) : gc ( )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:30\", 3, 22, 3, 24], \"300\"]]"}
{"project": "mypy", "commit_sha": "bac66529a78b89b8f97c2302f8d27358688459ee", "parent_sha": "38ea43eaea076becc0f735ef97b1bb09fb46a02c", "file_path": "network/random.py", "project_url": "https://github.com/atiasnir/mypy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -115,7 +115,7 @@ def shuffle(network, directed=False, max_iterations=None, seed=0):\n         network = csr_matrix(network)\n \n     if max_iterations is None:\n-        max_iterations = 10 * network.nnz\n+        max_iterations = 100 * network.nnz\n \n     return _shuffle_edges(network, directed, max_iterations, seed)\n \n", "before": "max_iterations = 10 * network . nnz", "after": "max_iterations = 100 * network . nnz", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:10\", 3, 26, 3, 28], \"100\"]]"}
{"project": "librosa", "commit_sha": "7089a62811d374020396aed0d68985cc55ab0707", "parent_sha": "12805b663a7d647b746fef0feca43429af56dd35", "file_path": "librosa/decompose.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -66,7 +66,7 @@ def decompose(S, n_components=None, transformer=None):\n \n     return (transformer.components_.T, activations.T)\n \n-def hpss(S, kernel_size=31, power=1.0, mask=False):\n+def hpss(S, kernel_size=31, power=2.0, mask=False):\n", "before": "def hpss ( S , kernel_size = 31 , power = 1.0 , mask = False ) : ", "after": "def hpss ( S , kernel_size = 31 , power = 2.0 , mask = False ) : ", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:1.0\", 3, 35, 3, 38], \"2.0\"]]"}
{"project": "blink-qt", "commit_sha": "3b61f15904ca8e8754052f46ddeb8d45b4953420", "parent_sha": "701e260b847d5ba6e9ba8f8309b2692010cb25f6", "file_path": "blink/widgets/graph.py", "project_url": "https://github.com/kogmbh/blink-qt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -106,7 +106,7 @@ class GraphWidget(QWidget, ColorHelperMixin):\n         self.boundary = None\n         self.boundaryColor = None\n         self.smoothEnvelope = True\n-        self.smoothFactor = 0.1\n+        self.smoothFactor = 0.15\n         self.fillEnvelope = True\n         self.fillTransparency = 50\n         self.scaler = SoftScaler()\n", "before": "self . smoothFactor = 0.1", "after": "self . smoothFactor = 0.15", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:0.1\", 3, 29, 3, 32], \"0.15\"]]"}
{"project": "blink-qt", "commit_sha": "c142792534748b666d415f5242da7f4b46240433", "parent_sha": "3b61f15904ca8e8754052f46ddeb8d45b4953420", "file_path": "blink/widgets/graph.py", "project_url": "https://github.com/kogmbh/blink-qt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -108,7 +108,7 @@ class GraphWidget(QWidget, ColorHelperMixin):\n         self.smoothEnvelope = True\n         self.smoothFactor = 0.15\n         self.fillEnvelope = True\n-        self.fillTransparency = 50\n+        self.fillTransparency = 40\n         self.scaler = SoftScaler()\n         self.graphs = []\n         self.__dict__['graph_width'] = 0\n", "before": "self . fillTransparency = 50", "after": "self . fillTransparency = 40", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:50\", 3, 33, 3, 35], \"40\"]]"}
{"project": "CloudBot", "commit_sha": "0c6ad95d28464aa1597cc89286a3ac0c4cdca2fb", "parent_sha": "2b2f434a39076e3aa786ce8fc94a6f97d2ae6bf9", "file_path": "cloudbot/util/colors.py", "project_url": "https://github.com/MrW24/CloudBot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ def get_color(colour, return_formatted=True):\n         raise KeyError(\"The colour '{}' is not in the list of available colours.\".format(colour))\n \n     if colour == \"random\":  # Special keyword for a random colour\n-        rand = randint(0, 16)\n+        rand = randint(0, 15)\n         if rand < 10:  # Prepend '0' before colour so it always is double digits.\n             rand = \"0\" + str(rand)\n         rand = str(rand)\n", "before": "rand = randint ( 0 , 16 )", "after": "rand = randint ( 0 , 15 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:16\", 3, 27, 3, 29], \"15\"]]"}
{"project": "reportlab", "commit_sha": "1daba0d942b5b2c3ffb790518206bbf78d9116e9", "parent_sha": "f53a17f8c7853f1edcc5982c84181768722388c4", "file_path": "tests/test_platypus_paragraphs.py", "project_url": "https://github.com/eduardocereto/reportlab", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -102,7 +102,7 @@ class ParagraphCorners(unittest.TestCase):\n         aW,aH=439.275590551,121.88976378\n         w,h=p.wrap(aW,aH)\n         S=p.split(aW,aH)\n-        assert len(S)==3, 'Multi frag CJK splitting failed'\n+        assert len(S)==2, 'Multi frag CJK splitting failed'\n         w0,h0=S[0].wrap(aW,aH)\n         assert h0<=aH,'Multi-frag CJK split[0] has wrong height %s >= available %s' % (H0,aH)\n         w1,h1=S[1].wrap(aW,aH)\n", "before": "assert len ( S ) == 3 , 'Multi frag CJK splitting failed'", "after": "assert len ( S ) == 2 , 'Multi frag CJK splitting failed'", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:3\", 3, 24, 3, 25], \"2\"]]"}
{"project": "qal", "commit_sha": "84dcd30576e88b3af18decb054176f260927cd5b", "parent_sha": "3e3701eedb216662fe613cd447e40eaee3b7ddc9", "file_path": "qal/common/listhelper.py", "project_url": "https://github.com/OptimalBPM/qal", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -46,7 +46,7 @@ def pretty_list(_array):\n     \n     _result = \"\"\n     if len(_array) > 0:\n-        for _row_idx in range(len(_array) - 2) :\n+        for _row_idx in range(len(_array) - 1) :\n             _result+= _handle_types(_array[_row_idx]) + \",\\n\"\n \n         _result+= _handle_types(_array[_row_idx + 1]) + \"\\n\"\n", "before": "for _row_idx in range ( len ( _array ) - 2 ) : _result += _handle_types ( _array [ _row_idx ] ) + \",\\n\"", "after": "for _row_idx in range ( len ( _array ) - 1 ) : _result += _handle_types ( _array [ _row_idx ] ) + \",\\n\"", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 45, 3, 46], \"1\"]]"}
{"project": "urbanbus-rest", "commit_sha": "52a357245088b37641977f3d1df582ee295a5cb7", "parent_sha": "d571b9d2521338c717d29bf7b7a65b1cf77d6eae", "file_path": "database/database_access.py", "project_url": "https://github.com/LoveXanome/urbanbus-rest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -226,7 +226,7 @@ def get_average_speed(agency_id, stop_id, route_id):\n \t\t\tindiceMoins = -1\n \t\tif indiceStop < len(results)-2:\n \t\t\tindicePlus = 2\n-\t\telif indiceStop == len(results)-1:\n+\t\telif indiceStop == len(results)-2:\n \t\t\tindicePlus = 1\n \t\telse:\n \t\t\tindicePlus = 0\n", "before": "if indiceStop < len ( results ) - 2 : indicePlus = 2 elif indiceStop == len ( results ) - 1 : indicePlus = 1 else : indicePlus = 0", "after": "if indiceStop < len ( results ) - 2 : indicePlus = 2 elif indiceStop == len ( results ) - 2 : indicePlus = 1 else : indicePlus = 0", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1\", 3, 35, 3, 36], \"2\"]]"}
{"project": "DARTpy", "commit_sha": "18dd7f3c7cdf8d93dc76020697565d02441deeb3", "parent_sha": "083771958e35356e1452486465e71aedca4219a3", "file_path": "experiment_settings.py", "project_url": "https://github.com/LisaNeef/DARTpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -397,7 +397,7 @@ def get_expt_CopyMetaData_state_space(E):\n \t\treturn None\n \n \n-def exp_paths_era(datetime_in,hostname='taurus',resolution=1.5,diagnostic=None,variable='U',level_type='pressure_levels'):\n+def exp_paths_era(datetime_in,hostname='taurus',resolution=0.75,diagnostic=None,variable='U',level_type='pressure_levels'):\n \n", "before": "def exp_paths_era ( datetime_in , hostname = 'taurus' , resolution = 1.5 , diagnostic = None , variable = 'U' , level_type = 'pressure_levels' ) : ", "after": "def exp_paths_era ( datetime_in , hostname = 'taurus' , resolution = 0.75 , diagnostic = None , variable = 'U' , level_type = 'pressure_levels' ) : ", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:1.5\", 3, 60, 3, 63], \"0.75\"]]"}
{"project": "tribler", "commit_sha": "53176519ff11f83d129720a0fd50c3fc7a87748b", "parent_sha": "00770c7a000b2b840fa9549fe761e8febd4135d3", "file_path": "Tribler/Utilities/TimedTaskQueue.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ class TimedTaskQueue:\n             self.callstack[self.count] = format_stack()\n             \n         if id != None:  # remove all redundant tasks\n-            self.queue = filter(lambda item:item[2]!=id, self.queue)\n+            self.queue = filter(lambda item:item[3]!=id, self.queue)\n         self.queue.append((when,self.count,task,id))\n         self.count += 1.0\n         self.cond.notify()\n", "before": "self . queue = filter ( lambda item : item [ 2 ] != id , self . queue )", "after": "self . queue = filter ( lambda item : item [ 3 ] != id , self . queue )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 50, 3, 51], \"3\"]]"}
{"project": "tribler", "commit_sha": "bb059ddcb5a13f34b2b2f653ff1c9127de85c750", "parent_sha": "a534781bac6096de25fa36521c081bb80b70abbc", "file_path": "Tribler/Community/barter/community.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -75,7 +75,7 @@ class BarterCommunity(Community):\n \n     @property\n     def dispersy_sync_response_limit(self):\n-       return 32 * 1024\n+       return 5 * 1024\n \n     @property\n     def barter_forward_record_on_creation(self):\n", "before": "return 32 * 1024", "after": "return 5 * 1024", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:32\", 3, 15, 3, 17], \"5\"]]"}
{"project": "tribler", "commit_sha": "3a893c9a195e03ce68aa3326a8652a82c4e81264", "parent_sha": "95c500ceb451333ec4b20a420176b4ef160d2795", "file_path": "Tribler/Core/dispersy/community.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -526,7 +526,7 @@ class Community(object):\n-        return (1500 - 60 - 8 - 51 - self._my_member.signature_length - 14) // 6\n+        return (1500 - 60 - 8 - 51 - self._my_member.signature_length - 14) // 8\n \n     @property\n     def dispersy_sync_initial_delay(self):\n", "before": "return ( 1500 - 60 - 8 - 51 - self . _my_member . signature_length - 14 ) // 6", "after": "return ( 1500 - 60 - 8 - 51 - self . _my_member . signature_length - 14 ) // 8", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:6\", 0, 80, 0, 81], \"8\"]]"}
{"project": "tribler", "commit_sha": "f1669cdb14b7ac5fbd299a8b7d3f69dc1c3ebe89", "parent_sha": "bb55769caebc350350463fbb2598e2b26fffa05c", "file_path": "Tribler/Main/vwxGUI/list.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2214,7 +2214,7 @@ class ActivitiesList(List):\n         self.ResizeListItems()\n         self.DisableItem(2)\n         if not self.guiutility.frame.videoparentpanel:\n-            self.DisableItem(6)\n+            self.DisableItem(5)\n         self.DisableCollapse()\n         self.selectTab('home')\n \n", "before": "self . DisableItem ( 6 )", "after": "self . DisableItem ( 5 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:6\", 3, 30, 3, 31], \"5\"]]"}
{"project": "python-ivi", "commit_sha": "a9266c13b87d6a8d9510cfa0db2e44b5e531e4a2", "parent_sha": "22db683a6a2c1beb7f50ccfe08791fad84287e65", "file_path": "ivi/dicon/diconGP700.py", "project_url": "https://github.com/ianrrees/python-ivi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -540,7 +540,7 @@ class diconGP700(ivi.Driver):\n                     self._switch_input[index] = input\n                     self._set_cache_valid(True, 'switch_input', index)\n         elif name[0] == 'P' or name[0] == 'S':\n-            if output < 0 or output > self._switch_output_count[index]:\n+            if output < 1 or output > self._switch_output_count[index]:\n                 raise ivi.OutOfRangeException()\n             if input is not None and input != 1:\n                 raise ivi.OutOfRangeException()\n", "before": "if output < 0 or output > self . _switch_output_count [ index ] : raise ivi . OutOfRangeException ( )", "after": "if output < 1 or output > self . _switch_output_count [ index ] : raise ivi . OutOfRangeException ( )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0\", 3, 25, 3, 26], \"1\"]]"}
{"project": "naith", "commit_sha": "8dca3b9e06007de7bea0cdaea701a59b4321a5ff", "parent_sha": "b1e4f494ca145c979e7fb2e862642427b583f572", "file_path": "game/plugins/Loading/Loading.py", "project_url": "https://github.com/Panda3D-google-code-repositories/naith", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ class Loading:\n     self.node = loader.loadModel('data/weapons/assault/assault') ###########################\n     self.node.reparentTo(aspect2d)\n     self.node.setHpr(90.0,0.0,0.0)\n-    self.waitBar = DirectWaitBar(parent = render2d, text = \"\", value = 0, pos = (0, 0, -0.5), scale = (1, 1, 0.1), frameColor = (0, 0, 0, 1), barColor = (.8, .8, .8, 1))\n+    self.waitBar = DirectWaitBar(parent = render2d, text = \"\", value = 0, pos = (0, 0, -0.5), scale = (1, 1, 0.1), frameColor = (0, 0, 0, 0), barColor = (.8, .8, .8, 1))\n     LerpFunctionInterval(self.__setProgress, 2.5, 0.0, 100.0).start()\n \n   def __setProgress(self, progress):\n", "before": "self . waitBar = DirectWaitBar ( parent = render2d , text = \"\" , value = 0 , pos = ( 0 , 0 , - 0.5 ) , scale = ( 1 , 1 , 0.1 ) , frameColor = ( 0 , 0 , 0 , 1 ) , barColor = ( .8 , .8 , .8 , 1 ) )", "after": "self . waitBar = DirectWaitBar ( parent = render2d , text = \"\" , value = 0 , pos = ( 0 , 0 , - 0.5 ) , scale = ( 1 , 1 , 0.1 ) , frameColor = ( 0 , 0 , 0 , 0 ) , barColor = ( .8 , .8 , .8 , 1 ) )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1\", 3, 139, 3, 140], \"0\"]]"}
{"project": "MacDaily", "commit_sha": "58ee35f88fe7faecb30c5e0d2c998f4dd0853adc", "parent_sha": "9cadc3a87fbb97be5abbd49720c6329af332c948", "file_path": "src/util/tools/misc.py", "project_url": "https://github.com/JarryShaw/MacDaily", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,7 +34,7 @@ def kill(pid, signal):\n         except OSError as error:\n             message = ('failed to send signal to process %d '\n                        'with error message: %s') % (chld, error)\n-            warnings.showwarning(message, ResourceWarning, __file__, 34)\n+            warnings.showwarning(message, ResourceWarning, __file__, 33)\n \n \n def record(file, args, today, config=None, redirect=False):\n", "before": "warnings . showwarning ( message , ResourceWarning , __file__ , 34 )", "after": "warnings . showwarning ( message , ResourceWarning , __file__ , 33 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:34\", 3, 70, 3, 72], \"33\"]]"}
{"project": "cc-utils", "commit_sha": "41f11ed9ab64ce59af71b7dd3d0958989662855a", "parent_sha": "e70c7f6309ae25d8e10a586f5137ff8dd1544c8a", "file_path": "protecode/util.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ def upload_images(\n     protecode_cfg,\n     product_descriptor,\n     protecode_group_id=5,\n-    parallel_jobs=4,\n+    parallel_jobs=8,\n     cve_threshold=7,\n ):\n     executor = ThreadPoolExecutor(max_workers=parallel_jobs)\n", "before": "parallel_jobs = 4 ,", "after": "parallel_jobs = 8 ,", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:4\", 3, 19, 3, 20], \"8\"]]"}
{"project": "HydrantFC", "commit_sha": "61b9aa7e7fbce1d8e0301c4d96df56bce0161557", "parent_sha": "e0b5228aa5a5f298ca12e090900600c421798a80", "file_path": "hydrant/validate.py", "project_url": "https://github.com/broadinstitute/HydrantFC", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -50,7 +50,7 @@ def validate(wdl=None, inputs_json='tests/inputs.json'):\n                                 old_value.find('[') < 1:\n                                 old_data[old_datum[0].strip()] = clean_line\n             \n-            no_comma = len(input_data) - 2\n+            no_comma = len(input_data) - 1\n             for idx, datum in enumerate(input_data, 1):\n                 if idx > 1 and idx < no_comma:\n                     datum_key = datum.split(': ')[0].strip()\n", "before": "no_comma = len ( input_data ) - 2", "after": "no_comma = len ( input_data ) - 1", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 42, 3, 43], \"1\"]]"}
{"project": "brainzutils-python", "commit_sha": "baa5b0e15b0388afa44464dd7fbfe56b8ceb2888", "parent_sha": "9ac82bfa0c0478e8623fcdabe0248b5960d020fa", "file_path": "brainzutils/test/test_locks.py", "project_url": "https://github.com/metabrainz/brainzutils-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -81,7 +81,7 @@ class LockedOpenTestCase(unittest.TestCase):\n \n             p_other.join(1)\n             p_blocker.terminate()\n-            time.sleep(0.1)\n+            time.sleep(.3)\n \n             self.assertFalse(p_other.is_alive())\n             self.assertEqual(p_other.exitcode, 0)\n", "before": "time . sleep ( 0.1 )", "after": "time . sleep ( .3 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:0.1\", 3, 24, 3, 27], \".3\"]]"}
{"project": "mask-rcnn.pytorch", "commit_sha": "21455473f39ccb607c25789614371313036a4aef", "parent_sha": "85a7b2ebe3a0ddfd1b2d7366ace625cabcf3d1da", "file_path": "trainval_net.py", "project_url": "https://github.com/wkentaro/mask-rcnn.pytorch", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -83,7 +83,7 @@ def parse_args():\n                       default=\"sgd\", type=str)\n   parser.add_argument('--lr', dest='lr',\n                       help='starting learning rate',\n-                      default=0.01, type=float)\n+                      default=0.001, type=float)\n   parser.add_argument('--lr_decay_step', dest='lr_decay_step',\n                       help='step to do learning rate decay, unit is epoch',\n                       default=5, type=int)\n", "before": "parser . add_argument ( '--lr' , dest = 'lr' , help = 'starting learning rate' , default = 0.01 , type = float )", "after": "parser . add_argument ( '--lr' , dest = 'lr' , help = 'starting learning rate' , default = 0.001 , type = float )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:0.01\", 3, 31, 3, 35], \"0.001\"]]"}
{"project": "mask-rcnn.pytorch", "commit_sha": "172f2307751d20aba46ce37a2d1bdfc253dc6540", "parent_sha": "277551b150fae4e8af59a8d231c8e87138cd5e6c", "file_path": "lib/model/rpn/proposal_target_layer_cascade_pose_mask.py", "project_url": "https://github.com/wkentaro/mask-rcnn.pytorch", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -240,7 +240,7 @@ class _ProposalTargetLayer(nn.Module):\n \n         # round pose to integer position\n         gt_poses_keep = gt_poses_keep.round().type(torch.IntTensor)\n-        gt_poses_batch = gt_poses_keep[:, :, :, 1] * cfg.KRCNN.HEATMAP_SIZE + gt_poses_keep[:, :, :, 2]\n+        gt_poses_batch = gt_poses_keep[:, :, :, 1] * cfg.KRCNN.HEATMAP_SIZE + gt_poses_keep[:, :, :, 0]\n \n         # Calculate pose weights\n         poses_weights = torch.stack([masks_weights] * cfg.KRCNN.NUM_KEYPOINTS, dim=2)\n", "before": "gt_poses_batch = gt_poses_keep [ : , : , : , 1 ] * cfg . KRCNN . HEATMAP_SIZE + gt_poses_keep [ : , : , : , 2 ]", "after": "gt_poses_batch = gt_poses_keep [ : , : , : , 1 ] * cfg . KRCNN . HEATMAP_SIZE + gt_poses_keep [ : , : , : , 0 ]", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 102, 3, 103], \"0\"]]"}
{"project": "DeepDIVA", "commit_sha": "a422891697c3223e370ac8ffd98630b007c95038", "parent_sha": "0b43d4a89e962441ee153d07338ad421dc85056e", "file_path": "template/CL_arguments.py", "project_url": "https://github.com/DIVA-DIA/DeepDIVA", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -123,7 +123,7 @@ def parse_arguments():\n                                help='random seed')\n     parser_system.add_argument('--log-interval',\n                                type=int,\n-                               default=10,\n+                               default=20,\n                                help='print loss/accuracy every N batches')\n     parser_system.add_argument('-j', '--workers',\n                                type=int,\n", "before": "help = 'random seed' ) parser_system . add_argument ( '--log-interval' , type = int , default = 10 , help = 'print loss/accuracy every N batches' )", "after": "help = 'random seed' ) parser_system . add_argument ( '--log-interval' , type = int , default = 20 , help = 'print loss/accuracy every N batches' )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:10\", 3, 40, 3, 42], \"20\"]]"}
{"project": "rdpy", "commit_sha": "82d77982557ab453a36434b0b754e4d799968bb9", "parent_sha": "e9db7d720f6ee3c9b87d3a1228b3deda0dd1f11c", "file_path": "rdpy/protocol/rdp/gcc.py", "project_url": "https://github.com/preempt/rdpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -608,6 +608,6 @@ def writeConferenceCreateResponse(serverData):\n     \n     return (per.writeChoice(0), per.writeObjectIdentifier(t124_02_98_oid),\n             per.writeLength(len(serverDataStream.getvalue()) + 14), per.writeChoice(0x14),\n-            per.writeInteger16(0x79F3, 1001), per.writeInteger(1), per.writeEnumerates(16),\n+            per.writeInteger16(0x79F3, 1001), per.writeInteger(1), per.writeEnumerates(0),\n             per.writeNumberOfSet(1), per.writeChoice(0xc0),\n             per.writeOctetStream(h221_sc_key, 4), per.writeOctetStream(serverDataStream.getvalue()))\n\\ No newline at end of file\n", "before": "return ( per . writeChoice ( 0 ) , per . writeObjectIdentifier ( t124_02_98_oid ) , per . writeLength ( len ( serverDataStream . getvalue ( ) ) + 14 ) , per . writeChoice ( 0x14 ) , per . writeInteger16 ( 0x79F3 , 1001 ) , per . writeInteger ( 1 ) , per . writeEnumerates ( 16 ) , per . writeNumberOfSet ( 1 ) , per . writeChoice ( 0xc0 ) , per . writeOctetStream ( h221_sc_key , 4 ) , per . writeOctetStream ( serverDataStream . getvalue ( ) ) )   No newline at end of file", "after": "return ( per . writeChoice ( 0 ) , per . writeObjectIdentifier ( t124_02_98_oid ) , per . writeLength ( len ( serverDataStream . getvalue ( ) ) + 14 ) , per . writeChoice ( 0x14 ) , per . writeInteger16 ( 0x79F3 , 1001 ) , per . writeInteger ( 1 ) , per . writeEnumerates ( 0 ) , per . writeNumberOfSet ( 1 ) , per . writeChoice ( 0xc0 ) , per . writeOctetStream ( h221_sc_key , 4 ) , per . writeOctetStream ( serverDataStream . getvalue ( ) ) )   No newline at end of file", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:16\", 3, 88, 3, 90], \"0\"]]"}
{"project": "pyMaid", "commit_sha": "46fbfbd4a937fac8a8a4eccdcda2930f91ff4ef4", "parent_sha": "f8f2499c39cd94798f49886a40d7e8375e91fcbc", "file_path": "pymaid/fetch.py", "project_url": "https://github.com/schlegelp/pyMaid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -4923,7 +4923,7 @@ def get_label_list(remote_instance=None):\n     return pd.DataFrame(labels, columns=['label_id', 'tag', 'skeleton_id', 'treenode_id'])\r\n \r\n \r\n-def get_transactions(range_start=None, range_length=2500, remote_instance=None):\r\n+def get_transactions(range_start=None, range_length=25, remote_instance=None):\r\n", "before": "def get_transactions ( range_start = None , range_length = 2500 , remote_instance = None ) : ", "after": "def get_transactions ( range_start = None , range_length = 25 , remote_instance = None ) : ", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2500\", 3, 53, 3, 57], \"25\"]]"}
{"project": "warcprox", "commit_sha": "e79cdb84cbf957816dfa4245bffca6e2b13cd9f5", "parent_sha": "5d09aea67d8f46221e5ee866ea1d1909ccb0715e", "file_path": "warcprox/warcprox.py", "project_url": "https://github.com/edgi-govdata-archiving/warcprox", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -100,7 +100,7 @@ class CertificateAuthority(object):\n \n         # Generate certificate\n         self.cert = OpenSSL.crypto.X509()\n-        self.cert.set_version(3)\n+        self.cert.set_version(2)\n         # avoid sec_error_reused_issuer_and_serial\n         self.cert.set_serial_number(random.randint(0,2**64-1))\n         self.cert.get_subject().CN = 'Warcprox CA on {}'.format(socket.gethostname())[:64]\n", "before": "self . cert . set_version ( 3 )", "after": "self . cert . set_version ( 2 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:3\", 3, 31, 3, 32], \"2\"]]"}
{"project": "palabra", "commit_sha": "6ffddc1839f04536372f082adcaa0599c915496c", "parent_sha": "1287cb7f7b86ab0577cfa2bbe17010ed80c1092e", "file_path": "palabra/view.py", "project_url": "https://github.com/svisser/palabra", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -63,7 +63,7 @@ class GridViewProperties:\n         self.tile_size = 32\n         self.margin_x = 10\n         self.margin_y = 10\n-        self.line_width = 10\n+        self.line_width = 1\n         \n     def grid_to_screen_x(self, x, include_padding=True):\n         result = x * self.tile_size + (x + 1) * self.line_width\n", "before": "self . line_width = 10", "after": "self . line_width = 1", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:10\", 3, 27, 3, 29], \"1\"]]"}
{"project": "palabra", "commit_sha": "6218ee8b8ff70b2eb11857c1c01c96bb88114398", "parent_sha": "c023a3ee842f226f09d4142ee634b58df9fc9033", "file_path": "palabralib/newpuzzle.py", "project_url": "https://github.com/svisser/palabra", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -380,7 +380,7 @@ class NewWindow(gtk.Dialog):\n             if l in counts:\n                 counts[l] += 1\n             else:\n-                counts[l] = 0\n+                counts[l] = 1\n         return {\"counts\": counts, \"words\": words}\n         \n     def _check_grid(self, grid, criteria):\n", "before": "counts [ l ] = 0", "after": "counts [ l ] = 1", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0\", 3, 29, 3, 30], \"1\"]]"}
{"project": "bluesteel", "commit_sha": "362f00e64cbe671a6c216204f75c4d6af329b48d", "parent_sha": "42574ad0c810a40b5bd0526bab2565c4d7bff8e7", "file_path": "app/logic/bluesteelworker/download/GitFetcher.py", "project_url": "https://github.com/imvu/bluesteel", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -281,7 +281,7 @@ class GitFetcher(object):\n             self.report_stack.append(report)\n         else:\n             msg = 'No commands has been found. So we populate one command to let you know :D'\n-            rep = GitFetcher.create_report('No commands in: {0}'.format(name), 255, msg, '')\n+            rep = GitFetcher.create_report('No commands in: {0}'.format(name), 0, msg, '')\n             self.report_stack.append(rep)\n \n \n", "before": "rep = GitFetcher . create_report ( 'No commands in: {0}' . format ( name ) , 255 , msg , '' )", "after": "rep = GitFetcher . create_report ( 'No commands in: {0}' . format ( name ) , 0 , msg , '' )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:255\", 3, 80, 3, 83], \"0\"]]"}
{"project": "eniric", "commit_sha": "8602550874dbddb8223b6d7a23d2637fde6ab95c", "parent_sha": "dcf8ba7b4da68a13a530613cf7eabe01664bbcfa", "file_path": "tests/test_published_results.py", "project_url": "https://github.com/jason-neal/eniric", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ def test_published_precision_with_old_normalization(model_parameters, published_\n     assert published[\"RV_Cond_1[m/s]\"].values == round(results[id_string][0].value, 1)\n \n     # precision 2 has changed\n-    assert published[\"RV_Cond_1[m/s]\"].values != round(results[id_string][2].value, 1)\n+    assert published[\"RV_Cond_1[m/s]\"].values != round(results[id_string][1].value, 1)\n \n     # precision 3\n     assert published[\"RV_Cond_3[m/s]\"].values == round(results[id_string][2].value, 1)\n", "before": "assert published [ \"RV_Cond_1[m/s]\" ] . values != round ( results [ id_string ] [ 2 ] . value , 1 )", "after": "assert published [ \"RV_Cond_1[m/s]\" ] . values != round ( results [ id_string ] [ 1 ] . value , 1 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 75, 3, 76], \"1\"]]"}
{"project": "angr", "commit_sha": "0714d9e37fd6ba295bcc7204839d39b1ff54b26c", "parent_sha": "af1504db696c4d08088e73e521ab46552c7a8ecf", "file_path": "tests/test_never.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ def test_static():\n \n     # now try with a blank state\n     s = never_nolibs.sim_run(never_nolibs.exit_to(0x40050C, mode='static'))\n-    nose.tools.assert_equal(len(s.refs()[simuvex.SimMemRead]), 0)\n+    nose.tools.assert_equal(len(s.refs()[simuvex.SimMemRead]), 1)\n     nose.tools.assert_equal(len(s.refs()[simuvex.SimMemWrite]), 0)\n     nose.tools.assert_equal(len(s.refs()[simuvex.SimMemRef]), 2)\n \n", "before": "nose . tools . assert_equal ( len ( s . refs ( ) [ simuvex . SimMemRead ] ) , 0 )", "after": "nose . tools . assert_equal ( len ( s . refs ( ) [ simuvex . SimMemRead ] ) , 1 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0\", 3, 64, 3, 65], \"1\"]]"}
{"project": "angr", "commit_sha": "6541f6c27bbcf46ae6b3613f9368bd756a4e19f3", "parent_sha": "0714d9e37fd6ba295bcc7204839d39b1ff54b26c", "file_path": "tests/test_never.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -49,7 +49,7 @@ def test_static():\n     # now try with a blank state\n     s = never_nolibs.sim_run(never_nolibs.exit_to(0x40050C, mode='static'))\n     nose.tools.assert_equal(len(s.refs()[simuvex.SimMemRead]), 1)\n-    nose.tools.assert_equal(len(s.refs()[simuvex.SimMemWrite]), 0)\n+    nose.tools.assert_equal(len(s.refs()[simuvex.SimMemWrite]), 2)\n     nose.tools.assert_equal(len(s.refs()[simuvex.SimMemRef]), 2)\n \n     return s\n", "before": "nose . tools . assert_equal ( len ( s . refs ( ) [ simuvex . SimMemWrite ] ) , 0 )", "after": "nose . tools . assert_equal ( len ( s . refs ( ) [ simuvex . SimMemWrite ] ) , 2 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0\", 3, 65, 3, 66], \"2\"]]"}
{"project": "angr", "commit_sha": "cb7ed870668e02d71571d85f29b1ceb30495dd1e", "parent_sha": "6541f6c27bbcf46ae6b3613f9368bd756a4e19f3", "file_path": "tests/test_never.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -50,7 +50,7 @@ def test_static():\n     s = never_nolibs.sim_run(never_nolibs.exit_to(0x40050C, mode='static'))\n     nose.tools.assert_equal(len(s.refs()[simuvex.SimMemRead]), 1)\n     nose.tools.assert_equal(len(s.refs()[simuvex.SimMemWrite]), 2)\n-    nose.tools.assert_equal(len(s.refs()[simuvex.SimMemRef]), 2)\n+    nose.tools.assert_equal(len(s.refs()[simuvex.SimMemRef]), 15)\n \n     return s\n \n", "before": "nose . tools . assert_equal ( len ( s . refs ( ) [ simuvex . SimMemRef ] ) , 2 )", "after": "nose . tools . assert_equal ( len ( s . refs ( ) [ simuvex . SimMemRef ] ) , 15 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 63, 3, 64], \"15\"]]"}
{"project": "angr", "commit_sha": "e891fba692ac022fded7fa9b0a240c65028f849b", "parent_sha": "81a00d3cbba07e3c7574570a966c5232cabf0fc7", "file_path": "simuvex/procedures/libc___so___6/pthread_create.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -12,7 +12,7 @@ class pthread_create(simuvex.SimProcedure):\n \n         # Get main pc from arguments\n         code_addr = self.arg(2)\n-        func_arg = self.arg(0)\n+        func_arg = self.arg(3)\n \n         # Create the new state as well\n         new_state=self.state.copy()\n", "before": "func_arg = self . arg ( 0 )", "after": "func_arg = self . arg ( 3 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0\", 3, 29, 3, 30], \"3\"]]"}
{"project": "angr", "commit_sha": "5cbf3669385f6d444f6871fbd27da72dbef93f1e", "parent_sha": "862ad20549bbf9532c91fa29cecb98082cf4ccaf", "file_path": "angr/analyses/cfg.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -20,7 +20,7 @@ class CFG(Analysis, CFGBase):\n     '''\n     This class represents a control-flow graph.\n     '''\n-    def __init__(self, context_sensitivity_level=2, start=None, avoid_runs=None, enable_function_hints=False, call_depth=None, initial_state=None,\n+    def __init__(self, context_sensitivity_level=1, start=None, avoid_runs=None, enable_function_hints=False, call_depth=None, initial_state=None,\n                  text_base=None, # Temporary\n                  text_size=None # Temporary\n                 ):\n", "before": "def __init__ ( self , context_sensitivity_level = 2 , start = None , avoid_runs = None , enable_function_hints = False , call_depth = None , initial_state = None , text_base = None , text_size = None ) : ", "after": "def __init__ ( self , context_sensitivity_level = 1 , start = None , avoid_runs = None , enable_function_hints = False , call_depth = None , initial_state = None , text_base = None , text_size = None ) : ", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 50, 3, 51], \"1\"]]"}
{"project": "angr", "commit_sha": "bf59343382f6d82963f5f5d8866fc8a06d6955da", "parent_sha": "dfb64df8fe4cb76faf470eeeb3d53aed60c13781", "file_path": "simuvex/procedures/libc___so___6/recv.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ class recv(simuvex.SimProcedure):\n \t\t# TODO: Symbolic fd\n \t\tfd = self.arg(0)\n \t\tdst = self.arg(1)\n-\t\tlength = self.arg(1)\n+\t\tlength = self.arg(2)\n \t\tplugin = self.state['posix']\n \n \t\t# TODO handle errors\n", "before": "length = self . arg ( 1 )", "after": "length = self . arg ( 2 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1\", 3, 21, 3, 22], \"2\"]]"}
{"project": "auto-sklearn", "commit_sha": "e4cc72769787f8d0627526e0940500e042f0be56", "parent_sha": "1a49f63c727bd3c39111eb5bf742cf27a8adbfae", "file_path": "test/test_pipeline/components/data_preprocessing/test_balancing.py", "project_url": "https://github.com/faisalomar/auto-sklearn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ class BalancingComponentTest(unittest.TestCase):\n                  ('random_forest', RandomForest, 0.846, 0.792),\n                  ('libsvm_svc', LibSVM_SVC, 0.800, 0.762),\n                  ('liblinear_svc', LibLinear_SVC, 0.679, 0.690),\n-                 ('sgd', SGD, 0.651, 0.578)\n+                 ('sgd', SGD, 0.635, 0.578)\n                 ]:\n             for strategy, acc in [('none', acc_no_weighting),\n                                   ('weighting', acc_weighting)]:\n", "before": "( 'sgd' , SGD , 0.651 , 0.578 )", "after": "( 'sgd' , SGD , 0.635 , 0.578 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:0.651\", 3, 31, 3, 36], \"0.635\"]]"}
{"project": "auto-sklearn", "commit_sha": "f37a2b8357cf545dfc4e624d371331f2f8dc9b38", "parent_sha": "48015cedc3d017ac6ea7679d3d1fca7a2e2972cb", "file_path": "test/test_pipeline/components/data_preprocessing/test_balancing.py", "project_url": "https://github.com/faisalomar/auto-sklearn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ class BalancingComponentTest(unittest.TestCase):\n                  ('random_forest', RandomForest, 0.75, 0.821),\n                  ('libsvm_svc', LibSVM_SVC, 0.769, 0.706),\n                  ('liblinear_svc', LibLinear_SVC, 0.762, 0.72),\n-                 ('sgd', SGD, 0.739, 0.632)\n+                 ('sgd', SGD, 0.739, 0.735)\n                 ]:\n             for strategy, acc in [('none', acc_no_weighting),\n                                   ('weighting', acc_weighting)]:\n", "before": "( 'sgd' , SGD , 0.739 , 0.632 )", "after": "( 'sgd' , SGD , 0.739 , 0.735 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:0.632\", 3, 38, 3, 43], \"0.735\"]]"}
{"project": "angr", "commit_sha": "b80e44722c39bf34ab8ff355708b46266b11a5e8", "parent_sha": "e0e2c46168fc2ae822ac380b564cc333bc497bcf", "file_path": "angr/surveyors/explorer.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -20,7 +20,7 @@ class Explorer(Surveyor):\n \n \tpath_lists = Surveyor.path_lists + [ 'found', 'avoided', 'deviating', 'looping']\n \n-\tdef __init__(self, project, start=None, starts=None, max_concurrency=None, max_active=None, pickle_paths=None, find=(), avoid=(), restrict=(), min_depth=0, max_depth=None, max_repeats=10, num_find=1, num_avoid=None, num_deviate=1, num_loop=None, cut_lost=None):\n+\tdef __init__(self, project, start=None, starts=None, max_concurrency=None, max_active=None, pickle_paths=None, find=(), avoid=(), restrict=(), min_depth=0, max_depth=None, max_repeats=10000000, num_find=1, num_avoid=None, num_deviate=1, num_loop=None, cut_lost=None):\n", "before": "def __init__ ( self , project , start = None , starts = None , max_concurrency = None , max_active = None , pickle_paths = None , find = ( ) , avoid = ( ) , restrict = ( ) , min_depth = 0 , max_depth = None , max_repeats = 10 , num_find = 1 , num_avoid = None , num_deviate = 1 , num_loop = None , cut_lost = None ) : ", "after": "def __init__ ( self , project , start = None , starts = None , max_concurrency = None , max_active = None , pickle_paths = None , find = ( ) , avoid = ( ) , restrict = ( ) , min_depth = 0 , max_depth = None , max_repeats = 10000000 , num_find = 1 , num_avoid = None , num_deviate = 1 , num_loop = None , cut_lost = None ) : ", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:10\", 3, 186, 3, 188], \"10000000\"]]"}
{"project": "zipline", "commit_sha": "36e4556d09da473494f8fee521eb14f31a9fe3b9", "parent_sha": "21f889bb4f3b4ff9eb17eab48966bc52cbfd5b69", "file_path": "zipline/data/minute_bars.py", "project_url": "https://github.com/michaelballard7/zipline", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -899,7 +899,7 @@ class BcolzMinuteBarReader(MinuteBarReader):\n     FIELDS = ('open', 'high', 'low', 'close', 'volume')\n \n-    def __init__(self, rootdir, sid_cache_size=1000):\n+    def __init__(self, rootdir, sid_cache_size=1550):\n         self._rootdir = rootdir\n \n         metadata = self._get_metadata()\n", "before": "def __init__ ( self , rootdir , sid_cache_size = 1000 ) : self . _rootdir = rootdir metadata = self . _get_metadata ( )", "after": "def __init__ ( self , rootdir , sid_cache_size = 1550 ) : self . _rootdir = rootdir metadata = self . _get_metadata ( )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1000\", 2, 48, 2, 52], \"1550\"]]"}
{"project": "litex-buildenv", "commit_sha": "5b9665b48d817b3190a8581e552d10d559735642", "parent_sha": "1d0d8f2729ad791f70f61b97ead64e080980fea9", "file_path": "gateware/xadc.py", "project_url": "https://github.com/jimmo/litex-buildenv", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -19,7 +19,7 @@ class XADC(Module, AutoCSR):\n         # # #\n \n         busy = Signal()\n-        channel = Signal(5)\n+        channel = Signal(7)\n         eoc = Signal()\n         eos = Signal()\n         data = Signal(16)\n", "before": "channel = Signal ( 5 )", "after": "channel = Signal ( 7 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:5\", 3, 26, 3, 27], \"7\"]]"}
{"project": "litex-buildenv", "commit_sha": "122d450da8308a84e8c0d2dd3452b0c9a4adb9f3", "parent_sha": "0b0c1255620d8d8e02cbf86c6d259fb3fc707a19", "file_path": "hdl/csc/rgb2ycbcr.py", "project_url": "https://github.com/jimmo/litex-buildenv", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -74,7 +74,7 @@ class RGB2YCbCrDatapath(Module):\n \n         # stage 3\n         # ca*(r-g) + cb*(b-g)\n-        carg_plus_cbbg = Signal((rgb_w + coef_w + 2, True))\n+        carg_plus_cbbg = Signal((rgb_w + coef_w + 9, True)) # XXX\n         self.sync += [\n             carg_plus_cbbg.eq(ca_mult_rg + cb_mult_bg)\n         ]\n", "before": "carg_plus_cbbg = Signal ( ( rgb_w + coef_w + 2 , True ) )", "after": "carg_plus_cbbg = Signal ( ( rgb_w + coef_w + 9 , True ) )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 51, 3, 52], \"9\"]]"}
{"project": "netpyne", "commit_sha": "9742bb209b2136974e2b1d3a3e2354e2a334f783", "parent_sha": "42ff2f8a9e27b90f695b5312cc16ccd8004da0c5", "file_path": "netpyne/tests/checks.py", "project_url": "https://github.com/rodriguez-facundo/netpyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ def checkOutput(modelName, verbose=False):\n \n \t\t# tut7 expected output \n \t\texpectedAll['numSyns']['tut7'] = 2500\n-\t\texpectedAll['numSpikes']['tut7'] = 583\n+\t\texpectedAll['numSpikes']['tut7'] = 332\n \n \t\t# tut_import expected output \n \t\texpectedAll['numSyns']['tut_import'] = 340\n", "before": "expectedAll [ 'numSpikes' ] [ 'tut7' ] = 583", "after": "expectedAll [ 'numSpikes' ] [ 'tut7' ] = 332", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:583\", 3, 38, 3, 41], \"332\"]]"}
{"project": "fitbit-googlefit", "commit_sha": "09a30db9a7b401bc1c7286c78ddaa59f61e87a90", "parent_sha": "0cd9a571d91737e22bbea93b2612db6fec906920", "file_path": "convertors.py", "project_url": "https://github.com/lightmaster/fitbit-googlefit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -213,7 +213,7 @@ class Convertor:\n \t\treturn dict(\n \t\t\tdataTypeName='com.google.activity.segment',\n \t\t\tstartTimeNanos=epoch_time_nanos,\n-\t\t\tendTimeNanos=epoch_time_nanos+110,\n+\t\t\tendTimeNanos=epoch_time_nanos+60000000000,\n \t\t\tvalue=[dict(intVal=sleepType)]\n \t\t\t)\n \n", "before": "return dict ( dataTypeName = 'com.google.activity.segment' , startTimeNanos = epoch_time_nanos , endTimeNanos = epoch_time_nanos + 110 , value = [ dict ( intVal = sleepType ) ] )", "after": "return dict ( dataTypeName = 'com.google.activity.segment' , startTimeNanos = epoch_time_nanos , endTimeNanos = epoch_time_nanos + 60000000000 , value = [ dict ( intVal = sleepType ) ] )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:110\", 3, 34, 3, 37], \"60000000000\"]]"}
{"project": "mitmproxy", "commit_sha": "40156ce123962a6d0e431761833a506ec5aeebb9", "parent_sha": "5e123844865715085cb3ab06f264c0c3032458c4", "file_path": "pathod/test.py", "project_url": "https://github.com/aisier/mitmproxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -51,7 +51,7 @@ class Daemon:\n     def text_log(self):\n         return self.logfp.getvalue()\n \n-    def expect_log(self, n, timeout=1):\n+    def expect_log(self, n, timeout=5):\n         l = []\n         start = time.time()\n         while True:\n", "before": "def expect_log ( self , n , timeout = 1 ) : l = [ ] start = time . time ( ) while True : ", "after": "def expect_log ( self , n , timeout = 5 ) : l = [ ] start = time . time ( ) while True : ", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1\", 3, 37, 3, 38], \"5\"]]"}
{"project": "rasp-smartdoor", "commit_sha": "258bf7708fe398d5b9171f64bcb8e9efecc1eb4c", "parent_sha": "b5c73a7cddcd53aa8b323e279c76a1b9a95510c2", "file_path": "gpio_utils.py", "project_url": "https://github.com/joaohenriquef/rasp-smartdoor", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -12,7 +12,7 @@ def setup():\n   GPIO.setup(LED_PIN, GPIO.OUT)\n   GPIO.output(LED_PIN, 1)           # Keep this LED ON.\n \n-def pulse_relay(relay_pin=RELAY_PIN, delay=1):\n+def pulse_relay(relay_pin=RELAY_PIN, delay=2):\n   setup()\n   GPIO.output(relay_pin, False)\n   time.sleep(delay)\n", "before": "def pulse_relay ( relay_pin = RELAY_PIN , delay = 1 ) : setup ( ) GPIO . output ( relay_pin , False ) time . sleep ( delay )", "after": "def pulse_relay ( relay_pin = RELAY_PIN , delay = 2 ) : setup ( ) GPIO . output ( relay_pin , False ) time . sleep ( delay )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1\", 3, 44, 3, 45], \"2\"]]"}
{"project": "funcx-web-service", "commit_sha": "bbe30fc0362b94f32aade6bc432672380827a83a", "parent_sha": "b991997b61c33d10f952d7037b0c9b630897f563", "file_path": "forwarder/forwarder/__init__.py", "project_url": "https://github.com/funcx-faas/funcx-web-service", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -12,7 +12,7 @@ __version__ = VERSION\n def set_file_logger(filename,\n                     name='funcx.forwarder',\n                     level=logging.DEBUG,\n-                    maxBytes=256*1024*1024,\n+                    maxBytes=32*1024*1024,\n                     backupCount=1,\n                     format_string=None):\n", "before": "def set_file_logger ( filename , name = 'funcx.forwarder' , level = logging . DEBUG , maxBytes = 256 * 1024 * 1024 , backupCount = 1 , format_string = None ) : ", "after": "def set_file_logger ( filename , name = 'funcx.forwarder' , level = logging . DEBUG , maxBytes = 32 * 1024 * 1024 , backupCount = 1 , format_string = None ) : ", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:256\", 3, 30, 3, 33], \"32\"]]"}
{"project": "openCEM", "commit_sha": "0f1726ad0404d85482559fdc068096ac61f26069", "parent_sha": "8658e710b80eff407a166b0a1bfb42ea9be532ee", "file_path": "cemo/multi.py", "project_url": "https://github.com/openCEMorg/openCEM", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -638,7 +638,7 @@ group by zones,all_tech;\" : [zones,all_tech] hyb_cap_initial;\n         strd1 = \"'\" + str(date1) + \"'\"\n         date2 = datetime.datetime(year, 6, 30, 23, 0, 0)\n         if test:\n-            date2 = datetime.datetime(year - 1, 7, 12, 23, 0, 0)\n+            date2 = datetime.datetime(year - 1, 7, 3, 23, 0, 0)\n         strd2 = \"'\" + str(date2) + \"'\"\n         drange = \"BETWEEN \" + strd1 + \" AND \" + strd2\n         dcfName = self.tmpdir / ('Sim' + str(year) + '.dat')\n", "before": "date2 = datetime . datetime ( year - 1 , 7 , 12 , 23 , 0 , 0 )", "after": "date2 = datetime . datetime ( year - 1 , 7 , 3 , 23 , 0 , 0 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:12\", 3, 52, 3, 54], \"3\"]]"}
{"project": "sympy", "commit_sha": "319edd396f090f5ff410af29d98c385c14e551fc", "parent_sha": "9902087926a386c0fb94d1bcd010702882f76803", "file_path": "sympy/matrices/matrices.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2438,7 +2438,7 @@ def dot(self, b):\n         if (1 not in mat.shape) or (1 not in b.shape) :\n             SymPyDeprecationWarning(\n                 feature=\"dot() no longer support dot of (m,n) and (1,n) matrices.\",\n-                issue=13808,\n+                issue=13815,\n                 deprecated_since_version=\"1.2\").warn()\n             return super(MatrixBase,self)._array_dot(b)\n         if len(mat) != len(b):\n", "before": "SymPyDeprecationWarning ( feature = \"dot() no longer support dot of (m,n) and (1,n) matrices.\" , issue = 13808 , deprecated_since_version = \"1.2\" ) . warn ( )", "after": "SymPyDeprecationWarning ( feature = \"dot() no longer support dot of (m,n) and (1,n) matrices.\" , issue = 13815 , deprecated_since_version = \"1.2\" ) . warn ( )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:13808\", 3, 23, 3, 28], \"13815\"]]"}
{"project": "osc", "commit_sha": "42f9f2bf3ef43a3dbf4b918f2dbd768025fb8a1d", "parent_sha": "7f1d7f6258ebb9f368b608bf109b62dd4cf47081", "file_path": "osc/core.py", "project_url": "https://github.com/lethliel/osc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2901,7 +2901,7 @@ def makeurl(baseurl, l, query=[]):\n     return urlunsplit((scheme, netloc, '/'.join(l), query, ''))\n \n \n-def http_request(method, url, headers={}, data=None, file=None, timeout=100):\n+def http_request(method, url, headers={}, data=None, file=None, timeout=0):\n     \"\"\"wrapper around urllib2.urlopen for error handling,\n     and to support additional (PUT, DELETE) methods\"\"\"\n     def create_memoryview(obj):\n", "before": "def http_request ( method , url , headers = { } , data = None , file = None , timeout = 100 ) : \"\"\"wrapper around urllib2.urlopen for error handling,\n     and to support additional (PUT, DELETE) methods\"\"\" def create_memoryview ( obj ) : ", "after": "def http_request ( method , url , headers = { } , data = None , file = None , timeout = 0 ) : \"\"\"wrapper around urllib2.urlopen for error handling,\n     and to support additional (PUT, DELETE) methods\"\"\" def create_memoryview ( obj ) : ", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:100\", 3, 73, 3, 76], \"0\"]]"}
{"project": "Percy", "commit_sha": "b536bb9117254bf0865c0676bad13a51f9298eb5", "parent_sha": "a611918d001f3505e9831e7e2638e49549af10d3", "file_path": "mysite/app_folder/api/nlp.py", "project_url": "https://github.com/estasney/Percy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -103,7 +103,7 @@ class SynonymParser(object):\n         entities = [word for word, tag in entities]  # Remove tag\n         return entities\n \n-    def run_query_(self, entities, topn=5):\n+    def run_query_(self, entities, topn=10):\n         if isinstance(entities, str):\n             entities = [entities]\n \n", "before": "def run_query_ ( self , entities , topn = 5 ) : if isinstance ( entities , str ) : entities = [ entities ]", "after": "def run_query_ ( self , entities , topn = 10 ) : if isinstance ( entities , str ) : entities = [ entities ]", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:5\", 3, 41, 3, 42], \"10\"]]"}
{"project": "copenhagent", "commit_sha": "4254fddf0dafef0c640e9e94a829cc6799833466", "parent_sha": "3aaf0b15051a1bcfef2cf790585871c67bc9ae74", "file_path": "copenhagent.py", "project_url": "https://github.com/sxlijin/copenhagent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -67,7 +67,7 @@ def main():\n \n     if (name, token).count(None) != 1:\n         parser.print_help()\n-        sys.exit(0)\n+        sys.exit(1)\n \n     opened = shell.Shell(token, name)\n     try:\n", "before": "sys . exit ( 0 )", "after": "sys . exit ( 1 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0\", 3, 18, 3, 19], \"1\"]]"}
{"project": "suitcase", "commit_sha": "ae025fcacbf009c3f4df7984aa8321a1c78b0dbd", "parent_sha": "391482f9f5825f659ef19c07aa44217c3ef6b117", "file_path": "suitcase/tests/test_hdf5.py", "project_url": "https://github.com/ronpandolfi/suitcase", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ def test_filter_fields():\n     hdr = db[-1]\n     unwanted_fields = ['point_det']\n     out = hdf5.filter_fields(hdr, unwanted_fields)\n-    assert len(out)==0\n+    assert len(out)==1\n \n \n def test_hdf5_export_list():\n", "before": "assert len ( out ) == 0", "after": "assert len ( out ) == 1", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0\", 3, 22, 3, 23], \"1\"]]"}
{"project": "flower", "commit_sha": "b684f9b4cc216ef2c19a8406c443005fb180aeee", "parent_sha": "e2e3770adddb14c3c59caffcbe01202351fbd5c3", "file_path": "flower/views/auth.py", "project_url": "https://github.com/Rocket-amphora/flower", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ class LoginHandler(BaseHandler, tornado.auth.GoogleOAuth2Mixin):\n                 \"Access denied to '{email}'. Please use another account or \"\n                 \"ask your admin to add your email to flower --auth.\"\n             ).format(email=email)\n-            raise tornado.web.HTTPError(404, message)\n+            raise tornado.web.HTTPError(401, message)\n \n         self.set_secure_cookie(\"user\", str(email))\n \n", "before": "raise tornado . web . HTTPError ( 404 , message )", "after": "raise tornado . web . HTTPError ( 401 , message )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:404\", 3, 41, 3, 44], \"401\"]]"}
{"project": "dosenet-raspberrypi", "commit_sha": "63dfbca35eaba68f3fc4a322d34455577324973c", "parent_sha": "7407966fa2ab8c8af55fb323a1b07ea44264da0e", "file_path": "tests.py", "project_url": "https://github.com/ludicao/dosenet-raspberrypi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -354,7 +354,7 @@ class TestDataLog(unittest.TestCase):\n         mgr.takedown()\n         \n         self.assertIsNotNone(output)\n-        self.assertEqual(len(output), 3)\n+        self.assertEqual(len(output), 2)\n \n     def tearDown(self):\n         os.remove(DEFAULT_TEST_DATALOG)\n", "before": "self . assertEqual ( len ( output ) , 3 )", "after": "self . assertEqual ( len ( output ) , 2 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:3\", 3, 39, 3, 40], \"2\"]]"}
{"project": "Stock-Data", "commit_sha": "ec52acb97b498cfb3e1500fa6949f026e4152eed", "parent_sha": "dc009d31c96a56651b39f8db381e498f5bda343d", "file_path": "data.py", "project_url": "https://github.com/twigtheoracle/Stock-Data", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -21,7 +21,7 @@ class Data():\n     # gets the old date for data access\n     def get_old_date(self, date):\n         return_string = \"\"\n-        return_string += str(self.current_year - 10) + \"-\"\n+        return_string += str(self.current_year - 11) + \"-\"\n         if(self.current_month < 10):\n             return_string += \"0\"\n         return_string += str(self.current_month) + \"-01\"\n", "before": "return_string += str ( self . current_year - 10 ) + \"-\"", "after": "return_string += str ( self . current_year - 11 ) + \"-\"", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:10\", 3, 50, 3, 52], \"11\"]]"}
{"project": "GiraffeOfDoom", "commit_sha": "2623c301c59de1258efa6e73750c4e55a9582cf5", "parent_sha": "7f518185b5130a92014029c51885219bd87d3a4d", "file_path": "dnacore04/chart_spark_swdens.py", "project_url": "https://github.com/vmalkin/GiraffeOfDoom", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ def process_dashboard(density):\n         returnvalue = \"none\"\n     if density >= 10 and density < 20:\n         returnvalue = \"low\"\n-    if density >= 20 and density < 30:\n+    if density >= 20 and density < 40:\n         returnvalue = \"med\"\n     if density >=40:\n         returnvalue = \"high\"\n", "before": "if density >= 20 and density < 30 : returnvalue = \"med\"", "after": "if density >= 20 and density < 40 : returnvalue = \"med\"", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:30\", 3, 36, 3, 38], \"40\"]]"}
{"project": "InstaPy", "commit_sha": "72cd28abff13175869c8439000cee632f56e47e9", "parent_sha": "5ccdbc5977c49d8c4f3734dbf0d16b45f5ce8830", "file_path": "instapy/database_engine.py", "project_url": "https://github.com/anyulled/InstaPy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -79,7 +79,7 @@ def get_db(make=False):\n \n \n def get_profile(name, address, logger):\n-    sleep(1)\n+    sleep(2)\n     \"\"\" Get a profile for users and return its id \"\"\"\n     try:\n         conn = sqlite3.connect(address)\n", "before": "sleep ( 1 )", "after": "sleep ( 2 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1\", 3, 11, 3, 12], \"2\"]]"}
{"project": "flutterfuck", "commit_sha": "5610d8587ad81ce6db377c8ae7e001fc1b63160c", "parent_sha": "dfbd99ea994408911de3625c37435bcf07e37631", "file_path": "sopel/bot.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -174,7 +174,7 @@ class Sopel(irc.Bot):\n                     self.register(*relevant_parts)\n                     success_count += 1\n \n-        if len(modules) > 2:  # coretasks is counted\n+        if len(modules) > 1:  # coretasks is counted\n             stderr('\\n\\nRegistered %d modules,' % (success_count - 1))\n             stderr('%d modules failed to load\\n\\n' % error_count)\n         else:\n", "before": "if len ( modules ) > 2 : stderr ( '\\n\\nRegistered %d modules,' % ( success_count - 1 ) ) stderr ( '%d modules failed to load\\n\\n' % error_count ) else : ", "after": "if len ( modules ) > 1 : stderr ( '\\n\\nRegistered %d modules,' % ( success_count - 1 ) ) stderr ( '%d modules failed to load\\n\\n' % error_count ) else : ", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 27, 3, 28], \"1\"]]"}
{"project": "pokeminer", "commit_sha": "f59ab3bd2d13351b557ea4160cbccae24de9646d", "parent_sha": "ba335c03ea72d8ef452d24b15b55b5193c4529f9", "file_path": "landmarks.py", "project_url": "https://github.com/pogosandbox/pokeminer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -200,7 +200,7 @@ class Landmarks:\n         else:\n             print(landmark.name, landmark.size, type(landmark.location), '\\n')\n \n-    def find_landmark(self, coords, max_distance=1000):\n+    def find_landmark(self, coords, max_distance=750):\n         if self.points_of_interest:\n             found = find_within(self.points_of_interest, coords)\n             if found:\n", "before": "def find_landmark ( self , coords , max_distance = 1000 ) : if self . points_of_interest : found = find_within ( self . points_of_interest , coords ) if found : ", "after": "def find_landmark ( self , coords , max_distance = 750 ) : if self . points_of_interest : found = find_within ( self . points_of_interest , coords ) if found : ", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1000\", 3, 50, 3, 54], \"750\"]]"}
{"project": "pokeminer", "commit_sha": "be50f925b5b6f5e9dd4f82f6caaa40871a4a2c66", "parent_sha": "8fc6db8a8dc6257ef91487b072d4e6b8a5544ee5", "file_path": "landmarks.py", "project_url": "https://github.com/pogosandbox/pokeminer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -200,7 +200,7 @@ class Landmarks:\n         else:\n             print(landmark.name, landmark.size, type(landmark.location), '\\n')\n \n-    def find_landmark(self, coords, max_distance=1000):\n+    def find_landmark(self, coords, max_distance=750):\n         if self.points_of_interest:\n             found = find_within(self.points_of_interest, coords)\n             if found:\n", "before": "def find_landmark ( self , coords , max_distance = 1000 ) : if self . points_of_interest : found = find_within ( self . points_of_interest , coords ) if found : ", "after": "def find_landmark ( self , coords , max_distance = 750 ) : if self . points_of_interest : found = find_within ( self . points_of_interest , coords ) if found : ", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1000\", 3, 50, 3, 54], \"750\"]]"}
{"project": "cclib", "commit_sha": "678c305fadafb1aded7af268ad42b85fd5627ebc", "parent_sha": "32fbbbb40196aaf3da7a114b9ed4080b1841adae", "file_path": "test/regression.py", "project_url": "https://github.com/chemistry-scripts/cclib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -119,7 +119,7 @@ def testGaussian_Gaussian98_water_zmatrix_nosym_log(logfile):\n \r\n def testGaussian_Gaussian03_AM1_SP_out(logfile):\r\n     \"\"\"Previously, caused scfvalue parsing to fail.\"\"\"\r\n-    assert len(logfile.data.scfvalues[0])==12\r\n+    assert len(logfile.data.scfvalues[0])==13\r\n \r\n def testGaussian_Gaussian03_anthracene_log(logfile):\r\n     \"\"\"This file exposed a bug in extracting the vibsyms.\"\"\"\r\n", "before": "assert len ( logfile . data . scfvalues [ 0 ] ) == 12", "after": "assert len ( logfile . data . scfvalues [ 0 ] ) == 13", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:12\", 3, 44, 3, 46], \"13\"]]"}
{"project": "qinling", "commit_sha": "7234980037c368aa1673af78d72e1458e258d2c1", "parent_sha": "de1d83bf59bcbb58d3c96759950619528739b19b", "file_path": "runtimes/sidecar/sidecar.py", "project_url": "https://github.com/openstack/qinling", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ def _download_package(url, zip_file, token=None, unzip=None):\n         headers = {'X-Auth-Token': token}\n \n     try:\n-        r = requests.get(url, headers=headers, stream=True, timeout=5,\n+        r = requests.get(url, headers=headers, stream=True, timeout=30,\n                          verify=False)\n         if r.status_code != 200:\n             return make_response(DOWNLOAD_ERROR % (url, r.content), 500)\n", "before": "r = requests . get ( url , headers = headers , stream = True , timeout = 5 , verify = False )", "after": "r = requests . get ( url , headers = headers , stream = True , timeout = 30 , verify = False )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:5\", 3, 69, 3, 70], \"30\"]]"}
{"project": "dcos-e2e", "commit_sha": "3d0e2ac9d3fb344b0a855071d7d2811656c441f4", "parent_sha": "e9d8b7e4d04ad2a9a5e3ebb2a65aee2ba6440d4c", "file_path": "src/dcos_e2e/backends/_vagrant/__init__.py", "project_url": "https://github.com/dcos/dcos-e2e", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ class Vagrant(ClusterBackend):\n         self,\n         virtualbox_description: str = '',\n         workspace_dir: Optional[Path] = None,\n-        vm_memory_mb: int = 4096,\n+        vm_memory_mb: int = 2048,\n     ) -> None:\n", "before": "vm_memory_mb : int = 4096 ,", "after": "vm_memory_mb : int = 2048 ,", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:4096\", 3, 29, 3, 33], \"2048\"]]"}
{"project": "abcpy", "commit_sha": "33136453c607a57d63cf8fa3a82ded3765a0ac97", "parent_sha": "ad08b988ac8b0f01d3546cb80be73b91ea838ad1", "file_path": "examples/backends/mpi/pmcabc_gaussian.py", "project_url": "https://github.com/eth-cscs/abcpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -84,7 +84,7 @@ class ExampleGaussianMPITest(unittest.TestCase):\n         journal = infer_parameters()\n         test_result = journal.posterior_mean()[0]\n         expected_result = 178.07690877694714\n-        self.assertLess(abs(test_result - expected_result), 1e-1)\n+        self.assertLess(abs(test_result - expected_result), 2)\n \n \n if __name__  == \"__main__\":\n", "before": "self . assertLess ( abs ( test_result - expected_result ) , 1e-1 )", "after": "self . assertLess ( abs ( test_result - expected_result ) , 2 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 24, 3, 66], [\"integer:2\", \"T\"], 3], [\"Delete\", [\"float:1e-1\", 3, 61, 3, 65]]]"}
{"project": "abcpy", "commit_sha": "d75198620bb717bab5c8a18c0ede9b31e68d7a27", "parent_sha": "4639d6d6968a684c7a6b1bc1bfb17ec146669753", "file_path": "tests/approx_lhd_tests.py", "project_url": "https://github.com/eth-cscs/abcpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,7 +41,7 @@ class PenLogRegTests(unittest.TestCase):\n         y_sim_bivariate = self.model_bivariate.forward_simulate(self.model_bivariate.get_input_values(), 100,\n                                                                 rng=np.random.RandomState(1))\n         comp_likelihood_biv = self.likfun_bivariate.likelihood(y_obs_bivariate, y_sim_bivariate)\n-        expected_likelihood_biv = 0.9364479566809435\n+        expected_likelihood_biv = 0.999999999999999\n         self.assertAlmostEqual(comp_likelihood_biv, expected_likelihood_biv)\n \n \n", "before": "expected_likelihood_biv = 0.9364479566809435", "after": "expected_likelihood_biv = 0.999999999999999", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:0.9364479566809435\", 3, 35, 3, 53], \"0.999999999999999\"]]"}
{"project": "asm3", "commit_sha": "3121fdd79e9f24a05902e26e987c0acc3c3adcb5", "parent_sha": "bc0fab5efa3e5730bfac93459cc243682a68bf37", "file_path": "src/cachemem.py", "project_url": "https://github.com/bobintetley/asm3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -78,7 +78,7 @@ def _get_mc():\n     import memcache\n-    mc = memcache.Client([MEMCACHED_SERVER], debug=0)\n+    mc = memcache.Client([MEMCACHED_SERVER], debug=1) # causes any errors to be pumped out to stderr and picked up my mod_wsgi\n     return mc\n \n def _memcache_available():\n", "before": "mc = memcache . Client ( [ MEMCACHED_SERVER ] , debug = 0 )", "after": "mc = memcache . Client ( [ MEMCACHED_SERVER ] , debug = 1 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0\", 1, 52, 1, 53], \"1\"]]"}
{"project": "lsh-hdc", "commit_sha": "a03d3294dec95796ef37231eb8c5ed68c1e26fcd", "parent_sha": "ecefcb460bf817b220c3e96a1bdf8f98c34bf9f6", "file_path": "lsh_hdc/metrics.py", "project_url": "https://github.com/escherba/lsh-hdc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1096,7 +1096,7 @@ class ConfusionMatrix2(ContingencyTable, OrderedCrossTab):\n         Kappa coefficient is best known in the psychology field where it was\n         introduced to measure interrater agreement [1]_. It has also been used\n         in replication studies [2]_, clustering evaluation [3]_, image\n-        segmentation [4]_, feature selection [5]_, and forecasting [56]_. The\n+        segmentation [4]_, feature selection [5]_, and forecasting [6]_. The\n         first derivation of this measure is in [7]_.\n \n         Kappa can be derived by correcting Accuracy (Simple Matching\n", "before": "segmentation [ 4 ] _ , feature selection [ 5 ] _ , and forecasting [ 56 ] _ . The", "after": "segmentation [ 4 ] _ , feature selection [ 5 ] _ , and forecasting [ 6 ] _ . The", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:56\", 3, 69, 3, 71], \"6\"]]"}
{"project": "edx-platform", "commit_sha": "6c1a7ce66e86ed3d2e12e864b0159fde3d02b7b4", "parent_sha": "84794a230da7039e030936d522efc917a4198407", "file_path": "staticbook/views.py", "project_url": "https://github.com/easy-edx/edx-platform", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -5,7 +5,7 @@ import os\n from django.conf import settings\n from django.http import Http404\n \n-def index(request, page=1): \n+def index(request, page=0): \n     if not request.user.is_authenticated():\n         return redirect('/')\n     return render_to_response('staticbook.html',{'page':int(page)})\n", "before": "def index ( request , page = 1 ) : if not request . user . is_authenticated ( ) : return redirect ( '/' ) return render_to_response ( 'staticbook.html' , { 'page' : int ( page ) } )", "after": "def index ( request , page = 0 ) : if not request . user . is_authenticated ( ) : return redirect ( '/' ) return render_to_response ( 'staticbook.html' , { 'page' : int ( page ) } )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1\", 3, 25, 3, 26], \"0\"]]"}
{"project": "macsyfinder", "commit_sha": "afda048b5bd68683aaf618f1065217631c5e1b78", "parent_sha": "1e596e9309bf26e7dfdbe23511395372be65c2eb", "file_path": "tests/test_macsyfinder.py", "project_url": "https://github.com/gem-pasteur/macsyfinder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -837,7 +837,7 @@ Use ordered replicon to have better prediction.\n                            ]\n         self.assertListEqual([s.id for s in systems], expected_sys_id)\n \n-        expected_scores = [10.5, 10.0, 12.0, 9.5, 9.0, 8.5, 6.0, 5.0, 5.5, 10.5, 7.5, 7.0, 8.0, 8.3, 7.5]\n+        expected_scores = [10.5, 10.0, 12.0, 9.5, 9.0, 8.5, 6.0, 5.0, 5.5, 10.5, 7.5, 7.0, 8.0, 8.5, 7.5]\n         self.assertListEqual([s.score for s in systems], expected_scores)\n         self.assertEqual(len(rejected_clst), 11)\n \n", "before": "expected_scores = [ 10.5 , 10.0 , 12.0 , 9.5 , 9.0 , 8.5 , 6.0 , 5.0 , 5.5 , 10.5 , 7.5 , 7.0 , 8.0 , 8.3 , 7.5 ]", "after": "expected_scores = [ 10.5 , 10.0 , 12.0 , 9.5 , 9.0 , 8.5 , 6.0 , 5.0 , 5.5 , 10.5 , 7.5 , 7.0 , 8.0 , 8.5 , 7.5 ]", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:8.3\", 3, 97, 3, 100], \"8.5\"]]"}
{"project": "macsyfinder", "commit_sha": "0c33e0f9753e2a5fddee475909b9983ca79f595e", "parent_sha": "415b8b1a60a708aded277b2025a1a353e120240f", "file_path": "tests/test_macsyfinder.py", "project_url": "https://github.com/gem-pasteur/macsyfinder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -837,7 +837,7 @@ Use ordered replicon to have better prediction.\n                            ]\n         self.assertListEqual([s.id for s in systems], expected_sys_id)\n \n-        expected_scores = [10.5, 10.0, 12.0, 9.5, 9.0, 8.5, 6.0, 5.0, 5.5, 10.5, 7.5, 7.0, 8.0, 8.5, 7.5]\n+        expected_scores = [10.5, 10.0, 12.0, 9.5, 9.0, 8.5, 6.0, 5.0, 5.5, 10.5, 7.5, 7.0, 8.0, 8.3, 7.5]\n         self.assertListEqual([s.score for s in systems], expected_scores)\n         self.assertEqual(len(rejected_clst), 11)\n \n", "before": "expected_scores = [ 10.5 , 10.0 , 12.0 , 9.5 , 9.0 , 8.5 , 6.0 , 5.0 , 5.5 , 10.5 , 7.5 , 7.0 , 8.0 , 8.5 , 7.5 ]", "after": "expected_scores = [ 10.5 , 10.0 , 12.0 , 9.5 , 9.0 , 8.5 , 6.0 , 5.0 , 5.5 , 10.5 , 7.5 , 7.0 , 8.0 , 8.3 , 7.5 ]", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:8.5\", 3, 97, 3, 100], \"8.3\"]]"}
{"project": "FX-BT-Scripts", "commit_sha": "d119202a17db91351b29489505b99330039206f3", "parent_sha": "b09aa459253b83f08f508785902c6975d767ed71", "file_path": "dl_bt_dukascopy.py", "project_url": "https://github.com/FX31337/FX-BT-Scripts", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -97,7 +97,7 @@ def bt5_to_csv(self):\n         print(\"Converting into CSV (%s)...\" % (new_path))\n \n         # Opening, uncompressing & reading raw data\n-        lzma._BUFFER_SIZE = 2047 # Fix for liblzma bug: EOFError\n+        lzma._BUFFER_SIZE = 1023 # Fix for liblzma bug: EOFError\n         with lzma.open(self.path) as f:\n             data = f.read()\n \n", "before": "lzma . _BUFFER_SIZE = 2047", "after": "lzma . _BUFFER_SIZE = 1023", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2047\", 3, 29, 3, 33], \"1023\"]]"}
{"project": "FX-BT-Scripts", "commit_sha": "f82bfdfc015dc56288c62de81d35640067611445", "parent_sha": "fee7c6c79baf5c9b0058b24eb854c67992e4c1b9", "file_path": "dl_bt_dukascopy.py", "project_url": "https://github.com/FX31337/FX-BT-Scripts", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -102,7 +102,7 @@ def bt5_to_csv(self):\n         print(\"Converting into CSV (%s)...\" % (new_path))\n \n         # Opening, uncompressing & reading raw data\n-        lzma._BUFFER_SIZE = 1023 # Fix for liblzma bug: EOFError\n+        lzma._BUFFER_SIZE = 511 # Fix for liblzma bug: EOFError\n         with lzma.open(self.path) as f:\n             data = f.read()\n \n", "before": "lzma . _BUFFER_SIZE = 1023", "after": "lzma . _BUFFER_SIZE = 511", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1023\", 3, 29, 3, 33], \"511\"]]"}
{"project": "weblyzard_api", "commit_sha": "6c46a090a9fad21e1939c06d0cfa96f479e8e6fc", "parent_sha": "e967c8a257f58eb46cada08fb960995ec8a17a43", "file_path": "src/python/weblyzard_api/tests/client/test_recognize_ng.py", "project_url": "https://github.com/weblyzard/weblyzard_api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ class TestRecognizeNg(unittest.TestCase):\n         text = 'Vienna is the capital of Austria, Berlin is the capital of Germany. Linz also is in Austria'\n         result = self.client.search_text(\n             self.PROFILE_NAME, lang='en', text=text)\n-        assert len(result) == 5\n+        assert len(result) == 6\n \n     def test_annotate_document(self):\n         for document in self.DOCUMENTS:\n", "before": "assert len ( result ) == 5", "after": "assert len ( result ) == 6", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:5\", 3, 31, 3, 32], \"6\"]]"}
{"project": "macsyfinder", "commit_sha": "aaeffc3e12b275828fd17b157ba93f66c2d6c6cd", "parent_sha": "beb624c6b85af477b2a6f04aa169d831d790ac5d", "file_path": "test/test_Config.py", "project_url": "https://github.com/gem-pasteur/macsyfinder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -234,7 +234,7 @@ class Test(unittest.TestCase):\n                           profile_dir = os.path.join(self._data_dir, 'profiles'),\n                           res_search_dir = '/tmp'\n                           )\n-        self.assertEqual(self.cfg.i_evalue_sel, 0.5)\n+        self.assertEqual(self.cfg.i_evalue_sel, 0.001)\n         self.tearDown()\n         self.cfg = Config(cfg_file = \"nimportnaoik\",\n                           sequence_db = os.path.join(self._data_dir, \"base\", \"test_base.fa\"),\n", "before": "self . assertEqual ( self . cfg . i_evalue_sel , 0.5 )", "after": "self . assertEqual ( self . cfg . i_evalue_sel , 0.001 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:0.5\", 3, 49, 3, 52], \"0.001\"]]"}
{"project": "openbci", "commit_sha": "fb216b9ed5485198e408de6d78e2b49cb242ae45", "parent_sha": "3a7e172e6626128bdb6431ad93a4d77f0f15ad66", "file_path": "logic/configs/config_drone.py", "project_url": "https://github.com/BrainTech/openbci", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -10,7 +10,7 @@ class Config(object):\n         self.other_configs = []\n         self.state = self.number_of_states * [self.number_of_decisions * [0]]\n         self.state[0] = [1, 1, 1, 0, 0, 1, 0, 0]\n-        self.state[1] = [1, 1, 1, 1, 1, 1, 1, 0]\n+        self.state[1] = [1, 1, 1, 1, 1, 1, 1, 1]\n         self.letters = self.number_of_states * [self.number_of_decisions * [\"\"]]\n         self.letters[0] = [u\"Start\", u\"Start\",u\"Start\", u\"\",u\"\",u\"Start\", u\"\", u\"\"]\n         #self.letters[0] = [u\"Lewo\", u\"Prosto\",u\"Prawo\", u\"\",u\"\",u\"Ty\u0142\", u\"\", u\"\"]\n", "before": "self . state [ 1 ] = [ 1 , 1 , 1 , 1 , 1 , 1 , 1 , 0 ]", "after": "self . state [ 1 ] = [ 1 , 1 , 1 , 1 , 1 , 1 , 1 , 1 ]", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0\", 3, 47, 3, 48], \"1\"]]"}
{"project": "LtSense", "commit_sha": "b0a9b16c285f5c16c73dbd154cd09a3ed4cc3cfe", "parent_sha": "452b193ecd1093407b0f9a46476a603b5299d65a", "file_path": "ltsense/location.py", "project_url": "https://github.com/BigSense/LtSense", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ class GPSLocation(AbstractLocation, Thread):\n         Thread.__init__(self)\n         self._gps = gps(mode=WATCH_ENABLE)\n         self.location_ready = False\n-        self.poll_rate = 1.0\n+        self.poll_rate = 0.3\n         self.start()\n         logging.info(\"GPS Location Thread Activated\")\n \n", "before": "self . poll_rate = 1.0", "after": "self . poll_rate = 0.3", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:1.0\", 3, 26, 3, 29], \"0.3\"]]"}
{"project": "pypushover", "commit_sha": "351d629fca2cfd887e8e053d6a8fb29539f41fd0", "parent_sha": "26617994fab747e8fe34256ed864cfda7e2b7a6c", "file_path": "tests/runtests.py", "project_url": "https://github.com/KronoSKoderS/pypushover", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -217,7 +217,7 @@ class TestVerifcation(unittest.TestCase):\n \n     def test_val_user(self):\n         self.assertTrue(self.valid_vm.verify_user(user_key, device='test_device'))\n-        time.sleep(5)\n+        time.sleep(10)\n         self.assertTrue(pypo.verification.verify_user(app_key, user_key, device='test_device'))\n \n     def test_inv_user(self):\n", "before": "time . sleep ( 5 )", "after": "time . sleep ( 10 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:5\", 3, 20, 3, 21], \"10\"]]"}
{"project": "Crux", "commit_sha": "deafa9ddf66df1f5e68dcf11f910b9a970bb9289", "parent_sha": "b47393bf89adcf7f118ca104d6ffa7b7bde8e883", "file_path": "tools/generate_db.py", "project_url": "https://github.com/mavroudisv/Crux", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -6,7 +6,7 @@ from petlib.ec import EcGroup, EcPt\n from petlib.bn import Bn\n \n \n-def _make_table(start=-200000, end=100000):\n+def _make_table(start=-200000, end=2000):\n     G = EcGroup(nid=713)\n     g = G.generator()\n     o = G.order()\n", "before": "def _make_table ( start = - 200000 , end = 100000 ) : G = EcGroup ( nid = 713 ) g = G . generator ( ) o = G . order ( )", "after": "def _make_table ( start = - 200000 , end = 2000 ) : G = EcGroup ( nid = 713 ) g = G . generator ( ) o = G . order ( )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:100000\", 3, 36, 3, 42], \"2000\"]]"}
{"project": "obfsproxy", "commit_sha": "556bd2699cb9d0490e6c3b1ea78326aa767ed7ed", "parent_sha": "6cdbc64828d2d6c27cf90b0f10bfdd28c324d7d2", "file_path": "obfsproxy/network/socks5.py", "project_url": "https://github.com/david415/obfsproxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -534,7 +534,7 @@ class _ByteBuffer(bytearray):\n             ret = struct.unpack(\"!I\", self[0:4])[0]\n         else:\n             ret = struct.unpack(\"I\", self[0:4])[0]\n-        del self[0:2]\n+        del self[0:4]\n         return ret\n \n     def add(self, val):\n", "before": "del self [ 0 : 2 ]", "after": "del self [ 0 : 4 ]", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 20, 3, 21], \"4\"]]"}
{"project": "fenapack", "commit_sha": "d31d1c141ae6c773a832538ed04fd6036632a69e", "parent_sha": "ca3e844f3649136153e34bc4e78f787da710a370", "file_path": "test/bench/test_pcd_scaling.py", "project_url": "https://github.com/blechta/fenapack", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -333,7 +333,7 @@ class Postprocessor(object):\n     @staticmethod\n     def _create_figure():\n         fig = pyplot.figure()\n-        gs = gridspec.GridSpec(2, 1, height_ratios=[2, 2, 1], hspace=0.05)\n+        gs = gridspec.GridSpec(3, 1, height_ratios=[2, 2, 1], hspace=0.05)\n         ax2 = fig.add_subplot(gs[1])\n         ax1 = fig.add_subplot(gs[0], sharex=ax2)\n         ax1.xaxis.set_label_position('top')\n", "before": "gs = gridspec . GridSpec ( 2 , 1 , height_ratios = [ 2 , 2 , 1 ] , hspace = 0.05 )", "after": "gs = gridspec . GridSpec ( 3 , 1 , height_ratios = [ 2 , 2 , 1 ] , hspace = 0.05 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 32, 3, 33], \"3\"]]"}
{"project": "PyNMRSTAR", "commit_sha": "20820f9dc63dfb14d78288f9937871be83c56aa5", "parent_sha": "f9eaf2b09000b604f92b8e409a95f525af9f98c9", "file_path": "bmrb.py", "project_url": "https://github.com/uwbmrb/PyNMRSTAR", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -599,7 +599,7 @@ class _Parser(object):\n                         trim = True\n                         for pos in range(1, len(self.token) - 4):\n                             if self.token[pos] == \"\\n\":\n-                                if self.token[pos+1:pos+3] != \"   \":\n+                                if self.token[pos+1:pos+4] != \"   \":\n                                     trim = False\n \n                         if trim:\n", "before": "if self . token [ pos + 1 : pos + 3 ] != \"   \" : trim = False", "after": "if self . token [ pos + 1 : pos + 4 ] != \"   \" : trim = False", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:3\", 3, 57, 3, 58], \"4\"]]"}
{"project": "bot", "commit_sha": "6272e4db87d524f465e61fc9be06e3ebd965ce64", "parent_sha": "00f0ea58a8de333a9d14ed2e66da256eb7e04357", "file_path": "hackserv.py", "project_url": "https://github.com/trackmastersteve/bot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -707,7 +707,7 @@ def main(): # This is the main function for all of the bot controls.\n                                 \n                 # Respond to '.mining' command from admin.\n                 if name.lower() == adminname.lower() and message.find('.mining') != -1:\n-                    target = message.split(' ', 1)[1]\n+                    target = message.split(' ', 1)[0]\n                     nonExist(target, name)\n                 \n                 # Respond to '.persistence' command from admin.\n", "before": "target = message . split ( ' ' , 1 ) [ 1 ]", "after": "target = message . split ( ' ' , 1 ) [ 0 ]", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:1\", 3, 52, 3, 53], \"0\"]]"}
{"project": "pfsspy", "commit_sha": "619bffcc4fefe4e827a583e504e344611421eeb4", "parent_sha": "115999c966ea6503c6f9491a3346a18032ce7cfb", "file_path": "pfsspy/tracing.py", "project_url": "https://github.com/dstansby/pfsspy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -66,7 +66,7 @@ class FortranTracer(Tracer):\n-    def __init__(self, max_steps=1000, step_size=0.1):\n+    def __init__(self, max_steps=1000, step_size=0.01):\n         from streamtracer import StreamTracer\n         self.max_steps = max_steps\n         self.step_size = step_size\n", "before": "def __init__ ( self , max_steps = 1000 , step_size = 0.1 ) : from streamtracer import StreamTracer self . max_steps = max_steps self . step_size = step_size", "after": "def __init__ ( self , max_steps = 1000 , step_size = 0.01 ) : from streamtracer import StreamTracer self . max_steps = max_steps self . step_size = step_size", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:0.1\", 0, 50, 0, 53], \"0.01\"]]"}
{"project": "hnn", "commit_sha": "6d3f40bd4c00b58e6e091d14b1740e13db9a130f", "parent_sha": "5a8983a7699a920d792e687520184a06f847782b", "file_path": "hnn_qt5.py", "project_url": "https://github.com/jonescompneurolab/hnn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -316,7 +316,7 @@ class RunParamDialog (DictDialog):\n     self.danalysis = OrderedDict([('save_spec_data', 0),\n                                   ('f_max_spec', 40),\n                                   ('dipole_scalefctr',30e3),\n-                                  ('dipole_smooth_win',15.0)])\n+                                  ('dipole_smooth_win',5.0)])\n \n     self.ldict = [self.drun, self.drand, self.danalysis]\n     self.ltitle = ['Run', 'Randomization Seeds','Analysis']\n", "before": "self . danalysis = OrderedDict ( [ ( 'save_spec_data' , 0 ) , ( 'f_max_spec' , 40 ) , ( 'dipole_scalefctr' , 30e3 ) , ( 'dipole_smooth_win' , 15.0 ) ] )", "after": "self . danalysis = OrderedDict ( [ ( 'save_spec_data' , 0 ) , ( 'f_max_spec' , 40 ) , ( 'dipole_scalefctr' , 30e3 ) , ( 'dipole_smooth_win' , 5.0 ) ] )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"float:15.0\", 3, 56, 3, 60], \"5.0\"]]"}
{"project": "hnn", "commit_sha": "4b4608cca4007d6e1cb4c3cea204b5801a127e13", "parent_sha": "87f9644857d3cda3496114b67634560b4f830e2c", "file_path": "hnn_qt5.py", "project_url": "https://github.com/jonescompneurolab/hnn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -854,7 +854,7 @@ class HNNGUI (QMainWindow):\n   def shownetparamwin (self): self.baseparamwin.netparamwin.show()\n   def showdistparamwin (self):\n     self.baseparamwin.evparamwin.show()\n-    self.baseparamwin.evparamwin.tabs.setCurrentIndex(2)\n+    self.baseparamwin.evparamwin.tabs.setCurrentIndex(1)\n   def showproxparamwin (self):\n     self.baseparamwin.evparamwin.show()\n     self.baseparamwin.evparamwin.tabs.setCurrentIndex(0)\n", "before": "self . baseparamwin . evparamwin . tabs . setCurrentIndex ( 2 )", "after": "self . baseparamwin . evparamwin . tabs . setCurrentIndex ( 1 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:2\", 3, 55, 3, 56], \"1\"]]"}
{"project": "udapi-python", "commit_sha": "cb2539abe259778d76240a1134269c3bdcc0b8bb", "parent_sha": "5b582f6b9a1a705767222c9b628ed4dbfd10186b", "file_path": "udapi/block/ud/fixpunct.py", "project_url": "https://github.com/udapi/udapi-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -198,7 +198,7 @@ class FixPunct(Block):\n         for node in root.descendants[opening_node.ord:]:\n             if node.form == closing_punct:\n                 if nested_level > 0:\n-                    nested_level -= 0\n+                    nested_level -= 1\n                 else:\n                     self._fix_pair(root, opening_node, node)\n                     return\n", "before": "nested_level -= 0", "after": "nested_level -= 1", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0\", 3, 37, 3, 38], \"1\"]]"}
{"project": "transformer-lm", "commit_sha": "295fc96f65fcfa01a00fc921f3ec602ee1a1010f", "parent_sha": "90f9d73acf1733d8078d0d5320216e28e379708a", "file_path": "lm_web_ui/main.py", "project_url": "https://github.com/lopuhin/transformer-lm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,7 +34,7 @@ def index(request):\n     score_words = request.query.get('score_words')\n     score_tokens = request.query.get('score_tokens')\n     if request.query.get('next_token'):\n-        next_top_k = model.get_next_top_k(tokenize(text), top_k=10)\n+        next_top_k = model.get_next_top_k(tokenize(text), top_k=20)\n         next_top_k = [[token, log_prob] for log_prob, token in next_top_k]\n         ctx['next_token_prediction'] = next_top_k\n         ctx['next_token_prediction_csv'] = to_csv_data_url(\n", "before": "next_top_k = model . get_next_top_k ( tokenize ( text ) , top_k = 10 )", "after": "next_top_k = model . get_next_top_k ( tokenize ( text ) , top_k = 20 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:10\", 3, 65, 3, 67], \"20\"]]"}
{"project": "transformer-lm", "commit_sha": "92f9e3f186b00b8569d175b672391ebc0dc09526", "parent_sha": "0eb91bdcce99c0f0ae8085aea0be5bd195f17b08", "file_path": "lm_web_ui/main.py", "project_url": "https://github.com/lopuhin/transformer-lm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ def handle_token_prediction(model, ctx, text):\n \n def handle_text_generation(model, ctx, text):\n     tokens = model.generate_tokens(\n-        tokenize(text), tokens_to_generate=20, top_k=20)\n+        tokenize(text), tokens_to_generate=50, top_k=20)\n     ctx['generated_text'] = model.sp_model.decode_pieces(tokens)\n     # TODO paragraphs\n \n", "before": "tokens = model . generate_tokens ( tokenize ( text ) , tokens_to_generate = 20 , top_k = 20 )", "after": "tokens = model . generate_tokens ( tokenize ( text ) , tokens_to_generate = 50 , top_k = 20 )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:20\", 3, 44, 3, 46], \"50\"]]"}
{"project": "plugin.video.mediathekview", "commit_sha": "92fa567ffa853cb4ec94baa73e06310a00b450c9", "parent_sha": "8cfccdc621d4db097066ca6952598cb4bffb6dd5", "file_path": "resources/lib/kodi/kodiui.py", "project_url": "https://github.com/mediathekview/plugin.video.mediathekview", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -123,7 +123,7 @@ class KodiUI(object):\n         self.show_notification(\n             heading, message, xbmcgui.NOTIFICATION_WARNING, time, sound)\n \n-    def show_error(self, heading, message, time=5000, sound=True):\n+    def show_error(self, heading, message, time=8000, sound=True):\n", "before": "def show_error ( self , heading , message , time = 5000 , sound = True ) : ", "after": "def show_error ( self , heading , message , time = 8000 , sound = True ) : ", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:5000\", 3, 49, 3, 53], \"8000\"]]"}
{"project": "LogESP", "commit_sha": "a46dd01f5c2d23d8830945b99faeef5d40580918", "parent_sha": "5c6f815ea086cddb9a6b605515ac34050639e5f1", "file_path": "daemons/parser/parse.py", "project_url": "https://github.com/dogoncouch/LogESP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -145,7 +145,7 @@ class LiveParser:\n                                 dbtries = 40\n                                 msg = 'LDSI parser thread for ' + filename + \\\n                                         ' got 40 db errors. Event: ' + \\\n-                                        str(ourline[:80]) + \\\n+                                        str(ourline[:120]) + \\\n                                         '... Error: ' + str(err)\n                                 syslog.syslog(syslog.LOG_ERR, msg)\n                             dbtries -= 1\n", "before": "msg = 'LDSI parser thread for ' + filename + ' got 40 db errors. Event: ' + str ( ourline [ : 80 ] ) + '... Error: ' + str ( err )", "after": "msg = 'LDSI parser thread for ' + filename + ' got 40 db errors. Event: ' + str ( ourline [ : 120 ] ) + '... Error: ' + str ( err )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:80\", 3, 54, 3, 56], \"120\"]]"}
{"project": "spotify-skill", "commit_sha": "acb0e18206ffa409aacb3c7713abb14298b87d07", "parent_sha": "210663178e60e6fc0508e3c98b2d5e24673647c5", "file_path": "__init__.py", "project_url": "https://github.com/forslund/spotify-skill", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -279,7 +279,7 @@ class SpotifySkill(CommonPlaySkill):\n         self.__device_list = None\n         self.__devices_fetched = 0\n         self.OAUTH_ID = 1\n-        self.DEFAULT_VOLUME = 65\n+        self.DEFAULT_VOLUME = 80\n         self._playlists = None\n \n     def launch_librespot(self):\n", "before": "self . DEFAULT_VOLUME = 65", "after": "self . DEFAULT_VOLUME = 80", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:65\", 3, 31, 3, 33], \"80\"]]"}
{"project": "digitalocean-backup", "commit_sha": "f720c639e4795878a8dadc823b885d4afbb3d26c", "parent_sha": "d53c5ce559e10ba14e6ed5a6ddead4051a1a0dd3", "file_path": "dobackup/dobackup.py", "project_url": "https://github.com/jotyGill/digitalocean-backup", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -188,7 +188,7 @@ def find_old_backups(manager, older_than):\n     for each_snapshot in manager.get_droplet_snapshots():\n         # print(each_snapshot.name, each_snapshot.created_at, each_snapshot.id)\n         if \"--dobackup--\" in each_snapshot.name:\n-            backed_on = each_snapshot.name[each_snapshot.name.find(\"--dobackup--\") + 15:]\n+            backed_on = each_snapshot.name[each_snapshot.name.find(\"--dobackup--\") + 12:]\n             # print(\"backed_on\", backed_on)\n             backed_on_date = datetime.datetime.strptime(backed_on, \"%Y-%m-%d %H:%M:%S\")\n             if backed_on_date < last_backup_to_keep:\n", "before": "backed_on = each_snapshot . name [ each_snapshot . name . find ( \"--dobackup--\" ) + 15 : ]", "after": "backed_on = each_snapshot . name [ each_snapshot . name . find ( \"--dobackup--\" ) + 12 : ]", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:15\", 3, 86, 3, 88], \"12\"]]"}
{"project": "graphtools", "commit_sha": "9832058fcac4921db563e0938dcdf189fab66a7f", "parent_sha": "aaef51106aa0f32e07fadb45fd31dda3b3ee2787", "file_path": "graphtools/graph.py", "project_url": "https://github.com/KrishnaswamyLab/graphtools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -613,7 +613,7 @@ def Graph(data,\n           thresh=1e-5,\n           n_landmark=None,\n           n_svd=100,\n-          beta=0,\n+          beta=1,\n           gamma=0.5,\n           n_jobs=-1,\n           verbose=False,\n", "before": "beta = 0 ,", "after": "beta = 1 ,", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:0\", 3, 16, 3, 17], \"1\"]]"}
{"project": "graphtools", "commit_sha": "30957685f59ea22cef370204c85a94b8a47fcc19", "parent_sha": "05bf8305f7b16d6716ad4dfe16f45a22e6b57d46", "file_path": "graphtools/graph.py", "project_url": "https://github.com/KrishnaswamyLab/graphtools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1619,7 +1619,7 @@ def Graph(data,\n           knn=5,\n           decay=None,\n           distance='euclidean',\n-          thresh=1e-5,\n+          thresh=0,\n           n_landmark=None,\n           n_svd=100,\n           beta=1,\n", "before": "thresh = 1e-5 ,", "after": "thresh = 0 ,", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Insert\", [\"expression_list\", 3, 18, 3, 23], [\"integer:0\", \"T\"], 0], [\"Delete\", [\"float:1e-5\", 3, 18, 3, 22]]]"}
{"project": "graphtools", "commit_sha": "a9b3d6d97b5e2e346713579919fc7f340da5a242", "parent_sha": "0c884ce3972067bb54eae0df9ca72d7faa465924", "file_path": "graphtools/graphs.py", "project_url": "https://github.com/KrishnaswamyLab/graphtools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -70,7 +70,7 @@ class kNNGraph(DataGraph):\n         knn=5,\n         decay=None,\n         knn_max=None,\n-        search_multiplier=20,\n+        search_multiplier=6,\n         bandwidth=None,\n         bandwidth_scale=1.0,\n         distance=\"euclidean\",\n", "before": "search_multiplier = 20 ,", "after": "search_multiplier = 6 ,", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:20\", 3, 27, 3, 29], \"6\"]]"}
{"project": "python-grader", "commit_sha": "288f390d002f6263e309df0ec89b95b92e17655a", "parent_sha": "06a2659e6f7c956546bab6fde408421eeac4cd85", "file_path": "grader/code_runner.py", "project_url": "https://github.com/kspar/python-grader", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ def read_proc_results(proc, decode):\n     return status, stdout, stderr\n \n def microseconds_passed(time_delta):\n-    return time_delta.microseconds + time_delta.seconds * 10**7\n+    return time_delta.microseconds + time_delta.seconds * 10**6\n \n \n def call_command(cmd, timeout=float('inf'), cwd=None, decode=True, **subproc_options):\n", "before": "return time_delta . microseconds + time_delta . seconds * 10 ** 7", "after": "return time_delta . microseconds + time_delta . seconds * 10 ** 6", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:7\", 3, 63, 3, 64], \"6\"]]"}
{"project": "depot_tools", "commit_sha": "86eb9e75835e3516073f19276f6769101b1df92f", "parent_sha": "239f411a1d749767ac727976b77dcfd45a106663", "file_path": "patch.py", "project_url": "https://github.com/Neozaru/depot_tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -247,7 +247,7 @@ class FilePatchDiff(FilePatchBase):\n     if match:\n       mode = match.group(1)\n       # Only look at owner ACL for executable.\n-      if bool(int(mode[4]) & 4):\n+      if bool(int(mode[4]) & 1):\n         self.svn_properties.append(('svn:executable', '*'))\n \n     # Handle \"--- \"\n", "before": "if bool ( int ( mode [ 4 ] ) & 4 ) : self . svn_properties . append ( ( 'svn:executable' , '*' ) )", "after": "if bool ( int ( mode [ 4 ] ) & 1 ) : self . svn_properties . append ( ( 'svn:executable' , '*' ) )", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:4\", 3, 30, 3, 31], \"1\"]]"}
{"project": "awslimitchecker", "commit_sha": "9d536135deabfe913338eb785250768a1c90924f", "parent_sha": "1029ce36350ed778fa5ec66fa16848d0740cf8d1", "file_path": "awslimitchecker/tests/services/test_rds.py", "project_url": "https://github.com/sstarcher/awslimitchecker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -499,7 +499,7 @@ class Test_RDSService(object):\n \n         usage = sorted(cls.limits['DB snapshots per user'].get_current_usage())\n         assert len(usage) == 1\n-        assert usage[0].get_value() == 4\n+        assert usage[0].get_value() == 2\n         assert usage[0].aws_type == 'AWS::RDS::DBSnapshot'\n \n     def test_find_usage_param_groups(self):\n", "before": "assert usage [ 0 ] . get_value ( ) == 4", "after": "assert usage [ 0 ] . get_value ( ) == 2", "sstub_pattern": "CHANGE_NUMERIC_LITERAL", "edit_script": "[[\"Update\", [\"integer:4\", 3, 40, 3, 41], \"2\"]]"}
{"project": "trac", "commit_sha": "e6c6969246d395cfae8f817229ae59846f46773c", "parent_sha": "c8221cee7eac3dcd8ba12503e281f7a01b6175b0", "file_path": "trac/Href.py", "project_url": "https://github.com/arielnetworks/trac", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ class Href:\n     def query(self, constraints, order=None, desc=0):\n         href = href_join(self.base, 'query')\n         params = []\n-        for field in constraints:\n+        for field in constraints.keys():\n             values = constraints[field]\n             if type(values) != list:\n                 values = [values]\n", "before": "for field in constraints : values = constraints [ field ] if type ( values ) != list : values = [ values ]", "after": "for field in constraints . keys ( ) : values = constraints [ field ] if type ( values ) != list : values = [ values ]", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"for_statement\", 3, 9, 6, 34], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:constraints\", 3, 22, 3, 33], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:keys\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "TracBlockdiag", "commit_sha": "0fe7245dbe9cebd2869dc6d070e1e16de24f94f5", "parent_sha": "9f79756b117e4bccc1dc8b9d30bf9ab270488205", "file_path": "tracblockdiag/diag.py", "project_url": "https://github.com/arielnetworks/TracBlockdiag", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ class BaseBuilder(object):\n     def draw_svg(self, diagram, options):\n         drawer = self.DiagramDraw('SVG', diagram, None, **options)\n         drawer.draw()\n-        return drawer.save()\n+        return drawer.save().encode('utf-8')\n \n     def create_fontmap(self, font):\n         fontmap = FontMap()\n", "before": "return drawer . save ( )", "after": "return drawer . save ( ) . encode ( 'utf-8' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 16, 3, 29], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 16, 3, 29], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 29], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'utf-8'\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "cloud-bdii-provider", "commit_sha": "1be724ee58b8298ef821c0520fb390e1668475e9", "parent_sha": "c14cd43a2b853c9f4deea4ed500791786c380dfc", "file_path": "cloud_bdii/providers/openstack.py", "project_url": "https://github.com/alvarolopez/cloud-bdii-provider", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -120,7 +120,7 @@ class OpenStackProvider(providers.BaseProvider):\n                 continue\n \n             aux = defaults.copy()\n-            aux.update({'template_id': 'resource_tpl#%s' % flavor.name,\n+            aux.update({'template_id': 'resource_tpl#%s' % flavor.name.lower(),\n                         'template_memory': flavor.ram,\n                         'template_cpu': flavor.vcpus})\n             flavors[flavor.id] = aux\n", "before": "aux . update ( { 'template_id' : 'resource_tpl#%s' % flavor . name , 'template_memory' : flavor . ram , 'template_cpu' : flavor . vcpus } )", "after": "aux . update ( { 'template_id' : 'resource_tpl#%s' % flavor . name . lower ( ) , 'template_memory' : flavor . ram , 'template_cpu' : flavor . vcpus } )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 40, 3, 71], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 60, 3, 71], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:lower\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "testinfra", "commit_sha": "81908f0ee9d48f8c8e113d685ee7b441879a0eb4", "parent_sha": "4ab331a82972d5dc7e77c7078fb7847e638bf5be", "file_path": "testinfra/backend/base.py", "project_url": "https://github.com/underdogio/testinfra", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -105,7 +105,7 @@ class BaseBackend(object):\n         cmd = self.run(\n             \"python -c 'import locale;print(locale.getpreferredencoding())'\")\n         if cmd.rc == 0:\n-            encoding = cmd.stdout_bytes.splitlines()[0]\n+            encoding = cmd.stdout_bytes.splitlines()[0].decode(\"ascii\")\n         else:\n             # Python is not installed, we hope the encoding to be the same as\n             # local machine...\n", "before": "encoding = cmd . stdout_bytes . splitlines ( ) [ 0 ]", "after": "encoding = cmd . stdout_bytes . splitlines ( ) [ 0 ] . decode ( \"ascii\" )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 13, 3, 56], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 24, 3, 56], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:\\\"ascii\\\"\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "alipay-python-sdk", "commit_sha": "4b68d6f8552ffbcbaa040c09754f9fe92f7bb7ec", "parent_sha": "83448ecd1a61133c64dba02f7c631b829bd461e0", "file_path": "src/alipay/__init__.py", "project_url": "https://github.com/bowenpay/alipay-python-sdk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -21,7 +21,7 @@ class Alipay(object):\n     def _generate_sign(self, params):\n         src = '&'.join(['%s=%s' % (key, value) for key,\n                         value in sorted(params.items())]) + self.key\n-        return md5(src).hexdigest()\n+        return md5(src.encode('utf-8')).hexdigest()\n \n     def _check_params(self, params, names):\n         if not all(k in params for k in names):\n", "before": "return md5 ( src ) . hexdigest ( )", "after": "return md5 ( src . encode ( 'utf-8' ) ) . hexdigest ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 19, 3, 24], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 19, 3, 24], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:src\", 3, 20, 3, 23], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'utf-8'\", \"T\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 23, 3, 24], 2]]"}
{"project": "opbeat-hipchat", "commit_sha": "60cb44a2ea0713f40fb30bc0e5528699bbc8d4ea", "parent_sha": "291baed1b99acffadb5e3aea7e39c8bd1a812ac1", "file_path": "tests/test_translation.py", "project_url": "https://github.com/yunojuno/opbeat-hipchat", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,7 +41,7 @@ class ActivityTranslatorTestCase(TestCase):\n                 }),\n         ):\n             with open(os.path.join(fixtures_path, fixture_name), 'rb') as f:\n-                fixture = json.loads(f.read())\n+                fixture = json.loads(f.read().decode('utf-8'))\n \n             actual = translator.translate(fixture)\n             self.assertEquals(expected, actual)\n", "before": "fixture = json . loads ( f . read ( ) )", "after": "fixture = json . loads ( f . read ( ) . decode ( 'utf-8' ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 38, 3, 46], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 38, 3, 46], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 38, 3, 46], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'utf-8'\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "gsutil", "commit_sha": "f81fb067416798497494e1ca3f6f2e8fe595a3ea", "parent_sha": "a96150c20d1574030be73f54c4197f858432836f", "file_path": "gslib/third_party/storage_apitools/http_wrapper.py", "project_url": "https://github.com/zalora/gsutil", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -86,7 +86,7 @@ def _Httplib2Debuglevel(http_request, level, http=None):\n   yield\n   httplib2.debuglevel = old_level\n   if http is not None:\n-    for connection_key, old_level in http_levels:\n+    for connection_key, old_level in http_levels.iteritems():\n       if connection_key in http.connections:\n         http.connections[connection_key].set_debuglevel(old_level)\n \n", "before": "for connection_key , old_level in http_levels : if connection_key in http . connections : http . connections [ connection_key ] . set_debuglevel ( old_level )", "after": "for connection_key , old_level in http_levels . iteritems ( ) : if connection_key in http . connections : http . connections [ connection_key ] . set_debuglevel ( old_level )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"for_statement\", 3, 5, 5, 67], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:http_levels\", 3, 38, 3, 49], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:iteritems\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "librosa", "commit_sha": "c023fc9a6f35f2dfa67583f6aaa993b40516820a", "parent_sha": "9ee0d82d9c8a7533257c764423f67d9727e1808b", "file_path": "tests/test_features.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -264,7 +264,7 @@ def test_spectral_rolloff_synthetic():\n         if freq is None:\n             freq = librosa.fft_frequencies(sr=sr, n_fft=n_fft)\n \n-        idx = np.floor(pct * freq.shape[0])\n+        idx = np.floor(pct * freq.shape[0]).astype(int)\n         assert np.allclose(rolloff, freq[idx])\n \n     S = np.ones((1 + n_fft // 2, 10))\n", "before": "idx = np . floor ( pct * freq . shape [ 0 ] )", "after": "idx = np . floor ( pct * freq . shape [ 0 ] ) . astype ( int )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 15, 3, 44], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 15, 3, 44], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 15, 3, 44], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:astype\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"identifier:int\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "blink-qt", "commit_sha": "facb2ac372b23e557b2c6f4ebd06ccd0a6f59beb", "parent_sha": "d15ccabbc9799ec4229bb25898ac89fa9c315ee6", "file_path": "blink/screensharing/vncclient.py", "project_url": "https://github.com/kogmbh/blink-qt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -190,6 +190,6 @@ class VNCClient(QObject):\n \n     def _EH_RFBCutTextEvent(self, event):\n         if self.rfb_client is not None:\n-            self.rfb_client.send_client_cut_text(event.text)\n+            self.rfb_client.send_client_cut_text(event.text.encode('utf8'))\n \n \n", "before": "self . rfb_client . send_client_cut_text ( event . text )", "after": "self . rfb_client . send_client_cut_text ( event . text . encode ( 'utf8' ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 49, 3, 61], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 49, 3, 61], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 50, 3, 60], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'utf8'\", \"T\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 60, 3, 61], 2]]"}
{"project": "acme-tiny", "commit_sha": "71a97aa92f0901d026a39810ad86a61f09e30cae", "parent_sha": "aaf109183891bdd4626976427e4865c744989ff1", "file_path": "tests/test_module.py", "project_url": "https://github.com/nuxi/acme-tiny", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -175,7 +175,7 @@ class TestModule(unittest.TestCase):\n         # make sure the certificate was issued and the contact details were updated\n         out, err = Popen([\"openssl\", \"x509\", \"-text\", \"-noout\"], stdin=PIPE, stdout=PIPE, stderr=PIPE).communicate(crt)\n         self.assertIn(\"Issuer: CN=Fake LE Intermediate\", out.decode(\"utf8\"))\n-        self.assertIn(\"Updated contact details:\\nmailto:devteam@example.com\\nmailto:boss@example.com\", log_string)\n+        self.assertIn(\"Updated contact details:\\nmailto:devteam@example.com\\nmailto:boss@example.com\", log_string.decode(\"utf8\"))\n         # remove logging capture\n         acme_tiny.LOGGER.removeHandler(debug_handler)\n \n", "before": "self . assertIn ( \"Updated contact details:\\nmailto:devteam@example.com\\nmailto:boss@example.com\" , log_string )", "after": "self . assertIn ( \"Updated contact details:\\nmailto:devteam@example.com\\nmailto:boss@example.com\" , log_string . decode ( \"utf8\" ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 22, 3, 115], [\"call\", \"N0\"], 3], [\"Insert\", [\"argument_list\", 3, 22, 3, 115], [\"):)\", \"T\"], 4], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:log_string\", 3, 104, 3, 114], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:\\\"utf8\\\"\", \"T\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 114, 3, 115], 2]]"}
{"project": "librosa", "commit_sha": "8b7792bbb759e3e56f7056a05f91f59c9dd689f3", "parent_sha": "9cea6c19b35c9fb196c593aab44377e070eb09d5", "file_path": "tests/test_onset.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -127,7 +127,7 @@ def test_onset_strength_multi():\n     y, sr = librosa.load(__EXAMPLE_FILE)\n     S = librosa.feature.melspectrogram(y=y, sr=sr)\n \n-    channels = np.linspace(0, S.shape[0], num=5)\n+    channels = np.linspace(0, S.shape[0], num=5).astype(int)\n \n     for lag in [1, 2, 3]:\n         for max_size in [1]:\n", "before": "channels = np . linspace ( 0 , S . shape [ 0 ] , num = 5 )", "after": "channels = np . linspace ( 0 , S . shape [ 0 ] , num = 5 ) . astype ( int )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 16, 3, 49], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 16, 3, 49], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 49], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:astype\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"identifier:int\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "librosa", "commit_sha": "db068b734c6f96b528bac5b7e1eef810030dd414", "parent_sha": "97a8c7e3fd3310c7f4f6b7a81137126c93188655", "file_path": "librosa/util/_nnls.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -150,7 +150,7 @@ def nnls(A, B, **kwargs):\n \n     # Process in blocks:\n     if B.shape[-1] <= n_columns:\n-        return _nnls_lbfgs_block(A, B, **kwargs)\n+        return _nnls_lbfgs_block(A, B, **kwargs).astype(A.dtype)\n \n     x = np.linalg.lstsq(A, B, rcond=None)[0].astype(A.dtype)\n     np.clip(x, 0, None, out=x)\n", "before": "return _nnls_lbfgs_block ( A , B , ** kwargs )", "after": "return _nnls_lbfgs_block ( A , B , ** kwargs ) . astype ( A . dtype )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 16, 3, 49], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 16, 3, 49], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 49], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:astype\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:A\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:dtype\", \"T\"], 2]]"}
{"project": "librosa", "commit_sha": "7077e9e60e169137f4e8e54c57b3f04003a25b40", "parent_sha": "75a5d9db5877ecf2025f31f7e88a9f23315eda9c", "file_path": "librosa/util/_nnls.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -150,7 +150,7 @@ def nnls(A, B, **kwargs):\n \n     # Process in blocks:\n     if B.shape[-1] <= n_columns:\n-        return _nnls_lbfgs_block(A, B, **kwargs)\n+        return _nnls_lbfgs_block(A, B, **kwargs).astype(A.dtype)\n \n     x = np.linalg.lstsq(A, B, rcond=None)[0].astype(A.dtype)\n     np.clip(x, 0, None, out=x)\n", "before": "return _nnls_lbfgs_block ( A , B , ** kwargs )", "after": "return _nnls_lbfgs_block ( A , B , ** kwargs ) . astype ( A . dtype )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 16, 3, 49], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 16, 3, 49], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 49], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:astype\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:A\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:dtype\", \"T\"], 2]]"}
{"project": "pylinac", "commit_sha": "f570f9ecf72fdae7aaa5b07b7ebcf0f9c849b462", "parent_sha": "9e10af15b2652f8249f3b459723b754942d1c110", "file_path": "pylinac/log_analyzer.py", "project_url": "https://github.com/midamo/pylinac", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1140,7 +1140,7 @@ class GammaFluence(Fluence):\n         gamma_map = np.zeros(expected.shape)\n \n         # image gradient in x-direction (leaf movement direction) using sobel filter\n-        img_x = spf.sobel(actual, 1)\n+        img_x = spf.sobel(actual.astype(np.float32), 1)\n \n         # equation: (measurement - reference) / sqrt ( doseTA^2 + distTA^2 * image_gradient^2 )\n         for leaf in range(self._mlc.num_pairs):\n", "before": "img_x = spf . sobel ( actual , 1 )", "after": "img_x = spf . sobel ( actual . astype ( np . float32 ) , 1 )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 37], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 26, 3, 37], [\"):)\", \"T\"], 5], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:actual\", 3, 27, 3, 33], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:astype\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 36, 3, 37], 2], [\"Insert\", \"N3\", [\"identifier:np\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:float32\", \"T\"], 2]]"}
{"project": "stx-config", "commit_sha": "98a176a5af4df16e7e5bea84e06fd3343d3d9e2f", "parent_sha": "46e7ef2b13b1885fadf0878dcd2082a903655e94", "file_path": "controllerconfig/controllerconfig/controllerconfig/configassistant.py", "project_url": "https://github.com/openstack/stx-config", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -702,7 +702,7 @@ class ConfigAssistant():\n         }\n         user_input = prompt_for(\n             \"Configure Distributed Cloud System Controller [y/N]: \", 'n',\n-            lambda text: \"Invalid choice\" if text not in value_mapping\n+            lambda text: \"Invalid choice\" if text.lower() not in value_mapping\n             else None\n         )\n         self.system_dc_role = value_mapping[user_input.lower()]\n", "before": "user_input = prompt_for ( \"Configure Distributed Cloud System Controller [y/N]: \" , 'n' , lambda text : \"Invalid choice\" if text not in value_mapping else None )", "after": "user_input = prompt_for ( \"Configure Distributed Cloud System Controller [y/N]: \" , 'n' , lambda text : \"Invalid choice\" if text . lower ( ) not in value_mapping else None )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 46, 3, 71], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:text\", 3, 46, 3, 50], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:lower\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "cc-utils", "commit_sha": "40504041a141964d41e4c8d1a6522773e2054f9f", "parent_sha": "d579da376afdc4b1c6f6753ace9d40bcfa9c2586", "file_path": "model/container_registry.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -69,7 +69,7 @@ class ContainerRegistryConfig(NamedModelElement, ModelDefaultsMixin):\n         auth_str = f'{self.credentials().username()}:{self.credentials().passwd()}'\n-        auth_str = base64.b64encode(auth_str.encode('utf-8'))\n+        auth_str = base64.b64encode(auth_str.encode('utf-8')).decode('utf-8')\n \n         auths = {\n             host: {'auth': auth_str} for host in self.image_reference_prefixes()\n", "before": "auth_str = base64 . b64encode ( auth_str . encode ( 'utf-8' ) )", "after": "auth_str = base64 . b64encode ( auth_str . encode ( 'utf-8' ) ) . decode ( 'utf-8' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 1, 20, 1, 62], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 1, 20, 1, 62], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 1, 20, 1, 62], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'utf-8'\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "FreeCAD_assembly3", "commit_sha": "b590b577933e87b87442fed02faf5d37fa91350b", "parent_sha": "6c68f0f9015fc85eec15f8f17fbcc023c030d730", "file_path": "freecad/asm3/mover.py", "project_url": "https://github.com/realthunder/FreeCAD_assembly3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ class AsmMovingPart(object):\n     def __init__(self, moveInfo, element, moveElement):\n         hierarchy = moveInfo.HierarchyList\n         info = moveInfo.ElementInfo\n-        self.objs = [h.Assembly for h in reversed(hierarchy)]\n+        self.objs = [h.Assembly.getLinkedObject(True) for h in reversed(hierarchy)]\n         self.assembly = resolveAssembly(info.Parent)\n         self.viewObject = self.assembly.Object.ViewObject\n         self.info = info\n", "before": "self . objs = [ h . Assembly for h in reversed ( hierarchy ) ]", "after": "self . objs = [ h . Assembly . getLinkedObject ( True ) for h in reversed ( hierarchy ) ]", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"list_comprehension\", 3, 21, 3, 62], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 22, 3, 32], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:getLinkedObject\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"true:True\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "mask-rcnn.pytorch", "commit_sha": "b4f14f6601fbd1669092f28eb3b52aabe09d83a0", "parent_sha": "8deeac1301ae28728ea014cc0321cc11f2402e37", "file_path": "lib/model/rpn/proposal_target_layer_cascade_pose_mask.py", "project_url": "https://github.com/wkentaro/mask-rcnn.pytorch", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -213,7 +213,7 @@ class _ProposalTargetLayer(nn.Module):\n             rois_batch[i,:,0] = i\n \n             gt_rois_batch[i] = gt_boxes[i][gt_assignment[i][keep_inds]]\n-            gt_poses_keep[i] = gt_poses[i][gt_assignment[i][keep_inds]]\n+            gt_poses_keep[i] = gt_poses[i][gt_assignment[i][keep_inds].cpu()]\n \n             # cropped to bbox boundaries and resized to neural network output size\n             # use masks_weights to select valid masks: foreground and rounded box area > 0\n", "before": "gt_poses_keep [ i ] = gt_poses [ i ] [ gt_assignment [ i ] [ keep_inds ] ]", "after": "gt_poses_keep [ i ] = gt_poses [ i ] [ gt_assignment [ i ] [ keep_inds ] . cpu ( ) ]", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"subscript\", 3, 32, 3, 72], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 44, 3, 71], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:cpu\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "Playlist-Length", "commit_sha": "a6face01b6895bfafc4c34fc3dd4b89ce1a036dc", "parent_sha": "c298d36396e2787aeb36d336ef71033abb027c72", "file_path": "playlist_length/main.py", "project_url": "https://github.com/karansthr/Playlist-Length", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ def probe(vid_file_path):\n     pipe = sp.Popen(command, stdout=sp.PIPE, stderr=sp.STDOUT)\n     out, error = pipe.communicate()\n     if not error:\n-        return json.loads(out)\n+        return json.loads(out.decode('utf-8'))\n \n \n def duration(vid_file_path):\n", "before": "return json . loads ( out )", "after": "return json . loads ( out . decode ( 'utf-8' ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 31], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 26, 3, 31], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:out\", 3, 27, 3, 30], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'utf-8'\", \"T\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 30, 3, 31], 2]]"}
{"project": "ADCPy", "commit_sha": "aba6efbe1d920afeff14ed034e17e32cc2e2f1c7", "parent_sha": "8122cd96d921d7f58dd8cc90b5e3675ec72511de", "file_path": "ADCPcdf2ncEPIC.py", "project_url": "https://github.com/mmartini-usgs/ADCPy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -495,7 +495,7 @@ def inst2earth(adcpo, reverse=False, fixed_orientation=False, force=False):\n     r = adcpo['roll_deg'] * deg2rad\n     p = np.arctan(np.tan(adcpo['pitch_deg'] * deg2rad) * np.cos(r))\n     h = adcpo['heading_deg'] * deg2rad\n-    if adcpo['config']['orientation'] == 'up': \n+    if adcpo['config']['orientation'].lower() == 'up': \n         r += np.pi\n     ch = np.cos(h)\n     sh = np.sin(h)\n", "before": "if adcpo [ 'config' ] [ 'orientation' ] == 'up' : r += np . pi", "after": "if adcpo [ 'config' ] [ 'orientation' ] . lower ( ) == 'up' : r += np . pi", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 8, 3, 46], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 8, 3, 38], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:lower\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "pyMaid", "commit_sha": "88f6e95df08ec51c3ed12e9b6115b6b12c8a8fe2", "parent_sha": "ee4fb104ceabd51917a67a40a09f23b30ca25041", "file_path": "pymaid/fetch.py", "project_url": "https://github.com/schlegelp/pyMaid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2096,7 +2096,7 @@ def get_connectors(x, relation_type=None, tags=None, remote_instance=None):\n                                'edition_time'])\r\n \r\n     # Add tags\r\n-    df['tags'] = df.connector_id.map(data['tags'])\r\n+    df['tags'] = df.connector_id.astype(str).map(data['tags'])\r\n \r\n     # Map hardwire connector type ID to their type name\r\n     # ATTENTION: \"attachment\" can be part of any connector type\r\n", "before": "df [ 'tags' ] = df . connector_id . map ( data [ 'tags' ] )", "after": "df [ 'tags' ] = df . connector_id . astype ( str ) . map ( data [ 'tags' ] )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"attribute\", 3, 18, 3, 37], [\"call\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 18, 3, 37], [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 18, 3, 33], 0], [\"Move\", \"N1\", [\".:.\", 3, 33, 3, 34], 1], [\"Insert\", \"N1\", [\"identifier:astype\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:str\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "bluesteel", "commit_sha": "fd40c6e0ad045af8af81920ced5c5355799f8365", "parent_sha": "eebd0c53574ee54c996fa03bedf009562c25a660", "file_path": "app/logic/gitrepo/models/GitCommitModel.py", "project_url": "https://github.com/imvu/bluesteel", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -23,6 +23,6 @@ class GitCommitEntry(models.Model):\n         obj['hash'] = self.commit_hash\n         obj['short_hash'] = str(self.commit_hash)[0:20]\n         obj['author'] = self.author.as_object()\n-        obj['author_date'] = self.author_date\n+        obj['author_date'] = self.author_date.isoformat()\n         obj['committer'] = self.committer.as_object()\n         return obj\n", "before": "obj [ 'author_date' ] = self . author_date", "after": "obj [ 'author_date' ] = self . author_date . isoformat ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 46], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 30, 3, 46], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:isoformat\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "angr", "commit_sha": "7a12e2996f171d9e231fe1fd3cf234aebb4e847c", "parent_sha": "56f2baa9622cae9cc3403ab2af389d14a7b4ec13", "file_path": "angr/analyses/code_location.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -62,5 +62,5 @@ class CodeLocation(object):\n         return hash((self.simrun_addr, self.stmt_idx, self.sim_procedure))\n \n     def _store_kwargs(self, **kwargs):\n-        for k, v in kwargs:\n+        for k, v in kwargs.iteritems():\n             self.info[k] = v\n", "before": "for k , v in kwargs : self . info [ k ] = v", "after": "for k , v in kwargs . iteritems ( ) : self . info [ k ] = v", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"for_statement\", 3, 9, 4, 29], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:kwargs\", 3, 21, 3, 27], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:iteritems\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "pyoidc", "commit_sha": "d1afd32e5359751059a1790f0a3c8d8b8b9ecbf0", "parent_sha": "35ed422d6b507e2f10b0acbada56cb9d4df95743", "file_path": "src/oic/oic/provider.py", "project_url": "https://github.com/qaavi/pyoidc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -821,7 +821,7 @@ class Provider(AProvider):\n \n         assert req[\"grant_type\"] == \"authorization_code\"\n \n-        _access_code = req[\"code\"]\n+        _access_code = req[\"code\"].replace(' ', '+')\n         # assert that the code is valid\n         if self.sdb.is_revoked(_access_code):\n             return self._error(error=\"access_denied\", descr=\"Token is revoked\")\n", "before": "_access_code = req [ \"code\" ]", "after": "_access_code = req [ \"code\" ] . replace ( ' ' , '+' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 35], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 24, 3, 35], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:' '\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"string:'+'\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "SentEval", "commit_sha": "1d4064e81fb27e2a898d79cf69c563689514fd30", "parent_sha": "0a3a29d27960fd24ffb01926d027ae4c56b3e85b", "file_path": "senteval/tools/relatedness.py", "project_url": "https://github.com/vrindaprabhu/SentEval", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -107,7 +107,7 @@ class RelatednessPytorch(object):\n             all_costs = []\n             for i in range(0, len(X), self.batch_size):\n                 # forward\n-                idx = torch.cuda.LongTensor(permutation[i:i + self.batch_size])\n+                idx = torch.cuda.LongTensor(permutation[i:i + self.batch_size].tolist())\n                 Xbatch = Variable(X.index_select(0, idx))\n                 ybatch = Variable(y.index_select(0, idx))\n                 output = self.model(Xbatch)\n", "before": "idx = torch . cuda . LongTensor ( permutation [ i : i + self . batch_size ] )", "after": "idx = torch . cuda . LongTensor ( permutation [ i : i + self . batch_size ] . tolist ( ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 44, 3, 80], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 44, 3, 80], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 45, 3, 79], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:tolist\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"):)\", 3, 79, 3, 80], 1]]"}
{"project": "dexpy", "commit_sha": "4c72a10f92c1ff899543141c3185fab3278c1a40", "parent_sha": "349e6ecdc337e8a4ff0784e9762e08e91b8354b2", "file_path": "dexpy/glucose.py", "project_url": "https://github.com/winemug/dexpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -26,7 +26,7 @@ class GlucoseValue():\n         return GlucoseValue(dt, wt, st, value, trend)\n \n     def equals(self, other):\n-        secondDifference = abs(self.st - other.st)\n+        secondDifference = abs((self.st - other.st).total_seconds())\n         if secondDifference >= 240:\n             return False\n         if self.trend != other.trend:\n", "before": "secondDifference = abs ( self . st - other . st )", "after": "secondDifference = abs ( ( self . st - other . st ) . total_seconds ( ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 31, 3, 51], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 31, 3, 51], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"parenthesized_expression\", \"N3\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:total_seconds\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Move\", \"N3\", [\"binary_operator\", 3, 32, 3, 50], 1], [\"Move\", \"N3\", [\"):)\", 3, 50, 3, 51], 2]]"}
{"project": "python_planet", "commit_sha": "a2f77e62af2be169c1ee30562687062ee715311e", "parent_sha": "18e5fd4e50c46edd774b4b53664f036dbf168ce3", "file_path": "planet/control/CActivity.py", "project_url": "https://github.com/haobin12358/python_planet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -139,7 +139,7 @@ class CActivity(CUser):\n                 if magic_box_join:\n                     magic_apply.fill('current_price', magic_box_join.MBJcurrentPrice)\n                     # \u62c6\u76d2\u8bb0\u5f55\n-                    mbp_history = MagicBoxOpen.query.filter_by_({'MBJid': magic_box_join.MBJid}).limit(4).all()\n+                    mbp_history = MagicBoxOpen.query.filter_by_({'MBJid': magic_box_join.MBJid}).order_by(MagicBoxOpen.createtime.desc()).limit(4).all()\n                     magic_apply.fill('open_history', mbp_history)\n \n         elif ac_type == 'guess_num':\n", "before": "mbp_history = MagicBoxOpen . query . filter_by_ ( { 'MBJid' : magic_box_join . MBJid } ) . limit ( 4 ) . all ( )", "after": "mbp_history = MagicBoxOpen . query . filter_by_ ( { 'MBJid' : magic_box_join . MBJid } ) . order_by ( MagicBoxOpen . createtime . desc ( ) ) . limit ( 4 ) . all ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 35, 3, 97], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 35, 3, 97], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 35, 3, 97], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:order_by\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"call\", \"N2\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N3\", [\"attribute\", \"N5\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:desc\", \"T\"], 2], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"):)\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:MagicBoxOpen\", \"T\"], 0], [\"Insert\", \"N5\", [\".:.\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:createtime\", \"T\"], 2]]"}
{"project": "python_planet", "commit_sha": "9db54a189d920048fe92ba55978e1135c1ea50ca", "parent_sha": "a39cfdcb6025031592f3056bfc549484b399c308", "file_path": "planet/control/CGuessNum.py", "project_url": "https://github.com/haobin12358/python_planet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -63,7 +63,7 @@ class CGuessNum(COrder):\n         usid = request.user.id\n         join_history = GuessNum.query.filter_(\n             GuessNum.USid == usid,\n-            cast(GuessNum.createtime, Date) == form.date.data,\n+            cast(GuessNum.createtime, Date) == form.date.data.date(),\n             GuessNum.isdelete == False\n         ).first_()\n         if not join_history:\n", "before": "join_history = GuessNum . query . filter_ ( GuessNum . USid == usid , cast ( GuessNum . createtime , Date ) == form . date . data , GuessNum . isdelete == False ) . first_ ( )", "after": "join_history = GuessNum . query . filter_ ( GuessNum . USid == usid , cast ( GuessNum . createtime , Date ) == form . date . data . date ( ) , GuessNum . isdelete == False ) . first_ ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 13, 3, 62], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 48, 3, 62], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:date\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "python_planet", "commit_sha": "46ff24f2f930973e6b43ca1a05023e9b13d0e507", "parent_sha": "b2771ef8c55ab7e9c6c7f7aa314f68dffbf10612", "file_path": "planet/control/CPlay.py", "project_url": "https://github.com/haobin12358/python_planet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1647,7 +1647,7 @@ class CPlay():\n \n     def _opayno(self):\n         opayno = self.wx_pay.nonce_str\n-        pp = PlayPay.query.filter_by(PPpayno=opayno, isdelete=False)\n+        pp = PlayPay.query.filter_by(PPpayno=opayno, isdelete=False).first()\n         if pp:\n             return self._opayno()\n         return opayno\n", "before": "pp = PlayPay . query . filter_by ( PPpayno = opayno , isdelete = False )", "after": "pp = PlayPay . query . filter_by ( PPpayno = opayno , isdelete = False ) . first ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 14, 3, 69], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 14, 3, 69], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 14, 3, 69], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:first\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "pyfpdf", "commit_sha": "c24345d9315d9c2ea522cf474552bdb37ab43da5", "parent_sha": "ddca4cf6b3499c8c5265a94493f5810d401cc675", "file_path": "fpdf/template.py", "project_url": "https://github.com/scott1028/pyfpdf", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ class Template:\n         self.texts[self.pg_no] = {}\n         \n     def __setitem__(self, name, value):\n-        if name in self.keys:\n+        if name.lower() in self.keys:\n             if not PY3K and isinstance(value, unicode):\n                 value = value.encode(\"latin1\",\"ignore\")\n             elif value is None:\n", "before": "if name in self . keys : if not PY3K and isinstance ( value , unicode ) : value = value . encode ( \"latin1\" , \"ignore\" ) elif value is None : ", "after": "if name . lower ( ) in self . keys : if not PY3K and isinstance ( value , unicode ) : value = value . encode ( \"latin1\" , \"ignore\" ) elif value is None : ", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 29], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:name\", 3, 12, 3, 16], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:lower\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "sympy", "commit_sha": "5f644a591088bdb80893b66f7837086355245bae", "parent_sha": "f616b7fcc3d287157ce9991afd6760c173559580", "file_path": "sympy/physics/quantum/tests/test_grover.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -88,4 +88,4 @@ def test_grover():\n     nqubits = 4\n     basis_states = superposition_basis(nqubits)\n     expected = (-13*basis_states)/64 + 264*IntQubit(2, nqubits)/256\n-    assert apply_grover(return_one_on_two, 4).simplify() == qapply(expected)\n+    assert apply_grover(return_one_on_two, 4).simplify() == qapply(expected).simplify()\n", "before": "assert apply_grover ( return_one_on_two , 4 ) . simplify ( ) == qapply ( expected )", "after": "assert apply_grover ( return_one_on_two , 4 ) . simplify ( ) == qapply ( expected ) . simplify ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 61, 3, 77], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 61, 3, 77], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 61, 3, 77], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:simplify\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "sympy", "commit_sha": "48f4bcf9dbfdeb6a25c5b02e67a7bcda4d7a31e6", "parent_sha": "118d75541c967b7a52ad648354d9f19f7a090a85", "file_path": "sympy/solvers/ode.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2809,7 +2809,7 @@ def checkodesol(ode, sol, func=None, order='auto', solve_for_func=True):\n             else:\n                 testnum += 1\n                 continue\n-            ss = simplify(s)\n+            ss = simplify(s.rewrite(exp))\n             if ss:\n                 # with the new numer_denom in power.py, if we do a simple\n                 # expansion then testnum == 0 verifies all solutions.\n", "before": "ss = simplify ( s )", "after": "ss = simplify ( s . rewrite ( exp ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 29], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 26, 3, 29], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:s\", 3, 27, 3, 28], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:rewrite\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:exp\", \"T\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 28, 3, 29], 2]]"}
{"project": "sympy", "commit_sha": "a8ded05108119afcd438af19300737f9c0583874", "parent_sha": "0f0939e4fa0d18ad392a468c0082c75b1a868fd1", "file_path": "sympy/solvers/solveset.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2902,7 +2902,7 @@ def _solve_using_known_values(result, solver):\n                             base = value_res.base_set\n                             imgset_yes = (dummy_n, base)\n                 # update eq with everything that is known so far\n-                eq2 = eq.subs(res)\n+                eq2 = eq.subs(res).expand()\n                 unsolved_syms = _unsolved_syms(eq2, sort=True)\n                 if not unsolved_syms:\n                     if res:\n", "before": "eq2 = eq . subs ( res )", "after": "eq2 = eq . subs ( res ) . expand ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 23, 3, 35], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 23, 3, 35], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 23, 3, 35], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:expand\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "sympy", "commit_sha": "6071543fbe8b09a47d8676098cede7c4f743cd72", "parent_sha": "4213a94ccdb51dd5e76546edbbb793601f4cd38b", "file_path": "sympy/polys/polytools.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -6610,7 +6610,7 @@ def cancel(f, *gens, **args):\n \n     if not isinstance(f, (tuple, Tuple)):\n         if f.is_Number or isinstance(f, Relational) or not isinstance(f, Expr):\n-            return f\n+            return f.expand()\n         f = factor_terms(f, radical=True)\n         p, q = f.as_numer_denom()\n \n", "before": "return f", "after": "return f . expand ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 13, 3, 21], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:f\", 3, 20, 3, 21], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:expand\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "flower", "commit_sha": "28ff9aee1f8d3feec772295b833f15b989281f6b", "parent_sha": "10cef872a7d4a4022dfdb02ff705b434f94103a7", "file_path": "flower/views/auth.py", "project_url": "https://github.com/Rocket-amphora/flower", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -103,7 +103,7 @@ class GithubLoginHandler(BaseHandler, tornado.auth.OAuth2Mixin):\n                 'OAuth authentication error: %s' % str(response)))\n             return\n \n-        future.set_result(json.loads(response.body))\n+        future.set_result(json.loads(response.body.decode('utf-8')))\n \n     def get_auth_http_client(self):\n         return httpclient.AsyncHTTPClient()\n", "before": "future . set_result ( json . loads ( response . body ) )", "after": "future . set_result ( json . loads ( response . body . decode ( 'utf-8' ) ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 37, 3, 52], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 37, 3, 52], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 38, 3, 51], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'utf-8'\", \"T\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 51, 3, 52], 2]]"}
{"project": "py-etl", "commit_sha": "6f7fa3daa10ae63d549c3c03b5ce9d01761169b1", "parent_sha": "94987b821f3e18aff236eb8f6f39487899bb06aa", "file_path": "etl.py", "project_url": "https://github.com/edushare-at/py-etl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -645,7 +645,7 @@ class ODBC_Connector (object) :\n                 return msg\n             if 'idnDistributionPassword' in ld_update :\n                 self.ldap.extend.standard.modify_password \\\n-                    (dn, new_password = rw ['passwort'])\n+                    (dn, new_password = rw ['passwort'].encode ('utf-8'))\n     # end def sync_to_ldap\n \n     def to_ldap (self, item, dbkey) :\n", "before": "self . ldap . extend . standard . modify_password ( dn , new_password = rw [ 'passwort' ] )", "after": "self . ldap . extend . standard . modify_password ( dn , new_password = rw [ 'passwort' ] . encode ( 'utf-8' ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 26, 3, 56], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 41, 3, 56], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'utf-8'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "py-etl", "commit_sha": "487b7f52bff37a538e9665b07252a1ff5abd8a5d", "parent_sha": "6f7fa3daa10ae63d549c3c03b5ce9d01761169b1", "file_path": "etl.py", "project_url": "https://github.com/edushare-at/py-etl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -495,7 +495,7 @@ class ODBC_Connector (object) :\n             fields      = self.fields [tbl]\n             self.cursor.execute \\\n                 ('select %s from %s' % (','.join (fields), self.table))\n-            for n, row in enumerate (self.cursor) :\n+            for n, row in enumerate (self.cursor.fetchall ()) :\n                 if (n % 100) == 0 or self.args.verbose :\n                     self.log.debug (n)\n                 idx = fields.index ('pk_uniqueid')\n", "before": "for n , row in enumerate ( self . cursor ) : if ( n % 100 ) == 0 or self . args . verbose : self . log . debug ( n ) idx = fields . index ( 'pk_uniqueid' )", "after": "for n , row in enumerate ( self . cursor . fetchall ( ) ) : if ( n % 100 ) == 0 or self . args . verbose : self . log . debug ( n ) idx = fields . index ( 'pk_uniqueid' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 37, 3, 50], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 37, 3, 50], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 38, 3, 49], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:fetchall\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"):)\", 3, 49, 3, 50], 1]]"}
{"project": "ykdl", "commit_sha": "0e17ee6faf2a3a00ed09e5a8adf3d91d98961332", "parent_sha": "94daacc0b2d6d4ef43f3e64f7e00b4a982f46557", "file_path": "src/you_get/downloader/xiami.py", "project_url": "https://github.com/YU-zreo/ykdl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ def location_dec(str):\n def xiami_download_lyric(lrc_url, file_name, output_dir):\n     lrc = get_html(lrc_url, faker = True)\n     if len(lrc) > 0:\n-        with open(output_dir + \"/\" + file_name.replace('/', '-') + '.lrc', 'w', encoding='utf-8') as x:\n+        with open(output_dir + \"/\" + file_name.replace('/', '-').replace('?', '-') + '.lrc', 'w', encoding='utf-8') as x:\n             x.write(lrc)\n \n def xiami_download_pic(pic_url, file_name, output_dir):\n", "before": "with open ( output_dir + \"/\" + file_name . replace ( '/' , '-' ) + '.lrc' , 'w' , encoding = 'utf-8' ) as x : x . write ( lrc )", "after": "with open ( output_dir + \"/\" + file_name . replace ( '/' , '-' ) . replace ( '?' , '-' ) + '.lrc' , 'w' , encoding = 'utf-8' ) as x : x . write ( lrc )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 38, 3, 65], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 38, 3, 65], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 38, 3, 65], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'?'\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:'-'\", \"T\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4]]"}
{"project": "flutterfuck", "commit_sha": "859b9c3185a27631254e8e2f3e0d2edb0ec7cdb0", "parent_sha": "4df92b693d1f8e1e6268c2ac42c651fa5c28c153", "file_path": "willie/coretasks.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -429,7 +429,7 @@ def auth_proceed(bot, trigger):\n     sasl_token = '\\0'.join((sasl_username, sasl_username,\n                            bot.config.core.sasl_password))\n     # Spec says we do a base 64 encode on the SASL stuff\n-    bot.write(('AUTHENTICATE', base64.b64encode(sasl_token)))\n+    bot.write(('AUTHENTICATE', base64.b64encode(sasl_token.encode('utf-8'))))\n \n \n @willie.module.event('903')\n", "before": "bot . write ( ( 'AUTHENTICATE' , base64 . b64encode ( sasl_token ) ) )", "after": "bot . write ( ( 'AUTHENTICATE' , base64 . b64encode ( sasl_token . encode ( 'utf-8' ) ) ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 48, 3, 60], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 48, 3, 60], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:sasl_token\", 3, 49, 3, 59], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'utf-8'\", \"T\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 59, 3, 60], 2]]"}
{"project": "flutterfuck", "commit_sha": "04e655990abd2a338d3ed7986dab77ddd92a4bbf", "parent_sha": "fe47145a5e3a55510f2f6d9378b037f2b8118783", "file_path": "willie/modules/url.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -186,7 +186,7 @@ def check_callbacks(willie, trigger, url, run=True):\n \n def find_title(url):\n     \"\"\"Return the title for the given URL.\"\"\"\n-    content = web.get(url)\n+    content = web.get(url).decode('utf8')\n     # Some cleanup that I don't really grok, but was in the original, so\n     # we'll keep it (with the compiled regexes made global) for now.\n     content = title_tag_data.sub(r'<\\1title>', content)\n", "before": "content = web . get ( url )", "after": "content = web . get ( url ) . decode ( 'utf8' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 15, 3, 27], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 15, 3, 27], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 15, 3, 27], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'utf8'\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "edx-platform", "commit_sha": "cbcb1059a31087e2c479eaf85f6d7c5eb87f46a6", "parent_sha": "76a04fa805466afc4a7e8dae402b383ca8394c2e", "file_path": "lms/djangoapps/django_comment_client/forum/tests.py", "project_url": "https://github.com/easy-edx/edx-platform", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -285,7 +285,7 @@ class UserProfileTestCase(ModuleStoreTestCase):\n             StringEndsWithMatcher('/users/{}/active_threads'.format(self.profiled_user.id)),\n             data=None,\n             params=PartialDictMatcher({\n-                \"course_id\": self.course.id,\n+                \"course_id\": self.course.id.to_deprecated_string(),\n                 \"page\": params.get(\"page\", 1),\n                 \"per_page\": views.THREADS_PER_PAGE\n                 }),\n", "before": "params = PartialDictMatcher ( { \"course_id\" : self . course . id , \"page\" : params . get ( \"page\" , 1 ) , \"per_page\" : views . THREADS_PER_PAGE } ) ,", "after": "params = PartialDictMatcher ( { \"course_id\" : self . course . id . to_deprecated_string ( ) , \"page\" : params . get ( \"page\" , 1 ) , \"per_page\" : views . THREADS_PER_PAGE } ) ,", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"pair\", 3, 17, 3, 44], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 30, 3, 44], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:to_deprecated_string\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "nci-webtools-dceg-linkage", "commit_sha": "9d53eae4cb0344c1464206813ccf3ef652313648", "parent_sha": "76d0e2d63a0c7adbc1bd08bbdb3ce4e0ced5cfe4", "file_path": "LDlink/LDassoc.py", "project_url": "https://github.com/CBIIT/nci-webtools-dceg-linkage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -584,7 +584,7 @@ def calculate_assoc(file, region, pop, request, web, myargs):\n \tout_prox=[]\n \tfor i in range(len(out_raw)):\n \t\tfor j in range(len(out_raw[i])):\n-\t\t\tcol=out_raw[i][j].strip().split(\"\\t\")\n+\t\t\tcol=out_raw[i][j].decode('utf-8').strip().split(\"\\t\")\n \t\t\tcol[6]=int(col[6])\n \t\t\tcol[7]=float(col[7])\n \t\t\tcol[8]=float(col[8])\n", "before": "col = out_raw [ i ] [ j ] . strip ( ) . split ( \"\\t\" )", "after": "col = out_raw [ i ] [ j ] . decode ( 'utf-8' ) . strip ( ) . split ( \"\\t\" )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"attribute\", 3, 8, 3, 27], [\"call\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 8, 3, 27], [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 8, 3, 21], 0], [\"Move\", \"N1\", [\".:.\", 3, 21, 3, 22], 1], [\"Insert\", \"N1\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'utf-8'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "sipa", "commit_sha": "12d4bfb895051001cfff62a2c5b03d26cf617eb7", "parent_sha": "8c861a1c248233344bf0413f617a42acd0dfe28e", "file_path": "sipa/blueprints/usersuite.py", "project_url": "https://github.com/agdsn/sipa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -157,7 +157,7 @@ def generate_epc_qr_code(details: PaymentDetails, months):\n     return EPC_FORMAT.format(\n         bic=details.bic,\n         recipient=details.recipient,\n-        iban=details.iban,\n+        iban=details.iban.replace(' ', ''),\n         amount=months * MEMBERSHIP_CONTRIBUTION / 100,\n         purpose=details.purpose)\n \n", "before": "return EPC_FORMAT . format ( bic = details . bic , recipient = details . recipient , iban = details . iban , amount = months * MEMBERSHIP_CONTRIBUTION / 100 , purpose = details . purpose )", "after": "return EPC_FORMAT . format ( bic = details . bic , recipient = details . recipient , iban = details . iban . replace ( ' ' , '' ) , amount = months * MEMBERSHIP_CONTRIBUTION / 100 , purpose = details . purpose )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 9, 3, 26], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 14, 3, 26], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:' '\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"string:''\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "regulations-site", "commit_sha": "cf371d893a82e6a11d92e6c3d749b8a8eaf28b18", "parent_sha": "61a9e32f8159797efea2374a00a8fd7ee8c5e131", "file_path": "regulations/views/chrome_breakaway.py", "project_url": "https://github.com/eregs/regulations-site", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,7 +25,7 @@ class ChromeBreakawayView(ChromeView):\n         meta = api_reader.ApiReader().layer('meta', context['reg_part'],\n                                             context['version'])\n         context['meta'] = meta[context['reg_part']][0]\n-        context['formatted_id'] = label_to_text(context['label_id'])\n+        context['formatted_id'] = label_to_text(context['label_id'].split('-'))\n \n         content = self.content(context)\n         if isinstance(content, HttpResponse):  # error occurred\n", "before": "context [ 'formatted_id' ] = label_to_text ( context [ 'label_id' ] )", "after": "context [ 'formatted_id' ] = label_to_text ( context [ 'label_id' ] . split ( '-' ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 48, 3, 69], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 48, 3, 69], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 49, 3, 68], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:split\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'-'\", \"T\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 68, 3, 69], 2]]"}
{"project": "taskgrader", "commit_sha": "a4cdd140042d759fccbe77e240d08d94d099548d", "parent_sha": "4348f94ca7478a3b914daf0252cd5eeea4e49733", "file_path": "taskgrader.py", "project_url": "https://github.com/France-ioi/taskgrader", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -492,7 +492,7 @@ def evaluation(evaluationParams):\n \n     # We load a \"preprocessing\" JSON node or file\n     try:\n-        varData.update(json.load(open(os.path.join(evaluationParams['taskPath'], 'defaultParams.json'), 'r')))\n+        varData.update(json.load(open(os.path.join(evaluationParams['taskPath'].replace('$ROOT_PATH', evaluationParams['rootPath']), 'defaultParams.json'), 'r')))\n     except:\n         pass\n     if evaluationParams.has_key('extraParams'):\n", "before": "varData . update ( json . load ( open ( os . path . join ( evaluationParams [ 'taskPath' ] , 'defaultParams.json' ) , 'r' ) ) )", "after": "varData . update ( json . load ( open ( os . path . join ( evaluationParams [ 'taskPath' ] . replace ( '$ROOT_PATH' , evaluationParams [ 'rootPath' ] ) , 'defaultParams.json' ) , 'r' ) ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 51, 3, 103], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 51, 3, 103], [\",:,\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 52, 3, 80], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'$ROOT_PATH'\", \"T\"], 1], [\"Move\", \"N2\", [\",:,\", 3, 80, 3, 81], 2], [\"Insert\", \"N2\", [\"subscript\", \"N3\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4], [\"Insert\", \"N3\", [\"identifier:evaluationParams\", \"T\"], 0], [\"Insert\", \"N3\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N3\", [\"string:'rootPath'\", \"T\"], 2], [\"Insert\", \"N3\", [\"]:]\", \"T\"], 3]]"}
{"project": "databroker", "commit_sha": "b0b64c3b2d41f40db997434e6535f8442ddd74bb", "parent_sha": "b90bbd9fa6dca48961655dc375caa7f6fc5d2da5", "file_path": "replay/pipeline/pipeline.py", "project_url": "https://github.com/bluesky/databroker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -290,7 +290,7 @@ class DataMuggler(QtCore.QObject):\n             elif col_fill_type is None:\n                 tmp_dict[col_name] = False\n             else:\n-                algnable = self._dataframe[col_name][ref_index].notnull().all()\n+                algnable = self._dataframe[col_name].fillna(col_fill_type)[ref_index].notnull().all()\n                 tmp_dict[col_name] = bool(algnable)\n         return tmp_dict\n \n", "before": "else : algnable = self . _dataframe [ col_name ] [ ref_index ] . notnull ( ) . all ( )", "after": "else : algnable = self . _dataframe [ col_name ] . fillna ( col_fill_type ) [ ref_index ] . notnull ( ) . all ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"subscript\", 3, 28, 3, 64], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 28, 3, 53], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:fillna\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:col_fill_type\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "Pyglet", "commit_sha": "bd676393e37e4e05a971a5af932288c14b78e14a", "parent_sha": "18bcf616482e19850af46e8e1a9f03966032beb8", "file_path": "pyglet/font/quartz.py", "project_url": "https://github.com/adamlwgriffiths/Pyglet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -261,7 +261,7 @@ class QuartzFont(base.Font):\n         if traits in fonts:\n             return fonts[traits]\n         # Otherwise try to find a font with some of the traits.\n-        for (t, f) in fonts:\n+        for (t, f) in fonts.items():\n             if traits & t:\n                 return f\n         # Otherwise try to return a regular font.\n", "before": "for ( t , f ) in fonts : if traits & t : return f", "after": "for ( t , f ) in fonts . items ( ) : if traits & t : return f", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"for_statement\", 3, 9, 5, 25], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:fonts\", 3, 23, 3, 28], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:items\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "django-xadmin", "commit_sha": "df3cf9addc382e12d5c63c3d46c5a421086ea6c2", "parent_sha": "dbff87d1fe75ea1979ddd47ae495944377cba372", "file_path": "xadmin/views/edit.py", "project_url": "https://github.com/scrapinghub/django-xadmin", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -120,7 +120,7 @@ class ModelFormAdminView(ModelAdminView):\n \n         for klass in db_field.__class__.mro():\n             if klass in self.formfield_overrides:\n-                return self.formfield_overrides[klass]\n+                return self.formfield_overrides[klass].copy()\n \n         return {}\n \n", "before": "return self . formfield_overrides [ klass ]", "after": "return self . formfield_overrides [ klass ] . copy ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 17, 3, 55], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 24, 3, 55], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:copy\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "sweettooth", "commit_sha": "4ee7c6e1862515be1bad9da5c8bf70ed933d1376", "parent_sha": "c64a72cd857adae33b7ba221af04973ec6b4a366", "file_path": "sweettooth/review/views.py", "project_url": "https://github.com/magcius/sweettooth", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -107,7 +107,7 @@ class ReviewVersionView(DetailView):\n         previous_versions = CodeReview.objects.filter(version__extension=self.object.extension)\n \n         # Other reviews on the same version\n-        previous_reviews = self.object.reviews\n+        previous_reviews = self.object.reviews.all()\n \n         context.update(dict(previous_versions=previous_versions,\n                             previous_reviews=previous_reviews))\n", "before": "previous_reviews = self . object . reviews", "after": "previous_reviews = self . object . reviews . all ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 47], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 28, 3, 47], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:all\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "skylibs", "commit_sha": "f4a0e3a5a505a4589e0c73ce6d9fbe2bc21d682d", "parent_sha": "141cfc392169dc4400307c1381579740b616fd6d", "file_path": "envmap/environmentmap.py", "project_url": "https://github.com/soravux/skylibs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -163,7 +163,7 @@ class EnvironmentMap:\n         eTmp = EnvironmentMap(targetDim, targetFormat)\n         dx, dy, dz, valid = eTmp.worldCoordinates()\n         u, v = self.world2image(dx, dy, dz)\n-        self.format_ = targetFormat\n+        self.format_ = targetFormat.lower()\n         self.interpolate(u, v, valid)\n \n     def rotate(self, format, input_):\n", "before": "self . format_ = targetFormat", "after": "self . format_ = targetFormat . lower ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 36], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:targetFormat\", 3, 24, 3, 36], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:lower\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "aes-lac-2018", "commit_sha": "8fb93819351a9693687b572d49ce0390902b5a1f", "parent_sha": "1b49d3412867e25cd55fba40b5264dd685a87d34", "file_path": "data/utils.py", "project_url": "https://github.com/igormq/aes-lac-2018", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -32,7 +32,7 @@ def create_manifest(data_path, tag, ordered=True):\n         for wav_path in file_paths:\n             transcript_path = wav_path.replace('/wav/', '/txt/').replace('.wav', '.txt')\n             sample = os.path.abspath(wav_path) + ',' + os.path.abspath(transcript_path) + '\\n'\n-            file.write(sample)\n+            file.write(sample.encode('utf-8'))\n             counter += 1\n             _update_progress(counter / float(size))\n     print('\\n')\n", "before": "file . write ( sample )", "after": "file . write ( sample . encode ( 'utf-8' ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 23, 3, 31], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 23, 3, 31], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:sample\", 3, 24, 3, 30], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'utf-8'\", \"T\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 30, 3, 31], 2]]"}
{"project": "pfsspy", "commit_sha": "5f74b7be26a74e0ce7eccc91570e6317b3e3ffde", "parent_sha": "9457f3b94f6a57e6fd60edf60205c4d25e2ffb51", "file_path": "pfsspy/tracing.py", "project_url": "https://github.com/dstansby/pfsspy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -93,7 +93,7 @@ class FortranTracer(Tracer):\n         from streamtracer import VectorGrid\n \n         # The indexing order on the last index is (phi, s, r)\n-        vectors = output.bg\n+        vectors = output.bg.copy()\n \n         # Correct s direction for coordinate system distortion\n         sqrtsg = output.grid._sqrtsg_correction\n", "before": "vectors = output . bg", "after": "vectors = output . bg . copy ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 28], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 19, 3, 28], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:copy\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "bitcoinperf", "commit_sha": "ff6e67e8061e7f94e8fa14f00d6115b8d77e39b0", "parent_sha": "ee637b584f134eb47c16bdf19807d4dad577d1e3", "file_path": "runner/run_bench.py", "project_url": "https://github.com/chaincodelabs/bitcoinperf", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -336,7 +336,7 @@ def run_benches():\n                 send_to_slack_attachment(\n                     \"Microbench exited with code %s\" %\n                     microbench_ps.returncode,\n-                    {}, text=microbench_output, success=False)\n+                    {}, text=microbench_output.decode(), success=False)\n \n             microbench_lines = [\n                 # Skip the first line (header)\n", "before": "send_to_slack_attachment ( \"Microbench exited with code %s\" % microbench_ps . returncode , { } , text = microbench_output , success = False )", "after": "send_to_slack_attachment ( \"Microbench exited with code %s\" % microbench_ps . returncode , { } , text = microbench_output . decode ( ) , success = False )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 25, 3, 47], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:microbench_output\", 3, 30, 3, 47], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "pybrake", "commit_sha": "cfc0a432a7240f1a4f5d3dfa976417df2fba276a", "parent_sha": "0c9f3ad3de1cdfc0ae17e97e0d05119186c96366", "file_path": "pybrake/notifier.py", "project_url": "https://github.com/airbrake/pybrake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -346,7 +346,7 @@ class Notifier:\n         ctx = self._context.copy()\n \n         versions = ctx[\"versions\"]\n-        for name, mod in sys.modules.items():\n+        for name, mod in sys.modules.copy().items():\n             if name.startswith(\"_\"):\n                 continue\n             if hasattr(mod, \"__version__\"):\n", "before": "for name , mod in sys . modules . items ( ) : if name . startswith ( \"_\" ) : continue if hasattr ( mod , \"__version__\" ) : ", "after": "for name , mod in sys . modules . copy ( ) . items ( ) : if name . startswith ( \"_\" ) : continue if hasattr ( mod , \"__version__\" ) : ", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"attribute\", 3, 26, 3, 43], [\"call\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 26, 3, 43], [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 26, 3, 37], 0], [\"Move\", \"N1\", [\".:.\", 3, 37, 3, 38], 1], [\"Insert\", \"N1\", [\"identifier:copy\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "knowledge-repo", "commit_sha": "162d06547043572eebd1b855ea2c9ef3e6ebe042", "parent_sha": "055c45ad83cdb1cb97f965b93b02b5dd05e25980", "file_path": "knowledge_repo/app/utils/render.py", "project_url": "https://github.com/RasaHQ/knowledge-repo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ def render_post(post):\n     def intra_knowledge_urlmapper(name, url):\n         if name == 'a' and url.startswith('knowledge:'):\n-            return url_for('render.render', markdown=url.split('knowledge:')[1])\n+            return url_for('render.render', markdown=url.split('knowledge:')[1]).replace('%2F', '/')  # Temporary fix before url revamp\n         return None\n \n     html = render_post_header(post) + (post if isinstance(post, KnowledgePost) else post.kp).to_string('html',\n", "before": "return url_for ( 'render.render' , markdown = url . split ( 'knowledge:' ) [ 1 ] )", "after": "return url_for ( 'render.render' , markdown = url . split ( 'knowledge:' ) [ 1 ] ) . replace ( '%2F' , '/' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 2, 20, 2, 81], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 2, 20, 2, 81], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 2, 20, 2, 81], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'%2F'\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:'/'\", \"T\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4]]"}
{"project": "cb4", "commit_sha": "a4d4688bb20b17fa2782e0fd06220afea4ecfec5", "parent_sha": "a29f6e8a754826be04b6f5f3ef124c6ecbfd2f2a", "file_path": "vj4/util/pwhash.py", "project_url": "https://github.com/joint-online-judge/cb4", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,7 +35,7 @@ def gen_salt(byte_length: int=20):\n @argmethod.wrap\n def hash_vj2(uname: str, password: str, salt: str):\n   password_md5 = _md5(password)\n-  mixed_sha1 = _sha1(_md5(uname + password_md5) +\n+  mixed_sha1 = _sha1(_md5(uname.lower() + password_md5) +\n                      salt +\n                      _sha1(password_md5 + salt))\n   return _HASH_TYPE_VJ2 + '|' + _b64encode(uname) + '|' + mixed_sha1\n", "before": "mixed_sha1 = _sha1 ( _md5 ( uname + password_md5 ) + salt + _sha1 ( password_md5 + salt ) )", "after": "mixed_sha1 = _sha1 ( _md5 ( uname . lower ( ) + password_md5 ) + salt + _sha1 ( password_md5 + salt ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 27, 3, 47], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:uname\", 3, 27, 3, 32], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:lower\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "examples", "commit_sha": "c66593f1699ece14a4a2f4d314f1afb03c6793d9", "parent_sha": "4ef2d4d0c8524372d0047e050065edcac665ce1a", "file_path": "mnist/main.py", "project_url": "https://github.com/jazzsaxmafia/examples", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -100,7 +100,7 @@ def test():\n         output = model(data)\n         test_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss\n         pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n-        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n+        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n \n     test_loss /= len(test_loader.dataset)\n     print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n", "before": "correct += pred . eq ( target . data . view_as ( pred ) ) . cpu ( ) . sum ( )", "after": "correct += pred . eq ( target . data . view_as ( pred ) ) . long ( ) . cpu ( ) . sum ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 20, 3, 54], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 20, 3, 54], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 20, 3, 54], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:long\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "repobee", "commit_sha": "e61742b2100c5d6346bc1c955524e6802d47e6a4", "parent_sha": "ed4179dec9488224f372e8e4ab94810ef847f9a4", "file_path": "tests/integration_tests/integration_tests.py", "project_url": "https://github.com/repobee/repobee", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -234,7 +234,7 @@ def update_repo(repo_name, filename, text):\n         url_with_token = (\n             proj.web_url.replace(\n                 \"https://\", \"https://oauth2:{}@\".format(TOKEN)\n-            )\n+            ).replace(BASE_DOMAIN, LOCAL_DOMAIN)\n             + \".git\"\n         )\n         clone_proc = subprocess.run(\n", "before": "url_with_token = ( proj . web_url . replace ( \"https://\" , \"https://oauth2:{}@\" . format ( TOKEN ) ) + \".git\" )", "after": "url_with_token = ( proj . web_url . replace ( \"https://\" , \"https://oauth2:{}@\" . format ( TOKEN ) ) . replace ( BASE_DOMAIN , LOCAL_DOMAIN ) + \".git\" )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 1, 13, 3, 14], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 1, 13, 3, 14], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 1, 13, 3, 14], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"identifier:BASE_DOMAIN\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:LOCAL_DOMAIN\", \"T\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4]]"}
{"project": "reconfigure", "commit_sha": "6b9043acb2ebc631a33b81e23de02802f8921622", "parent_sha": "9477af58276415c5e46aaedc253e1259cb620394", "file_path": "reconfigure/items/netatalk.py", "project_url": "https://github.com/predat/reconfigure", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -18,7 +18,7 @@ class ShareData (BoundData):\n     def template(self):\n         return Node(\n             'share',\n-            *[PropertyNode(x, y) for x, y in zip(ShareData.fields, ShareData.defaults)]\n+            *[PropertyNode(x.replace(' ', '_'), y) for x, y in zip(ShareData.fields, ShareData.defaults)]\n         )\n \n \n", "before": "return Node ( 'share' , * [ PropertyNode ( x , y ) for x , y in zip ( ShareData . fields , ShareData . defaults ) ] )", "after": "return Node ( 'share' , * [ PropertyNode ( x . replace ( ' ' , '_' ) , y ) for x , y in zip ( ShareData . fields , ShareData . defaults ) ] )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 27, 3, 33], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 27, 3, 33], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 27, 3, 33], [\"):)\", \"T\"], 5], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:x\", 3, 28, 3, 29], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:' '\", \"T\"], 1], [\"Move\", \"N2\", [\",:,\", 3, 29, 3, 30], 2], [\"Insert\", \"N2\", [\"string:'_'\", \"T\"], 3], [\"Move\", \"N2\", [\"):)\", 3, 32, 3, 33], 4]]"}
{"project": "sympy", "commit_sha": "336231d97c2aff307a2f9505d8792a123fbe201d", "parent_sha": "e0eb63b02cb6706b57396b76ff9c240a08c471cb", "file_path": "release/fabfile.py", "project_url": "https://github.com/grannydatasoup/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ def vagrant():\n     # connect to the port-forwarded ssh\n     env.hosts = ['%s:%s' % (vc['HostName'], vc['Port'])]\n     # use vagrant ssh key\n-    env.key_filename = vc['IdentityFile']\n+    env.key_filename = vc['IdentityFile'].strip('\"')\n     # Forward the agent if specified:\n     env.forward_agent = vc.get('ForwardAgent', 'no') == 'yes'\n \n", "before": "env . key_filename = vc [ 'IdentityFile' ]", "after": "env . key_filename = vc [ 'IdentityFile' ] . strip ( '\"' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 5, 3, 42], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 24, 3, 42], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:strip\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'\\\"'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "incubator-airflow", "commit_sha": "e4cca0de2cb6a69fa46107f085554611cf2c405c", "parent_sha": "f8185f9d85e3adadf67b42f26eff8342b304a9df", "file_path": "airflow/contrib/operators/gcs_to_bq.py", "project_url": "https://github.com/brandsoulmates/incubator-airflow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -120,7 +120,7 @@ class GoogleCloudStorageToBigQueryOperator(BaseOperator):\n         bq_hook = BigQueryHook(bigquery_conn_id=self.bigquery_conn_id,\n                                delegate_to=self.delegate_to)\n \n-        schema_fields = self.schema_fields if self.schema_fields else json.loads(gcs_hook.download(self.bucket, self.schema_object))\n+        schema_fields = self.schema_fields if self.schema_fields else json.loads(gcs_hook.download(self.bucket, self.schema_object).decode(\"utf-8\"))\n         source_uris = ['gs://{}/{}'.format(self.bucket, schema_object) for schema_object in self.source_objects]\n         conn = bq_hook.get_conn()\n         cursor = conn.cursor()\n", "before": "schema_fields = self . schema_fields if self . schema_fields else json . loads ( gcs_hook . download ( self . bucket , self . schema_object ) )", "after": "schema_fields = self . schema_fields if self . schema_fields else json . loads ( gcs_hook . download ( self . bucket , self . schema_object ) . decode ( \"utf-8\" ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 82, 3, 132], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 82, 3, 132], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 82, 3, 132], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:\\\"utf-8\\\"\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "peerpalette", "commit_sha": "f3fa23316b710beb0950321271f7bca522e28a25", "parent_sha": "957938cc3eca7365385c04d7edc8c0d3fbeb3bbf", "file_path": "peerpalette.com/CleanupOnlineUsers.py", "project_url": "https://github.com/zaidka/peerpalette", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -11,7 +11,7 @@ import datetime\n class CleanupOnlineUsers(webapp.RequestHandler):\n   def get(self):\n     online_users = models.OnlineUser.all(keys_only = True).fetch(3000)\n-    users_status = memcache.get_multi([config.MEMCACHE_LAST_BEEN_ONLINE(u.id_or_name()) for u in online_users])\n+    users_status = memcache.get_multi([config.MEMCACHE_LAST_BEEN_ONLINE(u.id_or_name()) for u in online_users]).values()\n \n     todel = []\n     for u in online_users:\n", "before": "users_status = memcache . get_multi ( [ config . MEMCACHE_LAST_BEEN_ONLINE ( u . id_or_name ( ) ) for u in online_users ] )", "after": "users_status = memcache . get_multi ( [ config . MEMCACHE_LAST_BEEN_ONLINE ( u . id_or_name ( ) ) for u in online_users ] ) . values ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 20, 3, 112], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 20, 3, 112], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 20, 3, 112], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:values\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "xos-1", "commit_sha": "48f8503113969e312163678edc924312ea35f3c4", "parent_sha": "97238a0461cc043807a271e6251d6ec3465e3254", "file_path": "plstackapi/planetstack/views/deployment_networks.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -18,7 +18,7 @@ class DeploymentNetworkListCreate(APIView):\n         if 'auth' not in data:\n             return Response(status=status.HTTP_400_BAD_REQUEST)        \n         elif 'deployment_network' in data:\n-            deployment = add_deployment_network(data['auth'], data['deployment_network'])\n+            deployment = add_deployment_network(data['auth'], data['deployment_network'].get('name'))\n             serializer = DeploymentNetworkSerializer(deployment)\n             return Response(serializer.data, status=status.HTTP_201_CREATED)\n         else:\n", "before": "deployment = add_deployment_network ( data [ 'auth' ] , data [ 'deployment_network' ] )", "after": "deployment = add_deployment_network ( data [ 'auth' ] , data [ 'deployment_network' ] . get ( 'name' ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 48, 3, 90], [\"call\", \"N0\"], 3], [\"Insert\", [\"argument_list\", 3, 48, 3, 90], [\"):)\", \"T\"], 4], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 63, 3, 89], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:get\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'name'\", \"T\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 89, 3, 90], 2]]"}
{"project": "xos-1", "commit_sha": "072f08ad35e1885d3477992355d4aabff434627a", "parent_sha": "c3933b98b975e5d56f3f6d9e9b8e83fd84bde64b", "file_path": "xos/synchronizers/vpn/steps/sync_vpntenant.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -55,7 +55,7 @@ class SyncVPNTenant(SyncInstanceUsingAnsible):\n         script.write(\"\\\" > login.up\\n\")\n         script.write(\"printf \\\"\")\n         for line in tenant.ca_crt:\n-            script.write(line + r\"\\n\")\n+            script.write(line.rstrip() + r\"\\n\")\n         script.write(\"\\\" > ca.crt\\n\")\n         # make sure openvpn is installed\n         script.write(\"apt-get update\\n\")\n", "before": "script . write ( line + r\"\\n\" )", "after": "script . write ( line . rstrip ( ) + r\"\\n\" )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 26, 3, 38], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:line\", 3, 26, 3, 30], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:rstrip\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "prior-engine", "commit_sha": "3eb3efae7289ae4240c3eb26ae6186e52e0695fc", "parent_sha": "d0fa5f883cec5ebf0e7aa9720cfded7b4af61ec4", "file_path": "multiply_prior_engine/vegetation_prior_creator.py", "project_url": "https://github.com/multiply-org/prior-engine", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1110,7 +1110,7 @@ class VegetationPriorCreator(PriorCreator):\n         time = self.date\n         doystr = time.strftime('%j')\n \n-        if self.ptype == 'database':\n+        if self.ptype.lower() == 'database':\n             # 0. Setup Processing\n             # filenames = self.CombineTiles2Virtualfile(variables, doystr)\n             filenames = self.CombineTiles2Virtualfile(self.variable, doystr)\n", "before": "if self . ptype == 'database' : filenames = self . CombineTiles2Virtualfile ( self . variable , doystr )", "after": "if self . ptype . lower ( ) == 'database' : filenames = self . CombineTiles2Virtualfile ( self . variable , doystr )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 36], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 12, 3, 22], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:lower\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "askbot-devel", "commit_sha": "7b7b7c9b1b8c5d5995d512ea759a04699bcdfa81", "parent_sha": "5cbe3177031222ac7734e25418dc0c5a5847c40d", "file_path": "askbot/models/post.py", "project_url": "https://github.com/kingctan/askbot-devel", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -586,7 +586,7 @@ class Post(models.Model):\n         user_filter = models.Q(is_superuser=True) | models.Q(status='m')\n         if askbot_settings.GROUPS_ENABLED:\n             user_filter = user_filter & models.Q(groups__in=self.groups.all())\n-        return User.objects.filter(user_filter)\n+        return User.objects.filter(user_filter).distinct()\n \n     def get_previous_answer(self, user=None):\n", "before": "return User . objects . filter ( user_filter )", "after": "return User . objects . filter ( user_filter ) . distinct ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 16, 3, 48], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 16, 3, 48], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 48], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:distinct\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "MANTHIS-terminal", "commit_sha": "cffd2c057d8c94f2e2d647371c96fb2279a73909", "parent_sha": "b6a25136903291246385c603420d183f048e9938", "file_path": "Main.py", "project_url": "https://github.com/MMeent/MANTHIS-terminal", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -62,7 +62,7 @@ def afrekenClick():\n     scan = pymfrc.scan(2)\n     id = str(scan[:4])\n     seed = str(scan[-12:])\n-    new_seed = str(random.randrange(0, 2**31))\n+    new_seed = str(random.randrange(0, 2**31)).rjust(12, '0')\n \n     print(\"id \" + id)\n     print(\"hash \" + seed)\n", "before": "new_seed = str ( random . randrange ( 0 , 2 ** 31 ) )", "after": "new_seed = str ( random . randrange ( 0 , 2 ** 31 ) ) . rjust ( 12 , '0' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 16, 3, 47], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 16, 3, 47], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 47], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:rjust\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"integer:12\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:'0'\", \"T\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4]]"}
{"project": "snabb-api-backend", "commit_sha": "f3fbbebcd4f97ec715bda344c507ffbb1c8736fa", "parent_sha": "058d663a7e96b89b5bed4e73e67da0ddcf5a8b58", "file_path": "snabb/deliveries/models.py", "project_url": "https://github.com/SnabbHQ/snabb-api-backend", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ from django.db import models\n def _create_hash():\n     \"\"\"This function generate 10 character long hash\"\"\"\n     hash_value = hashlib.sha1()\n-    hash_value.update(str(time.time()))\n+    hash_value.update(str(time.time()).encode('utf8'))\n     return hash_value.hexdigest()[:-20]\n \n \n", "before": "hash_value . update ( str ( time . time ( ) ) )", "after": "hash_value . update ( str ( time . time ( ) ) . encode ( 'utf8' ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 23, 3, 39], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 23, 3, 39], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 23, 3, 39], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'utf8'\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "xadmin", "commit_sha": "db1327d2590f25d51a76aa72ad101c3a9d27af93", "parent_sha": "bced97554c03929e6ea74812837cfe3e37ca2648", "file_path": "xadmin/widgets.py", "project_url": "https://github.com/zhqin9/xadmin", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -54,7 +54,7 @@ class AdminSelectWidget(forms.Select):\n     @property\n     def media(self):\n         return vendor('select.js', 'select.css', 'xadmin.widget.select.js') + \\\n-            Media(js=[static('xadmin/vendor/select2/select2_locale_%s.js' % get_language())])\n+            Media(js=[static('xadmin/vendor/select2/select2_locale_%s.js' % get_language().replace('_','-'))])\n \n \n class AdminSplitDateTime(forms.SplitDateTimeWidget):\n", "before": "return vendor ( 'select.js' , 'select.css' , 'xadmin.widget.select.js' ) + Media ( js = [ static ( 'xadmin/vendor/select2/select2_locale_%s.js' % get_language ( ) ) ] )", "after": "return vendor ( 'select.js' , 'select.css' , 'xadmin.widget.select.js' ) + Media ( js = [ static ( 'xadmin/vendor/select2/select2_locale_%s.js' % get_language ( ) . replace ( '_' , '-' ) ) ] )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 77, 3, 91], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 77, 3, 91], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 77, 3, 91], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'_'\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:'-'\", \"T\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4]]"}
{"project": "Cura", "commit_sha": "4d418a7c1a94ddfe11a3f3e6b252821b9e077d73", "parent_sha": "7dbafa06d1ae2b53e77726dee45662d721470ccb", "file_path": "cura/ExtruderManager.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -36,7 +36,7 @@ class ExtruderManager(QObject):\n         if not UM.Application.getInstance().getGlobalContainerStack():\n             return None #No active machine, so no active extruder.\n         try:\n-            return self._extruder_trains[UM.Application.getInstance().getGlobalContainerStack().getId()][str(self._active_extruder_index)]\n+            return self._extruder_trains[UM.Application.getInstance().getGlobalContainerStack().getBottom().getId()][str(self._active_extruder_index)]\n         except KeyError: #Extruder index could be -1 if the global tab is selected, or the entry doesn't exist if the machine definition is wrong.\n             return None\n \n", "before": "return self . _extruder_trains [ UM . Application . getInstance ( ) . getGlobalContainerStack ( ) . getId ( ) ] [ str ( self . _active_extruder_index ) ]", "after": "return self . _extruder_trains [ UM . Application . getInstance ( ) . getGlobalContainerStack ( ) . getBottom ( ) . getId ( ) ] [ str ( self . _active_extruder_index ) ]", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"attribute\", 3, 42, 3, 94], [\"call\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 42, 3, 94], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 42, 3, 94], [\"identifier:getBottom\", \"T\"], 2], [\"Move\", \"N0\", [\"attribute\", 3, 42, 3, 94], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "Cura", "commit_sha": "3df1bc4e62c302721d89974838104c948cea6a0e", "parent_sha": "8ebc75e09a5e6df4860389448ef049002ec1db60", "file_path": "plugins/CuraEngineBackend/StartSliceJob.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -174,7 +174,7 @@ class StartSliceJob(Job):\n         message = self._slice_message.addRepeatedMessage(\"extruders\")\n         message.id = int(stack.getMetaDataEntry(\"position\"))\n         for key in stack.getAllKeys():\n-            setting = message.addRepeatedMessage(\"settings\")\n+            setting = message.getMessage(\"settings\").addRepeatedMessage(\"settings\")\n             setting.name = key\n             setting.value = str(stack.getProperty(key, \"value\")).encode(\"utf-8\")\n             Job.yieldThread()\n", "before": "setting = message . addRepeatedMessage ( \"settings\" )", "after": "setting = message . getMessage ( \"settings\" ) . addRepeatedMessage ( \"settings\" )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"attribute\", 3, 23, 3, 49], [\"call\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 23, 3, 49], [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:message\", 3, 23, 3, 30], 0], [\"Move\", \"N1\", [\".:.\", 3, 30, 3, 31], 1], [\"Insert\", \"N1\", [\"identifier:getMessage\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:\\\"settings\\\"\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "RatticWeb", "commit_sha": "e41da1c1c6887004ad2b988b1bd31f185905b385", "parent_sha": "732b5509f0b8e15babd5c8fc205cec5a419a6844", "file_path": "cred/models.py", "project_url": "https://github.com/efornal/RatticWeb", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -116,7 +116,7 @@ class CredChangeQManager(models.Manager):\n         return self.get_or_create(cred=cred)\n \n     def for_user(self, user):\n-        return self.filter(cred__group__in=user.groups.all())\n+        return self.filter(cred__group__in=user.groups.all()).filter(cred__is_deleted=False)\n \n class CredChangeQ(models.Model):\n     objects = CredChangeQManager()\n", "before": "return self . filter ( cred__group__in = user . groups . all ( ) )", "after": "return self . filter ( cred__group__in = user . groups . all ( ) ) . filter ( cred__is_deleted = False )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 16, 3, 62], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 16, 3, 62], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 62], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:filter\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"keyword_argument\", \"N2\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:cred__is_deleted\", \"T\"], 0], [\"Insert\", \"N2\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N2\", [\"false:False\", \"T\"], 2]]"}
{"project": "flocker", "commit_sha": "663dadaf8f0e241ff72cebf8f56fdbfe777c6aa4", "parent_sha": "6f7bfc70e64740664a2c804f4e02c950f2426785", "file_path": "admin/aws.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -149,7 +149,7 @@ def perform_copy_s3_keys(dispatcher, intent):\n         # We are explicit about Content-Type here, since the upload tool\n         # isn't smart enough to set the right Content-Type.\n         destination_metadata = source_key.metadata\n-        for extention, content_type in EXTENSION_MIME_TYPES:\n+        for extention, content_type in EXTENSION_MIME_TYPES.items():\n             if key.endswith(extention):\n                 destination_metadata['Content-Type'] = content_type\n                 break\n", "before": "for extention , content_type in EXTENSION_MIME_TYPES : if key . endswith ( extention ) : destination_metadata [ 'Content-Type' ] = content_type break", "after": "for extention , content_type in EXTENSION_MIME_TYPES . items ( ) : if key . endswith ( extention ) : destination_metadata [ 'Content-Type' ] = content_type break", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"for_statement\", 3, 9, 6, 22], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:EXTENSION_MIME_TYPES\", 3, 40, 3, 60], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:items\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "flocker", "commit_sha": "394833a2afbfe67de1e948cea1eaa7dda9bcf859", "parent_sha": "7a9a0e6bdbfc385e8f71b4e1bba1820dccc95206", "file_path": "flocker/apiclient/test/test_client.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -769,7 +769,7 @@ class FlockerClientTests(make_clientv1_tests()):\n                                         for manifestation\n                                         in node.manifestations.values()},\n                                  devices={})\n-                       for node in deployment.nodes]\n+                       for node in deployment.nodes.values()]\n         self.cluster_state_service.apply_changes(node_states)\n \n     def get_configuration_tag(self):\n", "before": "for manifestation in node . manifestations . values ( ) } , devices = { } ) for node in deployment . nodes ] self . cluster_state_service . apply_changes ( node_states ) def get_configuration_tag ( self ) : ", "after": "for manifestation in node . manifestations . values ( ) } , devices = { } ) for node in deployment . nodes . values ( ) ] self . cluster_state_service . apply_changes ( node_states ) def get_configuration_tag ( self ) : ", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 28, 3, 52], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 36, 3, 52], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:values\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "flocker", "commit_sha": "1e1d5a5765045c0cf22945246e0b04ebcf7f6e7b", "parent_sha": "9a89d51a1f73474ed0c68e7d713012857810dcce", "file_path": "flocker/control/test/test_generations.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ class GenerationTrackerTests(TestCase):\n-        deployments = related_deployments_strategy(6)\n+        deployments = related_deployments_strategy(6).example()\n         tracker_under_test = GenerationTracker(4)\n         for d in deployments:\n             tracker_under_test.insert_latest(d)\n", "before": "deployments = related_deployments_strategy ( 6 )", "after": "deployments = related_deployments_strategy ( 6 ) . example ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 0, 23, 0, 54], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 0, 23, 0, 54], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 0, 23, 0, 54], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:example\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "PyMySQL", "commit_sha": "64529927144f0122c86309813af007e97511974a", "parent_sha": "24a5552821f3298a2f0b9225102a082fb1c647ac", "file_path": "pymysql/cursors.py", "project_url": "https://github.com/fanout/PyMySQL", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -110,7 +110,7 @@ class Cursor(object):\n                 #Worst case it will throw a Value error\n                 escaped_args = conn.escape(args)\n \n-            query = query % escaped_args\n+            query = query.decode(charset) % escaped_args\n \n         result = 0\n         try:\n", "before": "query = query % escaped_args", "after": "query = query . decode ( charset ) % escaped_args", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 21, 3, 41], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:query\", 3, 21, 3, 26], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:charset\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "pyload.plugins", "commit_sha": "ad3312c62b2442a9824cb58cd2dcfad8cdfe817d", "parent_sha": "cfdac1567f8b4e47a6def11010a0a80473fe29c7", "file_path": "module/plugins/hoster/YoupornCom.py", "project_url": "https://github.com/vuolter/pyload.plugins", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -47,7 +47,7 @@ class YoupornCom(Hoster):\n             self.download_html()\n \n         file_name_pattern = r\".*<title>(.*) - Free Porn Videos - YouPorn.com Lite \\(BETA\\)</title>.*\"\n-        return re.search(file_name_pattern, self.html).group(1).replace(\"&amp;\", \"&\") + '.flv'\n+        return re.search(file_name_pattern, self.html).group(1).replace(\"&amp;\", \"&\").replace(\"/\",\"\") + '.flv'\n \n     def file_exists(self):\n", "before": "return re . search ( file_name_pattern , self . html ) . group ( 1 ) . replace ( \"&amp;\" , \"&\" ) + '.flv'", "after": "return re . search ( file_name_pattern , self . html ) . group ( 1 ) . replace ( \"&amp;\" , \"&\" ) . replace ( \"/\" , \"\" ) + '.flv'", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 16, 3, 86], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 16, 3, 86], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 86], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:\\\"/\\\"\", \"T\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:\\\"\\\"\", \"T\"], 3], [\"Insert\", \"N1\", [\"):)\", \"T\"], 4]]"}
{"project": "h", "commit_sha": "8ff45462c3202a6fdef6df7b534689d5b8c235e4", "parent_sha": "017a64c408920821b1f2c90d8c0a75ef3302db9b", "file_path": "h/accounts/schemas.py", "project_url": "https://github.com/project-star/h", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,7 +34,7 @@ def email_exists(node, value):\n     user = User.get_by_email(value)\n     if not user:\n         msg = _('We have no user with the email address \"{}\". Try correcting '\n-                'this address or try another.')\n+                'this address or try another.').format(value)\n         raise colander.Invalid(node, msg)\n \n \n", "before": "msg = _ ( 'We have no user with the email address \"{}\". Try correcting ' 'this address or try another.' )", "after": "msg = _ ( 'We have no user with the email address \"{}\". Try correcting ' 'this address or try another.' ) . format ( value )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 2, 15, 3, 48], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 2, 15, 3, 48], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 2, 15, 3, 48], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:format\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"identifier:value\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "requests-html", "commit_sha": "aea39709e64fc4306ee905b4cfda8533ae136afa", "parent_sha": "fff407e2ed5556e6d2a335745b7cc6c69e76bcff", "file_path": "requests_html.py", "project_url": "https://github.com/wuqiangroy/requests-html", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -254,7 +254,7 @@ class HTML(BaseParser):\n                 except TimeoutError:\n                     pass\n \n-        html = HTML(url=self.url, html=content, default_encoding=DEFAULT_ENCODING)\n+        html = HTML(url=self.url, html=content.encode(DEFAULT_ENCODING), default_encoding=DEFAULT_ENCODING)\n         self.__dict__.update(html.__dict__)\n \n \n", "before": "html = HTML ( url = self . url , html = content , default_encoding = DEFAULT_ENCODING )", "after": "html = HTML ( url = self . url , html = content . encode ( DEFAULT_ENCODING ) , default_encoding = DEFAULT_ENCODING )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 35, 3, 47], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:content\", 3, 40, 3, 47], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:DEFAULT_ENCODING\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "script.skin.helper.service", "commit_sha": "0e0da9d680b16df66b9fe2f00f3f561ee47e7f07", "parent_sha": "8ff8cf0d028a3efddf7d4bf20b0c2759c59168e7", "file_path": "resources/lib/PluginContent.py", "project_url": "https://github.com/mgonzales71/script.skin.helper.service", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1315,7 +1315,7 @@ def getCast(movie=None,tvshow=None,movieset=None,episode=None,downloadThumbs=Fal\n             tmdbdetails = artutils.getTmdbDetails(movie,None,\"movie\",\"\",True)\n         elif tvshow and not allCast and not itemId:\n             tmdbdetails = artutils.getTmdbDetails(tvshow,None,\"tv\",\"\",True)\n-        if tmdbdetails:\n+        if tmdbdetails.get(\"cast\"):\n             allCast = eval(tmdbdetails.get(\"cast\"))\n         \n         #optional: download missing actor thumbs\n", "before": "if tmdbdetails : allCast = eval ( tmdbdetails . get ( \"cast\" ) )", "after": "if tmdbdetails . get ( \"cast\" ) : allCast = eval ( tmdbdetails . get ( \"cast\" ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 52], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:tmdbdetails\", 3, 12, 3, 23], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:get\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:\\\"cast\\\"\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "plyer", "commit_sha": "6e1f86c75fe9391dad50c752c1d176584e4c86b1", "parent_sha": "5a754cc0b017500272ae3414e47f811e970a9907", "file_path": "plyer/platforms/linux/filechooser.py", "project_url": "https://github.com/elvis124/plyer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,7 +52,7 @@ class SubprocessFileChooser(object):\n             ret = self._process.poll()\n             if ret is not None:\n                 if ret == self.successretcode:\n-                    out = self._process.communicate()[0].strip()\n+                    out = self._process.communicate()[0].strip().decode('utf8')\n                     self.selection = self._split_output(out)\n                     return self.selection\n                 else:\n", "before": "out = self . _process . communicate ( ) [ 0 ] . strip ( )", "after": "out = self . _process . communicate ( ) [ 0 ] . strip ( ) . decode ( 'utf8' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 27, 3, 65], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 27, 3, 65], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 27, 3, 65], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'utf8'\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "plyer", "commit_sha": "04cbd9ccb88624d4cb6cf1720ba7009b4ddfeaed", "parent_sha": "e95cac04f6ab23ffe25f283a60af3e344af55e47", "file_path": "plyer/platforms/win/filechooser.py", "project_url": "https://github.com/elvis124/plyer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -96,7 +96,7 @@ class Win32FileChooser(object):\n                     self.title if self.title else \"Pick a folder...\",\n                     0, None, None\n                 )\n-                self.selection = [str(get_path(pidl))]\n+                self.selection = [str(get_path(pidl).decode('utf-8'))]\n \n             return self.selection\n         except (RuntimeError, pywintypes.error):\n", "before": "self . selection = [ str ( get_path ( pidl ) ) ]", "after": "self . selection = [ str ( get_path ( pidl ) . decode ( 'utf-8' ) ) ]", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 39, 3, 53], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 39, 3, 53], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 39, 3, 53], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'utf-8'\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "kitsune", "commit_sha": "5bddb8493fd5b3ad6b9dfe7db5534110b14ac996", "parent_sha": "6609c94644332f60c3e22137936ae2ae429be91d", "file_path": "apps/questions/models.py", "project_url": "https://github.com/skcrouch7/kitsune", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -296,7 +296,7 @@ class Question(ModelBase, BigVocabTaggableMixin, SearchMixin):\n         cache_key = self.tags_cache_key % self.id\n         tags = cache.get(cache_key)\n         if tags is None:\n-            tags = self.tags.all()\n+            tags = self.tags.all().order_by('name')\n             cache.add(cache_key, tags, CACHE_TIMEOUT)\n         return tags\n \n", "before": "tags = self . tags . all ( )", "after": "tags = self . tags . all ( ) . order_by ( 'name' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 20, 3, 35], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 20, 3, 35], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 20, 3, 35], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:order_by\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:'name'\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "kitsune", "commit_sha": "d43f2d54ef4b24f63df3d1ebec7464fd0b433ae3", "parent_sha": "6cc9392ce912eeec53649dbc50dea7084fd69142", "file_path": "apps/search/views.py", "project_url": "https://github.com/skcrouch7/kitsune", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -380,7 +380,7 @@ def search(request, template=None):\n     results_['Expires'] = (datetime.utcnow() +\n                            timedelta(minutes=settings.SEARCH_CACHE_PERIOD)) \\\n                            .strftime(expires_fmt)\n-    results_.set_cookie(settings.LAST_SEARCH_COOKIE, cleaned['q'],\n+    results_.set_cookie(settings.LAST_SEARCH_COOKIE, cleaned['q'].encode('utf-8'),\n                         max_age=3600, secure=False, httponly=False)\n     return results_\n \n", "before": "results_ . set_cookie ( settings . LAST_SEARCH_COOKIE , cleaned [ 'q' ] , max_age = 3600 , secure = False , httponly = False )", "after": "results_ . set_cookie ( settings . LAST_SEARCH_COOKIE , cleaned [ 'q' ] . encode ( 'utf-8' ) , max_age = 3600 , secure = False , httponly = False )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 24, 4, 68], [\"call\", \"N0\"], 3], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"subscript\", 3, 54, 3, 66], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'utf-8'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "hetnet-ml", "commit_sha": "21b1e640fb885900529237c0abd1bffedadd1484", "parent_sha": "64bf59abe3456ce66e09655061b9d843f27f48b7", "file_path": "src/graph_tools.py", "project_url": "https://github.com/mmayers12/hetnet-ml", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -150,7 +150,7 @@ def add_colons(df, id_name='', col_types={}):\n     change_dict = {}\n     for name in to_change:\n         # Reserved column names go after the colon\n-        if name in reserved_cols:\n+        if name.lower() in reserved_cols:\n             if name.lower() == 'id':\n                 new_name = id_name + ':' + name.upper()\n             else:\n", "before": "if name in reserved_cols : if name . lower ( ) == 'id' : new_name = id_name + ':' + name . upper ( ) else : ", "after": "if name . lower ( ) in reserved_cols : if name . lower ( ) == 'id' : new_name = id_name + ':' + name . upper ( ) else : ", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 33], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:name\", 3, 12, 3, 16], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:lower\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "pyload.plugins", "commit_sha": "d92b4f08f623295028cf59338ca33d2a55c29f7b", "parent_sha": "d0acce3be51760fc97c6d8cf298ef37ba2f299ec", "file_path": "module/plugins/hoster/ZDF.py", "project_url": "https://github.com/vuolter/pyload.plugins", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ class ZDF(Hoster):\n \n \n     def process(self, pyfile):\n-        xml = etree.fromstring(self.load(self.XML_API % self.get_id(pyfile.url)))\n+        xml = etree.fromstring(self.load(self.XML_API % self.get_id(pyfile.url)).encode(\"UTF-8\"))\n \n         status = xml.findtext(\"./status/statuscode\")\n         if status != \"ok\":\n", "before": "xml = etree . fromstring ( self . load ( self . XML_API % self . get_id ( pyfile . url ) ) )", "after": "xml = etree . fromstring ( self . load ( self . XML_API % self . get_id ( pyfile . url ) ) . encode ( \"UTF-8\" ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 32, 3, 81], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 32, 3, 81], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 32, 3, 81], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"string:\\\"UTF-8\\\"\", \"T\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2]]"}
{"project": "salt", "commit_sha": "f2e52a86d5e359e8c3cc7e6bad3ef4fc16a84939", "parent_sha": "a3abab13aae6852f03ab7156032ea8cea3d394cd", "file_path": "salt/client/ssh/state.py", "project_url": "https://github.com/kraney/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -143,7 +143,7 @@ def prep_trans_tar(file_client, chunks, file_refs, pillar=None):\n         fp_.write(json.dumps(chunks))\n     if pillar:\n         with salt.utils.fopen(pillarfn, 'w+') as fp_:\n-            fp_.write(json.dumps(pillar))\n+            fp_.write(json.dumps(pillar._dict()))\n     for saltenv in file_refs:\n         file_refs[saltenv].extend(sync_refs)\n         env_root = os.path.join(gendir, saltenv)\n", "before": "fp_ . write ( json . dumps ( pillar ) )", "after": "fp_ . write ( json . dumps ( pillar . _dict ( ) ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 33, 3, 41], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 33, 3, 41], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:pillar\", 3, 34, 3, 40], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:_dict\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"):)\", 3, 40, 3, 41], 1]]"}
{"project": "stock-logistics-warehouse", "commit_sha": "00026f3fcef8a0799fb83d3c1b3619b7c8f56955", "parent_sha": "d269f7ac857ba610aadf50d907c2ceb300fb16d5", "file_path": "models/stock.py", "project_url": "https://github.com/kmee/stock-logistics-warehouse", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ class StockQuant(models.Model):\n                 if self._get_latest_move(self) == self._get_latest_move(quant):\n                     self.qty += quant.qty\n                     self.cost += quant.cost\n-                    quant.unlink()\n+                    quant.sudo().unlink()\n \n     @api.model\n     def quants_unreserve(self, move):\n", "before": "quant . unlink ( )", "after": "quant . sudo ( ) . unlink ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"attribute\", 3, 21, 3, 33], [\"call\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 21, 3, 33], [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:quant\", 3, 21, 3, 26], 0], [\"Move\", \"N1\", [\".:.\", 3, 26, 3, 27], 1], [\"Insert\", \"N1\", [\"identifier:sudo\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "amepah", "commit_sha": "9c697d6b092bbaf1f2ee8613c396bc670068b51a", "parent_sha": "6c762dbe719b4ecfcb0074e5b1ead1703c54a2e9", "file_path": "calibrate_zodi_time.py", "project_url": "https://github.com/berkelem/amepah", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -20,7 +20,7 @@ class Coadder:\n         self.galaxy_mask = self.mask_galaxy()\n         self.galaxy_mask_inds = np.arange(len(self.galaxy_mask))[self.galaxy_mask]\n \n-        self.south_pole_mask = HealpixMap(\"/home/users/mberkeley/wisemapper/data/masks/south_pole_mask.fits\")\n+        self.south_pole_mask = HealpixMap(\"/home/users/mberkeley/wisemapper/data/masks/south_pole_mask.fits\").read_data()\n         self.south_pole_mask_inds = np.arange(len(self.south_pole_mask))[self.south_pole_mask]\n \n         self.numerator = np.zeros_like(self.fsm.mapdata)\n", "before": "self . south_pole_mask = HealpixMap ( \"/home/users/mberkeley/wisemapper/data/masks/south_pole_mask.fits\" )", "after": "self . south_pole_mask = HealpixMap ( \"/home/users/mberkeley/wisemapper/data/masks/south_pole_mask.fits\" ) . read_data ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 32, 3, 110], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 32, 3, 110], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 32, 3, 110], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:read_data\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "pritunl", "commit_sha": "da2195329bddff9e34aee849f7c97d701a3249d9", "parent_sha": "9233106498674df89059248afaf28a67bcbaedd4", "file_path": "pritunl/logger/formatter.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ class LogFormatter(logging.Formatter):\n                         if stderr_lines and not stderr_lines[-1]:\n                             stderr_lines.pop()\n                         for line in stderr_lines:\n-                            formatted_record += '\\n  ' + line\n+                            formatted_record += '\\n  ' + line.decode('utf-8')\n                     if traceback:\n                         formatted_record += \\\n                             '\\nTraceback (most recent call last):\\n'\n", "before": "formatted_record += '\\n  ' + line", "after": "formatted_record += '\\n  ' + line . decode ( 'utf-8' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 49, 3, 62], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:line\", 3, 58, 3, 62], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:decode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'utf-8'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "pritunl", "commit_sha": "545b79cb1ece9741719dac90234b28f6017ac8d5", "parent_sha": "8ee489657510126830ac51176cbd87370a3b883c", "file_path": "pritunl/utils/network.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -174,7 +174,7 @@ def get_interfaces():\n def find_interface(network):\n     network = ipaddress.IPNetwork(network)\n \n-    for interface, data in get_interfaces():\n+    for interface, data in get_interfaces().items():\n         try:\n             address = ipaddress.IPAddress(data['address'])\n         except ValueError:\n", "before": "for interface , data in get_interfaces ( ) : try : address = ipaddress . IPAddress ( data [ 'address' ] ) except ValueError : ", "after": "for interface , data in get_interfaces ( ) . items ( ) : try : address = ipaddress . IPAddress ( data [ 'address' ] ) except ValueError : ", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 28, 3, 44], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 28, 3, 44], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 28, 3, 44], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:items\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "lektor", "commit_sha": "98c1ee765f1970ab41bd5c25c8cb6410abcfdd95", "parent_sha": "8a8a150b5153958a1acfafbaab68ae369896d413", "file_path": "lektor/admin/utils.py", "project_url": "https://github.com/lektor/lektor", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,7 +16,7 @@ def eventstream(f):\n     def new_func(*args, **kwargs):\n         def generate():\n             for event in chain(f(*args, **kwargs), (None,)):\n-                yield 'data: %s\\n\\n' % json.dumps(event)\n+                yield ('data: %s\\n\\n' % json.dumps(event)).encode()\n         return Response(generate(), mimetype='text/event-stream',\n                         direct_passthrough=True)\n     return update_wrapper(new_func, f)\n", "before": "yield 'data: %s\\n\\n' % json . dumps ( event )", "after": "yield ( 'data: %s\\n\\n' % json . dumps ( event ) ) . encode ( )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"yield\", 3, 17, 3, 57], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"parenthesized_expression\", \"N3\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Move\", \"N3\", [\"binary_operator\", 3, 23, 3, 57], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "openstates", "commit_sha": "63e7b5ad9e28c26ea4e76f1f606a4c401b7ae523", "parent_sha": "062b9a1e23f3a62b79c79266ee1b03eec837dc11", "file_path": "fiftystates/scrape/va/bills.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -195,7 +195,7 @@ class VABillScraper(BillScraper):\n \n     def split_vote(self, block):\n         if block:\n-            block = block[0].text\n+            block = block[0].text.replace('\\r\\n', ' ')\n \n             pieces = block.split('--')\n             # if there are only two pieces, there are no abstentions\n", "before": "block = block [ 0 ] . text", "after": "block = block [ 0 ] . text . replace ( '\\r\\n' , ' ' )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 13, 3, 34], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"attribute\", 3, 21, 3, 34], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:replace\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'\\\\r\\\\n'\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"string:' '\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "openstates", "commit_sha": "fed1ece326c8db19debd7b2b582cbbfb2e67598d", "parent_sha": "70ecac921c4d258717220796148fd7b19f9bfd0a", "file_path": "billy/site/api/xml.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -180,7 +180,7 @@ def render_full_legislator(leg):\n \n     old_terms = []\n     if leg.get('old_roles'):\n-        for key, value in leg.get('old_roles'):\n+        for key, value in leg.get('old_roles').iteritems():\n             old_terms.append(E.term(\n                 *[role(r) for r in value],\n                 name=key))\n", "before": "for key , value in leg . get ( 'old_roles' ) : old_terms . append ( E . term ( * [ role ( r ) for r in value ] , name = key ) )", "after": "for key , value in leg . get ( 'old_roles' ) . iteritems ( ) : old_terms . append ( E . term ( * [ role ( r ) for r in value ] , name = key ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"call\", 3, 27, 3, 47], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"call\", 3, 27, 3, 47], [\"argument_list\", \"N1\"], 1], [\"Move\", \"N0\", [\"call\", 3, 27, 3, 47], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:iteritems\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"):)\", \"T\"], 1]]"}
{"project": "secrets-manager-2", "commit_sha": "247544350a486392d9e081db8b7c33bd8273bc42", "parent_sha": "1eccf5beb8b1cbe2d50e8fb76f6d01b778046363", "file_path": "s-manager.py", "project_url": "https://github.com/RcdFdz/secrets-manager-2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -46,7 +46,7 @@ def get_key_value(args, option):\n \tjson_content = json.loads(str(decrypt_content()))\n \tif option.lower() == 'all':\n \t\tfor e in KEYS:\n-\t\t\tprint(e+':',json_content[args][e])\n+\t\t\tprint(e.capitalize()+':',json_content[args][e])\n \telif option.lower() == 'user': print(json_content[args]['user'])\n \telif option.lower() == 'pass': print(json_content[args]['password'])\n \telif option.lower() == 'url': print(json_content[args]['url'])\n", "before": "print ( e + ':' , json_content [ args ] [ e ] )", "after": "print ( e . capitalize ( ) + ':' , json_content [ args ] [ e ] )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 10, 3, 15], [\"call\", \"N0\"], 0], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:e\", 3, 10, 3, 11], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:capitalize\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "spyne", "commit_sha": "38c2db7dd995c4a066519477d012160d9692ebbf", "parent_sha": "2dfdd05968ee73adfbb31844f210ee8111432606", "file_path": "soaplib/soap.py", "project_url": "https://github.com/duixteam/spyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -146,7 +146,7 @@ def from_soap(xml_string):\n     '''\n     Parses the xml string into the header and payload\n     '''\n-    root, xmlids = ElementTree.XMLID(xml_string)\n+    root, xmlids = ElementTree.XMLID(xml_string.encode()) \n     if xmlids:\n         resolve_hrefs(root, xmlids)\n     body = None\n", "before": "root , xmlids = ElementTree . XMLID ( xml_string )", "after": "root , xmlids = ElementTree . XMLID ( xml_string . encode ( ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 37, 3, 49], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 37, 3, 49], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:xml_string\", 3, 38, 3, 48], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"):)\", 3, 48, 3, 49], 1]]"}
{"project": "spyne", "commit_sha": "24dd4005358009d22ad5d9b1331fa7ff6ff14842", "parent_sha": "e22a106cddb38f9f466da77d819e0b278e7c3ef3", "file_path": "soaplib/soap.py", "project_url": "https://github.com/duixteam/spyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -146,7 +146,7 @@ def from_soap(xml_string):\n     '''\n     Parses the xml string into the header and payload\n     '''\n-    root, xmlids = ElementTree.XMLID(xml_string)\n+    root, xmlids = ElementTree.XMLID(xml_string.encode()) \n     if xmlids:\n         resolve_hrefs(root, xmlids)\n     body = None\n", "before": "root , xmlids = ElementTree . XMLID ( xml_string )", "after": "root , xmlids = ElementTree . XMLID ( xml_string . encode ( ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 37, 3, 49], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 37, 3, 49], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:xml_string\", 3, 38, 3, 48], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"):)\", 3, 48, 3, 49], 1]]"}
{"project": "plugins", "commit_sha": "11608947ed75edf992670c2c7e41f51d3bbda0d1", "parent_sha": "b00d653de5e419f46aa193d8e17dce1c36be7d4d", "file_path": "v7/import_jekyll/import_jekyll.py", "project_url": "https://github.com/ChillarAnand/plugins", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -170,7 +170,7 @@ class JekyllPostImport(object):\n         header = utils.write_metadata(metadata)\n \n         pattern = '<!--\\n{0}\\n-->\\n\\n{1}' if is_html else '{0}\\n\\n{1}'\n-        return pattern.format(header, doc)\n+        return pattern.format(header.strip(), doc)\n \n     def _split_metadata(self, path):\n         with codecs.open(path, encoding='utf-8') as fd:\n", "before": "return pattern . format ( header , doc )", "after": "return pattern . format ( header . strip ( ) , doc )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 43], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 30, 3, 43], [\"):)\", \"T\"], 5], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:header\", 3, 31, 3, 37], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:strip\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"):)\", 3, 42, 3, 43], 1]]"}
{"project": "plugins", "commit_sha": "158df14e4325c4868e949f1b752cdddd5b81cb78", "parent_sha": "ee98220952e34c6526ee4b574bb7cf5f3ceb89ad", "file_path": "v6/graphviz/graphviz.py", "project_url": "https://github.com/ChillarAnand/plugins", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -89,7 +89,7 @@ class Graphviz(Directive):\n         node_list = []\n         try:\n             p = Popen([self.dot_path, '-Tsvg'], stdin=PIPE, stdout=PIPE, stderr=PIPE)\n-            svg_data, errors = p.communicate(input=data)\n+            svg_data, errors = p.communicate(input=data.encode('utf8'))\n             code = p.wait()\n             if code:  # Some error\n                 document = self.state.document\n", "before": "svg_data , errors = p . communicate ( input = data )", "after": "svg_data , errors = p . communicate ( input = data . encode ( 'utf8' ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 46, 3, 56], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:data\", 3, 52, 3, 56], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:encode\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"string:'utf8'\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "pandas", "commit_sha": "b5041291db42a5a60d0b63b331af5cd3f643e3e6", "parent_sha": "84d3a4a8d14cd147ec91821bead8fe6a60fd5de1", "file_path": "pandas/tseries/index.py", "project_url": "https://github.com/jmwoloso/pandas", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -875,7 +875,7 @@ class DatetimeIndex(Int64Index):\n         else:\n             if com._is_bool_indexer(key):\n                 key = np.asarray(key)\n-                key = lib.maybe_booleans_to_slice(key)\n+                key = lib.maybe_booleans_to_slice(key.view(np.uint8))\n \n             new_offset = None\n             if isinstance(key, slice):\n", "before": "key = lib . maybe_booleans_to_slice ( key )", "after": "key = lib . maybe_booleans_to_slice ( key . view ( np . uint8 ) )", "sstub_pattern": "ADD_METHOD_CALL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 50, 3, 55], [\"call\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 50, 3, 55], [\"):)\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Move\", \"N1\", [\"identifier:key\", 3, 51, 3, 54], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:view\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 1], [\"Move\", \"N2\", [\"):)\", 3, 54, 3, 55], 2], [\"Insert\", \"N3\", [\"identifier:np\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:uint8\", \"T\"], 2]]"}
{"project": "SleekXMPP", "commit_sha": "10664d723b24739bd0b868b71dbcc8dab80d02ef", "parent_sha": "c012208a8fd411ff2f915a162ec5a3f8eeec41cb", "file_path": "sleekxmpp/componentxmpp.py", "project_url": "https://github.com/mayflower/SleekXMPP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -79,7 +79,7 @@ class ComponentXMPP(BaseXMPP):\n                                self._handle_probe)\n \n     def connect(self, host=None, port=None, use_ssl=False, \n-                      use_tls=True, reattempt=True):\n+                      use_tls=False, reattempt=True):\n", "before": "def connect ( self , host = None , port = None , use_ssl = False , use_tls = True , reattempt = True ) : ", "after": "def connect ( self , host = None , port = None , use_ssl = False , use_tls = False , reattempt = True ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 23, 3, 35], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 31, 3, 35]]]"}
{"project": "SleekXMPP", "commit_sha": "e06368f8cdef7bee0bd648cadb4a9c26c2be6209", "parent_sha": "4b37a4706f62d4ac447d2e0e5127a9199075287d", "file_path": "sleekxmpp/componentxmpp.py", "project_url": "https://github.com/mayflower/SleekXMPP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -79,7 +79,7 @@ class ComponentXMPP(BaseXMPP):\n                                self._handle_probe)\n \n     def connect(self, host=None, port=None, use_ssl=False, \n-                      use_tls=True, reattempt=True):\n+                      use_tls=False, reattempt=True):\n", "before": "def connect ( self , host = None , port = None , use_ssl = False , use_tls = True , reattempt = True ) : ", "after": "def connect ( self , host = None , port = None , use_ssl = False , use_tls = False , reattempt = True ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 23, 3, 35], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 31, 3, 35]]]"}
{"project": "stoq", "commit_sha": "c16c2dc5de3dafb42e2247446ff484af1920d651", "parent_sha": "73ffa15c7b8a849cab52b7ba8e0853e08517791b", "file_path": "stoqlib/gui/slaves/user.py", "project_url": "https://github.com/bellini666/stoq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -66,7 +66,7 @@ class PasswordEditorSlave(BaseEditorSlave):\n     size_group_widgets = ('password_lbl',\n                           'confirm_password_lbl')\n \n-    def __init__(self, conn, model=None, confirm_password=False):\n+    def __init__(self, conn, model=None, confirm_password=True):\n         BaseEditorSlave.__init__(self, conn, model)\n         self._confirm_password = confirm_password\n         self._setup_widgets()\n", "before": "def __init__ ( self , conn , model = None , confirm_password = False ) : BaseEditorSlave . __init__ ( self , conn , model ) self . _confirm_password = confirm_password self . _setup_widgets ( )", "after": "def __init__ ( self , conn , model = None , confirm_password = True ) : BaseEditorSlave . __init__ ( self , conn , model ) self . _confirm_password = confirm_password self . _setup_widgets ( )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 42, 3, 64], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 59, 3, 64]]]"}
{"project": "Terrarium", "commit_sha": "66a8ce0ca1138d2e11632be8f8fe61c251d43225", "parent_sha": "4c4c682ee47b7c3cdbd5d48e1b9df4aa43871e73", "file_path": "tests/test_environment.py", "project_url": "https://github.com/artPlusPlus/Terrarium", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,7 +31,7 @@ class TestEnvironment(object):\n         self._environment.set_var('BAR', '$FOO/bar')\n         self._environment.set_var('BAZ', '${BAR}/baz')\n \n-        result = self._environment.compress('C:/foo/bar/baz/end', var_format='${0}', use_runtime_environment=False)\n+        result = self._environment.compress('C:/foo/bar/baz/end', var_format='${0}', use_runtime_environment=True)\n         assert result == '$BAZ/end'\n \n if __name__ == '__main__':\n", "before": "result = self . _environment . compress ( 'C:/foo/bar/baz/end' , var_format = '${0}' , use_runtime_environment = False )", "after": "result = self . _environment . compress ( 'C:/foo/bar/baz/end' , var_format = '${0}' , use_runtime_environment = True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 86, 3, 115], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 110, 3, 115]]]"}
{"project": "htcondenser", "commit_sha": "39b339f9d18d901a604b6e7197d5e19a6b269b49", "parent_sha": "c2eaa5ec0ac423f6db2b3d38342c12a9677a2850", "file_path": "htcondenser/core/jobset.py", "project_url": "https://github.com/kreczko/htcondenser", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -116,7 +116,7 @@ class JobSet(object):\n                  cpus=1, memory='100MB', disk='100MB',\n                  certificate=False,\n                  transfer_hdfs_input=True,\n-                 share_exe_setup=False,\n+                 share_exe_setup=True,\n                  common_input_files=None,\n                  hdfs_store=None,\n                  dag_mode=False,\n", "before": "share_exe_setup = False ,", "after": "share_exe_setup = True ,", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"expression_list\", 3, 34, 3, 40], [\"true:True\", \"T\"], 0], [\"Delete\", [\"false:False\", 3, 34, 3, 39]]]"}
{"project": "librosa", "commit_sha": "1cb552a745ff0085ad201a38e00869a881e16d33", "parent_sha": "a9350b4162cd264bdb086f70cf77b717fe0b1823", "file_path": "librosa/onset.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ __all__ = ['onset_detect',\n \n \n def onset_detect(y=None, sr=22050, onset_envelope=None, hop_length=512,\n-                 backtrack=True, energy=None,\n+                 backtrack=False, energy=None,\n                  units='frames', **kwargs):\n", "before": "def onset_detect ( y = None , sr = 22050 , onset_envelope = None , hop_length = 512 , backtrack = True , energy = None , units = 'frames' , ** kwargs ) : ", "after": "def onset_detect ( y = None , sr = 22050 , onset_envelope = None , hop_length = 512 , backtrack = False , energy = None , units = 'frames' , ** kwargs ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 18, 3, 32], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 28, 3, 32]]]"}
{"project": "mdtraj", "commit_sha": "cd6fe8f34a55c7b477886fa4fe59532662d7d72a", "parent_sha": "1cd2953826d8f86aa59734f44ba199c68c0e0020", "file_path": "MDTraj/formats/hdf5.py", "project_url": "https://github.com/Eigenstate/mdtraj", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -248,7 +248,7 @@ class HDF5TrajectoryFile(object):\n                 self._needs_initialization = False\n             except self.tables.NoSuchNodeError:\n                 self._frame_index = 0\n-                self._needs_initialization = False\n+                self._needs_initialization = True\n         elif mode == 'r':\n             self._frame_index = 0\n             self._needs_initialization = False\n", "before": "self . _needs_initialization = False", "after": "self . _needs_initialization = True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 17, 3, 51], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 46, 3, 51]]]"}
{"project": "ansible-bender", "commit_sha": "ec6561cd6fdf80852f0bfcae2e1a9be61bcec354", "parent_sha": "4db4d3c9801c984a31f4693181ca172bb91ea498", "file_path": "ansible_bender/builders/buildah_builder.py", "project_url": "https://github.com/TomasTomecek/ansible-bender", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -256,7 +256,7 @@ class BuildahBuilder(Builder):\n         for i in self.python_interpr_prio:\n             cmd = [\"ls\", i]\n             try:\n-                podman_run_cmd(self.build.base_image, cmd, log_stderr=False)\n+                podman_run_cmd(self.build.base_image, cmd, log_stderr=True)\n             except subprocess.CalledProcessError:\n                 logger.info(\"python interpreter %s does not exist\", i)\n                 continue\n", "before": "podman_run_cmd ( self . build . base_image , cmd , log_stderr = False )", "after": "podman_run_cmd ( self . build . base_image , cmd , log_stderr = True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 60, 3, 76], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 71, 3, 76]]]"}
{"project": "WMAS", "commit_sha": "33280b704b880ca34ed976e9097a854697079640", "parent_sha": "98530fb94412077886e8df96e25bfdcd3ce460d3", "file_path": "tools/ci/check_stability.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -270,7 +270,7 @@ def run(venv, wpt_args, **kwargs):\n         wpt_kwargs[\"install\"] = wpt_kwargs[\"product\"].split(\":\")[0] == \"firefox\"\n \n         wpt_kwargs[\"pause_after_test\"] = False\n-        wpt_kwargs[\"verify_log_full\"] = True\n+        wpt_kwargs[\"verify_log_full\"] = False\n         if wpt_kwargs[\"repeat\"] == 1:\n             wpt_kwargs[\"repeat\"] = 10\n \n", "before": "wpt_kwargs [ \"verify_log_full\" ] = True", "after": "wpt_kwargs [ \"verify_log_full\" ] = False", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 45], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 41, 3, 45]]]"}
{"project": "rllab-curriculum", "commit_sha": "46668a7f3d5f8a2378988173d142be52317f5a6f", "parent_sha": "ee19cf7bfccccbc74d89ab3d7068209466431bf4", "file_path": "rllab/algos/batch_polopt.py", "project_url": "https://github.com/florensacc/rllab-curriculum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ class BatchPolopt(RLAlgorithm):\n             center_adv=True,\n             positive_adv=False,\n             store_paths=False,\n-            whole_paths=False,\n+            whole_paths=True,\n             **kwargs\n     ):\n", "before": "whole_paths = False ,", "after": "whole_paths = True ,", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"expression_list\", 3, 25, 3, 31], [\"true:True\", \"T\"], 0], [\"Delete\", [\"false:False\", 3, 25, 3, 30]]]"}
{"project": "elsie", "commit_sha": "ac8abff444d4990a11ba6cb67dca1daec5ce56c2", "parent_sha": "c90acc4f41c4eb5b6d07d1788cf78924999ba321", "file_path": "elsie/slides.py", "project_url": "https://github.com/spirali/elsie", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -150,7 +150,7 @@ class Slides:\n \n     def render(self, output, cache_dir=\"./elsie-cache\",\n                threads=None, return_svg=False, pdf_merger=\"pypdf\",\n-               drop_redundant_slides=True):\n+               drop_redundant_slides=False):\n         inkscape_version = get_inkscape_version()\n         if not os.path.isdir(cache_dir):\n             print(\"Creating cache directory:\", cache_dir)\n", "before": "def render ( self , output , cache_dir = \"./elsie-cache\" , threads = None , return_svg = False , pdf_merger = \"pypdf\" , drop_redundant_slides = True ) : inkscape_version = get_inkscape_version ( ) if not os . path . isdir ( cache_dir ) : print ( \"Creating cache directory:\" , cache_dir )", "after": "def render ( self , output , cache_dir = \"./elsie-cache\" , threads = None , return_svg = False , pdf_merger = \"pypdf\" , drop_redundant_slides = False ) : inkscape_version = get_inkscape_version ( ) if not os . path . isdir ( cache_dir ) : print ( \"Creating cache directory:\" , cache_dir )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 16, 3, 42], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 38, 3, 42]]]"}
{"project": "pyMaid", "commit_sha": "af5d43ee44b4b7b1a5c75e5feab52754ae8f1ae7", "parent_sha": "78651160878973c77a4fa6b548e927d1d3f62eb7", "file_path": "pymaid/fetch.py", "project_url": "https://github.com/schlegelp/pyMaid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2939,7 +2939,7 @@ def has_soma(x, tag='soma', min_rad=500, return_ids=False,\n \r\n @cache.undo_on_error\r\n def get_annotated(x, include_sub_annotations=False, raise_not_found=True,\r\n-                  allow_partial=True, remote_instance=None):\r\n+                  allow_partial=False, remote_instance=None):\r\n", "before": "def get_annotated ( x , include_sub_annotations = False , raise_not_found = True , allow_partial = True , remote_instance = None ) : ", "after": "def get_annotated ( x , include_sub_annotations = False , raise_not_found = True , allow_partial = False , remote_instance = None ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 19, 3, 37], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 33, 3, 37]]]"}
{"project": "pygl-prototype", "commit_sha": "416e6436b049438d1d27aed9390e701fc35ede34", "parent_sha": "3773ff81cfb54fa463e8e55fcb974d24d7aa1aee", "file_path": "graphics.py", "project_url": "https://github.com/dvoraka/pygl-prototype", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -241,7 +241,7 @@ class GameWindow(pyglet.window.Window):\n \n         self.camera = camera.FPSCamera(x_pos=10, y_pos=53, z_pos=-20)\n         self.camera.gravity = True\n-        self.camera_fall_collision = False\n+        self.camera_fall_collision = True\n \n         # for testing only\n         self.test_obj = TestObject()\n", "before": "self . camera_fall_collision = False", "after": "self . camera_fall_collision = True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 43], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 38, 3, 43]]]"}
{"project": "angr", "commit_sha": "f7f108662cddf56324c31f28e8434f989216addc", "parent_sha": "f846096b47d73ce7f9e2fd59c4fcda8a0252ac69", "file_path": "angr/analyses/dfg.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,7 +25,7 @@ class DFG(Analysis):\n         if self._annocfg is not None:\n             whitelist = self._annocfg.get_whitelisted_statements(addr)\n             if whitelist is False or (whitelist is not None and stmt_idx not in whitelist):\n-                return False\n+                return True\n         if stmt.tag == 'Ist_IMark' or stmt.tag == 'Ist_AbiHint' or stmt.tag == 'Ist_Exit':\n             return True\n         elif stmt.tag == 'Ist_Put':\n", "before": "return False", "after": "return True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 17, 3, 29], [\"true:True\", \"T\"], 1], [\"Delete\", [\"false:False\", 3, 24, 3, 29]]]"}
{"project": "mitmproxy", "commit_sha": "3594faf5c42bfe4d422b16e4ceedb482802c95ce", "parent_sha": "c062e302e9281e4d8e216595b14fb089ed784b4e", "file_path": "mitmproxy/options.py", "project_url": "https://github.com/aisier/mitmproxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,7 +35,7 @@ class Options(optmanager.OptManager):\n             keepserving: bool = True,\n             no_server: bool = False,\n             server_replay_nopop: bool = False,\n-            refresh_server_playback: bool = False,\n+            refresh_server_playback: bool = True,\n             rfile: Optional[str] = None,\n             scripts: Sequence[str] = [],\n             showhost: bool = False,\n", "before": "refresh_server_playback : bool = False ,", "after": "refresh_server_playback : bool = True ,", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"expression_list\", 3, 45, 3, 51], [\"true:True\", \"T\"], 0], [\"Delete\", [\"false:False\", 3, 45, 3, 50]]]"}
{"project": "sympy", "commit_sha": "9551efb9b76b691bf13395e46d527e1b1cfdeac3", "parent_sha": "cdb7087312125ea69aedc97a1c334eecaed982a1", "file_path": "sympy/printing/str.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -707,7 +707,7 @@ def _print_Complement(self, expr):\n         return r' \\ '.join(self._print(set) for set in expr.args)\n \n     def _print_Quantity(self, expr):\n-        if self._settings.get(\"abbrev\", True):\n+        if self._settings.get(\"abbrev\", False):\n             return \"%s\" % expr.abbrev\n         return \"%s\" % expr.name\n \n", "before": "if self . _settings . get ( \"abbrev\" , True ) : return \"%s\" % expr . abbrev", "after": "if self . _settings . get ( \"abbrev\" , False ) : return \"%s\" % expr . abbrev", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 46], [\"false:False\", \"T\"], 3], [\"Delete\", [\"true:True\", 3, 41, 3, 45]]]"}
{"project": "sympy", "commit_sha": "5d2b067da9f61283756d8dcc9770fc9943e130b7", "parent_sha": "dc087922a4cd5f20b145b24dd6755b69afc883f6", "file_path": "sympy/ntheory/tests/test_residue.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -134,7 +134,7 @@ def test_residue():\n     assert is_nthpow_residue(1, 0, 2) is True\n     assert is_nthpow_residue(3, 0, 2) is False\n     assert is_nthpow_residue(0, 1, 8) is True\n-    assert is_nthpow_residue(2, 3, 2) is False\n+    assert is_nthpow_residue(2, 3, 2) is True\n     assert is_nthpow_residue(2, 3, 9) is False\n     assert is_nthpow_residue(3, 5, 30) is True\n     assert is_nthpow_residue(21, 11, 20) is True\n", "before": "assert is_nthpow_residue ( 2 , 3 , 2 ) is False", "after": "assert is_nthpow_residue ( 2 , 3 , 2 ) is True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 47], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 42, 3, 47]]]"}
{"project": "copenhagent", "commit_sha": "500939dc97eb81de97d285eb5f6664a96ea7d86c", "parent_sha": "76db6574a64e61333a2556349e35666744c0ae33", "file_path": "shell.py", "project_url": "https://github.com/sxlijin/copenhagent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -12,7 +12,7 @@ def navigation_ai(shell):\n     \"\"\"\n     The methods to be executed when the \"navigation ai\" command is run.\n     \"\"\"\n-    debug = True\n+    debug = False\n     \n     def nav_setup():\n         nav_inst = lib.navigation.Instance(shell, debug=debug)\n", "before": "debug = True", "after": "debug = False", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 5, 3, 17], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 13, 3, 17]]]"}
{"project": "InstaPy", "commit_sha": "f95bd95d2cda17011ff50dcb63e6340eadeaa6ce", "parent_sha": "1798a8d06dcfbc74df460f527c354f537748c79b", "file_path": "instapy/instapy.py", "project_url": "https://github.com/anyulled/InstaPy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ class InstaPy:\n                  proxy_port=None,\n                  disable_image_load=False,\n                  bypass_suspicious_attempt=False,\n-                 multi_logs=False):\n+                 multi_logs=True):\n \n         if nogui:\n             self.display = Display(visible=0, size=(800, 600))\n", "before": "multi_logs = False", "after": "multi_logs = True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 18, 3, 34], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 29, 3, 34]]]"}
{"project": "InstaPy", "commit_sha": "8c011b1702a5e48eb3fa0eed424bfaf0ead2734d", "parent_sha": "58d808a50682e25b18194eb93b86ea83d0f56540", "file_path": "instapy/instapy.py", "project_url": "https://github.com/anyulled/InstaPy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -89,7 +89,7 @@ class InstaPy:\n                  proxy_address=None,\n                  proxy_chrome_extension=None,\n                  proxy_port=None,\n-                 disable_image_load=True,\n+                 disable_image_load=False,\n                  bypass_suspicious_attempt=False,\n                  multi_logs=False):\n \n", "before": "disable_image_load = True ,", "after": "disable_image_load = False ,", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"expression_list\", 3, 37, 3, 42], [\"false:False\", \"T\"], 0], [\"Delete\", [\"true:True\", 3, 37, 3, 41]]]"}
{"project": "flutterfuck", "commit_sha": "47d16e9a72029217c297c39f57a4602c1e67057c", "parent_sha": "7eabed9fc5c04789f09528010bba73713574d15b", "file_path": "sopel/loader.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -147,7 +147,7 @@ def clean_callable(func, config):\n     doc = trim_docstring(func.__doc__)\n     example = None\n \n-    func.unblockable = getattr(func, 'unblockable', True)\n+    func.unblockable = getattr(func, 'unblockable', False)\n     func.priority = getattr(func, 'priority', 'medium')\n     func.thread = getattr(func, 'thread', True)\n     func.rate = getattr(func, 'rate', 0)\n", "before": "func . unblockable = getattr ( func , 'unblockable' , True )", "after": "func . unblockable = getattr ( func , 'unblockable' , False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 31, 3, 58], [\"false:False\", \"T\"], 5], [\"Delete\", [\"true:True\", 3, 53, 3, 57]]]"}
{"project": "lsh-hdc", "commit_sha": "2c72dbe2ffe3f97da02af67e421b29b128eff87b", "parent_sha": "ec65fa49356278853b00293797d3572dcd0afeda", "file_path": "lsh_hdc/metrics.py", "project_url": "https://github.com/escherba/lsh-hdc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -529,7 +529,7 @@ class ContingencyTable(CrossTab):\n \n         if subtract_null:\n             null_cost = self.expected(discrete=False).assignment_score(\n-                discrete=True, subtract_null=False, normalize=False)\n+                discrete=False, subtract_null=False, normalize=False)\n             cost -= null_cost\n \n         if normalize:\n", "before": "null_cost = self . expected ( discrete = False ) . assignment_score ( discrete = True , subtract_null = False , normalize = False )", "after": "null_cost = self . expected ( discrete = False ) . assignment_score ( discrete = False , subtract_null = False , normalize = False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 17, 3, 30], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 26, 3, 30]]]"}
{"project": "weblyzard_api", "commit_sha": "8fa8379b6df5f464c702dddba048db24e9207211", "parent_sha": "640cc956cad623a31eb23fcacb475341b80a24c0", "file_path": "src/python/weblyzard_api/xml_content/parsers/json_10.py", "project_url": "https://github.com/weblyzard/weblyzard_api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -198,7 +198,7 @@ class JSON10ParserXMLContent(JSONParserBase):\n-        cls._check_document_format(api_dict, strict=True)\n+        cls._check_document_format(api_dict, strict=False)\n         # This basically creates an empty XMLContent object\n         xml_content = XMLContent(xml_content=None, remove_duplicates=True)\n         # add all items in api_dict unless they need special handling\n", "before": "cls . _check_document_format ( api_dict , strict = True )", "after": "cls . _check_document_format ( api_dict , strict = False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 0, 46, 0, 57], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 0, 53, 0, 57]]]"}
{"project": "databroker", "commit_sha": "079e09c3edad153d1c2aa5519708fdc7d95e2cbb", "parent_sha": "f579834936f5da941ffd59ffd5de7560f50e9821", "file_path": "metadatastore/mds.py", "project_url": "https://github.com/bluesky/databroker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -10,7 +10,7 @@ _API_MAP = {1: core}\n \n \n class MDSRO(object):\n-    def __init__(self, config, version=1, auth=True):\n+    def __init__(self, config, version=1, auth=False):\n         self._RUNSTART_CACHE = {}\n         self._RUNSTOP_CACHE = {}\n         self._DESCRIPTOR_CACHE = {}\n", "before": "def __init__ ( self , config , version = 1 , auth = True ) : self . _RUNSTART_CACHE = { } self . _RUNSTOP_CACHE = { } self . _DESCRIPTOR_CACHE = { }", "after": "def __init__ ( self , config , version = 1 , auth = False ) : self . _RUNSTART_CACHE = { } self . _RUNSTOP_CACHE = { } self . _DESCRIPTOR_CACHE = { }", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 43, 3, 52], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 48, 3, 52]]]"}
{"project": "lambdipy", "commit_sha": "f64af6c03e61d22fa2a515a0012d12948b5963af", "parent_sha": "40b7e32746c0110715371b20e264f1fbed471b76", "file_path": "lambdipy/release.py", "project_url": "https://github.com/customink/lambdipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ def _get_release_by_tag(tag, use_token):\n     return GitRelease(repo._requester, headers, data, completed=True)\n \n \n-def get_release(build, use_token=True):\n+def get_release(build, use_token=False):\n     try:\n         return _get_release_by_tag(build.git_tag(), use_token=use_token)\n     except UnknownObjectException:\n", "before": "def get_release ( build , use_token = True ) : try : return _get_release_by_tag ( build . git_tag ( ) , use_token = use_token ) except UnknownObjectException : ", "after": "def get_release ( build , use_token = False ) : try : return _get_release_by_tag ( build . git_tag ( ) , use_token = use_token ) except UnknownObjectException : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 24, 3, 38], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 34, 3, 38]]]"}
{"project": "udapi-python", "commit_sha": "e2fe7e03eb0dc809a77010be58f10e42c1ce881e", "parent_sha": "6868f58ab7773b1c5fb3815bdfed0af39b3ffab5", "file_path": "udapi/block/tokenize/onwhitespace.py", "project_url": "https://github.com/udapi/udapi-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -32,7 +32,7 @@ class OnWhitespace(Block):\n \n     escape_whitespace_table = str.maketrans({' ':r'\\s', '\\t':r'\\t', '\\r':r'\\r', '\\n':r'\\n'})\n \n-    def __init__(self, keep_spaces=True, **kwargs):\n+    def __init__(self, keep_spaces=False, **kwargs):\n         super().__init__(**kwargs)\n         self.keep_spaces = keep_spaces\n \n", "before": "def __init__ ( self , keep_spaces = True , ** kwargs ) : super ( ) . __init__ ( ** kwargs ) self . keep_spaces = keep_spaces", "after": "def __init__ ( self , keep_spaces = False , ** kwargs ) : super ( ) . __init__ ( ** kwargs ) self . keep_spaces = keep_spaces", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 24, 3, 40], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 36, 3, 40]]]"}
{"project": "strax", "commit_sha": "128a0a5060ae183b3be806f30f770dcc51561325", "parent_sha": "427d923f7d501d37e4ef1a537d7f8efa3d24fa73", "file_path": "strax/processor.py", "project_url": "https://github.com/AxFoundation/strax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -228,7 +228,7 @@ class ThreadedMailboxProcessor:\n                 # Unfortunately there is no wait=timeout option, so we have to\n                 # roll our own\n                 pids = self.process_executor._processes.keys()\n-                self.process_executor.shutdown(wait=False)\n+                self.process_executor.shutdown(wait=True)\n \n                 t0 = time.time()\n                 while time.time() < t0 + 20:\n", "before": "self . process_executor . shutdown ( wait = False )", "after": "self . process_executor . shutdown ( wait = True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 48, 3, 58], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 53, 3, 58]]]"}
{"project": "blockchain-ops", "commit_sha": "5bdb5df0fba482de3fecae4e8156ad68a3f1588b", "parent_sha": "df973bcc5a1c46a426dc461b50c0c468233d7e89", "file_path": "tasks.py", "project_url": "https://github.com/kinecosystem/blockchain-ops", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -230,7 +230,7 @@ def build_go(c, version, org_name='kinecosystem', repo_name='go', remote='origin\n \n \n @task\n-def push_dockerhub(c, app, version, latest=True):\n+def push_dockerhub(c, app, version, latest=False):\n     \"\"\"Push image to Dockerhub.\"\"\"\n     if app.lower() == 'core':\n         c.run('sudo docker push kinecosystem/stellar-core:{version}'.format(version=version))\n", "before": "def push_dockerhub ( c , app , version , latest = True ) : \"\"\"Push image to Dockerhub.\"\"\" if app . lower ( ) == 'core' : c . run ( 'sudo docker push kinecosystem/stellar-core:{version}' . format ( version = version ) )", "after": "def push_dockerhub ( c , app , version , latest = False ) : \"\"\"Push image to Dockerhub.\"\"\" if app . lower ( ) == 'core' : c . run ( 'sudo docker push kinecosystem/stellar-core:{version}' . format ( version = version ) )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 37, 3, 48], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 44, 3, 48]]]"}
{"project": "team1", "commit_sha": "bb2185ba62cf4d29c021ab4faf59e0113d9d7bd1", "parent_sha": "ea31ff9b4526a6f5d59b87b4debdba490bb0e1af", "file_path": "barista/app.py", "project_url": "https://github.com/thk-emq-16/team1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,8 +14,8 @@ def coffee():\n     machine = int(request.args.get('machine'))\n \n     order = make_coffee(amount, COFFEES[coffee], MACHINES[machine])\n-    \n+\n     return render_template('coffee.html', order=order)\n \n if __name__ == \"__main__\":\n-    app.run(host=\"0.0.0.0\", debug=True)\n+    app.run(host=\"0.0.0.0\", debug=False)\n", "before": "app . run ( host = \"0.0.0.0\" , debug = True )", "after": "app . run ( host = \"0.0.0.0\" , debug = False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 7, 29, 7, 39], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 7, 35, 7, 39]]]"}
{"project": "auto-perf-test", "commit_sha": "e31ee5ac215042425ff941e2a3d470cc737c661e", "parent_sha": "08186965ba649edcdb1b4622e051b677f83955a7", "file_path": "autotest.py", "project_url": "https://github.com/ScreamingUdder/auto-perf-test", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -158,7 +158,7 @@ def main():\n         job_queue = []\n         process = None\n         logfile = None\n-        enable_build_on_push = False\n+        enable_build_on_push = True\n         current_job = CurrentJob('')\n         e_tag = ''  # to avoid getting unchanged data back from github\n         e_tag = poll_github(job_queue, e_tag, initial_call=True)\n", "before": "enable_build_on_push = False", "after": "enable_build_on_push = True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 37], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 32, 3, 37]]]"}
{"project": "harpoon-2", "commit_sha": "3ac6466893881826f5399ee7322c5d726b1a667c", "parent_sha": "6d6ef684918ce0be8881c83c24d9a9c5c9b883bc", "file_path": "harpoon/option_spec/harpoon_specs.py", "project_url": "https://github.com/pombredanne/harpoon-2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -111,7 +111,7 @@ class HarpoonSpec(object):\n                     , enabled = defaulted(boolean(), True)\n \n                     , parent_dir = directory_spec(formatted(defaulted(string_spec(), \"{config_root}\"), formatter=MergedOptionStringFormatter))\n-                    , use_gitignore = defaulted(boolean(), True)\n+                    , use_gitignore = defaulted(boolean(), False)\n                     , use_git_timestamps = defaulted(or_spec(boolean(), listof(string_spec())), False)\n                     )\n                 )\n", "before": " , use_gitignore = defaulted ( boolean ( ) , True )", "after": " , use_gitignore = defaulted ( boolean ( ) , False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 48, 3, 65], [\"false:False\", \"T\"], 3], [\"Delete\", [\"true:True\", 3, 60, 3, 64]]]"}
{"project": "Sublimall", "commit_sha": "4101c23821c2d51a57cab2092767459d6d06c9c1", "parent_sha": "1d26b77dd9a040079cfe3295e6a2ebbc8a7ee5e9", "file_path": "sublimall/archiver.py", "project_url": "https://github.com/alsibir/Sublimall", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ class Archiver(object):\n         if command == 'a':\n             assert 'output_filename' in kwargs\n             command_args = [self._get_7za_executable(), command, '-tzip', '-mx=9', '-y']\n-            if self.settings.get('symlinks', True):\n+            if self.settings.get('symlinks', False):\n                 command_args.append('-l')\n             if password is not None:\n                 command_args.append('-p%s' % password)\n", "before": "if self . settings . get ( 'symlinks' , True ) : command_args . append ( '-l' )", "after": "if self . settings . get ( 'symlinks' , False ) : command_args . append ( '-l' )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 33, 3, 51], [\"false:False\", \"T\"], 3], [\"Delete\", [\"true:True\", 3, 46, 3, 50]]]"}
{"project": "cvxpy", "commit_sha": "8cd797b0aac0db8422d3b7b2cc9dac3a6f7a6d64", "parent_sha": "27765c8ddfe51530e40773b88999b2d5c7771e0d", "file_path": "cvxpy/tests/test_constant_atoms.py", "project_url": "https://github.com/zqcr/cvxpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -221,7 +221,7 @@ def run_atom(atom, problem, obj_val, solver):\n         if solver == ROBUST_CVXOPT:\n             result = problem.solve(solver=CVXOPT, verbose=False, kktsolver=ROBUST_KKTSOLVER)\n         else:\n-            result = problem.solve(solver=solver, verbose=True)\n+            result = problem.solve(solver=solver, verbose=False)\n         if problem.status is OPTIMAL:\n             print(result)\n             print(obj_val)\n", "before": "result = problem . solve ( solver = solver , verbose = True )", "after": "result = problem . solve ( solver = solver , verbose = False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 51, 3, 63], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 59, 3, 63]]]"}
{"project": "fapistrano", "commit_sha": "32f1ecd46dd6701e07a33500032ea8ca23cdd6d7", "parent_sha": "01d89c371ca8d56858c4b432765f28a9321d2a41", "file_path": "fapistrano/configuration.py", "project_url": "https://github.com/soasme/fapistrano", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -20,7 +20,7 @@ def setdefault(key, value):\n         setattr(env, key, value)\n \n def set_default_configurations():\n-    setdefault('show_output', True)\n+    setdefault('show_output', False)\n     setdefault('user', 'deploy')\n     setdefault('use_ssh_config', True)\n     setdefault('path', '/home/%(user)s/www/%(project_name)s')\n", "before": "setdefault ( 'show_output' , True )", "after": "setdefault ( 'show_output' , False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 15, 3, 36], [\"false:False\", \"T\"], 3], [\"Delete\", [\"true:True\", 3, 31, 3, 35]]]"}
{"project": "zulip", "commit_sha": "ccc1f3861f40fe7e68ab4ddfa4662c9f5f546528", "parent_sha": "78b1b80987870e977d5f498939c676f71ea0f760", "file_path": "zproject/backends.py", "project_url": "https://github.com/punit-agarwal/zulip", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -316,7 +316,7 @@ class ZulipLDAPAuthBackend(ZulipLDAPAuthBackendBase):\n                 short_name = ldap_user.attrs[short_name_attr][0]\n \n             user_profile = do_create_user(username, None, realm, full_name, short_name)\n-            return user_profile, False\n+            return user_profile, True\n \n # Just like ZulipLDAPAuthBackend, but doesn't let you log in.\n class ZulipLDAPUserPopulator(ZulipLDAPAuthBackendBase):\n", "before": "return user_profile , False", "after": "return user_profile , True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"expression_list\", 3, 20, 3, 39], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 34, 3, 39]]]"}
{"project": "h", "commit_sha": "b572376ade5bcece9827e85c55a880722d2e1cf1", "parent_sha": "95814fcd7c4c8971d7e9bccd7631d3ac10364b75", "file_path": "h/api.py", "project_url": "https://github.com/project-star/h", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -486,7 +486,7 @@ def includeme(config):\n     # Maybe initialize the models\n     if asbool(settings.get('basemodel.should_drop_all', False)):\n         delete_db()\n-    if asbool(settings.get('basemodel.should_create_all', True)):\n+    if asbool(settings.get('basemodel.should_create_all', False)):\n         create_db()\n \n     config.scan(__name__)\n", "before": "if asbool ( settings . get ( 'basemodel.should_create_all' , True ) ) : create_db ( )", "after": "if asbool ( settings . get ( 'basemodel.should_create_all' , False ) ) : create_db ( )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 27, 3, 64], [\"false:False\", \"T\"], 3], [\"Delete\", [\"true:True\", 3, 59, 3, 63]]]"}
{"project": "semstr", "commit_sha": "25d410d4f9034b7f2778dbbd58bae9cc394c93f0", "parent_sha": "504b9ed98fa2d4d24e1fefc691c51e4644d210a8", "file_path": "semstr/convert.py", "project_url": "https://github.com/huji-nlp/semstr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ def from_conllu(lines, passage_id=None, split=True, return_original=False, annot\n     return ConlluConverter().from_format(lines, passage_id, split, return_original=return_original, annotate=annotate)\n \n \n-def to_conllu(passage, test=False, tree=False, *args, **kwargs):\n+def to_conllu(passage, test=False, tree=True, *args, **kwargs):\n", "before": "def to_conllu ( passage , test = False , tree = False , * args , ** kwargs ) : ", "after": "def to_conllu ( passage , test = False , tree = True , * args , ** kwargs ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 36, 3, 46], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 41, 3, 46]]]"}
{"project": "django-jinja", "commit_sha": "92ea167a97d4ebdef213f4e28b4e62b44cbdd73c", "parent_sha": "81f9b801f0c0e2dbdc77973a5b0260a68a0a9156", "file_path": "django_jinja/base.py", "project_url": "https://github.com/alanjds/django-jinja", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -245,7 +245,7 @@ def match_template(template_name, regex=None, extension=None):\n     elif regex:\n         return re.match(regex, template_name)\n     else:\n-        return False\n+        return True\n \n \n def make_environment(defaults=None, clspath=None):\n", "before": "else : return False", "after": "else : return True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"type\", 3, 16, 3, 21], [\"true:True\", \"T\"], 0], [\"Delete\", [\"false:False\", 3, 16, 3, 21]]]"}
{"project": "gevent", "commit_sha": "9268e53824f042338a83348e242c55492a38d7a2", "parent_sha": "e25df83d958c3abe31eff4a5d8127a2b35611d8c", "file_path": "gevent/monkey.py", "project_url": "https://github.com/gevent/gevent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -168,7 +168,7 @@ def patch_subprocess():\n \n \n def patch_all(socket=True, dns=True, time=True, select=True, thread=True, os=True, ssl=True, httplib=False,\n-              subprocess=True, sys=False, aggressive=True, Event=False):\n+              subprocess=False, sys=False, aggressive=True, Event=False):\n     \"\"\"Do all of the default monkey patching (calls every other function in this module.\"\"\"\n     # order is important\n     if sys:\n", "before": "def patch_all ( socket = True , dns = True , time = True , select = True , thread = True , os = True , ssl = True , httplib = False , subprocess = True , sys = False , aggressive = True , Event = False ) : \"\"\"Do all of the default monkey patching (calls every other function in this module.\"\"\" if sys : ", "after": "def patch_all ( socket = True , dns = True , time = True , select = True , thread = True , os = True , ssl = True , httplib = False , subprocess = False , sys = False , aggressive = True , Event = False ) : \"\"\"Do all of the default monkey patching (calls every other function in this module.\"\"\" if sys : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 15, 3, 30], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 26, 3, 30]]]"}
{"project": "pritunl", "commit_sha": "6e9b95ba10880070f9ec0ab257c38e228907cc16", "parent_sha": "3943be4f7d54217bbbac59afbc042ac99f0d6cb0", "file_path": "pritunl/queue.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -220,7 +220,7 @@ class Queue(MongoObject):\n         pass\n \n     def stop_task(self):\n-        return True\n+        return False\n \n     def complete_task(self):\n         \"\"\"not_overridden\"\"\"\n", "before": "return True", "after": "return False", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 9, 3, 20], [\"false:False\", \"T\"], 1], [\"Delete\", [\"true:True\", 3, 16, 3, 20]]]"}
{"project": "spyne", "commit_sha": "36c9ec69f4e542088a077ce61e9c7db3ffe09842", "parent_sha": "7bb3cf790f880c7e21fa1f5fd86c1c0b7e6c4db6", "file_path": "spyne/protocol/http.py", "project_url": "https://github.com/duixteam/spyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -115,7 +115,7 @@ class HttpRpc(SimpleDictDocument):\n     type.add('http')\n \n     def __init__(self, app=None, validator=None, mime_type=None,\n-                    tmp_dir=None, tmp_delete_on_close=True, ignore_uncap=True,\n+                    tmp_dir=None, tmp_delete_on_close=True, ignore_uncap=False,\n                                                             parse_cookie=True):\n         super(HttpRpc, self).__init__(app, validator, mime_type,\n                                                       ignore_uncap=ignore_uncap)\n", "before": "def __init__ ( self , app = None , validator = None , mime_type = None , tmp_dir = None , tmp_delete_on_close = True , ignore_uncap = True , parse_cookie = True ) : super ( HttpRpc , self ) . __init__ ( app , validator , mime_type , ignore_uncap = ignore_uncap )", "after": "def __init__ ( self , app = None , validator = None , mime_type = None , tmp_dir = None , tmp_delete_on_close = True , ignore_uncap = False , parse_cookie = True ) : super ( HttpRpc , self ) . __init__ ( app , validator , mime_type , ignore_uncap = ignore_uncap )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 61, 3, 78], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 74, 3, 78]]]"}
{"project": "depot_tools", "commit_sha": "943f35a5f0fe1a349d58965fdd4f482e8bc4bc97", "parent_sha": "d2046a802af45cc3d9ab1f2e540d06aaf5e84f4b", "file_path": "recipes/chromium.py", "project_url": "https://github.com/withtone/depot_tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -18,7 +18,7 @@ class Chromium(recipe_util.Recipe):\n     solution = { 'name'   :'src',\n                  'url'    : url,\n                  'deps_file': '.DEPS.git',\n-                 'managed'   : True,\n+                 'managed'   : False,\n                  'custom_deps': {},\n                  'safesync_url': '',\n     }\n", "before": "solution = { 'name' : 'src' , 'url' : url , 'deps_file' : '.DEPS.git' , 'managed' : True , 'custom_deps' : { } , 'safesync_url' : '' , }", "after": "solution = { 'name' : 'src' , 'url' : url , 'deps_file' : '.DEPS.git' , 'managed' : False , 'custom_deps' : { } , 'safesync_url' : '' , }", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"pair\", 3, 18, 3, 36], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 32, 3, 36]]]"}
{"project": "Count-files", "commit_sha": "bc6764c9070c71361ac87e08038166bef7604d15", "parent_sha": "27651475e41cbdfc3d8d5800059121bf8e1916ba", "file_path": "word_counter.py", "project_url": "https://github.com/victordomingos/Count-files", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ class WordCounter:\n         return total\n \n     @staticmethod\n-    def get_files_by_extension(location: str, extension: str, preview=False, preview_size=395, recursion=False) -> int:\n+    def get_files_by_extension(location: str, extension: str, preview=False, preview_size=395, recursion=True) -> int:\n", "before": "def get_files_by_extension ( location : str , extension : str , preview = False , preview_size = 395 , recursion = False ) -> int : ", "after": "def get_files_by_extension ( location : str , extension : str , preview = False , preview_size = 395 , recursion = True ) -> int : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 96, 3, 111], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 106, 3, 111]]]"}
{"project": "neo-python", "commit_sha": "611b9e3daadc5e5d7c7cb492c2fe9be5d2b0f0f8", "parent_sha": "8ac3c46c1ba3a54c04748c11351763266d6b22bb", "file_path": "neo/Settings.py", "project_url": "https://github.com/hal0x2328/neo-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -200,7 +200,7 @@ class SettingsHolder:\n         self.USE_DEBUG_STORAGE = config.get('DebugStorage', True)\n         self.DEBUG_STORAGE_PATH = config.get('DebugStoragePath', 'Chains/debugstorage')\n         self.NOTIFICATION_DB_PATH = config.get('NotificationDataPath', 'Chains/notification_data')\n-        self.SERVICE_ENABLED = config.get('ServiceEnabled', True)\n+        self.SERVICE_ENABLED = config.get('ServiceEnabled', False)\n         self.COMPILER_NEP_8 = config.get('CompilerNep8', False)\n \n     def setup_mainnet(self):\n", "before": "self . SERVICE_ENABLED = config . get ( 'ServiceEnabled' , True )", "after": "self . SERVICE_ENABLED = config . get ( 'ServiceEnabled' , False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 42, 3, 66], [\"false:False\", \"T\"], 3], [\"Delete\", [\"true:True\", 3, 61, 3, 65]]]"}
{"project": "porthole", "commit_sha": "f3f601b76799ebe2acfff486280f52cbf7261a83", "parent_sha": "0386e3563a6b330d2843610aa7b7877c9623498f", "file_path": "porthole/xlsx.py", "project_url": "https://github.com/speedyturkey/porthole", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ class WorkbookBuilder(object):\n     def add_worksheet(\n             self, sheet_name, field_names, sheet_data,\n             format_axis=None, format_rules=None, row_start=0, col_start=0,\n-            autofit_columns=False, column_width=None, freeze_first_row=False,\n+            autofit_columns=True, column_width=None, freeze_first_row=False,\n             header_format=None, show_autofilter=False\n     ):\n", "before": "def add_worksheet ( self , sheet_name , field_names , sheet_data , format_axis = None , format_rules = None , row_start = 0 , col_start = 0 , autofit_columns = False , column_width = None , freeze_first_row = False , header_format = None , show_autofilter = False ) : ", "after": "def add_worksheet ( self , sheet_name , field_names , sheet_data , format_axis = None , format_rules = None , row_start = 0 , col_start = 0 , autofit_columns = True , column_width = None , freeze_first_row = False , header_format = None , show_autofilter = False ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 13, 3, 34], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 29, 3, 34]]]"}
{"project": "scipy", "commit_sha": "e2a316a8f1be7717a35188032f5f03c2987de41e", "parent_sha": "481fe33787a14d0a0d87d2d3c6b8c958700e0a4c", "file_path": "scipy/optimize/_linprog_ip.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1606,7 +1606,7 @@ def _linprog_ip(\n         sparse=False,\n         lstsq=False,\n         sym_pos=True,\n-        cholesky=True,\n+        cholesky=False,\n         pc=True,\n         ip=False,\n         presolve=True,\n", "before": "cholesky = True ,", "after": "cholesky = False ,", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"expression_list\", 3, 18, 3, 23], [\"false:False\", \"T\"], 0], [\"Delete\", [\"true:True\", 3, 18, 3, 22]]]"}
{"project": "scipy", "commit_sha": "2a5418f9e6c7f283620a07d61eb2efafa11fe2f6", "parent_sha": "5064b9023f9c5f8967225fa56f97900d2cb9ab10", "file_path": "scipy/optimize/_linprog_ip.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1606,7 +1606,7 @@ def _linprog_ip(\n         sparse=False,\n         lstsq=False,\n         sym_pos=True,\n-        cholesky=True,\n+        cholesky=False,\n         pc=True,\n         ip=False,\n         presolve=True,\n", "before": "cholesky = True ,", "after": "cholesky = False ,", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"expression_list\", 3, 18, 3, 23], [\"false:False\", \"T\"], 0], [\"Delete\", [\"true:True\", 3, 18, 3, 22]]]"}
{"project": "smart-cache", "commit_sha": "1cfd675c05ada9480647917a7a023d730933259a", "parent_sha": "ce2e5f08493471b8234272dee4534d78cdb5f364", "file_path": "SmartCache/sim/simulator/__main__.py", "project_url": "https://github.com/Cloud-PG/smart-cache", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ def main():\n                         default=\"./simulation_results\",\n                         help='The folder where the simulation results will be stored [DEFAULT: \"simulation_results\"]')\n     parser.add_argument('--read-on-hit', type='bool',\n-                        default=True,\n+                        default=False,\n                         help='Use read on hit data [DEFAULT: True]')\n     parser.add_argument('--simulation-steps', type=str,\n                         default='single,normal,nextW,nextP',\n", "before": "help = 'The folder where the simulation results will be stored [DEFAULT: \"simulation_results\"]' ) parser . add_argument ( '--read-on-hit' , type = 'bool' , default = True , help = 'Use read on hit data [DEFAULT: True]' )", "after": "help = 'The folder where the simulation results will be stored [DEFAULT: \"simulation_results\"]' ) parser . add_argument ( '--read-on-hit' , type = 'bool' , default = False , help = 'Use read on hit data [DEFAULT: True]' )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 25, 3, 37], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 33, 3, 37]]]"}
{"project": "django-lfs", "commit_sha": "4ecc1436300357c2dc11ec0d7312796525cb81b4", "parent_sha": "8063b8862b57220365719545d7cef2a83343c4a2", "file_path": "lfs/checkout/views.py", "project_url": "https://github.com/baffolobill/django-lfs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -331,7 +331,7 @@ def one_page_checkout(request, checkout_form=OnePageCheckoutForm,\n             \"shipping_lastname\": shipping_address.lastname,\n             \"shipping_phone\": shipping_address.phone,\n             \"shipping_email\": shipping_address.email,\n-            \"no_shipping\": False,\n+            \"no_shipping\": True,\n         })\n         form = checkout_form(initial=initial)\n     cart = cart_utils.get_cart(request)\n", "before": "False ,", "after": "True ,", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"expression_statement\", 3, 28, 3, 34], [\"true:True\", \"T\"], 0], [\"Delete\", [\"false:False\", 3, 28, 3, 33]]]"}
{"project": "praw", "commit_sha": "ff50f8ea86f8f3958500f1df254283720248ed3f", "parent_sha": "e83b26918416e98a99cf443cf0498e52e9183e7d", "file_path": "reddit/objects.py", "project_url": "https://github.com/SIlver--/praw", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -118,7 +118,7 @@ class Approvable(RedditContentObject):\n         return response\n \n     @require_login\n-    def remove(self, spam=True):\n+    def remove(self, spam=False):\n         url = self.reddit_session.config['remove']\n         params = {'id': self.content_id,\n                   'spam': 'True' if spam else 'False'}\n", "before": "def remove ( self , spam = True ) : url = self . reddit_session . config [ 'remove' ] params = { 'id' : self . content_id , 'spam' : 'True' if spam else 'False' }", "after": "def remove ( self , spam = False ) : url = self . reddit_session . config [ 'remove' ] params = { 'id' : self . content_id , 'spam' : 'True' if spam else 'False' }", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 22, 3, 31], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 27, 3, 31]]]"}
{"project": "sunpy", "commit_sha": "ad7f24b204f6d9653478bab40173d74c8e2a090f", "parent_sha": "ba14a2d581d9b343affd69a8b99a278e797eded2", "file_path": "sunpy/map/mapbase.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -902,7 +902,7 @@ installed, falling back to the interpolation='spline' of order=3\"\"\" ,Warning)\n         return axes\n \n     @toggle_pylab\n-    def peek(self, draw_limb=True, draw_grid=False, gamma=None,\n+    def peek(self, draw_limb=False, draw_grid=False, gamma=None,\n                    colorbar=True, basic_plot=False, **matplot_args):\n", "before": "def peek ( self , draw_limb = True , draw_grid = False , gamma = None , colorbar = True , basic_plot = False , ** matplot_args ) : ", "after": "def peek ( self , draw_limb = False , draw_grid = False , gamma = None , colorbar = True , basic_plot = False , ** matplot_args ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 20, 3, 34], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 30, 3, 34]]]"}
{"project": "python_utilities", "commit_sha": "9c20f79df172b75be4e2c2e51a7cc63d2b0da86b", "parent_sha": "9030f91ec8e02189c6af854c1acaa84369bd20fc", "file_path": "logging/logging_helper.py", "project_url": "https://github.com/jonathanmorgan/python_utilities", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -292,7 +292,7 @@ class LoggingHelper( object ):\n         # initialize variables\n         self.m_logger = None\n         self.m_logger_name = self.LOGGER_NAME\n-        self.logger_debug_flag = False\n+        self.logger_debug_flag = True\n         self.logger_also_print_flag = False\n         self.logger_resource_string = \"\"\n \n", "before": "self . logger_debug_flag = False", "after": "self . logger_debug_flag = True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 39], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 34, 3, 39]]]"}
{"project": "enigma2", "commit_sha": "8da0699500e3ef63875fa4af6d8d5c5248e99704", "parent_sha": "8d6a064f7a6f3b38ddf2940290b0ebdc6b4d5356", "file_path": "lib/python/Components/AVSwitch.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -160,5 +160,5 @@ def InitAVSwitch():\n \tif can_downmix:\n \t\tdef setAC3Downmix(configElement):\n \t\t\topen(\"/proc/stb/audio/ac3\", \"w\").write(configElement.value and \"downmix\" or \"passthrough\")\n-\t\tconfig.av.downmix_ac3 = ConfigYesNo(default = False)\n+\t\tconfig.av.downmix_ac3 = ConfigYesNo(default = True)\n \t\tconfig.av.downmix_ac3.addNotifier(setAC3Downmix)\n", "before": "config . av . downmix_ac3 = ConfigYesNo ( default = False )", "after": "config . av . downmix_ac3 = ConfigYesNo ( default = True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 39, 3, 54], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 49, 3, 54]]]"}
{"project": "enigma2", "commit_sha": "005f1f1dad01c8899d08021f242a9e235ef92b7c", "parent_sha": "e9e07c13c707b7007b2254dac5d53804398dfd07", "file_path": "lib/python/Components/UsageConfig.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -191,7 +191,7 @@ def InitUsageConfig():\n \t\tm = ngettext(\"%d minute\", \"%d minutes\", m) % m\n \t\tchoicelist.append((str(i), _(\"after \") + m))\n \tconfig.usage.standby_to_shutdown_timer = ConfigSelection(default = \"0\", choices = choicelist)\n-\tconfig.usage.standby_to_shutdown_timer_blocktime = ConfigYesNo(default = True)\n+\tconfig.usage.standby_to_shutdown_timer_blocktime = ConfigYesNo(default = False)\n \tconfig.usage.standby_to_shutdown_timer_blocktime_begin = ConfigClock(default = time.mktime((0, 0, 0, 6, 0, 0, 0, 0, 0)))\n \tconfig.usage.standby_to_shutdown_timer_blocktime_end = ConfigClock(default = time.mktime((0, 0, 0, 23, 0, 0, 0, 0, 0)))\n \n", "before": "config . usage . standby_to_shutdown_timer_blocktime = ConfigYesNo ( default = True )", "after": "config . usage . standby_to_shutdown_timer_blocktime = ConfigYesNo ( default = False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 65, 3, 79], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 75, 3, 79]]]"}
{"project": "enigma2", "commit_sha": "2fe55e90ef98d28905a98921d2bd928fc565a618", "parent_sha": "5acb5b791e5f14ec1b18d6e89b281242ff840de2", "file_path": "lib/python/Components/UsageConfig.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -191,7 +191,7 @@ def InitUsageConfig():\n \t\tm = ngettext(\"%d minute\", \"%d minutes\", m) % m\n \t\tchoicelist.append((str(i), _(\"after \") + m))\n \tconfig.usage.standby_to_shutdown_timer = ConfigSelection(default = \"0\", choices = choicelist)\n-\tconfig.usage.standby_to_shutdown_timer_blocktime = ConfigYesNo(default = True)\n+\tconfig.usage.standby_to_shutdown_timer_blocktime = ConfigYesNo(default = False)\n \tconfig.usage.standby_to_shutdown_timer_blocktime_begin = ConfigClock(default = time.mktime((0, 0, 0, 6, 0, 0, 0, 0, 0)))\n \tconfig.usage.standby_to_shutdown_timer_blocktime_end = ConfigClock(default = time.mktime((0, 0, 0, 23, 0, 0, 0, 0, 0)))\n \n", "before": "config . usage . standby_to_shutdown_timer_blocktime = ConfigYesNo ( default = True )", "after": "config . usage . standby_to_shutdown_timer_blocktime = ConfigYesNo ( default = False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 65, 3, 79], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 75, 3, 79]]]"}
{"project": "enigma2", "commit_sha": "3bbd63cf1f2f5f96cf360300bd414a3af5aad74d", "parent_sha": "8c9a7853c84753b24efaa66143b0e9c1a9b1a9a4", "file_path": "lib/python/Components/PluginList.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -47,7 +47,7 @@ def PluginDownloadComponent(plugin, name, version=None, width=440):\n \t\n \n class PluginList(MenuList):\n-\tdef __init__(self, list, enableWrapAround=False):\n+\tdef __init__(self, list, enableWrapAround=True):\n \t\tMenuList.__init__(self, list, enableWrapAround, eListboxPythonMultiContent)\n \t\tself.l.setFont(0, gFont(\"Regular\", 20))\n \t\tself.l.setFont(1, gFont(\"Regular\", 14))\n", "before": "def __init__ ( self , list , enableWrapAround = False ) : MenuList . __init__ ( self , list , enableWrapAround , eListboxPythonMultiContent ) self . l . setFont ( 0 , gFont ( \"Regular\" , 20 ) ) self . l . setFont ( 1 , gFont ( \"Regular\" , 14 ) )", "after": "def __init__ ( self , list , enableWrapAround = True ) : MenuList . __init__ ( self , list , enableWrapAround , eListboxPythonMultiContent ) self . l . setFont ( 0 , gFont ( \"Regular\" , 20 ) ) self . l . setFont ( 1 , gFont ( \"Regular\" , 14 ) )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 27, 3, 49], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 44, 3, 49]]]"}
{"project": "enigma2", "commit_sha": "d3d10a08a7c2c75040f8c8966f14ff8a714adf29", "parent_sha": "233fba41e9644bfe5ad94e3fa22dbfdf42aad000", "file_path": "lib/python/Components/UsageConfig.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -571,7 +571,7 @@ def InitUsageConfig():\n \n \tconfig.subtitles.dvb_subtitles_yellow = ConfigYesNo(default = False)\n \tconfig.subtitles.dvb_subtitles_original_position = ConfigSelection(default = \"0\", choices = [(\"0\", _(\"Original\")), (\"1\", _(\"Fixed\")), (\"2\", _(\"Relative\"))])\n-\tconfig.subtitles.dvb_subtitles_centered = ConfigYesNo(default = True)\n+\tconfig.subtitles.dvb_subtitles_centered = ConfigYesNo(default = False)\n \tconfig.subtitles.subtitle_bad_timing_delay = ConfigSelection(default = \"0\", choices = subtitle_delay_choicelist)\n \tconfig.subtitles.dvb_subtitles_backtrans = ConfigSelection(default = \"0\", choices = [\n \t\t(\"0\", _(\"No transparency\")),\n", "before": "config . subtitles . dvb_subtitles_centered = ConfigYesNo ( default = True )", "after": "config . subtitles . dvb_subtitles_centered = ConfigYesNo ( default = False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 56, 3, 70], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 66, 3, 70]]]"}
{"project": "enigma2", "commit_sha": "f4d56df86f8a35a3bbfb57e7a56631dff899465e", "parent_sha": "d6618a36c67ddab1a33766969ef5bd2ff7d0ae11", "file_path": "lib/python/Components/UsageConfig.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ def InitUsageConfig():\n \tconfig.misc.showrotorposition = ConfigSelection(default = \"no\", choices = [(\"no\", _(\"no\")), (\"yes\", _(\"yes\")), (\"withtext\", _(\"with text\")), (\"tunername\", _(\"with tuner name\"))])\n \tconfig.usage.multibouquet = ConfigYesNo(default = True)\n \n-\tconfig.usage.alternative_number_mode = ConfigYesNo(default = True)\n+\tconfig.usage.alternative_number_mode = ConfigYesNo(default = False)\n \tdef alternativeNumberModeChange(configElement):\n \t\teDVBDB.getInstance().setNumberingMode(configElement.value)\n \t\trefreshServiceList()\n", "before": "config . usage . alternative_number_mode = ConfigYesNo ( default = True )", "after": "config . usage . alternative_number_mode = ConfigYesNo ( default = False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 53, 3, 67], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 63, 3, 67]]]"}
{"project": "enigma2", "commit_sha": "9197e79795aa1ca0fcdc7bb9bd73923c0df9c3f0", "parent_sha": "40e8e6ed02e7ab405c8d6e0a6cf44946c1ed2dd6", "file_path": "lib/python/Components/Lcd.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -85,7 +85,7 @@ def InitLcd():\n \t\tif SystemInfo[\"LcdLiveTV\"]:\n \t\t\tdef lcdLiveTvChanged(configElement):\n \t\t\t\topen(SystemInfo[\"LcdLiveTV\"], \"w\").write(configElement.value and \"0\" or \"1\")\n-\t\t\tconfig.lcd.showTv = ConfigYesNo(default = True)\n+\t\t\tconfig.lcd.showTv = ConfigYesNo(default = False)\n \t\t\tconfig.lcd.showTv.addNotifier(lcdLiveTvChanged)\n \telse:\n \t\tdef doNothing():\n", "before": "config . lcd . showTv = ConfigYesNo ( default = True )", "after": "config . lcd . showTv = ConfigYesNo ( default = False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 36, 3, 50], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 46, 3, 50]]]"}
{"project": "RSync", "commit_sha": "422b4b40234a5c90817216dce41f3a55c642e8ac", "parent_sha": "1366fd49680a7f73096a5e0a468bff06f81d7388", "file_path": "rsyncconfig/test/filter.py", "project_url": "https://github.com/compuwizard123/RSync", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -136,7 +136,7 @@ def add_tests(suite):\n         ('[[:digit:]]', '9', None, True),\n         ('[[:graph:]]', '*', None, True),\n         ('[[:lower:]]', 'a', None, True),\n-        ('[[:lower:]]', 'B', None, True),\n+        ('[[:lower:]]', 'B', None, False),\n         ('[[:print:]]', '&', None, True),\n         ('[[:punct:]]', '(', None, True),\n         ('[[:space:]]', '\\v', None, True),\n", "before": "( '[[:lower:]]' , 'B' , None , True ) ,", "after": "( '[[:lower:]]' , 'B' , None , False ) ,", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"tuple\", 3, 9, 3, 41], [\"false:False\", \"T\"], 7], [\"Delete\", [\"true:True\", 3, 36, 3, 40]]]"}
{"project": "enigma2", "commit_sha": "9c4232a74d5e662a0e9abdd3a5b21fa2f81eabfd", "parent_sha": "4e6ce6864f3ec8768763192ebd4d19f61044e637", "file_path": "lib/python/Components/UsageConfig.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -384,7 +384,7 @@ def InitUsageConfig():\n \t\tconfig.usage.LcdLiveTVMode = ConfigSelection(default = \"0\", choices=[str(x) for x in range(0,9)])\n \t\tconfig.usage.LcdLiveTVMode.addNotifier(setLcdLiveTVMode)\n \n-\tconfig.usage.boolean_graphic = ConfigYesNo(default=False)\n+\tconfig.usage.boolean_graphic = ConfigYesNo(default=True)\n \n \tconfig.epg = ConfigSubsection()\n \tconfig.epg.eit = ConfigYesNo(default = True)\n", "before": "config . usage . boolean_graphic = ConfigYesNo ( default = False )", "after": "config . usage . boolean_graphic = ConfigYesNo ( default = True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 45, 3, 58], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 53, 3, 58]]]"}
{"project": "hytra", "commit_sha": "bdd958080694497ad758c9d3c3c80ae56b79d4c5", "parent_sha": "ee602047d49b85c56735fcdc2879d849778b2e5d", "file_path": "hytra/core/hypothesesgraph.py", "project_url": "https://github.com/chaubold/hytra", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -69,7 +69,7 @@ class HypothesesGraph(object):\n     def __init__(self):\n         self._graph = nx.DiGraph()\n         self.withTracklets = False\n-        self.allowLengthOneTracks = False\n+        self.allowLengthOneTracks = True\n         self._nextNodeUuid = 0\n \n     def nodeIterator(self):\n", "before": "self . allowLengthOneTracks = False", "after": "self . allowLengthOneTracks = True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 42], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 37, 3, 42]]]"}
{"project": "oq-hazardlib", "commit_sha": "7e5c6cab08fc3ef31292f0467f97ec2012923a98", "parent_sha": "b53330e47e2f1028da1f30a7ad85cd724482baf1", "file_path": "openquake/hazardlib/tests/gsim/check_gsim.py", "project_url": "https://github.com/treviallen/oq-hazardlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,7 +33,7 @@ from openquake.hazardlib.gsim.base import (SitesContext, RuptureContext,\n from openquake.hazardlib.imt import PGA, PGV, PGD, SA, CAV\n \n \n-def check_gsim(gsim_cls, datafile, max_discrep_percentage, debug=True):\n+def check_gsim(gsim_cls, datafile, max_discrep_percentage, debug=False):\n", "before": "def check_gsim ( gsim_cls , datafile , max_discrep_percentage , debug = True ) : ", "after": "def check_gsim ( gsim_cls , datafile , max_discrep_percentage , debug = False ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 60, 3, 70], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 66, 3, 70]]]"}
{"project": "website", "commit_sha": "90bdd36120fb3eba742205020815a9b19a8f3108", "parent_sha": "9f35cbbda1071657beb33f1d6c40eb1078e45a39", "file_path": "apps/locker/management/commands/unarchive_locker.py", "project_url": "https://github.com/SutCEGoS/website", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -8,7 +8,7 @@ class Command(BaseCommand):\n         pass\n \n     def handle(self, *args, **options):\n-        lockers = Rack.objects.filter(archived=False)\n+        lockers = Rack.objects.filter(archived=True)\n         self.stdout.write(\"Start archive lockers. count: %d\\n\" % len(lockers))\n         for locker in lockers:\n             if not locker.archived:\n", "before": "lockers = Rack . objects . filter ( archived = False )", "after": "lockers = Rack . objects . filter ( archived = True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 39, 3, 53], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 48, 3, 53]]]"}
{"project": "toppra", "commit_sha": "1d5b88eaf88c375c0032caa25ffd9f5c01c6829a", "parent_sha": "6c54375fad0d0531e5a9b9b75fe74d4f5293a01d", "file_path": "toppra/TOPP.py", "project_url": "https://github.com/hungpham2511/toppra", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ def compute_trajectory_gridpoints(path, sgrid, ugrid, xgrid):\n \n def compute_trajectory_points(path, sgrid,\n                               ugrid, xgrid,\n-                              dt=1e-2, smooth=True,\n+                              dt=1e-2, smooth=False,\n                               smooth_eps=1e-4):\n", "before": "def compute_trajectory_points ( path , sgrid , ugrid , xgrid , dt = 1e-2 , smooth = True , smooth_eps = 1e-4 ) : ", "after": "def compute_trajectory_points ( path , sgrid , ugrid , xgrid , dt = 1e-2 , smooth = False , smooth_eps = 1e-4 ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 40, 3, 51], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 47, 3, 51]]]"}
{"project": "enigma2", "commit_sha": "a6f026e2a12be339eae5952fe98545907d0972ef", "parent_sha": "485f9603074a072910d0d1d6bcb365bc41cc77d2", "file_path": "lib/python/Components/UsageConfig.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -63,7 +63,7 @@ def InitUsageConfig():\n \tconfig.usage.show_infobar_on_skip = ConfigYesNo(default = True)\n \tconfig.usage.show_infobar_on_event_change = ConfigYesNo(default = False)\n \tconfig.usage.show_second_infobar = ConfigSelection(default = None, choices = [(None, _(\"None\"))] + choicelist + [(\"EPG\",_(\"EPG\"))])\n-\tconfig.usage.show_simple_second_infobar = ConfigYesNo(default = True)\n+\tconfig.usage.show_simple_second_infobar = ConfigYesNo(default = False)\n \tconfig.usage.infobar_frontend_source = ConfigSelection(default = \"tuner\", choices = [(\"settings\", _(\"Settings\")), (\"tuner\", _(\"Tuner\"))])\n \tconfig.usage.oldstyle_zap_controls = ConfigYesNo(default = False)\n \tconfig.usage.oldstyle_channel_select_controls = ConfigYesNo(default = False)\n", "before": "config . usage . show_simple_second_infobar = ConfigYesNo ( default = True )", "after": "config . usage . show_simple_second_infobar = ConfigYesNo ( default = False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 56, 3, 70], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 66, 3, 70]]]"}
{"project": "airflow", "commit_sha": "c985490fd0fc943b622c40d7dc7713171be73f42", "parent_sha": "751e18892f632f838bdf45f09f3bb62984705dcc", "file_path": "airflow/utils/logging.py", "project_url": "https://github.com/costrouc/airflow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -147,7 +147,7 @@ class GCSLog(object):\n                     'airflow[gcp_api] is installed and the GCS connection '\n                     'exists.'.format(remote_conn_id))\n \n-    def read(self, remote_log_location, return_error=True):\n+    def read(self, remote_log_location, return_error=False):\n", "before": "def read ( self , remote_log_location , return_error = True ) : ", "after": "def read ( self , remote_log_location , return_error = False ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 41, 3, 58], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 54, 3, 58]]]"}
{"project": "spaCy", "commit_sha": "878327d38e1e3c7f2284c9aa442b0566d519b2e6", "parent_sha": "cc2f58a1b06773bb8ee6aed5ec05f231737e1777", "file_path": "spacy/cli/debug_model.py", "project_url": "https://github.com/connorbrinton/spaCy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,7 +25,7 @@ def debug_model_cli(\n     P0: bool = Opt(False, \"--print-step0\", \"-P0\", help=\"Print model before training\"),\n     P1: bool = Opt(False, \"--print-step1\", \"-P1\", help=\"Print model after initialization\"),\n     P2: bool = Opt(False, \"--print-step2\", \"-P2\", help=\"Print model after training\"),\n-    P3: bool = Opt(True, \"--print-step3\", \"-P3\", help=\"Print final predictions\"),\n+    P3: bool = Opt(False, \"--print-step3\", \"-P3\", help=\"Print final predictions\"),\n     use_gpu: int = Opt(-1, \"--gpu-id\", \"-g\", help=\"GPU ID or -1 for CPU\")\n     # fmt: on\n ):\n", "before": "P3 : bool = Opt ( True , \"--print-step3\" , \"-P3\" , help = \"Print final predictions\" ) ,", "after": "P3 : bool = Opt ( False , \"--print-step3\" , \"-P3\" , help = \"Print final predictions\" ) ,", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 19, 3, 81], [\"false:False\", \"T\"], 1], [\"Delete\", [\"true:True\", 3, 20, 3, 24]]]"}
{"project": "airflow", "commit_sha": "cae918e912fedd7d187a7ca9a9488e86caf6ad82", "parent_sha": "c27098b8d31fee7177f37108a6c2fb7c7ad37170", "file_path": "airflow/hooks/dbapi_hook.py", "project_url": "https://github.com/costrouc/airflow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -137,7 +137,7 @@ class DbApiHook(BaseHook):\n                     cur.execute(sql)\n                 return cur.fetchone()\n \n-    def run(self, sql, autocommit=True, parameters=None):\n+    def run(self, sql, autocommit=False, parameters=None):\n", "before": "def run ( self , sql , autocommit = True , parameters = None ) : ", "after": "def run ( self , sql , autocommit = False , parameters = None ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 24, 3, 39], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 35, 3, 39]]]"}
{"project": "dolo", "commit_sha": "f7e8a1cbcf07703196f269db56e2c0ae683dcf74", "parent_sha": "140b0441d448d9f08d4d48518fcbd9af37c735fb", "file_path": "dolo/misc/modfile.py", "project_url": "https://github.com/TomAugspurger/dolo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -329,7 +329,7 @@ class Instruction_group():\n \n \n \n-def dynare_import(filename,names_dict={},full_output=False, debug=True):\n+def dynare_import(filename,names_dict={},full_output=False, debug=False):\n     '''Imports model defined in specified file'''\n     import os\n     basename = os.path.basename(filename)\n", "before": "def dynare_import ( filename , names_dict = { } , full_output = False , debug = True ) : '''Imports model defined in specified file''' import os basename = os . path . basename ( filename )", "after": "def dynare_import ( filename , names_dict = { } , full_output = False , debug = False ) : '''Imports model defined in specified file''' import os basename = os . path . basename ( filename )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 61, 3, 71], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 67, 3, 71]]]"}
{"project": "dolo", "commit_sha": "87a986219e6b7c6a6689eeea4a69ec41b4cc818f", "parent_sha": "09f34bcfc0d0e110f1ae5e20df3e69e3dd711344", "file_path": "src/dolo/compiler/compiler_global.py", "project_url": "https://github.com/TomAugspurger/dolo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -252,7 +252,7 @@ def test_residuals(s,dr, f,g,parms, epsilons, weights):\n     return std_errors\n \n \n-def time_iteration(grid, interp, xinit, f, g, parms, epsilons, weights, x_bounds=None, options={}, serial_grid=True, verbose=True, method='lmmcp', maxit=500, nmaxit=50, backsteps=10, hook=None):\n+def time_iteration(grid, interp, xinit, f, g, parms, epsilons, weights, x_bounds=None, options={}, serial_grid=False, verbose=True, method='lmmcp', maxit=500, nmaxit=50, backsteps=10, hook=None):\n \n     from dolo.numeric.solver import solver\n", "before": "def time_iteration ( grid , interp , xinit , f , g , parms , epsilons , weights , x_bounds = None , options = { } , serial_grid = True , verbose = True , method = 'lmmcp' , maxit = 500 , nmaxit = 50 , backsteps = 10 , hook = None ) : from dolo . numeric . solver import solver", "after": "def time_iteration ( grid , interp , xinit , f , g , parms , epsilons , weights , x_bounds = None , options = { } , serial_grid = False , verbose = True , method = 'lmmcp' , maxit = 500 , nmaxit = 50 , backsteps = 10 , hook = None ) : from dolo . numeric . solver import solver", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 100, 3, 116], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 112, 3, 116]]]"}
{"project": "unknown-horizons", "commit_sha": "6e37551c06c49821491560774eecd49ba6bf6996", "parent_sha": "4270b9d233cecce0311081a0f925b69ce5b8169e", "file_path": "horizons/world/units/unit.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -81,7 +81,7 @@ class Unit(MovingObject):\n \t\t\tself.act(self._action, location, True)\n \t\tself.session.view.cam.refresh()\n \n-\tdef draw_health(self, remove_only=True):\n+\tdef draw_health(self, remove_only=False):\n \t\t\"\"\"Draws the units current health as a healthbar over the unit.\"\"\"\n \t\tif not self.has_component(HealthComponent):\n \t\t\treturn\n", "before": "def draw_health ( self , remove_only = True ) : \"\"\"Draws the units current health as a healthbar over the unit.\"\"\" if not self . has_component ( HealthComponent ) : return", "after": "def draw_health ( self , remove_only = False ) : \"\"\"Draws the units current health as a healthbar over the unit.\"\"\" if not self . has_component ( HealthComponent ) : return", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 24, 3, 40], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 36, 3, 40]]]"}
{"project": "ansible-1", "commit_sha": "28b86b11485444d2dd46ed60dc8ae27fd2b81303", "parent_sha": "91ce5c70d3c29be2fb4127813245e99cd20a8d12", "file_path": "lib/ansible/modules/files/file.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -177,7 +177,7 @@ def main():\n             original_basename=dict(required=False),  # Internal use only, for recursive ops\n             recurse=dict(default=False, type='bool'),\n             force=dict(required=False, default=False, type='bool'),\n-            follow=dict(required=False, default=True, type='bool'),\n+            follow=dict(required=False, default=False, type='bool'),\n             diff_peek=dict(default=None),  # Internal use only, for internal checks in the action plugins\n             validate=dict(required=False, default=None),  # Internal use only, for template and copy\n             src=dict(required=False, default=None, type='path'),\n", "before": "follow = dict ( required = False , default = True , type = 'bool' ) ,", "after": "follow = dict ( required = False , default = False , type = 'bool' ) ,", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 41, 3, 53], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 49, 3, 53]]]"}
{"project": "ansible-1", "commit_sha": "c1400ce9091a6fcf2c2db465b5c1fbd01cce9447", "parent_sha": "8bccd0830be8f2c64bfe2c6828111f5b5d6d8c94", "file_path": "lib/ansible/plugins/cache/__init__.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -153,7 +153,7 @@ class BaseFileCacheModule(BaseCacheModule):\n     def has_expired(self, key):\n \n         if self._timeout == 0:\n-            return True\n+            return False\n \n         cachefile = \"%s/%s\" % (self._cache_dir, key)\n         try:\n", "before": "return True", "after": "return False", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 13, 3, 24], [\"false:False\", \"T\"], 1], [\"Delete\", [\"true:True\", 3, 20, 3, 24]]]"}
{"project": "pritunl", "commit_sha": "074811d8cf04439736584bb881d0a21d460ae646", "parent_sha": "c66c5ede5976aa06e1cfad99a8654ca5bebcad01", "file_path": "pritunl/handlers/admin.py", "project_url": "https://github.com/security-geeks/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -291,7 +291,7 @@ def admin_post():\n             username=username,\n             password=password,\n             yubikey_id=yubikey_id,\n-            default=True,\n+            default=False,\n             otp_auth=otp_auth,\n             auth_api=auth_api,\n             disabled=disabled,\n", "before": "username = username , password = password , yubikey_id = yubikey_id , default = True ,", "after": "username = username , password = password , yubikey_id = yubikey_id , default = False ,", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"expression_list\", 3, 21, 3, 26], [\"false:False\", \"T\"], 0], [\"Delete\", [\"true:True\", 3, 21, 3, 25]]]"}
{"project": "ansible-1", "commit_sha": "9a25e16140407dd99b382e336ecdf9c3157ea0da", "parent_sha": "cc27fc368a817d03b89f79c4eac03d7551a12a8c", "file_path": "lib/ansible/plugins/action/template.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -62,7 +62,7 @@ class ActionModule(ActionBase):\n         source = self._task.args.get('src', None)\n         dest   = self._task.args.get('dest', None)\n         faf    = self._task.first_available_file\n-        force  = boolean(self._task.args.get('force', False))\n+        force  = boolean(self._task.args.get('force', True))\n \n         if (source is None and faf is not None) or dest is None:\n             result['failed'] = True\n", "before": "force = boolean ( self . _task . args . get ( 'force' , False ) )", "after": "force = boolean ( self . _task . args . get ( 'force' , True ) )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 45, 3, 61], [\"true:True\", \"T\"], 3], [\"Delete\", [\"false:False\", 3, 55, 3, 60]]]"}
{"project": "ansible-1", "commit_sha": "c7dde72aa0a3b211efd2b52196b5cb424412719c", "parent_sha": "ac66e4001cca09dc8717af6b1507b4daaa6651c7", "file_path": "lib/ansible/utils/listify.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -26,7 +26,7 @@ from ansible.template.safe_eval import safe_eval\n __all__ = ['listify_lookup_plugin_terms']\n \n #FIXME: probably just move this into lookup plugin base class\n-def listify_lookup_plugin_terms(terms, templar, loader, fail_on_undefined=False, convert_bare=False):\n+def listify_lookup_plugin_terms(terms, templar, loader, fail_on_undefined=False, convert_bare=True):\n \n     if isinstance(terms, basestring):\n         stripped = terms.strip()\n", "before": "def listify_lookup_plugin_terms ( terms , templar , loader , fail_on_undefined = False , convert_bare = False ) : if isinstance ( terms , basestring ) : stripped = terms . strip ( )", "after": "def listify_lookup_plugin_terms ( terms , templar , loader , fail_on_undefined = False , convert_bare = True ) : if isinstance ( terms , basestring ) : stripped = terms . strip ( )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 82, 3, 100], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 95, 3, 100]]]"}
{"project": "FalcomBot2-cogs", "commit_sha": "b8f22aecef9c96116143d685e8615822d2cda28f", "parent_sha": "c1a850dc02e4c80e7b690a020393b1ca90a53c7b", "file_path": "rolereqs/rolereqs.py", "project_url": "https://github.com/nmbook/FalcomBot2-cogs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ class RoleRequests(commands.Cog):\n                 \"max_requestable\": 3,\n                 \"request_channel\": 0,\n                 \"auto_post_list\": True,\n-                \"show_member_count\": True,\n+                \"show_member_count\": False,\n         }\n \n         default_channel = {\n", "before": "True ,", "after": "False ,", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"expression_statement\", 3, 38, 3, 43], [\"false:False\", \"T\"], 0], [\"Delete\", [\"true:True\", 3, 38, 3, 42]]]"}
{"project": "ansible-1", "commit_sha": "8d69eb44882c49e56f50e1308ad11d1d170bd4bf", "parent_sha": "9cf217a1518fa36eba7e2d8cd81adc5a064f0901", "file_path": "lib/ansible/modules/web_infrastructure/letsencrypt.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -853,7 +853,7 @@ def main():\n             challenge=dict(required=False, default='http-01', choices=['http-01', 'dns-01', 'tls-sni-02'], type='str'),\n             csr=dict(required=True, aliases=['src'], type='path'),\n             data=dict(required=False, no_log=True, default=None, type='dict'),\n-            fullchain=dict(required=False, default=True, type='bool'),\n+            fullchain=dict(required=False, default=False, type='bool'),\n             dest=dict(required=True, aliases=['cert'], type='path'),\n             remaining_days=dict(required=False, default=10, type='int'),\n         ),\n", "before": "fullchain = dict ( required = False , default = True , type = 'bool' ) ,", "after": "fullchain = dict ( required = False , default = False , type = 'bool' ) ,", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 44, 3, 56], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 52, 3, 56]]]"}
{"project": "mxnet", "commit_sha": "abeaba780409aa598a23aa131831208b3514bc73", "parent_sha": "ea4e2b3c7c081390015480beaa82d4814939b55e", "file_path": "python/mxnet/gluon/block.py", "project_url": "https://github.com/zhiiker/mxnet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -913,7 +913,7 @@ class HybridBlock(Block):\n         self._monitor_all = False\n         self._backend = None\n         self._backend_opts = {}\n-        self._partition_if_dynamic = True\n+        self._partition_if_dynamic = False\n         self._first_forward = True\n \n     def __setattr__(self, name, value):\n", "before": "self . _partition_if_dynamic = True", "after": "self . _partition_if_dynamic = False", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 42], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 38, 3, 42]]]"}
{"project": "pysmurf", "commit_sha": "c847ac98e77b785c1cee10ef34b9653bd6be419d", "parent_sha": "70f41b236af8a025c5e33bb2422a9b7b6bb826f3", "file_path": "python/pysmurf/core/emulators/_StreamDataEmulator.py", "project_url": "https://github.com/slaclab/pysmurf", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,7 +35,7 @@ class StreamDataEmulator(pyrogue.Device):\n             name='Disable',\n             description='Disable the processing block. Data will just pass thorough to the next slave.',\n             mode='RW',\n-            value=False,\n+            value=True,\n             localSet=lambda value: self._emulator.setDisable(value),\n             localGet=self._emulator.getDisable))\n \n", "before": "value = False ,", "after": "value = True ,", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"expression_list\", 3, 19, 3, 25], [\"true:True\", \"T\"], 0], [\"Delete\", [\"false:False\", 3, 19, 3, 24]]]"}
{"project": "pysmurf", "commit_sha": "00ec6252adb6c321ee5ac9ed590c00de64e72423", "parent_sha": "b16c62efd352bfa7f3261b25b5aebf62ef10755a", "file_path": "util/smurf_util.py", "project_url": "https://github.com/slaclab/pysmurf", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -433,7 +433,7 @@ class SmurfUtilMixin(SmurfBase):\n         return data_filename\n \n \n-    def stream_data_on(self, write_config=True, gcp_mode=True):\n+    def stream_data_on(self, write_config=False, gcp_mode=True):\n", "before": "def stream_data_on ( self , write_config = True , gcp_mode = True ) : ", "after": "def stream_data_on ( self , write_config = False , gcp_mode = True ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 30, 3, 47], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 43, 3, 47]]]"}
{"project": "pysmurf", "commit_sha": "d1e908b8363f7d2245442f6a6737aba18c1fd7b2", "parent_sha": "655be43b9571501e49c8a65c8273e65fe46c1c1a", "file_path": "tune/smurf_tune.py", "project_url": "https://github.com/slaclab/pysmurf", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2261,7 +2261,7 @@ class SmurfTuneMixin(SmurfBase):\n         # Switched to a more stable estimator\n         if lms_freq_hz is None:\n             if meas_lms_freq:\n-                lms_freq_hz = self.estimate_lms_freq(band,fraction_full_scale=fraction_full_scale,channel=channel,make_plot=True)\n+                lms_freq_hz = self.estimate_lms_freq(band,fraction_full_scale=fraction_full_scale,channel=channel,make_plot=False)\n             else:\n                 lms_freq_hz = self.config.get('tune_band').get('lms_freq')[str(band)]\n             self.lms_freq_hz[band] = lms_freq_hz\n", "before": "lms_freq_hz = self . estimate_lms_freq ( band , fraction_full_scale = fraction_full_scale , channel = channel , make_plot = True )", "after": "lms_freq_hz = self . estimate_lms_freq ( band , fraction_full_scale = fraction_full_scale , channel = channel , make_plot = False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 115, 3, 129], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 125, 3, 129]]]"}
{"project": "conda-build", "commit_sha": "427146e4d942deeb40a94a5d2e8a3976fd60b9f5", "parent_sha": "24087e9233187b64a6766a378b2cda6adea35d0a", "file_path": "conda_build/build.py", "project_url": "https://github.com/bgruening/conda-build", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -973,7 +973,7 @@ def record_prefix_files(m, files_with_prefix):\n \n         print(\"Files containing CONDA_PREFIX\")\n         print(\"-----------------------------\")\n-        detect_binary_files_with_prefix = m.get_value('build/detect_binary_files_with_prefix', False)\n+        detect_binary_files_with_prefix = m.get_value('build/detect_binary_files_with_prefix', True)\n         with open(join(m.config.info_dir, 'has_prefix'), 'w') as fo:\n             for pfix, mode, fn in files_with_prefix:\n                 ignored_because = None\n", "before": "detect_binary_files_with_prefix = m . get_value ( 'build/detect_binary_files_with_prefix' , False )", "after": "detect_binary_files_with_prefix = m . get_value ( 'build/detect_binary_files_with_prefix' , True )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 54, 3, 102], [\"true:True\", \"T\"], 3], [\"Delete\", [\"false:False\", 3, 96, 3, 101]]]"}
{"project": "hfsbe", "commit_sha": "44274fab90bf58c73ee771d05b4c74bd9f4820b0", "parent_sha": "7ebcda1531b9422c3aa39a72e2fe14f13dcdddd0", "file_path": "sbe/utility/params_parser.py", "project_url": "https://github.com/ccmt-regensburg/hfsbe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -26,7 +26,7 @@ def parse_params(user_params):\n     if hasattr(UP, 'save_approx'):\n         P.save_approx = UP.save_approx\n \n-    P.save_txt = False                      # Save data as human readable text file\n+    P.save_txt = True                       # Save data as human readable text file\n     if hasattr(UP, 'save_txt'):\n         P.save_txt = UP.save_txt\n \n", "before": "P . save_txt = False", "after": "P . save_txt = True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 5, 3, 23], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 18, 3, 23]]]"}
{"project": "flair", "commit_sha": "8a761e0e715ea5030a03bd52cd1b8e3d485b75b9", "parent_sha": "d5b60fa9af45be647fa80762ecfb6a52374c4be5", "file_path": "flair/trainers/sequence_tagger_trainer.py", "project_url": "https://github.com/datamics/flair", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ class SequenceTaggerTrainer:\n               max_epochs: int = 100,\n               anneal_factor: float = 0.5,\n               patience: int = 2,\n-              save_model: bool = False,\n+              save_model: bool = True,\n               embeddings_in_memory: bool = True,\n               train_with_dev: bool = False):\n \n", "before": "save_model : bool = False ,", "after": "save_model : bool = True ,", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"expression_list\", 3, 34, 3, 40], [\"true:True\", \"T\"], 0], [\"Delete\", [\"false:False\", 3, 34, 3, 39]]]"}
{"project": "salt", "commit_sha": "8ec6a4468014813bb32e277749b4833e39d0d0fb", "parent_sha": "3493c50f8e7874172d77ac524b1d952f879a7738", "file_path": "salt/states/user.py", "project_url": "https://github.com/StepOneInc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,7 +34,7 @@ import salt.utils\n log = logging.getLogger(__name__)\n \n \n-def _group_changes(cur, wanted, remove=True):\n+def _group_changes(cur, wanted, remove=False):\n     '''\n     Determine if the groups need to be changed\n     '''\n", "before": "def _group_changes ( cur , wanted , remove = True ) : '''\n     Determine if the groups need to be changed\n     '''", "after": "def _group_changes ( cur , wanted , remove = False ) : '''\n     Determine if the groups need to be changed\n     '''", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 33, 3, 44], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 40, 3, 44]]]"}
{"project": "dj-stripe", "commit_sha": "35a4ec2e2cbcd3bd3cb92b3c1b2db9a1b88c5ad3", "parent_sha": "68668e6bf7ca74773934f313b8c88ccf341febcf", "file_path": "djstripe/models.py", "project_url": "https://github.com/v-kopitsa/dj-stripe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -514,7 +514,7 @@ class Customer(StripeObject):\n             self.send_invoice()\n         subscription_made.send(sender=self, plan=plan, stripe_response=resp)\n \n-    def charge(self, amount, currency=\"usd\", description=None, send_receipt=False):\n+    def charge(self, amount, currency=\"usd\", description=None, send_receipt=True):\n", "before": "def charge ( self , amount , currency = \"usd\" , description = None , send_receipt = False ) : ", "after": "def charge ( self , amount , currency = \"usd\" , description = None , send_receipt = True ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 64, 3, 82], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 77, 3, 82]]]"}
{"project": "gensim", "commit_sha": "4fb424c8649cc46be780dfc051a3e3f31e1a978f", "parent_sha": "19b28f8ddfdb11658d27cdedddfb588c12a4aab2", "file_path": "gensim/models/wrappers/dtmmodel.py", "project_url": "https://github.com/springhser/gensim", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ class DtmModel(utils.SaveLoad):\n \n     def __init__(\n             self, dtm_path, corpus=None, time_slices=None, mode='fit', model='dtm', num_topics=100, id2word=None, prefix=None,\n-            lda_sequence_min_iter=6, lda_sequence_max_iter=20, lda_max_em_iter=10, alpha=0.01, top_chain_var=0.005, rng_seed=0, initialize_lda=False):\n+            lda_sequence_min_iter=6, lda_sequence_max_iter=20, lda_max_em_iter=10, alpha=0.01, top_chain_var=0.005, rng_seed=0, initialize_lda=True):\n", "before": "def __init__ ( self , dtm_path , corpus = None , time_slices = None , mode = 'fit' , model = 'dtm' , num_topics = 100 , id2word = None , prefix = None , lda_sequence_min_iter = 6 , lda_sequence_max_iter = 20 , lda_max_em_iter = 10 , alpha = 0.01 , top_chain_var = 0.005 , rng_seed = 0 , initialize_lda = False ) : ", "after": "def __init__ ( self , dtm_path , corpus = None , time_slices = None , mode = 'fit' , model = 'dtm' , num_topics = 100 , id2word = None , prefix = None , lda_sequence_min_iter = 6 , lda_sequence_max_iter = 20 , lda_max_em_iter = 10 , alpha = 0.01 , top_chain_var = 0.005 , rng_seed = 0 , initialize_lda = True ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 129, 3, 149], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 144, 3, 149]]]"}
{"project": "not_db", "commit_sha": "8978b36ec1bd147ea17c12b10a67cc08a17a8fde", "parent_sha": "006c76f64ca6eaacb784dec6c8bcf685d85e7a88", "file_path": "Not_Db/server.py", "project_url": "https://github.com/martyni/not_db", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -149,7 +149,7 @@ api.add_resource(File_Auto_Name, '/<string:db>/file/')\n api.add_resource(Book, '/<string:db>')\n \n def main():\n-   app.run(host=\"0.0.0.0\", debug=True)\n+   app.run(host=\"0.0.0.0\", debug=False)\n \n if __name__ == '__main__':\n    app.run(host=\"0.0.0.0\", debug=True)\n", "before": "app . run ( host = \"0.0.0.0\" , debug = True )", "after": "app . run ( host = \"0.0.0.0\" , debug = False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 28, 3, 38], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 34, 3, 38]]]"}
{"project": "Qcodes", "commit_sha": "bb025d1d0f31cabbfec58028a24da18f921d1eec", "parent_sha": "0cd61ac0ed2b2c65558fa83fed2a927aa363ac0f", "file_path": "qcodes/instrument_drivers/oxford/mercuryiPS.py", "project_url": "https://github.com/jenshnielsen/Qcodes", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -82,7 +82,7 @@ class MercuryiPS(IPInstrument):\n         self.add_parameter('hold_after_set',\n                            get_cmd=None, set_cmd=None,\n                            vals=Bool(),\n-                           initial_value=False,\n+                           initial_value=True,\n                            docstring='Should the driver block while waiting for the Magnet power supply '\n                                      'to go into hold mode.'\n                            )\n", "before": "self . add_parameter ( 'hold_after_set' , get_cmd = None , set_cmd = None , vals = Bool ( ) , initial_value = False , docstring = 'Should the driver block while waiting for the Magnet power supply ' 'to go into hold mode.' )", "after": "self . add_parameter ( 'hold_after_set' , get_cmd = None , set_cmd = None , vals = Bool ( ) , initial_value = True , docstring = 'Should the driver block while waiting for the Magnet power supply ' 'to go into hold mode.' )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 28, 3, 47], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 42, 3, 47]]]"}
{"project": "Qcodes", "commit_sha": "6e16aa541ebe5270da95e321cb370a702cac10e4", "parent_sha": "7854340c94e4a3d0773e74bc7ef9d0dfbb1fcc47", "file_path": "qcodes/instrument_drivers/AlazarTech/ATS.py", "project_url": "https://github.com/jenshnielsen/Qcodes", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -442,7 +442,7 @@ class AlazarParameter(Parameter):\n         super().__init__(name=name, label=label, unit=unit, vals=vals)\n         self.instrument = instrument\n         self._byte = None\n-        self._uptodate_flag = True\n+        self._uptodate_flag = False\n \n         # TODO (M) check this block\n         if byte_to_value_dict is None:\n", "before": "self . _uptodate_flag = True", "after": "self . _uptodate_flag = False", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 35], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 31, 3, 35]]]"}
{"project": "Qcodes", "commit_sha": "7874515a3c451eff10c23caa84824d5306c9ae6f", "parent_sha": "54b0f30d6ddbeae3a8b2af21bd2a2aad073ad253", "file_path": "qcodes/tests/dataset/test_measurement_context_manager.py", "project_url": "https://github.com/jenshnielsen/Qcodes", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ def empty_temp_db():\n     # create a temp database for testing\n     with tempfile.TemporaryDirectory() as tmpdirname:\n         qc.config[\"core\"][\"db_location\"] = os.path.join(tmpdirname, 'temp.db')\n-        qc.config[\"core\"][\"db_debug\"] = False\n+        qc.config[\"core\"][\"db_debug\"] = True\n         initialise_database()\n         yield\n \n", "before": "qc . config [ \"core\" ] [ \"db_debug\" ] = False", "after": "qc . config [ \"core\" ] [ \"db_debug\" ] = True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 46], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 41, 3, 46]]]"}
{"project": "Qcodes", "commit_sha": "e580b619acb659dc8f4e35c308d8bdbad4130e4a", "parent_sha": "e7799119a8ba4283589a29876beb4a95e32eb2e6", "file_path": "qcodes/instrument_drivers/Keysight/keysightb1500/KeysightB1520A.py", "project_url": "https://github.com/jenshnielsen/Qcodes", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -654,7 +654,7 @@ class B1520A(B1500Module):\n             measure_delay: float = 0,\n             abort_enabled: int = constants.Abort.ENABLED,\n             sweep_mode: int = constants.SweepMode.LINEAR,\n-            volt_monitor: bool = False\n+            volt_monitor: bool = True\n     ) -> List[str]:\n", "before": "abort_enabled : int = constants . Abort . ENABLED , sweep_mode : int = constants . SweepMode . LINEAR , volt_monitor : bool = False", "after": "abort_enabled : int = constants . Abort . ENABLED , sweep_mode : int = constants . SweepMode . LINEAR , volt_monitor : bool = True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 2, 31, 3, 39], [\"true:True\", \"T\"], 4], [\"Delete\", [\"false:False\", 3, 34, 3, 39]]]"}
{"project": "portage", "commit_sha": "db30bb430e5a022f6e358f32dbccba243637bf49", "parent_sha": "8504698e23dd3c51451ce9137fc74f66366a542d", "file_path": "pym/portage/package/ebuild/doebuild.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1033,7 +1033,7 @@ def doebuild(myebuild, mydo, _unused=DeprecationWarning, settings=None, debug=0,\n \t\t\tif mf is not None:\n \t\t\t\tdist_digests = mf.getTypeDigests(\"DIST\")\n \t\t\tif not fetch(fetchme, mysettings, listonly=listonly,\n-\t\t\t\tfetchonly=fetchonly, allow_missing_digests=True,\n+\t\t\t\tfetchonly=fetchonly, allow_missing_digests=False,\n \t\t\t\tdigests=dist_digests):\n \t\t\t\tspawn_nofetch(mydbapi, myebuild, settings=mysettings,\n \t\t\t\t\tfd_pipes=fd_pipes)\n", "before": "if not fetch ( fetchme , mysettings , listonly = listonly , fetchonly = fetchonly , allow_missing_digests = True , digests = dist_digests ) : spawn_nofetch ( mydbapi , myebuild , settings = mysettings , fd_pipes = fd_pipes )", "after": "if not fetch ( fetchme , mysettings , listonly = listonly , fetchonly = fetchonly , allow_missing_digests = False , digests = dist_digests ) : spawn_nofetch ( mydbapi , myebuild , settings = mysettings , fd_pipes = fd_pipes )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 26, 3, 52], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 48, 3, 52]]]"}
{"project": "portage", "commit_sha": "902d3661c352875e577a491bf1c758b396c95863", "parent_sha": "c752202d57a1e3163aded69301e2d71d1ea26ae7", "file_path": "pym/portage/tests/resolver/test_slot_conflict_rebuild.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -173,7 +173,7 @@ class SlotConflictRebuildTestCase(TestCase):\n \t\tworld = []\n \n \t\tplayground = ResolverPlayground(ebuilds=ebuilds,\n-\t\t\tinstalled=installed, world=world, debug=True)\n+\t\t\tinstalled=installed, world=world, debug=False)\n \t\ttry:\n \t\t\tfor test_case in test_cases:\n \t\t\t\tplayground.run_TestCase(test_case)\n", "before": "playground = ResolverPlayground ( ebuilds = ebuilds , installed = installed , world = world , debug = True )", "after": "playground = ResolverPlayground ( ebuilds = ebuilds , installed = installed , world = world , debug = False )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 38, 3, 48], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 44, 3, 48]]]"}
{"project": "ESP-Website-1", "commit_sha": "7ee279a7011d2217ea1bd5240b096ae1e0547918", "parent_sha": "db7b3b9bd27182be4811c845bc45369a15e13bde", "file_path": "esp/esp/program/setup.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/ESP-Website-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -159,7 +159,7 @@ def commit_program(prog, datatrees, userbits, modules, costs = (0, 0)):\n         new_ub = UserBit()\n         new_ub.verb = DataTree.get_by_uri(tup[0], create=True)\n         new_ub.qsc = prog.anchor\n-        new_ub.recursive = False\n+        new_ub.recursive = True\n         new_ub.startdate = tup[2]\n         new_ub.enddate = tup[3]\n         if (tup[1] is None) or (tup[1] == 0) or (tup[1] == '(all)'):\n", "before": "new_ub . recursive = False", "after": "new_ub . recursive = True", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 33], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 28, 3, 33]]]"}
{"project": "raven-python", "commit_sha": "755bb79f6e5999d776fb0b9aec56a297881b83e2", "parent_sha": "539afcd60400166f51b337a3e0b869edd00f2952", "file_path": "raven/transport/http.py", "project_url": "https://github.com/pozytywnie/raven-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -19,7 +19,7 @@ class HTTPTransport(Transport):\n \n     scheme = ['sync+http', 'sync+https']\n \n-    def __init__(self, parsed_url, timeout=defaults.TIMEOUT, verify_ssl=False,\n+    def __init__(self, parsed_url, timeout=defaults.TIMEOUT, verify_ssl=True,\n                  ca_certs=defaults.CA_BUNDLE):\n         self.check_scheme(parsed_url)\n \n", "before": "def __init__ ( self , parsed_url , timeout = defaults . TIMEOUT , verify_ssl = False , ca_certs = defaults . CA_BUNDLE ) : self . check_scheme ( parsed_url )", "after": "def __init__ ( self , parsed_url , timeout = defaults . TIMEOUT , verify_ssl = True , ca_certs = defaults . CA_BUNDLE ) : self . check_scheme ( parsed_url )", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 62, 3, 78], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 73, 3, 78]]]"}
{"project": "fabtools", "commit_sha": "daa11d5a56f863f4cce3c23b950d71b372db84fe", "parent_sha": "a8eebc136bec193305fe40e3bdadcc623d38e421", "file_path": "fabtools/require/users.py", "project_url": "https://github.com/urbn/fabtools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ import fabtools.require\n \n \n def user(name, comment=None, home=None, group=None, extra_groups=None,\n-    create_home=False, skeleton_dir=None, password=None, system=False,\n+    create_home=True, skeleton_dir=None, password=None, system=False,\n     shell=None, uid=None):\n", "before": "def user ( name , comment = None , home = None , group = None , extra_groups = None , create_home = False , skeleton_dir = None , password = None , system = False , shell = None , uid = None ) : ", "after": "def user ( name , comment = None , home = None , group = None , extra_groups = None , create_home = True , skeleton_dir = None , password = None , system = False , shell = None , uid = None ) : ", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 5, 3, 22], [\"true:True\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 17, 3, 22]]]"}
{"project": "fabtools", "commit_sha": "4087492c95a25f446c127914e13490ac980fe72b", "parent_sha": "b6b2c439303fe7ce7811c774d235d94aa6f13bbe", "file_path": "fabtools/pkg.py", "project_url": "https://github.com/urbn/fabtools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ def update_index(force=False):\n         sudo(\"%(manager)s up\" % locals())\n \n \n-def upgrade(full=True):\n+def upgrade(full=False):\n     \"\"\"\n     Upgrade all packages.\n     \"\"\"\n", "before": "def upgrade ( full = True ) : \"\"\"\n     Upgrade all packages.\n     \"\"\"", "after": "def upgrade ( full = False ) : \"\"\"\n     Upgrade all packages.\n     \"\"\"", "sstub_pattern": "CHANGE_BOOLEAN_LITERAL", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 13, 3, 22], [\"false:False\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 18, 3, 22]]]"}
{"project": "SleekXMPP", "commit_sha": "a186972f09db03c6e8dae2126ad86801cdc27d2f", "parent_sha": "751628401ebc23fd8919c99758db2878817c0056", "file_path": "sleekxmpp/exceptions.py", "project_url": "https://github.com/mayflower/SleekXMPP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ class XMPPError(Exception):\n \n-    def __init__(self, condition='undefined-condition', text=None,\n+    def __init__(self, condition='undefined-condition', text='',\n                 etype='cancel', extension=None, extension_ns=None,\n                 extension_args=None, clear=True):\n         if extension_args is None:\n", "before": "def __init__ ( self , condition = 'undefined-condition' , text = None , etype = 'cancel' , extension = None , extension_ns = None , extension_args = None , clear = True ) : if extension_args is None : ", "after": "def __init__ ( self , condition = 'undefined-condition' , text = '' , etype = 'cancel' , extension = None , extension_ns = None , extension_args = None , clear = True ) : if extension_args is None : ", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 1, 57, 1, 66], [\"string:''\", \"T\"], 2], [\"Delete\", [\"none:None\", 1, 62, 1, 66]]]"}
{"project": "blink-qt", "commit_sha": "d3ada0d84bf6923c7cdc4ae51e220ff9847a663a", "parent_sha": "687f8b9352d707be6a067e1b2ef26031d50e41d7", "file_path": "blink/presence.py", "project_url": "https://github.com/kogmbh/blink-qt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -84,7 +84,7 @@ class PresencePublicationHandler(object):\n \n         if presence_state == 'Invisible':\n             # Publish an empty offline state so that other clients are also synced\n-            return self.build_offline_pidf(account, False)\n+            return self.build_offline_pidf(account, None)\n \n         doc = pidf.PIDF(str(account.uri))\n         timestamp = ISOTimestamp.now()\n", "before": "return self . build_offline_pidf ( account , False )", "after": "return self . build_offline_pidf ( account , None )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 43, 3, 59], [\"none:None\", \"T\"], 3], [\"Delete\", [\"false:False\", 3, 53, 3, 58]]]"}
{"project": "librosa", "commit_sha": "283ccfb79c8ceeb2cd554ed2d5bcd208f4cc3ec7", "parent_sha": "7e18f0dfbddd2aeae3894df0a7c290086e294fb5", "file_path": "tests/test_features.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -458,7 +458,7 @@ def test_tempogram_fail():\n         yield __test, y, sr, None, hop_length, win_length, True, None, np.inf\n \n     # Fail when len(window) != win_length\n-    yield __test, y, sr, None, hop_length, win_length, True, np.ones(win_length + 1), np.inf\n+    yield __test, y, sr, None, hop_length, 384, True, np.ones(win_length + 1), np.inf\n \n \n def test_tempogram_audio():\n", "before": "yield __test , y , sr , None , hop_length , win_length , True , np . ones ( win_length + 1 ) , np . inf", "after": "yield __test , y , sr , None , hop_length , 384 , True , np . ones ( win_length + 1 ) , np . inf", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"expression_list\", 3, 11, 3, 93], [\"integer:384\", \"T\"], 10], [\"Delete\", [\"identifier:win_length\", 3, 44, 3, 54]]]"}
{"project": "librosa", "commit_sha": "e5e31f2d8a9890b7c8e690be50eb296984b5f4da", "parent_sha": "f979e18fa7757681b8e6bdfd9ecae33fc25d5b63", "file_path": "tests/test_core.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -182,7 +182,7 @@ def test_stft():\n             win_length = None\n \n         else:\n-            window = None\n+            window = 'hann'\n             win_length = DATA['hann_w'][0, 0]\n \n         # Compute the STFT\n", "before": "else : window = None", "after": "else : window = 'hann'", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"assignment\", 2, 9, 3, 26], [\"string:'hann'\", \"T\"], 4], [\"Delete\", [\"none:None\", 3, 22, 3, 26]]]"}
{"project": "mdtraj", "commit_sha": "bfddc272e12adee2f9c1fa7d2f46345412c0fc4b", "parent_sha": "8074efe71093c063b8bb7d8c6f80d778d75cc1ab", "file_path": "MDTraj/utils/delay_import.py", "project_url": "https://github.com/Eigenstate/mdtraj", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -107,7 +107,7 @@ def import_(module):\n     >>> # user-facing message about what's wrong (where you can install the\n     >>> # module from, etc) if the import fails\n     >>> import tables\n-    >>> tables = import_(tables)\n+    >>> tables = import_('tables')\n", "before": "tables = import_ ( tables )", "after": "tables = import_ ( 'tables' )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 25, 3, 33], [\"string:'tables'\", \"T\"], 1], [\"Delete\", [\"identifier:tables\", 3, 26, 3, 32]]]"}
{"project": "desk", "commit_sha": "c393e665d1eef4f7899c9831050566fdba9dccdd", "parent_sha": "bcfcf2cec55cc642938fbf88ab296d5dfd9d3f32", "file_path": "desk/plugin/base.py", "project_url": "https://github.com/yvess/desk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -37,7 +37,7 @@ class MergedDoc(object):\n                     empty_keys.append(item_key)\n             merged_doc.update(doc_no_empty)\n             for key in empty_keys:\n-                if key in merged_doc and merged_doc['key']:\n+                if key in merged_doc and merged_doc[key]:\n                     pass\n                 else:\n                     merged_doc[key] = []\n", "before": "if key in merged_doc and merged_doc [ 'key' ] : pass else : merged_doc [ key ] = [ ]", "after": "if key in merged_doc and merged_doc [ key ] : pass else : merged_doc [ key ] = [ ]", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"subscript\", 3, 42, 3, 59], [\"identifier:key\", \"T\"], 2], [\"Delete\", [\"string:'key'\", 3, 53, 3, 58]]]"}
{"project": "tekka", "commit_sha": "e0c82a015a497fec0220f0b16463f01fe68af9ca", "parent_sha": "4c73b4475a0228ece56a3922aaf828f83410da67", "file_path": "dialogs/preferencesDialog.py", "project_url": "https://github.com/sushi-irc/tekka", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -159,7 +159,7 @@ def colors_set_color_from_entry(entry, key):\n \tif not text:\n \t\treturn\n \n-\tconfig.set(\"colors\", \"key\", text)\n+\tconfig.set(\"colors\", key, text)\n \n def colors_own_text_written(entry, event):\n \tcolors_set_color_from_entry(entry, \"own_text\")\n", "before": "config . set ( \"colors\" , \"key\" , text )", "after": "config . set ( \"colors\" , key , text )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 12, 3, 35], [\"identifier:key\", \"T\"], 3], [\"Delete\", [\"string:\\\"key\\\"\", 3, 23, 3, 28]]]"}
{"project": "SleekXMPP", "commit_sha": "3625573c7d071db17beeeb84631fa082bdaf808a", "parent_sha": "d9e7f555e6e313b590ea3c35577c5dbbbb5b5a59", "file_path": "sleekxmpp/plugins/xep_0045.py", "project_url": "https://github.com/mayflower/SleekXMPP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -195,7 +195,7 @@ class xep_0045(base.base_plugin):\n \t\t\treturn False\n \t\treturn True\n \t\n-\tdef joinMUC(self, room, nick, maxhistory=None, password='', wait=False, pstatus=None, pshow=None):\n+\tdef joinMUC(self, room, nick, maxhistory=\"0\", password='', wait=False, pstatus=None, pshow=None):\n \t\t\"\"\" Join the specified room, requesting 'maxhistory' lines of history.\n \t\t\"\"\"\n \t\tstanza = self.xmpp.makePresence(pto=\"%s/%s\" % (room, nick), pstatus=pstatus, pshow=pshow)\n", "before": "def joinMUC ( self , room , nick , maxhistory = None , password = '' , wait = False , pstatus = None , pshow = None ) : \"\"\" Join the specified room, requesting 'maxhistory' lines of history.\n \t\t\"\"\" stanza = self . xmpp . makePresence ( pto = \"%s/%s\" % ( room , nick ) , pstatus = pstatus , pshow = pshow )", "after": "def joinMUC ( self , room , nick , maxhistory = \"0\" , password = '' , wait = False , pstatus = None , pshow = None ) : \"\"\" Join the specified room, requesting 'maxhistory' lines of history.\n \t\t\"\"\" stanza = self . xmpp . makePresence ( pto = \"%s/%s\" % ( room , nick ) , pstatus = pstatus , pshow = pshow )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 32, 3, 47], [\"string:\\\"0\\\"\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 43, 3, 47]]]"}
{"project": "goulash-bot", "commit_sha": "87fd5a44eac42654b2aa79e6fa932ff45b984515", "parent_sha": "5149acaa1eee69b4b835db3bf2e7ede99e4d043f", "file_path": "main.py", "project_url": "https://github.com/damdev/goulash-bot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -154,7 +154,7 @@ class GoulashBot:\n         return \"HAY %s (%s) [temp: %sC]!!!!\" % found\n \n     def ifttt(self, found):\n-        requests.post(\"https://maker.ifttt.com/trigger/goulash/with/key/%s\" % self.configuration.ifttt_key, data={value1: self.build_message(found)})\n+        requests.post(\"https://maker.ifttt.com/trigger/goulash/with/key/%s\" % self.configuration.ifttt_key, data={'value1': self.build_message(found)})\n \n     # Correr periodicamente\n     def check_for_goulash(self):\n", "before": "requests . post ( \"https://maker.ifttt.com/trigger/goulash/with/key/%s\" % self . configuration . ifttt_key , data = { value1 : self . build_message ( found ) } )", "after": "requests . post ( \"https://maker.ifttt.com/trigger/goulash/with/key/%s\" % self . configuration . ifttt_key , data = { 'value1' : self . build_message ( found ) } )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"pair\", 3, 115, 3, 148], [\"string:'value1'\", \"T\"], 0], [\"Delete\", [\"identifier:value1\", 3, 115, 3, 121]]]"}
{"project": "v2ray.fun", "commit_sha": "af82e3533ca23faeefa581e35048f1b10abbbae4", "parent_sha": "cbcea25caeeaf97c1a254eb96bb7e1b6f722d310", "file_path": "v2ray_util/util_core/utils.py", "project_url": "https://github.com/Jrohy/v2ray.fun", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -267,5 +267,5 @@ def readchar(prompt=\"\"):\n     finally:\n         termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)\n \n-    print(\"\")\n+    print(ch)\n     return ch.strip()\n\\ No newline at end of file\n", "before": "print ( \"\" )", "after": "print ( ch )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 10, 3, 14], [\"identifier:ch\", \"T\"], 1], [\"Delete\", [\"string:\\\"\\\"\", 3, 11, 3, 13]]]"}
{"project": "WMAS", "commit_sha": "1e219f02c4322ae8e40d9fad5662bb789df445b4", "parent_sha": "2502c46f5becb599e3a1e30754a1114e12a7d88d", "file_path": "dom/nodes/Document-contentType/support/contenttype_setter.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,7 +14,7 @@ def main(request, response):\n     content = '<head>'\n     mimeHead = request.GET.first(\"mime\", None);\n     if mimeHead:\n-        content = '<meta http-equiv=\"Content-Type\" content=\"%s; charset=utf-8\"/>' % mimeHead\n+        content += '<meta http-equiv=\"Content-Type\" content=\"%s; charset=utf-8\"/>' % mimeHead\n     content += \"</head>\"\n \n     return content\n", "before": "content = '<meta http-equiv=\"Content-Type\" content=\"%s; charset=utf-8\"/>' % mimeHead", "after": "content += '<meta http-equiv=\"Content-Type\" content=\"%s; charset=utf-8\"/>' % mimeHead", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"expression_statement\", 3, 9, 3, 93], [\"augmented_assignment\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:content\", 3, 9, 3, 16], 0], [\"Insert\", \"N0\", [\"+=:+=\", \"T\"], 1], [\"Move\", \"N0\", [\"binary_operator\", 3, 19, 3, 93], 2], [\"Delete\", [\"=:=\", 3, 17, 3, 18]], [\"Delete\", [\"assignment\", 3, 9, 3, 93]]]"}
{"project": "rllab-curriculum", "commit_sha": "127baf6390032de9b84efc77454c55956087eec3", "parent_sha": "0d5a547ec1b21f48f9b455c220670119b439c843", "file_path": "rllab/viskit/core.py", "project_url": "https://github.com/florensacc/rllab-curriculum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -96,7 +96,7 @@ def lookup(d, keys):\n def load_exps_data(exp_folder_paths, disable_variant=False, ignore_missing_keys=False):\n     exps = []\n     for exp_folder_path in exp_folder_paths:\n-        exps += [x[0] for x in os.walk(exp_folder_path, followlinks=Truey)]\n+        exps += [x[0] for x in os.walk(exp_folder_path, followlinks=True)]\n     print(\"finished walking exp folders\")\n     exps_data = []\n     for exp in exps:\n", "before": "exps += [ x [ 0 ] for x in os . walk ( exp_folder_path , followlinks = Truey ) ]", "after": "exps += [ x [ 0 ] for x in os . walk ( exp_folder_path , followlinks = True ) ]", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 57, 3, 74], [\"true:True\", \"T\"], 2], [\"Delete\", [\"identifier:Truey\", 3, 69, 3, 74]]]"}
{"project": "Yakbot-plugins", "commit_sha": "89b5b5d2dfc98d486ca2f139fa7124b9879d77e9", "parent_sha": "61f93f9fb90cf08386e65e77e6fa9ed889ef5255", "file_path": "SMPlugins/search.py", "project_url": "https://github.com/theY4Kman/Yakbot-plugins", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ class SearchPluginsError(Exception):\n     pass\n \n \n-def search(title=None, author=None, approved=True):\n+def search(title=None, author=None, approved=None):\n     args = dict([('title', title)] if title else [] + [('author', author)] if author else [])\n     if approved is not None:\n         args['approved'] = int(approved)\n", "before": "def search ( title = None , author = None , approved = True ) : args = dict ( [ ( 'title' , title ) ] if title else [ ] + [ ( 'author' , author ) ] if author else [ ] ) if approved is not None : args [ 'approved' ] = int ( approved )", "after": "def search ( title = None , author = None , approved = None ) : args = dict ( [ ( 'title' , title ) ] if title else [ ] + [ ( 'author' , author ) ] if author else [ ] ) if approved is not None : args [ 'approved' ] = int ( approved )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 37, 3, 50], [\"none:None\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 46, 3, 50]]]"}
{"project": "xmusic-crawler", "commit_sha": "e44922ca3f56f8710e6123dcaf6ce81513b2389c", "parent_sha": "a42fe6e7723729878518c36051771102642042f9", "file_path": "daemon/authorization/spotify.py", "project_url": "https://github.com/rockers7414/xmusic-crawler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -23,7 +23,7 @@ class Spotify:\n         self.parameter = {\n-            grant_type: grant_type\n+            \"grant_type\": grant_type\n         }\n \n         user_info_bytes = base64.b64encode((client_id + \":\" + client_secret).encode())\n", "before": "self . parameter = { grant_type : grant_type }", "after": "self . parameter = { \"grant_type\" : grant_type }", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"pair\", 1, 13, 1, 35], [\"string:\\\"grant_type\\\"\", \"T\"], 0], [\"Delete\", [\"identifier:grant_type\", 1, 13, 1, 23]]]"}
{"project": "WhatTodo", "commit_sha": "a500e04daf5215012f9ac9e9270ff164a73077ff", "parent_sha": "e95fbd57a090b004faef06df0c77a39d6bbf80af", "file_path": "what_todo.py", "project_url": "https://github.com/FMCorz/WhatTodo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -165,7 +165,7 @@ class WhatTodo(object):\n \tdef _highlight(self):\n \t\t\"\"\"Highlight the regions\"\"\"\n \t\tregions = self.view.get_regions('what_todo')\n-\t\tself.view.add_regions('what_todo_highlight', regions, self.s().get('scope_name'), '', sublime.DRAW_OUTLINED if self.s().get('draw_outlined') else None)\n+\t\tself.view.add_regions('what_todo_highlight', regions, self.s().get('scope_name'), '', sublime.DRAW_OUTLINED if self.s().get('draw_outlined') else 0)\n \n \tdef find(self):\n \t\t\"\"\"Creates a find timeout\"\"\"\n", "before": "self . view . add_regions ( 'what_todo_highlight' , regions , self . s ( ) . get ( 'scope_name' ) , '' , sublime . DRAW_OUTLINED if self . s ( ) . get ( 'draw_outlined' ) else None )", "after": "self . view . add_regions ( 'what_todo_highlight' , regions , self . s ( ) . get ( 'scope_name' ) , '' , sublime . DRAW_OUTLINED if self . s ( ) . get ( 'draw_outlined' ) else 0 )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"conditional_expression\", 3, 89, 3, 153], [\"integer:0\", \"T\"], 4], [\"Delete\", [\"none:None\", 3, 149, 3, 153]]]"}
{"project": "eniric", "commit_sha": "d22b5003284ddecfe4fbcc13e2f10e3e4c1e1bf0", "parent_sha": "80540656e1dc1181c05c39331263aba6c0708727", "file_path": "eniric/Qcalculator.py", "project_url": "https://github.com/jason-neal/eniric", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -111,7 +111,7 @@ def quality(wavelength: Union[Quantity, ndarray], flux: Union[Quantity, ndarray]\n     if not isinstance(flux, np.ndarray):\n         flux = np.asarray(flux)\n     \n-    flux = flux = u.dimensionless_unscaled # Turn into Quantity if not already\n+    flux = flux * u.dimensionless_unscaled # Turn into Quantity if not already\n     flux = flux / flux.unit  # Remove units from flux (sqrt(N_e) is unitless)\n \n     wis = sqrt_sum_wis(wavelength, flux)\n", "before": "flux = flux = u . dimensionless_unscaled", "after": "flux = flux * u . dimensionless_unscaled", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"assignment\", 3, 5, 3, 43], [\"binary_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:flux\", \"T\"], 0], [\"Insert\", \"N0\", [\"*:*\", \"T\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 19, 3, 43], 2], [\"Delete\", [\"identifier:flux\", 3, 5, 3, 9]], [\"Delete\", [\"=:=\", 3, 10, 3, 11]]]"}
{"project": "angr", "commit_sha": "eed6ae3f047bc58fa61c62b2d6a397bf8ca2edb5", "parent_sha": "018804d6e2bd1b5fb83d015260a2b1ca29eb3cfb", "file_path": "simuvex/s_run.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,7 +33,7 @@ class SimRunMeta(type):\n class SimRun(object):\n \t__metaclass__ = SimRunMeta\n \n-\tdef __init__(self, state, options=None, mode=None):\n+\tdef __init__(self, state, options=None, mode=\"static\"):\n \t\t# the options and mode\n \t\tif options is None:\n \t\t\toptions = o.default_options[mode]\n", "before": "def __init__ ( self , state , options = None , mode = None ) : if options is None : options = o . default_options [ mode ]", "after": "def __init__ ( self , state , options = None , mode = \"static\" ) : if options is None : options = o . default_options [ mode ]", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 42, 3, 51], [\"string:\\\"static\\\"\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 47, 3, 51]]]"}
{"project": "pyoidc", "commit_sha": "9b674e8ea367104054485d0bbf3ab40de02842c5", "parent_sha": "8dc2016be732120687f158688930a95b93db6e2d", "file_path": "src/oic/utils/keyio.py", "project_url": "https://github.com/qaavi/pyoidc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -375,9 +375,9 @@ class KeyJar(object):\n             self.issuer_keys[issuer] = []\n \n         for use in usage:\n-            self.issuer_keys[\"\"].append(KeyBundle([{\"kty\": \"oct\",\n-                                                    \"key\": key,\n-                                                    \"use\": use}]))\n+            self.issuer_keys[issuer].append(KeyBundle([{\"kty\": \"oct\",\n+                                                        \"key\": key,\n+                                                        \"use\": use}]))\n \n     def add_kb(self, issuer, kb):\n         try:\n", "before": "self . issuer_keys [ \"\" ] . append ( KeyBundle ( [ { \"kty\" : \"oct\" , \"key\" : key , \"use\" : use } ] ) )", "after": "self . issuer_keys [ issuer ] . append ( KeyBundle ( [ { \"kty\" : \"oct\" , \"key\" : key , \"use\" : use } ] ) )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"subscript\", 3, 13, 3, 33], [\"identifier:issuer\", \"T\"], 2], [\"Delete\", [\"string:\\\"\\\"\", 3, 30, 3, 32]]]"}
{"project": "docker-cpu-miner", "commit_sha": "45a19a0c5153babb6a47c6a2b5f13ab45cd46f2c", "parent_sha": "b37cca390fc9dc5ac3e8a9eec069858064cc5004", "file_path": "cpuminer_driver.py", "project_url": "https://github.com/pbutenee/docker-cpu-miner", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -160,7 +160,7 @@ def main():\n             if cpuminer_thread != None and cpuminer_thread.nof_hashes > NOF_HASHES_BEFORE_UPDATE:\n                 benchmarks[running_algorithm]['hash_rate'] = cpuminer_thread.hash_sum / cpuminer_thread.nof_hashes\n                 benchmarks[running_algorithm]['last_updated'] = time()\n-                json.dump(benchmarks, open('benchmarks.json', 'w'))\n+                json.dump(benchmarks, open(BENCHMARKS_FILE, 'w'))\n                 logging.info('UPDATED HASH RATE OF ' + running_algorithm + ' TO: ' + str(benchmarks[running_algorithm]['hash_rate']))\n \n             # Compute payout and get best algorithm\n", "before": "json . dump ( benchmarks , open ( 'benchmarks.json' , 'w' ) )", "after": "json . dump ( benchmarks , open ( BENCHMARKS_FILE , 'w' ) )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 43, 3, 67], [\"identifier:BENCHMARKS_FILE\", \"T\"], 1], [\"Delete\", [\"string:'benchmarks.json'\", 3, 44, 3, 61]]]"}
{"project": "SentEval", "commit_sha": "4f7a0d816477164837a55ce2f3b374ebd47d12fc", "parent_sha": "798db7ac8cf19946d0dd77b225d72153c7c1a2af", "file_path": "sts.py", "project_url": "https://github.com/vrindaprabhu/SentEval", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ class STSEval(object):\n         \n \n     def do_prepare(self, params, prepare):\n-        if similarity in params:\n+        if 'similarity' in params:\n             self.similarity = similarity\n         else: # Default similarity is cosine\n", "before": "if similarity in params : self . similarity = similarity else : ", "after": "if 'similarity' in params : self . similarity = similarity else : ", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 32], [\"string:'similarity'\", \"T\"], 0], [\"Delete\", [\"identifier:similarity\", 3, 12, 3, 22]]]"}
{"project": "bnm", "commit_sha": "2c590fe33c9754a7c64a4c64aeea7ececfdf5410", "parent_sha": "32a7790025cadb4c481aabf8aa94e4587f9a65b3", "file_path": "bestnewmusic/sources.py", "project_url": "https://github.com/ddbourgin/bnm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -549,7 +549,7 @@ def wfmu(oldest_first=False, n_items=None):\n             print_airplay_list(tds, next_entry(ix), \"light\", n_items)\n \n \n-def stranded(oldest_first=False, n_items=None):\n+def stranded(oldest_first=False, n_items=30):\n", "before": "def stranded ( oldest_first = False , n_items = None ) : ", "after": "def stranded ( oldest_first = False , n_items = 30 ) : ", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 34, 3, 46], [\"integer:30\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 42, 3, 46]]]"}
{"project": "dival", "commit_sha": "f8d4f84cd983d7cde492e4f081d03a10b912d1e3", "parent_sha": "89ee20793c052cdc3bbbe2fccff50d17ff66bc51", "file_path": "dival/reconstructors/reconstructor.py", "project_url": "https://github.com/jleuschn/dival", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -225,7 +225,7 @@ class IterativeReconstructor(Reconstructor):\n     def __init__(self, callback=None, **kwargs):\n-        self.callback = None\n+        self.callback = callback\n         super().__init__(**kwargs)\n \n \n", "before": "self . callback = None", "after": "self . callback = callback", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"assignment\", 1, 9, 1, 29], [\"identifier:callback\", \"T\"], 2], [\"Delete\", [\"none:None\", 1, 25, 1, 29]]]"}
{"project": "echronos-sandbox", "commit_sha": "11c26b17cc899a5ebfaf1304ee439706373c0a12", "parent_sha": "d2a3cea6565eefa5b70cc858b7336a7dea124d16", "file_path": "prj/app/prj.py", "project_url": "https://github.com/schnommus/echronos-sandbox", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1552,7 +1552,7 @@ def get_paths_from_dom(dom, element_name):\n-    for sp_el in dom.getElementsByTagName('search-path'):\n+    for sp_el in dom.getElementsByTagName(element_name):\n         yield single_text_child(sp_el).rstrip(os.sep)\n \n \n", "before": "for sp_el in dom . getElementsByTagName ( 'search-path' ) : yield single_text_child ( sp_el ) . rstrip ( os . sep )", "after": "for sp_el in dom . getElementsByTagName ( element_name ) : yield single_text_child ( sp_el ) . rstrip ( os . sep )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 0, 42, 0, 57], [\"identifier:element_name\", \"T\"], 1], [\"Delete\", [\"string:'search-path'\", 0, 43, 0, 56]]]"}
{"project": "echronos-sandbox", "commit_sha": "e401cb2ddf6754b7ccc0c0e4876feae55a3cd625", "parent_sha": "c8df53d3f4f2a75501971712b7d1ed1ade35ba44", "file_path": "prj/app/prj.py", "project_url": "https://github.com/schnommus/echronos-sandbox", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1552,7 +1552,7 @@ def get_paths_from_dom(dom, element_name):\n-    for sp_el in dom.getElementsByTagName('search-path'):\n+    for sp_el in dom.getElementsByTagName(element_name):\n         yield single_text_child(sp_el).rstrip(os.sep)\n \n \n", "before": "for sp_el in dom . getElementsByTagName ( 'search-path' ) : yield single_text_child ( sp_el ) . rstrip ( os . sep )", "after": "for sp_el in dom . getElementsByTagName ( element_name ) : yield single_text_child ( sp_el ) . rstrip ( os . sep )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 0, 42, 0, 57], [\"identifier:element_name\", \"T\"], 1], [\"Delete\", [\"string:'search-path'\", 0, 43, 0, 56]]]"}
{"project": "funcx-web-service", "commit_sha": "5b5355384e1c12cc01ed0744f52bfd8e7c2cda23", "parent_sha": "cd93ef2adc5ce4de34db7ea12cc489305dbde4cc", "file_path": "gui/routes.py", "project_url": "https://github.com/funcx-faas/funcx-web-service", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,7 +16,7 @@ guiapi = Blueprint(\"guiapi\", __name__)\n \n @guiapi.route('/')\n def start():\n-    functions_executed = \"\"\n+    functions_executed = 0\n     if 'redis_client' not in g:\n         g.redis_client = redis.Redis(\n             host=app.config['REDIS_HOST'],\n", "before": "functions_executed = \"\"", "after": "functions_executed = 0", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"assignment\", 3, 5, 3, 28], [\"integer:0\", \"T\"], 2], [\"Delete\", [\"string:\\\"\\\"\", 3, 26, 3, 28]]]"}
{"project": "OpenNMT-entmax", "commit_sha": "3e11d7bae41b5feccf12fb8267b472c892042092", "parent_sha": "b3f93266841d55c6244a0d74cfcf86b5e036830e", "file_path": "translate.py", "project_url": "https://github.com/deep-spin/OpenNMT-entmax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -99,7 +99,7 @@ def main():\n                 if opt.n_best > 1:\n                     print('\\nBEST HYP:')\n                     for n in range(opt.n_best):\n-                        print(\"[%.4f] %s\" % (predScore[b][n], \" \".join(predBatch[b][0])))\n+                        print(\"[%.4f] %s\" % (predScore[b][n], \" \".join(predBatch[b][n])))\n \n                 print('')\n \n", "before": "print ( \"[%.4f] %s\" % ( predScore [ b ] [ n ] , \" \" . join ( predBatch [ b ] [ 0 ] ) ) )", "after": "print ( \"[%.4f] %s\" % ( predScore [ b ] [ n ] , \" \" . join ( predBatch [ b ] [ n ] ) ) )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"subscript\", 3, 72, 3, 87], [\"identifier:n\", \"T\"], 2], [\"Delete\", [\"integer:0\", 3, 85, 3, 86]]]"}
{"project": "mailman3", "commit_sha": "b2f93dd974304b3d640523d67b5503ce2fe28ce8", "parent_sha": "c86eb81a8e7793c86115e318ad10dda2284f332a", "file_path": "src/mailman/app/tests/test_inject.py", "project_url": "https://github.com/stackexpress-shivam/mailman3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -144,7 +144,7 @@ class TestInjectText(unittest.TestCase):\n \n     def setUp(self):\n         self.mlist = create_list('test@example.com')\n-        self.text = b\"\"\"\\\n+        self.text = \"\"\"\\\n From: bart@example.com\n To: test@example.com\n Subject: A test message\n", "before": "self . text = b\"\"\" \\\n From : bart @ example . com", "after": "self . text = \"\"\" \\\n From : bart @ example . com", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"\\\":b\\\"\\\"\\\"\", 3, 21, 3, 25], \"\\\"\\\"\\\"\"]]"}
{"project": "pyfpdf", "commit_sha": "d2d542906434f80b6080e4c521723f890621a6b3", "parent_sha": "2f2fd861595f538806d80b4ea0e89f94ea4cd2df", "file_path": "ttfonts.py", "project_url": "https://github.com/scott1028/pyfpdf", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -107,7 +107,7 @@ class TTFontFile:\n         if (version==0x74746366):\r\n             die(\"ERROR - TrueType Fonts Collections not supported\")\r\n         if (version not in (0x00010000,0x74727565)):\r\n-            die(\"Not a TrueType font: version=\".version)\r\n+            die(\"Not a TrueType font: version=\" + version)\r\n         self.readTableDirectory()\r\n         self.extractInfo()\r\n         self.fh.close()\r\n", "before": "die ( \"Not a TrueType font: version=\" . version )", "after": "die ( \"Not a TrueType font: version=\" + version )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 16, 3, 57], [\"binary_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"string:\\\"Not a TrueType font: version=\\\"\", 3, 17, 3, 48], 0], [\"Insert\", \"N0\", [\"+:+\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:version\", 3, 49, 3, 56], 2], [\"Delete\", [\".:.\", 3, 48, 3, 49]], [\"Delete\", [\"attribute\", 3, 17, 3, 56]]]"}
{"project": "sympy", "commit_sha": "fea11ad1cfb4929a7d96e88f603a92c019d83bd9", "parent_sha": "285ece7b32adf63b4a43492e82846688016fb6a9", "file_path": "sympy/mpmath/calculus/polynomials.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -144,7 +144,7 @@ def polyroots(ctx, coeffs, maxsteps=50, cleanup=True, extraprec=10, error=False)\n     orig = ctx.prec\n     weps = +ctx.eps\n     try:\n-        ctx.prec += 10\n+        ctx.prec += extraprec\n         tol = ctx.eps * 128\n         deg = len(coeffs) - 1\n         # Must be monic\n", "before": "ctx . prec += 10", "after": "ctx . prec += extraprec", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"augmented_assignment\", 3, 9, 3, 23], [\"identifier:extraprec\", \"T\"], 2], [\"Delete\", [\"integer:10\", 3, 21, 3, 23]]]"}
{"project": "sympy", "commit_sha": "714a5081c92160dab8dc6ee42101afd4ade3634c", "parent_sha": "0b03a0bf9452ad4f4e0281d397a1789bddd7be76", "file_path": "sympy/sets/tests/test_fancysets.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -124,7 +124,7 @@ def test_ImageSet():\n     # Passing a set instead of a FiniteSet shouldn't raise\n     assert unchanged(ImageSet, Lambda(x, x**2), {1, 2, 3})\n \n-    raises(TypeError, lambda: ImageSet(Lambda(x, x**2), None))\n+    raises(TypeError, lambda: ImageSet(Lambda(x, x**2), 1))\n \n \n def test_image_is_ImageSet():\n", "before": "raises ( TypeError , lambda : ImageSet ( Lambda ( x , x ** 2 ) , None ) )", "after": "raises ( TypeError , lambda : ImageSet ( Lambda ( x , x ** 2 ) , 1 ) )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 39, 3, 62], [\"integer:1\", \"T\"], 3], [\"Delete\", [\"none:None\", 3, 57, 3, 61]]]"}
{"project": "stockz-twilio", "commit_sha": "1fc7db2cbf03239b8ea94c8a93efcd0ecaf1d13c", "parent_sha": "9122fb7d54cb0a7e27aa09dc9aae7f37d8d368b2", "file_path": "app.py", "project_url": "https://github.com/AwesomeTeamName/stockz-twilio", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -50,7 +50,7 @@ def get_error(name):\n \t\traise TypeError('name must be a string')\n \n \tif name in config['errors']:\n-\t\treturn config['errors']['name']\n+\t\treturn config['errors'][name]\n \n \treturn config['errors']['default']\n \n", "before": "return config [ 'errors' ] [ 'name' ]", "after": "return config [ 'errors' ] [ name ]", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"subscript\", 3, 10, 3, 34], [\"identifier:name\", \"T\"], 2], [\"Delete\", [\"string:'name'\", 3, 27, 3, 33]]]"}
{"project": "course-discovery", "commit_sha": "93332bdd4b57a6ee3a07c860f94aaa4f12f4a6fe", "parent_sha": "0dfca92a932af06d530742a4b6b8f0cd683b10ae", "file_path": "course_discovery/apps/course_metadata/salesforce.py", "project_url": "https://github.com/EDUlib/course-discovery", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -63,7 +63,7 @@ class SalesforceUtil:\n                 'organizationId': salesforce_config.organization_id,\n                 # security_token must be an empty string if organizationId is set\n                 'security_token': '' if salesforce_config.organization_id else salesforce_config.token,\n-                'domain': 'test' if salesforce_config.is_sandbox else ''\n+                'domain': 'test' if salesforce_config.is_sandbox else None\n             }\n             return Salesforce(**sf_kwargs)\n \n", "before": "'domain' : 'test' if salesforce_config . is_sandbox else ''", "after": "'domain' : 'test' if salesforce_config . is_sandbox else None", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"conditional_expression\", 3, 17, 3, 73], [\"none:None\", \"T\"], 4], [\"Delete\", [\"string:''\", 3, 71, 3, 73]]]"}
{"project": "django-connectwise", "commit_sha": "a1e8a3d3833aad704e0209250d4eaceab7785dca", "parent_sha": "f1ce365f9c86a756375663cf68aea0762c1eb6da", "file_path": "djconnectwise/tests/test_sync.py", "project_url": "https://github.com/trinitonesounds/django-connectwise", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -563,7 +563,7 @@ class TestSyncJob(TestCase):\n \n     def test_sync_successful(self):\n         created, updated, deleted = self.synchronizer.sync()\n-        self.assert_sync_job(created, updated, deleted, '', True)\n+        self.assert_sync_job(created, updated, deleted, None, True)\n \n     def test_sync_failed(self):\n         try:\n", "before": "self . assert_sync_job ( created , updated , deleted , '' , True )", "after": "self . assert_sync_job ( created , updated , deleted , None , True )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 29, 3, 66], [\"none:None\", \"T\"], 7], [\"Delete\", [\"string:''\", 3, 57, 3, 59]]]"}
{"project": "dosenet-raspberrypi", "commit_sha": "ad5987ddc5617bc823370cb37819c14f9d2ad7c0", "parent_sha": "8a6d7a2797c976e14022b0ff712e19f5fc98194a", "file_path": "manager.py", "project_url": "https://github.com/ludicao/dosenet-raspberrypi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -431,7 +431,7 @@ class Manager(object):\n                 DEFAULT_PORT))\n         # datalog\n         parser.add_argument(\n-            '--datalog', '-d', default=DEFAULT_DATALOG,\n+            '--datalog', '-d', default=None,\n             help='Specify a path for the datalog (default {})'.format(\n                 DEFAULT_DATALOG))\n         parser.add_argument(\n", "before": "parser . add_argument ( '--datalog' , '-d' , default = DEFAULT_DATALOG , help = 'Specify a path for the datalog (default {})' . format ( DEFAULT_DATALOG ) )", "after": "parser . add_argument ( '--datalog' , '-d' , default = None , help = 'Specify a path for the datalog (default {})' . format ( DEFAULT_DATALOG ) )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 32, 3, 55], [\"none:None\", \"T\"], 2], [\"Delete\", [\"identifier:DEFAULT_DATALOG\", 3, 40, 3, 55]]]"}
{"project": "GPflowOpt", "commit_sha": "b2929b4172900a8477076c02b9afab424d8021fb", "parent_sha": "7679a68b01f1a69d35917d43122c5d0ab7f52e20", "file_path": "GPflowOpt/scaling.py", "project_url": "https://github.com/nknudde/GPflowOpt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -75,7 +75,7 @@ class DataScaler(GPModel):\n         self._output_transform = LinearTransform(np.ones(n_outputs), np.zeros(n_outputs))\n \n         # The assignments in the constructor of GPModel take care of initial re-scaling of model data.\n-        super(DataScaler, self).__init__(model.X.value, model.Y.value, None, None, None, name=model.name+\"_datascaler\")\n+        super(DataScaler, self).__init__(model.X.value, model.Y.value, None, None, 1, name=model.name+\"_datascaler\")\n         del self.kern\n         del self.mean_function\n         del self.likelihood\n", "before": "super ( DataScaler , self ) . __init__ ( model . X . value , model . Y . value , None , None , None , name = model . name + \"_datascaler\" )", "after": "super ( DataScaler , self ) . __init__ ( model . X . value , model . Y . value , None , None , 1 , name = model . name + \"_datascaler\" )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 41, 3, 120], [\"integer:1\", \"T\"], 9], [\"Delete\", [\"none:None\", 3, 84, 3, 88]]]"}
{"project": "dosenet-raspberrypi", "commit_sha": "ffe2a5da9e1488247eb8a43e4197143cec281dff", "parent_sha": "7060fa24a7f9ec95448362e4cbb2a51b61f09a66", "file_path": "GUI_interface.py", "project_url": "https://github.com/ludicao/dosenet-raspberrypi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ def weather_test(btn):\n     app=gui(\"Weather Test\",\"800x400\")\n     def press(button):\n         if button == \"Start\":\n-            if True:\n+            while True:\n                 results=csv.writer(open(filename, \"ab+\"), delimiter = \",\")\n                 metadata=[\"Time\", \"Temp (C)\",\"Pressure (hPa)\", \"Humidity (%)\"]\n                 results.writerow(metadata)\n", "before": "if True : results = csv . writer ( open ( filename , \"ab+\" ) , delimiter = \",\" ) metadata = [ \"Time\" , \"Temp (C)\" , \"Pressure (hPa)\" , \"Humidity (%)\" ] results . writerow ( metadata )", "after": "while True : results = csv . writer ( open ( filename , \"ab+\" ) , delimiter = \",\" ) metadata = [ \"Time\" , \"Temp (C)\" , \"Pressure (hPa)\" , \"Humidity (%)\" ] results . writerow ( metadata )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"block\", 3, 13, 6, 43], [\"while_statement\", \"N0\"], 0], [\"Insert\", \"N0\", [\"while:while\", \"T\"], 0], [\"Move\", \"N0\", [\"true:True\", 3, 16, 3, 20], 1], [\"Move\", \"N0\", [\":::\", 3, 20, 3, 21], 2], [\"Move\", \"N0\", [\"block\", 4, 17, 6, 43], 3]]"}
{"project": "Stock-Data", "commit_sha": "f9e8d3413f94603cea79a90134d676f5b97d1b36", "parent_sha": "d56db3a4b2eb64570f52f464bdfd75bbe7286a58", "file_path": "stock.py", "project_url": "https://github.com/twigtheoracle/Stock-Data", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ class Stock():\n         # bin size calculations\n         minimum, maximum = stats.describe(self.data_prices, bias=False, nan_policy=\"omit\")[1]\n         minimum -= .05\n-        maximum -= .05\n+        maximum += .05\n         difference = maximum - minimum\n         bin_size = difference / self.bins\n \n", "before": "maximum -= .05", "after": "maximum += .05", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"augmented_assignment\", 3, 9, 3, 23], [\"+=:+=\", \"T\"], 1], [\"Delete\", [\"-=:-=\", 3, 17, 3, 19]]]"}
{"project": "flutterfuck", "commit_sha": "e28519887ff85f016a6fd70b24f1dc17455f5647", "parent_sha": "0e0bcc97cee1f001d05c97d33cd64dae25fb30a0", "file_path": "willie/modules/bugzilla.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ def configure(config):\n def setup(willie):\n     regexes = []\n     if willie.config.has_option('bugzilla', 'domains'):\n-        for domain in willie.config.bugzilla.get_list(domains):\n+        for domain in willie.config.bugzilla.get_list('domains'):\n             regex = re.compile('%s/show_bug.cgi\\?\\S*?id=(\\d+)' % domain)\n             regexes.append(regex)\n     else:\n", "before": "for domain in willie . config . bugzilla . get_list ( domains ) : regex = re . compile ( '%s/show_bug.cgi\\?\\S*?id=(\\d+)' % domain ) regexes . append ( regex )", "after": "for domain in willie . config . bugzilla . get_list ( 'domains' ) : regex = re . compile ( '%s/show_bug.cgi\\?\\S*?id=(\\d+)' % domain ) regexes . append ( regex )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 54, 3, 63], [\"string:'domains'\", \"T\"], 1], [\"Delete\", [\"identifier:domains\", 3, 55, 3, 62]]]"}
{"project": "flutterfuck", "commit_sha": "404f4efdc4ecc553fb38edcd0b508a9b628f0483", "parent_sha": "aaf4efcb4bcf187419aed644d8f2c4540b437653", "file_path": "willie/modules/github.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -86,7 +86,7 @@ def add_traceback(bot, trigger):\n     # Make sure the input is valid\n     args = trigger.group(2).split(None, 1)\n     if len(args) != 2:\n-        bot.say(validate)\n+        bot.say('Please give both the issue number and the error message.')\n         return\n     number, trace = args\n \n", "before": "bot . say ( validate )", "after": "bot . say ( 'Please give both the issue number and the error message.' )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 16, 3, 26], [\"string:'Please give both the issue number and the error message.'\", \"T\"], 1], [\"Delete\", [\"identifier:validate\", 3, 17, 3, 25]]]"}
{"project": "abcpy", "commit_sha": "50c0156ed2d46a3032709ab156d2f6b35cadbab8", "parent_sha": "3e1df22e76c7b532de0fa1393696b428aa47f4a1", "file_path": "abcpy/inferences.py", "project_url": "https://github.com/eth-cscs/abcpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2728,7 +2728,7 @@ class SMCABC(BaseDiscrepancy, InferenceMethod):\n \n         self.simulation_counter = 0\n \n-    def sample(self, observations, steps, n_samples=10000, n_samples_per_param=1, epsilon_final=0.1, alpha=None,\n+    def sample(self, observations, steps, n_samples=10000, n_samples_per_param=1, epsilon_final=0.1, alpha=0.95,\n                covFactor=2, resample=None, full_output=0, which_mcmc_kernel=0, r=None,\n                journal_file=None):\n", "before": "def sample ( self , observations , steps , n_samples = 10000 , n_samples_per_param = 1 , epsilon_final = 0.1 , alpha = None , covFactor = 2 , resample = None , full_output = 0 , which_mcmc_kernel = 0 , r = None , journal_file = None ) : ", "after": "def sample ( self , observations , steps , n_samples = 10000 , n_samples_per_param = 1 , epsilon_final = 0.1 , alpha = 0.95 , covFactor = 2 , resample = None , full_output = 0 , which_mcmc_kernel = 0 , r = None , journal_file = None ) : ", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 102, 3, 112], [\"float:0.95\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 108, 3, 112]]]"}
{"project": "tvm", "commit_sha": "c698a52799c15d79cdc7d1bf890fffe19964f655", "parent_sha": "ab3e88acb908c091e4027b897892b471dfd14f79", "file_path": "python/tvm/relay/frontend/tflite.py", "project_url": "https://github.com/neo-ai/tvm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -3093,7 +3093,7 @@ class OperatorConverter(object):\n         valid_count = ret[0]\n         # keep only the top 'max_detections' rows\n         ret = _op.strided_slice(\n-            ret[1], [0, 0, 0], [batch_size, custom_options[\"max_detections\"], anchor_boxes]\n+            ret[1], [0, 0, 0], [batch_size, custom_options[\"max_detections\"], 6]\n         )\n         # the output needs some reshaping to match tflite\n         ret = _op.split(ret, 6, axis=2)\n", "before": "ret = _op . strided_slice ( ret [ 1 ] , [ 0 , 0 , 0 ] , [ batch_size , custom_options [ \"max_detections\" ] , anchor_boxes ] )", "after": "ret = _op . strided_slice ( ret [ 1 ] , [ 0 , 0 , 0 ] , [ batch_size , custom_options [ \"max_detections\" ] , 6 ] )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"list\", 3, 32, 3, 92], [\"integer:6\", \"T\"], 5], [\"Delete\", [\"identifier:anchor_boxes\", 3, 79, 3, 91]]]"}
{"project": "burp_server_reports", "commit_sha": "c74b69887a0a25dcfe52cbc91a94d8330fea9732", "parent_sha": "5f3521dccb5c880b6dfe6b0626c3c4b386da3bc2", "file_path": "burp-reports.py", "project_url": "https://github.com/pablodav/burp_server_reports", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -432,7 +432,7 @@ def send_email(text_file):\n     msg['From'] = fromaddr\n     msg['To'] = toaddr\n     msg['subject'] = 'Sending content of file %s' % text_file\n-    server = smtplib.SMTP('10.196.81.38')\n+    server = smtplib.SMTP(smtp_server)\n     server.set_debuglevel(1)\n     server.send_message(msg)\n     server.quit()\n", "before": "server = smtplib . SMTP ( '10.196.81.38' )", "after": "server = smtplib . SMTP ( smtp_server )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 42], [\"identifier:smtp_server\", \"T\"], 1], [\"Delete\", [\"string:'10.196.81.38'\", 3, 27, 3, 41]]]"}
{"project": "macsyfinder", "commit_sha": "606e46f47dc2d15d8fa0d5451a5edc3ea2840c49", "parent_sha": "95a1aa3da27ac2baa3670f90d05bcf3bb07d438d", "file_path": "macsypy/config.py", "project_url": "https://github.com/gem-pasteur/macsyfinder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -54,7 +54,7 @@ class MacsyDefaults(dict):\n             prefix_data = os.path.join(__MACSY_DATA__, 'data')\n         self.cfg_file = kwargs.get('cfg_file', None)\n         self.coverage_profile = kwargs.get('coverage_profile', 0.5)\n-        self.e_value_search = kwargs.get('e_value_search', None)\n+        self.e_value_search = kwargs.get('e_value_search', 0.1)\n         self.cut_ga = kwargs.get('cut_ga', True)\n         self.db_type = kwargs.get('db_type', None)\n         self.hmmer = kwargs.get('hmmer', 'hmmsearch')\n", "before": "self . e_value_search = kwargs . get ( 'e_value_search' , None )", "after": "self . e_value_search = kwargs . get ( 'e_value_search' , 0.1 )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 41, 3, 65], [\"float:0.1\", \"T\"], 3], [\"Delete\", [\"none:None\", 3, 60, 3, 64]]]"}
{"project": "macsyfinder", "commit_sha": "37f58beffac112ef1fc650708c565cc41b5bf200", "parent_sha": "27288f0d6391bf54122da0ecd7a9633db9cdf95f", "file_path": "macsypy/config.py", "project_url": "https://github.com/gem-pasteur/macsyfinder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ class MacsyDefaults(dict):\n         self.multi_loci = kwargs.get('multi_loci', set())\n         self.mute = kwargs.get('mute', False)\n         self.out_dir = kwargs.get('out_dir', None)\n-        self.previous_run = kwargs.get('previous_run', False)\n+        self.previous_run = kwargs.get('previous_run', None)\n         self.profile_suffix = kwargs.get('profile_suffix', '.hmm')\n         self.quiet = kwargs.get('quiet', 0)\n         self.relative_path = kwargs.get('relative_path', False)\n", "before": "self . previous_run = kwargs . get ( 'previous_run' , False )", "after": "self . previous_run = kwargs . get ( 'previous_run' , None )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 39, 3, 62], [\"none:None\", \"T\"], 3], [\"Delete\", [\"false:False\", 3, 56, 3, 61]]]"}
{"project": "databroker", "commit_sha": "76bbd349e82fbc0b3cc1a4af3ea8034ea26eff20", "parent_sha": "176a34d717ab0dab49fef54f89f3ed97a36fa60e", "file_path": "metadatastore/commands.py", "project_url": "https://github.com/bluesky/databroker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -312,7 +312,7 @@ def __as_document(mongoengine_object):\n \n \n @_ensure_connection\n-def find_run_start(limit=50, **kwargs):\n+def find_run_start(limit=None, **kwargs):\n", "before": "def find_run_start ( limit = 50 , ** kwargs ) : ", "after": "def find_run_start ( limit = None , ** kwargs ) : ", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 20, 3, 28], [\"none:None\", \"T\"], 2], [\"Delete\", [\"integer:50\", 3, 26, 3, 28]]]"}
{"project": "databroker", "commit_sha": "2cd2eb008cd5ec0ab9bedcd8975bd58722048129", "parent_sha": "d5a7c8521cba296f1f054bdfe772baa2a60a5aff", "file_path": "base.py", "project_url": "https://github.com/bluesky/databroker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ class DataSourceMixin(DataSource):\n         metadata.update(self._ds.attrs)\n         return Schema(\n             datashape=None,\n-            dtype=s,\n+            dtype=None,\n             shape=None,\n             npartitions=None,\n             extra_metadata=metadata)\n", "before": "return Schema ( datashape = None , dtype = s , shape = None , npartitions = None , extra_metadata = metadata )", "after": "return Schema ( datashape = None , dtype = None , shape = None , npartitions = None , extra_metadata = metadata )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 13, 3, 20], [\"none:None\", \"T\"], 2], [\"Delete\", [\"identifier:s\", 3, 19, 3, 20]]]"}
{"project": "openbci", "commit_sha": "1700679b0d5e1dc11a3229f6edddd27b459389fb", "parent_sha": "85cc8f388930091bac6e77013cdae642160f1e6d", "file_path": "exps/ventures/maze_game/screen_text/screen_text.py", "project_url": "https://github.com/BrainTech/openbci", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -68,7 +68,7 @@ def get_instruction_1(session_type, session_condition):\n     else:\n         ret += u\"\\n\\nKulk\u0105 kieruje si\u0119 poprzez wychylenie si\u0119 w odpowiedni\u0105 stron\u0119 i pozostanie w takiej pozycji przez kilka sekund. Nale\u017cy wychyla\u0107 si\u0119 tak, aby wy\u015bwietlona strza\u0142ka stawa\u0142a si\u0119 coraz bardziej zielona.\"\n     if session_condition != 'motor':\n-        ret = u\"\\n\\n\"\n+        ret += u\"\\n\\n\"\n     ret = ret + u\"\\n<aby przej\u015b\u0107 dalej naci\u015bnij spacj\u0119>\" \n     return ret\n \n", "before": "ret = u\"\\n\\n\"", "after": "ret += u\"\\n\\n\"", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"expression_statement\", 3, 9, 3, 22], [\"augmented_assignment\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:ret\", 3, 9, 3, 12], 0], [\"Insert\", \"N0\", [\"+=:+=\", \"T\"], 1], [\"Move\", \"N0\", [\"string:u\\\"\\\\n\\\\n\\\"\", 3, 15, 3, 22], 2], [\"Delete\", [\"=:=\", 3, 13, 3, 14]], [\"Delete\", [\"assignment\", 3, 9, 3, 22]]]"}
{"project": "openbci", "commit_sha": "3de9bd866d01a4bd2a8d2fb7f89d7188ef248873", "parent_sha": "c1f76e05f25504c57b17739627297b43065481ba", "file_path": "bin/obci_run_proxy.py", "project_url": "https://github.com/BrainTech/openbci", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,7 +52,7 @@ def try_local_path_file():\n         else:\n             obci_dir_name = '.obci'\n \n-        fname = os.path.join(os.path.expanduser('~'), '.obci', 'local_path')\n+        fname = os.path.join(os.path.expanduser('~'), obci_dir_name, 'local_path')\n \n         if os.path.isfile(fname):\n             with open(fname, 'r') as f:\n", "before": "fname = os . path . join ( os . path . expanduser ( '~' ) , '.obci' , 'local_path' )", "after": "fname = os . path . join ( os . path . expanduser ( '~' ) , obci_dir_name , 'local_path' )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 29, 3, 77], [\"identifier:obci_dir_name\", \"T\"], 3], [\"Delete\", [\"string:'.obci'\", 3, 55, 3, 62]]]"}
{"project": "sweettooth", "commit_sha": "f6b2687e64c058f80d55f2f0f48f5f1f7af53ede", "parent_sha": "01cdd091cdd5a983b0062f7b54a5eefc393d4c3e", "file_path": "sweettooth/extensions/views.py", "project_url": "https://github.com/magcius/sweettooth", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -70,7 +70,7 @@ def upload_screenshot(request, pk):\n \n         return redirect('extensions-detail', pk=extension.pk)\n     else:\n-        form = UploadScreenshotForm(initial=dict(extension=\"FOO\"))\n+        form = UploadScreenshotForm(initial=dict(extension=extension))\n \n     return render(request, 'extensions/upload-screenshot.html', dict(form=form))\n \n", "before": "else : form = UploadScreenshotForm ( initial = dict ( extension = \"FOO\" ) )", "after": "else : form = UploadScreenshotForm ( initial = dict ( extension = extension ) )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 50, 3, 65], [\"identifier:extension\", \"T\"], 2], [\"Delete\", [\"string:\\\"FOO\\\"\", 3, 60, 3, 65]]]"}
{"project": "nfp", "commit_sha": "5bad162bc5a719030a2fc29b1851e1fa6636492a", "parent_sha": "3075598f9de3ae0018b9b9bdff2224cdb6dc9d6e", "file_path": "tests/layers/test_graph_layers.py", "project_url": "https://github.com/NREL/nfp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -37,7 +37,7 @@ def test_layer(smiles_inputs, layer, dropout):\n def test_global(smiles_inputs, dropout):\n     preprocessor, inputs = smiles_inputs\n \n-    atom_class = layers.Input(shape=[11], dtype=tf.int64, name='atom')\n+    atom_class = layers.Input(shape=[None], dtype=tf.int64, name='atom')\n     bond_class = layers.Input(shape=[None], dtype=tf.int64, name='bond')\n     connectivity = layers.Input(shape=[None, 2], dtype=tf.int64, name='connectivity')\n \n", "before": "atom_class = layers . Input ( shape = [ 11 ] , dtype = tf . int64 , name = 'atom' )", "after": "atom_class = layers . Input ( shape = [ None ] , dtype = tf . int64 , name = 'atom' )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"list\", 3, 37, 3, 41], [\"none:None\", \"T\"], 1], [\"Delete\", [\"integer:11\", 3, 38, 3, 40]]]"}
{"project": "taserver", "commit_sha": "421303b7d8990a4b527392b2ea540182cc7e085b", "parent_sha": "55db9923f1ac6f216f5e905b6ddb1f97cba69c4d", "file_path": "login_server/loginserver.py", "project_url": "https://github.com/Griffon26/taserver", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -170,7 +170,7 @@ class LoginServer:\n             game_server = msg.peer\n             game_server.server_id = server_id\n             game_server.match_id = server_id + 10000000\n-            game_server.game_setting_mode = 'ootb'\n+            game_server.game_setting_mode = None\n             game_server.login_server = self\n \n             self.game_servers[server_id] = game_server\n", "before": "game_server . game_setting_mode = 'ootb'", "after": "game_server . game_setting_mode = None", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"assignment\", 3, 13, 3, 51], [\"none:None\", \"T\"], 2], [\"Delete\", [\"string:'ootb'\", 3, 45, 3, 51]]]"}
{"project": "pyduofern", "commit_sha": "9153b6f3b945cb34561713df1af77c491409b404", "parent_sha": "e805e19d5e8e092264db8795302118fb366250af", "file_path": "pyduofern/duofern.py", "project_url": "https://github.com/gluap/pyduofern", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -564,7 +564,7 @@ class Duofern(object):\n                 chan = \"01\"\n \n             chans = []\n-            if (sensorMsg[id][chan] == 5):\n+            if (sensorMsg[id][\"chan\"] == 5):\n                 chanCount = 4 if (code[0:2] == \"73\") else 5\n                 for x in range(0, chanCount):\n                     if ((0x01 << x) & int(chan, 16)):\n", "before": "if ( sensorMsg [ id ] [ chan ] == 5 ) : chanCount = 4 if ( code [ 0 : 2 ] == \"73\" ) else 5 for x in range ( 0 , chanCount ) : if ( ( 0x01 << x ) & int ( chan , 16 ) ) : ", "after": "if ( sensorMsg [ id ] [ \"chan\" ] == 5 ) : chanCount = 4 if ( code [ 0 : 2 ] == \"73\" ) else 5 for x in range ( 0 , chanCount ) : if ( ( 0x01 << x ) & int ( chan , 16 ) ) : ", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"subscript\", 3, 17, 3, 36], [\"string:\\\"chan\\\"\", \"T\"], 2], [\"Delete\", [\"identifier:chan\", 3, 31, 3, 35]]]"}
{"project": "HexRaysPyTools", "commit_sha": "1b13f875dc06e9eb046c0b95dd4146102f15ccf9", "parent_sha": "14e9525a44c14cd19213b1a58f7f7a79229e1f3d", "file_path": "HexRaysPyTools/Core/StructureGraph.py", "project_url": "https://github.com/fjh658/HexRaysPyTools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -105,7 +105,7 @@ class StructureGraph:\n \n             local_tinfo = StructureGraph.get_tinfo_by_ordinal(ordinal)\n             if not local_tinfo:\n-                return\n+                continue\n             name = idc.GetLocalTypeName(ordinal)\n \n             if local_tinfo.is_typeref():\n", "before": "return", "after": "continue", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"block\", 3, 17, 3, 23], [\"continue_statement\", \"N0\"], 0], [\"Insert\", \"N0\", [\"continue:continue\", \"T\"], 0], [\"Delete\", [\"return:return\", 3, 17, 3, 23]], [\"Delete\", [\"return_statement\", 3, 17, 3, 23]]]"}
{"project": "pyo365", "commit_sha": "830b2bbbb023ccf3acb0d892929c2945e8fec721", "parent_sha": "12db5117950ce6c44462c785b2ff0dfc8bb61e5f", "file_path": "O365/attachment.py", "project_url": "https://github.com/janscas/pyo365", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -159,6 +159,6 @@ class Attachment( object ):\n \t\t\tlog.error('tried to give me an attachment as a base64 and it is not.')\n \t\t\traise\n \t\tself.json['ContentBytes'] = val\n-\t\treturn true\n+\t\treturn True\n \n #To the King!\n", "before": "return true", "after": "return True", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 3, 3, 14], [\"true:True\", \"T\"], 1], [\"Delete\", [\"identifier:true\", 3, 10, 3, 14]]]"}
{"project": "graphtools", "commit_sha": "6ed050d5df93b944b6d9c0c771b0152eeba29c00", "parent_sha": "7b442f7c2b07256f3166892c826f24e192e3f4a6", "file_path": "test/__init__.py", "project_url": "https://github.com/KrishnaswamyLab/graphtools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ def generate_swiss_roll(n_samples=1000, noise=0.5, seed=42):\n     X = np.concatenate((x, y))\n     X += noise * generator.randn(2, n_samples)\n     X = X.T[np.argsort(t)]\n-    X = np.hstack((X, z.reshape(3000, 1)))\n+    X = np.hstack((X, z.reshape(n_samples, 1)))\n     return X, sample_idx\n \n \n", "before": "X = np . hstack ( ( X , z . reshape ( 3000 , 1 ) ) )", "after": "X = np . hstack ( ( X , z . reshape ( n_samples , 1 ) ) )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 32, 3, 41], [\"identifier:n_samples\", \"T\"], 1], [\"Delete\", [\"integer:3000\", 3, 33, 3, 37]]]"}
{"project": "graphtools", "commit_sha": "7b23b1355d2467eaa991d5bed91c37f8d1ba11f5", "parent_sha": "2b965118f5ca6b0b3fc4776f73a7c8092f975702", "file_path": "test/test_landmark.py", "project_url": "https://github.com/KrishnaswamyLab/graphtools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -57,7 +57,7 @@ def test_landmark_mnn_graph():\n     X, sample_idx = generate_swiss_roll()\n     # mnn graph\n     G = build_graph(X, n_landmark=n_landmark,\n-                    thresh=1e-5, n_pca=20,\n+                    thresh=1e-5, n_pca=None,\n                     decay=10, knn=5, random_state=42,\n                     sample_idx=sample_idx)\n     assert(G.landmark_op.shape == (n_landmark, n_landmark))\n", "before": "G = build_graph ( X , n_landmark = n_landmark , thresh = 1e-5 , n_pca = 20 , decay = 10 , knn = 5 , random_state = 42 , sample_idx = sample_idx )", "after": "G = build_graph ( X , n_landmark = n_landmark , thresh = 1e-5 , n_pca = None , decay = 10 , knn = 5 , random_state = 42 , sample_idx = sample_idx )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 34, 3, 42], [\"none:None\", \"T\"], 2], [\"Delete\", [\"integer:20\", 3, 40, 3, 42]]]"}
{"project": "python-grader", "commit_sha": "60de245695e192d5891c52979e5d41976e1d5003", "parent_sha": "886e5a5e1ad8d14fcdc0dd95e99bf5321d40d77e", "file_path": "grader/code_runner.py", "project_url": "https://github.com/kspar/python-grader", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ def call_test(test_index, tester_path, solution_path, options):\n         solution_path,\n         str(test_index)\n     ]\n-    timeout = options.get(timeout, 1.0)\n+    timeout = options.get('timeout', 1.0)\n     status, stdout, stderr = call_command(cmd, timeout)\n     return status == 0, stdout, stderr\n \n", "before": "timeout = options . get ( timeout , 1.0 )", "after": "timeout = options . get ( 'timeout' , 1.0 )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 40], [\"string:'timeout'\", \"T\"], 1], [\"Delete\", [\"identifier:timeout\", 3, 27, 3, 34]]]"}
{"project": "wger_stark", "commit_sha": "c26d665ca80871d140eb2355eb5753893bdcffb0", "parent_sha": "48fae3144d2ea790eb415baf423a989555c81536", "file_path": "wger/exercises/models.py", "project_url": "https://github.com/andela/wger_stark", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -147,5 +147,5 @@ class ExerciseComment(models.Model):\n         \"\"\"\n         Comment has no owner information\n         \"\"\"\n-        return self\n+        return False\n \n", "before": "return self", "after": "return False", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 9, 3, 20], [\"false:False\", \"T\"], 1], [\"Delete\", [\"identifier:self\", 3, 16, 3, 20]]]"}
{"project": "Algorithms", "commit_sha": "d996988c79018f01d2df4272f114807145f3221a", "parent_sha": "de288c9a4f296ce74f5f13885ccd82a8ab6503f2", "file_path": "graphs/digraph.py", "project_url": "https://github.com/c-rap/Algorithms", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -18,7 +18,7 @@ class digraph(graph):\n     def __str__(self):\n         return \"Directed Graph \\nNodes: %s \\nEdges: %s\" % (self.nodes(), self.edges())\n \n-    def add_edge(self, edge, wt=1, label=\"\"):\n+    def add_edge(self, edge, wt=DEFAULT_WEIGHT, label=\"\"):\n", "before": "def add_edge ( self , edge , wt = 1 , label = \"\" ) : ", "after": "def add_edge ( self , edge , wt = DEFAULT_WEIGHT , label = \"\" ) : ", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 30, 3, 34], [\"identifier:DEFAULT_WEIGHT\", \"T\"], 2], [\"Delete\", [\"integer:1\", 3, 33, 3, 34]]]"}
{"project": "salt", "commit_sha": "791c2dac94af323b39175f8535e12ebbbee82581", "parent_sha": "d165c9cb315c133d7a56c15b9be7c0bd06738bf3", "file_path": "salt/runners/winrepo.py", "project_url": "https://github.com/htrd2016/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -201,7 +201,7 @@ def update_git_repos(opts=None, masterless=False):\n                     targetname = remote_info.split('/')[-1]\n                 else:\n                     targetname = remote_info\n-                rev = None\n+                rev = 'HEAD'\n                 # If a revision is specified, use it.\n                 try:\n                     rev, remote_url = remote_info.strip().split()\n", "before": "rev = None", "after": "rev = 'HEAD'", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"assignment\", 3, 17, 3, 27], [\"string:'HEAD'\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 23, 3, 27]]]"}
{"project": "GMhil", "commit_sha": "8f05c69991437e8231839c4c593cd03c47048ccf", "parent_sha": "38d6b69da31d62202645b043f403fee0b4dbf9aa", "file_path": "haas/cli.py", "project_url": "https://github.com/gfaline/GMhil", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -119,7 +119,7 @@ def network_create_simple(network, project):\n     url = object_url('network', network)\n     check_status_code(requests.put(url, data={'creator': project,\n                                               'access': project,\n-                                              'net_id': net_id}))\n+                                              'net_id': \"\"}))\n \n @cmd\n def network_delete(network):\n", "before": "check_status_code ( requests . put ( url , data = { 'creator' : project , 'access' : project , 'net_id' : net_id } ) )", "after": "check_status_code ( requests . put ( url , data = { 'creator' : project , 'access' : project , 'net_id' : \"\" } ) )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"pair\", 3, 47, 3, 63], [\"string:\\\"\\\"\", \"T\"], 2], [\"Delete\", [\"identifier:net_id\", 3, 57, 3, 63]]]"}
{"project": "GMhil", "commit_sha": "1654ee79483697c8e98fbc290ce34d14894aa6af", "parent_sha": "6137246446fea5cde7e67c9036d1c9d9b723a205", "file_path": "haas/model.py", "project_url": "https://github.com/gfaline/GMhil", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -325,7 +325,7 @@ class Switch(Model):\n         HaaS avoid connecting and disconnecting for each change. the session\n         object must have the methods:\n \n-            def apply_network(self, net_map):\n+            def apply_networking(self, net_map):\n", "before": "def apply_network ( self , net_map ) : ", "after": "def apply_networking ( self , net_map ) : ", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Update\", [\"identifier:apply_network\", 3, 17, 3, 30], \"apply_networking\"]]"}
{"project": "tensorflow_apps", "commit_sha": "8a827e15d2018681448533eba85fea10bb0daef5", "parent_sha": "c25b48409a941264a1d1d78be702a51ef72fd357", "file_path": "src/cnn/topology.py", "project_url": "https://github.com/jswelling/tensorflow_apps", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -319,7 +319,7 @@ def build_filter(input, pattern_str):\n             biases  = bias_variable([num_neurons])\n \n             # dense : [batch_size, num_neurons]\n-            dense = tf.nn.relu(tf.matmul(pool2_flat, weights) + biases, name=dense_binary_relu)\n+            dense = tf.nn.relu(tf.matmul(pool2_flat, weights) + biases, name='dense_binary_relu')\n             print('dense: ', dense)\n         \n         logits = _add_dense_linear_layer(dense, 2)\n", "before": "dense = tf . nn . relu ( tf . matmul ( pool2_flat , weights ) + biases , name = dense_binary_relu )", "after": "dense = tf . nn . relu ( tf . matmul ( pool2_flat , weights ) + biases , name = 'dense_binary_relu' )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 73, 3, 95], [\"string:'dense_binary_relu'\", \"T\"], 2], [\"Delete\", [\"identifier:dense_binary_relu\", 3, 78, 3, 95]]]"}
{"project": "MuGo", "commit_sha": "fb1acd33a9ece8d114fbd0183825006c9bb76202", "parent_sha": "859c490fdc1accc5f4b156edfaf08cab077b6068", "file_path": "go.py", "project_url": "https://github.com/OpneSourceAnalysisJourney/MuGo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -187,7 +187,7 @@ class Position(namedtuple('Position', 'board n komi caps groups ko last last2 pl\n         return Position(EMPTY_BOARD, n=0, komi=7.5, caps=(0, 0), groups=(set(), set()), ko=None, last=None, last2=None, player1turn=True)\n \n     def possible_moves(self):\n-        return [c for c in ALL_COORDS if self.board[c] == '.' and not is_likely_eye(self.board, c)]\n+        return [c for c in ALL_COORDS if self.board[c] == EMPTY and not is_likely_eye(self.board, c)]\n \n     def __str__(self):\n         pretty_print_map = {\n", "before": "return [ c for c in ALL_COORDS if self . board [ c ] == '.' and not is_likely_eye ( self . board , c ) ]", "after": "return [ c for c in ALL_COORDS if self . board [ c ] == EMPTY and not is_likely_eye ( self . board , c ) ]", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 42, 3, 62], [\"identifier:EMPTY\", \"T\"], 2], [\"Delete\", [\"string:'.'\", 3, 59, 3, 62]]]"}
{"project": "xos-1", "commit_sha": "ed4821bba95fd7dda5b5ea9d962ec9beeb9da222", "parent_sha": "286fad5950141323ca59e627e2542638275a2f9a", "file_path": "xos/observers/helloworldservice/steps/sync_helloworldtenant.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -32,4 +32,4 @@ class SyncHelloWorldServiceTenant(SyncInstanceUsingAnsible):\n         super(SyncHelloWorldServiceTenant, self).run_playbook(o, fields)\n \n     def delete_record(self, m):\n-        pass\n+        return\n", "before": "pass", "after": "return", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"block\", 3, 9, 3, 13], [\"return_statement\", \"N0\"], 0], [\"Insert\", \"N0\", [\"return:return\", \"T\"], 0], [\"Delete\", [\"pass:pass\", 3, 9, 3, 13]], [\"Delete\", [\"pass_statement\", 3, 9, 3, 13]]]"}
{"project": "xos-1", "commit_sha": "f3083323570eeb9838bf78a965feeb54dfb45cd0", "parent_sha": "567e3e6b85c3d78449ca17a406e09abd488755e3", "file_path": "planetstack/openstack/manager.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -305,7 +305,7 @@ class OpenStackManager:\n     def save_sliver(self, sliver):\n         if not sliver.instance_id:\n             slice_memberships = SliceMembership.objects.filter(slice=sliver.slice)\n-            pubkeys = [sm.user.public_key for sm in slice_memberships if sm.user.public_key != null]\n+            pubkeys = [sm.user.public_key for sm in slice_memberships if sm.user.public_key != None]\n             pubkeys.append(sliver.creator.public_key) \n             instance = self.driver.spawn_instance(name=sliver.name,\n                                    key_name = sliver.creator.keyname,\n", "before": "pubkeys = [ sm . user . public_key for sm in slice_memberships if sm . user . public_key != null ]", "after": "pubkeys = [ sm . user . public_key for sm in slice_memberships if sm . user . public_key != None ]", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 74, 3, 100], [\"none:None\", \"T\"], 2], [\"Delete\", [\"identifier:null\", 3, 96, 3, 100]]]"}
{"project": "elastalert", "commit_sha": "4a7c736d99824f01a4dcd27b00986a01c3082631", "parent_sha": "3bfdfe1ea6cb25949f8cd31d6ba0496a2d28c644", "file_path": "elastalert/util.py", "project_url": "https://github.com/viveksyngh/elastalert", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -47,7 +47,7 @@ def lookup_es_key(lookup_dict, term):\n         subkey = ''\n \n         while subkeys:\n-            subkey = subkeys.pop(0)\n+            subkey += subkeys.pop(0)\n             if subkey in go_deeper:\n                 go_deeper = go_deeper[subkey]\n                 subkey = ''\n", "before": "subkey = subkeys . pop ( 0 )", "after": "subkey += subkeys . pop ( 0 )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"expression_statement\", 3, 13, 3, 36], [\"augmented_assignment\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:subkey\", 3, 13, 3, 19], 0], [\"Insert\", \"N0\", [\"+=:+=\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 22, 3, 36], 2], [\"Delete\", [\"=:=\", 3, 20, 3, 21]], [\"Delete\", [\"assignment\", 3, 13, 3, 36]]]"}
{"project": "Cura", "commit_sha": "d34f54a3c723687afa82d7ae1431f574ff81b82b", "parent_sha": "544941e33e577d90eeb050c9c500dfbb56e47bdc", "file_path": "cura/Settings/ContainerManager.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -172,7 +172,7 @@ class ContainerManager(QObject):\n         containers = self._container_registry.findContainers(None, id=container_id)\n         if not containers:\n             UM.Logger.log(\"w\", \"Could not get metadata of container %s because it was not found.\", container_id)\n-            return False\n+            return \"\"\n \n         result = containers[0].getMetaDataEntry(entry_name)\n         if result:\n", "before": "return False", "after": "return \"\"", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 13, 3, 25], [\"string:\\\"\\\"\", \"T\"], 1], [\"Delete\", [\"false:False\", 3, 20, 3, 25]]]"}
{"project": "Cura", "commit_sha": "5ce237502cd53b3374c887c5353bf353798fb676", "parent_sha": "981907d26a582939afe023b0456460b4ba5ac511", "file_path": "cura/Settings/MachineManager.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -566,7 +566,7 @@ class MachineManager(QObject):\n             quality = self._active_container_stack.findContainer(type = \"quality\")\n             if quality:\n                 return Util.parseBool(quality.getMetaDataEntry(\"supported\", True))\n-        return \"\"\n+        return False\n \n     ##  Get the Quality ID associated with the currently active extruder\n     #   Note that this only returns the \"quality\", not the \"quality_changes\"\n", "before": "return \"\"", "after": "return False", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 9, 3, 18], [\"false:False\", \"T\"], 1], [\"Delete\", [\"string:\\\"\\\"\", 3, 16, 3, 18]]]"}
{"project": "Cura", "commit_sha": "a2972e26f5e2711df6157af3615b464cc921fccc", "parent_sha": "9171908c8bc578a393183b53b4e842adb013df85", "file_path": "cura/CuraApplication.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -97,7 +97,7 @@ class CuraApplication(QtApplication):\n         SettingDefinition.addSupportedProperty(\"settable_per_extruder\", DefinitionPropertyType.Any, default = True)\n         SettingDefinition.addSupportedProperty(\"settable_per_meshgroup\", DefinitionPropertyType.Any, default = True)\n         SettingDefinition.addSupportedProperty(\"settable_globally\", DefinitionPropertyType.Any, default = True)\n-        SettingDefinition.addSettingType(\"extruder\", int, str, Validator)\n+        SettingDefinition.addSettingType(\"extruder\", None, str, Validator)\n \n         ## Add the 4 types of profiles to storage.\n         Resources.addStorageType(self.ResourceTypes.QualityInstanceContainer, \"quality\")\n", "before": "SettingDefinition . addSettingType ( \"extruder\" , int , str , Validator )", "after": "SettingDefinition . addSettingType ( \"extruder\" , None , str , Validator )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 41, 3, 74], [\"none:None\", \"T\"], 3], [\"Delete\", [\"identifier:int\", 3, 54, 3, 57]]]"}
{"project": "OpenTidalFarm", "commit_sha": "09ca3c9d4eed9c5ab745d977f1249cb824b8d169", "parent_sha": "5c761906f249e1fff230c7e4f3557806821c0ab5", "file_path": "opentidalfarm/tidal.py", "project_url": "https://github.com/baba-mpe/OpenTidalFarm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -20,7 +20,7 @@ class TidalForcing(Expression):\n     def __init__(self, grid_file_name, data_file_name, ranges, utm_zone, utm_band, initial_time, constituents):\n-        self.t = None\n+        self.t = 0\n         self.utm_zone = utm_zone\n         self.utm_band = utm_band\n \n", "before": "self . t = None", "after": "self . t = 0", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"assignment\", 1, 9, 1, 22], [\"integer:0\", \"T\"], 2], [\"Delete\", [\"none:None\", 1, 18, 1, 22]]]"}
{"project": "flocker", "commit_sha": "651891310727ce7d262cb4a05f8253382c08d1e8", "parent_sha": "a56410c65934497a1ad703de6481319fb71e86d6", "file_path": "flocker/node/agents/ebs.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -488,7 +488,7 @@ def _get_volume_tag(volume, name):\n     for tag in volume.tags:\n         if tag['Key'] == name:\n             return tag['Value']\n-    return TagNotFound(volume.id, name, volume.tags)\n+    raise TagNotFound(volume.id, name, volume.tags)\n \n \n class _EC2(PClass):\n", "before": "return TagNotFound ( volume . id , name , volume . tags )", "after": "raise TagNotFound ( volume . id , name , volume . tags )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"module\", 0, 5, 7, 0], [\"raise_statement\", \"N0\"], 1], [\"Insert\", \"N0\", [\"raise:raise\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 53], 1], [\"Delete\", [\"return:return\", 3, 5, 3, 11]], [\"Delete\", [\"return_statement\", 3, 5, 3, 53]]]"}
{"project": "beets", "commit_sha": "bfa56b1d8d12979ef9ab72baa0eaf829f3a6158f", "parent_sha": "5db8f69bc1f475b3f094978555889e5cfcab6208", "file_path": "test/test_embedart.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -168,7 +168,7 @@ class EmbedartCliTest(_common.TestCase, TestHelper):\n @patch('beets.art.extract')\n class ArtSimilarityTest(unittest.TestCase):\n     def test_imagemagick_response(self, mock_extract, mock_subprocess):\n-        mock_extract.return_value = True\n+        mock_extract.return_value = b'extracted_path'\n         proc = mock_subprocess.Popen.return_value\n         log = logging.getLogger('beets.embedart')\n         item = _common.item()\n", "before": "mock_extract . return_value = True", "after": "mock_extract . return_value = b'extracted_path'", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 41], [\"string:b'extracted_path'\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 37, 3, 41]]]"}
{"project": "larray", "commit_sha": "174797955f19b0ce10e64974141f37324f57c63e", "parent_sha": "46cfcbdb9a784c5d7cab6472be1788b44ce9c78a", "file_path": "larray/core.py", "project_url": "https://github.com/alixdamman/larray", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1096,7 +1096,7 @@ class AxisCollection(object):\n             if -len(self) <= axis < len(self):\n                 return axis\n             else:\n-                return ValueError(\"axis %d is not in collection\" % axis)\n+                raise ValueError(\"axis %d is not in collection\" % axis)\n         elif isinstance(axis, Axis) and axis.name is None:\n             try:\n                 # first look by id. This avoids testing labels of each axis\n", "before": "return ValueError ( \"axis %d is not in collection\" % axis )", "after": "raise ValueError ( \"axis %d is not in collection\" % axis )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"block\", 3, 17, 3, 73], [\"raise_statement\", \"N0\"], 0], [\"Insert\", \"N0\", [\"raise:raise\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 24, 3, 73], 1], [\"Delete\", [\"return:return\", 3, 17, 3, 23]], [\"Delete\", [\"return_statement\", 3, 17, 3, 73]]]"}
{"project": "cluster_generator", "commit_sha": "f6bccd4bfbce65f05cfcd1d018cadd49e810c88a", "parent_sha": "c7aa2e25e3419b143b6a946486f2162c9622df40", "file_path": "cluster_generator/cluster_particles.py", "project_url": "https://github.com/jzuhone/cluster_generator", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -651,7 +651,7 @@ def resample_one_cluster(particles, hse, center, velocity):\n     particles[\"gas\", \"thermal_energy\"] = YTArray(get_energy(r), \"kpc**2/Myr**2\")\n     vol = particles[\"gas\", \"particle_mass\"] / particles[\"gas\", \"density\"]\n     particles[\"gas\", \"particle_mass\"] = YTArray(dens*vol.d, \"Msun\")\n-    particles[\"gas\", \"particle_velocity\"][:,:] += velocity\n+    particles[\"gas\", \"particle_velocity\"][:,:] = velocity\n     particles[\"gas\", \"density\"] = YTArray(dens, \"Msun/kpc**3\")\n     return particles\n \n", "before": "particles [ \"gas\" , \"particle_velocity\" ] [ : , : ] += velocity", "after": "particles [ \"gas\" , \"particle_velocity\" ] [ : , : ] = velocity", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"expression_statement\", 3, 5, 3, 59], [\"assignment\", \"N0\"], 0], [\"Move\", \"N0\", [\"subscript\", 3, 5, 3, 47], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:velocity\", 3, 51, 3, 59], 2], [\"Delete\", [\"+=:+=\", 3, 48, 3, 50]], [\"Delete\", [\"augmented_assignment\", 3, 5, 3, 59]]]"}
{"project": "pyload.plugins", "commit_sha": "69155bda6952e4bc88a4f1ec3a228c8f2523b358", "parent_sha": "925fde4260ab5e76820d1bc6a87a372f0a6b42d8", "file_path": "pyLoadGui.py", "project_url": "https://github.com/vuolter/pyload.plugins", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -93,7 +93,7 @@ class main(QObject):\n         self.core = None # pyLoadCore if started\n         \n         \n-        if True:\n+        if first:\n             self.tray = TrayIcon()\n             self.tray.show()\n             self.notification = Notification(self.tray)\n", "before": "if True : self . tray = TrayIcon ( ) self . tray . show ( ) self . notification = Notification ( self . tray )", "after": "if first : self . tray = TrayIcon ( ) self . tray . show ( ) self . notification = Notification ( self . tray )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 56], [\"identifier:first\", \"T\"], 1], [\"Delete\", [\"true:True\", 3, 12, 3, 16]]]"}
{"project": "TAMProxy-pyHost", "commit_sha": "2664f1101fbd9936877e8236f0726934dbdf4a43", "parent_sha": "7bae2088970cb0422e990e6fe99849339e6148de", "file_path": "tamproxy/devices/digital_input.py", "project_url": "https://github.com/skrub-wreckers/TAMProxy-pyHost", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -8,7 +8,7 @@ class DigitalInput(Device):\n \n     def __init__(self, tamproxy, pin, pullup=True, continuous=True):\n         self.pin = pin\n-        self.pullup = True\n+        self.pullup = pullup\n         self.val = 0\n         self.prev_val = None\n", "before": "self . pullup = True", "after": "self . pullup = pullup", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 27], [\"identifier:pullup\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 23, 3, 27]]]"}
{"project": "RackHD", "commit_sha": "bc2a9c4a85bdab475eb8a8c1c58d3006e28e7060", "parent_sha": "59cd2fe90b5c6ae5bd4aaba004974e96e37eaad2", "file_path": "test/tests/api/v1_1/os_install_tests.py", "project_url": "https://github.com/RackHD-Mirror/RackHD", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -181,7 +181,7 @@ class OSInstallTests(object):\n     \n     def install_windowsServer2012(self, version, nodes=[], options=None):\n         graph_name = 'Graph.InstallWindowsServer'\n-        os_repo = defaults.get('RACKHD_SMB_WINDOWS_REPO_PATH', none)\n+        os_repo = defaults.get('RACKHD_SMB_WINDOWS_REPO_PATH', None)\n         if None == os_repo:\n             fail('user must set RACKHD_SMB_WINDOWS_REPO_PATH')\n         body = options\n", "before": "os_repo = defaults . get ( 'RACKHD_SMB_WINDOWS_REPO_PATH' , none )", "after": "os_repo = defaults . get ( 'RACKHD_SMB_WINDOWS_REPO_PATH' , None )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 31, 3, 69], [\"none:None\", \"T\"], 3], [\"Delete\", [\"identifier:none\", 3, 64, 3, 68]]]"}
{"project": "spotpy", "commit_sha": "fc0126b4b034d4d54f4e884fde308504fecea35b", "parent_sha": "ebcded67b98c57addf3ecbd3f1c24eec8d584c30", "file_path": "spotpy/analyser.py", "project_url": "https://github.com/zutn/spotpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -129,7 +129,7 @@ def get_minlikeindex(results):\n     return index, minimum    \n \n \n-def get_percentiles(results,sim_number=None):\n+def get_percentiles(results,sim_number=''):\n", "before": "def get_percentiles ( results , sim_number = None ) : ", "after": "def get_percentiles ( results , sim_number = '' ) : ", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 29, 3, 44], [\"string:''\", \"T\"], 2], [\"Delete\", [\"none:None\", 3, 40, 3, 44]]]"}
{"project": "requests-html", "commit_sha": "034d43e6afddd9e52be8f88c367fd0d132bf7208", "parent_sha": "575dbfc9f2c60554d99dadb48932e3295ec8f289", "file_path": "requests_html.py", "project_url": "https://github.com/wuqiangroy/requests-html", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -268,7 +268,7 @@ class BrowserSession(Session):\n         r = super(BrowserSession, self).request(*args, **kwargs)\n \n         r._content = self.render(r.text).encode(DEFAULT_ENCODING)\n-        r.encoding = 'utf-8'\n+        r.encoding = DEFAULT_ENCODING\n \n         r.html = HTML(url=r.url, html=r.text, default_encoding=r.encoding)\n \n", "before": "r . encoding = 'utf-8'", "after": "r . encoding = DEFAULT_ENCODING", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 29], [\"identifier:DEFAULT_ENCODING\", \"T\"], 2], [\"Delete\", [\"string:'utf-8'\", 3, 22, 3, 29]]]"}
{"project": "simple_algo_trading", "commit_sha": "edf695f5e086ed6bdfdee84b8d5c74169509766b", "parent_sha": "b76993397e1a7054a567e26a3746297ef60dda1d", "file_path": "main.py", "project_url": "https://github.com/hestinr12/simple_algo_trading", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,7 +33,7 @@ def main():\n \tconfig = json.load(open('./data_config.json', 'r'))\n \t\n \ttws = Connection.create(port=tws_port, clientId=tws_client_id)\n-\ttws_manager = (tws, config, 1) \n+\ttws_manager = (tws, config, default_order_id) \n \t#demo_strat = DemoStrategy() # Soon...\n \n \n", "before": "tws_manager = ( tws , config , 1 )", "after": "tws_manager = ( tws , config , default_order_id )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"tuple\", 3, 16, 3, 32], [\"identifier:default_order_id\", \"T\"], 5], [\"Delete\", [\"integer:1\", 3, 30, 3, 31]]]"}
{"project": "salt", "commit_sha": "c1caf7bafd8aaa6b7c6ebd85839074c8de806957", "parent_sha": "60b50856968ef6648e09b95356a60a7be3117791", "file_path": "salt/states/network.py", "project_url": "https://github.com/kraney/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -409,7 +409,7 @@ def managed(name, type, enabled=True, **kwargs):\n             for iface in interfaces:\n                 if 'secondary' in interfaces[iface]:\n                     for second in interfaces[iface]['secondary']:\n-                        if second.get('label', '') == 'name':\n+                        if second.get('label', '') == name:\n                             interface_status = True\n         if enabled:\n             if 'noifupdown' not in kwargs:\n", "before": "if second . get ( 'label' , '' ) == 'name' : interface_status = True", "after": "if second . get ( 'label' , '' ) == name : interface_status = True", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 28, 3, 61], [\"identifier:name\", \"T\"], 2], [\"Delete\", [\"string:'name'\", 3, 55, 3, 61]]]"}
{"project": "reverse", "commit_sha": "a71db24a65b3a1d3e814f42e2a1353b1a8248b5a", "parent_sha": "1150195406d0ead25cb3fe05a9d9cbad2e729503", "file_path": "lib/elf.py", "project_url": "https://github.com/d4nnyk/reverse", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -108,7 +108,7 @@ class ELF:\n         for s in self.elf.iter_sections():\n             start = s.header.sh_addr\n             end = start + s.header.sh_size\n-            if  start <= addr <= end:\n+            if  start <= addr < end:\n                 return s\n         return None\n \n", "before": "if start <= addr <= end : return s", "after": "if start <= addr < end : return s", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 17, 3, 37], [\"<:<\", \"T\"], 3], [\"Delete\", [\"<=:<=\", 3, 31, 3, 33]]]"}
{"project": "reverse", "commit_sha": "ba312d015c19be187627b0a5e8ed4f563b54c1fe", "parent_sha": "6fb505984bf43d07b8928d1354282cfedebed253", "file_path": "lib/pe.py", "project_url": "https://github.com/d4nnyk/reverse", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -148,7 +148,7 @@ class PE:\n         base = self.pe.OPTIONAL_HEADER.ImageBase\n         start = base + self.rodata.VirtualAddress\n         end = start + self.rodata.SizeOfRawData\n-        return  start <= addr <= end\n+        return  start <= addr < end\n \n \n     def get_section(self, addr):\n", "before": "return start <= addr <= end", "after": "return start <= addr < end", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 17, 3, 37], [\"<:<\", \"T\"], 3], [\"Delete\", [\"<=:<=\", 3, 31, 3, 33]]]"}
{"project": "reverse", "commit_sha": "fc8daadfc2a59abf13a2d0b2633a91eb9adfc682", "parent_sha": "c826a9eaabebb2bd0aef29e33bb64b1cdc645cbb", "file_path": "lib/disassembler.py", "project_url": "https://github.com/d4nnyk/reverse", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -167,7 +167,7 @@ class Disassembler():\n         # Disassemble by block of N bytes\n         N = 1024\n \n-        d = self.binary.section_stream_read(addr, 4)\n+        d = self.binary.section_stream_read(addr, N)\n         gen = self.md.disasm(d, addr)\n \n         first = None\n", "before": "d = self . binary . section_stream_read ( addr , 4 )", "after": "d = self . binary . section_stream_read ( addr , N )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 44, 3, 53], [\"identifier:N\", \"T\"], 3], [\"Delete\", [\"integer:4\", 3, 51, 3, 52]]]"}
{"project": "salt", "commit_sha": "d50916ccdd7fe5dfc704db1d693953c8ceb92659", "parent_sha": "196b18146da980533ab7235dfabd10a79b0035a4", "file_path": "salt/states/rabbitmq_plugin.py", "project_url": "https://github.com/kraney/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -88,7 +88,7 @@ def disabled(name, runas=None):\n     try:\n         plugin_enabled = __salt__['rabbitmq.plugin_is_enabled'](name, runas=runas)\n     except CommandExecutionError as err:\n-        ret[result] = False\n+        ret['result'] = False\n         ret['comment'] = 'Error: {0}'.format(err)\n         return ret\n \n", "before": "ret [ result ] = False", "after": "ret [ 'result' ] = False", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"subscript\", 3, 9, 3, 20], [\"string:'result'\", \"T\"], 2], [\"Delete\", [\"identifier:result\", 3, 13, 3, 19]]]"}
{"project": "spiderfoot", "commit_sha": "7a4cfd053454ef3572ab1551244cf0383ee94824", "parent_sha": "bf9f053f4382fadba3901b3b5c247b3eaac22ea3", "file_path": "modules/sfp_apple_itunes.py", "project_url": "https://github.com/smicallef/spiderfoot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -138,7 +138,7 @@ class sfp_apple_itunes(SpiderFootPlugin):\n \n             app_full_name = f\"{trackName} {version} ({bundleId})\"\n \n-            if not bundleId.startswith(domain_reversed) and f\".{domain_reversed}.\" not in bundleId:\n+            if not bundleId.startswith(f\"{domain_reversed}.\") and f\".{domain_reversed}.\" not in bundleId:\n                 self.sf.debug(f\"App {app_full_name} does not match {domain_reversed}, skipping\")\n                 continue\n \n", "before": "if not bundleId . startswith ( domain_reversed ) and f\".{domain_reversed}.\" not in bundleId : self . sf . debug ( f\"App {app_full_name} does not match {domain_reversed}, skipping\" ) continue", "after": "if not bundleId . startswith ( f\"{domain_reversed}.\" ) and f\".{domain_reversed}.\" not in bundleId : self . sf . debug ( f\"App {app_full_name} does not match {domain_reversed}, skipping\" ) continue", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 39, 3, 56], [\"string:f\\\"{domain_reversed}.\\\"\", \"T\"], 1], [\"Delete\", [\"identifier:domain_reversed\", 3, 40, 3, 55]]]"}
{"project": "pritunl", "commit_sha": "0408b047ce7a1af8bed48b5c60ad495a92e55b8f", "parent_sha": "c9c59b0f28e0d9d749b40c403cd82ccc3194bf8d", "file_path": "pritunl/handlers/server.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ def server_get():\n             'name': server.name,\n             'status': 'online' if server.organizations else 'ofline',\n             'uptime': 88573 if server.organizations else None,\n-            'users_online': 16 if server.organizations else None,\n+            'users_online': 16 if server.organizations else 0,\n             'users_total': 32,\n             'network': server.network,\n             'interface': server.interface,\n", "before": "'users_online' : 16 if server . organizations else None ,", "after": "'users_online' : 16 if server . organizations else 0 ,", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"conditional_expression\", 3, 13, 3, 65], [\"integer:0\", \"T\"], 5], [\"Delete\", [\"none:None\", 3, 61, 3, 65]]]"}
{"project": "pritunl", "commit_sha": "b94f6e862ef3262b4045c59b6ef518fc19e9e1c0", "parent_sha": "adb2cf9eb9df664b2d372ea1616557a5d738a0aa", "file_path": "pritunl/queue_com.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -7,7 +7,7 @@ import subprocess\n \n class QueueCom(object):\n     def __init__(self):\n-        self.state = RUNNING\n+        self.state = None\n         self.state_lock = threading.Lock()\n         self.running = threading.Event()\n         self.running.set()\n", "before": "self . state = RUNNING", "after": "self . state = None", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 29], [\"none:None\", \"T\"], 2], [\"Delete\", [\"identifier:RUNNING\", 3, 22, 3, 29]]]"}
{"project": "pritunl", "commit_sha": "715ab2a768210d65e9535bb785eef25c3854aa15", "parent_sha": "e99fb15dbdc2aaed2ec90e48f6161067f9c442fd", "file_path": "pritunl/handlers/server.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -244,7 +244,7 @@ def server_put_post(server_id=None):\n         lzo_compression = True if flask.request.json[\n             'lzo_compression'] else False\n \n-    chiper = False\n+    chiper = None\n     chiper_def = False\n     if 'chiper' in flask.request.json:\n         chiper_def = True\n", "before": "chiper = False", "after": "chiper = None", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"assignment\", 3, 5, 3, 19], [\"none:None\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 14, 3, 19]]]"}
{"project": "napalm-eos", "commit_sha": "3fd1b1e6640f9bd5717312393f6c95199459bf9a", "parent_sha": "28a43ef51f42a07e699fca6dab5552f09e98f2dc", "file_path": "napalm_eos/eos.py", "project_url": "https://github.com/narJH27/napalm-eos", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1012,7 +1012,7 @@ class EOSDriver(NetworkDriver):\n             if prefix not in routes.keys():\n                 routes[prefix] = list()\n             route_protocol = route_details.get('routeType').upper()\n-            preference = route_details.get('preference', '')\n+            preference = route_details.get('preference', 0)\n \n             route = {\n                 'current_active': False,\n", "before": "preference = route_details . get ( 'preference' , '' )", "after": "preference = route_details . get ( 'preference' , 0 )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 43, 3, 61], [\"integer:0\", \"T\"], 3], [\"Delete\", [\"string:''\", 3, 58, 3, 60]]]"}
{"project": "pritunl", "commit_sha": "176136e0e23515f051a51b5719eb25e2118f9a29", "parent_sha": "135c502e454f2496f22d208657a050e322acf05d", "file_path": "pritunl/server_ip_pool.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -134,7 +134,7 @@ class ServerIpPool:\n                 'user_id': {'$exists': True},\n             }},\n             {'$project': {\n-                'user_id': 1,\n+                'user_id': True,\n             }},\n             {'$group': {\n                 '_id': '$user_id',\n", "before": "{ '$project' : { 'user_id' : 1 , } } ,", "after": "{ '$project' : { 'user_id' : True , } } ,", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"pair\", 3, 17, 3, 29], [\"true:True\", \"T\"], 2], [\"Delete\", [\"integer:1\", 3, 28, 3, 29]]]"}
{"project": "dups", "commit_sha": "3c9da01c5021b27c62c5b0efb5484a4cd586efdf", "parent_sha": "a10ef96fcd75bdc7ca1fd16e4025a51b4971e1e6", "file_path": "dups/utils.py", "project_url": "https://github.com/linuxwhatelse/dups", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -234,7 +234,7 @@ def rotate_gffs(datetimes, days=7, weeks=4, months=12, years=3, start=None):\n \n     for dt in datetimes:\n         # Most recent \"n\" days\n-        if dt > start - datetime.timedelta(days=7) and len(daily) < days:\n+        if dt > start - datetime.timedelta(days=days) and len(daily) < days:\n             daily.append(dt)\n             continue\n \n", "before": "if dt > start - datetime . timedelta ( days = 7 ) and len ( daily ) < days : daily . append ( dt ) continue", "after": "if dt > start - datetime . timedelta ( days = days ) and len ( daily ) < days : daily . append ( dt ) continue", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 44, 3, 50], [\"identifier:days\", \"T\"], 2], [\"Delete\", [\"integer:7\", 3, 49, 3, 50]]]"}
{"project": "openstates", "commit_sha": "71c1fc326d6228662d9c86ac5a4fcc4825818494", "parent_sha": "a7640152e06d95ce31cb35e7afffd9f288e275dc", "file_path": "openstates/oh/committees.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,7 +38,7 @@ class OHCommitteeScraper(CommitteeScraper):\n                 if comm_id < 92:\n                     chamber = \"joint\"\n \n-                committee = Committee('lower', comm_name)\n+                committee = Committee(chamber, comm_name)\n                 committee.add_source(comm_url)\n \n                 for link in page.xpath(\"//a[contains(@href, 'district')]\"):\n", "before": "committee = Committee ( 'lower' , comm_name )", "after": "committee = Committee ( chamber , comm_name )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 38, 3, 58], [\"identifier:chamber\", \"T\"], 1], [\"Delete\", [\"string:'lower'\", 3, 39, 3, 46]]]"}
{"project": "openstates", "commit_sha": "8df2bdbaa365fa103640cf6a76439774ac1cc557", "parent_sha": "bebfbe80d9aaa430e584de8383213973051fbdf8", "file_path": "openstates/sd/bills.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -146,7 +146,7 @@ class SDBillScraper(BillScraper):\n             motion = ', '.join(header.split(', ')[2:]).strip()\n             if not motion:\n                 # If we can't detect a motion, skip this vote\n-                continue\n+                return\n \n             yes_count = int(\n                 page.xpath(\"string(//td[contains(@id, 'tdAyes')])\"))\n", "before": "continue", "after": "return", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"block\", 3, 17, 3, 25], [\"return_statement\", \"N0\"], 0], [\"Insert\", \"N0\", [\"return:return\", \"T\"], 0], [\"Delete\", [\"continue:continue\", 3, 17, 3, 25]], [\"Delete\", [\"continue_statement\", 3, 17, 3, 25]]]"}
{"project": "openstates", "commit_sha": "05c6646b072444f13581961d204e12b76b1f181b", "parent_sha": "589a462dafcb98b9058e1d482b65adf9e239462f", "file_path": "fiftystates/scrape/sd/bills.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -111,7 +111,7 @@ class SDBillScraper(BillScraper):\n \n             passed = yes_count > no_count\n \n-            vote = Vote(chamber, None, motion, passed, yes_count, no_count,\n+            vote = Vote(chamber, date, motion, passed, yes_count, no_count,\n                         other_count)\n \n             if committee:\n", "before": "vote = Vote ( chamber , None , motion , passed , yes_count , no_count , other_count )", "after": "vote = Vote ( chamber , date , motion , passed , yes_count , no_count , other_count )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 24, 4, 37], [\"identifier:date\", \"T\"], 3], [\"Delete\", [\"none:None\", 3, 34, 3, 38]]]"}
{"project": "openstates", "commit_sha": "3ec94162bf47bb1301d98ce09c3a9d7641b7c782", "parent_sha": "78ff1f9f419db2b411b6cd1e7b088a275a230704", "file_path": "openstates/oh/events.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -117,7 +117,7 @@ class OHEventScraper(EventScraper):\n                             description=bill['description'],\n                             type='consideration'\n                         )\n-                    event.add_participant(\"host\", ctty, committee, chamber=chamber)\n+                    event.add_participant(\"host\", ctty, 'committee', chamber=chamber)\n                     self.save_event(event)\n \n     def scrape(self, chamber, session):\n", "before": "event . add_participant ( \"host\" , ctty , committee , chamber = chamber )", "after": "event . add_participant ( \"host\" , ctty , 'committee' , chamber = chamber )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 42, 3, 84], [\"string:'committee'\", \"T\"], 5], [\"Delete\", [\"identifier:committee\", 3, 57, 3, 66]]]"}
{"project": "openstates", "commit_sha": "b392ae285372b77e2f1e068418b7e86934c90b27", "parent_sha": "11da1235276a9ab972dfd14c41143974fb07de0f", "file_path": "openstates/ia/votes.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -230,7 +230,7 @@ def _get_chunks(el, buff=None, until=None):\n     # Tag, text, tail, recur...\n     yield tagmap.get(el.tag, '')\n     yield el.text or ''\n-    if el.text == 'until':\n+    if el.text == until:\n         return\n     for kid in el:\n         for text in _get_chunks(kid, until=until):\n", "before": "if el . text == 'until' : return", "after": "if el . text == until : return", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 8, 3, 26], [\"identifier:until\", \"T\"], 2], [\"Delete\", [\"string:'until'\", 3, 19, 3, 26]]]"}
{"project": "secrets-manager-2", "commit_sha": "3bc5f7644279d828936940624b1ccb15fac9be86", "parent_sha": "2f55709952cce2024a46594fb40741ebfe719ffc", "file_path": "s-manager.py", "project_url": "https://github.com/RcdFdz/secrets-manager-2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ def encrypt_content(json_content):\n \treturn gpg.encrypt(json_content, *finger_prints, always_trust=True, output=FILE)\n \n def decrypt_content():\n-\tfile = open('secrets', 'a+')\n+\tfile = open(FILE, 'a+')\n \tfile.seek(0)\n \treturn gpg.decrypt(file.read())\n \n", "before": "file = open ( 'secrets' , 'a+' )", "after": "file = open ( FILE , 'a+' )", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 13, 3, 30], [\"identifier:FILE\", \"T\"], 1], [\"Delete\", [\"string:'secrets'\", 3, 14, 3, 23]]]"}
{"project": "openstates", "commit_sha": "2a39d76398c4e7721e82c292a2916c571014f44a", "parent_sha": "dcf2d193ba4775afe8e76a7ce598303e99f30734", "file_path": "billy/site/browse/views.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -62,7 +62,7 @@ def all_states(request, template='billy/index.html'):\n                 state['external_ids'] = (1 - (missing_ids /\n                                               (active_legs * 2))) * 100\n                 total_missing_ids += missing_ids\n-                total_active = active_legs\n+                total_active += active_legs\n \n             missing_bill_sources = db.bills.find({'state': state['id'],\n                                               'sources': {'$size': 0}}).count()\n", "before": "total_active = active_legs", "after": "total_active += active_legs", "sstub_pattern": "SINGLE_TOKEN", "edit_script": "[[\"Insert\", [\"expression_statement\", 3, 17, 3, 43], [\"augmented_assignment\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:total_active\", 3, 17, 3, 29], 0], [\"Insert\", \"N0\", [\"+=:+=\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:active_legs\", 3, 32, 3, 43], 2], [\"Delete\", [\"=:=\", 3, 30, 3, 31]], [\"Delete\", [\"assignment\", 3, 17, 3, 43]]]"}
{"project": "nixops", "commit_sha": "b416286049bb036009b302c01db8f81b28d060d6", "parent_sha": "c2f86ffb2ae8532e0d43182f2f70d2283811b286", "file_path": "charon/deployment.py", "project_url": "https://github.com/zalora/nixops", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -148,7 +148,7 @@ class Deployment:\n                 if response == \"\": return False\n                 response = response.rstrip().lower()\n                 if response == \"y\": return True\n-                if response == \"n\": return False\n+                if response == \"n\" or response == \"\": return False\n \n \n     def evaluate(self):\n", "before": "if response == \"n\" : return False", "after": "if response == \"n\" or response == \"\" : return False", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 3, 49], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 35], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:response\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:\\\"\\\"\", \"T\"], 2]]"}
{"project": "nixops", "commit_sha": "8013132d582dc8123a00e895b5d6c6df1f38622d", "parent_sha": "f4181da8725ea910d9e7ceea6c30be851769906e", "file_path": "charon/backends/ec2.py", "project_url": "https://github.com/zalora/nixops", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -412,7 +412,7 @@ class EC2State(MachineState):\n             self.write()\n \n         # Assign or release an elastic IP address, if given.\n-        if (self._elastic_ipv4 or \"\") != defn.elastic_ipv4:\n+        if (self._elastic_ipv4 or \"\") != defn.elastic_ipv4 or check:\n             self.connect()\n             if defn.elastic_ipv4 != \"\":\n                 # wait until machine is in running state\n", "before": "if ( self . _elastic_ipv4 or \"\" ) != defn . elastic_ipv4 : self . connect ( ) if defn . elastic_ipv4 != \"\" : ", "after": "if ( self . _elastic_ipv4 or \"\" ) != defn . elastic_ipv4 or check : self . connect ( ) if defn . elastic_ipv4 != \"\" : ", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 57], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 59], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:check\", \"T\"], 2]]"}
{"project": "nupic", "commit_sha": "2fb330c5a767233c3697d3abe037fb3ef78bd463", "parent_sha": "32d9dc3f86f39c15a646d893303b31283b96c8ed", "file_path": "nupic/algorithms/anomaly.py", "project_url": "https://github.com/newicon/nupic", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -94,7 +94,7 @@ class Anomaly(object):\n     else:\n       self._movingAverage = None\n \n-    if self._mode == Anomaly.MODE_LIKELIHOOD:\n+    if self._mode == Anomaly.MODE_LIKELIHOOD or self._mode == Anomaly.MODE_WEIGHTED:\n       self._likelihood = AnomalyLikelihood() # probabilistic anomaly\n     if not self._mode in Anomaly._supportedModes:\n       raise ValueError(\"Invalid anomaly mode; only supported modes are: \"\n", "before": "if self . _mode == Anomaly . MODE_LIKELIHOOD : self . _likelihood = AnomalyLikelihood ( )", "after": "if self . _mode == Anomaly . MODE_LIKELIHOOD or self . _mode == Anomaly . MODE_WEIGHTED : self . _likelihood = AnomalyLikelihood ( )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 4, 69], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 45], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 2], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:_mode\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:Anomaly\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:MODE_WEIGHTED\", \"T\"], 2]]"}
{"project": "stoq", "commit_sha": "2584d2fce0506700f0921278b794803f869d3726", "parent_sha": "48336f6e7f62659a5033f85aafaf2fcbde09628d", "file_path": "stoqlib/interface/list.py", "project_url": "https://github.com/bellini666/stoq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -90,7 +90,7 @@ class AdditionListSlave(Delegates.SlaveDelegate):\n         if not services.finish_transaction(self.parent.conn, model):\n             services._warn('Transaction not concluded. Probably a failure.')\n             return\n-        if edit_mode:\n+        if edit_mode or model in self.klist:\n             self.klist.update_instance(model)\n             self.parent.on_edit_item(model)\n         else:\n", "before": "if edit_mode : self . klist . update_instance ( model ) self . parent . on_edit_item ( model ) else : ", "after": "if edit_mode or model in self . klist : self . klist . update_instance ( model ) self . parent . on_edit_item ( model ) else : ", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 14], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:edit_mode\", 3, 12, 3, 21], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:model\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 2], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:klist\", \"T\"], 2]]"}
{"project": "PyMonopoly", "commit_sha": "792fcad1021797b5eca438b648e5890a95049c9e", "parent_sha": "127eadc75b88105b306597a27562d74fb5119d51", "file_path": "LIB/modules/GameObjects.py", "project_url": "https://github.com/Kycko/PyMonopoly", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -94,7 +94,7 @@ class FieldCell():\n         if not self.number % 10:\n             y = 35\n         elif self.group in ('chance', 'chest', 'income', 'railroad', 'service', 'tax'):\n-            if self.group == 'income' and self.number in (13, 32):\n+            if (self.group == 'income' and self.number in (13, 32)) or (self.group == 'tax' and self.number == 38):\n                 y = -7\n             else:\n                 y = (self.rect.h-self.group_symbol.get_height())/2\n", "before": "if self . group == 'income' and self . number in ( 13 , 32 ) : y = - 7 else : y = ( self . rect . h - self . group_symbol . get_height ( ) ) / 2", "after": "if ( self . group == 'income' and self . number in ( 13 , 32 ) ) or ( self . group == 'tax' and self . number == 38 ) : y = - 7 else : y = ( self . rect . h - self . group_symbol . get_height ( ) ) / 2", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 16, 3, 66], [\"parenthesized_expression\", \"N0\"], 0], [\"Insert\", [\"boolean_operator\", 3, 16, 3, 66], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 16, 3, 66], [\"parenthesized_expression\", \"N1\"], 2], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"boolean_operator\", 3, 16, 3, 66], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"boolean_operator\", \"N2\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"comparison_operator\", \"N3\"], 0], [\"Insert\", \"N2\", [\"and:and\", \"T\"], 1], [\"Insert\", \"N2\", [\"comparison_operator\", \"N4\"], 2], [\"Insert\", \"N3\", [\"attribute\", \"N5\"], 0], [\"Insert\", \"N3\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N3\", [\"string:'tax'\", \"T\"], 2], [\"Insert\", \"N4\", [\"attribute\", \"N6\"], 0], [\"Insert\", \"N4\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N4\", [\"integer:38\", \"T\"], 2], [\"Insert\", \"N5\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N5\", [\".:.\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:group\", \"T\"], 2], [\"Insert\", \"N6\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N6\", [\".:.\", \"T\"], 1], [\"Insert\", \"N6\", [\"identifier:number\", \"T\"], 2]]"}
{"project": "qal", "commit_sha": "d6ca2a1f4ed12063df20c7748687ad2fad1ee27c", "parent_sha": "2d39dd19b2aff5d47cb40b4fce61137bd8c0c2e2", "file_path": "qal/dal/dal.py", "project_url": "https://github.com/OptimalBPM/qal", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -72,7 +72,7 @@ class Database_Abstraction_Layer(object):\n \n         elif (self.db_type == DB_POSTGRESQL):\n             import postgresql.driver as pg_driver \n-            if self.DB_Port == None or self.DB_Port == \"\":\n+            if self.DB_Port == None or self.DB_Port == \"\" or self.DB_Port == 0:\n                 _port = 5432\n             else:\n                 _port = self.DB_Port\n", "before": "if self . DB_Port == None or self . DB_Port == \"\" : _port = 5432 else : _port = self . DB_Port", "after": "if self . DB_Port == None or self . DB_Port == \"\" or self . DB_Port == 0 : _port = 5432 else : _port = self . DB_Port", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 16, 3, 58], [\"boolean_operator\", 3, 16, 3, 58], 0], [\"Insert\", [\"boolean_operator\", 3, 16, 3, 58], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 16, 3, 58], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N0\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:DB_Port\", \"T\"], 2]]"}
{"project": "tribler", "commit_sha": "747641853c061df0eb2db250a08484ef311e2eb5", "parent_sha": "402c2679ec47f990a67336536d36758b9fde56eb", "file_path": "Tribler/Core/CacheDB/SqliteCacheDBHandler.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -861,7 +861,7 @@ class TorrentDBHandler(BasicDBHandler):\n             self._db.executemany(sql, new_mapping_list)\n \n         # add trackers into the torrent file if it has been collected\n-        if not self.session.get_torrent_store():\n+        if not self.session.get_torrent_store() or self.session.lm.torrent_store is None:\n             return\n \n         infohash = self.getInfohash(torrent_id)\n", "before": "if not self . session . get_torrent_store ( ) : return", "after": "if not self . session . get_torrent_store ( ) or self . session . lm . torrent_store is None : return", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 12, 3, 48], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 48], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:torrent_store\", \"T\"], 2], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:lm\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:session\", \"T\"], 2]]"}
{"project": "tribler", "commit_sha": "f27dd7e4b95da67027a1734efbc810798fb49c33", "parent_sha": "09662e2cdf9296f03f184d072ad652e7b26fbc3d", "file_path": "Tribler/Core/APIImplementation/LaunchManyCore.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -497,7 +497,7 @@ class TriblerLaunchMany(TaskManager):\n \n         self._logger.debug(\"tlm: load_checkpoint: pstate is %s %s\",\n                            pstate.get('dlstate', 'status'), pstate.get('dlstate', 'progress'))\n-        if pstate.get('state', 'engineresumedata') is None:\n+        if pstate is None or pstate.get('state', 'engineresumedata') is None:\n             self._logger.debug(\"tlm: load_checkpoint: resumedata None\")\n         else:\n             self._logger.debug(\"tlm: load_checkpoint: resumedata len %d\", len(pstate.get('state', 'engineresumedata')))\n", "before": "if pstate . get ( 'state' , 'engineresumedata' ) is None : self . _logger . debug ( \"tlm: load_checkpoint: resumedata None\" ) else : self . _logger . debug ( \"tlm: load_checkpoint: resumedata len %d\" , len ( pstate . get ( 'state' , 'engineresumedata' ) ) )", "after": "if pstate is None or pstate . get ( 'state' , 'engineresumedata' ) is None : self . _logger . debug ( \"tlm: load_checkpoint: resumedata None\" ) else : self . _logger . debug ( \"tlm: load_checkpoint: resumedata len %d\" , len ( pstate . get ( 'state' , 'engineresumedata' ) ) )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 120], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 59], 2], [\"Insert\", \"N1\", [\"identifier:pstate\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2]]"}
{"project": "tribler", "commit_sha": "fa7594b84d8495aa10a468958f3d83142549fa54", "parent_sha": "1e3170099b41ea88a67df7f3b5e7eb4311262881", "file_path": "Tribler/Core/Swift/SwiftProcess.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -83,7 +83,7 @@ class SwiftProcess:\n             args.append(\"180\") # seconds\r\n         #args.append(\"-B\") # Enable debugging on swift        \r\n         \r\n-        if DEBUG:\r\n+        if True or DEBUG:\r\n             print >>sys.stderr,\"SwiftProcess: __init__: Running\",args,\"workdir\",workdir\r\n         \r\n         if sys.platform == \"win32\":\r\n", "before": "if DEBUG : print >> sys . stderr , \"SwiftProcess: __init__: Running\" , args , \"workdir\" , workdir", "after": "if True or DEBUG : print >> sys . stderr , \"SwiftProcess: __init__: Running\" , args , \"workdir\" , workdir", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 88], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"true:True\", \"T\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:DEBUG\", 3, 12, 3, 17], 2]]"}
{"project": "WMAS", "commit_sha": "dcfcadb2c6892a187de6f0be7c42eed09d91fe90", "parent_sha": "5782d6704b66adbcce7398911a74a4abdf323ef7", "file_path": "tools/wptrunner/wptrunner/testloader.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -661,7 +661,7 @@ class PathGroupedSource(GroupedSource):\n     @classmethod\n     def new_group(cls, state, test, **kwargs):\n         depth = kwargs.get(\"depth\")\n-        if depth is True:\n+        if depth is True or depth == 0:\n             depth = None\n         path = urlparse.urlsplit(test.url).path.split(\"/\")[1:-1][:depth]\n         rv = path != state.get(\"prev_path\")\n", "before": "if depth is True : depth = None", "after": "if depth is True or depth == 0 : depth = None", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 25], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 25], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:depth\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2]]"}
{"project": "Btools", "commit_sha": "ed05d8593fe968fb5f3737a90eb405c4b538a0e6", "parent_sha": "e747573e9b7d3cc9c8e68f379c07e81f4a588a73", "file_path": "models.py", "project_url": "https://github.com/gr/Btools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -26,7 +26,7 @@ class BooksField(TextField):\n             return base64.encodestring(pickle.dumps(pickling_books, 2))\n         \n     def to_python(self, value):\n-        if not isinstance(value, basestring):\n+        if not isinstance(value, basestring) or value in ( False, None, '' ):\n             return value \n         books_fields = pickle.loads(base64.decodestring(value))\n         return [ Output( book_fields, 'utf-8') for book_fields in books_fields ]\n", "before": "if not isinstance ( value , basestring ) : return value", "after": "if not isinstance ( value , basestring ) or value in ( False , None , '' ) : return value", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 12, 3, 45], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 45], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:value\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"tuple\", \"N2\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"false:False\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"none:None\", \"T\"], 3], [\"Insert\", \"N2\", [\",:,\", \"T\"], 4], [\"Insert\", \"N2\", [\"string:''\", \"T\"], 5], [\"Insert\", \"N2\", [\"):)\", \"T\"], 6]]"}
{"project": "Visual_Script", "commit_sha": "63c98261b1a3dc6d395d53a74172b0d46d4ed2f9", "parent_sha": "ead8c08315c382b518974527749320f8cf44b35b", "file_path": "GeometrA/src/ADB/adbRobot.py", "project_url": "https://github.com/NTUTVisualScript/Visual_Script", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -119,7 +119,7 @@ class ADBRobot(Robot):\n     def get_device_size(self):\n         result = subprocess.getoutput('adb shell wm size')\n         sizeList = result.split('\\n')\n-        if sizeList[1] is \"\":\n+        if len(sizeList) == 1 or sizeList[1] is \"\":\n             sizeList = sizeList[0].split(':') #Only physical size\n         else:\n             sizeList = sizeList[1].split(':') #Override size\n", "before": "if sizeList [ 1 ] is \"\" : sizeList = sizeList [ 0 ] . split ( ':' ) else : sizeList = sizeList [ 1 ] . split ( ':' )", "after": "if len ( sizeList ) == 1 or sizeList [ 1 ] is \"\" : sizeList = sizeList [ 0 ] . split ( ':' ) else : sizeList = sizeList [ 1 ] . split ( ':' )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 46], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 29], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:1\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:sizeList\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "angr", "commit_sha": "86f9745c9e67c225a262790834bf042462fc08b4", "parent_sha": "c7a6c538a3937e7e97a5d105b288e890fe66a58c", "file_path": "simuvex/s_cc.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -456,7 +456,7 @@ class SimCC(object):\n                     (self.func_ty is not None and isinstance(self.func_ty.args[i], s_type.SimTypeFloat)):\n                 arg_locs[i] = arg_session.next_arg(is_fp=True, size=val.length/8)\n                 continue\n-            if val.length > state.arch.bits:\n+            if val.length > state.arch.bits or not isinstance(arg, (int, long)):\n                 vals[i] = allocator.dump(val, state)\n             elif val.length < state.arch.bits:\n                 if self.arch.memory_endness == 'Iend_LE':\n", "before": "if val . length > state . arch . bits : vals [ i ] = allocator . dump ( val , state ) elif val . length < state . arch . bits : if self . arch . memory_endness == 'Iend_LE' : ", "after": "if val . length > state . arch . bits or not isinstance ( arg , ( int , long ) ) : vals [ i ] = allocator . dump ( val , state ) elif val . length < state . arch . bits : if self . arch . memory_endness == 'Iend_LE' : ", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 58], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 44], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"call\", \"N2\"], 1], [\"Insert\", \"N2\", [\"identifier:isinstance\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:arg\", \"T\"], 1], [\"Insert\", \"N3\", [\",:,\", \"T\"], 2], [\"Insert\", \"N3\", [\"tuple\", \"N4\"], 3], [\"Insert\", \"N3\", [\"):)\", \"T\"], 4], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"identifier:int\", \"T\"], 1], [\"Insert\", \"N4\", [\",:,\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:long\", \"T\"], 3], [\"Insert\", \"N4\", [\"):)\", \"T\"], 4]]"}
{"project": "angr", "commit_sha": "e8989d95615d564b331473c0fb5c96f762d1bf63", "parent_sha": "04ea00a782ff008182c57749530e095b24efaf52", "file_path": "angr/scout.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -192,7 +192,7 @@ class Scout(object):\n         # block_size = s_irsb.irsb.size()\n         # self._next_addr = curr_addr + block_size\n         self._next_addr = curr_addr\n-        if curr_addr < self._ending_point:\n+        if self._ending_point is None or curr_addr < self._ending_point:\n             l.debug(\"Returning new recon address: 0x%08x\", curr_addr)\n             return curr_addr\n         else:\n", "before": "if curr_addr < self . _ending_point : l . debug ( \"Returning new recon address: 0x%08x\" , curr_addr ) return curr_addr else : ", "after": "if self . _ending_point is None or curr_addr < self . _ending_point : l . debug ( \"Returning new recon address: 0x%08x\" , curr_addr ) return curr_addr else : ", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 14], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 42], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:_ending_point\", \"T\"], 2]]"}
{"project": "django-pyodbc-azure", "commit_sha": "6c4e9b1b6c0ab87aab512b3477d49603adde7e99", "parent_sha": "0fe48ccc9912b4be741fd028cfe4d90cf439da23", "file_path": "sql_server/pyodbc/compiler.py", "project_url": "https://github.com/mejimaru/django-pyodbc-azure", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ class SQLCompiler(compiler.SQLCompiler):\n             for _, (s_sql, s_params), alias in self.select + extra_select:\n                 if alias:\n                     s_sql = '%s AS %s' % (s_sql, self.connection.ops.quote_name(alias))\n-                elif with_col_aliases:\n+                elif with_col_aliases or do_offset_emulation:\n                     s_sql = '%s AS %s' % (s_sql, 'Col%d' % col_idx)\n                     col_idx += 1\n                 params.extend(s_params)\n", "before": "if alias : s_sql = '%s AS %s' % ( s_sql , self . connection . ops . quote_name ( alias ) ) elif with_col_aliases : s_sql = '%s AS %s' % ( s_sql , 'Col%d' % col_idx ) col_idx += 1", "after": "if alias : s_sql = '%s AS %s' % ( s_sql , self . connection . ops . quote_name ( alias ) ) elif with_col_aliases or do_offset_emulation : s_sql = '%s AS %s' % ( s_sql , 'Col%d' % col_idx ) col_idx += 1", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"elif_clause\", 3, 17, 5, 33], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:with_col_aliases\", 3, 22, 3, 38], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:do_offset_emulation\", \"T\"], 2]]"}
{"project": "OpenNMT-entmax", "commit_sha": "f2e10e3e6cea210a7b2fb7b21cacfae148e66bbc", "parent_sha": "2a72c4a2574981db4114820e93362145277bb06e", "file_path": "onmt/trainer.py", "project_url": "https://github.com/deep-spin/OpenNMT-entmax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -139,7 +139,7 @@ class Trainer(object):\n \n             reduce_counter = 0\n             for i, batch in enumerate(train_iter):\n-                if (i % self.n_gpu == self.gpu_rank):\n+                if self.n_gpu == 0 or (i % self.n_gpu == self.gpu_rank):\n                     if self.gpu_verbose > 1:\n                         print(\"GPU %d: index: %d accum: %d\" % (self.gpu_rank, i, accum))        \n                     cur_dataset = train_iter.get_cur_dataset()\n", "before": "if ( i % self . n_gpu == self . gpu_rank ) : if self . gpu_verbose > 1 : print ( \"GPU %d: index: %d accum: %d\" % ( self . gpu_rank , i , accum ) ) cur_dataset = train_iter . get_cur_dataset ( )", "after": "if self . n_gpu == 0 or ( i % self . n_gpu == self . gpu_rank ) : if self . gpu_verbose > 1 : print ( \"GPU %d: index: %d accum: %d\" % ( self . gpu_rank , i , accum ) ) cur_dataset = train_iter . get_cur_dataset ( )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 6, 63], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"parenthesized_expression\", 3, 20, 3, 53], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:n_gpu\", \"T\"], 2]]"}
{"project": "gcsfs", "commit_sha": "2d13950de004d808e8b49a30da7d418d7f101a26", "parent_sha": "000afec54e65ff318ab094e9edd3545a6251dad4", "file_path": "gcsfs/core.py", "project_url": "https://github.com/martindurant/gcsfs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -152,7 +152,7 @@ def validate_response(r, path):\n         except:\n             msg = str(r.content)\n \n-        if \"Not Found\" in m:\n+        if \"Not Found\" in m or 'No such object' in m:\n             raise FileNotFoundError(path)\n         elif \"forbidden\" in m:\n             raise IOError(\"Forbidden: %s\\n%s\" % (path, msg))\n", "before": "if \"Not Found\" in m : raise FileNotFoundError ( path ) elif \"forbidden\" in m : raise IOError ( \"Forbidden: %s\\n%s\" % ( path , msg ) )", "after": "if \"Not Found\" in m or 'No such object' in m : raise FileNotFoundError ( path ) elif \"forbidden\" in m : raise IOError ( \"Forbidden: %s\\n%s\" % ( path , msg ) )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 61], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 28], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"string:'No such object'\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:m\", \"T\"], 2]]"}
{"project": "sympy", "commit_sha": "ea8014190e1e47880aa78edd0ebe0e52afccd54d", "parent_sha": "d86934f347f8de58a67215e32bb5ee1f55ffa19c", "file_path": "sympy/concrete/summations.py", "project_url": "https://github.com/fatData/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -779,7 +779,7 @@ def eval_sum_hyper(f, i_a_b):\n     if res is not None:\n         r, c = res\n         if c == False:\n-            if r.is_number:\n+            if r.is_number or r is S.ComplexInfinity:\n                 f = f.subs(i, Dummy('i', integer=True, positive=True) + a)\n                 if f.is_positive or f.is_zero:\n                     return S.Infinity\n", "before": "if r . is_number : f = f . subs ( i , Dummy ( 'i' , integer = True , positive = True ) + a ) if f . is_positive or f . is_zero : return S . Infinity", "after": "if r . is_number or r is S . ComplexInfinity : f = f . subs ( i , Dummy ( 'i' , integer = True , positive = True ) + a ) if f . is_positive or f . is_zero : return S . Infinity", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 38], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 16, 3, 27], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:r\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 2], [\"Insert\", \"N2\", [\"identifier:S\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:ComplexInfinity\", \"T\"], 2]]"}
{"project": "ykdl", "commit_sha": "b42bcb8d3f10b29cb3f016afb05c7eb852b956d9", "parent_sha": "1b0eaf86894930514592879d2e3e61469b6e089f", "file_path": "src/you_get/extractors/sohubase.py", "project_url": "https://github.com/YU-zreo/ykdl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -49,7 +49,7 @@ class SohuBase(VideoExtractor):\n             self.title = data['tvName']\n             for stream in self.supported_stream_types:\n                 lvid = data[stream]\n-                if lvid == 0:\n+                if lvid == 0 or not lvid:\n                     continue\n                 if lvid != self.vid :\n                     info = json.loads(get_content(self.apiurl % lvid))\n", "before": "if lvid == 0 : continue", "after": "if lvid == 0 or not lvid : continue", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 4, 29], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 29], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"identifier:lvid\", \"T\"], 1]]"}
{"project": "cfapi", "commit_sha": "eeac462d217f7bacf56b2a7de537e8145e1efdfe", "parent_sha": "252f7a41b0e2b339e804116fb2512039c8754288", "file_path": "run_update.py", "project_url": "https://github.com/opensavannah/cfapi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -225,7 +225,7 @@ def get_projects(organization):\n                 return []\n \n             # If its a csv\n-            if \"csv\" in organization.projects_list_url and ('content-type' in response.headers and 'text/csv' in response.headers['content-type']):\n+            if \"csv\" in organization.projects_list_url and (('content-type' in response.headers and 'text/csv' in response.headers['content-type']) or 'content-type' not in response.headers):\n                 data = response.content.splitlines()\n                 projects = list(DictReader(data, dialect='excel'))\n                 # convert all the values to unicode\n", "before": "if \"csv\" in organization . projects_list_url and ( 'content-type' in response . headers and 'text/csv' in response . headers [ 'content-type' ] ) : data = response . content . splitlines ( ) projects = list ( DictReader ( data , dialect = 'excel' ) )", "after": "if \"csv\" in organization . projects_list_url and ( ( 'content-type' in response . headers and 'text/csv' in response . headers [ 'content-type' ] ) or 'content-type' not in response . headers ) : data = response . content . splitlines ( ) projects = list ( DictReader ( data , dialect = 'excel' ) )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 61, 3, 146], [\"parenthesized_expression\", \"N0\"], 0], [\"Insert\", [\"boolean_operator\", 3, 61, 3, 146], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 61, 3, 146], [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Move\", \"N0\", [\"boolean_operator\", 3, 61, 3, 146], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:'content-type'\", \"T\"], 0], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 1], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 3], [\"Insert\", \"N2\", [\"identifier:response\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:headers\", \"T\"], 2]]"}
{"project": "pokeminer", "commit_sha": "205a73e3876b4c94d2d0532f12f4641a8ca8a1d7", "parent_sha": "4faf0363cc7a17a34ea7d44225b30552bdae0649", "file_path": "example.py", "project_url": "https://github.com/pogosandbox/pokeminer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -349,7 +349,7 @@ def main():\n     print('[+] Received API endpoint: {}'.format(api_endpoint))\n \n     profile_response = get_profile(access_token, api_endpoint, None)\n-    if profile_response is None:\n+    if profile_response is None or not profile_response.payload:\n         print('[-] Ooops...')\n         raise Exception(\"Could not get profile\")\n \n", "before": "if profile_response is None : print ( '[-] Ooops...' ) raise Exception ( \"Could not get profile\" )", "after": "if profile_response is None or not profile_response . payload : print ( '[-] Ooops...' ) raise Exception ( \"Could not get profile\" )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 5, 49], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 32], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 1], [\"Insert\", \"N2\", [\"identifier:profile_response\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:payload\", \"T\"], 2]]"}
{"project": "pokeminer", "commit_sha": "568fb3ef71b17c79a5d08d56a16dea77b525ac14", "parent_sha": "622a4a902d98eed3bfd257811db142904e0e5ca3", "file_path": "worker.py", "project_url": "https://github.com/pogosandbox/pokeminer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -183,7 +183,7 @@ class Slave(threading.Thread):\n                         # Care only about 15 min spawns\n                         # 30 and 45 min ones will be just put after\n                         # time_till_hidden is below 15 min\n-                        if pokemon['time_till_hidden_ms'] < 0:\n+                        if pokemon['time_till_hidden_ms'] < 0 or pokemon['time_till_hidden_ms'] > 900000:\n                             continue\n                         pokemons.append(\n                             self.normalize_pokemon(\n", "before": "if pokemon [ 'time_till_hidden_ms' ] < 0 : continue", "after": "if pokemon [ 'time_till_hidden_ms' ] < 0 or pokemon [ 'time_till_hidden_ms' ] > 900000 : continue", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 25, 4, 37], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 28, 3, 62], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"subscript\", \"N2\"], 0], [\"Insert\", \"N1\", [\">:>\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:900000\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:pokemon\", \"T\"], 0], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N2\", [\"string:'time_till_hidden_ms'\", \"T\"], 2], [\"Insert\", \"N2\", [\"]:]\", \"T\"], 3]]"}
{"project": "macsyfinder", "commit_sha": "fa65e4d5d20c6ea7c5d4784022692aa788477ede", "parent_sha": "fa2518f2cac7e7636413fd653ee1a74e9a91b06f", "file_path": "macsypy/cluster.py", "project_url": "https://github.com/gem-pasteur/macsyfinder", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -83,9 +83,10 @@ def build_clusters(hits, rep_info, model, hit_weights):\n                 cluster_scaffold.append(hit)\n             else:\n                 is_a_loner = model.get_gene(cluster_scaffold[0].gene.name).loner\n-                if len(cluster_scaffold) > 1 or is_a_loner:\n+                if len(cluster_scaffold) > 1 or is_a_loner or model.min_genes_required == 1:\n                     # close the current scaffold if it contains at least 2 hits\n                     # or one loner\n+                    # or min_gene_required == 1\n                     cluster = Cluster(cluster_scaffold, model, hit_weights)\n                     clusters.append(cluster)\n                 # open new scaffold\n", "before": "if len ( cluster_scaffold ) > 1 or is_a_loner : cluster = Cluster ( cluster_scaffold , model , hit_weights ) clusters . append ( cluster )", "after": "if len ( cluster_scaffold ) > 1 or is_a_loner or model . min_genes_required == 1 : cluster = Cluster ( cluster_scaffold , model , hit_weights ) clusters . append ( cluster )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 20, 3, 59], [\"boolean_operator\", 3, 20, 3, 59], 0], [\"Insert\", [\"boolean_operator\", 3, 20, 3, 59], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 20, 3, 59], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N0\", [\"integer:1\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:model\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:min_genes_required\", \"T\"], 2]]"}
{"project": "course-management", "commit_sha": "ad55bc347532395648f170723234a884015589e4", "parent_sha": "6706532eba57776a544ed41ea400c2328f75e09b", "file_path": "user/views/verify.py", "project_url": "https://github.com/fsr/course-management", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -36,7 +36,7 @@ def no_verify_view(request):\n \n def verify(request, type_):\n \n-    if 'token' not in request.GET:\n+    if 'token' not in request.GET or type_.lower() not in VERIFICATIONS:\n         try:\n             return VERIFICATIONS[type_.lower()].view(request)\n         except KeyError:\n", "before": "if 'token' not in request . GET : try : return VERIFICATIONS [ type_ . lower ( ) ] . view ( request ) except KeyError : ", "after": "if 'token' not in request . GET or type_ . lower ( ) not in VERIFICATIONS : try : return VERIFICATIONS [ type_ . lower ( ) ] . view ( request ) except KeyError : ", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 6, 25], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 34], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 1], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:VERIFICATIONS\", \"T\"], 3], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N3\", [\"identifier:type_\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:lower\", \"T\"], 2], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"):)\", \"T\"], 1]]"}
{"project": "weblyzard_api", "commit_sha": "093c27feb443f1482d3ddd76cee19620cca9f404", "parent_sha": "939931095f0a0264d87d450b467aaff42ec92b44", "file_path": "src/python/weblyzard_api/client/rdf.py", "project_url": "https://github.com/weblyzard/weblyzard_api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -100,7 +100,7 @@ def to_fully_qualified(attribute: str) -> str:\n-    if len(attribute.split(':')) <= 1:\n+    if len(attribute.split(':')) <= 1 or attribute.startswith('{'):\n         return attribute\n \n     namespace, attr_name = attribute.split(':')\n", "before": "if len ( attribute . split ( ':' ) ) <= 1 : return attribute", "after": "if len ( attribute . split ( ':' ) ) <= 1 or attribute . startswith ( '{' ) : return attribute", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 0, 5, 1, 25], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 0, 8, 0, 38], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"identifier:attribute\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:startswith\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"string:'{'\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "django-xadmin", "commit_sha": "ca019837749f211f1f03b95e73a5111e3870271c", "parent_sha": "01f6f44cf3044ef4f2051572dbf2405d02578bcb", "file_path": "xadmin/views/edit.py", "project_url": "https://github.com/scrapinghub/django-xadmin", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -176,7 +176,7 @@ class ModelFormAdminView(ModelAdminView):\n         layout = copy.deepcopy(self.form_layout)\n         fields = self.form_obj.fields.keys() + list(self.get_readonly_fields())\n \n-        if layout is None:\n+        if layout is None or len(fields) < len(layout.get_field_names()):\n             layout = Layout(Container(\n                 Fieldset(\"\", *fields, css_class=\"unsort no_title\"), css_class=\"form-horizontal\"\n             ))\n", "before": "if layout is None : layout = Layout ( Container ( Fieldset ( \"\" , * fields , css_class = \"unsort no_title\" ) , css_class = \"form-horizontal\" ) )", "after": "if layout is None or len ( fields ) < len ( layout . get_field_names ( ) ) : layout = Layout ( Container ( Fieldset ( \"\" , * fields , css_class = \"unsort no_title\" ) , css_class = \"form-horizontal\" ) )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 15], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 26], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"<:<\", \"T\"], 1], [\"Insert\", \"N1\", [\"call\", \"N3\"], 2], [\"Insert\", \"N2\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N3\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N3\", [\"argument_list\", \"N5\"], 1], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"identifier:fields\", \"T\"], 1], [\"Insert\", \"N4\", [\"):)\", \"T\"], 2], [\"Insert\", \"N5\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N5\", [\"call\", \"N6\"], 1], [\"Insert\", \"N5\", [\"):)\", \"T\"], 2], [\"Insert\", \"N6\", [\"attribute\", \"N7\"], 0], [\"Insert\", \"N6\", [\"argument_list\", \"N8\"], 1], [\"Insert\", \"N7\", [\"identifier:layout\", \"T\"], 0], [\"Insert\", \"N7\", [\".:.\", \"T\"], 1], [\"Insert\", \"N7\", [\"identifier:get_field_names\", \"T\"], 2], [\"Insert\", \"N8\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N8\", [\"):)\", \"T\"], 1]]"}
{"project": "fenapack", "commit_sha": "9f480c06770daeb021f7998936fff4eec4865abc", "parent_sha": "e6a54ab1029d8a7619631127509368ed02df3652", "file_path": "fenapack/nonlinear_solvers.py", "project_url": "https://github.com/blechta/fenapack", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -289,7 +289,7 @@ class _PCDProblem(PCDProblem):\n         mat = ksp.getOperators()[0]\n         # FIXME: This logic that it is created once should be visible\n         #        in higher level, not in these internals\n-        if not mat.isAssembled():\n+        if mat.type is None or not mat.isAssembled():\n             dolfin_mat = self.get_work_dolfin_mat(assemble_func,\n                                                   can_be_destroyed=True,\n                                                   can_be_shared=True)\n", "before": "if not mat . isAssembled ( ) : dolfin_mat = self . get_work_dolfin_mat ( assemble_func , can_be_destroyed = True , can_be_shared = True )", "after": "if mat . type is None or not mat . isAssembled ( ) : dolfin_mat = self . get_work_dolfin_mat ( assemble_func , can_be_destroyed = True , can_be_shared = True )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 70], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"not_operator\", 3, 12, 3, 33], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:mat\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:type\", \"T\"], 2]]"}
{"project": "motools", "commit_sha": "92185952cc06f69a9baffe0862834e52a5120be5", "parent_sha": "6226fee77809f3e796694c21354c3e7620dc024d", "file_path": "mopy/mopy/PropertySet.py", "project_url": "https://github.com/moustaki/motools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,7 +25,7 @@ class PropertySet(set):\n \t\t#\tprint \"(lits allowed)\"\n \t\tif not ((self.allowLits and isinstance(o, self.Lits))\\\n \t\t\t\tor (self.validTypes != None and isinstance(o, self.validTypes))\\\n-\t\t\t\t):\n+\t\t\t\tor self.validTypes == None):\n \t\t\tmsg = \"Invalid type for \"+self.shortname+\" property ! Got \"+str(type(o))+\" but expected one of : \"+str(self.validTypes)\n \t\t\tif self.allowLits:\n \t\t\t\tmsg+= \" (or a literal)\"\n", "before": "if not ( ( self . allowLits and isinstance ( o , self . Lits ) ) or ( self . validTypes != None and isinstance ( o , self . validTypes ) ) ) : msg = \"Invalid type for \" + self . shortname + \" property ! Got \" + str ( type ( o ) ) + \" but expected one of : \" + str ( self . validTypes ) if self . allowLits : msg += \" (or a literal)\"", "after": "if not ( ( self . allowLits and isinstance ( o , self . Lits ) ) or ( self . validTypes != None and isinstance ( o , self . validTypes ) ) or self . validTypes == None ) : msg = \"Invalid type for \" + self . shortname + \" property ! Got \" + str ( type ( o ) ) + \" but expected one of : \" + str ( self . validTypes ) if self . allowLits : msg += \" (or a literal)\"", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 1, 11, 2, 68], [\"boolean_operator\", 1, 11, 2, 68], 0], [\"Insert\", [\"boolean_operator\", 1, 11, 2, 68], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 1, 11, 2, 68], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N0\", [\"none:None\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:validTypes\", \"T\"], 2]]"}
{"project": "cloud-bots", "commit_sha": "b124c1bb6943abfc0f8c79c4b0373e1c1e22f935", "parent_sha": "7356ab3de542120c7e930ba8f5898cf5e1670490", "file_path": "bots/s3_only_allow_ssl.py", "project_url": "https://github.com/Dome9/cloud-bots", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -49,7 +49,7 @@ def run_action(boto_session, rule, entity, params):\n     policy_bucket = entity['policy']\n \n     try:\n-        if policy_bucket == \"null\":  # s3 does not have a bucket policy\n+        if policy_bucket == \"null\" or policy_bucket is None:  # s3 does not have a bucket policy\n \n             GETPUT_STAT[\"Resource\"] = GETPUT_STAT.get(\"Resource\").replace(\"bucketName\", bucket_name)\n             GETPUT_STAT[\"Principal\"][\"AWS\"] = account_number\n", "before": "if policy_bucket == \"null\" : GETPUT_STAT [ \"Resource\" ] = GETPUT_STAT . get ( \"Resource\" ) . replace ( \"bucketName\" , bucket_name ) GETPUT_STAT [ \"Principal\" ] [ \"AWS\" ] = account_number", "after": "if policy_bucket == \"null\" or policy_bucket is None : GETPUT_STAT [ \"Resource\" ] = GETPUT_STAT . get ( \"Resource\" ) . replace ( \"bucketName\" , bucket_name ) GETPUT_STAT [ \"Principal\" ] [ \"AWS\" ] = account_number", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 61], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 35], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:policy_bucket\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2]]"}
{"project": "udapi-python", "commit_sha": "5ae3fece2bf575d35b3cbda9761231cad2e68444", "parent_sha": "33bdb7d7529f7b07870927155bde15fc64852240", "file_path": "udapi/block/ud/fixpunct.py", "project_url": "https://github.com/udapi/udapi-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -114,7 +114,7 @@ class FixPunct(Block):\n         # If the candidates' descendants span across the punctuation, we also stop\n         # because climbing higher would cause a non-projectivity (the punct would be the gap).\n         l_path, r_path = [l_cand], [r_cand]\n-        if l_cand.is_root():\n+        if l_cand is None or l_cand.is_root():\n             l_cand = None\n         else:\n             while (not l_cand.parent.is_root() and l_cand.parent.precedes(node)\n", "before": "if l_cand . is_root ( ) : l_cand = None", "after": "if l_cand is None or l_cand . is_root ( ) : l_cand = None", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 26], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 28], 2], [\"Insert\", \"N1\", [\"identifier:l_cand\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2]]"}
{"project": "PyCoin", "commit_sha": "4790db1d6ff1b5cdae74f18078029de8a5a9b90b", "parent_sha": "8ec6600d60a3578705167703a41c515be02d64b5", "file_path": "server.py", "project_url": "https://github.com/devArtoria/PyCoin", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -66,7 +66,7 @@ def register_nodes():\n     nodes = values.get('nodes')\n     print(nodes)\n \n-    if nodes is None:\n+    if nodes is None or type(nodes) == str:\n         return \"Error : unvalid list of nodes\", 400\n \n     for node in nodes:\n", "before": "if nodes is None : return \"Error : unvalid list of nodes\" , 400", "after": "if nodes is None or type ( nodes ) == str : return \"Error : unvalid list of nodes\" , 400", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 4, 52], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 21], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:str\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:type\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:nodes\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "vermouth-martinize", "commit_sha": "40d6895c7572fede9c446ea1841ff28a31820559", "parent_sha": "af97e638e8a5f4b9a7dbe5beca68171b706a3bcc", "file_path": "vermouth/ffinput.py", "project_url": "https://github.com/marrink-lab/vermouth-martinize", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -611,7 +611,7 @@ def _base_parser(tokens, context, context_type, section, natoms=None, delete=Fal\n     # * interactions create nodes\n     if context_type == 'block':\n         treated_atoms = _treat_block_interaction_atoms(atoms, context, section)\n-    elif context_type == 'link':\n+    elif context_type == 'link' or context_type == 'modifications':\n         treated_atoms = _treat_link_interaction_atoms(atoms, context, section)\n \n \n", "before": "if context_type == 'block' : treated_atoms = _treat_block_interaction_atoms ( atoms , context , section ) elif context_type == 'link' : treated_atoms = _treat_link_interaction_atoms ( atoms , context , section )", "after": "if context_type == 'block' : treated_atoms = _treat_block_interaction_atoms ( atoms , context , section ) elif context_type == 'link' or context_type == 'modifications' : treated_atoms = _treat_link_interaction_atoms ( atoms , context , section )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"elif_clause\", 3, 5, 4, 79], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 10, 3, 32], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:context_type\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'modifications'\", \"T\"], 2]]"}
{"project": "depot_tools", "commit_sha": "20d1943ffbffc1f121aaa7c7b976e6820f66f87b", "parent_sha": "751797ac3cfea41f7c4e2379f8d8753372591610", "file_path": "owners.py", "project_url": "https://github.com/Neozaru/depot_tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -147,7 +147,7 @@ class Database(object):\n     for line in self.fopen(owners_path):\n       lineno += 1\n       line = line.strip()\n-      if line.startswith('#'):\n+      if line.startswith('#') or line == '':\n         continue\n       if line == 'set noparent':\n         self.stop_looking.add(dirpath)\n", "before": "if line . startswith ( '#' ) : continue", "after": "if line . startswith ( '#' ) or line == '' : continue", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 7, 4, 17], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 10, 3, 30], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:line\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:''\", \"T\"], 2]]"}
{"project": "add-curve-lsystem", "commit_sha": "0cb9429c454d2d06f4e74c52025699180bc5aec0", "parent_sha": "eb0c0d2d3d9bd0effe71fbcf93f8f9489b4b1c6c", "file_path": "lindenmayer_system.py", "project_url": "https://github.com/stante/add-curve-lsystem", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -365,7 +365,7 @@ def calculate_length(system, basic_length):\n         \n def grow(spline, movement, amount):\n     direction = movement.get_vector()\n-    if movement.has_changed():\n+    if movement.has_changed() or len(spline.bezier_points) == 1:\n         # Add second point\n         spline.bezier_points.add()\n         newpoint = spline.bezier_points[-1]\n", "before": "if movement . has_changed ( ) : spline . bezier_points . add ( ) newpoint = spline . bezier_points [ - 1 ]", "after": "if movement . has_changed ( ) or len ( spline . bezier_points ) == 1 : spline . bezier_points . add ( ) newpoint = spline . bezier_points [ - 1 ]", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 6, 44], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 8, 3, 30], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:1\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:spline\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:bezier_points\", \"T\"], 2]]"}
{"project": "Cura", "commit_sha": "b88f2847ef58cf27b4aab96398ef160a483b9c63", "parent_sha": "a948c7bcc67fafbc3e32c593a127eac51cd5b6b2", "file_path": "cura/CuraApplication.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -271,7 +271,7 @@ class CuraApplication(QtApplication):\n             file_name = urllib.parse.quote_plus(stack.getId()) + \".stack.cfg\"\n             stack_type = stack.getMetaDataEntry(\"type\", None)\n             path = None\n-            if not stack_type:\n+            if not stack_type or stack_type == \"machine\":\n                 path = Resources.getStoragePath(self.ResourceTypes.MachineStack, file_name)\n             elif stack_type == \"extruder\":\n                 path = Resources.getStoragePath(self.ResourceTypes.ExtruderStack, file_name)\n", "before": "if not stack_type : path = Resources . getStoragePath ( self . ResourceTypes . MachineStack , file_name ) elif stack_type == \"extruder\" : path = Resources . getStoragePath ( self . ResourceTypes . ExtruderStack , file_name )", "after": "if not stack_type or stack_type == \"machine\" : path = Resources . getStoragePath ( self . ResourceTypes . MachineStack , file_name ) elif stack_type == \"extruder\" : path = Resources . getStoragePath ( self . ResourceTypes . ExtruderStack , file_name )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 16, 3, 30], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:stack_type\", 3, 20, 3, 30], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:stack_type\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:\\\"machine\\\"\", \"T\"], 2]]"}
{"project": "tools_repo", "commit_sha": "936183a492373f8a54b6ecaa806e252d08b793c5", "parent_sha": "85e82670315cc2a6ac020430ae3f7e46862ff5d9", "file_path": "git_config.py", "project_url": "https://github.com/LineageOS/tools_repo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -619,7 +619,7 @@ class Remote(object):\n   def ToLocal(self, rev):\n     \"\"\"Convert a remote revision string to something we have locally.\n     \"\"\"\n-    if IsId(rev):\n+    if self.name == '.' or IsId(rev):\n       return rev\n \n     if not rev.startswith('refs/'):\n", "before": "if IsId ( rev ) : return rev", "after": "if self . name == '.' or IsId ( rev ) : return rev", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 4, 17], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 8, 3, 17], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'.'\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:name\", \"T\"], 2]]"}
{"project": "flocker", "commit_sha": "d8dd218f644274a04d4afa2f1af6edeb08d361ab", "parent_sha": "dc3b9fb49a6fa6c49c8cec964c305764cf617b49", "file_path": "flocker/provision/_install.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -989,7 +989,7 @@ def if_firewall_available(distribution, commands):\n-    if is_centos(distribution):\n+    if is_centos(distribution) or is_rhel(distribution):\n         firewall_command = b'firewall-cmd'\n     elif distribution == 'ubuntu-14.04':\n         firewall_command = b'ufw'\n", "before": "if is_centos ( distribution ) : firewall_command = b'firewall-cmd' elif distribution == 'ubuntu-14.04' : firewall_command = b'ufw'", "after": "if is_centos ( distribution ) or is_rhel ( distribution ) : firewall_command = b'firewall-cmd' elif distribution == 'ubuntu-14.04' : firewall_command = b'ufw'", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 0, 5, 3, 34], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 0, 8, 0, 31], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:is_rhel\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:distribution\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "flocker", "commit_sha": "d6b1b85d71337c3b83fc47eb3ae192e51f44436d", "parent_sha": "9156a50c170d78926639d7119ce6f054e5295dda", "file_path": "flocker/provision/_install.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -989,7 +989,7 @@ def if_firewall_available(distribution, commands):\n-    if is_centos(distribution):\n+    if is_centos(distribution) or is_rhel(distribution):\n         firewall_command = b'firewall-cmd'\n     elif distribution == 'ubuntu-14.04':\n         firewall_command = b'ufw'\n", "before": "if is_centos ( distribution ) : firewall_command = b'firewall-cmd' elif distribution == 'ubuntu-14.04' : firewall_command = b'ufw'", "after": "if is_centos ( distribution ) or is_rhel ( distribution ) : firewall_command = b'firewall-cmd' elif distribution == 'ubuntu-14.04' : firewall_command = b'ufw'", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 0, 5, 3, 34], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 0, 8, 0, 31], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:is_rhel\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:distribution\", \"T\"], 1], [\"Insert\", \"N2\", [\"):)\", \"T\"], 2]]"}
{"project": "larray", "commit_sha": "28f469e200dec0172ad67bdff721bd9650b188b0", "parent_sha": "b3dc327552fac5da237d39ee202e454c5e8bfe46", "file_path": "larray/viewer.py", "project_url": "https://github.com/alixdamman/larray", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2781,7 +2781,7 @@ def edit(obj=None, title='', minvalue=None, maxvalue=None, readonly=False, depth\n \n     dlg = MappingEditor(parent) if hasattr(obj, 'keys') else ArrayEditor(parent)\n     if dlg.setup_and_check(obj, title=title, minvalue=minvalue, maxvalue=maxvalue, readonly=readonly):\n-        if parent:\n+        if parent or isinstance(dlg, MappingEditor):\n             dlg.show()\n         else:\n             dlg.exec_()\n", "before": "if parent : dlg . show ( ) else : dlg . exec_ ( )", "after": "if parent or isinstance ( dlg , MappingEditor ) : dlg . show ( ) else : dlg . exec_ ( )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 24], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:parent\", 3, 12, 3, 18], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:isinstance\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:dlg\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:MappingEditor\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "kitsune", "commit_sha": "6f86f3fb04ec4fc4b9282a1134279839e11b7ec9", "parent_sha": "688313b4367f75cecd05a044fe1b89ec321725b1", "file_path": "apps/landings/views.py", "project_url": "https://github.com/skcrouch7/kitsune", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -99,7 +99,7 @@ def old_home(request, template=None):\n \n @mobile_template('landings/{mobile/}mobile.html')\n def mobile(request, template=None):\n-    if not request.MOBILE:\n+    if not request.MOBILE or waffle.flag_is_active(request, 'new-theme'):\n         return redirect_to(\n             request, 'products.product', slug='mobile', permanent=False)\n \n", "before": "if not request . MOBILE : return redirect_to ( request , 'products.product' , slug = 'mobile' , permanent = False )", "after": "if not request . MOBILE or waffle . flag_is_active ( request , 'new-theme' ) : return redirect_to ( request , 'products.product' , slug = 'mobile' , permanent = False )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 8, 3, 26], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 12, 3, 26], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"identifier:waffle\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:flag_is_active\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:request\", \"T\"], 1], [\"Insert\", \"N3\", [\",:,\", \"T\"], 2], [\"Insert\", \"N3\", [\"string:'new-theme'\", \"T\"], 3], [\"Insert\", \"N3\", [\"):)\", \"T\"], 4]]"}
{"project": "gevent", "commit_sha": "bd0bc104d81a0f739ff03e85036fad92c0e44deb", "parent_sha": "0813d0e91697768e09a72bb26cf307c2c90894b5", "file_path": "gevent/hub.py", "project_url": "https://github.com/gevent/gevent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -309,7 +309,7 @@ class Hub(greenlet):\n \n     def handle_system_error(self, type, value):\n         current = getcurrent()\n-        if current is self or current is self.parent:\n+        if current is self or current is self.parent or self.loop is None:\n             self.parent.throw(type, value)\n         else:\n             self.loop.run_callback(self.parent.throw, type, value)\n", "before": "if current is self or current is self . parent : self . parent . throw ( type , value ) else : self . loop . run_callback ( self . parent . throw , type , value )", "after": "if current is self or current is self . parent or self . loop is None : self . parent . throw ( type , value ) else : self . loop . run_callback ( self . parent . throw , type , value )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 12, 3, 53], [\"boolean_operator\", 3, 12, 3, 53], 0], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 53], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 53], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N0\", [\"none:None\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:loop\", \"T\"], 2]]"}
{"project": "pritunl", "commit_sha": "a098cba61ffd6c99ca31615b797d5656b6696423", "parent_sha": "2aaf1c7f30bcc982259ef8788f8b8829962527fc", "file_path": "pritunl/server/server.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -205,7 +205,7 @@ class Server(mongo.MongoObject):\n \n     @property\n     def uptime(self):\n-        if not self.start_timestamp:\n+        if self.status != ONLINE or not self.start_timestamp:\n             return\n         return max((utils.now() - self.start_timestamp).seconds, 1)\n \n", "before": "if not self . start_timestamp : return", "after": "if self . status != ONLINE or not self . start_timestamp : return", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 19], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"not_operator\", 3, 12, 3, 36], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:ONLINE\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:status\", \"T\"], 2]]"}
{"project": "pritunl", "commit_sha": "334587c5963bef2c27f11c9e4c0aaf611a26fd8a", "parent_sha": "8d15153a49721b15dcc9a28a454435f0b4133fbe", "file_path": "pritunl/handlers/server.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -136,7 +136,7 @@ def server_put_post(server_id=None):\n         except ValueError:\n             return _interface_not_valid()\n \n-        if interface_num > 64:\n+        if interface_num > 64 or interface_num < 0:\n             return _interface_not_valid()\n \n         interface = interface[:3] + str(interface_num)\n", "before": "if interface_num > 64 : return _interface_not_valid ( )", "after": "if interface_num > 64 or interface_num < 0 : return _interface_not_valid ( )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 42], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 30], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:interface_num\", \"T\"], 0], [\"Insert\", \"N1\", [\"<:<\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2]]"}
{"project": "pritunl", "commit_sha": "bfa9402a5f3b42bf582a93364c5b3c2856d58f6f", "parent_sha": "175aa5405ccc5f0978c66837ddf75f38d43c23c2", "file_path": "pritunl/host/host.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ class Host(mongo.MongoObject):\n \n     @property\n     def uptime(self):\n-        if not self.start_timestamp:\n+        if self.status != ONLINE or not self.start_timestamp:\n             return\n         return max((utils.now() - self.start_timestamp).seconds, 1)\n \n", "before": "if not self . start_timestamp : return", "after": "if self . status != ONLINE or not self . start_timestamp : return", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 19], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"not_operator\", 3, 12, 3, 36], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"!=:!=\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:ONLINE\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:status\", \"T\"], 2]]"}
{"project": "openstates", "commit_sha": "2752a6ab36a3327eac3bcd7577d2fd316bc7e47d", "parent_sha": "97ac73d99941331b43725548efd39ac5e3718c99", "file_path": "fiftystates/scrape/bills.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -126,7 +126,7 @@ class Bill(FiftystatesObject):\n \n-        if not 'type' in kwargs:\n+        if not 'type' in kwargs or kwargs['type'] is None:\n             kwargs['type'] = ['other']\n         elif not isinstance(kwargs['type'], list):\n             kwargs['type'] = list(kwargs['type'])\n", "before": "if not 'type' in kwargs : kwargs [ 'type' ] = [ 'other' ] elif not isinstance ( kwargs [ 'type' ] , list ) : kwargs [ 'type' ] = list ( kwargs [ 'type' ] )", "after": "if not 'type' in kwargs or kwargs [ 'type' ] is None : kwargs [ 'type' ] = [ 'other' ] elif not isinstance ( kwargs [ 'type' ] , list ) : kwargs [ 'type' ] = list ( kwargs [ 'type' ] )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 1, 12, 1, 32], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 1, 16, 1, 32], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"subscript\", \"N2\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:kwargs\", \"T\"], 0], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N2\", [\"string:'type'\", \"T\"], 2], [\"Insert\", \"N2\", [\"]:]\", \"T\"], 3]]"}
{"project": "openstates", "commit_sha": "cedc7a3cf9b183d144f189d36c1acc27904d2acf", "parent_sha": "7645767b5c7da5ba6b39bdf06abda28212091d84", "file_path": "openstates/me/bills.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -153,7 +153,7 @@ class MEBillScraper(BillScraper):\n                     chamber = 'lower'\n \n                 action = row.xpath(\"string(td[3])\").strip()\n-                if action == 'Unfinished Business':\n+                if action == 'Unfinished Business' or not action:\n                     continue\n \n                 bill.add_action(chamber, action, date)\n", "before": "if action == 'Unfinished Business' : continue", "after": "if action == 'Unfinished Business' or not action : continue", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 4, 29], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 51], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"identifier:action\", \"T\"], 1]]"}
{"project": "openstates", "commit_sha": "b44f994b15bde2bb0d53c3acdd70fa659ed4a30f", "parent_sha": "cd561b30c21f1bbe362cb1e9dd6adb2616f55c96", "file_path": "openstates/ok/bills.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -59,7 +59,7 @@ class OKBillScraper(BillScraper):\n         act_table = page.xpath(\"//table[contains(@id, 'Actions')]\")[0]\n         for tr in act_table.xpath(\"tr\")[2:]:\n             action = tr.xpath(\"string(td[1])\").strip()\n-            if not action:\n+            if not action or action == 'None':\n                 continue\n \n             date = tr.xpath(\"string(td[3])\").strip()\n", "before": "if not action : continue", "after": "if not action or action == 'None' : continue", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 16, 3, 26], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:action\", 3, 20, 3, 26], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:action\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'None'\", \"T\"], 2]]"}
{"project": "spyne", "commit_sha": "c1598553e5d5c4ddddb31582551dfa9d187a788f", "parent_sha": "97293a3df8992806a27023ba2d1910a06c01699a", "file_path": "spyne/protocol/xml/model.py", "project_url": "https://github.com/duixteam/spyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -190,7 +190,7 @@ def alias_to_parent_element(prot, cls, value, tns, parent_elt, name=None):\n     if t is not None:\n         subvalue = getattr(value, k, None)\n         # Don't include empty values for non-nillable optional attributes.\n-        if subvalue is not None:\n+        if subvalue is not None or t.Attributes.min_occurs > 0:\n             prot.to_parent_element(t, subvalue, tns, parent_elt, name)\n \n \n", "before": "if subvalue is not None : prot . to_parent_element ( t , subvalue , tns , parent_elt , name )", "after": "if subvalue is not None or t . Attributes . min_occurs > 0 : prot . to_parent_element ( t , subvalue , tns , parent_elt , name )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 71], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 32], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\">:>\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:min_occurs\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:t\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:Attributes\", \"T\"], 2]]"}
{"project": "spyne", "commit_sha": "fb33ac7edb46f0b0645d15fa1cc35291dd1a6a76", "parent_sha": "7629a5757ff6bf6bdafe106e16a8d8b6d8056170", "file_path": "spyne/protocol/xml/model.py", "project_url": "https://github.com/duixteam/spyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -190,7 +190,7 @@ def alias_to_parent_element(prot, cls, value, tns, parent_elt, name=None):\n     if t is not None:\n         subvalue = getattr(value, k, None)\n         # Don't include empty values for non-nillable optional attributes.\n-        if subvalue is not None:\n+        if subvalue is not None or t.Attributes.min_occurs > 0:\n             prot.to_parent_element(t, subvalue, tns, parent_elt, name)\n \n \n", "before": "if subvalue is not None : prot . to_parent_element ( t , subvalue , tns , parent_elt , name )", "after": "if subvalue is not None or t . Attributes . min_occurs > 0 : prot . to_parent_element ( t , subvalue , tns , parent_elt , name )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 71], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 32], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\">:>\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:min_occurs\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:t\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:Attributes\", \"T\"], 2]]"}
{"project": "spyne", "commit_sha": "7df8e6612da851882279508caab8245af0f5bdbb", "parent_sha": "233c84c1ece3893d4a749fc42f6fa1c6eba4c471", "file_path": "spyne/protocol/cloth/to_cloth.py", "project_url": "https://github.com/duixteam/spyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -191,7 +191,7 @@ class ToClothMixin(ProtocolBase):\n             print(\"\\texit \", elt.tag, \"norm\")\n \n             for sibl in elt.itersiblings(preceding=False):\n-                if sibl is cloth:\n+                if sibl is cloth or cloth in sibl.xpath(\".//*\"):\n                     break\n                 if sibl in anc:\n                     break\n", "before": "if sibl is cloth : break", "after": "if sibl is cloth or cloth in sibl . xpath ( \".//*\" ) : break", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 4, 26], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 33], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:cloth\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"call\", \"N2\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N3\", [\"identifier:sibl\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:xpath\", \"T\"], 2], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"string:\\\".//*\\\"\", \"T\"], 1], [\"Insert\", \"N4\", [\"):)\", \"T\"], 2]]"}
{"project": "openobject-client-6.0", "commit_sha": "bf877ad851248104f7873bcfd4eb98fedff84b70", "parent_sha": "ee723ea859ec7abb5e658d4492fdf82a9ca0b940", "file_path": "bin/widget/model/field.py", "project_url": "https://github.com/hunslater/openobject-client-6.0", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -68,9 +68,9 @@ class CharField(object):\n         # removing default keys of the parent context\n         context_own = context.copy()\n         for c in context.items():\n-            if c[0].startswith('default_'):\n+            if c[0].startswith('default_') or c[0] in ('set_editable','set_visible'):\n                 del context_own[c[0]]\n-        \n+\n         field_context_str = self.attrs.get('context', '{}') or '{}'\n         if eval:\n", "before": "if c [ 0 ] . startswith ( 'default_' ) : del context_own [ c [ 0 ] ]", "after": "if c [ 0 ] . startswith ( 'default_' ) or c [ 0 ] in ( 'set_editable' , 'set_visible' ) : del context_own [ c [ 0 ] ]", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 38], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 43], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"subscript\", \"N2\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"tuple\", \"N3\"], 2], [\"Insert\", \"N2\", [\"identifier:c\", \"T\"], 0], [\"Insert\", \"N2\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N2\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N2\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"string:'set_editable'\", \"T\"], 1], [\"Insert\", \"N3\", [\",:,\", \"T\"], 2], [\"Insert\", \"N3\", [\"string:'set_visible'\", \"T\"], 3], [\"Insert\", \"N3\", [\"):)\", \"T\"], 4]]"}
{"project": "pony", "commit_sha": "5ed45d21a437edfb88292050c0c65a45b75f21dc", "parent_sha": "2b17c30dc17f7cb4cdfbca693cd1075d06bfb38c", "file_path": "pony/orm/dbapiprovider.py", "project_url": "https://github.com/jelmer/pony", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -846,7 +846,7 @@ class ArrayConverter(Converter):\n         return TrackedArray(obj, converter.attr, items)\n \n     def dbval2val(converter, dbval, obj=None):\n-        if obj is None:\n+        if obj is None or dbval is None:\n             return dbval\n         return TrackedArray(obj, converter.attr, dbval)\n \n", "before": "if obj is None : return dbval", "after": "if obj is None or dbval is None : return dbval", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 25], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 23], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:dbval\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2]]"}
{"project": "coursebuilder-core", "commit_sha": "22f0edb736f89ce9f768b99a6d9937dcb35ee7fe", "parent_sha": "1132d50586095538c3c9f95c022ce743911e4f47", "file_path": "coursebuilder/modules/dashboard/dashboard.py", "project_url": "https://github.com/imisi-akande/coursebuilder-core", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -527,7 +527,7 @@ class DashboardHandler(\n             # show different captions depending if the override exists or not\n             has_override = filename in unmerged_files\n             link_caption = '[Override]'\n-            if has_override:\n+            if has_override or not merge_local_files:\n                 link_caption = '[Edit]'\n \n             # make a <li> item\n", "before": "if has_override : link_caption = '[Edit]'", "after": "if has_override or not merge_local_files : link_caption = '[Edit]'", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 40], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:has_override\", 3, 16, 3, 28], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"identifier:merge_local_files\", \"T\"], 1]]"}
{"project": "kin-app-server", "commit_sha": "e100cd68b556f8256a57a20f1d97155d51656232", "parent_sha": "225d19b9a19f60f8deba40018ec7c546ba863200", "file_path": "kinappserver/models/user.py", "project_url": "https://github.com/kinecosystem/kin-app-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -614,7 +614,7 @@ def get_next_task_results_ts(user_id, cat_id):\n     \"\"\"return the task_result_ts field for the given user and task category\"\"\"\n     try:\n         user_app_data = UserAppData.query.filter_by(user_id=user_id).first()\n-        if user_app_data is None:\n+        if user_app_data is None or user_app_data.next_task_ts_dict is None:\n             return None\n         return user_app_data.next_task_ts_dict.get(cat_id, 0)  # can be None\n     except Exception as e:\n", "before": "if user_app_data is None : return None", "after": "if user_app_data is None or user_app_data . next_task_ts_dict is None : return None", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 24], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 33], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:user_app_data\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:next_task_ts_dict\", \"T\"], 2]]"}
{"project": "npm-install", "commit_sha": "679059094c631ee422355ca147b6a89c7f80c6a7", "parent_sha": "3dcbbc453c21a84eb1137534f5935024a7796bb2", "file_path": "npm-install.py", "project_url": "https://github.com/fcannizzaro/npm-install", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ def update_icons(view):\n         a, b = m.span(1)\n         module = m.group(1)\n         reg = Region(a + region.begin(), b + region.begin())\n-        if module in modules:\n+        if module in modules or module in CORE:\n             installed.append(reg)\n         else:\n", "before": "if module in modules : installed . append ( reg ) else : ", "after": "if module in modules or module in CORE : installed . append ( reg ) else : ", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 5, 14], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 29], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:module\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:CORE\", \"T\"], 2]]"}
{"project": "sterp", "commit_sha": "5c464e4a0108c82ed15c471f3d005af36b9ad6f9", "parent_sha": "69a3ee54f2262df71bbe59193363124cdb7e12cb", "file_path": "stock/doctype/stock_entry/stock_entry.py", "project_url": "https://github.com/gangadharkadam/sterp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -403,7 +403,7 @@ class DocType(StockController):\n \t\targ, ret = eval(arg), {}\n \t\tuom = sql(\"\"\"select conversion_factor from `tabUOM Conversion Detail` \n \t\t\twhere parent = %s and uom = %s\"\"\", (arg['item_code'], arg['uom']), as_dict = 1)\n-\t\tif not uom:\n+\t\tif not uom or not flt(uom[0].conversion_factor):\n \t\t\tmsgprint(\"There is no Conversion Factor for UOM '%s' in Item '%s'\" % (arg['uom'],\n \t\t\t\targ['item_code']))\n \t\t\tret = {'uom' : ''}\n", "before": "if not uom : msgprint ( \"There is no Conversion Factor for UOM '%s' in Item '%s'\" % ( arg [ 'uom' ] , arg [ 'item_code' ] ) ) ret = { 'uom' : '' }", "after": "if not uom or not flt ( uom [ 0 ] . conversion_factor ) : msgprint ( \"There is no Conversion Factor for UOM '%s' in Item '%s'\" % ( arg [ 'uom' ] , arg [ 'item_code' ] ) ) ret = { 'uom' : '' }", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 6, 3, 13], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:uom\", 3, 10, 3, 13], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"call\", \"N2\"], 1], [\"Insert\", \"N2\", [\"identifier:flt\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2], [\"Insert\", \"N4\", [\"subscript\", \"N5\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:conversion_factor\", \"T\"], 2], [\"Insert\", \"N5\", [\"identifier:uom\", \"T\"], 0], [\"Insert\", \"N5\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N5\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N5\", [\"]:]\", \"T\"], 3]]"}
{"project": "datadog-asteriskpbx", "commit_sha": "da786d6c9198837947dcd3906b2c2828463fbf61", "parent_sha": "eecb0a80483e2a1a12f83f1867f719884d7d8446", "file_path": "checks.d/asteriskpbx.py", "project_url": "https://github.com/jwestbrook/datadog-asteriskpbx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -125,7 +125,7 @@ class AsteriskCheck(AgentCheck):\n             called = \"N/A\"\n             callType = \"N/A\"\n \n-            if \"Dial\" == currentChannel.Application:\n+            if \"Dial\" == currentChannel.Application or \"Queue\" == currentChannel.Application:\n                 currentCall = Call(\"N/A\",\"N/A\",\"N/A\",\"N/A\",\"N/A\",\"N/A\")\n                 currentCall.Caller = currentChannel.CallerId\n                 currentCall.CallerChannel = currentChannel.Channel\n", "before": "if \"Dial\" == currentChannel . Application : currentCall = Call ( \"N/A\" , \"N/A\" , \"N/A\" , \"N/A\" , \"N/A\" , \"N/A\" ) currentCall . Caller = currentChannel . CallerId currentCall . CallerChannel = currentChannel . Channel", "after": "if \"Dial\" == currentChannel . Application or \"Queue\" == currentChannel . Application : currentCall = Call ( \"N/A\" , \"N/A\" , \"N/A\" , \"N/A\" , \"N/A\" , \"N/A\" ) currentCall . Caller = currentChannel . CallerId currentCall . CallerChannel = currentChannel . Channel", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 67], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 52], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"string:\\\"Queue\\\"\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 2], [\"Insert\", \"N2\", [\"identifier:currentChannel\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:Application\", \"T\"], 2]]"}
{"project": "sunpy", "commit_sha": "43e61f881060fe62b089d061400995fee2dea001", "parent_sha": "84b6b1da382f76f6384ab350377260634cac045e", "file_path": "sunpy/map/__init__.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ def Map(input_):\n-    if isinstance(input_, str):\n+    if isinstance(input_, str) or isinstance(input_, unicode):\n         fits = pyfits.open(input_)\n         data = fits[0].data\n         header = fits[0].header\n", "before": "if isinstance ( input_ , str ) : fits = pyfits . open ( input_ ) data = fits [ 0 ] . data header = fits [ 0 ] . header", "after": "if isinstance ( input_ , str ) or isinstance ( input_ , unicode ) : fits = pyfits . open ( input_ ) data = fits [ 0 ] . data header = fits [ 0 ] . header", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 0, 5, 3, 32], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 0, 8, 0, 31], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:isinstance\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:input_\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:unicode\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "sunpy", "commit_sha": "fa70403ee74c1c937a7ed81f98c76c1f470b2aea", "parent_sha": "41644da4238af238f9006509803ddc8cd7d2d778", "file_path": "sunpy/net/jsoc_drms/jsoc.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -472,7 +472,7 @@ class JSOCClient(object):\n         if isMeta:\n             return r\n \n-        if r is None:\n+        if r is None or r.empty:\n             return astropy.table.Table()\n         else:\n             return astropy.table.Table.from_pandas(r)\n", "before": "if r is None : return astropy . table . Table ( ) else : return astropy . table . Table . from_pandas ( r )", "after": "if r is None or r . empty : return astropy . table . Table ( ) else : return astropy . table . Table . from_pandas ( r )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 54], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 21], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:r\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:empty\", \"T\"], 2]]"}
{"project": "sunpy", "commit_sha": "60eb247793ccfc3d842da89d5cec9f4b1be0d511", "parent_sha": "606302b29e8faa23e064f8426faaaec2864efc4d", "file_path": "sunpy/net/dataretriever/client.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -338,7 +338,7 @@ class GenericClient(object):\n         # Check for type of path\n-        if isinstance(path, str):\n+        if isinstance(path, str) or path is None:\n             pass\n         elif isinstance(path, pathlib.Path):\n             path = str(path.absolute())\n", "before": "if isinstance ( path , str ) : pass elif isinstance ( path , pathlib . Path ) : path = str ( path . absolute ( ) )", "after": "if isinstance ( path , str ) or path is None : pass elif isinstance ( path , pathlib . Path ) : path = str ( path . absolute ( ) )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 1, 9, 4, 40], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 1, 12, 1, 33], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:path\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2]]"}
{"project": "pip", "commit_sha": "e7575cd1b2f7d9f16a4b663d6b06293a89013ab6", "parent_sha": "bcd88e79892276102b955f05f339130ee98b133c", "file_path": "pip/vcs/git.py", "project_url": "https://github.com/takluyver/pip", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -142,7 +142,7 @@ class Git(VersionControl):\n         branches = self._get_all_branch_names(location)\n         branch_revs = {}\n         for line in branches.splitlines():\n-            if '(no branch)' in line:\n+            if '(no branch)' in line or '(detached from ' in line:\n                 continue\n             line = line.split('->')[0].strip()\n             # actual branch case\n", "before": "if '(no branch)' in line : continue", "after": "if '(no branch)' in line or '(detached from ' in line : continue", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 25], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 37], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"string:'(detached from '\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:line\", \"T\"], 2]]"}
{"project": "astroid", "commit_sha": "0c5a7c0e4f383b87e191a98b71cd536f9663618a", "parent_sha": "8a71646692b2834eadea65fd0ff840a4e27a3aea", "file_path": "astroid/helpers.py", "project_url": "https://github.com/PCManticore/astroid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -90,7 +90,7 @@ def object_type(node, context=None):\n         types = set(_object_type(node, context))\r\n     except exceptions.InferenceError:\r\n         return bases.YES\r\n-    if len(types) > 1:\r\n+    if len(types) > 1 or not types:\r\n         return bases.YES\r\n     return list(types)[0]\r\n \r\n", "before": "if len ( types ) > 1 : return bases . YES", "after": "if len ( types ) > 1 or not types : return bases . YES", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 4, 25], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 22], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"identifier:types\", \"T\"], 1]]"}
{"project": "hytra", "commit_sha": "69fee0237d629b8bdd15f78c7c2ded30a5ac52fb", "parent_sha": "31569cd4b8d1a0196e7c088395ea4ef8f287ba13", "file_path": "toolbox/hdf5_to_ctc.py", "project_url": "https://github.com/chaubold/hytra", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -139,7 +139,7 @@ def convert_label_volume(options):\n             # see whether this was a track continuation or the first leg of a new track\n             if src in old_mapping.keys():\n                 mapping[dest] = old_mapping[src]\n-            elif src not in list(splits[:,0]):\n+            elif len(splits)==0 or src not in list(splits[:,0]):\n                 mapping[dest] = new_track_id\n                 tracks[new_track_id] = [0, frame]\n                 new_track_id += 1\n", "before": "if src in old_mapping . keys ( ) : mapping [ dest ] = old_mapping [ src ] elif src not in list ( splits [ : , 0 ] ) : mapping [ dest ] = new_track_id tracks [ new_track_id ] = [ 0 , frame ] new_track_id += 1", "after": "if src in old_mapping . keys ( ) : mapping [ dest ] = old_mapping [ src ] elif len ( splits ) == 0 or src not in list ( splits [ : , 0 ] ) : mapping [ dest ] = new_track_id tracks [ new_track_id ] = [ 0 , frame ] new_track_id += 1", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"elif_clause\", 3, 13, 6, 34], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 18, 3, 46], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:splits\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "pyPdf", "commit_sha": "1e00ca39be50cd0dc637fe642ae566394107855d", "parent_sha": "1d3b8ab55f256ad1de8bf92e071c66f1ac111b77", "file_path": "pyPdf/utils.py", "project_url": "https://github.com/Huuuze/pyPdf", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,7 +38,7 @@ def readUntilWhitespace(stream):\n     txt = \"\"\r\n     while True:\r\n         tok = stream.read(1)\r\n-        if tok.isspace():\r\n+        if tok.isspace() or not tok:\r\n             break\r\n         txt += tok\r\n     return txt\r\n", "before": "if tok . isspace ( ) : break", "after": "if tok . isspace ( ) or not tok : break", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 18], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 25], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"identifier:tok\", \"T\"], 1]]"}
{"project": "scout", "commit_sha": "e12a34b95249807bbc60584eb3342efb72300bad", "parent_sha": "7f68bcc74ea59d6a37dec8dd1d75c502219bd644", "file_path": "scout/parse/variant/transcript.py", "project_url": "https://github.com/Clinical-Genomics/scout", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -211,7 +211,7 @@ def parse_transcripts(raw_transcripts, allele=None):\n             for variant_id in variant_ids.split(\"&\"):\n                 if variant_id.startswith(\"rs\"):\n                     transcript[\"dbsnp\"].append(variant_id)\n-                elif variant_id.startswith(\"COSM\"):\n+                elif variant_id.startswith(\"COSM\") or variant_id.startswith(\"COSV\"):\n                     transcript[\"cosmic\"].append(int(variant_id[4:]))\n \n         yield transcript\n", "before": "if variant_id . startswith ( \"rs\" ) : transcript [ \"dbsnp\" ] . append ( variant_id ) elif variant_id . startswith ( \"COSM\" ) : transcript [ \"cosmic\" ] . append ( int ( variant_id [ 4 : ] ) )", "after": "if variant_id . startswith ( \"rs\" ) : transcript [ \"dbsnp\" ] . append ( variant_id ) elif variant_id . startswith ( \"COSM\" ) or variant_id . startswith ( \"COSV\" ) : transcript [ \"cosmic\" ] . append ( int ( variant_id [ 4 : ] ) )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"elif_clause\", 3, 17, 4, 69], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 22, 3, 51], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"identifier:variant_id\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:startswith\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"string:\\\"COSV\\\"\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "unknown-horizons", "commit_sha": "e5917fb6bb0ff29e4fef59f64b383c21bd942dd6", "parent_sha": "fdc451403bed5755c4bd01edb933ca4ba0acf33b", "file_path": "horizons/gui/gui.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -242,7 +242,7 @@ class Gui(SingleplayerMenu, MultiplayerMenu):\n \t\tselected_item = self.current.collectData(\"savegamelist\")\n-\t\tif selected_item == -1:\n+\t\tif selected_item == -1 or selected_item >= len(map_files):\n \t\t\tself.show_popup(_(\"No file selected\"), _(\"You need to select a savegame to delete\"))\n \t\t\treturn False\n \t\tselected_file = map_files[selected_item]\n", "before": "if selected_item == - 1 : self . show_popup ( _ ( \"No file selected\" ) , _ ( \"You need to select a savegame to delete\" ) ) return False", "after": "if selected_item == - 1 or selected_item >= len ( map_files ) : self . show_popup ( _ ( \"No file selected\" ) , _ ( \"You need to select a savegame to delete\" ) ) return False", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 1, 3, 3, 16], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 1, 6, 1, 25], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:selected_item\", \"T\"], 0], [\"Insert\", \"N1\", [\">=:>=\", \"T\"], 1], [\"Insert\", \"N1\", [\"call\", \"N2\"], 2], [\"Insert\", \"N2\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:map_files\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "awslimitchecker", "commit_sha": "7aca720f438c10e80ab3e2cfa294965b59015db2", "parent_sha": "37e843b7a6bfe07a856e61e5cad9f82847e39184", "file_path": "awslimitchecker/limit.py", "project_url": "https://github.com/tehama-io/awslimitchecker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -429,7 +429,7 @@ class AwsLimit(object):\n         for u in self._current_usage:\n             usage = u.get_value()\n             limit = u.get_maximum() or self.get_limit()\n-            if limit is None:\n+            if limit is None or limit == 0:\n                 continue\n             pct = (usage / (limit * 1.0)) * 100\n             if crit_int is not None and usage >= crit_int:\n", "before": "if limit is None : continue", "after": "if limit is None or limit == 0 : continue", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 25], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 29], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:limit\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "65e55d47b129e591d9676a3180773c4b8cb75bef", "parent_sha": "827723db90131ac8e8c3845dc90e361ea2353194", "file_path": "lib/ansible/modules/cloud/vmware/vmware_guest.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1055,7 +1055,7 @@ class PyVmomiHelper(object):\n         self.configure_disks(vm_obj=vm_obj)\n         self.configure_network(vm_obj=vm_obj)\n \n-        if len(self.params['customization']) > 0:\n+        if len(self.params['customization']) > 0 or len(self.params['networks']) > 0:\n             self.customize_vm(vm_obj=vm_obj)\n \n         try:\n", "before": "if len ( self . params [ 'customization' ] ) > 0 : self . customize_vm ( vm_obj = vm_obj )", "after": "if len ( self . params [ 'customization' ] ) > 0 or len ( self . params [ 'networks' ] ) > 0 : self . customize_vm ( vm_obj = vm_obj )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 45], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 49], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\">:>\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:len\", \"T\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"subscript\", \"N4\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2], [\"Insert\", \"N4\", [\"attribute\", \"N5\"], 0], [\"Insert\", \"N4\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N4\", [\"string:'networks'\", \"T\"], 2], [\"Insert\", \"N4\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N5\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N5\", [\".:.\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:params\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "930d5d88b75d0774e5b7631fdcc4c88145351c1f", "parent_sha": "ccdea1c3b86be198fc87eb81853900d49ee60b9b", "file_path": "contrib/inventory/cobbler.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -190,7 +190,7 @@ class CobblerInventory(object):\n                         if this_dns_name is not None and this_dns_name is not \"\":\n                             dns_name = this_dns_name\n \n-            if dns_name == '':\n+            if dns_name == '' or dns_name is None:\n                 continue\n \n             status = host['status']\n", "before": "if dns_name == '' : continue", "after": "if dns_name == '' or dns_name is None : continue", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 25], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 30], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:dns_name\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2]]"}
{"project": "pritunl", "commit_sha": "c8ede1f1b473f8e85cf57e4b0748375c16683908", "parent_sha": "985af7d7169f5250d5865be6d1bef497ef29d782", "file_path": "pritunl/link/link.py", "project_url": "https://github.com/security-geeks/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -408,7 +408,7 @@ class Location(mongo.MongoObject):\n                 excludes.add(exclude_id)\n \n             for location_id, location in locations.iteritems():\n-                if location_id in excludes:\n+                if location_id in excludes or location_id == self.id:\n                     continue\n \n                 peers.append({\n", "before": "if location_id in excludes : continue", "after": "if location_id in excludes or location_id == self . id : continue", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 4, 29], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 20, 3, 43], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:location_id\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 2], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:id\", \"T\"], 2]]"}
{"project": "ansible-modules-core", "commit_sha": "5f1ac88414a3d1a8cace175ff86f92d22608ec0c", "parent_sha": "997fa3b2b7c43db1d02a34377d01a181ad90c5a1", "file_path": "packaging/os/apt_key.py", "project_url": "https://github.com/drewp/ansible-modules-core", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -132,7 +132,7 @@ def all_keys(module, keyring, short_format):\n     results = []\n     lines = out.split('\\n')\n     for line in lines:\n-        if line.startswith(\"pub\"):\n+        if line.startswith(\"pub\") or line.startswith(\"sub\"):\n             tokens = line.split()\n             code = tokens[1]\n             (len_type, real_code) = code.split(\"/\")\n", "before": "if line . startswith ( \"pub\" ) : tokens = line . split ( ) code = tokens [ 1 ] ( len_type , real_code ) = code . split ( \"/\" )", "after": "if line . startswith ( \"pub\" ) or line . startswith ( \"sub\" ) : tokens = line . split ( ) code = tokens [ 1 ] ( len_type , real_code ) = code . split ( \"/\" )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 52], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 34], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"identifier:line\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:startswith\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"string:\\\"sub\\\"\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "mopidy", "commit_sha": "af540aee37c98a94188dbb63306d42a4871744c9", "parent_sha": "92ddd888ee3b09c17c935828483f6c788cfb0e36", "file_path": "mopidy/local/commands.py", "project_url": "https://github.com/atxwebs/mopidy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -118,7 +118,7 @@ class ScanCommand(commands.Command):\n             relpath = os.path.relpath(abspath, media_dir)\n             uri = translator.path_to_local_track_uri(relpath)\n \n-            if b'/.' in relpath:\n+            if b'/.' in relpath or relpath.startswith(b'.'):\n                 logger.debug('Skipped %s: Hidden directory/file.', uri)\n             elif relpath.lower().endswith(excluded_file_extensions):\n                 logger.debug('Skipped %s: File extension excluded.', uri)\n", "before": "if b'/.' in relpath : logger . debug ( 'Skipped %s: Hidden directory/file.' , uri ) elif relpath . lower ( ) . endswith ( excluded_file_extensions ) : logger . debug ( 'Skipped %s: File extension excluded.' , uri )", "after": "if b'/.' in relpath or relpath . startswith ( b'.' ) : logger . debug ( 'Skipped %s: Hidden directory/file.' , uri ) elif relpath . lower ( ) . endswith ( excluded_file_extensions ) : logger . debug ( 'Skipped %s: File extension excluded.' , uri )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 74], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 32], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"identifier:relpath\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:startswith\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"string:b'.'\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "1c11a35f70bc4aee40dfe1fdde7f151ea55eddc2", "parent_sha": "f9ec06d1dcdef5675a3c4b190bee45d8132f3fa6", "file_path": "lib/ansible/modules/cloud/vmware/vmware_guest.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1011,7 +1011,7 @@ class PyVmomiHelper(object):\n             if not rp[0]:\n                 continue\n \n-            if not hasattr(rp[0], 'parent'):\n+            if not hasattr(rp[0], 'parent') or not rp[0].parent:\n                 continue\n \n             # Find resource pool on host\n", "before": "if not hasattr ( rp [ 0 ] , 'parent' ) : continue", "after": "if not hasattr ( rp [ 0 ] , 'parent' ) or not rp [ 0 ] . parent : continue", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 16, 3, 44], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 20, 3, 44], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 1], [\"Insert\", \"N2\", [\"subscript\", \"N3\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:parent\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:rp\", \"T\"], 0], [\"Insert\", \"N3\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N3\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N3\", [\"]:]\", \"T\"], 3]]"}
{"project": "audioNet", "commit_sha": "e828297ba794c3848c71410c5cb3a0bd3db78a08", "parent_sha": "13db35612c09e593cd56d40eefacd3864828bcb6", "file_path": "webfront.py", "project_url": "https://github.com/nslab-saturn/audioNet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -80,7 +80,7 @@ def predictAction():\n                 os.remove(fullpath)\n             file.save(fullpath)  # save the uploaded file\n             \n-            if os.path.exists(FFMPEG_PATH):\n+            if os.path.exists(FFMPEG_PATH) or os.path.exists(FFMPEG_PATH + '.exe'):\n                 ffmpeg_cmd = ' -i {} -ac 1 -acodec pcm_f32le -ar 11025 {}.wav -v 1'.format(fullpath, fullpath)\n                 ffmpeg_cmd = FFMPEG_PATH + ffmpeg_cmd\n                 \n", "before": "if os . path . exists ( FFMPEG_PATH ) : ffmpeg_cmd = ' -i {} -ac 1 -acodec pcm_f32le -ar 11025 {}.wav -v 1' . format ( fullpath , fullpath ) ffmpeg_cmd = FFMPEG_PATH + ffmpeg_cmd", "after": "if os . path . exists ( FFMPEG_PATH ) or os . path . exists ( FFMPEG_PATH + '.exe' ) : ffmpeg_cmd = ' -i {} -ac 1 -acodec pcm_f32le -ar 11025 {}.wav -v 1' . format ( fullpath , fullpath ) ffmpeg_cmd = FFMPEG_PATH + ffmpeg_cmd", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 5, 54], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 43], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:exists\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"binary_operator\", \"N5\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:path\", \"T\"], 2], [\"Insert\", \"N5\", [\"identifier:FFMPEG_PATH\", \"T\"], 0], [\"Insert\", \"N5\", [\"+:+\", \"T\"], 1], [\"Insert\", \"N5\", [\"string:'.exe'\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "9c4eae525306bf201304a15d36f531b0308cd25e", "parent_sha": "1380c71fe06a09709ca37217fd42e812e0acee0a", "file_path": "lib/ansible/plugins/action/template.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -157,7 +157,7 @@ class ActionModule(ActionBase):\n             if self._play_context.diff:\n                 diff = self._get_diff_data(dest, resultant, task_vars, source_file=False)\n \n-            if not self._play_context.check_mode: # do actual work thorugh copy\n+            if not self._play_context.check_mode or self._task.always_run: # do actual work thorugh copy\n                 xfered = self._transfer_data(self._connection._shell.join_path(tmp, 'source'), resultant)\n \n                 # fix file permissions when the copy is done as a different user\n", "before": "if not self . _play_context . check_mode : xfered = self . _transfer_data ( self . _connection . _shell . join_path ( tmp , 'source' ) , resultant )", "after": "if not self . _play_context . check_mode or self . _task . always_run : xfered = self . _transfer_data ( self . _connection . _shell . join_path ( tmp , 'source' ) , resultant )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 16, 3, 49], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"attribute\", 3, 20, 3, 49], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:always_run\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:_task\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "8d16638fec3e88e0f7b0dde24aae095100436644", "parent_sha": "d31d04a1e075ef53c68a4049a539105dae95330d", "file_path": "lib/ansible/plugins/action/template.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -150,7 +150,7 @@ class ActionModule(ActionBase):\n         diff = {}\n         new_module_args = self._task.args.copy()\n \n-        if force and local_checksum != remote_checksum:\n+        if (remote_checksum == '1') or (force and local_checksum != remote_checksum):\n \n             result['changed'] = True\n             # if showing diffs, we need to get the remote value\n", "before": "if force and local_checksum != remote_checksum : result [ 'changed' ] = True", "after": "if ( remote_checksum == '1' ) or ( force and local_checksum != remote_checksum ) : result [ 'changed' ] = True", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 55], [\"parenthesized_expression\", \"N0\"], 0], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 55], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 55], [\"parenthesized_expression\", \"N1\"], 2], [\"Insert\", \"N0\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N0\", [\"comparison_operator\", \"N2\"], 1], [\"Insert\", \"N0\", [\"):)\", \"T\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"boolean_operator\", 3, 12, 3, 55], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:remote_checksum\", \"T\"], 0], [\"Insert\", \"N2\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N2\", [\"string:'1'\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "51a180b150da411787f6209521cf8abbac8b8b0d", "parent_sha": "4d1f4479083e87e97419fb554a943dafadce00d5", "file_path": "lib/ansible/inventory/__init__.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -392,7 +392,7 @@ class Inventory(object):\n         if not self.is_file():\n             return None\n         dname = os.path.dirname(self.host_list)\n-        if dname is None or dname == '':\n+        if dname is None or dname == '' or dname == '.':\n             cwd = os.getcwd()\n             return cwd \n         return dname\n", "before": "if dname is None or dname == '' : cwd = os . getcwd ( ) return cwd", "after": "if dname is None or dname == '' or dname == '.' : cwd = os . getcwd ( ) return cwd", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 12, 3, 40], [\"boolean_operator\", 3, 12, 3, 40], 0], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 40], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 12, 3, 40], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"identifier:dname\", \"T\"], 0], [\"Insert\", \"N0\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'.'\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "83667961bbb28974b2a7aca3ac0810fe2579d1d0", "parent_sha": "9ee857180b946d6f2e51cef8b8e24a1cce3fa535", "file_path": "lib/ansible/modules/extras/monitoring/monit.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -119,7 +119,7 @@ def main():\n         if module.check_mode:\n             module.exit_json(changed=True)\n         status = run_command('unmonitor')\n-        if status in ['not monitored']:\n+        if status in ['not monitored'] or 'unmonitor pending' in status:\n             module.exit_json(changed=True, name=name, state=state)\n         module.fail_json(msg='%s process not unmonitored' % name, status=status)\n \n", "before": "if status in [ 'not monitored' ] : module . exit_json ( changed = True , name = name , state = state )", "after": "if status in [ 'not monitored' ] or 'unmonitor pending' in status : module . exit_json ( changed = True , name = name , state = state )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 67], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 39], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"string:'unmonitor pending'\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:status\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "8d4fe2a7673fa90d65e92aecb8ff11c7f94ef623", "parent_sha": "fc87dd9650de0aea3c75cd75376692209d618378", "file_path": "lib/ansible/modules/packaging/os/apt_key.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -132,7 +132,7 @@ def all_keys(module, keyring, short_format):\n     results = []\n     lines = out.split('\\n')\n     for line in lines:\n-        if line.startswith(\"pub\"):\n+        if line.startswith(\"pub\") or line.startswith(\"sub\"):\n             tokens = line.split()\n             code = tokens[1]\n             (len_type, real_code) = code.split(\"/\")\n", "before": "if line . startswith ( \"pub\" ) : tokens = line . split ( ) code = tokens [ 1 ] ( len_type , real_code ) = code . split ( \"/\" )", "after": "if line . startswith ( \"pub\" ) or line . startswith ( \"sub\" ) : tokens = line . split ( ) code = tokens [ 1 ] ( len_type , real_code ) = code . split ( \"/\" )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 52], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 34], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"identifier:line\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:startswith\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"string:\\\"sub\\\"\", \"T\"], 1], [\"Insert\", \"N3\", [\"):)\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "c60749c9222c8139042a0f4280d6622b209de550", "parent_sha": "f2364ecf5f9abcb11112dc7fe7c7eaffb6703bd1", "file_path": "lib/ansible/module_utils/basic.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1274,7 +1274,7 @@ class AnsibleModule(object):\n         if isinstance(value, bool):\n             return value\n \n-        if isinstance(value, basestring):\n+        if isinstance(value, basestring) or isinstance(value, int):\n             return self.boolean(value)\n \n         raise TypeError('%s cannot be converted to a bool' % type(value))\n", "before": "if isinstance ( value , basestring ) : return self . boolean ( value )", "after": "if isinstance ( value , basestring ) or isinstance ( value , int ) : return self . boolean ( value )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 39], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 41], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:isinstance\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:value\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:int\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "bitbake", "commit_sha": "9a5ea24c80eca9592e0ad32cfdaf173e1815cb5e", "parent_sha": "349e85c15a3287c60e3f4a29b29c1a54220314ae", "file_path": "lib/bb/fetch/cvs.py", "project_url": "https://github.com/YoeDistro/bitbake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -194,7 +194,7 @@ class Cvs(Fetch):\n                 bb.debug(1, \"Running %s\" % cvscmd)\n                 myret = os.system(cvscmd)\n \n-            if myret != 0:\n+            if myret != 0 or not os.access(moddir, os.R_OK):\n                 try:\n                     os.rmdir(moddir)\n                 except OSError:\n", "before": "if myret != 0 : try : os . rmdir ( moddir ) except OSError : ", "after": "if myret != 0 or not os . access ( moddir , os . R_OK ) : try : os . rmdir ( moddir ) except OSError : ", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 32], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 26], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"call\", \"N2\"], 1], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N3\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:access\", \"T\"], 2], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"identifier:moddir\", \"T\"], 1], [\"Insert\", \"N4\", [\",:,\", \"T\"], 2], [\"Insert\", \"N4\", [\"attribute\", \"N5\"], 3], [\"Insert\", \"N4\", [\"):)\", \"T\"], 4], [\"Insert\", \"N5\", [\"identifier:os\", \"T\"], 0], [\"Insert\", \"N5\", [\".:.\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:R_OK\", \"T\"], 2]]"}
{"project": "bitbake", "commit_sha": "53efa01720a61da2cb344cbb7e977baa28deba3b", "parent_sha": "7753e075dbeee471b9ceb34f1e3165aa656932ed", "file_path": "lib/bb/ui/uihelper.py", "project_url": "https://github.com/YoeDistro/bitbake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ class BBUIHelper:\n             self.running_pids.remove(event.pid)\n             self.failed_tasks.append( { 'title' : \"%s %s\" % (event._package, event._task)})\n             self.needUpdate = True\n-        if isinstance(event, bb.runqueue.runQueueTaskStarted):\n+        if isinstance(event, bb.runqueue.runQueueTaskStarted) or isinstance(event, bb.runqueue.sceneQueueTaskStarted):\n             self.tasknumber_current = event.stats.completed + event.stats.active + event.stats.failed + 1\n             self.tasknumber_total = event.stats.total\n \n", "before": "if isinstance ( event , bb . runqueue . runQueueTaskStarted ) : self . tasknumber_current = event . stats . completed + event . stats . active + event . stats . failed + 1 self . tasknumber_total = event . stats . total", "after": "if isinstance ( event , bb . runqueue . runQueueTaskStarted ) or isinstance ( event , bb . runqueue . sceneQueueTaskStarted ) : self . tasknumber_current = event . stats . completed + event . stats . active + event . stats . failed + 1 self . tasknumber_total = event . stats . total", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 5, 54], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 62], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:isinstance\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:event\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4], [\"Insert\", \"N3\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:sceneQueueTaskStarted\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:bb\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:runqueue\", \"T\"], 2]]"}
{"project": "bitbake", "commit_sha": "70a8ead31f9ffc987d9c6db61a926f7a9af8f8b1", "parent_sha": "dd15648fc2654b8d7c3e00ea7ab3dbf04f24f24b", "file_path": "lib/bb/command.py", "project_url": "https://github.com/YoeDistro/bitbake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -117,7 +117,7 @@ class Command:\n             return False\n \n     def finishAsyncCommand(self, msg=None, code=None):\n-        if msg:\n+        if msg or msg == \"\":\n             bb.event.fire(CommandFailed(msg), self.cooker.event_data)\n         elif code:\n             bb.event.fire(CommandExit(code), self.cooker.event_data)\n", "before": "if msg : bb . event . fire ( CommandFailed ( msg ) , self . cooker . event_data ) elif code : bb . event . fire ( CommandExit ( code ) , self . cooker . event_data )", "after": "if msg or msg == \"\" : bb . event . fire ( CommandFailed ( msg ) , self . cooker . event_data ) elif code : bb . event . fire ( CommandExit ( code ) , self . cooker . event_data )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 69], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:msg\", 3, 12, 3, 15], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:msg\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:\\\"\\\"\", \"T\"], 2]]"}
{"project": "conda-build", "commit_sha": "a94f21fa5e89dc0317f48614a7630649cd828170", "parent_sha": "a3420d4bc7d61e1e3d32e5862df00bf44056af56", "file_path": "conda_build/post.py", "project_url": "https://github.com/bgruening/conda-build", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -153,7 +153,7 @@ def coerce_pycache_to_old_style(files, cwd):\n             f = os.path.join(cwd, f)\n         if not os.path.isfile(f) or not f.endswith('py'):\n             continue\n-        if '/' in f:\n+        if '/' in f or '\\\\' in f:\n             folder = os.path.join(cwd, os.path.dirname(f), '__pycache__')\n         else:\n             folder = os.path.join(cwd, '__pycache__')\n", "before": "if '/' in f : folder = os . path . join ( cwd , os . path . dirname ( f ) , '__pycache__' ) else : folder = os . path . join ( cwd , '__pycache__' )", "after": "if '/' in f or '\\\\' in f : folder = os . path . join ( cwd , os . path . dirname ( f ) , '__pycache__' ) else : folder = os . path . join ( cwd , '__pycache__' )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 54], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 20], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"string:'\\\\\\\\'\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:f\", \"T\"], 2]]"}
{"project": "millegrilles.consignation.python", "commit_sha": "1d465d26f8f3ca856f34a1b588637edc84cfc4c6", "parent_sha": "54f2a0d2a66d30688cc259aa05a48c25d4a09f5f", "file_path": "millegrilles/domaines/SenseursPassifs.py", "project_url": "https://github.com/dugrema/millegrilles.consignation.python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -112,7 +112,7 @@ class TraitementMessageLecture(TraitementMessageDomaine):\n         set_ops = dict()\n         for cle, donnees in senseurs.items():\n             donnees_actuelles = senseurs_actuels.get(cle)\n-            if donnees_actuelles is None or donnees_actuelles['timestamp'] < donnees['timestamp']:\n+            if donnees_actuelles is None or donnees_actuelles.get('timestamp') is None or donnees_actuelles['timestamp'] < donnees['timestamp']:\n                 for key, value in donnees.items():\n                     set_ops['senseurs.' + cle + '.' + key] = value\n \n", "before": "if donnees_actuelles is None or donnees_actuelles [ 'timestamp' ] < donnees [ 'timestamp' ] : for key , value in donnees . items ( ) : set_ops [ 'senseurs.' + cle + '.' + key ] = value", "after": "if donnees_actuelles is None or donnees_actuelles . get ( 'timestamp' ) is None or donnees_actuelles [ 'timestamp' ] < donnees [ 'timestamp' ] : for key , value in donnees . items ( ) : set_ops [ 'senseurs.' + cle + '.' + key ] = value", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 16, 3, 98], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", [\"boolean_operator\", 3, 16, 3, 98], [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 41], 0], [\"Move\", \"N0\", [\"or:or\", 3, 42, 3, 44], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"call\", \"N2\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N3\", [\"identifier:donnees_actuelles\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:get\", \"T\"], 2], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"string:'timestamp'\", \"T\"], 1], [\"Insert\", \"N4\", [\"):)\", \"T\"], 2]]"}
{"project": "BlindChat", "commit_sha": "e6099ef0c3f1af54cad0dce1b982e0c375e3683a", "parent_sha": "df4d1d4d13fcb947d6ee8abbb4abb864eec6ceb7", "file_path": "DB_Wrappers/Users.py", "project_url": "https://github.com/malmal200/BlindChat", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -51,7 +51,7 @@ class UsersDB:\n     def addMessage(self, id, message):\n         user = User.query.get(id)\n         m = user.messages\n-        if m == None:\n+        if m == None or m == \"\":\n             user.messages = message\n         elif len(m.split('#&#')) == 1:\n             user.messages = m + \"#&#\" + message\n", "before": "if m == None : user . messages = message elif len ( m . split ( '#&#' ) ) == 1 : user . messages = m + \"#&#\" + message", "after": "if m == None or m == \"\" : user . messages = message elif len ( m . split ( '#&#' ) ) == 1 : user . messages = m + \"#&#\" + message", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 48], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 21], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:m\", \"T\"], 0], [\"Insert\", \"N1\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:\\\"\\\"\", \"T\"], 2]]"}
{"project": "Japanese-Language-Mini-Games", "commit_sha": "e2d8e6230300e0b6a777e216ced8a1dc5a799aa1", "parent_sha": "d23608fe83370f4f7fcf7f1f1d98879153f9776b", "file_path": "src/conversion.py", "project_url": "https://github.com/Timothy-Davis/Japanese-Language-Mini-Games", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -210,7 +210,7 @@ def convert_to_kana(romaji: str, kana: bool = HIRAGANA) -> str:\n \n         # Unfortunately, special logic is also needed to handle singular \u3093 and double-consonant n-types.\n         if romaji[index] == 'n':\n-            if index+1 == len(romaji) or romaji[index+1] == 'n':\n+            if index+1 == len(romaji) or romaji[index+1] == 'n' or romaji[index+1] in TSU_CONSONANTS:\n                 if kana is KATAKANA:\n                     output_str += '\u30f3'\n                 else:\n", "before": "if index + 1 == len ( romaji ) or romaji [ index + 1 ] == 'n' : if kana is KATAKANA : output_str += '\u30f3' else : ", "after": "if index + 1 == len ( romaji ) or romaji [ index + 1 ] == 'n' or romaji [ index + 1 ] in TSU_CONSONANTS : if kana is KATAKANA : output_str += '\u30f3' else : ", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 16, 3, 64], [\"boolean_operator\", 3, 16, 3, 64], 0], [\"Insert\", [\"boolean_operator\", 3, 16, 3, 64], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 16, 3, 64], [\"comparison_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"subscript\", \"N1\"], 0], [\"Insert\", \"N0\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:TSU_CONSONANTS\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:romaji\", \"T\"], 0], [\"Insert\", \"N1\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N1\", [\"binary_operator\", \"N2\"], 2], [\"Insert\", \"N1\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N2\", [\"identifier:index\", \"T\"], 0], [\"Insert\", \"N2\", [\"+:+\", \"T\"], 1], [\"Insert\", \"N2\", [\"integer:1\", \"T\"], 2]]"}
{"project": "nikola", "commit_sha": "567f5de9438385544ca0a58e5b3b1916b850ae7d", "parent_sha": "e9f5c8920dde393a915eaec2f9a5088c3cfae8da", "file_path": "nikola/utils.py", "project_url": "https://github.com/michaeljoseph/nikola", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -426,7 +426,7 @@ def to_datetime(value, tzinfo=None):\n     try:\n         from dateutil import parser\n         dt = parser.parse(value)\n-        if tzinfo is None:\n+        if tzinfo is None or dt.tzinfo:\n             return dt\n         return tzinfo.localize(dt)\n     except ImportError:\n", "before": "if tzinfo is None : return dt", "after": "if tzinfo is None or dt . tzinfo : return dt", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 22], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 26], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:dt\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:tzinfo\", \"T\"], 2]]"}
{"project": "vumi-go", "commit_sha": "8559ba5358f2e72350f68411b089be7415671751", "parent_sha": "9879ecbc4d694e94c63053751ff2bc4beceb5478", "file_path": "go/conversation/views.py", "project_url": "https://github.com/ChrisNolan1992/vumi-go", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -46,7 +46,7 @@ def index(request):\n             raise ValueError(\n                 \"Unknown conversation status: %s\" % (conversation_status,))\n \n-    if not (conversation_type or conversation_status):\n+    if not (conversation_type or conversation_status or query):\n         conversations = [request.user_api.wrap_conversation(conversation) for\n                     conversation in request.user_api.active_conversations()]\n \n", "before": "if not ( conversation_type or conversation_status ) : conversations = [ request . user_api . wrap_conversation ( conversation ) for conversation in request . user_api . active_conversations ( ) ]", "after": "if not ( conversation_type or conversation_status or query ) : conversations = [ request . user_api . wrap_conversation ( conversation ) for conversation in request . user_api . active_conversations ( ) ]", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 13, 3, 53], [\"boolean_operator\", 3, 13, 3, 53], 0], [\"Insert\", [\"boolean_operator\", 3, 13, 3, 53], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 13, 3, 53], [\"identifier:query\", \"T\"], 2]]"}
{"project": "salt", "commit_sha": "7f197c568ce0c138665e2dcc325e82876eb1fb4c", "parent_sha": "8a5b4ae780ffe6b3d787789eb0ca6bb242475879", "file_path": "salt/output/__init__.py", "project_url": "https://github.com/StepOneInc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ def get_printout(out, opts=None, **kwargs):\n \n         if opts.get('force_color', False):\n             opts['color'] = True\n-        elif opts.get('no_color', False) or is_pipe():\n+        elif opts.get('no_color', False) or is_pipe() or salt.utils.is_windows():\n             opts['color'] = False\n         else:\n             opts['color'] = True\n", "before": "if opts . get ( 'force_color' , False ) : opts [ 'color' ] = True elif opts . get ( 'no_color' , False ) or is_pipe ( ) : opts [ 'color' ] = False else : opts [ 'color' ] = True", "after": "if opts . get ( 'force_color' , False ) : opts [ 'color' ] = True elif opts . get ( 'no_color' , False ) or is_pipe ( ) or salt . utils . is_windows ( ) : opts [ 'color' ] = False else : opts [ 'color' ] = True", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 14, 3, 54], [\"boolean_operator\", 3, 14, 3, 54], 0], [\"Insert\", [\"boolean_operator\", 3, 14, 3, 54], [\"or:or\", \"T\"], 1], [\"Insert\", [\"boolean_operator\", 3, 14, 3, 54], [\"call\", \"N0\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:is_windows\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:salt\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:utils\", \"T\"], 2]]"}
{"project": "gensim", "commit_sha": "71cd37dc3520ebd969b4dfcd13e06b02bb02a57a", "parent_sha": "548d94b9eff628c3635f78ae43ec6abcd8457573", "file_path": "gensim/utils.py", "project_url": "https://github.com/springhser/gensim", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -531,7 +531,7 @@ def is_corpus(obj):\n     except:\n         pass\n     try:\n-        if hasattr(obj, 'next'):\n+        if hasattr(obj, 'next') or hasattr(obj, '__next__'):\n             # the input is an iterator object, meaning once we call next()\n             # that element could be gone forever. we must be careful to put\n             # whatever we retrieve back again\n", "before": "if hasattr ( obj , 'next' ) : ", "after": "if hasattr ( obj , 'next' ) or hasattr ( obj , '__next__' ) : ", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 3, 33], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 32], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:hasattr\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"identifier:obj\", \"T\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"string:'__next__'\", \"T\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4]]"}
{"project": "gensim", "commit_sha": "e4e6a7092569fa1140807980bf1bbac69ce64103", "parent_sha": "e196b241b9c5fbaa8a500ca4307f6d6ceb7f081c", "file_path": "gensim/models/word2vec.py", "project_url": "https://github.com/springhser/gensim", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -715,7 +715,7 @@ class Word2Vec(utils.SaveLoad):\n                     job_queue.put((None, 0))  # give the workers heads up that they can finish -- no more work!\n                 push_done = True\n             try:\n-                while done_jobs < (job_no+1):\n+                while done_jobs < (job_no+1) or not push_done:\n                     word_count += progress_queue.get(push_done)  # only block after all jobs pushed\n                     done_jobs += 1\n                     elapsed = default_timer() - start\n", "before": "while done_jobs < ( job_no + 1 ) : word_count += progress_queue . get ( push_done ) done_jobs += 1 elapsed = default_timer ( ) - start", "after": "while done_jobs < ( job_no + 1 ) or not push_done : word_count += progress_queue . get ( push_done ) done_jobs += 1 elapsed = default_timer ( ) - start", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"while_statement\", 3, 17, 6, 54], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 23, 3, 45], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"identifier:push_done\", \"T\"], 1]]"}
{"project": "platformio", "commit_sha": "2a84aec59ef3fd3dbc7c9d3a64675057d308c6c0", "parent_sha": "68cec0448e4f791ba57765268c8bcfe6f2d437b9", "file_path": "platformio/platforms/base.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/platformio", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -208,7 +208,7 @@ class BasePlatform(object):\n \n         # append aliases of the installed packages\n         for name, options in self.get_packages().items():\n-            if name not in installed_packages:\n+            if \"alias\" not in options or name not in installed_packages:\n                 continue\n             variables.append(\n                 \"PIOPACKAGE_%s=%s\" % (options['alias'].upper(), name))\n", "before": "if name not in installed_packages : continue", "after": "if \"alias\" not in options or name not in installed_packages : continue", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 25], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 16, 3, 46], 2], [\"Insert\", \"N1\", [\"string:\\\"alias\\\"\", \"T\"], 0], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 1], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:options\", \"T\"], 3]]"}
{"project": "ESP-Website-1", "commit_sha": "fb515a3d9c4f12cb894c25b2f95846f97d5a4312", "parent_sha": "c1451c7e7af4d64b455019772c801c26033a51a5", "file_path": "esp/esp/program/modules/handlers/studentjunctionappmodule.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/ESP-Website-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -98,7 +98,7 @@ class StudentJunctionAppModule(ProgramModuleObj):\n             for i in [x['id'] for x in cls.studentappquestion_set.all().values('id')]:\n                 if i not in response_question_ids:\n                     return False\n-                elif not response_dict[i].complete:\n+                elif (not response_dict[i].complete) or response_dict[i].response == \"\":\n                     return False\n         return True\n         \n", "before": "if i not in response_question_ids : return False elif not response_dict [ i ] . complete : return False", "after": "if i not in response_question_ids : return False elif ( not response_dict [ i ] . complete ) or response_dict [ i ] . response == \"\" : return False", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"elif_clause\", 3, 17, 4, 33], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"parenthesized_expression\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N2\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"not_operator\", 3, 22, 3, 51], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N2\", [\"string:\\\"\\\"\", \"T\"], 2], [\"Insert\", \"N3\", [\"subscript\", \"N4\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:response\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:response_dict\", \"T\"], 0], [\"Insert\", \"N4\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:i\", \"T\"], 2], [\"Insert\", \"N4\", [\"]:]\", \"T\"], 3]]"}
{"project": "ESP-Website-1", "commit_sha": "30c69b627274ecf3f9825d2aa47881cc038bb6b1", "parent_sha": "f7f513f725f56df4278ee3cc63d4c1ca7aaff9cd", "file_path": "esp/esp/program/modules/handlers/studentjunctionappmodule.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/ESP-Website-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -98,7 +98,7 @@ class StudentJunctionAppModule(ProgramModuleObj):\n             for i in [x['id'] for x in cls.studentappquestion_set.all().values('id')]:\n                 if i not in response_question_ids:\n                     return False\n-                elif not response_dict[i].complete:\n+                elif (not response_dict[i].complete) or response_dict[i].response == \"\":\n                     return False\n         return True\n         \n", "before": "if i not in response_question_ids : return False elif not response_dict [ i ] . complete : return False", "after": "if i not in response_question_ids : return False elif ( not response_dict [ i ] . complete ) or response_dict [ i ] . response == \"\" : return False", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"elif_clause\", 3, 17, 4, 33], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"parenthesized_expression\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N2\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Move\", \"N1\", [\"not_operator\", 3, 22, 3, 51], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"==:==\", \"T\"], 1], [\"Insert\", \"N2\", [\"string:\\\"\\\"\", \"T\"], 2], [\"Insert\", \"N3\", [\"subscript\", \"N4\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:response\", \"T\"], 2], [\"Insert\", \"N4\", [\"identifier:response_dict\", \"T\"], 0], [\"Insert\", \"N4\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:i\", \"T\"], 2], [\"Insert\", \"N4\", [\"]:]\", \"T\"], 3]]"}
{"project": "portage-funtoo", "commit_sha": "38e7087a2bc99f4f429ca6968f4678cd2123ebdf", "parent_sha": "e9fe5d1a6789ceeaef1da6fae0761664c7cd727a", "file_path": "pym/_emerge/actions.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage-funtoo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2343,7 +2343,7 @@ def adjust_config(myopts, settings):\n \tsettings[\"EMERGE_WARNING_DELAY\"] = str(EMERGE_WARNING_DELAY)\n \tsettings.backup_changes(\"EMERGE_WARNING_DELAY\")\n \n-\tif \"--quiet\" in myopts:\n+\tif \"--quiet\" in myopts or \"--quiet-build\" in myopts:\n \t\tsettings[\"PORTAGE_QUIET\"]=\"1\"\n \t\tsettings.backup_changes(\"PORTAGE_QUIET\")\n \n", "before": "if \"--quiet\" in myopts : settings [ \"PORTAGE_QUIET\" ] = \"1\" settings . backup_changes ( \"PORTAGE_QUIET\" )", "after": "if \"--quiet\" in myopts or \"--quiet-build\" in myopts : settings [ \"PORTAGE_QUIET\" ] = \"1\" settings . backup_changes ( \"PORTAGE_QUIET\" )", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 2, 5, 43], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 5, 3, 24], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"string:\\\"--quiet-build\\\"\", \"T\"], 0], [\"Insert\", \"N1\", [\"in:in\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:myopts\", \"T\"], 2]]"}
{"project": "flake8", "commit_sha": "8eec1e5e116feaaa1587a37b5974d664728fff51", "parent_sha": "0d3cc25400c771d3f7f24ef8bb3e6d585852b5c6", "file_path": "flake8/util.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/flake8", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -49,8 +49,9 @@ def get_parser():\n \n def skip_warning(warning, ignore=[]):\n     # XXX quick dirty hack, just need to keep the line in the warning\n-    if not hasattr(warning, 'message'):\n+    if not hasattr(warning, 'message') or ignore is None:\n         # McCabe's warnings cannot be skipped afaik, and they're all strings.\n+        # And we'll get a TypeError otherwise\n         return False\n     if warning.message.split()[0] in ignore:\n         return True\n", "before": "if not hasattr ( warning , 'message' ) : return False", "after": "if not hasattr ( warning , 'message' ) or ignore is None : return False", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"not_operator\", 3, 8, 3, 39], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 39], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:ignore\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2]]"}
{"project": "bcbio-nextgen", "commit_sha": "7c9f2842aa24f3d7d49dc30c56d63be90f03504c", "parent_sha": "ba170ca42086f2dca7a5a912763fd35e99724bee", "file_path": "bcbio/install.py", "project_url": "https://github.com/tenxcloud/bcbio-nextgen", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -192,7 +192,7 @@ def add_install_defaults(args):\n     \"\"\"Add any saved installation defaults to the upgrade.\n     \"\"\"\n     install_config = _get_install_config()\n-    if install_config is None:\n+    if install_config is None or not utils.file_exists(install_config):\n         return args\n     with open(install_config) as in_handle:\n         default_args = yaml.load(in_handle)\n", "before": "if install_config is None : return args", "after": "if install_config is None or not utils . file_exists ( install_config ) : return args", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 4, 20], [\"boolean_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 30], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Insert\", \"N0\", [\"not_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"not:not\", \"T\"], 0], [\"Insert\", \"N1\", [\"call\", \"N2\"], 1], [\"Insert\", \"N2\", [\"attribute\", \"N3\"], 0], [\"Insert\", \"N2\", [\"argument_list\", \"N4\"], 1], [\"Insert\", \"N3\", [\"identifier:utils\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:file_exists\", \"T\"], 2], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"identifier:install_config\", \"T\"], 1], [\"Insert\", \"N4\", [\"):)\", \"T\"], 2]]"}
{"project": "HexViewer", "commit_sha": "67d0987b3d7ee0c54885e6d0bc418db802d8498c", "parent_sha": "1e17fc016d1794fa7ab079990fbb7ef65d52103d", "file_path": "hex_highlighter.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/HexViewer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -309,7 +309,7 @@ class HexHighlighterListenerCommand(sublime_plugin.EventListener):\n     def on_selection_modified(self, view):\r\n         \"\"\"Determine if a highlight should be triggered.\"\"\"\r\n \r\n-        if not common.is_enabled(view) or hh_thread.ignore_all:\r\n+        if hh_thread is None or not common.is_enabled(view) or hh_thread.ignore_all:\r\n             return\r\n         now = time()\r\n         if now - hh_thread.time > hh_thread.wait_time:\r\n", "before": "if not common . is_enabled ( view ) or hh_thread . ignore_all : return", "after": "if hh_thread is None or not common . is_enabled ( view ) or hh_thread . ignore_all : return", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 19], [\"boolean_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"not_operator\", 3, 12, 3, 63], 2], [\"Insert\", \"N1\", [\"identifier:hh_thread\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2]]"}
{"project": "django-hstore", "commit_sha": "8ea27bc787be337261562c04c2caecd5032ae771", "parent_sha": "1376a667d9a2baa0e383024c8dbaee59e924bade", "file_path": "django_hstore/forms.py", "project_url": "https://github.com/whyflyru/django-hstore", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -17,7 +17,7 @@ from . import utils\n def validate_hstore(value, is_serialized=False):\n     \"\"\" HSTORE validation. \"\"\"\n     # if empty\n-    if value == '' or value == 'null':\n+    if value is None or value == '' or value == 'null':\n         value = '{}'\n \n     # ensure valid JSON\n", "before": "if value == '' or value == 'null' : value = '{}'", "after": "if value is None or value == '' or value == 'null' : value = '{}'", "sstub_pattern": "LESS_SPECIFIC_IF", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 8, 3, 38], [\"boolean_operator\", \"N0\"], 0], [\"Insert\", \"N0\", [\"comparison_operator\", \"N1\"], 0], [\"Insert\", \"N0\", [\"or:or\", \"T\"], 1], [\"Move\", \"N0\", [\"comparison_operator\", 3, 8, 3, 19], 2], [\"Insert\", \"N1\", [\"identifier:value\", \"T\"], 0], [\"Insert\", \"N1\", [\"is:is\", \"T\"], 1], [\"Insert\", \"N1\", [\"none:None\", \"T\"], 2]]"}
{"project": "splinter", "commit_sha": "b42cc4c4b016367b53eb9e03bd148e27be8cc482", "parent_sha": "25c8cb8777f5864f0d0013ffbf8026f4501baba4", "file_path": "splinter/driver/zopetestbrowser.py", "project_url": "https://github.com/underdogio/splinter", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -170,7 +170,7 @@ class ZopeTestBrowser(DriverAPI):\n         for name, value in field_values.items():\n             element = self.find_by_name(name)\n             control = element.first._control\n-            if control.type in ['text', 'textarea']:\n+            if control.type in ['text', 'textarea', 'password']:\n                 control.value = value\n             elif control.type == 'checkbox':\n                 if value:\n", "before": "if control . type in [ 'text' , 'textarea' ] : control . value = value elif control . type == 'checkbox' : if value : ", "after": "if control . type in [ 'text' , 'textarea' , 'password' ] : control . value = value elif control . type == 'checkbox' : if value : ", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 32, 3, 52], [\",:,\", \"T\"], 4], [\"Insert\", [\"list\", 3, 32, 3, 52], [\"string:'password'\", \"T\"], 5]]"}
{"project": "pysolr", "commit_sha": "70c7da2136d8a91d60324f2037ffe5b48efd950f", "parent_sha": "5fe4c725698bf68446218f7f79c8c2e7869a1eb7", "file_path": "pysolr.py", "project_url": "https://github.com/acdha/pysolr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1307,7 +1307,7 @@ class SolrCoreAdmin(object):\n         if params is None:\n             params = {}\n         if headers is None:\n-            headers = {}\n+            headers = {'Content-Type': 'application/x-www-form-urlencoded'}\n \n         resp = requests.get(url, data=safe_urlencode(params), headers=headers)\n         return force_unicode(resp.content)\n", "before": "headers = { }", "after": "headers = { 'Content-Type' : 'application/x-www-form-urlencoded' }", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 23, 3, 25], [\"pair\", \"N0\"], 1], [\"Insert\", \"N0\", [\"string:'Content-Type'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'application/x-www-form-urlencoded'\", \"T\"], 2]]"}
{"project": "htcondenser", "commit_sha": "604e223970dd8711d03221c4b9965f0d0eb5507d", "parent_sha": "8ab8300c27ccc837d2ea7d04ac876360d7a6538f", "file_path": "htcondenser/core/job_classes.py", "project_url": "https://github.com/kreczko/htcondenser", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -308,7 +308,7 @@ class Job(object):\n-        job_args = []\n+        job_args = ['arguments=']\n \n         new_args = self.args[:]\n \n", "before": "job_args = [ ]", "after": "job_args = [ 'arguments=' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 0, 20, 0, 22], [\"string:'arguments='\", \"T\"], 1]]"}
{"project": "qal", "commit_sha": "254c2d7dd9080d0ef3645c5ee1c48f245ed643bd", "parent_sha": "179822ca32a9c8d4329a1a14e96f4cc21fb8b1e3", "file_path": "qal/sql/types.py", "project_url": "https://github.com/OptimalBPM/qal", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -63,7 +63,7 @@ def set_operator():\n \n def join_types():\n     \"\"\"Returns a list of the supported join types\"\"\"\n-    return ['INNER', 'LEFT OUTER', 'RIGHT OUTER', 'FULL OUTER', 'CROSS']\n+    return ['', 'INNER', 'LEFT OUTER', 'RIGHT OUTER', 'FULL OUTER', 'CROSS']\n \n \n def expression_item_types():\n", "before": "return [ 'INNER' , 'LEFT OUTER' , 'RIGHT OUTER' , 'FULL OUTER' , 'CROSS' ]", "after": "return [ '' , 'INNER' , 'LEFT OUTER' , 'RIGHT OUTER' , 'FULL OUTER' , 'CROSS' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 12, 3, 73], [\"string:''\", \"T\"], 1], [\"Insert\", [\"list\", 3, 12, 3, 73], [\",:,\", \"T\"], 2]]"}
{"project": "qal", "commit_sha": "170a65f95d6cc7e810ad18b1b87a7a94bd30c368", "parent_sha": "2caee692bf76e0cf32a94de77b05291296320d23", "file_path": "qal/common/resources.py", "project_url": "https://github.com/OptimalBPM/qal", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,7 +14,8 @@ from qal import __version__\n \n def resource_types():\n     \"\"\"Returns a list of the QAL-supported resource types\"\"\"\n-    return [\"CUSTOM\", \"FLATFILE\", \"MATRIX\", \"XPATH\", \"RDBMS\"]\n+    return [\"CUSTOM\", \"FLATFILE\", \"MATRIX\", \"XPATH\", \"RDBMS\", \"SPREADSHEET\"]\n+    # TODO: See to it that spreadsheets are added as resource types everywhere\n \n def generate_schema():\n     \"\"\"Generates an JSON schema based on the class structure in SQL.py\"\"\"\n", "before": "return [ \"CUSTOM\" , \"FLATFILE\" , \"MATRIX\" , \"XPATH\" , \"RDBMS\" ]", "after": "return [ \"CUSTOM\" , \"FLATFILE\" , \"MATRIX\" , \"XPATH\" , \"RDBMS\" , \"SPREADSHEET\" ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 12, 3, 62], [\",:,\", \"T\"], 10], [\"Insert\", [\"list\", 3, 12, 3, 62], [\"string:\\\"SPREADSHEET\\\"\", \"T\"], 11]]"}
{"project": "mdtraj", "commit_sha": "3550aaeade748a366b16984bc4c78e5d84036151", "parent_sha": "4d6f29ed53df2f8c2512c983d12f4da28d00d081", "file_path": "mdtraj/formats/mol2.py", "project_url": "https://github.com/Eigenstate/mdtraj", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -170,7 +170,7 @@ def mol2_to_dataframes(filename):\n     csv.seek(0)\n     atoms_frame = pd.read_csv(csv, sep=\"\\s*\", engine='python',  header=None,\n         names=[\"serial\", \"name\", \"x\", \"y\", \"z\",\n-               \"atype\", \"code\", \"resName\", \"charge\"])\n+               \"atype\", \"code\", \"resName\", \"charge\", \"status\"])\n     return atoms_frame, bonds_frame\n \n \n", "before": "atoms_frame = pd . read_csv ( csv , sep = \"\\s*\" , engine = 'python' , header = None , names = [ \"serial\" , \"name\" , \"x\" , \"y\" , \"z\" , \"atype\" , \"code\" , \"resName\" , \"charge\" ] )", "after": "atoms_frame = pd . read_csv ( csv , sep = \"\\s*\" , engine = 'python' , header = None , names = [ \"serial\" , \"name\" , \"x\" , \"y\" , \"z\" , \"atype\" , \"code\" , \"resName\" , \"charge\" , \"status\" ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\",:,\", 2, 24, 2, 25], [\"list\", 2, 15, 3, 53], 13], [\"Insert\", [\"list\", 2, 15, 3, 53], [\",:,\", \"T\"], 2], [\"Insert\", [\"list\", 2, 15, 3, 53], [\",:,\", \"T\"], 19], [\"Insert\", [\"list\", 2, 15, 3, 53], [\"string:\\\"status\\\"\", \"T\"], 20], [\"Delete\", [\",:,\", 3, 31, 3, 32]]]"}
{"project": "rq", "commit_sha": "0ddd1748682bc6f6193c9ef1be33a83c9c02c08b", "parent_sha": "8782b11f1e78453d84c5d03e9c7cbce04355a1c5", "file_path": "tests/test_scripts.py", "project_url": "https://github.com/dronedeploy/rq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -47,7 +47,7 @@ class TestRQCli(RQTestCase):\n     def test_requeue(self):\n         \"\"\"rq -u <url> requeue\"\"\"\n         runner = CliRunner()\n-        result = runner.invoke(rq_cli.main, ['-u', self.redis_url, 'requeue'])\n+        result = runner.invoke(rq_cli.main, ['-u', self.redis_url, 'requeue', '-a'])\n         self.assertEqual(result.exit_code, 0)\n         self.assertIn('Requeueing 1 jobs from FailedQueue', result.output)\n         self.assertIn('Unable to requeue 0 jobs from FailedQueue',\n", "before": "result = runner . invoke ( rq_cli . main , [ '-u' , self . redis_url , 'requeue' ] )", "after": "result = runner . invoke ( rq_cli . main , [ '-u' , self . redis_url , 'requeue' , '-a' ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 45, 3, 78], [\",:,\", \"T\"], 6], [\"Insert\", [\"list\", 3, 45, 3, 78], [\"string:'-a'\", \"T\"], 7]]"}
{"project": "ansible-bender", "commit_sha": "2163353896a59ee4636fbb49a7a75b9e3eafaab1", "parent_sha": "a04a4a2fa5dc5b477aeaa7c25ea1efd50d070465", "file_path": "ansible_bender/builders/buildah_builder.py", "project_url": "https://github.com/TomasTomecek/ansible-bender", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ def get_buildah_image_id(container_image):\n \n \n def pull_buildah_image(container_image):\n-    run_cmd([\"buildah\", \"pull\", container_image],\n+    run_cmd([\"buildah\", \"pull\", \"--quiet\", container_image],\n             save_output_in_exc=False,\n             log_stderr=False, print_output=True, log_output=False)\n \n", "before": "run_cmd ( [ \"buildah\" , \"pull\" , container_image ] , save_output_in_exc = False , log_stderr = False , print_output = True , log_output = False )", "after": "run_cmd ( [ \"buildah\" , \"pull\" , \"--quiet\" , container_image ] , save_output_in_exc = False , log_stderr = False , print_output = True , log_output = False )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 13, 3, 49], [\"string:\\\"--quiet\\\"\", \"T\"], 5], [\"Insert\", [\"list\", 3, 13, 3, 49], [\",:,\", \"T\"], 6]]"}
{"project": "openshift-components", "commit_sha": "909d132cc488a2e06336038d4a087ba4b87e398e", "parent_sha": "4a20da67281d85d1a0406f7294bc65eda397b8e5", "file_path": "apps/taiga/back/django/taiga/taiga_contrib_github_extended_auth/services.py", "project_url": "https://github.com/BCDevOps/openshift-components", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ def check_org_membership(github_id, org, headers:dict=connector.HEADERS):\n     logger.debug(\"Headers: {0}\".format(headers))\n \n     response = requests.get(url, headers=headers)\n-    if response.status_code not in [302]:\n+    if response.status_code not in [204, 302]:\n         logger.debug(\"User was not a member of GitHub organization {0}.Status was {1}\".format(org, response.status_code))\n         return False\n     else:\n", "before": "if response . status_code not in [ 302 ] : logger . debug ( \"User was not a member of GitHub organization {0}.Status was {1}\" . format ( org , response . status_code ) ) return False else : ", "after": "if response . status_code not in [ 204 , 302 ] : logger . debug ( \"User was not a member of GitHub organization {0}.Status was {1}\" . format ( org , response . status_code ) ) return False else : ", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 36, 3, 41], [\"integer:204\", \"T\"], 1], [\"Insert\", [\"list\", 3, 36, 3, 41], [\",:,\", \"T\"], 2]]"}
{"project": "angr", "commit_sha": "a01caa808eb1b78418b4ffb7ed60643e86a44d39", "parent_sha": "e523352ba6630e320fea4e79ed9394c6a14daa7c", "file_path": "angr/path.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -45,7 +45,7 @@ class Path(object):\n             # case. We should catch exceptions here.\n             try:\n                 stack_ptr = self.state.se.any_int(self.state.regs.sp)\n-            except (simuvex.SimSolverModeError, simuvex.SimUnsatError):\n+            except (simuvex.SimSolverModeError, simuvex.SimUnsatError, AttributeError):\n                 stack_ptr = None\n \n             # generate a base callframe\n", "before": "try : stack_ptr = self . state . se . any_int ( self . state . regs . sp ) except ( simuvex . SimSolverModeError , simuvex . SimUnsatError ) : stack_ptr = None", "after": "try : stack_ptr = self . state . se . any_int ( self . state . regs . sp ) except ( simuvex . SimSolverModeError , simuvex . SimUnsatError , AttributeError ) : stack_ptr = None", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 20, 3, 71], [\",:,\", \"T\"], 4], [\"Insert\", [\"tuple\", 3, 20, 3, 71], [\"identifier:AttributeError\", \"T\"], 5]]"}
{"project": "echronos-sandbox", "commit_sha": "534207dc92d847b1c8c71496308952062f1d285f", "parent_sha": "893acd45048fe848a86c7d6c3366da0f1168ae8c", "file_path": "prj/app/prj.py", "project_url": "https://github.com/schnommus/echronos-sandbox", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -806,7 +806,7 @@ might not be available on the PATH search path for executables.\")\n \n         include_path_options = ['-I{}'.format(include_path) for include_path in self.include_paths]\n         for c_file in self.c_files:\n-            subprocess.check_call([\"splint\"] + include_path_options + [c_file])\n+            subprocess.check_call([\"splint\", \"+quiet\"] + include_path_options + [c_file])\n \n     def _run_action(self, typ):\n         try:\n", "before": "subprocess . check_call ( [ \"splint\" ] + include_path_options + [ c_file ] )", "after": "subprocess . check_call ( [ \"splint\" , \"+quiet\" ] + include_path_options + [ c_file ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 35, 3, 45], [\",:,\", \"T\"], 2], [\"Insert\", [\"list\", 3, 35, 3, 45], [\"string:\\\"+quiet\\\"\", \"T\"], 3]]"}
{"project": "python_planet", "commit_sha": "732563e2e024cc08e446ed9bc9e184327c94f7db", "parent_sha": "b660fe0fac9169bd876f63a75ca09a8ebe114781", "file_path": "planet/control/CFile.py", "project_url": "https://github.com/haobin12358/python_planet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -176,7 +176,7 @@ class CFile(object):\n     def allowed_folder(folder):\n         return folder if folder in ['index', 'product', 'temp', 'item', 'news', 'category', 'video', 'avatar',\n                                     'voucher', 'idcard', 'brand', 'activity', 'contract', 'play',\n-                                    'scenicspot', 'raiders', 'travels', 'essay'] else 'temp'\n+                                    'scenicspot', 'raiders', 'travels', 'essay', 'feedback', 'ticket'] else 'temp'\n \n     def new_name(self, shuffix):\n         import string\n", "before": "return folder if folder in [ 'index' , 'product' , 'temp' , 'item' , 'news' , 'category' , 'video' , 'avatar' , 'voucher' , 'idcard' , 'brand' , 'activity' , 'contract' , 'play' , 'scenicspot' , 'raiders' , 'travels' , 'essay' ] else 'temp'", "after": "return folder if folder in [ 'index' , 'product' , 'temp' , 'item' , 'news' , 'category' , 'video' , 'avatar' , 'voucher' , 'idcard' , 'brand' , 'activity' , 'contract' , 'play' , 'scenicspot' , 'raiders' , 'travels' , 'essay' , 'feedback' , 'ticket' ] else 'temp'", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\",:,\", 1, 44, 1, 45], [\"list\", 1, 36, 3, 81], 35], [\"Insert\", [\"list\", 1, 36, 3, 81], [\",:,\", \"T\"], 2], [\"Insert\", [\"list\", 1, 36, 3, 81], [\"string:'feedback'\", \"T\"], 4], [\"Insert\", [\"list\", 1, 36, 3, 81], [\",:,\", \"T\"], 5], [\"Insert\", [\"list\", 1, 36, 3, 81], [\"string:'ticket'\", \"T\"], 6]]"}
{"project": "PokeAlarm", "commit_sha": "71c4e55eaaf2136ffc0f4cede8ba16a695f6eef6", "parent_sha": "6d0e2c192866b033148405dfcdf34667357191ce", "file_path": "PokeAlarm/Manager.py", "project_url": "https://github.com/tallypokemap/PokeAlarm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -659,7 +659,7 @@ class Manager(object):\n     # Returns true if string contains an argument that requires\n     def set_optional_args(self, line):\n         # Reverse Location\n-        args = {'address', 'postal', 'neighborhood', 'sublocality', 'city', 'county', 'state', 'country'}\n+        args = {'street', 'street_num', 'address', 'postal', 'neighborhood', 'sublocality', 'city', 'county', 'state', 'country'}\n         self.__api_req['REVERSE_LOCATION'] = self.__api_req['REVERSE_LOCATION'] or contains_arg(line, args)\n         log.debug(\"REVERSE_LOCATION set to %s\" % self.__api_req['REVERSE_LOCATION'])\n \n", "before": "args = { 'address' , 'postal' , 'neighborhood' , 'sublocality' , 'city' , 'county' , 'state' , 'country' }", "after": "args = { 'street' , 'street_num' , 'address' , 'postal' , 'neighborhood' , 'sublocality' , 'city' , 'county' , 'state' , 'country' }", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\"string:'address'\", 3, 17, 3, 26], [\"set\", 3, 16, 3, 106], 3], [\"Move\", [\"string:'postal'\", 3, 28, 3, 36], [\"set\", 3, 16, 3, 106], 6], [\"Move\", [\"string:'neighborhood'\", 3, 38, 3, 52], [\"set\", 3, 16, 3, 106], 8], [\"Move\", [\"string:'sublocality'\", 3, 54, 3, 67], [\"set\", 3, 16, 3, 106], 10], [\"Move\", [\"string:'city'\", 3, 69, 3, 75], [\"set\", 3, 16, 3, 106], 6], [\"Move\", [\",:,\", 3, 94, 3, 95], [\"set\", 3, 16, 3, 106], 7], [\"Insert\", [\"set\", 3, 16, 3, 106], [\"string:'street'\", \"T\"], 1], [\"Insert\", [\"set\", 3, 16, 3, 106], [\"string:'street_num'\", \"T\"], 4], [\"Insert\", [\"set\", 3, 16, 3, 106], [\",:,\", \"T\"], 13], [\"Insert\", [\"set\", 3, 16, 3, 106], [\",:,\", \"T\"], 18]]"}
{"project": "ykdl", "commit_sha": "02e1d3fe81b532eada39101465de1e4ab0542001", "parent_sha": "609d6e70d79c0b7b2ca247467da480927ca9e6e6", "file_path": "src/you_get/downloader/bilibili.py", "project_url": "https://github.com/YU-zreo/ykdl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -83,7 +83,7 @@ def bilibili_download(url, output_dir = '.', merge = True, info_only = False):\n     title = unescape_html(title)\n     title = escape_file_path(title)\n     \n-    flashvars = r1_of([r'flashvars=\"([^\"]+)\"', r'\"https://secure.bilibili.tv/secure,(cid=\\d+)(?:&aid=\\d+)?\"'], html)\n+    flashvars = r1_of([r'player_params=\\'(cid=\\d+)', r'flashvars=\"([^\"]+)\"', r'\"https://secure.bilibili.tv/secure,(cid=\\d+)(?:&aid=\\d+)?\"'], html)\n     assert flashvars\n     t, id = flashvars.split('=', 1)\n     id = id.split('&')[0]\n", "before": "flashvars = r1_of ( [ r'flashvars=\"([^\"]+)\"' , r'\"https://secure.bilibili.tv/secure,(cid=\\d+)(?:&aid=\\d+)?\"' ] , html )", "after": "flashvars = r1_of ( [ r'player_params=\\'(cid=\\d+)' , r'flashvars=\"([^\"]+)\"' , r'\"https://secure.bilibili.tv/secure,(cid=\\d+)(?:&aid=\\d+)?\"' ] , html )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\"string:r'flashvars=\\\"([^\\\"]+)\\\"'\", 3, 24, 3, 46], [\"list\", 3, 23, 3, 110], 2], [\"Insert\", [\"list\", 3, 23, 3, 110], [\"string:r'player_params=\\\\'(cid=\\\\d+)'\", \"T\"], 1], [\"Insert\", [\"list\", 3, 23, 3, 110], [\",:,\", \"T\"], 3]]"}
{"project": "weblyzard_api", "commit_sha": "c5134e82841de6debb2c7b72c30032e5a868d3cf", "parent_sha": "31dee35d128a7edc935be16919a357c653aaae65", "file_path": "src/weblyzard_api/xml_content/parsers/json_10.py", "project_url": "https://github.com/weblyzard/weblyzard_api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -159,7 +159,7 @@ class JSON10ParserXMLContent(JSONParserBase):\n         xml_content = XMLContent(xml_content=None, remove_duplicates=True)\n         # add all items in api_dict unless they need special handling\n         xml_content.update_attributes({key:value for key, value in api_dict.iteritems() if \n-                                       key not in ('sentences', 'annotations', 'language_id')})\n+                                       key not in ('sentences', 'annotations', 'language_id', 'title')})\n         sentences = [JSON10ParserSentence.from_api_dict(sentence_dict) for \n                      sentence_dict in api_dict.get('sentences', [])]\n         annotations = [JSON10ParserAnnotation.from_api_dict(annotation_dict) for \n", "before": "xml_content . update_attributes ( { key : value for key , value in api_dict . iteritems ( ) if key not in ( 'sentences' , 'annotations' , 'language_id' ) } )", "after": "xml_content . update_attributes ( { key : value for key , value in api_dict . iteritems ( ) if key not in ( 'sentences' , 'annotations' , 'language_id' , 'title' ) } )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 51, 3, 94], [\",:,\", \"T\"], 6], [\"Insert\", [\"tuple\", 3, 51, 3, 94], [\"string:'title'\", \"T\"], 7]]"}
{"project": "weblyzard_api", "commit_sha": "666c850a1eae6895961ed68a1cb781b892dedbb4", "parent_sha": "c75f6e5071b6228a1c281701f26f901c8afdc15e", "file_path": "src/weblyzard_api/xml_content/parsers/json_10.py", "project_url": "https://github.com/weblyzard/weblyzard_api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -159,7 +159,7 @@ class JSON10ParserXMLContent(JSONParserBase):\n         xml_content = XMLContent(xml_content=None, remove_duplicates=True)\n         # add all items in api_dict unless they need special handling\n         xml_content.update_attributes({key:value for key, value in api_dict.iteritems() if \n-                                       key not in ('sentences', 'annotations', 'language_id')})\n+                                       key not in ('sentences', 'annotations', 'language_id', 'title')})\n         sentences = [JSON10ParserSentence.from_api_dict(sentence_dict) for \n                      sentence_dict in api_dict.get('sentences', [])]\n         annotations = [JSON10ParserAnnotation.from_api_dict(annotation_dict) for \n", "before": "xml_content . update_attributes ( { key : value for key , value in api_dict . iteritems ( ) if key not in ( 'sentences' , 'annotations' , 'language_id' ) } )", "after": "xml_content . update_attributes ( { key : value for key , value in api_dict . iteritems ( ) if key not in ( 'sentences' , 'annotations' , 'language_id' , 'title' ) } )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 51, 3, 94], [\",:,\", \"T\"], 6], [\"Insert\", [\"tuple\", 3, 51, 3, 94], [\"string:'title'\", \"T\"], 7]]"}
{"project": "CRE-NS3", "commit_sha": "f0d34acab9d99e34c0a8738887b6ffa1a526c89b", "parent_sha": "5760506b54eef4a96627a28814e18b1f5ad83fff", "file_path": "bindings/python/ns3modulegen.py", "project_url": "https://github.com/abdulla-alali/CRE-NS3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -46,7 +46,7 @@ class MyMultiSectionFactory(MultiSectionFactory):\n         self.header_name = \"ns3module.h\"\n         header_file_name = os.path.join(os.path.dirname(self.main_file_name), self.header_name)\n         self.header_sink = FileCodeSink(open(header_file_name, \"wt\"))\n-        self.section_sinks = {}\n+        self.section_sinks = {'__main__': self.main_sink}\n \n         for module in modules:\n             section_name = 'ns3_module_%s' % module.replace('-', '_')\n", "before": "self . section_sinks = { }", "after": "self . section_sinks = { '__main__' : self . main_sink }", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 30, 3, 32], [\"pair\", \"N0\"], 1], [\"Insert\", \"N0\", [\"string:'__main__'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:main_sink\", \"T\"], 2]]"}
{"project": "taskgrader", "commit_sha": "e22e278c124a9e1f43e7203c4af95c612229af5d", "parent_sha": "b577ba088bfafc08cbbdf3a091e654826e6e7a8b", "file_path": "tools/taskstarter/taskstarter.py", "project_url": "https://github.com/France-ioi/taskgrader", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -114,7 +114,7 @@ def checkEditMe(path):\n def checkSvn(path):\n     \"\"\"Check, if the folder is versioned with SVN, that all files have been\n     committed.\"\"\"\n-    proc = subprocess.Popen(['/usr/bin/svn', 'status'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n+    proc = subprocess.Popen(['/usr/bin/svn', 'status', path], stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n     procOut, procErr = proc.communicate()\n \n     warningDisplayed = False\n", "before": "proc = subprocess . Popen ( [ '/usr/bin/svn' , 'status' ] , stdout = subprocess . PIPE , stderr = subprocess . PIPE , universal_newlines = True )", "after": "proc = subprocess . Popen ( [ '/usr/bin/svn' , 'status' , path ] , stdout = subprocess . PIPE , stderr = subprocess . PIPE , universal_newlines = True )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 29, 3, 55], [\",:,\", \"T\"], 4], [\"Insert\", [\"list\", 3, 29, 3, 55], [\"identifier:path\", \"T\"], 5]]"}
{"project": "pants", "commit_sha": "6f8888fcd4d6e1b6330eb8f6196bd1cb65fcda12", "parent_sha": "401d456f5ebcc7671a324b9f2bcc7cb291ac0148", "file_path": "src/python/pants/backend/codegen/tasks/code_gen.py", "project_url": "https://github.com/square/pants", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -21,7 +21,7 @@ class CodeGen(Task):\n \n   @classmethod\n   def product_types(cls):\n-    return ['java', 'scala']\n+    return ['java', 'scala', 'python']\n \n   def is_gentarget(self, target):\n     \"\"\"Subclass must return True if it handles generating for the target.\"\"\"\n", "before": "return [ 'java' , 'scala' ]", "after": "return [ 'java' , 'scala' , 'python' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 12, 3, 29], [\",:,\", \"T\"], 4], [\"Insert\", [\"list\", 3, 12, 3, 29], [\"string:'python'\", \"T\"], 5]]"}
{"project": "rmtest", "commit_sha": "eb565479ec9f21d4cebf941c91753d9eadf492d9", "parent_sha": "c5cdbdbbfc362e7c8ba6ccb1bf27d19e4ac2ceb8", "file_path": "test.py", "project_url": "https://github.com/RedisLabs/rmtest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -12,7 +12,7 @@ MODULE_PATH = os.path.abspath(os.path.dirname(__file__)) + '/' + 'module.so'\n \n def build_module():\n     csrc = MODULE_PATH[0:-3] + '.c'\n-    po = Popen(['cc', '-o', MODULE_PATH, '-shared', csrc])\n+    po = Popen(['cc', '-o', MODULE_PATH, '-shared', '-fPIC', csrc])\n     po.communicate()\n     if po.returncode != 0:\n", "before": "po = Popen ( [ 'cc' , '-o' , MODULE_PATH , '-shared' , csrc ] )", "after": "po = Popen ( [ 'cc' , '-o' , MODULE_PATH , '-shared' , '-fPIC' , csrc ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 16, 3, 58], [\"string:'-fPIC'\", \"T\"], 9], [\"Insert\", [\"list\", 3, 16, 3, 58], [\",:,\", \"T\"], 10]]"}
{"project": "SymPortal_framework", "commit_sha": "845e3b7d8f19cde823bc3a80039b2bb5ba774cd4", "parent_sha": "a75521d03271d39cb436e1ec7ebd448d84eb1142", "file_path": "tests/tests.py", "project_url": "https://github.com/SymPortal/SymPortal_framework", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ class SymPortalTester:\n \n     def _test_data_loading_work_flow(self):\n         custom_args_list = ['--load', self.test_data_dir_path, '--name', self.name, '--num_proc', str(self.num_proc), '--data_sheet',\n-             self.data_sheet_file_path]\n+             self.data_sheet_file_path, '--debug']\n         self.work_flow_manager = main.SymPortalWorkFlowManager(custom_args_list)\n         self.work_flow_manager.start_work_flow()\n \n", "before": "custom_args_list = [ '--load' , self . test_data_dir_path , '--name' , self . name , '--num_proc' , str ( self . num_proc ) , '--data_sheet' , self . data_sheet_file_path ]", "after": "custom_args_list = [ '--load' , self . test_data_dir_path , '--name' , self . name , '--num_proc' , str ( self . num_proc ) , '--data_sheet' , self . data_sheet_file_path , '--debug' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 2, 28, 3, 40], [\",:,\", \"T\"], 16], [\"Insert\", [\"list\", 2, 28, 3, 40], [\"string:'--debug'\", \"T\"], 17]]"}
{"project": "urdfpy", "commit_sha": "08ff7bb8311e7a23bb93c75446d908af62844375", "parent_sha": "53bb0d4775cf275193513499a9bb1332d6991281", "file_path": "urdfpy/urdf.py", "project_url": "https://github.com/mmatl/urdfpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -556,7 +556,7 @@ class Mesh(URDFType):\n     def meshes(self, value):\n         if isinstance(value, six.string_types):\n             value = load_meshes(value)\n-        elif isinstance(value, (list, tuple, set)):\n+        elif isinstance(value, (list, tuple, set, np.ndarray)):\n             value = list(value)\n             if len(value) == 0:\n                 raise ValueError('Mesh must have at least one trimesh.Trimesh')\n", "before": "if isinstance ( value , six . string_types ) : value = load_meshes ( value ) elif isinstance ( value , ( list , tuple , set ) ) : value = list ( value ) if len ( value ) == 0 : raise ValueError ( 'Mesh must have at least one trimesh.Trimesh' )", "after": "if isinstance ( value , six . string_types ) : value = load_meshes ( value ) elif isinstance ( value , ( list , tuple , set , np . ndarray ) ) : value = list ( value ) if len ( value ) == 0 : raise ValueError ( 'Mesh must have at least one trimesh.Trimesh' )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 32, 3, 50], [\",:,\", \"T\"], 6], [\"Insert\", [\"tuple\", 3, 32, 3, 50], [\"attribute\", \"N0\"], 7], [\"Insert\", \"N0\", [\"identifier:np\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:ndarray\", \"T\"], 2]]"}
{"project": "odoo-celery", "commit_sha": "06bc6080ca20868ed2077df5c5329db3d8ec0a73", "parent_sha": "2ed4c9993fd64671e36b7a47976dda5abad08b49", "file_path": "celery/models/celery_task.py", "project_url": "https://github.com/novacode-nl/odoo-celery", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -347,7 +347,7 @@ class CeleryTask(models.Model):\n             return (TASK_NOT_FOUND, msg)\n \n         model_obj = self.env[model]\n-        task = self.search([('uuid', '=', task_uuid), ('state', 'in', [STATE_PENDING, STATE_RETRY])], limit=1)\n+        task = self.search([('uuid', '=', task_uuid), ('state', 'in', [STATE_PENDING, STATE_RETRY, STATE_SCHEDULED])], limit=1)\n \n         if not task:\n             return ('OK', 'Task already processed')\n", "before": "task = self . search ( [ ( 'uuid' , '=' , task_uuid ) , ( 'state' , 'in' , [ STATE_PENDING , STATE_RETRY ] ) ] , limit = 1 )", "after": "task = self . search ( [ ( 'uuid' , '=' , task_uuid ) , ( 'state' , 'in' , [ STATE_PENDING , STATE_RETRY , STATE_SCHEDULED ] ) ] , limit = 1 )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 71, 3, 99], [\",:,\", \"T\"], 4], [\"Insert\", [\"list\", 3, 71, 3, 99], [\"identifier:STATE_SCHEDULED\", \"T\"], 5]]"}
{"project": "udapi-python", "commit_sha": "9e97a2751979c2cc59c2fda8c2f526b86c3dbb84", "parent_sha": "f21be2aa1c1c3f65ab36dc0bcda4f95549ea8db4", "file_path": "udapi/block/ud/google2ud.py", "project_url": "https://github.com/udapi/udapi-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -138,7 +138,7 @@ class Google2ud(Convert1to2):\n             self._fixpunct_block = FixPunct()\n \n         self._fixchain_block = None\n-        if lang in {'pt'}:\n+        if lang in {'pt', 'ru'}:\n             self._fixchain_block = FixChain()\n \n         # UD_English v2.0 still uses \"do n't\" with SpaceAfter=No,\n", "before": "if lang in { 'pt' } : self . _fixchain_block = FixChain ( )", "after": "if lang in { 'pt' , 'ru' } : self . _fixchain_block = FixChain ( )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"set\", 3, 20, 3, 26], [\",:,\", \"T\"], 2], [\"Insert\", [\"set\", 3, 20, 3, 26], [\"string:'ru'\", \"T\"], 3]]"}
{"project": "udapi-python", "commit_sha": "49e94345d6ab84d36478d687262906cf0672513c", "parent_sha": "67b303d666f93c87e3bbbbeb491b681f0ed829f9", "file_path": "udapi/core/coref.py", "project_url": "https://github.com/udapi/udapi-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -303,7 +303,7 @@ def load_coref_from_misc(doc):\n def store_coref_to_misc(doc):\n     if not doc._coref_clusters:\n         return\n-    attrs = (\"ClusterId\", \"MentionSpan\", \"ClusterType\", \"Bridging\", \"SplitAnte\")\n+    attrs = (\"ClusterId\", \"MentionSpan\", \"ClusterType\", \"Bridging\", \"SplitAnte\", \"MentionMisc\")\n     for node in doc.nodes_and_empty:\n         for key in list(node.misc):\n             if any(re.match(attr + r'(\\[\\d+\\])?$', key) for attr in attrs):\n", "before": "attrs = ( \"ClusterId\" , \"MentionSpan\" , \"ClusterType\" , \"Bridging\" , \"SplitAnte\" )", "after": "attrs = ( \"ClusterId\" , \"MentionSpan\" , \"ClusterType\" , \"Bridging\" , \"SplitAnte\" , \"MentionMisc\" )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 13, 3, 81], [\",:,\", \"T\"], 10], [\"Insert\", [\"tuple\", 3, 13, 3, 81], [\"string:\\\"MentionMisc\\\"\", \"T\"], 11]]"}
{"project": "python-utils", "commit_sha": "c2d7faf6e5cf2eb3224249cf44e5d2d2e3c0c609", "parent_sha": "17b5a9973fe7488d587ae61166b6cae7f54d4453", "file_path": "ffmpeg.py", "project_url": "https://github.com/kylemcdonald/python-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -130,7 +130,7 @@ def vidread(fn, samples=None, rate=None, hwaccel=None):\n         if stream['codec_type'] == 'video':\n             width, height = stream['width'], stream['height']\n             try:\n-                if stream['tags']['rotate'] in ['90','-90']:\n+                if stream['tags']['rotate'] in ['90','270','-90']: # not sure if -90 ever happens\n                     width, height = height, width\n             except KeyError:\n                 pass\n", "before": "if stream [ 'tags' ] [ 'rotate' ] in [ '90' , '-90' ] : width , height = height , width", "after": "if stream [ 'tags' ] [ 'rotate' ] in [ '90' , '270' , '-90' ] : width , height = height , width", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 48, 3, 60], [\"string:'270'\", \"T\"], 3], [\"Insert\", [\"list\", 3, 48, 3, 60], [\",:,\", \"T\"], 4]]"}
{"project": "erpnext-v7", "commit_sha": "6207883b7c6313b666dfbb64cf2a4bad2999c9a6", "parent_sha": "04a64a7f489a28d19c63506e05a703940a11a8e5", "file_path": "erpnext/patches/v7_0/migrate_schools_to_erpnext.py", "project_url": "https://github.com/YefriTavarez/erpnext-v7", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,5 +28,5 @@ def execute():\n \n def reload_doctypes_for_schools_icons():\n \tfor name in ('student', 'student_group', 'course_schedule', 'student_attendance',\n-\t\t'course', 'program', 'student_applicant', 'examination', 'fees', 'instructor'):\n+\t\t'course', 'program', 'student_applicant', 'examination', 'fees', 'instructor', 'announcement'):\n \t\tfrappe.reload_doc('schools', 'doctype', name)\n", "before": "for name in ( 'student' , 'student_group' , 'course_schedule' , 'student_attendance' , 'course' , 'program' , 'student_applicant' , 'examination' , 'fees' , 'instructor' ) : frappe . reload_doc ( 'schools' , 'doctype' , name )", "after": "for name in ( 'student' , 'student_group' , 'course_schedule' , 'student_attendance' , 'course' , 'program' , 'student_applicant' , 'examination' , 'fees' , 'instructor' , 'announcement' ) : frappe . reload_doc ( 'schools' , 'doctype' , name )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\",:,\", 2, 24, 2, 25], [\"tuple\", 2, 14, 3, 81], 15], [\"Insert\", [\"tuple\", 2, 14, 3, 81], [\",:,\", \"T\"], 2], [\"Insert\", [\"tuple\", 2, 14, 3, 81], [\",:,\", \"T\"], 21], [\"Insert\", [\"tuple\", 2, 14, 3, 81], [\"string:'announcement'\", \"T\"], 22], [\"Delete\", [\",:,\", 3, 58, 3, 59]]]"}
{"project": "depot_tools", "commit_sha": "b460ebe72348da309ae98e54acf55d4311db594c", "parent_sha": "4a56efe4a5519398db92b1ae2d1b04969b7959f2", "file_path": "win_toolchain/get_toolchain_if_necessary.py", "project_url": "https://github.com/Neozaru/depot_tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -121,7 +121,7 @@ def HaveSrcInternalAccess():\n   \"\"\"Checks whether access to src-internal is available.\"\"\"\n   with open(os.devnull, 'w') as nul:\n     if subprocess.call(\n-        ['svn', 'ls',\n+        ['svn', 'ls', '--non-interactive',\n          'svn://svn.chromium.org/chrome-internal/trunk/src-internal/'],\n         shell=True, stdin=nul, stdout=nul, stderr=nul) == 0:\n       return True\n", "before": "if subprocess . call ( [ 'svn' , 'ls' , 'svn://svn.chromium.org/chrome-internal/trunk/src-internal/' ] , shell = True , stdin = nul , stdout = nul , stderr = nul ) == 0 : return True", "after": "if subprocess . call ( [ 'svn' , 'ls' , '--non-interactive' , 'svn://svn.chromium.org/chrome-internal/trunk/src-internal/' ] , shell = True , stdin = nul , stdout = nul , stderr = nul ) == 0 : return True", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 9, 4, 71], [\"string:'--non-interactive'\", \"T\"], 5], [\"Insert\", [\"list\", 3, 9, 4, 71], [\",:,\", \"T\"], 6]]"}
{"project": "depot_tools", "commit_sha": "bd4dafb96359ea61bb603e41b5bcbcdc84d56977", "parent_sha": "6c2b49d392239a7d7ad1499bb43ecd049543359b", "file_path": "win_toolchain/get_toolchain_if_necessary.py", "project_url": "https://github.com/Neozaru/depot_tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -126,7 +126,7 @@ def HaveSrcInternalAccess():\n         shell=True, stdin=nul, stdout=nul, stderr=nul) == 0:\n       return True\n     return subprocess.call(\n-        ['git', 'remote', 'show',\n+        ['git', '-c', 'core.askpass=true', 'remote', 'show',\n          'https://chrome-internal.googlesource.com/chrome/src-internal/'],\n         shell=True, stdin=nul, stdout=nul, stderr=nul) == 0\n \n", "before": "return subprocess . call ( [ 'git' , 'remote' , 'show' , 'https://chrome-internal.googlesource.com/chrome/src-internal/' ] , shell = True , stdin = nul , stdout = nul , stderr = nul ) == 0", "after": "return subprocess . call ( [ 'git' , '-c' , 'core.askpass=true' , 'remote' , 'show' , 'https://chrome-internal.googlesource.com/chrome/src-internal/' ] , shell = True , stdin = nul , stdout = nul , stderr = nul ) == 0", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\"string:'remote'\", 3, 17, 3, 25], [\"list\", 3, 9, 4, 74], 5], [\"Move\", [\"string:'show'\", 3, 27, 3, 33], [\"list\", 3, 9, 4, 74], 4], [\"Insert\", [\"list\", 3, 9, 4, 74], [\"string:'-c'\", \"T\"], 3], [\"Insert\", [\"list\", 3, 9, 4, 74], [\"string:'core.askpass=true'\", \"T\"], 6], [\"Insert\", [\"list\", 3, 9, 4, 74], [\",:,\", \"T\"], 5], [\"Insert\", [\"list\", 3, 9, 4, 74], [\",:,\", \"T\"], 10]]"}
{"project": "depot_tools", "commit_sha": "cfa516f8a31d763429942e8c658a1afcbc7ee46a", "parent_sha": "9e849276a0bc654d78389499a1d5e3bf0af68063", "file_path": "git_map.py", "project_url": "https://github.com/Neozaru/depot_tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -66,7 +66,7 @@ def main():\n           line = line.rstrip(newline)\n           line += ''.join(\n               (BRIGHT, WHITE, '    <(%s)' % (', '.join(base_for_branches)),\n-               newline))\n+               RESET, newline))\n           for b in base_for_branches:\n             del merge_base_map[b]\n \n", "before": "line += '' . join ( ( BRIGHT , WHITE , '    <(%s)' % ( ', ' . join ( base_for_branches ) ) , newline ) )", "after": "line += '' . join ( ( BRIGHT , WHITE , '    <(%s)' % ( ', ' . join ( base_for_branches ) ) , RESET , newline ) )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 2, 15, 3, 24], [\"identifier:RESET\", \"T\"], 7], [\"Insert\", [\"tuple\", 2, 15, 3, 24], [\",:,\", \"T\"], 8]]"}
{"project": "depot_tools", "commit_sha": "4b5321ac01db374f23e43eda8d1782cb8f237009", "parent_sha": "2349b06655cdf6ae86a11716079cc5024af5abd0", "file_path": "git_cl_hooks.py", "project_url": "https://github.com/Neozaru/depot_tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,7 +35,7 @@ class ChangeOptions:\n     name = m.group(1)\n     description = m.group(2)\n     files = scm.GIT.CaptureStatus([root], upstream_branch)\n-    issue = Backquote(['cl', 'status', '--field=id'])\n+    issue = Backquote(['git', 'cl', 'status', '--field=id'])\n     patchset = None\n     self.change = presubmit_support.GitChange(name, description, root, files,\n                                               issue, patchset)\n", "before": "issue = Backquote ( [ 'cl' , 'status' , '--field=id' ] )", "after": "issue = Backquote ( [ 'git' , 'cl' , 'status' , '--field=id' ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\"string:'cl'\", 3, 24, 3, 28], [\"list\", 3, 23, 3, 53], 2], [\"Move\", [\"string:'status'\", 3, 30, 3, 38], [\"list\", 3, 23, 3, 53], 5], [\"Insert\", [\"list\", 3, 23, 3, 53], [\"string:'git'\", \"T\"], 1], [\"Insert\", [\"list\", 3, 23, 3, 53], [\",:,\", \"T\"], 5]]"}
{"project": "sqp", "commit_sha": "e08d7bbd49859d601caf9c0c1db4ff827e52bd1c", "parent_sha": "697cbe459b84d5136bdb39adce4d72a0a245518d", "file_path": "sqp-addons/boi/model/mrp.py", "project_url": "https://github.com/ecosoft-odoo/sqp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -102,7 +102,7 @@ class bom_choice_insulation(osv.osv):\n             order_obj = self.pool.get('sale.order')\n             order = order_obj.browse(cr, user, context.get('order_id'), context=context)\n             if order.product_tag_id and order.product_tag_id.name == 'BOI':\n-                args = [('name', 'in', ['PIR', 'PU', 'PU(DEN80)'])] + args\n+                args = [('name', 'in', ['PIR', 'PU', 'PU(DEN80)', 'Rockwool'])] + args\n             else:\n                 if context.get('object', 'not door') == 'door':\n                     args = [('name', '!=', 'PIR')] + args\n", "before": "args = [ ( 'name' , 'in' , [ 'PIR' , 'PU' , 'PU(DEN80)' ] ) ] + args", "after": "args = [ ( 'name' , 'in' , [ 'PIR' , 'PU' , 'PU(DEN80)' , 'Rockwool' ] ) ] + args", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 40, 3, 66], [\",:,\", \"T\"], 6], [\"Insert\", [\"list\", 3, 40, 3, 66], [\"string:'Rockwool'\", \"T\"], 7]]"}
{"project": "tensorflow_apps", "commit_sha": "58c77297a5f4b902d9b9e0e4d49e40ae3bfcdddd", "parent_sha": "669496b91919f93fb6de3f6356ec8ed3d9b36433", "file_path": "src/cnn/eval_binary.py", "project_url": "https://github.com/jswelling/tensorflow_apps", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -127,7 +127,7 @@ def eval_once(sess, iterator, saver, seed, label_op, loss_op, accuracy_op, predi\n     accuracyV = np.asarray(accuracy_samples)\n     print('%s: total examples @ 1 = %d' % (datetime.now(), examples))\n     print('%s: loss @ 1 = %.3f' % (datetime.now(), loss))\n-    print('%s: overall accuracy %s +- %s' % (np.mean(accuracyV),\n+    print('%s: overall accuracy %s +- %s' % (datetime.now(), np.mean(accuracyV),\n                                              np.std(accuracyV, ddof=1)))\n     print('%s: true positive @ 1 = %d' % (datetime.now(), n_true_pos))\n     print('%s: false positive @ 1 = %d' % (datetime.now(), n_false_pos))\n", "before": "print ( '%s: overall accuracy %s +- %s' % ( np . mean ( accuracyV ) , np . std ( accuracyV , ddof = 1 ) ) )", "after": "print ( '%s: overall accuracy %s +- %s' % ( datetime . now ( ) , np . mean ( accuracyV ) , np . std ( accuracyV , ddof = 1 ) ) )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 45, 4, 72], [\"call\", \"N0\"], 1], [\"Insert\", [\"tuple\", 3, 45, 4, 72], [\",:,\", \"T\"], 2], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N1\", [\"identifier:datetime\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:now\", \"T\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"):)\", \"T\"], 1]]"}
{"project": "NIPAP", "commit_sha": "ab9f06545b27949641a601a449d85d922120107a", "parent_sha": "5881fa2f91978a9e9565170487acf63d3605eedb", "file_path": "tests/xmlrpc.py", "project_url": "https://github.com/fredsod/NIPAP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -837,7 +837,7 @@ class NipapXmlTest(unittest.TestCase):\n                 'search_options': {'include_all_children':\n                 False, 'max_result': 50, 'include_all_parents': False,\n                 'parents_depth': 0, 'offset': 0, 'children_depth': 0,\n-                'parent_prefix': None },\n+                'parent_prefix': None, 'include_neighbors': False },\n                 'result': [\n                     {'comment': None,\n                         'external_key': None,\n", "before": "{ 'include_all_children' : False , 'max_result' : 50 , 'include_all_parents' : False , 'parents_depth' : 0 , 'offset' : 0 , 'children_depth' : 0 , 'parent_prefix' : None } ,", "after": "{ 'include_all_children' : False , 'max_result' : 50 , 'include_all_parents' : False , 'parents_depth' : 0 , 'offset' : 0 , 'children_depth' : 0 , 'parent_prefix' : None , 'include_neighbors' : False } ,", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 0, 35, 3, 40], [\",:,\", \"T\"], 14], [\"Insert\", [\"dictionary\", 0, 35, 3, 40], [\"pair\", \"N0\"], 15], [\"Insert\", \"N0\", [\"string:'include_neighbors'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"false:False\", \"T\"], 2]]"}
{"project": "Cura", "commit_sha": "dc01cdbc882faee68b66fcdf924884e7bc95dfa1", "parent_sha": "eb3cfd47cdab1bd9d5b6f03e6fdc7414c121ffdb", "file_path": "cura/LayerPolygon.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ class LayerPolygon:\n         \n         # When type is used as index returns true if type == LayerPolygon.InfillType or type == LayerPolygon.SkinType or type == LayerPolygon.SupportInfillType\n         # Should be generated in better way, not hardcoded.\n-        self._isInfillOrSkinTypeMap = numpy.array([0, 0, 0, 1, 0, 0, 1, 1, 0, 0], dtype=numpy.bool)\n+        self._isInfillOrSkinTypeMap = numpy.array([0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1], dtype=numpy.bool)\n         \n         self._build_cache_line_mesh_mask = None\n         self._build_cache_needed_points = None\n", "before": "self . _isInfillOrSkinTypeMap = numpy . array ( [ 0 , 0 , 0 , 1 , 0 , 0 , 1 , 1 , 0 , 0 ] , dtype = numpy . bool )", "after": "self . _isInfillOrSkinTypeMap = numpy . array ( [ 0 , 0 , 0 , 1 , 0 , 0 , 1 , 1 , 0 , 0 , 1 ] , dtype = numpy . bool )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 51, 3, 81], [\",:,\", \"T\"], 20], [\"Insert\", [\"list\", 3, 51, 3, 81], [\"integer:1\", \"T\"], 21]]"}
{"project": "RatticWeb", "commit_sha": "df67267e159604d7418e543669ccfe8c70f15963", "parent_sha": "4f3ffe0803950d720409496d1b6a2b6a4e9518a4", "file_path": "cred/views.py", "project_url": "https://github.com/efornal/RatticWeb", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -116,7 +116,7 @@ def add(request):\n         form = CredForm(request.user)\n \n     return render(request, 'cred_edit.html', {'form': form, 'action':\n-        '/cred/add/'})\n+      '/cred/add/', 'icons': CredIcon.objects.all()})\n \n @login_required\n def edit(request, cred_id):\n", "before": "return render ( request , 'cred_edit.html' , { 'form' : form , 'action' : '/cred/add/' } )", "after": "return render ( request , 'cred_edit.html' , { 'form' : form , 'action' : '/cred/add/' , 'icons' : CredIcon . objects . all ( ) } )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 2, 46, 3, 22], [\",:,\", \"T\"], 4], [\"Insert\", [\"dictionary\", 2, 46, 3, 22], [\"pair\", \"N0\"], 5], [\"Insert\", \"N0\", [\"string:'icons'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N3\"], 1], [\"Insert\", \"N2\", [\"attribute\", \"N4\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:all\", \"T\"], 2], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"):)\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:CredIcon\", \"T\"], 0], [\"Insert\", \"N4\", [\".:.\", \"T\"], 1], [\"Insert\", \"N4\", [\"identifier:objects\", \"T\"], 2]]"}
{"project": "python-logstash", "commit_sha": "6028f83921f7953953b920c9429d172f73a10a9b", "parent_sha": "37fb47927cc284f25d6e1ce1c0141510bd0d5c4e", "file_path": "logstash/formatter.py", "project_url": "https://github.com/Freezzz/python-logstash", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ class LogstashFormatterBase(logging.Formatter):\n             'processName', 'relativeCreated', 'thread', 'threadName', 'extra')\n \n         if sys.version_info < (3, 0):\n-            easy_types = (basestring, bool, dict, float, int, list, type(None))\n+            easy_types = (basestring, bool, dict, float, int, long, list, type(None))\n         else:\n             easy_types = (str, bool, dict, float, int, list, type(None))\n \n", "before": "easy_types = ( basestring , bool , dict , float , int , list , type ( None ) )", "after": "easy_types = ( basestring , bool , dict , float , int , long , list , type ( None ) )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 26, 3, 80], [\"identifier:long\", \"T\"], 11], [\"Insert\", [\"tuple\", 3, 26, 3, 80], [\",:,\", \"T\"], 12]]"}
{"project": "tools_repo", "commit_sha": "f2af7564256a65221e0ebc45d716672a42cd537a", "parent_sha": "544e7b0a9774a6366b6a06d25992c46fd5d4f31f", "file_path": "project.py", "project_url": "https://github.com/LineageOS/tools_repo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2186,7 +2186,7 @@ class Project(object):\n     symlink_dirs = ['hooks', 'objects', 'rr-cache', 'svn']\n     if share_refs:\n       # These objects can only be used by a single working tree.\n-      symlink_files += ['config', 'packed-refs']\n+      symlink_files += ['config', 'packed-refs', 'shallow']\n       symlink_dirs += ['logs', 'refs']\n     to_symlink = symlink_files + symlink_dirs\n \n", "before": "symlink_files += [ 'config' , 'packed-refs' ]", "after": "symlink_files += [ 'config' , 'packed-refs' , 'shallow' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 24, 3, 49], [\",:,\", \"T\"], 4], [\"Insert\", [\"list\", 3, 24, 3, 49], [\"string:'shallow'\", \"T\"], 5]]"}
{"project": "flocker", "commit_sha": "0a5d2e5438c458394f18776efb13285231c62b0d", "parent_sha": "d2dd213cabe8604e3a4b3f8fbc74c8b46d9d295f", "file_path": "flocker/node/agents/test/test_blockdevice.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2615,7 +2615,7 @@ class BlockDeviceDeployerCreationCalculateChangesTests(\n         )\n         changes = deployer.calculate_changes(configuration, state, local_state)\n         self.assertEqual(\n-            in_parallel(changes=[]),\n+            in_parallel(changes=[ActionNeeded(dataset_id=dataset_id)]),\n             changes\n         )\n \n", "before": "self . assertEqual ( in_parallel ( changes = [ ] ) , changes )", "after": "self . assertEqual ( in_parallel ( changes = [ ActionNeeded ( dataset_id = dataset_id ) ] ) , changes )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 33, 3, 35], [\"call\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:ActionNeeded\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"keyword_argument\", \"N2\"], 1], [\"Insert\", \"N1\", [\"):)\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:dataset_id\", \"T\"], 0], [\"Insert\", \"N2\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:dataset_id\", \"T\"], 2]]"}
{"project": "larray", "commit_sha": "ccf364c8efa280e898891d6be72d37c3b4298924", "parent_sha": "3a815d33cd6ba378a3fca16583431608890bdbae", "file_path": "larray/core/axis.py", "project_url": "https://github.com/alixdamman/larray", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2830,7 +2830,7 @@ class AxisCollection(object):\n \n         # transform non-Array advanced keys (list and ndarray) to Array\n         def to_la_ikey(axis, axis_key):\n-            if isinstance(axis_key, (int, np.integer, slice, Array)):\n+            if isinstance(axis_key, (int, long, np.integer, slice, Array)):\n                 return axis_key\n             else:\n                 assert isinstance(axis_key, (list, np.ndarray))\n", "before": "if isinstance ( axis_key , ( int , np . integer , slice , Array ) ) : return axis_key else : assert isinstance ( axis_key , ( list , np . ndarray ) )", "after": "if isinstance ( axis_key , ( int , long , np . integer , slice , Array ) ) : return axis_key else : assert isinstance ( axis_key , ( list , np . ndarray ) )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 37, 3, 68], [\"identifier:long\", \"T\"], 3], [\"Insert\", [\"tuple\", 3, 37, 3, 68], [\",:,\", \"T\"], 4]]"}
{"project": "zulip", "commit_sha": "c59cdbb92d400a28fe0a9f9de50b5dfee0494cf5", "parent_sha": "14018353fc7a0e517557caec021355338e4b2480", "file_path": "zerver/lib/actions.py", "project_url": "https://github.com/punit-agarwal/zulip", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2759,7 +2759,7 @@ def gather_subscriptions_helper(user_profile):\n             never_subscribed.append(stream_dict)\n \n     user_ids = set()\n-    for subs in [subscribed, unsubscribed]:\n+    for subs in [subscribed, unsubscribed, never_subscribed]:\n         for sub in subs:\n             if 'subscribers' in sub:\n                 for subscriber in sub['subscribers']:\n", "before": "for subs in [ subscribed , unsubscribed ] : for sub in subs : if 'subscribers' in sub : for subscriber in sub [ 'subscribers' ] : ", "after": "for subs in [ subscribed , unsubscribed , never_subscribed ] : for sub in subs : if 'subscribers' in sub : for subscriber in sub [ 'subscribers' ] : ", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 17, 3, 43], [\",:,\", \"T\"], 4], [\"Insert\", [\"list\", 3, 17, 3, 43], [\"identifier:never_subscribed\", \"T\"], 5]]"}
{"project": "pytrader", "commit_sha": "57abf381b9a3a8a16ab730234d505d05c4b6c8dc", "parent_sha": "14dae9290d2618642fed95feba8a71548aafc543", "file_path": "goxapi.py", "project_url": "https://github.com/caktux/pytrader", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1752,7 +1752,7 @@ class Gox(BaseObject):\n         # we are now going to fake a user_order message (the one we\n         # obviously missed earlier) that will have the effect of\n         # removing the order cleanly.\n-        fakemsg = {\"user_order\": {\"oid\": oid}}\n+        fakemsg = {\"user_order\": {\"oid\": oid, \"reason\": \"requested\"}}\n         self._on_op_private_user_order(fakemsg)\n \n     def _on_order_amount_too_low(self, _msg):\n", "before": "fakemsg = { \"user_order\" : { \"oid\" : oid } }", "after": "fakemsg = { \"user_order\" : { \"oid\" : oid , \"reason\" : \"requested\" } }", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 34, 3, 46], [\",:,\", \"T\"], 2], [\"Insert\", [\"dictionary\", 3, 34, 3, 46], [\"pair\", \"N0\"], 3], [\"Insert\", \"N0\", [\"string:\\\"reason\\\"\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:\\\"requested\\\"\", \"T\"], 2]]"}
{"project": "fimax", "commit_sha": "df582d4a5881f3a709e0326b05c0cc03c6a73bb4", "parent_sha": "a4289e42d834aabefb8051e9e52f0a1b1da9c798", "file_path": "fimax/install.py", "project_url": "https://github.com/YefriTavarez/fimax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,7 +34,7 @@ def add_default_loan_charges_type():\n \tfrom fimax.hook.loan_charges_type import create_loan_charges_type\n \n \tloan_charges_type_list = [\"Capital\", \"Interest\", \"Repayment Amount\",\n-\t\t\"Insurance\", \"Late Payment Fee\", \"GPS\"]\n+\t\t\"Insurance\", \"Late Payment Fee\", \"GPS\", \"Recovery Expenses\"]\n \n \tfor loan_charges_type in loan_charges_type_list:\n \t\tif frappe.db.exists(\"Loan Charges Type\", loan_charges_type):\n", "before": "loan_charges_type_list = [ \"Capital\" , \"Interest\" , \"Repayment Amount\" , \"Insurance\" , \"Late Payment Fee\" , \"GPS\" ]", "after": "loan_charges_type_list = [ \"Capital\" , \"Interest\" , \"Repayment Amount\" , \"Insurance\" , \"Late Payment Fee\" , \"GPS\" , \"Recovery Expenses\" ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\",:,\", 2, 37, 2, 38], [\"list\", 2, 27, 3, 42], 11], [\"Insert\", [\"list\", 2, 27, 3, 42], [\",:,\", \"T\"], 2], [\"Insert\", [\"list\", 2, 27, 3, 42], [\"string:\\\"Recovery Expenses\\\"\", \"T\"], 4]]"}
{"project": "pyroboime", "commit_sha": "2a333192f7af04130c68497ef8ed09d8f743e8af", "parent_sha": "43da295fff8b361c39e0888a34103894bcd2280e", "file_path": "roboime/core/plays/obeyreferee.py", "project_url": "https://github.com/KN2C/pyroboime", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -108,7 +108,7 @@ class ObeyReferee(Play):\n             else:\n                 self.indirect_kick.step()\n \n-        elif self.command in [Command.PrepareKickoffYellow, Command.PrepareKickoffBlue, Command.Stop]:\n+        elif self.command in [Command.PrepareKickoffYellow, Command.PrepareKickoffBlue, Command.Stop, Command.TimeoutYellow, Command.TimeoutBlue]:\n             self.stop.step()\n \n         elif self.command == Command.Halt:\n", "before": "elif self . command in [ Command . PrepareKickoffYellow , Command . PrepareKickoffBlue , Command . Stop ] : self . stop . step ( )", "after": "elif self . command in [ Command . PrepareKickoffYellow , Command . PrepareKickoffBlue , Command . Stop , Command . TimeoutYellow , Command . TimeoutBlue ] : self . stop . step ( )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 30, 3, 102], [\",:,\", \"T\"], 6], [\"Insert\", [\"list\", 3, 30, 3, 102], [\"attribute\", \"N0\"], 7], [\"Insert\", [\"list\", 3, 30, 3, 102], [\",:,\", \"T\"], 8], [\"Insert\", [\"list\", 3, 30, 3, 102], [\"attribute\", \"N1\"], 9], [\"Insert\", \"N0\", [\"identifier:Command\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:TimeoutYellow\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:Command\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:TimeoutBlue\", \"T\"], 2]]"}
{"project": "classycn", "commit_sha": "d420ce3b1aefaaf1531e07fee440badc1637dfc3", "parent_sha": "64f1bc70661b90aabd764a983a358cf84f42dad7", "file_path": "lstm.py", "project_url": "https://github.com/xlhdh/classycn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -120,7 +120,7 @@ class LSTM:\n         presig_output_sequence, train_updates = theano.scan(fn=lambda x, y: (x + y + bo),\n                                                       sequences = [output_sequencef, output_sequenceb],\n                                                       non_sequences=bo,\n-                                                      outputs_info=[None])\n+                                                      outputs_info=[None,])\n                                                       \n         # avoid log(0)\n         output_sequence = sig(presig_output_sequence)\n", "before": "presig_output_sequence , train_updates = theano . scan ( fn = lambda x , y : ( x + y + bo ) , sequences = [ output_sequencef , output_sequenceb ] , non_sequences = bo , outputs_info = [ None ] )", "after": "presig_output_sequence , train_updates = theano . scan ( fn = lambda x , y : ( x + y + bo ) , sequences = [ output_sequencef , output_sequenceb ] , non_sequences = bo , outputs_info = [ None , ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 68, 3, 74], [\",:,\", \"T\"], 2]]"}
{"project": "pritunl", "commit_sha": "d48a60e6cd22afb99b7e8aa71dd0480aeeb3e63b", "parent_sha": "08b8b7e54209d14c480a65e4cd2fcadcbfc21e8a", "file_path": "pritunl/handlers/server.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -680,7 +680,7 @@ def server_client_connect_post(server_id):\n     user_id = bson.ObjectId(flask.request.json['user_id'])\n \n     svr = server.get_server(id=server_id,\n-        fields=['_id', 'name', 'links', 'organizations'])\n+        fields=['_id', 'name', 'network', 'links', 'organizations'])\n     if not svr:\n         return utils.jsonify({\n             'error': SERVER_INVALID,\n", "before": "svr = server . get_server ( id = server_id , fields = [ '_id' , 'name' , 'links' , 'organizations' ] )", "after": "svr = server . get_server ( id = server_id , fields = [ '_id' , 'name' , 'network' , 'links' , 'organizations' ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\"string:'links'\", 3, 32, 3, 39], [\"list\", 3, 16, 3, 57], 6], [\"Insert\", [\"list\", 3, 16, 3, 57], [\"string:'network'\", \"T\"], 5], [\"Insert\", [\"list\", 3, 16, 3, 57], [\",:,\", \"T\"], 7]]"}
{"project": "case", "commit_sha": "91611c1386061980f5d82a4c851cea9cc93be9fe", "parent_sha": "3e7f1768e6f708b66b6a0d2c3950fbbd15361356", "file_path": "mypleasure/case/api/serializers.py", "project_url": "https://github.com/dheavy/case", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -403,7 +403,7 @@ class CuratedMediaAcquisitionSerializer(serializers.Serializer):\n             return ValidationError({'url': [\n                 'User already has video, or video is \\\n                 already queued for acquisition'\n-            ]})\n+            ], 'code': 'duplicate'})\n \n         return attrs\n \n", "before": "return ValidationError ( { 'url' : [ 'User already has video, or video is \\\n                 already queued for acquisition' ] } )", "after": "return ValidationError ( { 'url' : [ 'User already has video, or video is \\\n                 already queued for acquisition' ] , 'code' : 'duplicate' } )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 0, 36, 3, 15], [\",:,\", \"T\"], 2], [\"Insert\", [\"dictionary\", 0, 36, 3, 15], [\"pair\", \"N0\"], 3], [\"Insert\", \"N0\", [\"string:'code'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'duplicate'\", \"T\"], 2]]"}
{"project": "pyspider", "commit_sha": "4f8ccb4289b6943e9ca99cf7b16020aa3ea955c6", "parent_sha": "51b1a1ab34cc222fdddda42442139f7b687f1a55", "file_path": "libs/rabbitmq.py", "project_url": "https://github.com/atlas555/pyspider", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -18,7 +18,7 @@ def catch_error(func):\n     def wrap(self, *args, **kwargs):\n         try:\n             return func(self, *args, **kwargs)\n-        except (select.error, socket.error, pika.exceptions.AMQPConnectionError) as e:\n+        except (select.error, socket.error, pika.exceptions.ConnectionClosed, pika.exceptions.AMQPConnectionError) as e:\n             self.reconnect()\n             raise\n     return wrap\n", "before": "try : return func ( self , * args , ** kwargs ) except ( select . error , socket . error , pika . exceptions . AMQPConnectionError ) as e : self . reconnect ( ) raise", "after": "try : return func ( self , * args , ** kwargs ) except ( select . error , socket . error , pika . exceptions . ConnectionClosed , pika . exceptions . AMQPConnectionError ) as e : self . reconnect ( ) raise", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 16, 3, 81], [\"attribute\", \"N0\"], 5], [\"Insert\", [\"tuple\", 3, 16, 3, 81], [\",:,\", \"T\"], 6], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:ConnectionClosed\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:pika\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:exceptions\", \"T\"], 2]]"}
{"project": "openobject-client-6.0", "commit_sha": "4941c1ed19e63a247182fb637b9ecc51b291f4c9", "parent_sha": "22faa937b34a23d7c1c596facd4d9a78a2377b3b", "file_path": "bin/printer/printer.py", "project_url": "https://github.com/hunslater/openobject-client-6.0", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -104,7 +104,7 @@ class Printer(object):\n         else:\n             if options.options['printer.preview']:\n                 if options.options['printer.softpath'] == 'none':\n-                    prog = self._findInPath(['evince', 'xpdf', 'gpdf', 'kpdf', 'epdfview', 'acroread', 'open'])\n+                    prog = self._findInPath(['xdg-open', 'evince', 'xpdf', 'gpdf', 'kpdf', 'epdfview', 'acroread', 'open'])\n                     def opener(fn):\n                         self.__opener( lambda: os.execv(prog, (os.path.basename(prog), fn) ))\n                     return opener\n", "before": "options . options [ 'printer.preview' ] : if options . options [ 'printer.softpath' ] == 'none' : prog = self . _findInPath ( [ 'evince' , 'xpdf' , 'gpdf' , 'kpdf' , 'epdfview' , 'acroread' , 'open' ] )", "after": "options . options [ 'printer.preview' ] : if options . options [ 'printer.softpath' ] == 'none' : prog = self . _findInPath ( [ 'xdg-open' , 'evince' , 'xpdf' , 'gpdf' , 'kpdf' , 'epdfview' , 'acroread' , 'open' ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\"string:'evince'\", 3, 46, 3, 54], [\"list\", 3, 45, 3, 111], 2], [\"Move\", [\"string:'xpdf'\", 3, 56, 3, 62], [\"list\", 3, 45, 3, 111], 5], [\"Move\", [\"string:'gpdf'\", 3, 64, 3, 70], [\"list\", 3, 45, 3, 111], 7], [\"Move\", [\"string:'epdfview'\", 3, 80, 3, 90], [\"list\", 3, 45, 3, 111], 10], [\"Move\", [\"string:'acroread'\", 3, 92, 3, 102], [\"list\", 3, 45, 3, 111], 12], [\"Insert\", [\"list\", 3, 45, 3, 111], [\"string:'xdg-open'\", \"T\"], 1], [\"Insert\", [\"list\", 3, 45, 3, 111], [\",:,\", \"T\"], 7], [\"Insert\", [\"list\", 3, 45, 3, 111], [\",:,\", \"T\"], 14], [\"Delete\", [\",:,\", 3, 78, 3, 79]]]"}
{"project": "Crowdfunding-Backend", "commit_sha": "451098b0a0a0eb745fe467748582306c73bf2321", "parent_sha": "023bfbac7a7d178467e21f8b751e1c79f5793d48", "file_path": "poliedro_donate/utils.py", "project_url": "https://github.com/poliedro-polimi/Crowdfunding-Backend", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -74,7 +74,7 @@ def validate_donation(donation, stretch_goal, items):\n \n def validate_reference(ref):\n     dict(ref)\n-    validate_string([\"firstname\"])\n+    validate_string(ref[\"firstname\"])\n     validate_string(ref[\"lastname\"])\n     validate_email(ref[\"email\"])\n     validate_string(ref[\"phone\"])\n", "before": "validate_string ( [ \"firstname\" ] )", "after": "validate_string ( ref [ \"firstname\" ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 20, 3, 35], [\"subscript\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:ref\", \"T\"], 0], [\"Move\", \"N0\", [\"[:[\", 3, 21, 3, 22], 1], [\"Move\", \"N0\", [\"string:\\\"firstname\\\"\", 3, 22, 3, 33], 2], [\"Move\", \"N0\", [\"]:]\", 3, 33, 3, 34], 3], [\"Delete\", [\"list\", 3, 21, 3, 34]]]"}
{"project": "psutil", "commit_sha": "8acbd96b788e6b329b83975a02655a1d4a481807", "parent_sha": "ccb21133ceb280516bf4b3043917ef56cebe91b9", "file_path": "test/_windows.py", "project_url": "https://github.com/mindw/psutil", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -46,7 +46,7 @@ class WindowsSpecificTestCase(unittest.TestCase):\n             rss, vms = p.get_memory_info()\n         except psutil.AccessDenied:\n             # expected on Windows Vista and Windows 7\n-            if not platform.uname()[1] in ('vista', 'win-7'):\n+            if not platform.uname()[1] in ('vista', 'win-7', 'win7'):\n                 raise\n         else:\n             self.assertTrue(rss > 0)\n", "before": "except psutil . AccessDenied : if not platform . uname ( ) [ 1 ] in ( 'vista' , 'win-7' ) : raise", "after": "except psutil . AccessDenied : if not platform . uname ( ) [ 1 ] in ( 'vista' , 'win-7' , 'win7' ) : raise", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 43, 3, 61], [\",:,\", \"T\"], 4], [\"Insert\", [\"tuple\", 3, 43, 3, 61], [\"string:'win7'\", \"T\"], 5]]"}
{"project": "cpython", "commit_sha": "5d6215e11f3d0b74dd2faf05fe642b53259feaf2", "parent_sha": "04b98086bc126c83970b5b89825068aa581222a5", "file_path": "Lib/test/test_os.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -439,7 +439,7 @@ class URandomTests(unittest.TestCase):\n \n class ExecTests(unittest.TestCase):\n     def test_execvpe_with_bad_program(self):\n-        self.assertRaises(OSError, os.execvpe, 'no such app-', [], None)\n+        self.assertRaises(OSError, os.execvpe, 'no such app-', ['no such app-'], None)\n \n     def test_execvpe_with_bad_arglist(self):\n         self.assertRaises(ValueError, os.execvpe, 'notepad', [], None)\n", "before": "self . assertRaises ( OSError , os . execvpe , 'no such app-' , [ ] , None )", "after": "self . assertRaises ( OSError , os . execvpe , 'no such app-' , [ 'no such app-' ] , None )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 64, 3, 66], [\"string:'no such app-'\", \"T\"], 1]]"}
{"project": "cpython", "commit_sha": "7f2bbea68a1ad4165985fa67d797b5408ebfc733", "parent_sha": "55169df5afb6fd36a909472f860a7c5fe3395d9a", "file_path": "Lib/test/test_pyclbr.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -140,7 +140,7 @@ class PyclbrTest(TestCase):\n \n     def test_easy(self):\n         self.checkModule('pyclbr')\n-        self.checkModule('doctest', ignore=(\"TestResults\",))\n+        self.checkModule('doctest', ignore=(\"TestResults\", \"_SpoofOut\"))\n         self.checkModule('rfc822')\n         self.checkModule('difflib', ignore=(\"Match\",))\n \n", "before": "self . checkModule ( 'doctest' , ignore = ( \"TestResults\" , ) )", "after": "self . checkModule ( 'doctest' , ignore = ( \"TestResults\" , \"_SpoofOut\" ) )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 44, 3, 60], [\"string:\\\"_SpoofOut\\\"\", \"T\"], 3]]"}
{"project": "cpython", "commit_sha": "a1dd1c0a8b91cb75ef773ed9566fc93b232bc2b7", "parent_sha": "3c765e7fb416a9f8e38b74e02fda29cad336d009", "file_path": "Lib/test/test_dbm_gnu.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ class TestGdbm(unittest.TestCase):\n         self.g['12345678910'] = '019237410982340912840198242'\n         self.g[b'bytes'] = b'data'\n         key_set = set(self.g.keys())\n-        self.assertEqual(key_set, set([b'a', b'12345678910']))\n+        self.assertEqual(key_set, set([b'a', b'bytes', b'12345678910']))\n         self.assert_(b'a' in self.g)\n         self.assertEqual(self.g[b'bytes'], b'data')\n         key = self.g.firstkey()\n", "before": "self . assertEqual ( key_set , set ( [ b'a' , b'12345678910' ] ) )", "after": "self . assertEqual ( key_set , set ( [ b'a' , b'bytes' , b'12345678910' ] ) )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 39, 3, 61], [\"string:b'bytes'\", \"T\"], 3], [\"Insert\", [\"list\", 3, 39, 3, 61], [\",:,\", \"T\"], 4]]"}
{"project": "sigma", "commit_sha": "60b20a76a67fb37f8542cd01f91c9fdc4f67b676", "parent_sha": "0fe72d61338af1c60ceae2264309fea7a1987373", "file_path": "tools/sigma/backends/limacharlie.py", "project_url": "https://github.com/us3r/sigma", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -95,7 +95,7 @@ class LimaCharlieBackend(BaseBackend):\n         service = \"\"\r\n \r\n         mappingKey = \"%s/%s/%s\" % (product, category, service)\r\n-        topFilter, preCond, mappings, isAllStringValues = _allFieldMappings.get(mappingKey, tuple([None, None, None]))\r\n+        topFilter, preCond, mappings, isAllStringValues = _allFieldMappings.get(mappingKey, tuple([None, None, None, None]))\r\n         if mappings is None:\r\n             raise NotImplementedError(\"Log source %s/%s/%s not supported by backend.\" % (product, category, service))\r\n \r\n", "before": "topFilter , preCond , mappings , isAllStringValues = _allFieldMappings . get ( mappingKey , tuple ( [ None , None , None ] ) )", "after": "topFilter , preCond , mappings , isAllStringValues = _allFieldMappings . get ( mappingKey , tuple ( [ None , None , None , None ] ) )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 99, 3, 117], [\",:,\", \"T\"], 6], [\"Insert\", [\"list\", 3, 99, 3, 117], [\"none:None\", \"T\"], 7]]"}
{"project": "cpython", "commit_sha": "792c40c707d8a456fb69837ae29219cfd13c7c6b", "parent_sha": "155566d2b55a11cfef440e62c1acd3c0a555b9b9", "file_path": "Lib/test/test_urlparse.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -141,7 +141,7 @@ class UrlParseTestCase(unittest.TestCase):\n                          (base, relurl, expected))\n \n     def test_unparse_parse(self):\n-        for u in ['Python', './Python','x-newscheme://foo.com/stuff']:\n+        for u in ['Python', './Python','x-newscheme://foo.com/stuff','x://y','x:/y','x:/','/',]:\n             self.assertEqual(urlparse.urlunsplit(urlparse.urlsplit(u)), u)\n             self.assertEqual(urlparse.urlunparse(urlparse.urlparse(u)), u)\n \n", "before": "for u in [ 'Python' , './Python' , 'x-newscheme://foo.com/stuff' ] : self . assertEqual ( urlparse . urlunsplit ( urlparse . urlsplit ( u ) ) , u ) self . assertEqual ( urlparse . urlunparse ( urlparse . urlparse ( u ) ) , u )", "after": "for u in [ 'Python' , './Python' , 'x-newscheme://foo.com/stuff' , 'x://y' , 'x:/y' , 'x:/' , '/' , ] : self . assertEqual ( urlparse . urlunsplit ( urlparse . urlsplit ( u ) ) , u ) self . assertEqual ( urlparse . urlunparse ( urlparse . urlparse ( u ) ) , u )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 18, 3, 70], [\",:,\", \"T\"], 6], [\"Insert\", [\"list\", 3, 18, 3, 70], [\"string:'x://y'\", \"T\"], 7], [\"Insert\", [\"list\", 3, 18, 3, 70], [\",:,\", \"T\"], 8], [\"Insert\", [\"list\", 3, 18, 3, 70], [\"string:'x:/y'\", \"T\"], 9], [\"Insert\", [\"list\", 3, 18, 3, 70], [\",:,\", \"T\"], 10], [\"Insert\", [\"list\", 3, 18, 3, 70], [\"string:'x:/'\", \"T\"], 11], [\"Insert\", [\"list\", 3, 18, 3, 70], [\",:,\", \"T\"], 12], [\"Insert\", [\"list\", 3, 18, 3, 70], [\"string:'/'\", \"T\"], 13], [\"Insert\", [\"list\", 3, 18, 3, 70], [\",:,\", \"T\"], 14]]"}
{"project": "cpython", "commit_sha": "02601b747672726f03a0b35f2079ada341b59368", "parent_sha": "ac28ce7ee0e6ff60bd6ec0331df7dc5d7bb289b6", "file_path": "Lib/test/test_urlparse.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -138,7 +138,7 @@ class UrlParseTestCase(unittest.TestCase):\n                          (base, relurl, expected))\n \n     def test_unparse_parse(self):\n-        for u in ['Python', './Python','x-newscheme://foo.com/stuff']:\n+        for u in ['Python', './Python','x-newscheme://foo.com/stuff','x://y','x:/y','x:/','/',]:\n             self.assertEqual(urlparse.urlunsplit(urlparse.urlsplit(u)), u)\n             self.assertEqual(urlparse.urlunparse(urlparse.urlparse(u)), u)\n \n", "before": "for u in [ 'Python' , './Python' , 'x-newscheme://foo.com/stuff' ] : self . assertEqual ( urlparse . urlunsplit ( urlparse . urlsplit ( u ) ) , u ) self . assertEqual ( urlparse . urlunparse ( urlparse . urlparse ( u ) ) , u )", "after": "for u in [ 'Python' , './Python' , 'x-newscheme://foo.com/stuff' , 'x://y' , 'x:/y' , 'x:/' , '/' , ] : self . assertEqual ( urlparse . urlunsplit ( urlparse . urlsplit ( u ) ) , u ) self . assertEqual ( urlparse . urlunparse ( urlparse . urlparse ( u ) ) , u )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 18, 3, 70], [\",:,\", \"T\"], 6], [\"Insert\", [\"list\", 3, 18, 3, 70], [\"string:'x://y'\", \"T\"], 7], [\"Insert\", [\"list\", 3, 18, 3, 70], [\",:,\", \"T\"], 8], [\"Insert\", [\"list\", 3, 18, 3, 70], [\"string:'x:/y'\", \"T\"], 9], [\"Insert\", [\"list\", 3, 18, 3, 70], [\",:,\", \"T\"], 10], [\"Insert\", [\"list\", 3, 18, 3, 70], [\"string:'x:/'\", \"T\"], 11], [\"Insert\", [\"list\", 3, 18, 3, 70], [\",:,\", \"T\"], 12], [\"Insert\", [\"list\", 3, 18, 3, 70], [\"string:'/'\", \"T\"], 13], [\"Insert\", [\"list\", 3, 18, 3, 70], [\",:,\", \"T\"], 14]]"}
{"project": "cpython", "commit_sha": "e85f941a6873b420641ca3be1d295f8b06008b92", "parent_sha": "17f12c23e510bca7fd8430ae0fbdc349ab81cc77", "file_path": "Lib/test/test_urlparse.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -142,7 +142,7 @@ class UrlParseTestCase(unittest.TestCase):\n                          (base, relurl, expected))\n \n     def test_unparse_parse(self):\n-        for u in ['Python', './Python', 'x-newscheme://foo.com/stuff']:\n+        for u in ['Python', './Python','x-newscheme://foo.com/stuff','x://y','x:/y','x:/','/',]:\n             self.assertEqual(urllib.parse.urlunsplit(urllib.parse.urlsplit(u)), u)\n             self.assertEqual(urllib.parse.urlunparse(urllib.parse.urlparse(u)), u)\n \n", "before": "for u in [ 'Python' , './Python' , 'x-newscheme://foo.com/stuff' ] : self . assertEqual ( urllib . parse . urlunsplit ( urllib . parse . urlsplit ( u ) ) , u ) self . assertEqual ( urllib . parse . urlunparse ( urllib . parse . urlparse ( u ) ) , u )", "after": "for u in [ 'Python' , './Python' , 'x-newscheme://foo.com/stuff' , 'x://y' , 'x:/y' , 'x:/' , '/' , ] : self . assertEqual ( urllib . parse . urlunsplit ( urllib . parse . urlsplit ( u ) ) , u ) self . assertEqual ( urllib . parse . urlunparse ( urllib . parse . urlparse ( u ) ) , u )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 18, 3, 71], [\",:,\", \"T\"], 6], [\"Insert\", [\"list\", 3, 18, 3, 71], [\"string:'x://y'\", \"T\"], 7], [\"Insert\", [\"list\", 3, 18, 3, 71], [\",:,\", \"T\"], 8], [\"Insert\", [\"list\", 3, 18, 3, 71], [\"string:'x:/y'\", \"T\"], 9], [\"Insert\", [\"list\", 3, 18, 3, 71], [\",:,\", \"T\"], 10], [\"Insert\", [\"list\", 3, 18, 3, 71], [\"string:'x:/'\", \"T\"], 11], [\"Insert\", [\"list\", 3, 18, 3, 71], [\",:,\", \"T\"], 12], [\"Insert\", [\"list\", 3, 18, 3, 71], [\"string:'/'\", \"T\"], 13], [\"Insert\", [\"list\", 3, 18, 3, 71], [\",:,\", \"T\"], 14]]"}
{"project": "cpython", "commit_sha": "2d9aa77313938535141c8624c35368ca00d66dad", "parent_sha": "941219e30a86a12d7639eaa841ede2d0dcb15c8e", "file_path": "Lib/test/test_urlparse.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -142,7 +142,7 @@ class UrlParseTestCase(unittest.TestCase):\n                          (base, relurl, expected))\n \n     def test_unparse_parse(self):\n-        for u in ['Python', './Python', 'x-newscheme://foo.com/stuff']:\n+        for u in ['Python', './Python','x-newscheme://foo.com/stuff','x://y','x:/y','x:/','/',]:\n             self.assertEqual(urllib.parse.urlunsplit(urllib.parse.urlsplit(u)), u)\n             self.assertEqual(urllib.parse.urlunparse(urllib.parse.urlparse(u)), u)\n \n", "before": "for u in [ 'Python' , './Python' , 'x-newscheme://foo.com/stuff' ] : self . assertEqual ( urllib . parse . urlunsplit ( urllib . parse . urlsplit ( u ) ) , u ) self . assertEqual ( urllib . parse . urlunparse ( urllib . parse . urlparse ( u ) ) , u )", "after": "for u in [ 'Python' , './Python' , 'x-newscheme://foo.com/stuff' , 'x://y' , 'x:/y' , 'x:/' , '/' , ] : self . assertEqual ( urllib . parse . urlunsplit ( urllib . parse . urlsplit ( u ) ) , u ) self . assertEqual ( urllib . parse . urlunparse ( urllib . parse . urlparse ( u ) ) , u )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 18, 3, 71], [\",:,\", \"T\"], 6], [\"Insert\", [\"list\", 3, 18, 3, 71], [\"string:'x://y'\", \"T\"], 7], [\"Insert\", [\"list\", 3, 18, 3, 71], [\",:,\", \"T\"], 8], [\"Insert\", [\"list\", 3, 18, 3, 71], [\"string:'x:/y'\", \"T\"], 9], [\"Insert\", [\"list\", 3, 18, 3, 71], [\",:,\", \"T\"], 10], [\"Insert\", [\"list\", 3, 18, 3, 71], [\"string:'x:/'\", \"T\"], 11], [\"Insert\", [\"list\", 3, 18, 3, 71], [\",:,\", \"T\"], 12], [\"Insert\", [\"list\", 3, 18, 3, 71], [\"string:'/'\", \"T\"], 13], [\"Insert\", [\"list\", 3, 18, 3, 71], [\",:,\", \"T\"], 14]]"}
{"project": "cpython", "commit_sha": "2c82e34106a79636584366c75309ad4e3931a3da", "parent_sha": "ec061a90b6e742c23b0a7359a090f6e041679d2b", "file_path": "Lib/test/test_imp.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -328,7 +328,7 @@ class PEP3147Tests(unittest.TestCase):\n         importlib.invalidate_caches()\n         expected___file__ = os.sep.join(('.', 'pep3147', '__init__.py'))\n         m = __import__('pep3147')\n-        self.assertEqual(m.__file__, expected___file__, (m.__file__, m.__path__))\n+        self.assertEqual(m.__file__, expected___file__, (m.__file__, m.__path__, sys.path))\n         # Ensure we load the pyc file.\n         support.unload('pep3147')\n         m = __import__('pep3147')\n", "before": "self . assertEqual ( m . __file__ , expected___file__ , ( m . __file__ , m . __path__ ) )", "after": "self . assertEqual ( m . __file__ , expected___file__ , ( m . __file__ , m . __path__ , sys . path ) )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 57, 3, 81], [\",:,\", \"T\"], 4], [\"Insert\", [\"tuple\", 3, 57, 3, 81], [\"attribute\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:sys\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:path\", \"T\"], 2]]"}
{"project": "splinter", "commit_sha": "e7f6dc0c233997b7c3977f8ad444156d957a9499", "parent_sha": "12d4230a25d768709372e999370e5447d4cdd127", "file_path": "splinter/driver/webdriver/__init__.py", "project_url": "https://github.com/wisdom-garden/splinter", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -235,7 +235,7 @@ class BaseWebDriver(DriverAPI):\n         for name, value in field_values.items():\n             elements = self.find_by_name(name)\n             element = elements.first\n-            if element['type'] in ['text', 'password'] or element.tag_name == 'textarea':\n+            if element['type'] in ['text', 'password', 'tel'] or element.tag_name == 'textarea':\n                 element.value = value\n             elif element['type'] == 'checkbox':\n                 if value:\n", "before": "if element [ 'type' ] in [ 'text' , 'password' ] or element . tag_name == 'textarea' : element . value = value elif element [ 'type' ] == 'checkbox' : if value : ", "after": "if element [ 'type' ] in [ 'text' , 'password' , 'tel' ] or element . tag_name == 'textarea' : element . value = value elif element [ 'type' ] == 'checkbox' : if value : ", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 35, 3, 55], [\",:,\", \"T\"], 4], [\"Insert\", [\"list\", 3, 35, 3, 55], [\"string:'tel'\", \"T\"], 5]]"}
{"project": "rapidsms", "commit_sha": "cc2fbb2203ebd160d981d6c590d446c5e3a2f702", "parent_sha": "877fbf467f223952f28d015b6aa9cfa7eeda41b8", "file_path": "rapidsms/backends/vumi/outgoing.py", "project_url": "https://github.com/maniacs-satm/rapidsms", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,7 +25,7 @@ class VumiBackend(BackendBase):\n                   'headers': {'content-type': 'application/json'}}\n         payload = copy.copy(self.sendsms_params)\n         payload.update({'content': text, 'to_addr': identities,\n-                        'session_event': None})\n+                        'session_event': None, 'message_id': id_})\n         if len(identities) == 1 and 'external_id' in context:\n             payload['in_reply_to'] = context['external_id']\n         if self.sendsms_user and self.sendsms_pass:\n", "before": "payload . update ( { 'content' : text , 'to_addr' : identities , 'session_event' : None } )", "after": "payload . update ( { 'content' : text , 'to_addr' : identities , 'session_event' : None , 'message_id' : id_ } )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 2, 24, 3, 47], [\",:,\", \"T\"], 6], [\"Insert\", [\"dictionary\", 2, 24, 3, 47], [\"pair\", \"N0\"], 7], [\"Insert\", \"N0\", [\"string:'message_id'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:id_\", \"T\"], 2]]"}
{"project": "django-denorm", "commit_sha": "9b9b187dca4c06e3e835be609897c2bc53622261", "parent_sha": "12fbfb950f56da89a93e2aae592c977122b2c518", "file_path": "denorm/fields.py", "project_url": "https://github.com/Edrolo/django-denorm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -100,7 +100,7 @@ class CountField(models.PositiveIntegerField):\n \n     def south_field_triple(self):\n         return (\n-            '.'.join(('models',models.PositiveIntegerField.__name__)),\n+            '.'.join(('django','db','models',models.PositiveIntegerField.__name__)),\n             [],\n             self.kwargs,\n         )\n", "before": "return ( '.' . join ( ( 'models' , models . PositiveIntegerField . __name__ ) ) , [ ] , self . kwargs , )", "after": "return ( '.' . join ( ( 'django' , 'db' , 'models' , models . PositiveIntegerField . __name__ ) ) , [ ] , self . kwargs , )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 22, 3, 69], [\"string:'django'\", \"T\"], 1], [\"Insert\", [\"tuple\", 3, 22, 3, 69], [\",:,\", \"T\"], 2], [\"Insert\", [\"tuple\", 3, 22, 3, 69], [\"string:'db'\", \"T\"], 3], [\"Insert\", [\"tuple\", 3, 22, 3, 69], [\",:,\", \"T\"], 4]]"}
{"project": "kin-app-server", "commit_sha": "413d3ae15a470d893199730f5b288e751b71ce40", "parent_sha": "00c858c0358e91a74c2a1a2448493e87ea7b8008", "file_path": "kinappserver/models/task.py", "project_url": "https://github.com/kinecosystem/kin-app-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -225,7 +225,7 @@ def add_task(task_json):\n     try:\n         # sanity for task data\n         for item in task_json['items']:\n-            if item['type'] not in ['textimage', 'text']:\n+            if item['type'] not in ['textimage', 'text', 'text-multiple', 'text-emoji', 'rating']:\n                 raise InvalidUsage('cant add task with invalid item-type')\n \n         task = Task()\n", "before": "if item [ 'type' ] not in [ 'textimage' , 'text' ] : raise InvalidUsage ( 'cant add task with invalid item-type' )", "after": "if item [ 'type' ] not in [ 'textimage' , 'text' , 'text-multiple' , 'text-emoji' , 'rating' ] : raise InvalidUsage ( 'cant add task with invalid item-type' )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 36, 3, 57], [\",:,\", \"T\"], 4], [\"Insert\", [\"list\", 3, 36, 3, 57], [\"string:'text-multiple'\", \"T\"], 5], [\"Insert\", [\"list\", 3, 36, 3, 57], [\",:,\", \"T\"], 6], [\"Insert\", [\"list\", 3, 36, 3, 57], [\"string:'text-emoji'\", \"T\"], 7], [\"Insert\", [\"list\", 3, 36, 3, 57], [\",:,\", \"T\"], 8], [\"Insert\", [\"list\", 3, 36, 3, 57], [\"string:'rating'\", \"T\"], 9]]"}
{"project": "kin-app-server", "commit_sha": "ed19319b5077e0bae081a6898440ac80aff48ddd", "parent_sha": "280e5ff3547b3e280b55c95bb58163fcd0aad432", "file_path": "kinappserver/models/task.py", "project_url": "https://github.com/kinecosystem/kin-app-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -358,7 +358,7 @@ def get_task_details(task_id):\n     task = Task.query.filter_by(task_id=task_id).first()\n     if not task:\n         print('cant find task with task_id %s. using default text' % task_id)\n-        return {'title': 'Delayed Kin', 'desc': '', 'provider': {}}\n+        return {'title': 'Delayed Kin', 'desc': '', 'provider': {\"image_url\": \"https://cdn.kinitapp.com/brand_img/poll_logo_kin.png\", \"name\": \"Kinit Team\"}}\n     return {'title': task.title, 'desc': task.desc, 'provider': task.provider_data}\n \n \n", "before": "return { 'title' : 'Delayed Kin' , 'desc' : '' , 'provider' : { } }", "after": "return { 'title' : 'Delayed Kin' , 'desc' : '' , 'provider' : { \"image_url\" : \"https://cdn.kinitapp.com/brand_img/poll_logo_kin.png\" , \"name\" : \"Kinit Team\" } }", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 65, 3, 67], [\"pair\", \"N0\"], 1], [\"Insert\", [\"dictionary\", 3, 65, 3, 67], [\",:,\", \"T\"], 2], [\"Insert\", [\"dictionary\", 3, 65, 3, 67], [\"pair\", \"N1\"], 3], [\"Insert\", \"N0\", [\"string:\\\"image_url\\\"\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:\\\"https://cdn.kinitapp.com/brand_img/poll_logo_kin.png\\\"\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:\\\"name\\\"\", \"T\"], 0], [\"Insert\", \"N1\", [\":::\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:\\\"Kinit Team\\\"\", \"T\"], 2]]"}
{"project": "git-repo", "commit_sha": "4aa4b211c62a8f01abfe1953b4274af69d374ecf", "parent_sha": "203153e7bba61b1b2d782e9e75aef919eab0d54b", "file_path": "project.py", "project_url": "https://github.com/wangyidong-xiaomi/git-repo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -475,7 +475,7 @@ class RepoHook(object):\n \n       # Exec, storing global context in the context dict.  We catch exceptions\n       # and  convert to a HookError w/ just the failing traceback.\n-      context = {}\n+      context = {'__file__': self._script_fullpath}\n       try:\n         exec(compile(open(self._script_fullpath).read(),\n                      self._script_fullpath, 'exec'), context)\n", "before": "context = { }", "after": "context = { '__file__' : self . _script_fullpath }", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 17, 3, 19], [\"pair\", \"N0\"], 1], [\"Insert\", \"N0\", [\"string:'__file__'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:_script_fullpath\", \"T\"], 2]]"}
{"project": "kundan", "commit_sha": "e2d5ed55f011467017dbde2fbb13f192dcd4bfee", "parent_sha": "ae96ee794e477c4868012efd7298d66f3c55c7b0", "file_path": "bindings/python/ns3modulegen.py", "project_url": "https://github.com/Kundang30/kundan", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -46,7 +46,7 @@ class MyMultiSectionFactory(MultiSectionFactory):\n         self.header_name = \"ns3module.h\"\n         header_file_name = os.path.join(os.path.dirname(self.main_file_name), self.header_name)\n         self.header_sink = FileCodeSink(open(header_file_name, \"wt\"))\n-        self.section_sinks = {}\n+        self.section_sinks = {'__main__': self.main_sink}\n \n         for module in modules:\n             section_name = 'ns3_module_%s' % module.replace('-', '_')\n", "before": "self . section_sinks = { }", "after": "self . section_sinks = { '__main__' : self . main_sink }", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 30, 3, 32], [\"pair\", \"N0\"], 1], [\"Insert\", \"N0\", [\"string:'__main__'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:main_sink\", \"T\"], 2]]"}
{"project": "scipy", "commit_sha": "485d1f046823de5d34a07e97c7661266424589e1", "parent_sha": "8bf68476e05aeb36f6b0ecc7adaad7370b05eb34", "file_path": "scipy/io/wavfile.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -246,7 +246,7 @@ def read(filename, mmap=False):\n                 fmt_chunk = _read_fmt_chunk(fid, is_big_endian)\n                 format_tag, channels, fs = fmt_chunk[1:4]\n                 bit_depth = fmt_chunk[6]\n-                if bit_depth not in (8, 16, 32, 64, 128):\n+                if bit_depth not in (8, 16, 32, 64, 96, 128):\n                     raise ValueError(\"Unsupported bit depth: the wav file \"\n                                      \"has {}-bit data.\".format(bit_depth))\n             elif chunk_id == b'fact':\n", "before": "if bit_depth not in ( 8 , 16 , 32 , 64 , 128 ) : raise ValueError ( \"Unsupported bit depth: the wav file \" \"has {}-bit data.\" . format ( bit_depth ) ) elif chunk_id == b'fact' : ", "after": "if bit_depth not in ( 8 , 16 , 32 , 64 , 96 , 128 ) : raise ValueError ( \"Unsupported bit depth: the wav file \" \"has {}-bit data.\" . format ( bit_depth ) ) elif chunk_id == b'fact' : ", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 37, 3, 57], [\"integer:96\", \"T\"], 9], [\"Insert\", [\"tuple\", 3, 37, 3, 57], [\",:,\", \"T\"], 10]]"}
{"project": "smart-cache", "commit_sha": "635674e6793211619a52d11203cccba3a851d7a3", "parent_sha": "ba906d1bae4034ce0fd071a712c4cf458c44997d", "file_path": "DataManager/collector/dataset/stage.py", "project_url": "https://github.com/Cloud-PG/smart-cache", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -64,7 +64,7 @@ class CMSRawStage(Stage):\n                 ).collect()\n                 for cur_result in tasks_results:\n                     result += cur_result\n-                tasks = []\n+                tasks = [cur_input]\n             else:\n                 if tasks:\n                     tasks_results = sc.parallelize(\n", "before": "tasks = [ ]", "after": "tasks = [ cur_input ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 25, 3, 27], [\"identifier:cur_input\", \"T\"], 1]]"}
{"project": "scipy", "commit_sha": "4801538a18e13a06976265bf46d2d00b69e7d7f1", "parent_sha": "a64595a40960c74c4bac21f395d24a278d83a33a", "file_path": "tools/refguide_check.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -326,7 +326,7 @@ def validate_rst_syntax(text, name, dots=True):\n \n     ok_unknown_items = set([\n         'mod', 'currentmodule', 'autosummary', 'data',\n-        'obj', 'versionadded', 'versionchanged', 'module', 'class',\n+        'obj', 'versionadded', 'versionchanged', 'module', 'class', 'meth',\n         'ref', 'func', 'toctree', 'moduleauthor',\n         'sectionauthor', 'codeauthor', 'eq', 'doi', 'DOI', 'arXiv', 'arxiv'\n     ])\n", "before": "ok_unknown_items = set ( [ 'mod' , 'currentmodule' , 'autosummary' , 'data' , 'obj' , 'versionadded' , 'versionchanged' , 'module' , 'class' , 'ref' , 'func' , 'toctree' , 'moduleauthor' , 'sectionauthor' , 'codeauthor' , 'eq' , 'doi' , 'DOI' , 'arXiv' , 'arxiv' ] )", "after": "ok_unknown_items = set ( [ 'mod' , 'currentmodule' , 'autosummary' , 'data' , 'obj' , 'versionadded' , 'versionchanged' , 'module' , 'class' , 'meth' , 'ref' , 'func' , 'toctree' , 'moduleauthor' , 'sectionauthor' , 'codeauthor' , 'eq' , 'doi' , 'DOI' , 'arXiv' , 'arxiv' ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\",:,\", 2, 14, 2, 15], [\"list\", 1, 28, 6, 6], 33], [\"Insert\", [\"list\", 1, 28, 6, 6], [\",:,\", \"T\"], 2], [\"Insert\", [\"list\", 1, 28, 6, 6], [\"string:'meth'\", \"T\"], 20], [\"Insert\", [\"list\", 1, 28, 6, 6], [\",:,\", \"T\"], 21], [\"Delete\", [\",:,\", 5, 58, 5, 59]]]"}
{"project": "vmware-nsx", "commit_sha": "97e75084cb8818a3830444d06d5ee03fa7e63be7", "parent_sha": "6faeb887bb2a1de008f4215f3cced189789ca20e", "file_path": "neutron/agent/linux/ovs_lib.py", "project_url": "https://github.com/gkotton/vmware-nsx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -476,7 +476,7 @@ def get_installed_ovs_usr_version(root_helper):\n \n \n def get_installed_ovs_klm_version():\n-    args = [\"modinfo\", \"openvswitch\"]\n+    args = [\"modinfo\", \"-F vermagic\", \"openvswitch\"]\n     try:\n         cmd = utils.execute(args)\n         for line in cmd.split('\\n'):\n", "before": "args = [ \"modinfo\" , \"openvswitch\" ]", "after": "args = [ \"modinfo\" , \"-F vermagic\" , \"openvswitch\" ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 12, 3, 38], [\"string:\\\"-F vermagic\\\"\", \"T\"], 3], [\"Insert\", [\"list\", 3, 12, 3, 38], [\",:,\", \"T\"], 4]]"}
{"project": "registration", "commit_sha": "12b4cd8c37342220b07c411c5a49ee32cfb8f7bd", "parent_sha": "d12872d12059b3346bca2b1b793f8896a22aeef5", "file_path": "register/forms.py", "project_url": "https://github.com/HackCU/registration", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ class TypeformFetcher(ApplicationFormFetcher):\n         return self.base_url + self.form_id\n \n     def _fetch(self):\n-        resp = requests.get(self.url, params={'key': typeform_key, 'completed': 'true', 'offset': self.get_offset()})\n+        resp = requests.get(self.url, params={'key': typeform_key, 'limit':'8000', 'completed': 'true', 'offset': self.get_offset()})\n         if resp.status_code != 200:\n             error('The API responded with {}, status code:' + str(resp.status_code))\n             return []\n", "before": "resp = requests . get ( self . url , params = { 'key' : typeform_key , 'completed' : 'true' , 'offset' : self . get_offset ( ) } )", "after": "resp = requests . get ( self . url , params = { 'key' : typeform_key , 'limit' : '8000' , 'completed' : 'true' , 'offset' : self . get_offset ( ) } )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 46, 3, 117], [\"pair\", \"N0\"], 3], [\"Insert\", [\"dictionary\", 3, 46, 3, 117], [\",:,\", \"T\"], 4], [\"Insert\", \"N0\", [\"string:'limit'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'8000'\", \"T\"], 2]]"}
{"project": "sunpy", "commit_sha": "fde5bece6cf7c480adef4499ebf8b8bacc22bc43", "parent_sha": "d34cccb58c7f5d5bc38cf39b88d93f250f1270f4", "file_path": "setup.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -78,7 +78,7 @@ def install(setup): #pylint: disable=W0621\n         maintainer_email=\"sunpy@googlegroups.com\",\n         name=\"sunpy\",\n         packages=find_packages(),\n-        package_data={'': ['*.fits', '*.fit', 'sunpyrc']},\n+        package_data={'': ['*.fits', '*.fit', 'sunpyrc', '*.c', '*.h']},\n         platforms=[\"Windows\", \"Linux\", \"Solaris\", \"Mac OS-X\", \"Unix\"],\n         provides=['sunpy'],\n         url=\"http://www.sunpy.org/\",\n", "before": "package_data = { '' : [ '*.fits' , '*.fit' , 'sunpyrc' ] } ,", "after": "package_data = { '' : [ '*.fits' , '*.fit' , 'sunpyrc' , '*.c' , '*.h' ] } ,", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 27, 3, 57], [\",:,\", \"T\"], 6], [\"Insert\", [\"list\", 3, 27, 3, 57], [\"string:'*.c'\", \"T\"], 7], [\"Insert\", [\"list\", 3, 27, 3, 57], [\",:,\", \"T\"], 8], [\"Insert\", [\"list\", 3, 27, 3, 57], [\"string:'*.h'\", \"T\"], 9]]"}
{"project": "sunpy", "commit_sha": "b9013356ed944c42a3b640a616c7a7913d00687f", "parent_sha": "3e875de79e560fd95d2a2c891514f07803eedb32", "file_path": "sunpy/tests/tests/test_main.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -23,7 +23,7 @@ def test_main_stdlib_module():\n def test_main_noargs(monkeypatch):\n     monkeypatch.setattr(pytest, 'main', lambda x: x)\n     args = sunpy.tests.main()\n-    assert args in (['-k-online', 'sunpy'], [root_dir])\n+    assert args in (['-k-online', 'sunpy'], ['-k-online', root_dir])\n \n \n def test_main_submodule(monkeypatch):\n", "before": "assert args in ( [ '-k-online' , 'sunpy' ] , [ root_dir ] )", "after": "assert args in ( [ '-k-online' , 'sunpy' ] , [ '-k-online' , root_dir ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 45, 3, 55], [\"string:'-k-online'\", \"T\"], 1], [\"Insert\", [\"list\", 3, 45, 3, 55], [\",:,\", \"T\"], 2]]"}
{"project": "sterp", "commit_sha": "d90bba9346e90838a80df9af8aa73ee4dda078cd", "parent_sha": "b0c3bfc454c07c5dd773de22668f2e8236085635", "file_path": "patches/erpnext_structure_cleanup.py", "project_url": "https://github.com/gangadharkadam/sterp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -49,7 +49,7 @@ def delete_unwanted_search_criteria():\n def delete_unwanted_mappers():\n \t\"deletes unwanted mappers\"\n \t\n-\tlst = ['Customer Issue-Maintenance Report', 'Enquiry-Service Quotation', 'Sales Order-Maintenance Report', 'Service Quotation-Service Order', 'Supplier Quotation-Purchase Order', 'Visit Schedule-Maintenance Report']\n+\tlst = ['Customer Issue-Maintenance Report', 'Enquiry-Service Quotation', 'Sales Order-Maintenance Report', 'Service Quotation-Service Order', 'Supplier Quotation-Purchase Order', 'Visit Schedule-Maintenance Report', 'RFQ-Supplier Quotation']\n \tfor d in lst:\n \t\tdelete_doc('DocType Mapper', d)\n \t\t\n", "before": "lst = [ 'Customer Issue-Maintenance Report' , 'Enquiry-Service Quotation' , 'Sales Order-Maintenance Report' , 'Service Quotation-Service Order' , 'Supplier Quotation-Purchase Order' , 'Visit Schedule-Maintenance Report' ]", "after": "lst = [ 'Customer Issue-Maintenance Report' , 'Enquiry-Service Quotation' , 'Sales Order-Maintenance Report' , 'Service Quotation-Service Order' , 'Supplier Quotation-Purchase Order' , 'Visit Schedule-Maintenance Report' , 'RFQ-Supplier Quotation' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 8, 3, 217], [\",:,\", \"T\"], 12], [\"Insert\", [\"list\", 3, 8, 3, 217], [\"string:'RFQ-Supplier Quotation'\", \"T\"], 13]]"}
{"project": "sterp", "commit_sha": "cea316ef94df6a8f5f1e09fb01ad57c6884268f1", "parent_sha": "d90bba9346e90838a80df9af8aa73ee4dda078cd", "file_path": "patches/erpnext_structure_cleanup.py", "project_url": "https://github.com/gangadharkadam/sterp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -49,7 +49,7 @@ def delete_unwanted_search_criteria():\n def delete_unwanted_mappers():\n \t\"deletes unwanted mappers\"\n \t\n-\tlst = ['Customer Issue-Maintenance Report', 'Enquiry-Service Quotation', 'Sales Order-Maintenance Report', 'Service Quotation-Service Order', 'Supplier Quotation-Purchase Order', 'Visit Schedule-Maintenance Report', 'RFQ-Supplier Quotation']\n+\tlst = ['Customer Issue-Maintenance Report', 'Enquiry-Service Quotation', 'Sales Order-Maintenance Report', 'Service Quotation-Service Order', 'Supplier Quotation-Purchase Order', 'Visit Schedule-Maintenance Report', 'RFQ-Supplier Quotation', 'Indent-RFQ']\n \tfor d in lst:\n \t\tdelete_doc('DocType Mapper', d)\n \t\t\n", "before": "lst = [ 'Customer Issue-Maintenance Report' , 'Enquiry-Service Quotation' , 'Sales Order-Maintenance Report' , 'Service Quotation-Service Order' , 'Supplier Quotation-Purchase Order' , 'Visit Schedule-Maintenance Report' , 'RFQ-Supplier Quotation' ]", "after": "lst = [ 'Customer Issue-Maintenance Report' , 'Enquiry-Service Quotation' , 'Sales Order-Maintenance Report' , 'Service Quotation-Service Order' , 'Supplier Quotation-Purchase Order' , 'Visit Schedule-Maintenance Report' , 'RFQ-Supplier Quotation' , 'Indent-RFQ' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 8, 3, 243], [\",:,\", \"T\"], 14], [\"Insert\", [\"list\", 3, 8, 3, 243], [\"string:'Indent-RFQ'\", \"T\"], 15]]"}
{"project": "sterp", "commit_sha": "cb41791af841e8254f2b1bcd1e3e7428dee3cd16", "parent_sha": "cea316ef94df6a8f5f1e09fb01ad57c6884268f1", "file_path": "patches/erpnext_structure_cleanup.py", "project_url": "https://github.com/gangadharkadam/sterp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ sql = webnotes.conn.sql\n def delete_unwanted_doctypes():\n \t\"deletes doctypes which are not used anymore\"\n \t\n-\tlst = ['Zone',  'WN Account Control', 'Wiki Page', 'Wiki History', 'Wiki Control', 'While You Were Out', 'Web Visitor', 'Tweet', 'Transfer Utility', 'Transfer Module', 'Transfer Control', 'Transfer Account', 'Tips Common', 'TestTabDT', 'TestDT', 'Test Type', 'Test Run', 'Test Record Detail', 'Test Record', 'Test Case', 'Supplier TDS Category Detail', 'Shopping Cart Control', 'Service Series', 'Series Detail', 'Rule Engine', 'RFQ', 'Report Filter Detail', 'Report Field Detail','Report Control', 'Rating Widget Record', 'Rating Widget Control', 'Rating Template Detail', 'Rating Template', 'PV Ded Tax Detail', 'PV Add Tax Detail', 'Product Variant', 'Product Variance', 'Product Group', 'Product Feature', 'Payroll Tips Common', 'Payroll Rule', 'Password Control', 'Page Visit', 'Patch', 'Multiple Transfer', 'Module Tip Control', 'Module Setter', 'Module Manager', 'Module Import', 'Module Detail', 'Message Control', 'Message', 'Mail Participant Details', 'Mail', 'Leave Type Detail', 'Leave Detail', 'Leave Applicable Detail', 'Lead Item Detail', 'Lead Attachment Detail', 'Item Attachments Detail', 'Instant Message', 'Impact Analysis', 'Forum Topic', 'Forum Control', 'Form Settings', 'Follower', 'ERP Setup', 'Enquiry Attachment Detail', 'Documentation', 'Condition Detail', 'Complaint Note', 'Code History', 'Code Editor', 'Code Backup Control', 'Code Backup', 'City', 'Change Log', 'Business Letter Type', 'Business Letter Template', 'Business Letter', 'Badge Settings Detail', 'Application Type', 'Application', 'Action Detail', 'Accounts Setup', 'Stock Common', 'Job Application', 'Service Schedule', 'Comment Control', 'Bank', 'Tag Widget Control'] # bank\n+\tlst = ['Zone',  'WN Account Control', 'Wiki Page', 'Wiki History', 'Wiki Control', 'While You Were Out', 'Web Visitor', 'Tweet', 'Transfer Utility', 'Transfer Module', 'Transfer Control', 'Transfer Account', 'Tips Common', 'TestTabDT', 'TestDT', 'Test Type', 'Test Run', 'Test Record Detail', 'Test Record', 'Test Case', 'Supplier TDS Category Detail', 'Shopping Cart Control', 'Service Series', 'Series Detail', 'Rule Engine', 'RFQ', 'Report Filter Detail', 'Report Field Detail','Report Control', 'Rating Widget Record', 'Rating Widget Control', 'Rating Template Detail', 'Rating Template', 'PV Ded Tax Detail', 'PV Add Tax Detail', 'Product Variant', 'Product Variance', 'Product Group', 'Product Feature', 'Payroll Tips Common', 'Payroll Rule', 'Password Control', 'Page Visit', 'Patch', 'Multiple Transfer', 'Module Tip Control', 'Module Setter', 'Module Manager', 'Module Import', 'Module Detail', 'Message Control', 'Message', 'Mail Participant Details', 'Mail', 'Leave Type Detail', 'Leave Detail', 'Leave Applicable Detail', 'Lead Item Detail', 'Lead Attachment Detail', 'Item Attachments Detail', 'Instant Message', 'Impact Analysis', 'Forum Topic', 'Forum Control', 'Form Settings', 'Follower', 'ERP Setup', 'Enquiry Attachment Detail', 'Documentation', 'Condition Detail', 'Complaint Note', 'Code History', 'Code Editor', 'Code Backup Control', 'Code Backup', 'City', 'Change Log', 'Business Letter Type', 'Business Letter Template', 'Business Letter', 'Badge Settings Detail', 'Application Type', 'Application', 'Action Detail', 'Accounts Setup', 'Stock Common', 'Job Application', 'Service Schedule', 'Comment Control', 'Bank', 'Tag Widget Control', 'Feature Update'] # bank\n \tfor d in lst:\n \t\tsql(\"delete from `tabProperty Setter` where select_doctype = '%s'\" % d)\n \t\tsql(\"delete from `tabCustom Script` where dt = '%s'\" % d)\n", "before": "lst = [ 'Zone' , 'WN Account Control' , 'Wiki Page' , 'Wiki History' , 'Wiki Control' , 'While You Were Out' , 'Web Visitor' , 'Tweet' , 'Transfer Utility' , 'Transfer Module' , 'Transfer Control' , 'Transfer Account' , 'Tips Common' , 'TestTabDT' , 'TestDT' , 'Test Type' , 'Test Run' , 'Test Record Detail' , 'Test Record' , 'Test Case' , 'Supplier TDS Category Detail' , 'Shopping Cart Control' , 'Service Series' , 'Series Detail' , 'Rule Engine' , 'RFQ' , 'Report Filter Detail' , 'Report Field Detail' , 'Report Control' , 'Rating Widget Record' , 'Rating Widget Control' , 'Rating Template Detail' , 'Rating Template' , 'PV Ded Tax Detail' , 'PV Add Tax Detail' , 'Product Variant' , 'Product Variance' , 'Product Group' , 'Product Feature' , 'Payroll Tips Common' , 'Payroll Rule' , 'Password Control' , 'Page Visit' , 'Patch' , 'Multiple Transfer' , 'Module Tip Control' , 'Module Setter' , 'Module Manager' , 'Module Import' , 'Module Detail' , 'Message Control' , 'Message' , 'Mail Participant Details' , 'Mail' , 'Leave Type Detail' , 'Leave Detail' , 'Leave Applicable Detail' , 'Lead Item Detail' , 'Lead Attachment Detail' , 'Item Attachments Detail' , 'Instant Message' , 'Impact Analysis' , 'Forum Topic' , 'Forum Control' , 'Form Settings' , 'Follower' , 'ERP Setup' , 'Enquiry Attachment Detail' , 'Documentation' , 'Condition Detail' , 'Complaint Note' , 'Code History' , 'Code Editor' , 'Code Backup Control' , 'Code Backup' , 'City' , 'Change Log' , 'Business Letter Type' , 'Business Letter Template' , 'Business Letter' , 'Badge Settings Detail' , 'Application Type' , 'Application' , 'Action Detail' , 'Accounts Setup' , 'Stock Common' , 'Job Application' , 'Service Schedule' , 'Comment Control' , 'Bank' , 'Tag Widget Control' ]", "after": "lst = [ 'Zone' , 'WN Account Control' , 'Wiki Page' , 'Wiki History' , 'Wiki Control' , 'While You Were Out' , 'Web Visitor' , 'Tweet' , 'Transfer Utility' , 'Transfer Module' , 'Transfer Control' , 'Transfer Account' , 'Tips Common' , 'TestTabDT' , 'TestDT' , 'Test Type' , 'Test Run' , 'Test Record Detail' , 'Test Record' , 'Test Case' , 'Supplier TDS Category Detail' , 'Shopping Cart Control' , 'Service Series' , 'Series Detail' , 'Rule Engine' , 'RFQ' , 'Report Filter Detail' , 'Report Field Detail' , 'Report Control' , 'Rating Widget Record' , 'Rating Widget Control' , 'Rating Template Detail' , 'Rating Template' , 'PV Ded Tax Detail' , 'PV Add Tax Detail' , 'Product Variant' , 'Product Variance' , 'Product Group' , 'Product Feature' , 'Payroll Tips Common' , 'Payroll Rule' , 'Password Control' , 'Page Visit' , 'Patch' , 'Multiple Transfer' , 'Module Tip Control' , 'Module Setter' , 'Module Manager' , 'Module Import' , 'Module Detail' , 'Message Control' , 'Message' , 'Mail Participant Details' , 'Mail' , 'Leave Type Detail' , 'Leave Detail' , 'Leave Applicable Detail' , 'Lead Item Detail' , 'Lead Attachment Detail' , 'Item Attachments Detail' , 'Instant Message' , 'Impact Analysis' , 'Forum Topic' , 'Forum Control' , 'Form Settings' , 'Follower' , 'ERP Setup' , 'Enquiry Attachment Detail' , 'Documentation' , 'Condition Detail' , 'Complaint Note' , 'Code History' , 'Code Editor' , 'Code Backup Control' , 'Code Backup' , 'City' , 'Change Log' , 'Business Letter Type' , 'Business Letter Template' , 'Business Letter' , 'Badge Settings Detail' , 'Application Type' , 'Application' , 'Action Detail' , 'Accounts Setup' , 'Stock Common' , 'Job Application' , 'Service Schedule' , 'Comment Control' , 'Bank' , 'Tag Widget Control' , 'Feature Update' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 8, 3, 1665], [\",:,\", \"T\"], 182], [\"Insert\", [\"list\", 3, 8, 3, 1665], [\"string:'Feature Update'\", \"T\"], 183]]"}
{"project": "sterp", "commit_sha": "46be449f9c224d6e816433efe4f474619bb00c35", "parent_sha": "cb41791af841e8254f2b1bcd1e3e7428dee3cd16", "file_path": "patches/erpnext_structure_cleanup.py", "project_url": "https://github.com/gangadharkadam/sterp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -147,7 +147,7 @@ def sync_mapper():\n #---------------------------------------\n def run_patches():\n \t# update module\n-\tdt_module = {'LC PR Detail':'Stock', 'Landed Cost Detail':'Stock', 'Comment Widget Record': 'Core', 'Tag':'Core', 'Tag Detail': 'Core'}\n+\tdt_module = {'LC PR Detail':'Stock', 'Landed Cost Detail':'Stock', 'Comment Widget Record': 'Core', 'Tag':'Core', 'Tag Detail': 'Core', 'POS Settings': 'Accounts'}\n \tfor d in dt_module.keys():\n \t\tsql(\"update `tabDocType` set module = '%s' where name = '%s'\" % (dt_module[d], d))\n \tdelete_unwanted_mappers()\n", "before": "dt_module = { 'LC PR Detail' : 'Stock' , 'Landed Cost Detail' : 'Stock' , 'Comment Widget Record' : 'Core' , 'Tag' : 'Core' , 'Tag Detail' : 'Core' }", "after": "dt_module = { 'LC PR Detail' : 'Stock' , 'Landed Cost Detail' : 'Stock' , 'Comment Widget Record' : 'Core' , 'Tag' : 'Core' , 'Tag Detail' : 'Core' , 'POS Settings' : 'Accounts' }", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 14, 3, 137], [\",:,\", \"T\"], 10], [\"Insert\", [\"dictionary\", 3, 14, 3, 137], [\"pair\", \"N0\"], 11], [\"Insert\", \"N0\", [\"string:'POS Settings'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'Accounts'\", \"T\"], 2]]"}
{"project": "sterp", "commit_sha": "cc04b7913a7e1c5df726dabe56afcb2a775572d3", "parent_sha": "46be449f9c224d6e816433efe4f474619bb00c35", "file_path": "patches/erpnext_structure_cleanup.py", "project_url": "https://github.com/gangadharkadam/sterp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ sql = webnotes.conn.sql\n def delete_unwanted_doctypes():\n \t\"deletes doctypes which are not used anymore\"\n \t\n-\tlst = ['Zone',  'WN Account Control', 'Wiki Page', 'Wiki History', 'Wiki Control', 'While You Were Out', 'Web Visitor', 'Tweet', 'Transfer Utility', 'Transfer Module', 'Transfer Control', 'Transfer Account', 'Tips Common', 'TestTabDT', 'TestDT', 'Test Type', 'Test Run', 'Test Record Detail', 'Test Record', 'Test Case', 'Supplier TDS Category Detail', 'Shopping Cart Control', 'Service Series', 'Series Detail', 'Rule Engine', 'RFQ', 'Report Filter Detail', 'Report Field Detail','Report Control', 'Rating Widget Record', 'Rating Widget Control', 'Rating Template Detail', 'Rating Template', 'PV Ded Tax Detail', 'PV Add Tax Detail', 'Product Variant', 'Product Variance', 'Product Group', 'Product Feature', 'Payroll Tips Common', 'Payroll Rule', 'Password Control', 'Page Visit', 'Patch', 'Multiple Transfer', 'Module Tip Control', 'Module Setter', 'Module Manager', 'Module Import', 'Module Detail', 'Message Control', 'Message', 'Mail Participant Details', 'Mail', 'Leave Type Detail', 'Leave Detail', 'Leave Applicable Detail', 'Lead Item Detail', 'Lead Attachment Detail', 'Item Attachments Detail', 'Instant Message', 'Impact Analysis', 'Forum Topic', 'Forum Control', 'Form Settings', 'Follower', 'ERP Setup', 'Enquiry Attachment Detail', 'Documentation', 'Condition Detail', 'Complaint Note', 'Code History', 'Code Editor', 'Code Backup Control', 'Code Backup', 'City', 'Change Log', 'Business Letter Type', 'Business Letter Template', 'Business Letter', 'Badge Settings Detail', 'Application Type', 'Application', 'Action Detail', 'Accounts Setup', 'Stock Common', 'Job Application', 'Service Schedule', 'Comment Control', 'Bank', 'Tag Widget Control', 'Feature Update'] # bank\n+\tlst = ['Zone',  'WN Account Control', 'Wiki Page', 'Wiki History', 'Wiki Control', 'While You Were Out', 'Web Visitor', 'Tweet', 'Transfer Utility', 'Transfer Module', 'Transfer Control', 'Transfer Account', 'Tips Common', 'TestTabDT', 'TestDT', 'Test Type', 'Test Run', 'Test Record Detail', 'Test Record', 'Test Case', 'Supplier TDS Category Detail', 'Shopping Cart Control', 'Service Series', 'Series Detail', 'Rule Engine', 'RFQ', 'Report Filter Detail', 'Report Field Detail','Report Control', 'Rating Widget Record', 'Rating Widget Control', 'Rating Template Detail', 'Rating Template', 'PV Ded Tax Detail', 'PV Add Tax Detail', 'Product Variant', 'Product Variance', 'Product Group', 'Product Feature', 'Payroll Tips Common', 'Payroll Rule', 'Password Control', 'Page Visit', 'Patch', 'Multiple Transfer', 'Module Tip Control', 'Module Setter', 'Module Manager', 'Module Import', 'Module Detail', 'Message Control', 'Message', 'Mail Participant Details', 'Mail', 'Leave Type Detail', 'Leave Detail', 'Leave Applicable Detail', 'Lead Item Detail', 'Lead Attachment Detail', 'Item Attachments Detail', 'Instant Message', 'Impact Analysis', 'Forum Topic', 'Forum Control', 'Form Settings', 'Follower', 'ERP Setup', 'Enquiry Attachment Detail', 'Documentation', 'Condition Detail', 'Complaint Note', 'Code History', 'Code Editor', 'Code Backup Control', 'Code Backup', 'City', 'Change Log', 'Business Letter Type', 'Business Letter Template', 'Business Letter', 'Badge Settings Detail', 'Application Type', 'Application', 'Action Detail', 'Accounts Setup', 'Stock Common', 'Job Application', 'Service Schedule', 'Comment Control', 'Bank', 'Tag Widget Control', 'Feature Update', 'RFQ Detail'] # bank\n \tfor d in lst:\n \t\tsql(\"delete from `tabProperty Setter` where select_doctype = '%s'\" % d)\n \t\tsql(\"delete from `tabCustom Script` where dt = '%s'\" % d)\n", "before": "lst = [ 'Zone' , 'WN Account Control' , 'Wiki Page' , 'Wiki History' , 'Wiki Control' , 'While You Were Out' , 'Web Visitor' , 'Tweet' , 'Transfer Utility' , 'Transfer Module' , 'Transfer Control' , 'Transfer Account' , 'Tips Common' , 'TestTabDT' , 'TestDT' , 'Test Type' , 'Test Run' , 'Test Record Detail' , 'Test Record' , 'Test Case' , 'Supplier TDS Category Detail' , 'Shopping Cart Control' , 'Service Series' , 'Series Detail' , 'Rule Engine' , 'RFQ' , 'Report Filter Detail' , 'Report Field Detail' , 'Report Control' , 'Rating Widget Record' , 'Rating Widget Control' , 'Rating Template Detail' , 'Rating Template' , 'PV Ded Tax Detail' , 'PV Add Tax Detail' , 'Product Variant' , 'Product Variance' , 'Product Group' , 'Product Feature' , 'Payroll Tips Common' , 'Payroll Rule' , 'Password Control' , 'Page Visit' , 'Patch' , 'Multiple Transfer' , 'Module Tip Control' , 'Module Setter' , 'Module Manager' , 'Module Import' , 'Module Detail' , 'Message Control' , 'Message' , 'Mail Participant Details' , 'Mail' , 'Leave Type Detail' , 'Leave Detail' , 'Leave Applicable Detail' , 'Lead Item Detail' , 'Lead Attachment Detail' , 'Item Attachments Detail' , 'Instant Message' , 'Impact Analysis' , 'Forum Topic' , 'Forum Control' , 'Form Settings' , 'Follower' , 'ERP Setup' , 'Enquiry Attachment Detail' , 'Documentation' , 'Condition Detail' , 'Complaint Note' , 'Code History' , 'Code Editor' , 'Code Backup Control' , 'Code Backup' , 'City' , 'Change Log' , 'Business Letter Type' , 'Business Letter Template' , 'Business Letter' , 'Badge Settings Detail' , 'Application Type' , 'Application' , 'Action Detail' , 'Accounts Setup' , 'Stock Common' , 'Job Application' , 'Service Schedule' , 'Comment Control' , 'Bank' , 'Tag Widget Control' , 'Feature Update' ]", "after": "lst = [ 'Zone' , 'WN Account Control' , 'Wiki Page' , 'Wiki History' , 'Wiki Control' , 'While You Were Out' , 'Web Visitor' , 'Tweet' , 'Transfer Utility' , 'Transfer Module' , 'Transfer Control' , 'Transfer Account' , 'Tips Common' , 'TestTabDT' , 'TestDT' , 'Test Type' , 'Test Run' , 'Test Record Detail' , 'Test Record' , 'Test Case' , 'Supplier TDS Category Detail' , 'Shopping Cart Control' , 'Service Series' , 'Series Detail' , 'Rule Engine' , 'RFQ' , 'Report Filter Detail' , 'Report Field Detail' , 'Report Control' , 'Rating Widget Record' , 'Rating Widget Control' , 'Rating Template Detail' , 'Rating Template' , 'PV Ded Tax Detail' , 'PV Add Tax Detail' , 'Product Variant' , 'Product Variance' , 'Product Group' , 'Product Feature' , 'Payroll Tips Common' , 'Payroll Rule' , 'Password Control' , 'Page Visit' , 'Patch' , 'Multiple Transfer' , 'Module Tip Control' , 'Module Setter' , 'Module Manager' , 'Module Import' , 'Module Detail' , 'Message Control' , 'Message' , 'Mail Participant Details' , 'Mail' , 'Leave Type Detail' , 'Leave Detail' , 'Leave Applicable Detail' , 'Lead Item Detail' , 'Lead Attachment Detail' , 'Item Attachments Detail' , 'Instant Message' , 'Impact Analysis' , 'Forum Topic' , 'Forum Control' , 'Form Settings' , 'Follower' , 'ERP Setup' , 'Enquiry Attachment Detail' , 'Documentation' , 'Condition Detail' , 'Complaint Note' , 'Code History' , 'Code Editor' , 'Code Backup Control' , 'Code Backup' , 'City' , 'Change Log' , 'Business Letter Type' , 'Business Letter Template' , 'Business Letter' , 'Badge Settings Detail' , 'Application Type' , 'Application' , 'Action Detail' , 'Accounts Setup' , 'Stock Common' , 'Job Application' , 'Service Schedule' , 'Comment Control' , 'Bank' , 'Tag Widget Control' , 'Feature Update' , 'RFQ Detail' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 8, 3, 1683], [\",:,\", \"T\"], 184], [\"Insert\", [\"list\", 3, 8, 3, 1683], [\"string:'RFQ Detail'\", \"T\"], 185]]"}
{"project": "sterp", "commit_sha": "82567b01ec7b1a9e2b466d1b4169812811fdee27", "parent_sha": "cc04b7913a7e1c5df726dabe56afcb2a775572d3", "file_path": "patches/erpnext_structure_cleanup.py", "project_url": "https://github.com/gangadharkadam/sterp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ sql = webnotes.conn.sql\n def delete_unwanted_doctypes():\n \t\"deletes doctypes which are not used anymore\"\n \t\n-\tlst = ['Zone',  'WN Account Control', 'Wiki Page', 'Wiki History', 'Wiki Control', 'While You Were Out', 'Web Visitor', 'Tweet', 'Transfer Utility', 'Transfer Module', 'Transfer Control', 'Transfer Account', 'Tips Common', 'TestTabDT', 'TestDT', 'Test Type', 'Test Run', 'Test Record Detail', 'Test Record', 'Test Case', 'Supplier TDS Category Detail', 'Shopping Cart Control', 'Service Series', 'Series Detail', 'Rule Engine', 'RFQ', 'Report Filter Detail', 'Report Field Detail','Report Control', 'Rating Widget Record', 'Rating Widget Control', 'Rating Template Detail', 'Rating Template', 'PV Ded Tax Detail', 'PV Add Tax Detail', 'Product Variant', 'Product Variance', 'Product Group', 'Product Feature', 'Payroll Tips Common', 'Payroll Rule', 'Password Control', 'Page Visit', 'Patch', 'Multiple Transfer', 'Module Tip Control', 'Module Setter', 'Module Manager', 'Module Import', 'Module Detail', 'Message Control', 'Message', 'Mail Participant Details', 'Mail', 'Leave Type Detail', 'Leave Detail', 'Leave Applicable Detail', 'Lead Item Detail', 'Lead Attachment Detail', 'Item Attachments Detail', 'Instant Message', 'Impact Analysis', 'Forum Topic', 'Forum Control', 'Form Settings', 'Follower', 'ERP Setup', 'Enquiry Attachment Detail', 'Documentation', 'Condition Detail', 'Complaint Note', 'Code History', 'Code Editor', 'Code Backup Control', 'Code Backup', 'City', 'Change Log', 'Business Letter Type', 'Business Letter Template', 'Business Letter', 'Badge Settings Detail', 'Application Type', 'Application', 'Action Detail', 'Accounts Setup', 'Stock Common', 'Job Application', 'Service Schedule', 'Comment Control', 'Bank', 'Tag Widget Control', 'Feature Update', 'RFQ Detail'] # bank\n+\tlst = ['Zone',  'WN Account Control', 'Wiki Page', 'Wiki History', 'Wiki Control', 'While You Were Out', 'Web Visitor', 'Tweet', 'Transfer Utility', 'Transfer Module', 'Transfer Control', 'Transfer Account', 'Tips Common', 'TestTabDT', 'TestDT', 'Test Type', 'Test Run', 'Test Record Detail', 'Test Record', 'Test Case', 'Supplier TDS Category Detail', 'Shopping Cart Control', 'Service Series', 'Series Detail', 'Rule Engine', 'RFQ', 'Report Filter Detail', 'Report Field Detail','Report Control', 'Rating Widget Record', 'Rating Widget Control', 'Rating Template Detail', 'Rating Template', 'PV Ded Tax Detail', 'PV Add Tax Detail', 'Product Variant', 'Product Variance', 'Product Group', 'Product Feature', 'Payroll Tips Common', 'Payroll Rule', 'Password Control', 'Page Visit', 'Patch', 'Multiple Transfer', 'Module Tip Control', 'Module Setter', 'Module Manager', 'Module Import', 'Module Detail', 'Message Control', 'Message', 'Mail Participant Details', 'Mail', 'Leave Type Detail', 'Leave Detail', 'Leave Applicable Detail', 'Lead Item Detail', 'Lead Attachment Detail', 'Item Attachments Detail', 'Instant Message', 'Impact Analysis', 'Forum Topic', 'Forum Control', 'Form Settings', 'Follower', 'ERP Setup', 'Enquiry Attachment Detail', 'Documentation', 'Condition Detail', 'Complaint Note', 'Code History', 'Code Editor', 'Code Backup Control', 'Code Backup', 'City', 'Change Log', 'Business Letter Type', 'Business Letter Template', 'Business Letter', 'Badge Settings Detail', 'Application Type', 'Application', 'Action Detail', 'Accounts Setup', 'Stock Common', 'Job Application', 'Service Schedule', 'Comment Control', 'Bank', 'Tag Widget Control', 'Feature Update', 'RFQ Detail', 'Supplier Quotation Detail', 'Supplier Quotation'] # bank\n \tfor d in lst:\n \t\tsql(\"delete from `tabProperty Setter` where select_doctype = '%s'\" % d)\n \t\tsql(\"delete from `tabCustom Script` where dt = '%s'\" % d)\n", "before": "lst = [ 'Zone' , 'WN Account Control' , 'Wiki Page' , 'Wiki History' , 'Wiki Control' , 'While You Were Out' , 'Web Visitor' , 'Tweet' , 'Transfer Utility' , 'Transfer Module' , 'Transfer Control' , 'Transfer Account' , 'Tips Common' , 'TestTabDT' , 'TestDT' , 'Test Type' , 'Test Run' , 'Test Record Detail' , 'Test Record' , 'Test Case' , 'Supplier TDS Category Detail' , 'Shopping Cart Control' , 'Service Series' , 'Series Detail' , 'Rule Engine' , 'RFQ' , 'Report Filter Detail' , 'Report Field Detail' , 'Report Control' , 'Rating Widget Record' , 'Rating Widget Control' , 'Rating Template Detail' , 'Rating Template' , 'PV Ded Tax Detail' , 'PV Add Tax Detail' , 'Product Variant' , 'Product Variance' , 'Product Group' , 'Product Feature' , 'Payroll Tips Common' , 'Payroll Rule' , 'Password Control' , 'Page Visit' , 'Patch' , 'Multiple Transfer' , 'Module Tip Control' , 'Module Setter' , 'Module Manager' , 'Module Import' , 'Module Detail' , 'Message Control' , 'Message' , 'Mail Participant Details' , 'Mail' , 'Leave Type Detail' , 'Leave Detail' , 'Leave Applicable Detail' , 'Lead Item Detail' , 'Lead Attachment Detail' , 'Item Attachments Detail' , 'Instant Message' , 'Impact Analysis' , 'Forum Topic' , 'Forum Control' , 'Form Settings' , 'Follower' , 'ERP Setup' , 'Enquiry Attachment Detail' , 'Documentation' , 'Condition Detail' , 'Complaint Note' , 'Code History' , 'Code Editor' , 'Code Backup Control' , 'Code Backup' , 'City' , 'Change Log' , 'Business Letter Type' , 'Business Letter Template' , 'Business Letter' , 'Badge Settings Detail' , 'Application Type' , 'Application' , 'Action Detail' , 'Accounts Setup' , 'Stock Common' , 'Job Application' , 'Service Schedule' , 'Comment Control' , 'Bank' , 'Tag Widget Control' , 'Feature Update' , 'RFQ Detail' ]", "after": "lst = [ 'Zone' , 'WN Account Control' , 'Wiki Page' , 'Wiki History' , 'Wiki Control' , 'While You Were Out' , 'Web Visitor' , 'Tweet' , 'Transfer Utility' , 'Transfer Module' , 'Transfer Control' , 'Transfer Account' , 'Tips Common' , 'TestTabDT' , 'TestDT' , 'Test Type' , 'Test Run' , 'Test Record Detail' , 'Test Record' , 'Test Case' , 'Supplier TDS Category Detail' , 'Shopping Cart Control' , 'Service Series' , 'Series Detail' , 'Rule Engine' , 'RFQ' , 'Report Filter Detail' , 'Report Field Detail' , 'Report Control' , 'Rating Widget Record' , 'Rating Widget Control' , 'Rating Template Detail' , 'Rating Template' , 'PV Ded Tax Detail' , 'PV Add Tax Detail' , 'Product Variant' , 'Product Variance' , 'Product Group' , 'Product Feature' , 'Payroll Tips Common' , 'Payroll Rule' , 'Password Control' , 'Page Visit' , 'Patch' , 'Multiple Transfer' , 'Module Tip Control' , 'Module Setter' , 'Module Manager' , 'Module Import' , 'Module Detail' , 'Message Control' , 'Message' , 'Mail Participant Details' , 'Mail' , 'Leave Type Detail' , 'Leave Detail' , 'Leave Applicable Detail' , 'Lead Item Detail' , 'Lead Attachment Detail' , 'Item Attachments Detail' , 'Instant Message' , 'Impact Analysis' , 'Forum Topic' , 'Forum Control' , 'Form Settings' , 'Follower' , 'ERP Setup' , 'Enquiry Attachment Detail' , 'Documentation' , 'Condition Detail' , 'Complaint Note' , 'Code History' , 'Code Editor' , 'Code Backup Control' , 'Code Backup' , 'City' , 'Change Log' , 'Business Letter Type' , 'Business Letter Template' , 'Business Letter' , 'Badge Settings Detail' , 'Application Type' , 'Application' , 'Action Detail' , 'Accounts Setup' , 'Stock Common' , 'Job Application' , 'Service Schedule' , 'Comment Control' , 'Bank' , 'Tag Widget Control' , 'Feature Update' , 'RFQ Detail' , 'Supplier Quotation Detail' , 'Supplier Quotation' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 8, 3, 1697], [\",:,\", \"T\"], 186], [\"Insert\", [\"list\", 3, 8, 3, 1697], [\"string:'Supplier Quotation Detail'\", \"T\"], 187], [\"Insert\", [\"list\", 3, 8, 3, 1697], [\",:,\", \"T\"], 188], [\"Insert\", [\"list\", 3, 8, 3, 1697], [\"string:'Supplier Quotation'\", \"T\"], 189]]"}
{"project": "sterp", "commit_sha": "d6660c0a06935135b9b6e1318290d5bc127a3096", "parent_sha": "82567b01ec7b1a9e2b466d1b4169812811fdee27", "file_path": "patches/erpnext_structure_cleanup.py", "project_url": "https://github.com/gangadharkadam/sterp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ sql = webnotes.conn.sql\n def delete_unwanted_doctypes():\n \t\"deletes doctypes which are not used anymore\"\n \t\n-\tlst = ['Zone',  'WN Account Control', 'Wiki Page', 'Wiki History', 'Wiki Control', 'While You Were Out', 'Web Visitor', 'Tweet', 'Transfer Utility', 'Transfer Module', 'Transfer Control', 'Transfer Account', 'Tips Common', 'TestTabDT', 'TestDT', 'Test Type', 'Test Run', 'Test Record Detail', 'Test Record', 'Test Case', 'Supplier TDS Category Detail', 'Shopping Cart Control', 'Service Series', 'Series Detail', 'Rule Engine', 'RFQ', 'Report Filter Detail', 'Report Field Detail','Report Control', 'Rating Widget Record', 'Rating Widget Control', 'Rating Template Detail', 'Rating Template', 'PV Ded Tax Detail', 'PV Add Tax Detail', 'Product Variant', 'Product Variance', 'Product Group', 'Product Feature', 'Payroll Tips Common', 'Payroll Rule', 'Password Control', 'Page Visit', 'Patch', 'Multiple Transfer', 'Module Tip Control', 'Module Setter', 'Module Manager', 'Module Import', 'Module Detail', 'Message Control', 'Message', 'Mail Participant Details', 'Mail', 'Leave Type Detail', 'Leave Detail', 'Leave Applicable Detail', 'Lead Item Detail', 'Lead Attachment Detail', 'Item Attachments Detail', 'Instant Message', 'Impact Analysis', 'Forum Topic', 'Forum Control', 'Form Settings', 'Follower', 'ERP Setup', 'Enquiry Attachment Detail', 'Documentation', 'Condition Detail', 'Complaint Note', 'Code History', 'Code Editor', 'Code Backup Control', 'Code Backup', 'City', 'Change Log', 'Business Letter Type', 'Business Letter Template', 'Business Letter', 'Badge Settings Detail', 'Application Type', 'Application', 'Action Detail', 'Accounts Setup', 'Stock Common', 'Job Application', 'Service Schedule', 'Comment Control', 'Bank', 'Tag Widget Control', 'Feature Update', 'RFQ Detail', 'Supplier Quotation Detail', 'Supplier Quotation'] # bank\n+\tlst = ['Zone',  'WN Account Control', 'Wiki Page', 'Wiki History', 'Wiki Control', 'While You Were Out', 'Web Visitor', 'Tweet', 'Transfer Utility', 'Transfer Module', 'Transfer Control', 'Transfer Account', 'Tips Common', 'TestTabDT', 'TestDT', 'Test Type', 'Test Run', 'Test Record Detail', 'Test Record', 'Test Case', 'Supplier TDS Category Detail', 'Shopping Cart Control', 'Service Series', 'Series Detail', 'Rule Engine', 'RFQ', 'Report Filter Detail', 'Report Field Detail','Report Control', 'Rating Widget Record', 'Rating Widget Control', 'Rating Template Detail', 'Rating Template', 'PV Ded Tax Detail', 'PV Add Tax Detail', 'Product Variant', 'Product Variance', 'Product Group', 'Product Feature', 'Payroll Tips Common', 'Payroll Rule', 'Password Control', 'Page Visit', 'Patch', 'Multiple Transfer', 'Module Tip Control', 'Module Setter', 'Module Manager', 'Module Import', 'Module Detail', 'Message Control', 'Message', 'Mail Participant Details', 'Mail', 'Leave Type Detail', 'Leave Detail', 'Leave Applicable Detail', 'Lead Item Detail', 'Lead Attachment Detail', 'Item Attachments Detail', 'Instant Message', 'Impact Analysis', 'Forum Topic', 'Forum Control', 'Form Settings', 'Follower', 'ERP Setup', 'Enquiry Attachment Detail', 'Documentation', 'Condition Detail', 'Complaint Note', 'Code History', 'Code Editor', 'Code Backup Control', 'Code Backup', 'City', 'Change Log', 'Business Letter Type', 'Business Letter Template', 'Business Letter', 'Badge Settings Detail', 'Application Type', 'Application', 'Action Detail', 'Accounts Setup', 'Stock Common', 'Job Application', 'Service Schedule', 'Comment Control', 'Bank', 'Tag Widget Control', 'Feature Update', 'RFQ Detail', 'Supplier Quotation Detail', 'Supplier Quotation', 'Year Closing Voucher'] # bank\n \tfor d in lst:\n \t\tsql(\"delete from `tabProperty Setter` where select_doctype = '%s'\" % d)\n \t\tsql(\"delete from `tabCustom Script` where dt = '%s'\" % d)\n", "before": "lst = [ 'Zone' , 'WN Account Control' , 'Wiki Page' , 'Wiki History' , 'Wiki Control' , 'While You Were Out' , 'Web Visitor' , 'Tweet' , 'Transfer Utility' , 'Transfer Module' , 'Transfer Control' , 'Transfer Account' , 'Tips Common' , 'TestTabDT' , 'TestDT' , 'Test Type' , 'Test Run' , 'Test Record Detail' , 'Test Record' , 'Test Case' , 'Supplier TDS Category Detail' , 'Shopping Cart Control' , 'Service Series' , 'Series Detail' , 'Rule Engine' , 'RFQ' , 'Report Filter Detail' , 'Report Field Detail' , 'Report Control' , 'Rating Widget Record' , 'Rating Widget Control' , 'Rating Template Detail' , 'Rating Template' , 'PV Ded Tax Detail' , 'PV Add Tax Detail' , 'Product Variant' , 'Product Variance' , 'Product Group' , 'Product Feature' , 'Payroll Tips Common' , 'Payroll Rule' , 'Password Control' , 'Page Visit' , 'Patch' , 'Multiple Transfer' , 'Module Tip Control' , 'Module Setter' , 'Module Manager' , 'Module Import' , 'Module Detail' , 'Message Control' , 'Message' , 'Mail Participant Details' , 'Mail' , 'Leave Type Detail' , 'Leave Detail' , 'Leave Applicable Detail' , 'Lead Item Detail' , 'Lead Attachment Detail' , 'Item Attachments Detail' , 'Instant Message' , 'Impact Analysis' , 'Forum Topic' , 'Forum Control' , 'Form Settings' , 'Follower' , 'ERP Setup' , 'Enquiry Attachment Detail' , 'Documentation' , 'Condition Detail' , 'Complaint Note' , 'Code History' , 'Code Editor' , 'Code Backup Control' , 'Code Backup' , 'City' , 'Change Log' , 'Business Letter Type' , 'Business Letter Template' , 'Business Letter' , 'Badge Settings Detail' , 'Application Type' , 'Application' , 'Action Detail' , 'Accounts Setup' , 'Stock Common' , 'Job Application' , 'Service Schedule' , 'Comment Control' , 'Bank' , 'Tag Widget Control' , 'Feature Update' , 'RFQ Detail' , 'Supplier Quotation Detail' , 'Supplier Quotation' ]", "after": "lst = [ 'Zone' , 'WN Account Control' , 'Wiki Page' , 'Wiki History' , 'Wiki Control' , 'While You Were Out' , 'Web Visitor' , 'Tweet' , 'Transfer Utility' , 'Transfer Module' , 'Transfer Control' , 'Transfer Account' , 'Tips Common' , 'TestTabDT' , 'TestDT' , 'Test Type' , 'Test Run' , 'Test Record Detail' , 'Test Record' , 'Test Case' , 'Supplier TDS Category Detail' , 'Shopping Cart Control' , 'Service Series' , 'Series Detail' , 'Rule Engine' , 'RFQ' , 'Report Filter Detail' , 'Report Field Detail' , 'Report Control' , 'Rating Widget Record' , 'Rating Widget Control' , 'Rating Template Detail' , 'Rating Template' , 'PV Ded Tax Detail' , 'PV Add Tax Detail' , 'Product Variant' , 'Product Variance' , 'Product Group' , 'Product Feature' , 'Payroll Tips Common' , 'Payroll Rule' , 'Password Control' , 'Page Visit' , 'Patch' , 'Multiple Transfer' , 'Module Tip Control' , 'Module Setter' , 'Module Manager' , 'Module Import' , 'Module Detail' , 'Message Control' , 'Message' , 'Mail Participant Details' , 'Mail' , 'Leave Type Detail' , 'Leave Detail' , 'Leave Applicable Detail' , 'Lead Item Detail' , 'Lead Attachment Detail' , 'Item Attachments Detail' , 'Instant Message' , 'Impact Analysis' , 'Forum Topic' , 'Forum Control' , 'Form Settings' , 'Follower' , 'ERP Setup' , 'Enquiry Attachment Detail' , 'Documentation' , 'Condition Detail' , 'Complaint Note' , 'Code History' , 'Code Editor' , 'Code Backup Control' , 'Code Backup' , 'City' , 'Change Log' , 'Business Letter Type' , 'Business Letter Template' , 'Business Letter' , 'Badge Settings Detail' , 'Application Type' , 'Application' , 'Action Detail' , 'Accounts Setup' , 'Stock Common' , 'Job Application' , 'Service Schedule' , 'Comment Control' , 'Bank' , 'Tag Widget Control' , 'Feature Update' , 'RFQ Detail' , 'Supplier Quotation Detail' , 'Supplier Quotation' , 'Year Closing Voucher' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 8, 3, 1748], [\",:,\", \"T\"], 190], [\"Insert\", [\"list\", 3, 8, 3, 1748], [\"string:'Year Closing Voucher'\", \"T\"], 191]]"}
{"project": "sterp", "commit_sha": "a518a526ace6ef6ca80ce36ca4651f989c0ef969", "parent_sha": "d6660c0a06935135b9b6e1318290d5bc127a3096", "file_path": "patches/erpnext_structure_cleanup.py", "project_url": "https://github.com/gangadharkadam/sterp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ def delete_unwanted_pages():\n def delete_unwanted_search_criteria():\n \t\"deletes search criteria which are not used anymore\"\n \t\n-\tlst = ['_SRCH00002', '_SRCH00001', 'warranty-amc_summary1', 'test_so4', 'test_so3', 'test_so2', 'test_so1', 'test_so', 'test5', 'target_variance_report1', 'STDSRCH/00006', 'STDSRCH/00005', 'STDSRCH/00004', 'STDSRCH/00003', 'STDSRCH/00002', 'STDSRCH/00001', 'so_pending_items_6', 'so_pending_items_5', 'so_pending_items_3', 'so_pending_items_34', 'scrap', 'sales_report_test', 'salary_structure_details1', 'salary_structure_details2', 'salary_structure_details3', 'salary_slips1', 'projectwise_pending_qty_and_costs2', 'projectwise_pending_qty_and_costs1', 'projectwise_delivered_qty_and_costs1', 'projectwise_delivered_qty_and_costs2', 'New Search Criteria 1', 'monthly_salary_register2', 'monthly_salary_register1', 'installed_items','follow_up_history', 'follow_up_report', 'employee_in_company_experience2', 'employee_in_company_experience1', 'employee_in_company_experience', 'employee_details', 'employee_details1', 'employee_details2', 'employees_birthday1', 'draft_so_pending_items', 'draft_sales_orders', 'delivery_notewise_pending_qty_to_install', 'datewise_leave_report2', 'datewise_leave_report1', 'datewise_leave_report', 'customer_issues1', 'cancelled_so_pending_items1', 'cancelled_so_pending_items', 'budget_variance_report3', 'budget_variance_report1', 'account_-_inputs_rg_23_a_-_part_ii_wrong_one', 'territory_item_group_wise_gp', 'sales_orderwise_pending_packing_item_summary']\n+\tlst = ['_SRCH00002', '_SRCH00001', 'warranty-amc_summary1', 'test_so4', 'test_so3', 'test_so2', 'test_so1', 'test_so', 'test5', 'target_variance_report1', 'STDSRCH/00006', 'STDSRCH/00005', 'STDSRCH/00004', 'STDSRCH/00003', 'STDSRCH/00002', 'STDSRCH/00001', 'so_pending_items_6', 'so_pending_items_5', 'so_pending_items_3', 'so_pending_items_34', 'scrap', 'sales_report_test', 'salary_structure_details1', 'salary_structure_details2', 'salary_structure_details3', 'salary_slips1', 'projectwise_pending_qty_and_costs2', 'projectwise_pending_qty_and_costs1', 'projectwise_delivered_qty_and_costs1', 'projectwise_delivered_qty_and_costs2', 'New Search Criteria 1', 'monthly_salary_register2', 'monthly_salary_register1', 'installed_items','follow_up_history', 'follow_up_report', 'employee_in_company_experience2', 'employee_in_company_experience1', 'employee_in_company_experience', 'employee_details', 'employee_details1', 'employee_details2', 'employees_birthday1', 'draft_so_pending_items', 'draft_sales_orders', 'delivery_notewise_pending_qty_to_install', 'datewise_leave_report2', 'datewise_leave_report1', 'datewise_leave_report', 'customer_issues1', 'cancelled_so_pending_items1', 'cancelled_so_pending_items', 'budget_variance_report3', 'budget_variance_report1', 'account_-_inputs_rg_23_a_-_part_ii_wrong_one', 'territory_item_group_wise_gp', 'sales_orderwise_pending_packing_item_summary', 'itemwise_trend']\n \t\n \tfor d in lst:\n \t\tdelete_doc('Search Criteria', d)\n", "before": "lst = [ '_SRCH00002' , '_SRCH00001' , 'warranty-amc_summary1' , 'test_so4' , 'test_so3' , 'test_so2' , 'test_so1' , 'test_so' , 'test5' , 'target_variance_report1' , 'STDSRCH/00006' , 'STDSRCH/00005' , 'STDSRCH/00004' , 'STDSRCH/00003' , 'STDSRCH/00002' , 'STDSRCH/00001' , 'so_pending_items_6' , 'so_pending_items_5' , 'so_pending_items_3' , 'so_pending_items_34' , 'scrap' , 'sales_report_test' , 'salary_structure_details1' , 'salary_structure_details2' , 'salary_structure_details3' , 'salary_slips1' , 'projectwise_pending_qty_and_costs2' , 'projectwise_pending_qty_and_costs1' , 'projectwise_delivered_qty_and_costs1' , 'projectwise_delivered_qty_and_costs2' , 'New Search Criteria 1' , 'monthly_salary_register2' , 'monthly_salary_register1' , 'installed_items' , 'follow_up_history' , 'follow_up_report' , 'employee_in_company_experience2' , 'employee_in_company_experience1' , 'employee_in_company_experience' , 'employee_details' , 'employee_details1' , 'employee_details2' , 'employees_birthday1' , 'draft_so_pending_items' , 'draft_sales_orders' , 'delivery_notewise_pending_qty_to_install' , 'datewise_leave_report2' , 'datewise_leave_report1' , 'datewise_leave_report' , 'customer_issues1' , 'cancelled_so_pending_items1' , 'cancelled_so_pending_items' , 'budget_variance_report3' , 'budget_variance_report1' , 'account_-_inputs_rg_23_a_-_part_ii_wrong_one' , 'territory_item_group_wise_gp' , 'sales_orderwise_pending_packing_item_summary' ]", "after": "lst = [ '_SRCH00002' , '_SRCH00001' , 'warranty-amc_summary1' , 'test_so4' , 'test_so3' , 'test_so2' , 'test_so1' , 'test_so' , 'test5' , 'target_variance_report1' , 'STDSRCH/00006' , 'STDSRCH/00005' , 'STDSRCH/00004' , 'STDSRCH/00003' , 'STDSRCH/00002' , 'STDSRCH/00001' , 'so_pending_items_6' , 'so_pending_items_5' , 'so_pending_items_3' , 'so_pending_items_34' , 'scrap' , 'sales_report_test' , 'salary_structure_details1' , 'salary_structure_details2' , 'salary_structure_details3' , 'salary_slips1' , 'projectwise_pending_qty_and_costs2' , 'projectwise_pending_qty_and_costs1' , 'projectwise_delivered_qty_and_costs1' , 'projectwise_delivered_qty_and_costs2' , 'New Search Criteria 1' , 'monthly_salary_register2' , 'monthly_salary_register1' , 'installed_items' , 'follow_up_history' , 'follow_up_report' , 'employee_in_company_experience2' , 'employee_in_company_experience1' , 'employee_in_company_experience' , 'employee_details' , 'employee_details1' , 'employee_details2' , 'employees_birthday1' , 'draft_so_pending_items' , 'draft_sales_orders' , 'delivery_notewise_pending_qty_to_install' , 'datewise_leave_report2' , 'datewise_leave_report1' , 'datewise_leave_report' , 'customer_issues1' , 'cancelled_so_pending_items1' , 'cancelled_so_pending_items' , 'budget_variance_report3' , 'budget_variance_report1' , 'account_-_inputs_rg_23_a_-_part_ii_wrong_one' , 'territory_item_group_wise_gp' , 'sales_orderwise_pending_packing_item_summary' , 'itemwise_trend' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 8, 3, 1398], [\",:,\", \"T\"], 114], [\"Insert\", [\"list\", 3, 8, 3, 1398], [\"string:'itemwise_trend'\", \"T\"], 115]]"}
{"project": "sterp", "commit_sha": "be557f0f9fea013d479b31d5e138758143b4598e", "parent_sha": "a518a526ace6ef6ca80ce36ca4651f989c0ef969", "file_path": "patches/erpnext_structure_cleanup.py", "project_url": "https://github.com/gangadharkadam/sterp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ def delete_unwanted_pages():\n def delete_unwanted_search_criteria():\n \t\"deletes search criteria which are not used anymore\"\n \t\n-\tlst = ['_SRCH00002', '_SRCH00001', 'warranty-amc_summary1', 'test_so4', 'test_so3', 'test_so2', 'test_so1', 'test_so', 'test5', 'target_variance_report1', 'STDSRCH/00006', 'STDSRCH/00005', 'STDSRCH/00004', 'STDSRCH/00003', 'STDSRCH/00002', 'STDSRCH/00001', 'so_pending_items_6', 'so_pending_items_5', 'so_pending_items_3', 'so_pending_items_34', 'scrap', 'sales_report_test', 'salary_structure_details1', 'salary_structure_details2', 'salary_structure_details3', 'salary_slips1', 'projectwise_pending_qty_and_costs2', 'projectwise_pending_qty_and_costs1', 'projectwise_delivered_qty_and_costs1', 'projectwise_delivered_qty_and_costs2', 'New Search Criteria 1', 'monthly_salary_register2', 'monthly_salary_register1', 'installed_items','follow_up_history', 'follow_up_report', 'employee_in_company_experience2', 'employee_in_company_experience1', 'employee_in_company_experience', 'employee_details', 'employee_details1', 'employee_details2', 'employees_birthday1', 'draft_so_pending_items', 'draft_sales_orders', 'delivery_notewise_pending_qty_to_install', 'datewise_leave_report2', 'datewise_leave_report1', 'datewise_leave_report', 'customer_issues1', 'cancelled_so_pending_items1', 'cancelled_so_pending_items', 'budget_variance_report3', 'budget_variance_report1', 'account_-_inputs_rg_23_a_-_part_ii_wrong_one', 'territory_item_group_wise_gp', 'sales_orderwise_pending_packing_item_summary', 'itemwise_trend']\n+\tlst = ['_SRCH00002', '_SRCH00001', 'warranty-amc_summary1', 'test_so4', 'test_so3', 'test_so2', 'test_so1', 'test_so', 'test5', 'target_variance_report1', 'STDSRCH/00006', 'STDSRCH/00005', 'STDSRCH/00004', 'STDSRCH/00003', 'STDSRCH/00002', 'STDSRCH/00001', 'so_pending_items_6', 'so_pending_items_5', 'so_pending_items_3', 'so_pending_items_34', 'scrap', 'sales_report_test', 'salary_structure_details1', 'salary_structure_details2', 'salary_structure_details3', 'salary_slips1', 'projectwise_pending_qty_and_costs2', 'projectwise_pending_qty_and_costs1', 'projectwise_delivered_qty_and_costs1', 'projectwise_delivered_qty_and_costs2', 'New Search Criteria 1', 'monthly_salary_register2', 'monthly_salary_register1', 'installed_items','follow_up_history', 'follow_up_report', 'employee_in_company_experience2', 'employee_in_company_experience1', 'employee_in_company_experience', 'employee_details', 'employee_details1', 'employee_details2', 'employees_birthday1', 'draft_so_pending_items', 'draft_sales_orders', 'delivery_notewise_pending_qty_to_install', 'datewise_leave_report2', 'datewise_leave_report1', 'datewise_leave_report', 'customer_issues1', 'cancelled_so_pending_items1', 'cancelled_so_pending_items', 'budget_variance_report3', 'budget_variance_report1', 'account_-_inputs_rg_23_a_-_part_ii_wrong_one', 'territory_item_group_wise_gp', 'sales_orderwise_pending_packing_item_summary', 'itemwise_trend', 'monthly_attendance_details_old']\n \t\n \tfor d in lst:\n \t\tdelete_doc('Search Criteria', d)\n", "before": "lst = [ '_SRCH00002' , '_SRCH00001' , 'warranty-amc_summary1' , 'test_so4' , 'test_so3' , 'test_so2' , 'test_so1' , 'test_so' , 'test5' , 'target_variance_report1' , 'STDSRCH/00006' , 'STDSRCH/00005' , 'STDSRCH/00004' , 'STDSRCH/00003' , 'STDSRCH/00002' , 'STDSRCH/00001' , 'so_pending_items_6' , 'so_pending_items_5' , 'so_pending_items_3' , 'so_pending_items_34' , 'scrap' , 'sales_report_test' , 'salary_structure_details1' , 'salary_structure_details2' , 'salary_structure_details3' , 'salary_slips1' , 'projectwise_pending_qty_and_costs2' , 'projectwise_pending_qty_and_costs1' , 'projectwise_delivered_qty_and_costs1' , 'projectwise_delivered_qty_and_costs2' , 'New Search Criteria 1' , 'monthly_salary_register2' , 'monthly_salary_register1' , 'installed_items' , 'follow_up_history' , 'follow_up_report' , 'employee_in_company_experience2' , 'employee_in_company_experience1' , 'employee_in_company_experience' , 'employee_details' , 'employee_details1' , 'employee_details2' , 'employees_birthday1' , 'draft_so_pending_items' , 'draft_sales_orders' , 'delivery_notewise_pending_qty_to_install' , 'datewise_leave_report2' , 'datewise_leave_report1' , 'datewise_leave_report' , 'customer_issues1' , 'cancelled_so_pending_items1' , 'cancelled_so_pending_items' , 'budget_variance_report3' , 'budget_variance_report1' , 'account_-_inputs_rg_23_a_-_part_ii_wrong_one' , 'territory_item_group_wise_gp' , 'sales_orderwise_pending_packing_item_summary' , 'itemwise_trend' ]", "after": "lst = [ '_SRCH00002' , '_SRCH00001' , 'warranty-amc_summary1' , 'test_so4' , 'test_so3' , 'test_so2' , 'test_so1' , 'test_so' , 'test5' , 'target_variance_report1' , 'STDSRCH/00006' , 'STDSRCH/00005' , 'STDSRCH/00004' , 'STDSRCH/00003' , 'STDSRCH/00002' , 'STDSRCH/00001' , 'so_pending_items_6' , 'so_pending_items_5' , 'so_pending_items_3' , 'so_pending_items_34' , 'scrap' , 'sales_report_test' , 'salary_structure_details1' , 'salary_structure_details2' , 'salary_structure_details3' , 'salary_slips1' , 'projectwise_pending_qty_and_costs2' , 'projectwise_pending_qty_and_costs1' , 'projectwise_delivered_qty_and_costs1' , 'projectwise_delivered_qty_and_costs2' , 'New Search Criteria 1' , 'monthly_salary_register2' , 'monthly_salary_register1' , 'installed_items' , 'follow_up_history' , 'follow_up_report' , 'employee_in_company_experience2' , 'employee_in_company_experience1' , 'employee_in_company_experience' , 'employee_details' , 'employee_details1' , 'employee_details2' , 'employees_birthday1' , 'draft_so_pending_items' , 'draft_sales_orders' , 'delivery_notewise_pending_qty_to_install' , 'datewise_leave_report2' , 'datewise_leave_report1' , 'datewise_leave_report' , 'customer_issues1' , 'cancelled_so_pending_items1' , 'cancelled_so_pending_items' , 'budget_variance_report3' , 'budget_variance_report1' , 'account_-_inputs_rg_23_a_-_part_ii_wrong_one' , 'territory_item_group_wise_gp' , 'sales_orderwise_pending_packing_item_summary' , 'itemwise_trend' , 'monthly_attendance_details_old' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 8, 3, 1416], [\",:,\", \"T\"], 116], [\"Insert\", [\"list\", 3, 8, 3, 1416], [\"string:'monthly_attendance_details_old'\", \"T\"], 117]]"}
{"project": "sterp", "commit_sha": "8b941c1284fecfd419878d9ff19cb3b8da149c0b", "parent_sha": "be557f0f9fea013d479b31d5e138758143b4598e", "file_path": "patches/erpnext_structure_cleanup.py", "project_url": "https://github.com/gangadharkadam/sterp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ def delete_unwanted_pages():\n def delete_unwanted_search_criteria():\n \t\"deletes search criteria which are not used anymore\"\n \t\n-\tlst = ['_SRCH00002', '_SRCH00001', 'warranty-amc_summary1', 'test_so4', 'test_so3', 'test_so2', 'test_so1', 'test_so', 'test5', 'target_variance_report1', 'STDSRCH/00006', 'STDSRCH/00005', 'STDSRCH/00004', 'STDSRCH/00003', 'STDSRCH/00002', 'STDSRCH/00001', 'so_pending_items_6', 'so_pending_items_5', 'so_pending_items_3', 'so_pending_items_34', 'scrap', 'sales_report_test', 'salary_structure_details1', 'salary_structure_details2', 'salary_structure_details3', 'salary_slips1', 'projectwise_pending_qty_and_costs2', 'projectwise_pending_qty_and_costs1', 'projectwise_delivered_qty_and_costs1', 'projectwise_delivered_qty_and_costs2', 'New Search Criteria 1', 'monthly_salary_register2', 'monthly_salary_register1', 'installed_items','follow_up_history', 'follow_up_report', 'employee_in_company_experience2', 'employee_in_company_experience1', 'employee_in_company_experience', 'employee_details', 'employee_details1', 'employee_details2', 'employees_birthday1', 'draft_so_pending_items', 'draft_sales_orders', 'delivery_notewise_pending_qty_to_install', 'datewise_leave_report2', 'datewise_leave_report1', 'datewise_leave_report', 'customer_issues1', 'cancelled_so_pending_items1', 'cancelled_so_pending_items', 'budget_variance_report3', 'budget_variance_report1', 'account_-_inputs_rg_23_a_-_part_ii_wrong_one', 'territory_item_group_wise_gp', 'sales_orderwise_pending_packing_item_summary', 'itemwise_trend', 'monthly_attendance_details_old']\n+\tlst = ['_SRCH00002', '_SRCH00001', 'warranty-amc_summary1', 'test_so4', 'test_so3', 'test_so2', 'test_so1', 'test_so', 'test5', 'target_variance_report1', 'STDSRCH/00006', 'STDSRCH/00005', 'STDSRCH/00004', 'STDSRCH/00003', 'STDSRCH/00002', 'STDSRCH/00001', 'so_pending_items_6', 'so_pending_items_5', 'so_pending_items_3', 'so_pending_items_34', 'scrap', 'sales_report_test', 'salary_structure_details1', 'salary_structure_details2', 'salary_structure_details3', 'salary_slips1', 'projectwise_pending_qty_and_costs2', 'projectwise_pending_qty_and_costs1', 'projectwise_delivered_qty_and_costs1', 'projectwise_delivered_qty_and_costs2', 'New Search Criteria 1', 'monthly_salary_register2', 'monthly_salary_register1', 'installed_items','follow_up_history', 'follow_up_report', 'employee_in_company_experience2', 'employee_in_company_experience1', 'employee_in_company_experience', 'employee_details', 'employee_details1', 'employee_details2', 'employees_birthday1', 'draft_so_pending_items', 'draft_sales_orders', 'delivery_notewise_pending_qty_to_install', 'datewise_leave_report2', 'datewise_leave_report1', 'datewise_leave_report', 'customer_issues1', 'cancelled_so_pending_items1', 'cancelled_so_pending_items', 'budget_variance_report3', 'budget_variance_report1', 'account_-_inputs_rg_23_a_-_part_ii_wrong_one', 'territory_item_group_wise_gp', 'sales_orderwise_pending_packing_item_summary', 'itemwise_trend', 'monthly_attendance_details_old', 'projectwise_contribution_report']\n \t\n \tfor d in lst:\n \t\tdelete_doc('Search Criteria', d)\n", "before": "lst = [ '_SRCH00002' , '_SRCH00001' , 'warranty-amc_summary1' , 'test_so4' , 'test_so3' , 'test_so2' , 'test_so1' , 'test_so' , 'test5' , 'target_variance_report1' , 'STDSRCH/00006' , 'STDSRCH/00005' , 'STDSRCH/00004' , 'STDSRCH/00003' , 'STDSRCH/00002' , 'STDSRCH/00001' , 'so_pending_items_6' , 'so_pending_items_5' , 'so_pending_items_3' , 'so_pending_items_34' , 'scrap' , 'sales_report_test' , 'salary_structure_details1' , 'salary_structure_details2' , 'salary_structure_details3' , 'salary_slips1' , 'projectwise_pending_qty_and_costs2' , 'projectwise_pending_qty_and_costs1' , 'projectwise_delivered_qty_and_costs1' , 'projectwise_delivered_qty_and_costs2' , 'New Search Criteria 1' , 'monthly_salary_register2' , 'monthly_salary_register1' , 'installed_items' , 'follow_up_history' , 'follow_up_report' , 'employee_in_company_experience2' , 'employee_in_company_experience1' , 'employee_in_company_experience' , 'employee_details' , 'employee_details1' , 'employee_details2' , 'employees_birthday1' , 'draft_so_pending_items' , 'draft_sales_orders' , 'delivery_notewise_pending_qty_to_install' , 'datewise_leave_report2' , 'datewise_leave_report1' , 'datewise_leave_report' , 'customer_issues1' , 'cancelled_so_pending_items1' , 'cancelled_so_pending_items' , 'budget_variance_report3' , 'budget_variance_report1' , 'account_-_inputs_rg_23_a_-_part_ii_wrong_one' , 'territory_item_group_wise_gp' , 'sales_orderwise_pending_packing_item_summary' , 'itemwise_trend' , 'monthly_attendance_details_old' ]", "after": "lst = [ '_SRCH00002' , '_SRCH00001' , 'warranty-amc_summary1' , 'test_so4' , 'test_so3' , 'test_so2' , 'test_so1' , 'test_so' , 'test5' , 'target_variance_report1' , 'STDSRCH/00006' , 'STDSRCH/00005' , 'STDSRCH/00004' , 'STDSRCH/00003' , 'STDSRCH/00002' , 'STDSRCH/00001' , 'so_pending_items_6' , 'so_pending_items_5' , 'so_pending_items_3' , 'so_pending_items_34' , 'scrap' , 'sales_report_test' , 'salary_structure_details1' , 'salary_structure_details2' , 'salary_structure_details3' , 'salary_slips1' , 'projectwise_pending_qty_and_costs2' , 'projectwise_pending_qty_and_costs1' , 'projectwise_delivered_qty_and_costs1' , 'projectwise_delivered_qty_and_costs2' , 'New Search Criteria 1' , 'monthly_salary_register2' , 'monthly_salary_register1' , 'installed_items' , 'follow_up_history' , 'follow_up_report' , 'employee_in_company_experience2' , 'employee_in_company_experience1' , 'employee_in_company_experience' , 'employee_details' , 'employee_details1' , 'employee_details2' , 'employees_birthday1' , 'draft_so_pending_items' , 'draft_sales_orders' , 'delivery_notewise_pending_qty_to_install' , 'datewise_leave_report2' , 'datewise_leave_report1' , 'datewise_leave_report' , 'customer_issues1' , 'cancelled_so_pending_items1' , 'cancelled_so_pending_items' , 'budget_variance_report3' , 'budget_variance_report1' , 'account_-_inputs_rg_23_a_-_part_ii_wrong_one' , 'territory_item_group_wise_gp' , 'sales_orderwise_pending_packing_item_summary' , 'itemwise_trend' , 'monthly_attendance_details_old' , 'projectwise_contribution_report' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 8, 3, 1450], [\",:,\", \"T\"], 118], [\"Insert\", [\"list\", 3, 8, 3, 1450], [\"string:'projectwise_contribution_report'\", \"T\"], 119]]"}
{"project": "sterp", "commit_sha": "476e686ba6b873f99cbc2c209167214013fc94a2", "parent_sha": "8b941c1284fecfd419878d9ff19cb3b8da149c0b", "file_path": "patches/erpnext_structure_cleanup.py", "project_url": "https://github.com/gangadharkadam/sterp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ def delete_unwanted_pages():\n def delete_unwanted_search_criteria():\n \t\"deletes search criteria which are not used anymore\"\n \t\n-\tlst = ['_SRCH00002', '_SRCH00001', 'warranty-amc_summary1', 'test_so4', 'test_so3', 'test_so2', 'test_so1', 'test_so', 'test5', 'target_variance_report1', 'STDSRCH/00006', 'STDSRCH/00005', 'STDSRCH/00004', 'STDSRCH/00003', 'STDSRCH/00002', 'STDSRCH/00001', 'so_pending_items_6', 'so_pending_items_5', 'so_pending_items_3', 'so_pending_items_34', 'scrap', 'sales_report_test', 'salary_structure_details1', 'salary_structure_details2', 'salary_structure_details3', 'salary_slips1', 'projectwise_pending_qty_and_costs2', 'projectwise_pending_qty_and_costs1', 'projectwise_delivered_qty_and_costs1', 'projectwise_delivered_qty_and_costs2', 'New Search Criteria 1', 'monthly_salary_register2', 'monthly_salary_register1', 'installed_items','follow_up_history', 'follow_up_report', 'employee_in_company_experience2', 'employee_in_company_experience1', 'employee_in_company_experience', 'employee_details', 'employee_details1', 'employee_details2', 'employees_birthday1', 'draft_so_pending_items', 'draft_sales_orders', 'delivery_notewise_pending_qty_to_install', 'datewise_leave_report2', 'datewise_leave_report1', 'datewise_leave_report', 'customer_issues1', 'cancelled_so_pending_items1', 'cancelled_so_pending_items', 'budget_variance_report3', 'budget_variance_report1', 'account_-_inputs_rg_23_a_-_part_ii_wrong_one', 'territory_item_group_wise_gp', 'sales_orderwise_pending_packing_item_summary', 'itemwise_trend', 'monthly_attendance_details_old', 'projectwise_contribution_report']\n+\tlst = ['_SRCH00002', '_SRCH00001', 'warranty-amc_summary1', 'test_so4', 'test_so3', 'test_so2', 'test_so1', 'test_so', 'test5', 'target_variance_report1', 'STDSRCH/00006', 'STDSRCH/00005', 'STDSRCH/00004', 'STDSRCH/00003', 'STDSRCH/00002', 'STDSRCH/00001', 'so_pending_items_6', 'so_pending_items_5', 'so_pending_items_3', 'so_pending_items_34', 'scrap', 'sales_report_test', 'salary_structure_details1', 'salary_structure_details2', 'salary_structure_details3', 'salary_slips1', 'projectwise_pending_qty_and_costs2', 'projectwise_pending_qty_and_costs1', 'projectwise_delivered_qty_and_costs1', 'projectwise_delivered_qty_and_costs2', 'New Search Criteria 1', 'monthly_salary_register2', 'monthly_salary_register1', 'installed_items','follow_up_history', 'follow_up_report', 'employee_in_company_experience2', 'employee_in_company_experience1', 'employee_in_company_experience', 'employee_details', 'employee_details1', 'employee_details2', 'employees_birthday1', 'draft_so_pending_items', 'draft_sales_orders', 'delivery_notewise_pending_qty_to_install', 'datewise_leave_report2', 'datewise_leave_report1', 'datewise_leave_report', 'customer_issues1', 'cancelled_so_pending_items1', 'cancelled_so_pending_items', 'budget_variance_report3', 'budget_variance_report1', 'account_-_inputs_rg_23_a_-_part_ii_wrong_one', 'territory_item_group_wise_gp', 'sales_orderwise_pending_packing_item_summary', 'itemwise_trend', 'monthly_attendance_details_old', 'projectwise_contribution_report', 'projectwise_delivery_and_material_cost']\n \t\n \tfor d in lst:\n \t\tdelete_doc('Search Criteria', d)\n", "before": "lst = [ '_SRCH00002' , '_SRCH00001' , 'warranty-amc_summary1' , 'test_so4' , 'test_so3' , 'test_so2' , 'test_so1' , 'test_so' , 'test5' , 'target_variance_report1' , 'STDSRCH/00006' , 'STDSRCH/00005' , 'STDSRCH/00004' , 'STDSRCH/00003' , 'STDSRCH/00002' , 'STDSRCH/00001' , 'so_pending_items_6' , 'so_pending_items_5' , 'so_pending_items_3' , 'so_pending_items_34' , 'scrap' , 'sales_report_test' , 'salary_structure_details1' , 'salary_structure_details2' , 'salary_structure_details3' , 'salary_slips1' , 'projectwise_pending_qty_and_costs2' , 'projectwise_pending_qty_and_costs1' , 'projectwise_delivered_qty_and_costs1' , 'projectwise_delivered_qty_and_costs2' , 'New Search Criteria 1' , 'monthly_salary_register2' , 'monthly_salary_register1' , 'installed_items' , 'follow_up_history' , 'follow_up_report' , 'employee_in_company_experience2' , 'employee_in_company_experience1' , 'employee_in_company_experience' , 'employee_details' , 'employee_details1' , 'employee_details2' , 'employees_birthday1' , 'draft_so_pending_items' , 'draft_sales_orders' , 'delivery_notewise_pending_qty_to_install' , 'datewise_leave_report2' , 'datewise_leave_report1' , 'datewise_leave_report' , 'customer_issues1' , 'cancelled_so_pending_items1' , 'cancelled_so_pending_items' , 'budget_variance_report3' , 'budget_variance_report1' , 'account_-_inputs_rg_23_a_-_part_ii_wrong_one' , 'territory_item_group_wise_gp' , 'sales_orderwise_pending_packing_item_summary' , 'itemwise_trend' , 'monthly_attendance_details_old' , 'projectwise_contribution_report' ]", "after": "lst = [ '_SRCH00002' , '_SRCH00001' , 'warranty-amc_summary1' , 'test_so4' , 'test_so3' , 'test_so2' , 'test_so1' , 'test_so' , 'test5' , 'target_variance_report1' , 'STDSRCH/00006' , 'STDSRCH/00005' , 'STDSRCH/00004' , 'STDSRCH/00003' , 'STDSRCH/00002' , 'STDSRCH/00001' , 'so_pending_items_6' , 'so_pending_items_5' , 'so_pending_items_3' , 'so_pending_items_34' , 'scrap' , 'sales_report_test' , 'salary_structure_details1' , 'salary_structure_details2' , 'salary_structure_details3' , 'salary_slips1' , 'projectwise_pending_qty_and_costs2' , 'projectwise_pending_qty_and_costs1' , 'projectwise_delivered_qty_and_costs1' , 'projectwise_delivered_qty_and_costs2' , 'New Search Criteria 1' , 'monthly_salary_register2' , 'monthly_salary_register1' , 'installed_items' , 'follow_up_history' , 'follow_up_report' , 'employee_in_company_experience2' , 'employee_in_company_experience1' , 'employee_in_company_experience' , 'employee_details' , 'employee_details1' , 'employee_details2' , 'employees_birthday1' , 'draft_so_pending_items' , 'draft_sales_orders' , 'delivery_notewise_pending_qty_to_install' , 'datewise_leave_report2' , 'datewise_leave_report1' , 'datewise_leave_report' , 'customer_issues1' , 'cancelled_so_pending_items1' , 'cancelled_so_pending_items' , 'budget_variance_report3' , 'budget_variance_report1' , 'account_-_inputs_rg_23_a_-_part_ii_wrong_one' , 'territory_item_group_wise_gp' , 'sales_orderwise_pending_packing_item_summary' , 'itemwise_trend' , 'monthly_attendance_details_old' , 'projectwise_contribution_report' , 'projectwise_delivery_and_material_cost' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 8, 3, 1485], [\",:,\", \"T\"], 120], [\"Insert\", [\"list\", 3, 8, 3, 1485], [\"string:'projectwise_delivery_and_material_cost'\", \"T\"], 121]]"}
{"project": "sterp", "commit_sha": "d72a201711aa50c864a043451ba4302371577797", "parent_sha": "476e686ba6b873f99cbc2c209167214013fc94a2", "file_path": "patches/erpnext_structure_cleanup.py", "project_url": "https://github.com/gangadharkadam/sterp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ def delete_unwanted_pages():\n def delete_unwanted_search_criteria():\n \t\"deletes search criteria which are not used anymore\"\n \t\n-\tlst = ['_SRCH00002', '_SRCH00001', 'warranty-amc_summary1', 'test_so4', 'test_so3', 'test_so2', 'test_so1', 'test_so', 'test5', 'target_variance_report1', 'STDSRCH/00006', 'STDSRCH/00005', 'STDSRCH/00004', 'STDSRCH/00003', 'STDSRCH/00002', 'STDSRCH/00001', 'so_pending_items_6', 'so_pending_items_5', 'so_pending_items_3', 'so_pending_items_34', 'scrap', 'sales_report_test', 'salary_structure_details1', 'salary_structure_details2', 'salary_structure_details3', 'salary_slips1', 'projectwise_pending_qty_and_costs2', 'projectwise_pending_qty_and_costs1', 'projectwise_delivered_qty_and_costs1', 'projectwise_delivered_qty_and_costs2', 'New Search Criteria 1', 'monthly_salary_register2', 'monthly_salary_register1', 'installed_items','follow_up_history', 'follow_up_report', 'employee_in_company_experience2', 'employee_in_company_experience1', 'employee_in_company_experience', 'employee_details', 'employee_details1', 'employee_details2', 'employees_birthday1', 'draft_so_pending_items', 'draft_sales_orders', 'delivery_notewise_pending_qty_to_install', 'datewise_leave_report2', 'datewise_leave_report1', 'datewise_leave_report', 'customer_issues1', 'cancelled_so_pending_items1', 'cancelled_so_pending_items', 'budget_variance_report3', 'budget_variance_report1', 'account_-_inputs_rg_23_a_-_part_ii_wrong_one', 'territory_item_group_wise_gp', 'sales_orderwise_pending_packing_item_summary', 'itemwise_trend', 'monthly_attendance_details_old', 'projectwise_contribution_report', 'projectwise_delivery_and_material_cost']\n+\tlst = ['_SRCH00002', '_SRCH00001', 'warranty-amc_summary1', 'test_so4', 'test_so3', 'test_so2', 'test_so1', 'test_so', 'test5', 'target_variance_report1', 'STDSRCH/00006', 'STDSRCH/00005', 'STDSRCH/00004', 'STDSRCH/00003', 'STDSRCH/00002', 'STDSRCH/00001', 'so_pending_items_6', 'so_pending_items_5', 'so_pending_items_3', 'so_pending_items_34', 'scrap', 'sales_report_test', 'salary_structure_details1', 'salary_structure_details2', 'salary_structure_details3', 'salary_slips1', 'projectwise_pending_qty_and_costs2', 'projectwise_pending_qty_and_costs1', 'projectwise_delivered_qty_and_costs1', 'projectwise_delivered_qty_and_costs2', 'New Search Criteria 1', 'monthly_salary_register2', 'monthly_salary_register1', 'installed_items','follow_up_history', 'follow_up_report', 'employee_in_company_experience2', 'employee_in_company_experience1', 'employee_in_company_experience', 'employee_details', 'employee_details1', 'employee_details2', 'employees_birthday1', 'draft_so_pending_items', 'draft_sales_orders', 'delivery_notewise_pending_qty_to_install', 'datewise_leave_report2', 'datewise_leave_report1', 'datewise_leave_report', 'customer_issues1', 'cancelled_so_pending_items1', 'cancelled_so_pending_items', 'budget_variance_report3', 'budget_variance_report1', 'account_-_inputs_rg_23_a_-_part_ii_wrong_one', 'territory_item_group_wise_gp', 'sales_orderwise_pending_packing_item_summary', 'itemwise_trend', 'monthly_attendance_details_old', 'projectwise_contribution_report', 'projectwise_delivery_and_material_cost', 'projectwise_delivery_and_mat_cost_report']\n \t\n \tfor d in lst:\n \t\tdelete_doc('Search Criteria', d)\n", "before": "lst = [ '_SRCH00002' , '_SRCH00001' , 'warranty-amc_summary1' , 'test_so4' , 'test_so3' , 'test_so2' , 'test_so1' , 'test_so' , 'test5' , 'target_variance_report1' , 'STDSRCH/00006' , 'STDSRCH/00005' , 'STDSRCH/00004' , 'STDSRCH/00003' , 'STDSRCH/00002' , 'STDSRCH/00001' , 'so_pending_items_6' , 'so_pending_items_5' , 'so_pending_items_3' , 'so_pending_items_34' , 'scrap' , 'sales_report_test' , 'salary_structure_details1' , 'salary_structure_details2' , 'salary_structure_details3' , 'salary_slips1' , 'projectwise_pending_qty_and_costs2' , 'projectwise_pending_qty_and_costs1' , 'projectwise_delivered_qty_and_costs1' , 'projectwise_delivered_qty_and_costs2' , 'New Search Criteria 1' , 'monthly_salary_register2' , 'monthly_salary_register1' , 'installed_items' , 'follow_up_history' , 'follow_up_report' , 'employee_in_company_experience2' , 'employee_in_company_experience1' , 'employee_in_company_experience' , 'employee_details' , 'employee_details1' , 'employee_details2' , 'employees_birthday1' , 'draft_so_pending_items' , 'draft_sales_orders' , 'delivery_notewise_pending_qty_to_install' , 'datewise_leave_report2' , 'datewise_leave_report1' , 'datewise_leave_report' , 'customer_issues1' , 'cancelled_so_pending_items1' , 'cancelled_so_pending_items' , 'budget_variance_report3' , 'budget_variance_report1' , 'account_-_inputs_rg_23_a_-_part_ii_wrong_one' , 'territory_item_group_wise_gp' , 'sales_orderwise_pending_packing_item_summary' , 'itemwise_trend' , 'monthly_attendance_details_old' , 'projectwise_contribution_report' , 'projectwise_delivery_and_material_cost' ]", "after": "lst = [ '_SRCH00002' , '_SRCH00001' , 'warranty-amc_summary1' , 'test_so4' , 'test_so3' , 'test_so2' , 'test_so1' , 'test_so' , 'test5' , 'target_variance_report1' , 'STDSRCH/00006' , 'STDSRCH/00005' , 'STDSRCH/00004' , 'STDSRCH/00003' , 'STDSRCH/00002' , 'STDSRCH/00001' , 'so_pending_items_6' , 'so_pending_items_5' , 'so_pending_items_3' , 'so_pending_items_34' , 'scrap' , 'sales_report_test' , 'salary_structure_details1' , 'salary_structure_details2' , 'salary_structure_details3' , 'salary_slips1' , 'projectwise_pending_qty_and_costs2' , 'projectwise_pending_qty_and_costs1' , 'projectwise_delivered_qty_and_costs1' , 'projectwise_delivered_qty_and_costs2' , 'New Search Criteria 1' , 'monthly_salary_register2' , 'monthly_salary_register1' , 'installed_items' , 'follow_up_history' , 'follow_up_report' , 'employee_in_company_experience2' , 'employee_in_company_experience1' , 'employee_in_company_experience' , 'employee_details' , 'employee_details1' , 'employee_details2' , 'employees_birthday1' , 'draft_so_pending_items' , 'draft_sales_orders' , 'delivery_notewise_pending_qty_to_install' , 'datewise_leave_report2' , 'datewise_leave_report1' , 'datewise_leave_report' , 'customer_issues1' , 'cancelled_so_pending_items1' , 'cancelled_so_pending_items' , 'budget_variance_report3' , 'budget_variance_report1' , 'account_-_inputs_rg_23_a_-_part_ii_wrong_one' , 'territory_item_group_wise_gp' , 'sales_orderwise_pending_packing_item_summary' , 'itemwise_trend' , 'monthly_attendance_details_old' , 'projectwise_contribution_report' , 'projectwise_delivery_and_material_cost' , 'projectwise_delivery_and_mat_cost_report' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 8, 3, 1527], [\",:,\", \"T\"], 122], [\"Insert\", [\"list\", 3, 8, 3, 1527], [\"string:'projectwise_delivery_and_mat_cost_report'\", \"T\"], 123]]"}
{"project": "sterp", "commit_sha": "ece5f93616113f77e01795fdab1a7ba3c042d84f", "parent_sha": "d7e69f941268555498d0967ab2e20afe290a67b5", "file_path": "patches/erpnext_structure_cleanup.py", "project_url": "https://github.com/gangadharkadam/sterp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -148,7 +148,7 @@ def sync_mapper():\n #---------------------------------------\n def run_patches():\n \t# update module\n-\tdt_module = {'LC PR Detail':'Stock', 'Landed Cost Detail':'Stock', 'Comment Widget Record': 'Core', 'Tag':'Core', 'Tag Detail': 'Core', 'POS Settings': 'Accounts'}\n+\tdt_module = {'LC PR Detail':'Stock', 'Landed Cost Detail':'Stock', 'Comment Widget Record': 'Core', 'Tag':'Core', 'Tag Detail': 'Core', 'POS Settings': 'Accounts', 'Salary Structure Details': 'Accounts'}\n \tfor d in dt_module.keys():\n \t\tsql(\"update `tabDocType` set module = '%s' where name = '%s'\" % (dt_module[d], d))\n \tdelete_unwanted_mappers()\n", "before": "dt_module = { 'LC PR Detail' : 'Stock' , 'Landed Cost Detail' : 'Stock' , 'Comment Widget Record' : 'Core' , 'Tag' : 'Core' , 'Tag Detail' : 'Core' , 'POS Settings' : 'Accounts' }", "after": "dt_module = { 'LC PR Detail' : 'Stock' , 'Landed Cost Detail' : 'Stock' , 'Comment Widget Record' : 'Core' , 'Tag' : 'Core' , 'Tag Detail' : 'Core' , 'POS Settings' : 'Accounts' , 'Salary Structure Details' : 'Accounts' }", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 14, 3, 165], [\",:,\", \"T\"], 12], [\"Insert\", [\"dictionary\", 3, 14, 3, 165], [\"pair\", \"N0\"], 13], [\"Insert\", \"N0\", [\"string:'Salary Structure Details'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'Accounts'\", \"T\"], 2]]"}
{"project": "sterp", "commit_sha": "9ce064d2b62c906768bfa4756a7900ccc7bb189d", "parent_sha": "bcfd01489bd1558e9b632b9624d5638de47219eb", "file_path": "patches/erpnext_structure_cleanup.py", "project_url": "https://github.com/gangadharkadam/sterp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ def delete_unwanted_search_criteria():\n \t\n \tsql(\"update `tabSearch Criteria` set module = 'HR' where name = 'salary_structure_details'\")\n \t\n-\tlst = ['_SRCH00002', '_SRCH00001', 'warranty-amc_summary1', 'test_so4', 'test_so3', 'test_so2', 'test_so1', 'test_so', 'test5', 'target_variance_report1', 'STDSRCH/00006', 'STDSRCH/00005', 'STDSRCH/00004', 'STDSRCH/00003', 'STDSRCH/00002', 'STDSRCH/00001', 'so_pending_items_6', 'so_pending_items_5', 'so_pending_items_3', 'so_pending_items_34', 'scrap', 'sales_report_test', 'salary_structure_details1', 'salary_structure_details2', 'salary_structure_details3', 'salary_slips1', 'projectwise_pending_qty_and_costs2', 'projectwise_pending_qty_and_costs1', 'projectwise_delivered_qty_and_costs1', 'projectwise_delivered_qty_and_costs2', 'New Search Criteria 1', 'monthly_salary_register2', 'monthly_salary_register1', 'installed_items','follow_up_history', 'follow_up_report', 'employee_in_company_experience2', 'employee_in_company_experience1', 'employee_in_company_experience', 'employee_details', 'employee_details1', 'employee_details2', 'employees_birthday1', 'draft_so_pending_items', 'draft_sales_orders', 'delivery_notewise_pending_qty_to_install', 'datewise_leave_report2', 'datewise_leave_report1', 'datewise_leave_report', 'customer_issues1', 'cancelled_so_pending_items1', 'cancelled_so_pending_items', 'budget_variance_report3', 'budget_variance_report1', 'account_-_inputs_rg_23_a_-_part_ii_wrong_one', 'territory_item_group_wise_gp', 'sales_orderwise_pending_packing_item_summary', 'itemwise_trend', 'monthly_attendance_details_old', 'projectwise_contribution_report', 'projectwise_delivery_and_material_cost', 'projectwise_delivery_and_mat_cost_report']\n+\tlst = ['_SRCH00002', '_SRCH00001', 'warranty-amc_summary1', 'test_so4', 'test_so3', 'test_so2', 'test_so1', 'test_so', 'test5', 'target_variance_report1', 'STDSRCH/00006', 'STDSRCH/00005', 'STDSRCH/00004', 'STDSRCH/00003', 'STDSRCH/00002', 'STDSRCH/00001', 'so_pending_items_6', 'so_pending_items_5', 'so_pending_items_3', 'so_pending_items_34', 'scrap', 'sales_report_test', 'salary_structure_details1', 'salary_structure_details2', 'salary_structure_details3', 'salary_slips1', 'projectwise_pending_qty_and_costs2', 'projectwise_pending_qty_and_costs1', 'projectwise_delivered_qty_and_costs1', 'projectwise_delivered_qty_and_costs2', 'New Search Criteria 1', 'monthly_salary_register2', 'monthly_salary_register1', 'installed_items','follow_up_history', 'follow_up_report', 'employee_in_company_experience2', 'employee_in_company_experience1', 'employee_in_company_experience', 'employee_details', 'employee_details1', 'employee_details2', 'employees_birthday1', 'draft_so_pending_items', 'draft_sales_orders', 'delivery_notewise_pending_qty_to_install', 'datewise_leave_report2', 'datewise_leave_report1', 'datewise_leave_report', 'customer_issues1', 'cancelled_so_pending_items1', 'cancelled_so_pending_items', 'budget_variance_report3', 'budget_variance_report1', 'account_-_inputs_rg_23_a_-_part_ii_wrong_one', 'territory_item_group_wise_gp', 'sales_orderwise_pending_packing_item_summary', 'itemwise_trend', 'monthly_attendance_details_old', 'projectwise_contribution_report', 'projectwise_delivery_and_material_cost', 'projectwise_delivery_and_mat_cost_report', 'territorywise_trend', 'test_dn']\n \t\n \tfor d in lst:\n \t\tif sql(\"select name from `tabSearch Criteria` where ifnull(standard, 'Yes') = 'Yes' and name = '%s'\" % d):\n", "before": "lst = [ '_SRCH00002' , '_SRCH00001' , 'warranty-amc_summary1' , 'test_so4' , 'test_so3' , 'test_so2' , 'test_so1' , 'test_so' , 'test5' , 'target_variance_report1' , 'STDSRCH/00006' , 'STDSRCH/00005' , 'STDSRCH/00004' , 'STDSRCH/00003' , 'STDSRCH/00002' , 'STDSRCH/00001' , 'so_pending_items_6' , 'so_pending_items_5' , 'so_pending_items_3' , 'so_pending_items_34' , 'scrap' , 'sales_report_test' , 'salary_structure_details1' , 'salary_structure_details2' , 'salary_structure_details3' , 'salary_slips1' , 'projectwise_pending_qty_and_costs2' , 'projectwise_pending_qty_and_costs1' , 'projectwise_delivered_qty_and_costs1' , 'projectwise_delivered_qty_and_costs2' , 'New Search Criteria 1' , 'monthly_salary_register2' , 'monthly_salary_register1' , 'installed_items' , 'follow_up_history' , 'follow_up_report' , 'employee_in_company_experience2' , 'employee_in_company_experience1' , 'employee_in_company_experience' , 'employee_details' , 'employee_details1' , 'employee_details2' , 'employees_birthday1' , 'draft_so_pending_items' , 'draft_sales_orders' , 'delivery_notewise_pending_qty_to_install' , 'datewise_leave_report2' , 'datewise_leave_report1' , 'datewise_leave_report' , 'customer_issues1' , 'cancelled_so_pending_items1' , 'cancelled_so_pending_items' , 'budget_variance_report3' , 'budget_variance_report1' , 'account_-_inputs_rg_23_a_-_part_ii_wrong_one' , 'territory_item_group_wise_gp' , 'sales_orderwise_pending_packing_item_summary' , 'itemwise_trend' , 'monthly_attendance_details_old' , 'projectwise_contribution_report' , 'projectwise_delivery_and_material_cost' , 'projectwise_delivery_and_mat_cost_report' ]", "after": "lst = [ '_SRCH00002' , '_SRCH00001' , 'warranty-amc_summary1' , 'test_so4' , 'test_so3' , 'test_so2' , 'test_so1' , 'test_so' , 'test5' , 'target_variance_report1' , 'STDSRCH/00006' , 'STDSRCH/00005' , 'STDSRCH/00004' , 'STDSRCH/00003' , 'STDSRCH/00002' , 'STDSRCH/00001' , 'so_pending_items_6' , 'so_pending_items_5' , 'so_pending_items_3' , 'so_pending_items_34' , 'scrap' , 'sales_report_test' , 'salary_structure_details1' , 'salary_structure_details2' , 'salary_structure_details3' , 'salary_slips1' , 'projectwise_pending_qty_and_costs2' , 'projectwise_pending_qty_and_costs1' , 'projectwise_delivered_qty_and_costs1' , 'projectwise_delivered_qty_and_costs2' , 'New Search Criteria 1' , 'monthly_salary_register2' , 'monthly_salary_register1' , 'installed_items' , 'follow_up_history' , 'follow_up_report' , 'employee_in_company_experience2' , 'employee_in_company_experience1' , 'employee_in_company_experience' , 'employee_details' , 'employee_details1' , 'employee_details2' , 'employees_birthday1' , 'draft_so_pending_items' , 'draft_sales_orders' , 'delivery_notewise_pending_qty_to_install' , 'datewise_leave_report2' , 'datewise_leave_report1' , 'datewise_leave_report' , 'customer_issues1' , 'cancelled_so_pending_items1' , 'cancelled_so_pending_items' , 'budget_variance_report3' , 'budget_variance_report1' , 'account_-_inputs_rg_23_a_-_part_ii_wrong_one' , 'territory_item_group_wise_gp' , 'sales_orderwise_pending_packing_item_summary' , 'itemwise_trend' , 'monthly_attendance_details_old' , 'projectwise_contribution_report' , 'projectwise_delivery_and_material_cost' , 'projectwise_delivery_and_mat_cost_report' , 'territorywise_trend' , 'test_dn' ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 8, 3, 1571], [\",:,\", \"T\"], 124], [\"Insert\", [\"list\", 3, 8, 3, 1571], [\"string:'territorywise_trend'\", \"T\"], 125], [\"Insert\", [\"list\", 3, 8, 3, 1571], [\",:,\", \"T\"], 126], [\"Insert\", [\"list\", 3, 8, 3, 1571], [\"string:'test_dn'\", \"T\"], 127]]"}
{"project": "sterp", "commit_sha": "3eb03b2635bea9ee936f5070a56423feb616c623", "parent_sha": "68c6e00b52a6777d357c4c3534bcfc81bb1a8088", "file_path": "patches/erpnext_structure_cleanup.py", "project_url": "https://github.com/gangadharkadam/sterp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -150,7 +150,7 @@ def sync_mapper():\n #---------------------------------------\n def run_patches():\n \t# update module\n-\tdt_module = {'LC PR Detail':'Stock', 'Landed Cost Detail':'Stock', 'Comment Widget Record': 'Core', 'Tag':'Core', 'Tag Detail': 'Core', 'POS Settings': 'Accounts'}\n+\tdt_module = {'LC PR Detail':'Stock', 'Landed Cost Detail':'Stock', 'Comment Widget Record': 'Core', 'Tag':'Core', 'Tag Detail': 'Core', 'POS Settings': 'Accounts', 'Menu Item': 'Setup', 'Menu Item Role': 'Setup'}\n \tfor d in dt_module.keys():\n \t\tsql(\"update `tabDocType` set module = '%s' where name = '%s'\" % (dt_module[d], d))\n \tdelete_unwanted_mappers()\n", "before": "dt_module = { 'LC PR Detail' : 'Stock' , 'Landed Cost Detail' : 'Stock' , 'Comment Widget Record' : 'Core' , 'Tag' : 'Core' , 'Tag Detail' : 'Core' , 'POS Settings' : 'Accounts' }", "after": "dt_module = { 'LC PR Detail' : 'Stock' , 'Landed Cost Detail' : 'Stock' , 'Comment Widget Record' : 'Core' , 'Tag' : 'Core' , 'Tag Detail' : 'Core' , 'POS Settings' : 'Accounts' , 'Menu Item' : 'Setup' , 'Menu Item Role' : 'Setup' }", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 14, 3, 165], [\",:,\", \"T\"], 12], [\"Insert\", [\"dictionary\", 3, 14, 3, 165], [\"pair\", \"N0\"], 13], [\"Insert\", [\"dictionary\", 3, 14, 3, 165], [\",:,\", \"T\"], 14], [\"Insert\", [\"dictionary\", 3, 14, 3, 165], [\"pair\", \"N1\"], 15], [\"Insert\", \"N0\", [\"string:'Menu Item'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'Setup'\", \"T\"], 2], [\"Insert\", \"N1\", [\"string:'Menu Item Role'\", \"T\"], 0], [\"Insert\", \"N1\", [\":::\", \"T\"], 1], [\"Insert\", \"N1\", [\"string:'Setup'\", \"T\"], 2]]"}
{"project": "scipy", "commit_sha": "f7dae4f21593d94735a0377a1af3a9275413b889", "parent_sha": "35fe2e482d19cab49081c19d1c592480647d3ac8", "file_path": "tools/py3tool.py", "project_url": "https://github.com/GregoryEAllen/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -329,7 +329,7 @@ def sync_2to3(src, dst, patchfile=None, clean=False):\n         _old_stdout = sys.stdout\n         try:\n             sys.stdout = StringIO()\n-            lib2to3.main.main(\"lib2to3.fixes\", ['-w'] + flags.split()+filenames)\n+            lib2to3.main.main(\"lib2to3.fixes\", ['-w', '-n'] + flags.split()+filenames)\n         finally:\n             sys.stdout = _old_stdout\n \n", "before": "lib2to3 . main . main ( \"lib2to3.fixes\" , [ '-w' ] + flags . split ( ) + filenames )", "after": "lib2to3 . main . main ( \"lib2to3.fixes\" , [ '-w' , '-n' ] + flags . split ( ) + filenames )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 48, 3, 54], [\",:,\", \"T\"], 2], [\"Insert\", [\"list\", 3, 48, 3, 54], [\"string:'-n'\", \"T\"], 3]]"}
{"project": "cloudabi-ports", "commit_sha": "1d084bfc3f5d3b0937136bead4b49faeb6c61ad6", "parent_sha": "717df29207695c5325b38051b47fb01a4ccfa496", "file_path": "src/builder.py", "project_url": "https://github.com/moreati/cloudabi-ports", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -276,7 +276,7 @@ class HostBuilder:\n         self._install_directory = install_directory\n \n         self._cflags = [\n-            '-O2', '-I' + os.path.join(self.get_prefix(), 'include'),\n+            '-O2', '-fpie', '-I' + os.path.join(self.get_prefix(), 'include'),\n         ]\n \n     def gnu_configure(self, builddir, script, args):\n", "before": "self . _cflags = [ '-O2' , '-I' + os . path . join ( self . get_prefix ( ) , 'include' ) , ]", "after": "self . _cflags = [ '-O2' , '-fpie' , '-I' + os . path . join ( self . get_prefix ( ) , 'include' ) , ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 2, 24, 4, 10], [\"string:'-fpie'\", \"T\"], 3], [\"Insert\", [\"list\", 2, 24, 4, 10], [\",:,\", \"T\"], 4]]"}
{"project": "certbot", "commit_sha": "13aed36cd5ce6e3e4e974a6fbe0065d51c65181d", "parent_sha": "0fb3bf689db5bd29b6765985df9861350736f3a9", "file_path": "letsencrypt/cli.py", "project_url": "https://github.com/barkinet/certbot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1195,7 +1195,7 @@ class HelpfulArgumentParser(object):\n                     parsed_args.domains.append(domain)\n \n         if parsed_args.staging or parsed_args.dry_run:\n-            if parsed_args.server not in (flag_default(\"server\"), constants.STAGING_URI):\n+            if parsed_args.server not in (\"\", flag_default(\"server\"), constants.STAGING_URI):\n                 conflicts = [\"--staging\"] if parsed_args.staging else []\n                 conflicts += [\"--dry-run\"] if parsed_args.dry_run else []\n                 if not self.detect_defaults:\n", "before": "if parsed_args . server not in ( flag_default ( \"server\" ) , constants . STAGING_URI ) : conflicts = [ \"--staging\" ] if parsed_args . staging else [ ] conflicts += [ \"--dry-run\" ] if parsed_args . dry_run else [ ] if not self . detect_defaults : ", "after": "if parsed_args . server not in ( \"\" , flag_default ( \"server\" ) , constants . STAGING_URI ) : conflicts = [ \"--staging\" ] if parsed_args . staging else [ ] conflicts += [ \"--dry-run\" ] if parsed_args . dry_run else [ ] if not self . detect_defaults : ", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 42, 3, 89], [\"string:\\\"\\\"\", \"T\"], 1], [\"Insert\", [\"tuple\", 3, 42, 3, 89], [\",:,\", \"T\"], 2]]"}
{"project": "exoplanet", "commit_sha": "dd912046bad77799f94e731d6aef1fbcae0c5232", "parent_sha": "bcd66aa6a01ee3e7f69778eab9a07574af68104f", "file_path": "src/exoplanet/theano_ops/build_utils.py", "project_url": "https://github.com/dfm/exoplanet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,7 +14,7 @@ def get_compile_args(compiler):\n     if sys.platform == \"darwin\":\n         opts += [\"-stdlib=libc++\", \"-mmacosx-version-min=10.7\"]\n     if sys.platform.startswith(\"win\"):\n-        opts += [\"-D_USE_MATH_DEFINES\"]\n+        opts += [\"-D_USE_MATH_DEFINES\", \"-fno-asynchronous-unwind-tables\"]\n     return opts\n \n \n", "before": "opts += [ \"-D_USE_MATH_DEFINES\" ]", "after": "opts += [ \"-D_USE_MATH_DEFINES\" , \"-fno-asynchronous-unwind-tables\" ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 17, 3, 40], [\",:,\", \"T\"], 2], [\"Insert\", [\"list\", 3, 17, 3, 40], [\"string:\\\"-fno-asynchronous-unwind-tables\\\"\", \"T\"], 3]]"}
{"project": "mercury", "commit_sha": "14ae26f6ceb74cb1117734b15051c0725f21e8ca", "parent_sha": "2904f0c320cf04253f46ac13a96027558772aab9", "file_path": "fab/pantheon/ygg.py", "project_url": "https://github.com/pantheon-deprecated/mercury", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -7,7 +7,7 @@ certificate = '/etc/pantheon/system.pem'\n \n # Note: Same call structure as in the Prometheus httprequest module.\n # TODO: Unify\n-def send_event(thread, details, labels=[], site='self'):\n+def send_event(thread, details, labels=['source-cloud'], site='self'):\n", "before": "def send_event ( thread , details , labels = [ ] , site = 'self' ) : ", "after": "def send_event ( thread , details , labels = [ 'source-cloud' ] , site = 'self' ) : ", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 40, 3, 42], [\"string:'source-cloud'\", \"T\"], 1]]"}
{"project": "BertSum", "commit_sha": "9aa6ab84faf3a50724ce7112c780a4651de289b0", "parent_sha": "0f311ca828836eb3edb0d0d20bf98fa7bafbe74b", "file_path": "src/prepro/data_builder.py", "project_url": "https://github.com/nlpyang/BertSum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -229,7 +229,7 @@ def tokenize(args):\n             if (not s.endswith('story')):\n                 continue\n             f.write(\"%s\\n\" % (os.path.join(stories_dir, s)))\n-    command = ['java', 'edu.stanford.nlp.pipeline.StanfordCoreNLP' ,'-annotators', 'tokenize,ssplit', '-filelist', 'mapping_for_corenlp.txt', '-outputFormat', 'json', '-outputDirectory', tokenized_stories_dir]\n+    command = ['java', 'edu.stanford.nlp.pipeline.StanfordCoreNLP' ,'-annotators', 'tokenize,ssplit', '-ssplit.newlineIsSentenceBreak', 'always', '-filelist', 'mapping_for_corenlp.txt', '-outputFormat', 'json', '-outputDirectory', tokenized_stories_dir]\n     print(\"Tokenizing %i files in %s and saving in %s...\" % (len(stories), stories_dir, tokenized_stories_dir))\n     subprocess.call(command)\n     print(\"Stanford CoreNLP Tokenizer has finished.\")\n", "before": "command = [ 'java' , 'edu.stanford.nlp.pipeline.StanfordCoreNLP' , '-annotators' , 'tokenize,ssplit' , '-filelist' , 'mapping_for_corenlp.txt' , '-outputFormat' , 'json' , '-outputDirectory' , tokenized_stories_dir ]", "after": "command = [ 'java' , 'edu.stanford.nlp.pipeline.StanfordCoreNLP' , '-annotators' , 'tokenize,ssplit' , '-ssplit.newlineIsSentenceBreak' , 'always' , '-filelist' , 'mapping_for_corenlp.txt' , '-outputFormat' , 'json' , '-outputDirectory' , tokenized_stories_dir ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Move\", [\",:,\", 3, 141, 3, 142], [\"list\", 3, 15, 3, 210], 9], [\"Move\", [\",:,\", 3, 158, 3, 159], [\"list\", 3, 15, 3, 210], 10], [\"Move\", [\",:,\", 3, 186, 3, 187], [\"list\", 3, 15, 3, 210], 10], [\"Insert\", [\"list\", 3, 15, 3, 210], [\"string:'-ssplit.newlineIsSentenceBreak'\", \"T\"], 9], [\"Insert\", [\"list\", 3, 15, 3, 210], [\",:,\", \"T\"], 10], [\"Insert\", [\"list\", 3, 15, 3, 210], [\"string:'always'\", \"T\"], 11], [\"Insert\", [\"list\", 3, 15, 3, 210], [\",:,\", \"T\"], 18], [\"Insert\", [\"list\", 3, 15, 3, 210], [\",:,\", \"T\"], 23], [\"Delete\", [\",:,\", 3, 114, 3, 115]]]"}
{"project": "ansible-1", "commit_sha": "0d8ceefd4806c6086204cfa463d11bb709379c02", "parent_sha": "ea05c56a4136add9ff055add05c026b397947b59", "file_path": "lib/ansible/modules/extras/source_control/git_config.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -158,7 +158,7 @@ def main():\n     else:\n         new_value = None\n \n-    args = [git_path, \"config\"]\n+    args = [git_path, \"config\", \"--includes\"]\n     if params['list_all']:\n         args.append('-l')\n     if scope:\n", "before": "args = [ git_path , \"config\" ]", "after": "args = [ git_path , \"config\" , \"--includes\" ]", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 12, 3, 32], [\",:,\", \"T\"], 4], [\"Insert\", [\"list\", 3, 12, 3, 32], [\"string:\\\"--includes\\\"\", \"T\"], 5]]"}
{"project": "ansible-1", "commit_sha": "8c41fee7bfc180d3936875335add823e6b1accd6", "parent_sha": "0769460820a23f44dd2a0b5fe661b92470b42aaa", "file_path": "lib/ansible/module_utils/basic.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1696,7 +1696,7 @@ class AnsibleModule(object):\n                     if count == 0:\n                         missing.append(check)\n             if len(missing) and len(missing) >= max_missing_count:\n-                msg = \"%s is %s but %s of the following are missing: %s\" % (key, val, ', '.join(missing))\n+                msg = \"%s is %s but %s of the following are missing: %s\" % (key, val, term, ', '.join(missing))\n                 if self._options_context:\n                     msg += \" found in %s\" % \" -> \".join(self._options_context)\n                 self.fail_json(msg=msg)\n", "before": "msg = \"%s is %s but %s of the following are missing: %s\" % ( key , val , ', ' . join ( missing ) )", "after": "msg = \"%s is %s but %s of the following are missing: %s\" % ( key , val , term , ', ' . join ( missing ) )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 76, 3, 106], [\"identifier:term\", \"T\"], 5], [\"Insert\", [\"tuple\", 3, 76, 3, 106], [\",:,\", \"T\"], 6]]"}
{"project": "ansible-1", "commit_sha": "ce4ada93f9daae4e1806c612b5c2f96727dc3de5", "parent_sha": "be5e2251a78f182374a8e40b00744b26a7905e68", "file_path": "lib/ansible/module_utils/facts/hardware/linux.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -193,7 +193,7 @@ class LinuxHardware(Hardware):\n \n             # model name is for Intel arch, Processor (mind the uppercase P)\n             # works for some ARM devices, like the Sheevaplug.\n-            if key in ['model name', 'Processor', 'vendor_id', 'cpu', 'Vendor']:\n+            if key in ['model name', 'Processor', 'vendor_id', 'cpu', 'Vendor', 'processor']:\n                 if 'processor' not in cpu_facts:\n                     cpu_facts['processor'] = []\n                 cpu_facts['processor'].append(data[1].strip())\n", "before": "if key in [ 'model name' , 'Processor' , 'vendor_id' , 'cpu' , 'Vendor' ] : if 'processor' not in cpu_facts : cpu_facts [ 'processor' ] = [ ] cpu_facts [ 'processor' ] . append ( data [ 1 ] . strip ( ) )", "after": "if key in [ 'model name' , 'Processor' , 'vendor_id' , 'cpu' , 'Vendor' , 'processor' ] : if 'processor' not in cpu_facts : cpu_facts [ 'processor' ] = [ ] cpu_facts [ 'processor' ] . append ( data [ 1 ] . strip ( ) )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 23, 3, 80], [\",:,\", \"T\"], 10], [\"Insert\", [\"list\", 3, 23, 3, 80], [\"string:'processor'\", \"T\"], 11]]"}
{"project": "ansible-1", "commit_sha": "7f6c7c63342bd6d1c23cd9123b30986324ff6dce", "parent_sha": "7bb3467db9039e95aa10fe71be85cbbd739733d8", "file_path": "lib/ansible/modules/system/parted.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -590,7 +590,7 @@ def main():\n         },\n         supports_check_mode=True,\n     )\n-    module.run_command_environ_update = {'LANG': 'C', 'LC_ALL': 'C', 'LC_MESSAGES': 'C'}\n+    module.run_command_environ_update = {'LANG': 'C', 'LC_ALL': 'C', 'LC_MESSAGES': 'C', 'LC_CTYPE': 'C'}\n \n     # Data extraction\n     device = module.params['device']\n", "before": "module . run_command_environ_update = { 'LANG' : 'C' , 'LC_ALL' : 'C' , 'LC_MESSAGES' : 'C' }", "after": "module . run_command_environ_update = { 'LANG' : 'C' , 'LC_ALL' : 'C' , 'LC_MESSAGES' : 'C' , 'LC_CTYPE' : 'C' }", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"dictionary\", 3, 41, 3, 89], [\",:,\", \"T\"], 6], [\"Insert\", [\"dictionary\", 3, 41, 3, 89], [\"pair\", \"N0\"], 7], [\"Insert\", \"N0\", [\"string:'LC_CTYPE'\", \"T\"], 0], [\"Insert\", \"N0\", [\":::\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'C'\", \"T\"], 2]]"}
{"project": "ansible-1", "commit_sha": "95a0fe37dab5d88cafd5fb1d5de180160bdea84f", "parent_sha": "f8d522de69552fcb75695c266ed3e583bdd9c6b5", "file_path": "lib/ansible/modules/files/synchronize.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -483,7 +483,7 @@ def main():\n         if dest_port is not None:\n             ssh_cmd.extend(['-o', 'Port=%s' % dest_port])\n         if not verify_host:\n-            ssh_cmd.extend(['-o', 'StrictHostKeyChecking=no'])\n+            ssh_cmd.extend(['-o', 'StrictHostKeyChecking=no', '-o', 'UserKnownHostsFile=/dev/null'])\n         ssh_cmd_str = ' '.join(shlex_quote(arg) for arg in ssh_cmd)\n         if ssh_args:\n             ssh_cmd_str += ' %s' % ssh_args\n", "before": "ssh_cmd . extend ( [ '-o' , 'StrictHostKeyChecking=no' ] )", "after": "ssh_cmd . extend ( [ '-o' , 'StrictHostKeyChecking=no' , '-o' , 'UserKnownHostsFile=/dev/null' ] )", "sstub_pattern": "ADD_ELEMENTS_TO_ITERABLE", "edit_script": "[[\"Insert\", [\"list\", 3, 28, 3, 62], [\",:,\", \"T\"], 4], [\"Insert\", [\"list\", 3, 28, 3, 62], [\"string:'-o'\", \"T\"], 5], [\"Insert\", [\"list\", 3, 28, 3, 62], [\",:,\", \"T\"], 6], [\"Insert\", [\"list\", 3, 28, 3, 62], [\"string:'UserKnownHostsFile=/dev/null'\", \"T\"], 7]]"}
{"project": "testinfra", "commit_sha": "493dd0af5729aadb5007b2b021a6da34b040c11f", "parent_sha": "e907a60710613fdb351e09aa9807d0b75b091c8b", "file_path": "testinfra/plugin.py", "project_url": "https://github.com/underdogio/testinfra", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ def _get_testinfra_hosts():\n     # with pytest.mark.parametrize().\n     # See https://github.com/pytest-dev/pytest/issues/896\n     # This is a ugly working workaround\n-    parser = argparse.ArgumentParser()\n+    parser = argparse.ArgumentParser(add_help=False)\n     parser.add_argument(\"--hosts\", action=\"store\", dest=\"hosts\")\n     known_args, _ = parser.parse_known_args()\n     if known_args.hosts is None:\n", "before": "parser = argparse . ArgumentParser ( )", "after": "parser = argparse . ArgumentParser ( add_help = False )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 37, 3, 39], [\"keyword_argument\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:add_help\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"false:False\", \"T\"], 2]]"}
{"project": "testinfra", "commit_sha": "9c5da09b8b39852551e5684bfc807751e47549dd", "parent_sha": "51d5b86f95506e44033d5d09f00224b55c097e71", "file_path": "testinfra/backend/salt.py", "project_url": "https://github.com/underdogio/testinfra", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -50,7 +50,7 @@ class SaltBackend(base.BaseBackend):\n         command = self.quote(command, *args)\n         out = self.run_salt(\"cmd.run_all\", [command])\n         return base.CommandResult(\n-            out['retcode'], out['stdout'], out['stderr'], command)\n+            self, out['retcode'], out['stdout'], out['stderr'], command)\n \n     def run_salt(self, func, args=None):\n         return self.client.cmd(self.host, func, args or [])[self.host]\n", "before": "return base . CommandResult ( out [ 'retcode' ] , out [ 'stdout' ] , out [ 'stderr' ] , command )", "after": "return base . CommandResult ( self , out [ 'retcode' ] , out [ 'stdout' ] , out [ 'stderr' ] , command )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 34, 3, 67], [\"identifier:self\", \"T\"], 1], [\"Insert\", [\"argument_list\", 2, 34, 3, 67], [\",:,\", \"T\"], 2]]"}
{"project": "nixops", "commit_sha": "789139f8ea2a74ff5f0b2e3f5b5e78a18515f712", "parent_sha": "05438581445beb190638750db81bc5e5b44945a4", "file_path": "nixops/backends/ec2.py", "project_url": "https://github.com/zalora/nixops", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -744,7 +744,7 @@ class EC2State(MachineState):\n \n             # Generate a public/private host key.\n             if not self.public_host_key:\n-                (private, public) = nixops.util.create_key_pair()\n+                (private, public) = nixops.util.create_key_pair(type='dsa')\n                 with self.depl._db:\n                     self.public_host_key = public\n                     self.private_host_key = private\n", "before": "( private , public ) = nixops . util . create_key_pair ( )", "after": "( private , public ) = nixops . util . create_key_pair ( type = 'dsa' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 64, 3, 66], [\"keyword_argument\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:type\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'dsa'\", \"T\"], 2]]"}
{"project": "flask-rauth", "commit_sha": "6ff74a70e8a9325e69bf0839c717288d88973246", "parent_sha": "b4dc7dda8c9f389bf8269ac04a6fa2ee62bc0a88", "file_path": "flaskext/oauth.py", "project_url": "https://github.com/underdogio/flask-rauth", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -264,7 +264,7 @@ class OAuthRemoteApp(object):\n         return oauth2.Token(*rv)\n \n     def free_request_token(self):\n-        session.pop(self.name + '_oauthtok')\n+        session.pop(self.name + '_oauthtok', None)\n \n     def authorize(self, callback=None):\n", "before": "session . pop ( self . name + '_oauthtok' )", "after": "session . pop ( self . name + '_oauthtok' , None )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 20, 3, 45], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 20, 3, 45], [\"none:None\", \"T\"], 3]]"}
{"project": "gitinspector", "commit_sha": "28871199dfe5805960f0ccfba12b00505640378d", "parent_sha": "695a2b98df09043e86ce3f60b9f6544263fc2775", "file_path": "missing.py", "project_url": "https://github.com/hugorodgerbrown/gitinspector", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ __missing_files__ =  set()\n def add(file_name):\n \tif not os.path.exists(file_name):\n \t\tif __checkout_missing__:\n-\t\t\tsubprocess.call(\"git checkout \\\"\" + file_name.strip() + \"\\\"\")\n+\t\t\tsubprocess.call(\"git checkout \\\"\" + file_name.strip() + \"\\\"\", shell=True)\n \t\telse:\n \t\t\t__missing_files__.add(file_name)\n \t\t\treturn True\n", "before": "subprocess . call ( \"git checkout \\\"\" + file_name . strip ( ) + \"\\\"\" )", "after": "subprocess . call ( \"git checkout \\\"\" + file_name . strip ( ) + \"\\\"\" , shell = True )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 19, 3, 65], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 19, 3, 65], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:shell\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"true:True\", \"T\"], 2]]"}
{"project": "shipyard", "commit_sha": "e5a1f11739bc75b6f084e242047cda488e73f766", "parent_sha": "5992785cf6df5fe37cbfa9ea0f4499e68138cc39", "file_path": "applications/forms.py", "project_url": "https://github.com/mayflower/shipyard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ class ApplicationForm(forms.ModelForm):\n             if not port_proto in container_ports:\n                 msg = _(u'Port %s is not available on the selected containers.' % port_proto)\n                 self._errors['backend_port'] = self.error_class([msg])\n-            if not container_ports.get(port_proto).get(interface):\n+            if not container_ports.get(port_proto, {}).get(interface):\n                 msg = _(u'Port %s is not bound to the interface %s on the selected containers.' % (port_proto, interface))\n                 self._errors['host_interface'] = self.error_class([msg])\n \n", "before": "if not container_ports . get ( port_proto ) . get ( interface ) : msg = _ ( u'Port %s is not bound to the interface %s on the selected containers.' % ( port_proto , interface ) ) self . _errors [ 'host_interface' ] = self . error_class ( [ msg ] )", "after": "if not container_ports . get ( port_proto , { } ) . get ( interface ) : msg = _ ( u'Port %s is not bound to the interface %s on the selected containers.' % ( port_proto , interface ) ) self . _errors [ 'host_interface' ] = self . error_class ( [ msg ] )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 39, 3, 51], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 39, 3, 51], [\"dictionary\", \"N0\"], 3], [\"Insert\", \"N0\", [\"{:{\", \"T\"], 0], [\"Insert\", \"N0\", [\"}:}\", \"T\"], 1]]"}
{"project": "stoq", "commit_sha": "740fb75f743919200f8e4591ce64ea27f5a07731", "parent_sha": "a7aacc1c36a366de1ada516e10deee6f9946f326", "file_path": "stoqlib/domain/sale.py", "project_url": "https://github.com/bellini666/stoq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -337,7 +337,7 @@ class Sale(Domain):\n         if not self.status == self.STATUS_OPENED:\n             raise SellError('The sale must have STATUS_OPENED for this '\n                             'operation, got status %s instead'\n-                            % self.get_status_name())\n+                            % self.get_status_name(self.status))\n         conn = self.get_connection()\n         group = IPaymentGroup(self, connection=conn)\n         if not group:\n", "before": "raise SellError ( 'The sale must have STATUS_OPENED for this ' 'operation, got status %s instead' % self . get_status_name ( ) )", "after": "raise SellError ( 'The sale must have STATUS_OPENED for this ' 'operation, got status %s instead' % self . get_status_name ( self . status ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 51, 3, 53], [\"attribute\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:status\", \"T\"], 2]]"}
{"project": "stoq", "commit_sha": "7e27120e78d05657d0f62d116cb0fce3d0484b3c", "parent_sha": "25ccb15e6d3c480eddce15927259e0d6125cd5a3", "file_path": "tests/test_fiscal.py", "project_url": "https://github.com/bellini666/stoq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -111,7 +111,7 @@ class TestAbstractFiscalBookEntry(BaseDomainTest):\n \n     def test_reverse_entry(self):\n         afbe = get_abstract_fiscal_book_entry(self.trans, 1)\n-        self.assertRaises(NotImplementedError, afbe.reverse_entry)\n+        self.assertRaises(NotImplementedError, afbe.reverse_entry, 1)\n \n     def test_get_reversal_clone(self):\n         afbe = get_abstract_fiscal_book_entry(self.trans, 2)\n", "before": "self . assertRaises ( NotImplementedError , afbe . reverse_entry )", "after": "self . assertRaises ( NotImplementedError , afbe . reverse_entry , 1 )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 67], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 26, 3, 67], [\"integer:1\", \"T\"], 5]]"}
{"project": "librosa", "commit_sha": "99632865c361bcc76abfdae8e88871f3096e00d6", "parent_sha": "499e060f108bd2c7d392aa11ce66f4438285d47e", "file_path": "librosa/__init__.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ def load(path, mono=True, frame_size=1024):\n \n     with audioread.audio_open(path) as f:\n         sr  = f.samplerate\n-        y   = numpy.concatenate([frame for frame in framegenerator.audioread_timeseries(f, frame_size)], axis=0)\n+        y   = numpy.concatenate([frame for frame in framegenerator.audioread_timeseries(f, frame_size, mono=mono)], axis=0)\n         pass\n \n     return (y, sr)\n", "before": "y = numpy . concatenate ( [ frame for frame in framegenerator . audioread_timeseries ( f , frame_size ) ] , axis = 0 )", "after": "y = numpy . concatenate ( [ frame for frame in framegenerator . audioread_timeseries ( f , frame_size , mono = mono ) ] , axis = 0 )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 88, 3, 103], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 88, 3, 103], [\"keyword_argument\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:mono\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:mono\", \"T\"], 2]]"}
{"project": "pysolr", "commit_sha": "ba3a444b101c6d26af82098397072d8c12224642", "parent_sha": "f1cccc94b5ca8f474b9fdef2068c0ec2c8802bc2", "file_path": "pysolr.py", "project_url": "https://github.com/acdha/pysolr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1205,7 +1205,7 @@ class ZooKeeper(object):\n         self.aliases = {}\n         self.state = None\n \n-        self.zk = KazooClient(zkServerAddress, read_only=True)\n+        self.zk = KazooClient(zkServerAddress, read_only=True, timeout=zkClientTimeout)\n \n         self.zk.start()\n \n", "before": "self . zk = KazooClient ( zkServerAddress , read_only = True )", "after": "self . zk = KazooClient ( zkServerAddress , read_only = True , timeout = zkClientTimeout )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 63], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 30, 3, 63], [\"keyword_argument\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:timeout\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:zkClientTimeout\", \"T\"], 2]]"}
{"project": "ipython-sql", "commit_sha": "cba96e48c49b747d8d97b05c7173fd3cfa1eaeea", "parent_sha": "20a2c584069a285d7625bba70f247c755103d545", "file_path": "src/sql/magic.py", "project_url": "https://github.com/KarolTx/ipython-sql", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -32,7 +32,7 @@ class SQLMagics(Magics):\n \n     def __init__(self, shell):\n         super(SQLMagics, self).__init__(shell)\n-        self.config = SqlMagic()\n+        self.config = SqlMagic(config=self.shell.config)\n         # Add ourself to the list of module configurable via %config\n         self.shell.configurables.append(self.config)\n     \n", "before": "self . config = SqlMagic ( )", "after": "self . config = SqlMagic ( config = self . shell . config )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 31, 3, 33], [\"keyword_argument\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:config\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:config\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:shell\", \"T\"], 2]]"}
{"project": "rpm-gitoverlay", "commit_sha": "ee9189826bdad65f47891744b2ed0a3033bc26f0", "parent_sha": "3cba2325813845ad3a610d5767077563edf9ff6c", "file_path": "rgo/__main__.py", "project_url": "https://github.com/ignatenkobrain/rpm-gitoverlay", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ def add_build_actions(parser):\n \n def main():\n     parser = argparse.ArgumentParser()\n-    parser.add_argument(\"--log\", help=\"Log level\",\n+    parser.add_argument(\"--log\", help=\"Log level\", default=\"INFO\",\n                         choices=(\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"))\n     parser.add_argument(\"--gitdir\", default=os.path.join(os.getcwd(), \".rpm-gitoverlay\"),\n                         help=\"Directory with git repositories\")\n", "before": "parser . add_argument ( \"--log\" , help = \"Log level\" , choices = ( \"DEBUG\" , \"INFO\" , \"WARNING\" , \"ERROR\" , \"CRITICAL\" ) )", "after": "parser . add_argument ( \"--log\" , help = \"Log level\" , default = \"INFO\" , choices = ( \"DEBUG\" , \"INFO\" , \"WARNING\" , \"ERROR\" , \"CRITICAL\" ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 24, 4, 83], [\"keyword_argument\", \"N0\"], 5], [\"Insert\", [\"argument_list\", 3, 24, 4, 83], [\",:,\", \"T\"], 6], [\"Insert\", \"N0\", [\"identifier:default\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:\\\"INFO\\\"\", \"T\"], 2]]"}
{"project": "htcondenser", "commit_sha": "ef21cf296d88d365772193c0d98828e881c50b95", "parent_sha": "30315fa8ab6e40e66ac60ff64d231f81baece0ed", "file_path": "htcondenser/core/dagman.py", "project_url": "https://github.com/kreczko/htcondenser", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -111,7 +111,7 @@ class DAGMan(object):\n             raise TypeError('Cannot added a non-Job object to DAGMan.')\n \n         if job.name in self.jobs:\n-            raise KeyError()\n+            raise KeyError('Job with name %s already exists in DAG - names must be unique' % job.name)\n \n         # Append necessary job arguments to any user opts.\n         job_vars = job_vars or \"\"\n", "before": "raise KeyError ( )", "after": "raise KeyError ( 'Job with name %s already exists in DAG - names must be unique' % job . name )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 27, 3, 29], [\"binary_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"string:'Job with name %s already exists in DAG - names must be unique'\", \"T\"], 0], [\"Insert\", \"N0\", [\"%:%\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:job\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:name\", \"T\"], 2]]"}
{"project": "librosa", "commit_sha": "a3fbbf8239faedaf2ca98d9159d66efa8e11f124", "parent_sha": "442a169b94430bcdf048dd701fab14be9d23b906", "file_path": "librosa/cache.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,7 +16,7 @@ class CacheManager(Memory):\n \n     def __init__(self, cachedir, level=10, **kwargs):\n-        super().__init__(cachedir, **kwargs)\n+        super(CacheManager, self).__init__(cachedir, **kwargs)\n         # The level parameter controls which data we cache\n         # smaller numbers mean less caching\n         self.level = level\n", "before": "super ( ) . __init__ ( cachedir , ** kwargs )", "after": "super ( CacheManager , self ) . __init__ ( cachedir , ** kwargs )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 14, 2, 16], [\"identifier:CacheManager\", \"T\"], 1], [\"Insert\", [\"argument_list\", 2, 14, 2, 16], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 2, 14, 2, 16], [\"identifier:self\", \"T\"], 3]]"}
{"project": "librosa", "commit_sha": "5412339f66bcc1c573e6a65a6c579f78eb2fdef6", "parent_sha": "85bb9812576159ba04f70fc5ad59bedf5dba3765", "file_path": "librosa/core/audio.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -535,7 +535,7 @@ def resample(y, orig_sr, target_sr, res_type='kaiser_best', fix=True, scale=Fals\n     if scale:\n         y_hat /= np.sqrt(ratio)\n \n-    return np.asfortranarray(y_hat)\n+    return np.asfortranarray(y_hat, dtype=y.dtype)\n \n \n def get_duration(y=None, sr=22050, S=None, n_fft=2048, hop_length=512,\n", "before": "return np . asfortranarray ( y_hat )", "after": "return np . asfortranarray ( y_hat , dtype = y . dtype )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 29, 3, 36], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 29, 3, 36], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:dtype\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:y\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:dtype\", \"T\"], 2]]"}
{"project": "caplog", "commit_sha": "28592a69fe1f37b3c9a88a5e58378ca3770eeecb", "parent_sha": "f597847c2fc67847d859e52b6d429b048ce693ef", "file_path": "caplog.py", "project_url": "https://github.com/sheriferson/caplog", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,7 +14,7 @@ def from_unix_to_readable(unix_timestamp):\n     return(datetime.fromtimestamp(unix_timestamp).strftime('%B %d %Y %H:%M'))\n \n def add_log_message(logmessage):\n-    with open(log_file_path) as logfile:\n+    with open(log_file_path, 'a') as logfile:\n        logfile.write(logmessage) \n        logfile.write('\\n')\n \n", "before": "with open ( log_file_path ) as logfile : logfile . write ( logmessage ) logfile . write ( '\\n' )", "after": "with open ( log_file_path , 'a' ) as logfile : logfile . write ( logmessage ) logfile . write ( '\\n' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 14, 3, 29], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 14, 3, 29], [\"string:'a'\", \"T\"], 3]]"}
{"project": "mdtraj", "commit_sha": "e30284b2b8b33cf58a0c188238528cd8abe7312a", "parent_sha": "25d69ea48ea8750a26e036f1494000e3ade3e83b", "file_path": "examples/test_examples.py", "project_url": "https://github.com/Eigenstate/mdtraj", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ import nbformat\n from jupyter_client import KernelManager\n \n def test_examples():\n-    for f in os.listdir():\n+    for f in os.listdir('.'):\n         if f.endswith('.ipynb'):\n             yield check_one_notebook, f\n \n", "before": "for f in os . listdir ( ) : if f . endswith ( '.ipynb' ) : yield check_one_notebook , f", "after": "for f in os . listdir ( '.' ) : if f . endswith ( '.ipynb' ) : yield check_one_notebook , f", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 24, 3, 26], [\"string:'.'\", \"T\"], 1]]"}
{"project": "mdtraj", "commit_sha": "6ec390ff9761877dcf7ab467ee5673cfaa5a4c69", "parent_sha": "d0ede2ae22e2873c3187c3965a6221e191ad9e69", "file_path": "tests/test_mol2.py", "project_url": "https://github.com/Eigenstate/mdtraj", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -62,7 +62,7 @@ def test_load_freesolv_gaffmol2_vs_sybylmol2_vs_obabelpdb(get_fn, tmpdir):\n     tar.close()\n \n     with open(\"./v0.3/database.pickle\", 'rb') as f:\n-        database = pickle.load(f)\n+        database = pickle.load(f, encoding='latin-1')\n \n     for key in database:\n", "before": "database = pickle . load ( f )", "after": "database = pickle . load ( f , encoding = 'latin-1' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 31, 3, 34], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 31, 3, 34], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:encoding\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'latin-1'\", \"T\"], 2]]"}
{"project": "rq", "commit_sha": "e2f398be8001b409326d640ad551603468b80f17", "parent_sha": "69adec5bc73a51a2f70e8ab0db287566edd1b483", "file_path": "rq/scripts/rqworker.py", "project_url": "https://github.com/dronedeploy/rq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ def parse_args():\n     parser.add_argument('--job-class', '-j', action='store', default='rq.job.Job', help='RQ Job class to use')\n     parser.add_argument('--path', '-P', default='.', help='Specify the import path.')\n     parser.add_argument('--results-ttl', default=None, help='Default results timeout to be used')\n-    parser.add_argument('--worker-ttl', default=None, help='Default worker timeout to be used')\n+    parser.add_argument('--worker-ttl', type=int, default=None, help='Default worker timeout to be used')\n     parser.add_argument('--verbose', '-v', action='store_true', default=False, help='Show more output')\n     parser.add_argument('--quiet', '-q', action='store_true', default=False, help='Show less output')\n     parser.add_argument('--sentry-dsn', action='store', default=None, metavar='URL', help='Report exceptions to this Sentry DSN')  # noqa\n", "before": "parser . add_argument ( '--worker-ttl' , default = None , help = 'Default worker timeout to be used' )", "after": "parser . add_argument ( '--worker-ttl' , type = int , default = None , help = 'Default worker timeout to be used' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 24, 3, 96], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", [\"argument_list\", 3, 24, 3, 96], [\",:,\", \"T\"], 4], [\"Insert\", \"N0\", [\"identifier:type\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:int\", \"T\"], 2]]"}
{"project": "tribler", "commit_sha": "b85cccadebbdd8ab652c13a8904867a5660dbbcb", "parent_sha": "77f67ac86328719635385827aac63d265ded0086", "file_path": "Tribler/Core/TorrentDef.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -136,7 +136,7 @@ class TorrentDef(object):\n         # Class method, no locking required\n         try:\n-            response = requests.get(url, timeout=30)\n+            response = requests.get(url, timeout=30, verify=False)\n             if response.ok:\n                 return TorrentDef.load_from_memory(response.content)\n \n", "before": "response = requests . get ( url , timeout = 30 )", "after": "response = requests . get ( url , timeout = 30 , verify = False )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 36, 2, 53], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 2, 36, 2, 53], [\"keyword_argument\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:verify\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"false:False\", \"T\"], 2]]"}
{"project": "py-util", "commit_sha": "3e4d3080e0f1a2772e4425a30e5d61ee7346c71d", "parent_sha": "a980a04a4995e4aa422e540e2a8a83910e6b53d9", "file_path": "s/dicts.py", "project_url": "https://github.com/nathants/py-util", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,7 +35,7 @@ def _merge(k, a, b, concat, freeze):\n     assert k in a or k in b, '{k} not in {a} or {b}'.format(**locals())\n     if k in a and k in b:\n         if isinstance(a[k], dict) and isinstance(b[k], dict):\n-            return merge(a[k], b[k], concat)\n+            return merge(a[k], b[k], concat, freeze)\n         elif concat and _concatable(a[k], b[k]):\n             return a[k] + b[k]\n         else:\n", "before": "return merge ( a [ k ] , b [ k ] , concat )", "after": "return merge ( a [ k ] , b [ k ] , concat , freeze )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 25, 3, 45], [\",:,\", \"T\"], 6], [\"Insert\", [\"argument_list\", 3, 25, 3, 45], [\"identifier:freeze\", \"T\"], 7]]"}
{"project": "tribler", "commit_sha": "4b98550ed59d76b939a1b4971c26015be1766591", "parent_sha": "603f64cdb9d70e657b4fcb2e0c3bd89bd95d6088", "file_path": "Tribler/Core/Libtorrent/LibtorrentDownloadImpl.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -829,7 +829,7 @@ class LibtorrentDownloadImpl(DownloadRuntimeConfig):\n                 return self.get_byte_progress([(self.get_vod_fileindex(), self.vod_seekpos, self.vod_seekpos + self.prebuffsize), \\\r\n                                                (self.get_vod_fileindex(), -self.endbuffsize - 1, -1)], consecutive=True)\r\n             else:\r\n-                return self.get_byte_progress([(self.get_vod_fileindex(), self.vod_seekpos, self.vod_seekpos + self.prebuffsize)])\r\n+                return self.get_byte_progress([(self.get_vod_fileindex(), self.vod_seekpos, self.vod_seekpos + self.prebuffsize)], consecutive=True)\r\n         else:\r\n             return 0.0\r\n \r\n", "before": "else : return self . get_byte_progress ( [ ( self . get_vod_fileindex ( ) , self . vod_seekpos , self . vod_seekpos + self . prebuffsize ) ] )", "after": "else : return self . get_byte_progress ( [ ( self . get_vod_fileindex ( ) , self . vod_seekpos , self . vod_seekpos + self . prebuffsize ) ] , consecutive = True )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 46, 3, 131], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 46, 3, 131], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:consecutive\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"true:True\", \"T\"], 2]]"}
{"project": "tribler", "commit_sha": "c25d3f997793d912ebeb0729f344cc746753adf9", "parent_sha": "2f1cd4ae193e7767e4350f1e07529fe3b81c452d", "file_path": "Tribler/community/walktest/community.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -68,7 +68,7 @@ class WalktestCommunity(Community):\n \n     def create_contact(self, destination, identifier):\n         meta = self._meta_messages[u\"contact\"]\n-        message = meta.impl(destination=(destination,), payload=(identifier,))\n+        message = meta.impl(distribution=(self.global_time,), destination=(destination,), payload=(identifier,))\n         self._dispersy.store_update_forward([message], False, False, True)\n \n         log(\"walktest.log\",\n", "before": "message = meta . impl ( destination = ( destination , ) , payload = ( identifier , ) )", "after": "message = meta . impl ( distribution = ( self . global_time , ) , destination = ( destination , ) , payload = ( identifier , ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 28, 3, 79], [\"keyword_argument\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 28, 3, 79], [\",:,\", \"T\"], 2], [\"Insert\", \"N0\", [\"identifier:distribution\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"tuple\", \"N1\"], 2], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 1], [\"Insert\", \"N1\", [\",:,\", \"T\"], 2], [\"Insert\", \"N1\", [\"):)\", \"T\"], 3], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:global_time\", \"T\"], 2]]"}
{"project": "CloudBot", "commit_sha": "39744d714a11fb7ed9835cafd192406a74772092", "parent_sha": "1670e1d8ac313808f05df3a2bf6d4e67d5ae78ac", "file_path": "plugins/misc.py", "project_url": "https://github.com/MrW24/CloudBot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,7 +52,7 @@ def onjoin(paraml, conn=None, bot=None):\n         time.sleep(1)\n \n # Stay-alive code\n-    stayalive = conn.conf.get('stayalive')\n+    stayalive = conn.conf.get('stayalive', False)\n     if stayalive:\n         delay = conn.conf.get('stayalive_delay', 20)\n         while True:\n", "before": "stayalive = conn . conf . get ( 'stayalive' )", "after": "stayalive = conn . conf . get ( 'stayalive' , False )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 43], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 30, 3, 43], [\"false:False\", \"T\"], 3]]"}
{"project": "more-executors", "commit_sha": "4393f265ec2f87379d7efe7d326693af38d711e9", "parent_sha": "17b69518bc91b1708243f7034048046156bffcdc", "file_path": "tests/test_retry.py", "project_url": "https://github.com/rohanpm/more-executors", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ def test_basic_retry(executor):\n         future.add_done_callback(done_callback)\n \n         # It should give the correct result\n-        assert_that(future.result(), equal_to('result'))\n+        assert_that(future.result(10), equal_to('result'))\n \n         # It should not have any exception\n         assert_that(future.exception(), is_(None))\n", "before": "assert_that ( future . result ( ) , equal_to ( 'result' ) )", "after": "assert_that ( future . result ( 10 ) , equal_to ( 'result' ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 34, 3, 36], [\"integer:10\", \"T\"], 1]]"}
{"project": "getmyancestors", "commit_sha": "c5229aaa01d1f2bf4864f145c8e8f51b08d2530b", "parent_sha": "04510c67b9e0303dfb3901a089814287dc985950", "file_path": "gui.py", "project_url": "https://github.com/Linekio/getmyancestors", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -79,7 +79,7 @@ class Options(Frame):\n         askfilename.pack()\n \n     def askfilename(self):\n-        self.filename = filedialog.asksaveasfilename()\n+        self.filename = filedialog.asksaveasfilename(title='Save as', filetypes=(('GEDCOM files', '.ged'), ('All files', '*.*')))\n \n     def add_indi(self, data=None):\n         new_indi = StartIndi(self.indis)\n", "before": "self . filename = filedialog . asksaveasfilename ( )", "after": "self . filename = filedialog . asksaveasfilename ( title = 'Save as' , filetypes = ( ( 'GEDCOM files' , '.ged' ) , ( 'All files' , '*.*' ) ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 53, 3, 55], [\"keyword_argument\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 53, 3, 55], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 53, 3, 55], [\"keyword_argument\", \"N1\"], 3], [\"Insert\", [\"argument_list\", 3, 53, 3, 55], [\"):)\", \"T\"], 4], [\"Insert\", \"N0\", [\"identifier:title\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'Save as'\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:filetypes\", \"T\"], 0], [\"Insert\", \"N1\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N1\", [\"tuple\", \"N2\"], 2], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N2\", [\"tuple\", \"N3\"], 1], [\"Insert\", \"N2\", [\",:,\", \"T\"], 2], [\"Insert\", \"N2\", [\"tuple\", \"N4\"], 3], [\"Insert\", \"N2\", [\"):)\", \"T\"], 4], [\"Insert\", \"N3\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N3\", [\"string:'GEDCOM files'\", \"T\"], 1], [\"Insert\", \"N3\", [\",:,\", \"T\"], 2], [\"Insert\", \"N3\", [\"string:'.ged'\", \"T\"], 3], [\"Move\", \"N3\", [\"):)\", 3, 54, 3, 55], 4], [\"Insert\", \"N4\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N4\", [\"string:'All files'\", \"T\"], 1], [\"Insert\", \"N4\", [\",:,\", \"T\"], 2], [\"Insert\", \"N4\", [\"string:'*.*'\", \"T\"], 3], [\"Insert\", \"N4\", [\"):)\", \"T\"], 4]]"}
{"project": "valhallaAPI", "commit_sha": "de0a3d1518ebec2a17f5383a97ed76f4faf5e7cf", "parent_sha": "41e72750c06196f6f9d0376186346008ca5dc59a", "file_path": "valhallaAPI/valhalla.py", "project_url": "https://github.com/NextronSystems/valhallaAPI", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -94,7 +94,7 @@ class ValhallaAPI(object):\n-        r = requests.get(\"%s/quote\" % self.base_url, verify=self.verify_ssl)\n+        r = requests.get(\"%s/quote\" % self.base_url, verify=self.verify_ssl, proxies=self.proxies)\n         return r.text\n \n     def get_status(self):\n", "before": "r = requests . get ( \"%s/quote\" % self . base_url , verify = self . verify_ssl )", "after": "r = requests . get ( \"%s/quote\" % self . base_url , verify = self . verify_ssl , proxies = self . proxies )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 0, 25, 0, 77], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 0, 25, 0, 77], [\"keyword_argument\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:proxies\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:proxies\", \"T\"], 2]]"}
{"project": "Skynet2.0", "commit_sha": "87dadbf70074e62e17dd7b2a3648ad9fa19efe57", "parent_sha": "019d463d899ac56a2a48c8c1b8a0b0ede5820ab2", "file_path": "src/agent/SSH.py", "project_url": "https://github.com/Skynet2-0/Skynet2.0", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -19,7 +19,7 @@ class SSH(object):\n         self.pwd = pwd\n         self.client = SSHClient()\n         self.client.load_system_host_keys()\n-        self.connect(self.ip)\n+        self.connect(self.ip, self.username, self.pwd)\n \n     def connect(self, sshhost, user = None, pwd = None):\n", "before": "self . connect ( self . ip )", "after": "self . connect ( self . ip , self . username , self . pwd )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 21, 3, 30], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 21, 3, 30], [\"attribute\", \"N0\"], 3], [\"Insert\", [\"argument_list\", 3, 21, 3, 30], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 21, 3, 30], [\"attribute\", \"N1\"], 5], [\"Insert\", \"N0\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:username\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:pwd\", \"T\"], 2]]"}
{"project": "cc-utils", "commit_sha": "d93c48a47ee86d50d0efdd0021dcfff47dbd8683", "parent_sha": "cf8d73b08fe0370c88979f183665ed476fe470fc", "file_path": "doc/lib/sphinxutil.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ class SphinxUtilsMixin(object):\n         for line in lines:\n             text_nodes, messages = self.state.inline_text(line, self.lineno + self.content_offset)\n             parse_msgs += messages\n-            par_node = nodes.paragraph('', *text_nodes)\n+            par_node = nodes.paragraph('', '', *text_nodes)\n             list_item = nodes.list_item('', par_node)\n             bullet_list += list_item\n \n", "before": "par_node = nodes . paragraph ( '' , * text_nodes )", "after": "par_node = nodes . paragraph ( '' , '' , * text_nodes )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 39, 3, 56], [\"string:''\", \"T\"], 3], [\"Insert\", [\"argument_list\", 3, 39, 3, 56], [\",:,\", \"T\"], 4]]"}
{"project": "cc-utils", "commit_sha": "e438d659e837b63dfdba6257acb7c73695830d5b", "parent_sha": "883b4924750228dcec2621ed1a991ccb74a6be9d", "file_path": "util.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -146,7 +146,7 @@ def verbose(msg:str):\n     if not _verbose():\n         return\n     if msg:\n-        _print('VERBOSE: ' + msg)\n+        _print('VERBOSE: ' + msg, colour=None)\n \n \n def not_empty(value):\n", "before": "_print ( 'VERBOSE: ' + msg )", "after": "_print ( 'VERBOSE: ' + msg , colour = None )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 15, 3, 34], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 15, 3, 34], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:colour\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"none:None\", \"T\"], 2]]"}
{"project": "cc-utils", "commit_sha": "23ae5cb4e595440badb4a298a0c0dc0b0b60f1ea", "parent_sha": "30a93322e97a0a7a969c59f06eb7d65e9c3b41c1", "file_path": "ccc/elasticsearch.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -47,7 +47,7 @@ def _metadata_dict():\n         return {}\n \n     # XXX do not hard-code meta-dir\n-    meta_dir = util.existing_dir(os.path.join(util._root_dir()))\n+    meta_dir = util.existing_dir(os.path.join(util._root_dir(), 'meta'))\n     attrs = (\n         'atc-external-url',\n         'build-team-name',\n", "before": "meta_dir = util . existing_dir ( os . path . join ( util . _root_dir ( ) ) )", "after": "meta_dir = util . existing_dir ( os . path . join ( util . _root_dir ( ) , 'meta' ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 46, 3, 64], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 46, 3, 64], [\"string:'meta'\", \"T\"], 3]]"}
{"project": "cc-utils", "commit_sha": "2da4244f199fbeab78fbd78f8da28bd13e85f3dd", "parent_sha": "b3ae20a9298cffa1f2c4441d28d667c2fb58161a", "file_path": "protecode/client.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ class ProtecodeApiRoutes(object):\n         return self._api_url('upload', quote(file_name))\n \n     def product(self, product_id: int):\n-        return self._api_url('product')\n+        return self._api_url('product', str(product_id))\n \n     def product_custom_data(self, product_id: int):\n         return self._api_url('product', str(product_id), 'custom-data')\n", "before": "return self . _api_url ( 'product' )", "after": "return self . _api_url ( 'product' , str ( product_id ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 29, 3, 40], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 29, 3, 40], [\"call\", \"N0\"], 3], [\"Insert\", [\"argument_list\", 3, 29, 3, 40], [\"):)\", \"T\"], 4], [\"Insert\", \"N0\", [\"identifier:str\", \"T\"], 0], [\"Insert\", \"N0\", [\"argument_list\", \"N1\"], 1], [\"Insert\", \"N1\", [\"(:(\", \"T\"], 0], [\"Insert\", \"N1\", [\"identifier:product_id\", \"T\"], 1], [\"Move\", \"N1\", [\"):)\", 3, 39, 3, 40], 2]]"}
{"project": "WMAS", "commit_sha": "4b530ede78437a334181e5b4da52c91964c9c3e3", "parent_sha": "688a73bbd076ffba33d663867fc48054e02a7dcb", "file_path": "wptserve/handlers.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -113,7 +113,7 @@ class FileHandler(object):\n                     for line in headers_file if line]\n \n     def get_data(self, response, path, byte_ranges):\n-        with open(path) as f:\n+        with open(path , 'rb') as f:\n             if byte_ranges is None:\n                 return f.read()\n             else:\n", "before": "for line in headers_file if line ] def get_data ( self , response , path , byte_ranges ) : with open ( path ) as f : if byte_ranges is None : return f . read ( ) else : ", "after": "for line in headers_file if line ] def get_data ( self , response , path , byte_ranges ) : with open ( path , 'rb' ) as f : if byte_ranges is None : return f . read ( ) else : ", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 18, 3, 24], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 18, 3, 24], [\"string:'rb'\", \"T\"], 3]]"}
{"project": "WMAS", "commit_sha": "a1de23740cb079b71517dff563b919416198e6ca", "parent_sha": "d44e0531e8ca9b0e44a794a013b5cc42f22f5528", "file_path": "tools/wpt/virtualenv.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -21,7 +21,7 @@ class Virtualenv(object):\n     def create(self):\n         if os.path.exists(self.path):\n             shutil.rmtree(self.path)\n-        call(self.virtualenv, self.path)\n+        call(self.virtualenv, self.path, \"-p\", sys.executable)\n \n     @property\n     def bin_path(self):\n", "before": "call ( self . virtualenv , self . path )", "after": "call ( self . virtualenv , self . path , \"-p\" , sys . executable )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 13, 3, 41], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 13, 3, 41], [\"string:\\\"-p\\\"\", \"T\"], 5], [\"Insert\", [\"argument_list\", 3, 13, 3, 41], [\",:,\", \"T\"], 6], [\"Insert\", [\"argument_list\", 3, 13, 3, 41], [\"attribute\", \"N0\"], 7], [\"Insert\", \"N0\", [\"identifier:sys\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:executable\", \"T\"], 2]]"}
{"project": "FreeCAD_assembly3", "commit_sha": "bcaded5b436d59a757c7e79e84a1de731d46568d", "parent_sha": "b5489b8a9b7cdf2b7a0e9a9672a32cfae79fa1e1", "file_path": "system.py", "project_url": "https://github.com/realthunder/FreeCAD_assembly3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -237,7 +237,7 @@ class SystemExtension(object):\n         if count<0:\n             return\n         if count:\n-            return self.addPlaneCoincident(False,0,e1,e2,group)\n+            return self.addPlaneCoincident(False,0,0,e1,e2,group)\n         w1,p1,n1 = e1[:3]\n         _,p2,n2 = e2[:3]\n         n1,nx1 = n1[:2]\n", "before": "return self . addPlaneCoincident ( False , 0 , e1 , e2 , group )", "after": "return self . addPlaneCoincident ( False , 0 , 0 , e1 , e2 , group )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Move\", [\"identifier:e1\", 3, 52, 3, 54], [\"argument_list\", 3, 43, 3, 64], 6], [\"Move\", [\"identifier:e2\", 3, 55, 3, 57], [\"argument_list\", 3, 43, 3, 64], 9], [\"Insert\", [\"argument_list\", 3, 43, 3, 64], [\"integer:0\", \"T\"], 5], [\"Insert\", [\"argument_list\", 3, 43, 3, 64], [\",:,\", \"T\"], 9]]"}
{"project": "FreeCAD_assembly3", "commit_sha": "fa8a0e00d0e0e204c1e1d7dcaf0bf3a96dc317c3", "parent_sha": "cc91aa105fd4da6d771e36c174726d3aeaf5eeff", "file_path": "mover.py", "project_url": "https://github.com/realthunder/FreeCAD_assembly3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -345,7 +345,7 @@ class AsmQuickMover:\n                 \"SoMouseButtonEvent\",self.clickMouse)\n         self.callbackKey = self.view.addEventCallback(\n                 \"SoKeyboardEvent\",self.keyboardEvent)\n-        FreeCAD.setActiveTransaction('Assembly quick move')\n+        FreeCAD.setActiveTransaction('Assembly quick move',True)\n         self.active = True\n \n     def moveMouse(self, info):\n", "before": "FreeCAD . setActiveTransaction ( 'Assembly quick move' )", "after": "FreeCAD . setActiveTransaction ( 'Assembly quick move' , True )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 37, 3, 60], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 37, 3, 60], [\"true:True\", \"T\"], 3]]"}
{"project": "FreeCAD_assembly3", "commit_sha": "6725da5c915e936307fa1fdf21ceddd93667d54c", "parent_sha": "f1d1547e8e82d1c9e03334f3e752a371a127e8c8", "file_path": "freecad/asm3/assembly.py", "project_url": "https://github.com/realthunder/FreeCAD_assembly3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ def getProxy(obj,tp):\n \n def hasProperty(obj,prop):\n     try:\n-        obj.getPropertyByName(prop)\n+        obj.getPropertyByName(prop,1)\n         return True\n     except Exception:\n         return False\n", "before": "obj . getPropertyByName ( prop )", "after": "obj . getPropertyByName ( prop , 1 )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 36], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 30, 3, 36], [\"integer:1\", \"T\"], 3]]"}
{"project": "WMAS", "commit_sha": "bff4c17ccd913724ac15a8b0bb101ddf4e0c0822", "parent_sha": "404f561840b8d96a61b3fc7a10aed8d2d7e4e9b2", "file_path": "wptrunner/testloader.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -496,7 +496,7 @@ class TestLoader(object):\n     def iter_tests(self):\n         manifest_items = []\n \n-        for manifest in sorted(self.manifests.keys()):\n+        for manifest in sorted(self.manifests.keys(), key=lambda x:x.url_base):\n             manifest_iter = iterfilter(self.manifest_filters,\n                                        manifest.itertypes(*self.test_types))\n             manifest_items.extend(manifest_iter)\n", "before": "for manifest in sorted ( self . manifests . keys ( ) ) : manifest_iter = iterfilter ( self . manifest_filters , manifest . itertypes ( * self . test_types ) ) manifest_items . extend ( manifest_iter )", "after": "for manifest in sorted ( self . manifests . keys ( ) , key = lambda x : x . url_base ) : manifest_iter = iterfilter ( self . manifest_filters , manifest . itertypes ( * self . test_types ) ) manifest_items . extend ( manifest_iter )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 31, 3, 54], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 31, 3, 54], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:key\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"lambda\", \"N1\"], 2], [\"Insert\", \"N1\", [\"lambda:lambda\", \"T\"], 0], [\"Insert\", \"N1\", [\"lambda_parameters\", \"N2\"], 1], [\"Insert\", \"N1\", [\":::\", \"T\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 3], [\"Insert\", \"N2\", [\"identifier:x\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:x\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:url_base\", \"T\"], 2]]"}
{"project": "WMAS", "commit_sha": "2ace42a7c70dd7079ca41470b9a3567b2632e162", "parent_sha": "04792aa1e5a171cabcfa363dd80aed6b24f4397b", "file_path": "cors/resources/cors-makeheader.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -36,7 +36,7 @@ def main(request, response):\n \n         #Log that the preflight actually happened if we have an ident\n         if 'token' in request.GET:\n-            request.server.stash.put(request.GET['token'])\n+            request.server.stash.put(request.GET['token'], True)\n \n     if 'location' in request.GET:\n         if code is None:\n", "before": "request . server . stash . put ( request . GET [ 'token' ] )", "after": "request . server . stash . put ( request . GET [ 'token' ] , True )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 37, 3, 59], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 37, 3, 59], [\"true:True\", \"T\"], 3]]"}
{"project": "WMAS", "commit_sha": "d431dd6965b54b223e14a294addf9467dd6fca78", "parent_sha": "f150522805b5723254e0a5d372177d1e93a92dbc", "file_path": "wptrunner/executors/executormarionette.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -508,7 +508,7 @@ class MarionetteRefTestExecutor(RefTestExecutor):\n \n         marionette.execute_async_script(self.wait_script)\n \n-        screenshot = marionette.screenshot()\n+        screenshot = marionette.screenshot(full=False)\n         # strip off the data:img/png, part of the url\n         if screenshot.startswith(\"data:image/png;base64,\"):\n             screenshot = screenshot.split(\",\", 1)[1]\n", "before": "screenshot = marionette . screenshot ( )", "after": "screenshot = marionette . screenshot ( full = False )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 43, 3, 45], [\"keyword_argument\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:full\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"false:False\", \"T\"], 2]]"}
{"project": "django-sql-utils", "commit_sha": "453701b13e9d8156f76c7d2b764c72ff8e973f9b", "parent_sha": "1b40dda0430ff633060dad6cbce3c47a93088656", "file_path": "sql_util/test.py", "project_url": "https://github.com/martsberger/django-sql-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ class TestParentChild(TestCase):\n \n     def test_function(self):\n         annotation = {\n-            'oldest_child_with_other': SubqueryMin(Coalesce('child__other_timestamp', 'child__timestamp'),\n+            'oldest_child_with_other': SubqueryMin(Coalesce('child__other_timestamp', 'child__timestamp', output_field=DateTimeField()),\n                                                    output_field=DateTimeField())\n         }\n         parents = Parent.objects.filter(name='John').annotate(**annotation)\n", "before": "annotation = { 'oldest_child_with_other' : SubqueryMin ( Coalesce ( 'child__other_timestamp' , 'child__timestamp' ) , output_field = DateTimeField ( ) ) }", "after": "annotation = { 'oldest_child_with_other' : SubqueryMin ( Coalesce ( 'child__other_timestamp' , 'child__timestamp' , output_field = DateTimeField ( ) ) , output_field = DateTimeField ( ) ) }", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 60, 3, 106], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 60, 3, 106], [\"keyword_argument\", \"N0\"], 5], [\"Insert\", [\"argument_list\", 3, 60, 3, 106], [\"):)\", \"T\"], 6], [\"Insert\", \"N0\", [\"identifier:output_field\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"call\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:DateTimeField\", \"T\"], 0], [\"Insert\", \"N1\", [\"argument_list\", \"N2\"], 1], [\"Insert\", \"N2\", [\"(:(\", \"T\"], 0], [\"Move\", \"N2\", [\"):)\", 3, 105, 3, 106], 1]]"}
{"project": "pros-cli3", "commit_sha": "80f2d5d9270e062ed4769b3b7004afed58f2cfec", "parent_sha": "03a9d1f34ed34b8cea418a88a408caada7160b1b", "file_path": "proscli/serial_terminal.py", "project_url": "https://github.com/purduesigbots/pros-cli3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -193,7 +193,7 @@ class Terminal(object):\n                     if self.output_raw:\r\n                         self.console.write_bytes(data)\r\n                     else:\r\n-                        text = data.decode('utf-8')\r\n+                        text = data.decode('utf-8', 'ignore')\r\n                         for transformation in self.transformations:\r\n                             text = transformation(text)\r\n                         self.console.write(text)\r\n", "before": "text = data . decode ( 'utf-8' )", "after": "text = data . decode ( 'utf-8' , 'ignore' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 43, 3, 52], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 43, 3, 52], [\"string:'ignore'\", \"T\"], 3]]"}
{"project": "docstring_parser", "commit_sha": "cf443d99e904476ec56253204ff20b3de8f6700b", "parent_sha": "8307018981a6eddcfd84a51bcece03966bf24edc", "file_path": "docstring_parser/rest.py", "project_url": "https://github.com/rr-/docstring_parser", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,7 +38,7 @@ def _build_meta(args: T.List[str], desc: str) -> DocstringMeta:\n                 f\"Expected one or two arguments for a {key} keyword.\"\n             )\n \n-        m = re.match(r\".*defaults to (.+)\", desc)\n+        m = re.match(r\".*defaults to (.+)\", desc, flags=re.DOTALL)\n         default = m.group(1).rstrip(\".\") if m else None\n \n         return DocstringParam(\n", "before": "m = re . match ( r\".*defaults to (.+)\" , desc )", "after": "m = re . match ( r\".*defaults to (.+)\" , desc , flags = re . DOTALL )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 21, 3, 50], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 21, 3, 50], [\"keyword_argument\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:flags\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:re\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:DOTALL\", \"T\"], 2]]"}
{"project": "pyMaid", "commit_sha": "adbb27bec545efa8391b0b3b670c03c5a50633f7", "parent_sha": "51bb7e6813598cafd77358039e2897effbdf850d", "file_path": "pymaid/cluster.py", "project_url": "https://github.com/schlegelp/pyMaid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -885,7 +885,7 @@ class clust_results:\n \n         # Second, convert into condensed distance matrix - otherwise clustering\n         # thinks we are passing observations instead of final scores\n-        self.condensed_dist_mat = scipy.spatial.distance.squareform( self.dist_mat )\n+        self.condensed_dist_mat = scipy.spatial.distance.squareform( self.dist_mat, checks=False )\n \n         self.linkage = scipy.cluster.hierarchy.linkage(self.condensed_dist_mat, method=method)\n \n", "before": "self . condensed_dist_mat = scipy . spatial . distance . squareform ( self . dist_mat )", "after": "self . condensed_dist_mat = scipy . spatial . distance . squareform ( self . dist_mat , checks = False )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 68, 3, 85], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 68, 3, 85], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:checks\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"false:False\", \"T\"], 2]]"}
{"project": "rdpy", "commit_sha": "c755148a3c3439fd152f9c3d3ad10d5014c8924e", "parent_sha": "3e1b8e57eb5c1cdaa142a58b07a3add6e9325eab", "file_path": "rdpy/protocol/rdp/x224.py", "project_url": "https://github.com/preempt/rdpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -303,7 +303,7 @@ class ServerTLSContext(ssl.DefaultOpenSSLContextFactory):\n     def __init__(self, privateKeyFileName, certificateFileName):\n         class TPDUSSLContext(SSL.Context):\n             def __init__(self, method):\n-                SSL.Context.__init__(method)\n+                SSL.Context.__init__(self, method)\n                 self.set_options(SSL.OP_DONT_INSERT_EMPTY_FRAGMENTS)\n                 self.set_options(SSL.OP_TLS_BLOCK_PADDING_BUG)\n \n", "before": "SSL . Context . __init__ ( method )", "after": "SSL . Context . __init__ ( self , method )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 37, 3, 45], [\"identifier:self\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 37, 3, 45], [\",:,\", \"T\"], 2]]"}
{"project": "collectd-bird", "commit_sha": "aa35b16ad42cc0c6f7d410ffe82931c7a3417a66", "parent_sha": "59795707fb15b6d3f1fcd126a08c36d813b6db2d", "file_path": "bird.py", "project_url": "https://github.com/exoscale/collectd-bird", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -187,7 +187,7 @@ class Bird(object):\n         sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n         sock.connect(self.socket)\n         if sys.version_info >= (3, 0):\n-            sock = sock.makefile(encoding='ascii')\n+            sock = sock.makefile(encoding='ascii', mode='rw')\n         else:\n             sock = sock.makefile()\n \n", "before": "sock = sock . makefile ( encoding = 'ascii' )", "after": "sock = sock . makefile ( encoding = 'ascii' , mode = 'rw' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 33, 3, 51], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 33, 3, 51], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:mode\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'rw'\", \"T\"], 2]]"}
{"project": "tensorflow-extenteten", "commit_sha": "5067c290e15f1fd7eff4ac1f6b66658f7538bb66", "parent_sha": "2309eca4acc05f8b79409a956034191b646cd634", "file_path": "nn/embeddings_to_embedding.py", "project_url": "https://github.com/raviqqe/tensorflow-extenteten", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -10,7 +10,7 @@ def embeddings_to_embedding(child_embeddings):\n   embedding_size = child_shape[2]\n   rnn_cell = tf.nn.rnn_cell.GRUCell(embedding_size, embedding_size)\n \n-  state = rnn_cell.zero_state(batch_size)\n+  state = rnn_cell.zero_state(batch_size, tf.float32)\n   for child_embedding in _split_child_embeddings(child_embeddings):\n     parent_embedding, state = rnn_cell(child_embedding, state)\n   return parent_embedding\n", "before": "state = rnn_cell . zero_state ( batch_size )", "after": "state = rnn_cell . zero_state ( batch_size , tf . float32 )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 42], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 30, 3, 42], [\"attribute\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:tf\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:float32\", \"T\"], 2]]"}
{"project": "eniric", "commit_sha": "0dbc3a2d3701c1c4b2fc36e039e829400b3f5fbe", "parent_sha": "6d58565bf5d5564f0dc28b4e4913d76ebb7d39e8", "file_path": "bin/nIR_run.py", "project_url": "https://github.com/jason-neal/eniric", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ def _parser():\n     parser.add_argument(\"-b\", \"--band\", type=str, default=\"ALL\",\n                         choices=[\"ALL\", \"VIS\", \"GAP\", \"Z\", \"Y\", \"J\", \"H\", \"K\"],\n                         help=\"Wavelength band to select\")\n-    parser.add_argument('-d', '--data_dir', help='Data directory', type=str)\n+    parser.add_argument('-d', '--data_dir', help='Data directory', type=str, default=None)\n     parser.add_argument('--sample_rate', default=3.0, type=float,\n                         help=\"Resample rate, pixels per FWHM. Default=3.0\")\n     parser.add_argument('--results', default=None, type=str,\n", "before": "parser . add_argument ( '-d' , '--data_dir' , help = 'Data directory' , type = str )", "after": "parser . add_argument ( '-d' , '--data_dir' , help = 'Data directory' , type = str , default = None )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 24, 3, 77], [\",:,\", \"T\"], 8], [\"Insert\", [\"argument_list\", 3, 24, 3, 77], [\"keyword_argument\", \"N0\"], 9], [\"Insert\", \"N0\", [\"identifier:default\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"none:None\", \"T\"], 2]]"}
{"project": "angr", "commit_sha": "2b506252050c0aaec309b9b942f28bb82ca08f5e", "parent_sha": "a87b525ba5748a8f892473c87a2f7b2723b211e2", "file_path": "angr/analyses/bindiff.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -627,7 +627,7 @@ class FunctionDiff(object):\n         # if there were no exits (a function with a while 1) let's consider the block with the highest address to\n         # be the exit. This isn't the most scientific way, but since this case is pretty rare it should be okay\n         if not found_exits:\n-            last = max(function.graph.nodes())\n+            last = max(function.graph.nodes(), key=lambda x:x.addr)\n             reverse_graph.add_edge(\"start\", last)\n \n         dists = networkx.single_source_shortest_path_length(reverse_graph, \"start\")\n", "before": "last = max ( function . graph . nodes ( ) )", "after": "last = max ( function . graph . nodes ( ) , key = lambda x : x . addr )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 23, 3, 47], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 23, 3, 47], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:key\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"lambda\", \"N1\"], 2], [\"Insert\", \"N1\", [\"lambda:lambda\", \"T\"], 0], [\"Insert\", \"N1\", [\"lambda_parameters\", \"N2\"], 1], [\"Insert\", \"N1\", [\":::\", \"T\"], 2], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 3], [\"Insert\", \"N2\", [\"identifier:x\", \"T\"], 0], [\"Insert\", \"N3\", [\"identifier:x\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:addr\", \"T\"], 2]]"}
{"project": "py-zabbix", "commit_sha": "bb16e7795e8c18b8a2f40324daf05272c4742c88", "parent_sha": "5a81729649b3ead04456ce2caec6cbd17957f2e6", "file_path": "pyzabbix/sender.py", "project_url": "https://github.com/kingleoric2010/py-zabbix", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -110,7 +110,7 @@ class ZabbixSender(object):\n     def __repr__(self):\n         \"\"\"Represent detailed ZabbixSender view.\"\"\"\n \n-        result = json.dumps(self.__dict__)\n+        result = json.dumps(self.__dict__, ensure_ascii=False)\n         logger.debug('%s: %s', self.__class__.__name__, result)\n \n         return result\n", "before": "result = json . dumps ( self . __dict__ )", "after": "result = json . dumps ( self . __dict__ , ensure_ascii = False )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 28, 3, 43], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 28, 3, 43], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:ensure_ascii\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"false:False\", \"T\"], 2]]"}
{"project": "dataengineeringutils", "commit_sha": "e7900f92f466718ecc05b9f004bebd086ae52281", "parent_sha": "5180157c119f350b7ce9bdb611e81b3452805ab9", "file_path": "dataengineeringutils/glue.py", "project_url": "https://github.com/moj-analytical-services/dataengineeringutils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -449,7 +449,7 @@ def glue_folder_in_s3_to_job_spec(s3_base_path, **kwargs) :\n     #Base path should be a folder.  Ensure ends in \"/\"\n     # Otherwise listing the bucket could cause problems in e.g. the case there are two jobs, job_1 and job_12\n \n-    (glue_job, resources, py_resources) = get_glue_job_and_resources_from_s3()\n+    (glue_job, resources, py_resources) = get_glue_job_and_resources_from_s3(s3_base_path)\n \n     kwargs[\"ScriptLocation\"] = job_path\n     if resources != '':\n", "before": "( glue_job , resources , py_resources ) = get_glue_job_and_resources_from_s3 ( )", "after": "( glue_job , resources , py_resources ) = get_glue_job_and_resources_from_s3 ( s3_base_path )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 77, 3, 79], [\"identifier:s3_base_path\", \"T\"], 1]]"}
{"project": "OWASP-Nettacker", "commit_sha": "6d2e9f69f809c270cee57de5f761f5d915524546", "parent_sha": "6934fa624f24214198da0634a9ecdf252bb27233", "file_path": "config.py", "project_url": "https://github.com/susantaroy2002/OWASP-Nettacker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -11,7 +11,7 @@ def get_config():\n         \"verbose_level\": 0,\n         \"show_version\": False,\n         \"check_update\": False,\n-        \"log_in_file\": \"results/results_{0}_{1}.html\".format(now(),\n+        \"log_in_file\": \"results/results_{0}_{1}.html\".format(now(model=\"%Y_%m_%d_%H_%M_%S\"),\n                                                          ''.join(random.choice(string.ascii_lowercase) for x in range(10))),\n         \"graph_flag\": \"d3_tree_v1_graph\",\n         \"help_menu_flag\": False,\n", "before": "\"log_in_file\" : \"results/results_{0}_{1}.html\" . format ( now ( ) , '' . join ( random . choice ( string . ascii_lowercase ) for x in range ( 10 ) ) ) ,", "after": "\"log_in_file\" : \"results/results_{0}_{1}.html\" . format ( now ( model = \"%Y_%m_%d_%H_%M_%S\" ) , '' . join ( random . choice ( string . ascii_lowercase ) for x in range ( 10 ) ) ) ,", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 65, 3, 67], [\"keyword_argument\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:model\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:\\\"%Y_%m_%d_%H_%M_%S\\\"\", \"T\"], 2]]"}
{"project": "angr", "commit_sha": "f8709d9b8cc8420ad1e238f7ed834cce2a56dd9b", "parent_sha": "6f335412035fe59e1889261abd3da56512174ab6", "file_path": "angr/cfg.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -314,7 +314,7 @@ class CFG(CFGBase):\n                 retn_target = current_exit_wrapper.call_stack().get_ret_target()\n                 if retn_target is not None:\n                     new_call_stack = current_exit_wrapper.call_stack_copy()\n-                    exit_target_tpl = new_call_stack.stack_suffix() + (retn_target,)\n+                    exit_target_tpl = new_call_stack.stack_suffix(self._context_sensitivity_level) + (retn_target,)\n                     exit_targets[call_stack_suffix + (addr,)].append(\n                         (exit_target_tpl, 'Ijk_Ret'))\n             else:\n", "before": "exit_target_tpl = new_call_stack . stack_suffix ( ) + ( retn_target , )", "after": "exit_target_tpl = new_call_stack . stack_suffix ( self . _context_sensitivity_level ) + ( retn_target , )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 66, 3, 68], [\"attribute\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:_context_sensitivity_level\", \"T\"], 2]]"}
{"project": "ottertune", "commit_sha": "8b2868a3b1ca1b6296954800869d6a6e8d189372", "parent_sha": "f2fd72f796900e0852fe42f2c3e3f82437117834", "file_path": "server/website/website/parser/myrocks.py", "project_url": "https://github.com/master-MR-han/ottertune", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -242,7 +242,7 @@ class MyRocksParser(BaseParser):\n                 value = knobs[name]\n                 conv_value = None\n                 if metadata.vartype == VarType.BOOL:\n-                    conv_value = self.convert_bool(value)\n+                    conv_value = self.convert_bool(value, metadata)\n                 elif metadata.vartype == VarType.ENUM:\n                     conv_value = self.convert_enum(value, metadata)\n                 elif metadata.vartype == VarType.INTEGER:\n", "before": "conv_value = self . convert_bool ( value )", "after": "conv_value = self . convert_bool ( value , metadata )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 51, 3, 58], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 51, 3, 58], [\"identifier:metadata\", \"T\"], 3]]"}
{"project": "autogamess", "commit_sha": "97d80fe6e402cd347df5bc63dae32342cb0881a0", "parent_sha": "b16d19b86168c2d02f42795533e6175d4af07481", "file_path": "autogamess/opt2hes.py", "project_url": "https://github.com/Cavenfish/autogamess", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -103,7 +103,7 @@ def opt2hes(optfile, logfile):\n         inp.insert(ctr_f('$SCF', inp), force)\n \n     #Replace coordinates in file\n-    i    = ctr_f('$DATA')\n+    i    = ctr_f('$DATA', inp)\n     data = inp[i:-1]\n     for key in atomdict:\n         temp   = [x.replace(' ', '') for x in data]\n", "before": "i = ctr_f ( '$DATA' )", "after": "i = ctr_f ( '$DATA' , inp )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 17, 3, 26], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 17, 3, 26], [\"identifier:inp\", \"T\"], 3]]"}
{"project": "OpenNMT-entmax", "commit_sha": "5f5a9267c70f13b2f8218f06d2ad2552b2c5a28c", "parent_sha": "bf11e5e9ea8dc237ab877fdc13ea2ea54827c4ea", "file_path": "onmt/decoders/transformer.py", "project_url": "https://github.com/deep-spin/OpenNMT-entmax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -270,7 +270,7 @@ class TransformerDecoderState(DecoderState):\n                     self.previous_layer_inputs,\n                     self.src)\n         else:\n-            return (self.src)\n+            return (self.src,)\n \n     def detach(self):\n         if self.previous_input is not None:\n", "before": "self . src ) else : return ( self . src )", "after": "self . src ) else : return ( self . src , )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 20, 3, 30], [\",:,\", \"T\"], 2]]"}
{"project": "OpenNMT-entmax", "commit_sha": "847f9aa9d1c5a352c43206cab223d59bdf2d1f3b", "parent_sha": "7fb5e9256e0e9ddab8ec7854fdf11fcdb5717a45", "file_path": "onmt/train_single.py", "project_url": "https://github.com/deep-spin/OpenNMT-entmax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -121,7 +121,7 @@ def main(opt):\n         lazily_load_dataset(\"train\", opt), fields, opt)\n \n     def valid_iter_fct(): return build_dataset_iter(\n-        lazily_load_dataset(\"valid\", opt), fields, opt)\n+        lazily_load_dataset(\"valid\", opt), fields, opt, is_train=False)\n \n     # Do training.\n     trainer.train(train_iter_fct, valid_iter_fct, opt.train_steps,\n", "before": "return build_dataset_iter ( lazily_load_dataset ( \"valid\" , opt ) , fields , opt )", "after": "return build_dataset_iter ( lazily_load_dataset ( \"valid\" , opt ) , fields , opt , is_train = False )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 52, 3, 56], [\",:,\", \"T\"], 6], [\"Insert\", [\"argument_list\", 2, 52, 3, 56], [\"keyword_argument\", \"N0\"], 7], [\"Insert\", \"N0\", [\"identifier:is_train\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"false:False\", \"T\"], 2]]"}
{"project": "semeval19_task3", "commit_sha": "44bd90ac15106cf66b363e2ef2d8995358a0caa0", "parent_sha": "b2e8d758f7ab767129a77a14eaedf81e601df749", "file_path": "san/test.py", "project_url": "https://github.com/baaesh/semeval19_task3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -11,7 +11,7 @@ def test(model, data, criterion, args):\n     preds = []\n     labels = []\n     for batch in iter(iterator):\n-        pred = model(batch.text)\n+        pred = model(batch.text, batch.raw)\n \n         batch_loss = criterion(pred, batch.label)\n         loss += batch_loss.item()\n", "before": "pred = model ( batch . text )", "after": "pred = model ( batch . text , batch . raw )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 21, 3, 33], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 21, 3, 33], [\"attribute\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:batch\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:raw\", \"T\"], 2]]"}
{"project": "TinyControl", "commit_sha": "ce03946d61d42f51c437d3020a8193b9701f4348", "parent_sha": "54e6097661dda6e1da412cfd9eef49eca9698911", "file_path": "tcontrol/plot_utility.py", "project_url": "https://github.com/DaivdZhang/TinyControl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ def _plot_response_curve(y, t, title, continuous=True):\n     if continuous:\n         _plt.plot(t, y)\n     else:\n-        _plt.step(t, y)\n+        _plt.step(t, y, where='post')\n     _plt.grid()\n     _plt.show()\n \n", "before": "_plt . step ( t , y )", "after": "_plt . step ( t , y , where = 'post' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 18, 3, 24], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 18, 3, 24], [\"keyword_argument\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:where\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'post'\", \"T\"], 2]]"}
{"project": "python_planet", "commit_sha": "2bed68c857e8e9ae01530fd4fd3745d633df9b59", "parent_sha": "9db54a189d920048fe92ba55978e1135c1ea50ca", "file_path": "planet/control/COrder.py", "project_url": "https://github.com/haobin12358/python_planet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ class COrder(CPay, CCoupon):\n             # \u72b6\u6001\n             order_main.OMstatus_en = OrderMainStatus(order_main.OMstatus).name\n             order_main.OMstatus_zh = OrderMainStatus(order_main.OMstatus).zh_value  # \u6c49\u5b57\n-            order_main.add('OMstatus_en', 'OMstatus_zh').hide('OPayno', 'USid', )\n+            order_main.add('OMstatus_en', 'OMstatus_zh', 'createtime').hide('OPayno', 'USid', )\n             order_main.fill('OMfrom_zh', OrderFrom(order_main.OMfrom).zh_value)\n             # \u7528\u6237\n             # todo \u5356\u5bb6\u8ba2\u5355\n", "before": "order_main . add ( 'OMstatus_en' , 'OMstatus_zh' ) . hide ( 'OPayno' , 'USid' , )", "after": "order_main . add ( 'OMstatus_en' , 'OMstatus_zh' , 'createtime' ) . hide ( 'OPayno' , 'USid' , )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 27, 3, 57], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 27, 3, 57], [\"string:'createtime'\", \"T\"], 5]]"}
{"project": "python_planet", "commit_sha": "f783469fe6732d7b809207ea6fb1bd70d04dc0bc", "parent_sha": "a48db7ab309008514cf4b0c2c801010f971a6826", "file_path": "planet/control/CPlay.py", "project_url": "https://github.com/haobin12358/python_planet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -683,7 +683,7 @@ class CPlay():\n         user = get_current_user()\n         # now = datetime.now()\n         # selfplay = Play.query.filter(Play.PLcreate == user.USid, Play.PLstatus == PlayStatus.activity.value).first()\n-        play = Play.query.join(EnterLog.PLid == Play.PLid).filter(\n+        play = Play.query.join(EnterLog, EnterLog.PLid == Play.PLid).filter(\n             Play.PLstatus == PlayStatus.activity.value,\n             or_(Play.PLcreate == user.USid, EnterLog.USid == user.USid)).first()\n         if not play:\n", "before": "play = Play . query . join ( EnterLog . PLid == Play . PLid ) . filter ( Play . PLstatus == PlayStatus . activity . value , or_ ( Play . PLcreate == user . USid , EnterLog . USid == user . USid ) ) . first ( )", "after": "play = Play . query . join ( EnterLog , EnterLog . PLid == Play . PLid ) . filter ( Play . PLstatus == PlayStatus . activity . value , or_ ( Play . PLcreate == user . USid , EnterLog . USid == user . USid ) ) . first ( )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 31, 3, 59], [\"identifier:EnterLog\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 31, 3, 59], [\",:,\", \"T\"], 2]]"}
{"project": "python_planet", "commit_sha": "f4f97646b852830cf7cbbdf90fb2f713a0f279c0", "parent_sha": "c12511f9c185d9c37c4ea779ccdd590d5bce672f", "file_path": "planet/control/CPlay.py", "project_url": "https://github.com/haobin12358/python_planet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -724,7 +724,7 @@ class CPlay():\n                         update_dict = self._get_update_dict(ins_instance, ins)\n                         if update_dict.get('INcost'):\n                             update_dict.update(INcost=incost)\n-                        ins_instance.update()\n+                        ins_instance.update(update_dict)\n                         instance_list.append(ins_instance)\n                         inid_list.append(inid)\n                         continue\n", "before": "ins_instance . update ( )", "after": "ins_instance . update ( update_dict )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 44, 3, 46], [\"identifier:update_dict\", \"T\"], 1]]"}
{"project": "python_planet", "commit_sha": "a3e67e763000bbaca95d9c1a43f9e73faf77c3db", "parent_sha": "9b62afcd4e1e9c0687827602a6e9221acd1ad104", "file_path": "planet/common/token_handler.py", "project_url": "https://github.com/haobin12358/python_planet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,7 +25,7 @@ def usid_to_token(id, model='User', level=0, expiration='', username='none'):\n \n def binded_phone():\n     \"\"\"\u662f\u5426\u5df2\u7ed1\u5b9a\u624b\u673a\u53f7\"\"\"\n-    return common_user() and getattr(get_current_user(), 'UStelphone')\n+    return common_user() and getattr(get_current_user(), 'UStelphone', False)\n \n \n def is_admin():\n", "before": "return common_user ( ) and getattr ( get_current_user ( ) , 'UStelphone' )", "after": "return common_user ( ) and getattr ( get_current_user ( ) , 'UStelphone' , False )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 37, 3, 71], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 37, 3, 71], [\"false:False\", \"T\"], 5]]"}
{"project": "python_planet", "commit_sha": "40514fa218be318efe0669734c4aea9ce5a0b305", "parent_sha": "9f8e6b87e26ff146c2edb153f64c4fc959f58f6a", "file_path": "planet/control/CMaterialFeedback.py", "project_url": "https://github.com/haobin12358/python_planet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ class CMaterialFeedback():\n         ticket = Ticket.query.filter(Ticket.TIid == tso.TIid, Ticket.isdelete == false()).first_('ttid \u5931\u6548')\n         # umf = UserMaterialFeedback.query.filter_by()\n         user = get_current_user()\n-        mfls = data.get('mfls')\n+        mfls = data.get('mfls', [])\n         umf_dict = self._create_umdetails(data)\n \n         with db.auto_commit():\n", "before": "mfls = data . get ( 'mfls' )", "after": "mfls = data . get ( 'mfls' , [ ] )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 24, 3, 32], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 24, 3, 32], [\"list\", \"N0\"], 3], [\"Insert\", \"N0\", [\"[:[\", \"T\"], 0], [\"Insert\", \"N0\", [\"]:]\", \"T\"], 1]]"}
{"project": "mailman3", "commit_sha": "9beb81b9754ee9b3dbe892b3aaea3ed73cbd2468", "parent_sha": "0274a755a4657bbec652fec29bd868a632eb6c07", "file_path": "src/mailman/archiving/mhonarc.py", "project_url": "https://github.com/stackexpress-shivam/mailman3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -81,7 +81,7 @@ class MHonArc:\n         command = expand(self.command, substitutions)\n         proc = subprocess.Popen(\n             command, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n-            shell=True)\n+            universal_newlines=True, shell=True)\n         stdout, stderr = proc.communicate(msg.as_string())\n         if proc.returncode != 0:\n             log.error('%s: mhonarc subprocess had non-zero exit code: %s' %\n", "before": "proc = subprocess . Popen ( command , stdout = subprocess . PIPE , stderr = subprocess . PIPE , shell = True )", "after": "proc = subprocess . Popen ( command , stdout = subprocess . PIPE , stderr = subprocess . PIPE , universal_newlines = True , shell = True )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 1, 32, 3, 24], [\"keyword_argument\", \"N0\"], 7], [\"Insert\", [\"argument_list\", 1, 32, 3, 24], [\",:,\", \"T\"], 8], [\"Insert\", \"N0\", [\"identifier:universal_newlines\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"true:True\", \"T\"], 2]]"}
{"project": "sympy", "commit_sha": "a53bb1512fa576ce9457ec496568ec8ca0ed601f", "parent_sha": "92544afb631f514d4d3c0af120da2fe0e5f5894c", "file_path": "sympy/core/numbers.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1943,7 +1943,7 @@ class Integer(Rational):\n     __slots__ = ['p']\n \n     def _as_mpf_val(self, prec):\n-        return mlib.from_int(self.p, prec)\n+        return mlib.from_int(self.p, prec, rnd)\n \n     def _mpmath_(self, prec, rnd):\n         return mpmath.make_mpf(self._as_mpf_val(prec))\n", "before": "return mlib . from_int ( self . p , prec )", "after": "return mlib . from_int ( self . p , prec , rnd )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 29, 3, 43], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 29, 3, 43], [\"identifier:rnd\", \"T\"], 5]]"}
{"project": "sympy", "commit_sha": "f5234d4ebdb2b5489d8ae01190a24a2cc4f162db", "parent_sha": "a0b970afc90df294733cb51dd5adc8636955aa13", "file_path": "sympy/polys/groebnertools.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -733,7 +733,7 @@ def is_groebner(G, ring):\n     for i in range(len(G)):\n         for j in range(i + 1, len(G)):\n-            s = spoly(G[i], G[j])\n+            s = spoly(G[i], G[j], ring)\n             s = s.rem(G)\n             if s:\n                 return False\n", "before": "s = spoly ( G [ i ] , G [ j ] )", "after": "s = spoly ( G [ i ] , G [ j ] , ring )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 22, 2, 34], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 2, 22, 2, 34], [\"identifier:ring\", \"T\"], 5]]"}
{"project": "sympy", "commit_sha": "c7f6aef67fdec9db637cc57888f2573eff602b14", "parent_sha": "31daaf14f09b2202e0950d4bab10e73259bc3110", "file_path": "sympy/solvers/diophantine.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -517,7 +517,7 @@ def _diop_quadratic(var, coeff, t):\n     elif B**2 - 4*A*C == 0:\n \n         if A == 0:\n-            s = set()\n+            s = set([])\n             s1 = _diop_quadratic([var[1], var[0]], coeff, t)\n             for x_0, y_0 in s1:\n                 s.add((y_0, x_0))\n", "before": "s = set ( )", "after": "s = set ( [ ] )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 20, 3, 22], [\"list\", \"N0\"], 1], [\"Insert\", \"N0\", [\"[:[\", \"T\"], 0], [\"Insert\", \"N0\", [\"]:]\", \"T\"], 1]]"}
{"project": "sympy", "commit_sha": "520b81b2359d9240baa9a32816e67697a6a666c7", "parent_sha": "a738a9c626d80fed4d1bdf4f5aba9da4014cb961", "file_path": "sympy/holonomic/holonomic.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1561,7 +1561,7 @@ def change_ics(self, b, lenics=None):\n \n         from .holonomicerrors import NotPowerSeriesError, NotHyperSeriesError\n         try:\n-            sol = expr_to_holonomic(self.to_expr(), x0=b, lenics=lenics, domain=self.annihilator.parent.base.domain)\n+            sol = expr_to_holonomic(self.to_expr(), x=self.x, x0=b, lenics=lenics, domain=self.annihilator.parent.base.domain)\n         except (NotPowerSeriesError, NotHyperSeriesError):\n             symbolic = False\n \n", "before": "sol = expr_to_holonomic ( self . to_expr ( ) , x0 = b , lenics = lenics , domain = self . annihilator . parent . base . domain )", "after": "sol = expr_to_holonomic ( self . to_expr ( ) , x = self . x , x0 = b , lenics = lenics , domain = self . annihilator . parent . base . domain )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 36, 3, 117], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", [\"argument_list\", 3, 36, 3, 117], [\",:,\", \"T\"], 4], [\"Insert\", \"N0\", [\"identifier:x\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N1\"], 2], [\"Insert\", \"N1\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N1\", [\".:.\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:x\", \"T\"], 2]]"}
{"project": "sympy", "commit_sha": "98cb25315e8926a10a1cab2dbbe39b1a4bc8aa3e", "parent_sha": "24c62c84a000d1e220eea0633efc188c60859f55", "file_path": "sympy/core/operations.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -123,7 +123,7 @@ def flatten(cls, seq):\n         # apply associativity, no commutativity property is used\n         new_seq = []\n         while seq:\n-            o = seq.pop()\n+            o = seq.pop(0)\n             if o.__class__ is cls:  # classes must match exactly\n                 seq.extend(o.args)\n             else:\n", "before": "o = seq . pop ( )", "after": "o = seq . pop ( 0 )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 24, 3, 26], [\"integer:0\", \"T\"], 1]]"}
{"project": "sympy", "commit_sha": "00812c9ac1cbe4e0779d3ca2fa5fca5d69ad3792", "parent_sha": "48e477647096e70fb60227362c848905c01f336f", "file_path": "sympy/geometry/tests/test_ellipse.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -341,7 +341,7 @@ def test_construction():\n     #if vradius is not defined\n     assert Ellipse(None, 1, None, 1).length == 2\n     #if hradius is not defined\n-    raises(GeometryError, lambda: Ellipse(None, 1, eccentricity = 1))\n+    raises(GeometryError, lambda: Ellipse(None, None, 1, eccentricity = 1))\n \n     #tests for eccentricity < 0\n     raises(GeometryError, lambda: Ellipse(Point(3, 1), hradius=3, eccentricity = -3))\n", "before": "raises ( GeometryError , lambda : Ellipse ( None , 1 , eccentricity = 1 ) )", "after": "raises ( GeometryError , lambda : Ellipse ( None , None , 1 , eccentricity = 1 ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 42, 3, 69], [\"none:None\", \"T\"], 3], [\"Insert\", [\"argument_list\", 3, 42, 3, 69], [\",:,\", \"T\"], 4]]"}
{"project": "RxPY", "commit_sha": "1d6437308d77ffa9eda6deb17164991585e31bf7", "parent_sha": "2ec7f3e9fd212f1b38907ea25fc88b563da9227c", "file_path": "examples/timeflies/timeflies_qt.py", "project_url": "https://github.com/mako-taco/RxPY", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -19,7 +19,7 @@ except ImportError:\n class Window(QWidget):\n \n     def __init__(self):\n-        super().__init__()\n+        super(QWidget, self).__init__()\n         self.setWindowTitle(\"Rx for Python rocks\")\n         self.resize(600, 600)\n         self.setMouseTracking(True)\n", "before": "super ( ) . __init__ ( )", "after": "super ( QWidget , self ) . __init__ ( )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 14, 3, 16], [\"identifier:QWidget\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 14, 3, 16], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 14, 3, 16], [\"identifier:self\", \"T\"], 3]]"}
{"project": "sympy", "commit_sha": "121ea0c3ce2ceb6d06fd329eba69efe305f5399c", "parent_sha": "a85da27d8ffc62a7c99959d41c701bb78a0802f4", "file_path": "sympy/integrals/meijerint.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1346,7 +1346,7 @@ def statement(a, b, c, z):\n         return And(*[statement(a - 1, 0, 0, z) for a in g.an])\n \n     def E(z):\n-        return And(*[statement(a - 1, 0, z) for a in g.an])\n+        return And(*[statement(a - 1, 0, 0, z) for a in g.an])\n \n     def H(z):\n         return statement(theta, -sigma, 1/sigma, z)\n", "before": "return And ( * [ statement ( a - 1 , 0 , z ) for a in g . an ] )", "after": "return And ( * [ statement ( a - 1 , 0 , 0 , z ) for a in g . an ] )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 31, 3, 44], [\"integer:0\", \"T\"], 5], [\"Insert\", [\"argument_list\", 3, 31, 3, 44], [\",:,\", \"T\"], 6]]"}
{"project": "sympy", "commit_sha": "c202a5e3b55011f0eb738d2577cc2b1f92f22ccd", "parent_sha": "730b4fa5de4748162c5b873f731bc7927138c2b9", "file_path": "sympy/logic/boolalg.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1321,7 +1321,7 @@ def eliminate_implications(expr):\n-    return to_nnf(expr)\n+    return to_nnf(expr, simplify=False)\n \n \n def is_literal(expr):\n", "before": "return to_nnf ( expr )", "after": "return to_nnf ( expr , simplify = False )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 0, 18, 0, 24], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 0, 18, 0, 24], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:simplify\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"false:False\", \"T\"], 2]]"}
{"project": "gcsfs", "commit_sha": "697dd25fbbe544a3b16baa518d12f2dfbffd96b1", "parent_sha": "8253a266bc47f429aab2e5c8dff54f52895b1297", "file_path": "gcsfs/core.py", "project_url": "https://github.com/martindurant/gcsfs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -308,7 +308,7 @@ class GCSFileSystem(object):\n         GCSFileSystem.tokens = tokens\n \n     def _connect_google_default(self):\n-        credentials, project = gauth.default()\n+        credentials, project = gauth.default(scopes=[self.scope])\n         self.project = project\n         self.session = AuthorizedSession(credentials)\n \n", "before": "credentials , project = gauth . default ( )", "after": "credentials , project = gauth . default ( scopes = [ self . scope ] )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 45, 3, 47], [\"keyword_argument\", \"N0\"], 1], [\"Insert\", \"N0\", [\"identifier:scopes\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"list\", \"N1\"], 2], [\"Insert\", \"N1\", [\"[:[\", \"T\"], 0], [\"Insert\", \"N1\", [\"attribute\", \"N2\"], 1], [\"Insert\", \"N1\", [\"]:]\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:self\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:scope\", \"T\"], 2]]"}
{"project": "RxPY", "commit_sha": "465727bfadde2c902c8d47db33136f73781929b3", "parent_sha": "ece80c4e20c3743bcb6960442706cba2af7e7197", "file_path": "rx/linq/observable/merge.py", "project_url": "https://github.com/mako-taco/RxPY", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ class ObservableMerge(Observable):\n \n         if not isinstance(max_concurrent_or_other, int):\n-            return Observable.merge(max_concurrent_or_other)\n+            return Observable.merge(self, max_concurrent_or_other)\n \n         sources = self\n \n", "before": "return Observable . merge ( max_concurrent_or_other )", "after": "return Observable . merge ( self , max_concurrent_or_other )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 36, 2, 61], [\"identifier:self\", \"T\"], 1], [\"Insert\", [\"argument_list\", 2, 36, 2, 61], [\",:,\", \"T\"], 2]]"}
{"project": "performance", "commit_sha": "e8e8501aee3cef72fed31424d7f1ad32519f470f", "parent_sha": "073736a591c2db06b313edc46e76039135b7536c", "file_path": "performance/compare.py", "project_url": "https://github.com/willingc/performance", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -303,7 +303,7 @@ def format_csv(value):\n \n \n def write_csv(results, filename):\n-    with open(filename, \"w\") as f:\n+    with open(filename, \"w\", newline='') as f:\n         writer = csv.writer(f)\n         writer.writerow(['Benchmark', 'Base', 'Changed'])\n         for result in results:\n", "before": "with open ( filename , \"w\" ) as f : writer = csv . writer ( f ) writer . writerow ( [ 'Benchmark' , 'Base' , 'Changed' ] ) for result in results : ", "after": "with open ( filename , \"w\" , newline = '' ) as f : writer = csv . writer ( f ) writer . writerow ( [ 'Benchmark' , 'Base' , 'Changed' ] ) for result in results : ", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 14, 3, 29], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 14, 3, 29], [\"keyword_argument\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:newline\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:''\", \"T\"], 2]]"}
{"project": "ykdl", "commit_sha": "226c7adaaf2d988c3a0152795c6a9eb54256aa9d", "parent_sha": "96e3aea4ce8a481ac7b406c20ddd6a9a273b5457", "file_path": "src/you_get/downloader/xiami.py", "project_url": "https://github.com/YU-zreo/ykdl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ def location_dec(str):\n def xiami_download_lyric(lrc_url, file_name, output_dir):\n     lrc = get_html(lrc_url, faker = True)\n     if len(lrc) > 0:\n-        with open(output_dir + \"/\" + file_name.replace('/', '-') + '.lrc', 'w') as x:\n+        with open(output_dir + \"/\" + file_name.replace('/', '-') + '.lrc', 'w', encoding='utf-8') as x:\n             x.write(lrc)\n \n def xiami_download_song(sid, output_dir = '.', merge = True, info_only = False):\n", "before": "with open ( output_dir + \"/\" + file_name . replace ( '/' , '-' ) + '.lrc' , 'w' ) as x : x . write ( lrc )", "after": "with open ( output_dir + \"/\" + file_name . replace ( '/' , '-' ) + '.lrc' , 'w' , encoding = 'utf-8' ) as x : x . write ( lrc )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 18, 3, 80], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 18, 3, 80], [\"keyword_argument\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:encoding\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'utf-8'\", \"T\"], 2]]"}
{"project": "ykdl", "commit_sha": "89caa854f4d976ba5af6875ab0bc1f74db6555e8", "parent_sha": "e3e416c52640476b6e7d1646781fd48dffcaddee", "file_path": "src/you_get/downloader/khan.py", "project_url": "https://github.com/YU-zreo/ykdl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -8,7 +8,7 @@ from .youtube import youtube_download_by_id\n def khan_download(url, output_dir = '.', merge = True, info_only = False):\n     page = get_html(url)\n     id = page[page.find('src=\"https://www.youtube.com/embed/') + len('src=\"https://www.youtube.com/embed/') :page.find('?enablejsapi=1&wmode=transparent&modestbranding=1&rel=0&fs=1&showinfo=0')]\n-    youtube_download_by_id(id)\n+    youtube_download_by_id(id, output_dir=output_dir, merge=merge, info_only=info_only)\n \n site_info = \"khanacademy.org\"\n download = khan_download\n", "before": "youtube_download_by_id ( id )", "after": "youtube_download_by_id ( id , output_dir = output_dir , merge = merge , info_only = info_only )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 27, 3, 31], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 27, 3, 31], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", [\"argument_list\", 3, 27, 3, 31], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 27, 3, 31], [\"keyword_argument\", \"N1\"], 5], [\"Insert\", [\"argument_list\", 3, 27, 3, 31], [\",:,\", \"T\"], 6], [\"Insert\", [\"argument_list\", 3, 27, 3, 31], [\"keyword_argument\", \"N2\"], 7], [\"Insert\", \"N0\", [\"identifier:output_dir\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:output_dir\", \"T\"], 2], [\"Insert\", \"N1\", [\"identifier:merge\", \"T\"], 0], [\"Insert\", \"N1\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N1\", [\"identifier:merge\", \"T\"], 2], [\"Insert\", \"N2\", [\"identifier:info_only\", \"T\"], 0], [\"Insert\", \"N2\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:info_only\", \"T\"], 2]]"}
{"project": "ykdl", "commit_sha": "afdf7d258716ea3ad5d7298871456a1c3b9c5289", "parent_sha": "627209b14934b374c7db8db6b40e1f0edec84a39", "file_path": "src/you_get/common.py", "project_url": "https://github.com/YU-zreo/ykdl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -192,7 +192,7 @@ def get_decoded_html(url, faker = False):\n     data = response.data\n     charset = r1(r'charset=([\\w-]+)', response.headers['content-type'])\n     if charset:\n-        return data.decode(charset)\n+        return data.decode(charset, 'ignore')\n     else:\n         return data\n \n", "before": "return data . decode ( charset )", "after": "return data . decode ( charset , 'ignore' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 27, 3, 36], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 27, 3, 36], [\"string:'ignore'\", \"T\"], 3]]"}
{"project": "folium", "commit_sha": "daf7a4422f7a7c0c3eeb257c009bd7c02d10a785", "parent_sha": "a235897d3614a0649d72865497cb19b7bf253615", "file_path": "folium/map.py", "project_url": "https://github.com/rdd9999/folium", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -331,7 +331,7 @@ class FeatureGroup(Layer):\n     def __init__(self, name=None, overlay=True, control=True):\n-        super(FeatureGroup, self).__init__(overlay=overlay, control=control)\n+        super(FeatureGroup, self).__init__(overlay=overlay, control=control, name=name)\n         self._name = 'FeatureGroup'\n \n         self.tile_name = name if name is not None else self.get_name()\n", "before": "super ( FeatureGroup , self ) . __init__ ( overlay = overlay , control = control )", "after": "super ( FeatureGroup , self ) . __init__ ( overlay = overlay , control = control , name = name )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 1, 43, 1, 77], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 1, 43, 1, 77], [\"keyword_argument\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:name\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:name\", \"T\"], 2]]"}
{"project": "flutterfuck", "commit_sha": "25dbd0c04ff145575282d308609e90d87d9bf06c", "parent_sha": "f383ef2065e1c00201a8665a317462e8831d3079", "file_path": "willie/modules/clock.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -97,7 +97,7 @@ def update_user_format(bot, trigger):\n         tz = get_timezone(bot.db, bot.config, None, None,\n                                        trigger.sender)\n         try:\n-            timef = format_time(zone=tz)\n+            timef = format_time(db = bot.db, zone=tz, nick=trigger.nick)\n         except:\n             bot.reply(\"That format doesn't work. Try using\"\n                          \" http://strftime.net to make one.\")\n", "before": "timef = format_time ( zone = tz )", "after": "timef = format_time ( db = bot . db , zone = tz , nick = trigger . nick )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 32, 3, 41], [\"keyword_argument\", \"N0\"], 1], [\"Insert\", [\"argument_list\", 3, 32, 3, 41], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 32, 3, 41], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 32, 3, 41], [\"keyword_argument\", \"N1\"], 5], [\"Insert\", \"N0\", [\"identifier:db\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"attribute\", \"N2\"], 2], [\"Insert\", \"N1\", [\"identifier:nick\", \"T\"], 0], [\"Insert\", \"N1\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N1\", [\"attribute\", \"N3\"], 2], [\"Insert\", \"N2\", [\"identifier:bot\", \"T\"], 0], [\"Insert\", \"N2\", [\".:.\", \"T\"], 1], [\"Insert\", \"N2\", [\"identifier:db\", \"T\"], 2], [\"Insert\", \"N3\", [\"identifier:trigger\", \"T\"], 0], [\"Insert\", \"N3\", [\".:.\", \"T\"], 1], [\"Insert\", \"N3\", [\"identifier:nick\", \"T\"], 2]]"}
{"project": "flutterfuck", "commit_sha": "af26b8809a4cdcb3f130c016913f47b27b7a52ca", "parent_sha": "efd0aac1e4c3096fd6be2a87bb7c1e281bc49173", "file_path": "willie/modules/bugzilla.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -55,7 +55,7 @@ def show_bug(bot, trigger, match=None):\n     if domain not in bot.config.bugzilla.get_list('domains'):\n         return\n     url = 'https://%s%sctype=xml&%s' % match.groups()\n-    data = web.get(url)\n+    data = web.get(url, dont_decode=True)\n     bug = etree.fromstring(data).find('bug')\n \n     message = ('[BUGZILLA] %s | Product: %s | Component: %s | Version: %s | ' +\n", "before": "data = web . get ( url )", "after": "data = web . get ( url , dont_decode = True )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 19, 3, 24], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 19, 3, 24], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:dont_decode\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"true:True\", \"T\"], 2]]"}
{"project": "flutterfuck", "commit_sha": "d0fca6de974085465c2d2825203576b668522ec6", "parent_sha": "4d9804a96e448265925e24befa8f5874a0052047", "file_path": "willie/modules/chanlogs.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -72,7 +72,7 @@ def get_fpath(bot, trigger, channel=None):\n     basedir = os.path.expanduser(bot.config.chanlogs.dir)\n     channel = channel or trigger.sender\n     channel = channel.lstrip(\"#\")\n-    channel = BAD_CHARS.sub('__')\n+    channel = BAD_CHARS.sub('__', channel)\n \n     dt = get_datetime(bot)\n     if bot.config.chanlogs.by_day:\n", "before": "channel = BAD_CHARS . sub ( '__' )", "after": "channel = BAD_CHARS . sub ( '__' , channel )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 28, 3, 34], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 28, 3, 34], [\"identifier:channel\", \"T\"], 3]]"}
{"project": "ykdl", "commit_sha": "ecb7e84e6b47d0ad9205658bcc8c55fe049747aa", "parent_sha": "3f21a0672d1e90da49a96cf9cc73056521038d9e", "file_path": "src/you_get/extractor/bilibili.py", "project_url": "https://github.com/YU-zreo/ykdl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -101,7 +101,7 @@ def bilibili_download(url, output_dir = '.', merge = True, info_only = False):\n     if not info_only:\n         print('Downloading %s ...' % (title + '.cmt.xml'))\n         xml = get_srt_xml(id)\n-        with open(os.path.join(output_dir, title + '.cmt.xml'), 'w') as x:\n+        with open(os.path.join(output_dir, title + '.cmt.xml'), 'w', encoding='utf-8') as x:\n             x.write(xml)\n \n site_info = \"bilibili.tv\"\n", "before": "with open ( os . path . join ( output_dir , title + '.cmt.xml' ) , 'w' ) as x : x . write ( xml )", "after": "with open ( os . path . join ( output_dir , title + '.cmt.xml' ) , 'w' , encoding = 'utf-8' ) as x : x . write ( xml )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 18, 3, 69], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 18, 3, 69], [\"keyword_argument\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:encoding\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:'utf-8'\", \"T\"], 2]]"}
{"project": "ykdl", "commit_sha": "02cdfef400873ec8e63b5653f2feb4006c18b3a1", "parent_sha": "4cce8c8da3fa3e59d57dc8b488ffa5f8e34cb174", "file_path": "you_get/extractors/douyutv.py", "project_url": "https://github.com/YU-zreo/ykdl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ class Douyutv(VideoExtractor):\n         html = get_content(self.url)\n         vids = matchall(html, douyu_match_pattern)\n         for vid in vids:\n-            self.download_by_vid(vid, **kwargs)\n+            self.download_by_vid(vid, param, **kwargs)\n \n site = Douyutv()\n download = site.download_by_url\n", "before": "self . download_by_vid ( vid , ** kwargs )", "after": "self . download_by_vid ( vid , param , ** kwargs )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 33, 3, 48], [\"identifier:param\", \"T\"], 3], [\"Insert\", [\"argument_list\", 3, 33, 3, 48], [\",:,\", \"T\"], 4]]"}
{"project": "flutterfuck", "commit_sha": "39eee8b56660ab3794a3c47a0f82dee707bb9708", "parent_sha": "1cad7977cfb4eca694d654959f0625305584b335", "file_path": "sopel/config/types.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -206,7 +206,7 @@ class ValidatedAttribute(BaseValidated):\n         if self.parse == _parse_boolean:\n             prompt += ' (y/n)'\n             default = 'y' if default else 'n'\n-        return super(ValidatedAttribute, self).configure(prompt, default)\n+        return super(ValidatedAttribute, self).configure(prompt, default, parent, section_name)\n \n \n class ListAttribute(BaseValidated):\n", "before": "return super ( ValidatedAttribute , self ) . configure ( prompt , default )", "after": "return super ( ValidatedAttribute , self ) . configure ( prompt , default , parent , section_name )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 57, 3, 74], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 57, 3, 74], [\"identifier:parent\", \"T\"], 5], [\"Insert\", [\"argument_list\", 3, 57, 3, 74], [\",:,\", \"T\"], 6], [\"Insert\", [\"argument_list\", 3, 57, 3, 74], [\"identifier:section_name\", \"T\"], 7]]"}
{"project": "flutterfuck", "commit_sha": "2ab08a84cf4610dbdf06259d8090b5c78077dabe", "parent_sha": "c98aa42af3356863c84926c4826da3059f726ee3", "file_path": "sopel/modules/dice.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -184,7 +184,7 @@ def roll(bot, trigger):\n     if not trigger.group(2):\n         return bot.reply(\"No dice to roll.\")\n     arg_str = trigger.group(2)\n-    dice_expressions = re.findall(dice_regexp, arg_str)\n+    dice_expressions = re.findall(dice_regexp, arg_str, re.IGNORECASE)\n     arg_str = arg_str.replace(\"%\", \"%%\")\n     arg_str = re.sub(dice_regexp, \"%s\", arg_str)\n \n", "before": "dice_expressions = re . findall ( dice_regexp , arg_str )", "after": "dice_expressions = re . findall ( dice_regexp , arg_str , re . IGNORECASE )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 34, 3, 56], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 34, 3, 56], [\"attribute\", \"N0\"], 5], [\"Insert\", \"N0\", [\"identifier:re\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:IGNORECASE\", \"T\"], 2]]"}
{"project": "flutterfuck", "commit_sha": "66e1b1b2f7c3e9ff90ff9bf1059ef2d0197102cf", "parent_sha": "bb56dbf59f93d97e550007782c2cd741ec8e73ee", "file_path": "willie/modules/movie.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -23,7 +23,7 @@ def movie(bot, trigger):\n     word = word.replace(\" \", \"+\")\n     uri = \"http://www.imdbapi.com/?t=\" + word\n     u = web.get(uri, 30)\n-    data = json.loads(u.decode())  # data is a Dict containing all the information we need\n+    data = json.loads(u.decode('utf-8'))  # data is a Dict containing all the information we need\n     if data['Response'] == 'False':\n         if 'Error' in data:\n             message = '[MOVIE] %s' % data['Error']\n", "before": "data = json . loads ( u . decode ( ) )", "after": "data = json . loads ( u . decode ( 'utf-8' ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 31, 3, 33], [\"string:'utf-8'\", \"T\"], 1]]"}
{"project": "cfapi", "commit_sha": "9169defa7e26f10438e455bc42c38efcbc89b642", "parent_sha": "a1dc4ab1083edaad5d109b65a31daaa87b196dbe", "file_path": "run_update_test.py", "project_url": "https://github.com/opensavannah/cfapi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -214,7 +214,7 @@ class RunUpdateTestCase(unittest.TestCase):\n         old_organization = OrganizationFactory(name='Old Organization')\n         old_project = ProjectFactory(name='Old Project', organization_name='Old Organization')\n         old_event = EventFactory(name='Old Event', organization_name='Old Organization')\n-        old_issue = IssueFactory(title='Old Issue')\n+        old_issue = IssueFactory(title='Old Issue', project_id=1)\n         self.db.session.flush()\n \n         self.mock_rss_response()\n", "before": "old_issue = IssueFactory ( title = 'Old Issue' )", "after": "old_issue = IssueFactory ( title = 'Old Issue' , project_id = 1 )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 33, 3, 52], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 33, 3, 52], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:project_id\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"integer:1\", \"T\"], 2]]"}
{"project": "cfapi", "commit_sha": "ffcd4373bafaf2396ca64bd43d828e8f981d6a35", "parent_sha": "00313b18121717f0bd8fd83c034430977f86591c", "file_path": "run_update_test.py", "project_url": "https://github.com/opensavannah/cfapi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -553,7 +553,7 @@ class RunUpdateTestCase(unittest.TestCase):\n         from factories import OrganizationFactory, ProjectFactory\n \n         philly = OrganizationFactory(name=u'Code for Philly', projects_list_url=u'http://codeforphilly.org/projects.csv')\n-        old_project = ProjectFactory(name=u'Philly Map of Shame', organization_name=u'Code for Philly', description=u'PHL Map of Shame is a citizen-led project to map the impact of the School Reform Commission\\u2019s \\u201cdoomsday budget\\u201d on students and parents. We will visualize complaints filed with the Pennsylvania Department of Education.', categories=u'Education, CivicEngagement', type=u'', link_url=u'http://phillymapofshame.org', status=u'In Progress')\n+        old_project = ProjectFactory(name=u'Philly Map of Shame', organization_name=u'Code for Philly', description=u'PHL Map of Shame is a citizen-led project to map the impact of the School Reform Commission\\u2019s \\u201cdoomsday budget\\u201d on students and parents. We will visualize complaints filed with the Pennsylvania Department of Education.', categories=u'Education, CivicEngagement', type=u'', link_url=u'http://phillymapofshame.org', code_url=u'', status=u'In Progress')\n         self.db.session.flush()\n \n         def overwrite_response_content(url, request):\n", "before": "old_project = ProjectFactory ( name = u'Philly Map of Shame' , organization_name = u'Code for Philly' , description = u'PHL Map of Shame is a citizen-led project to map the impact of the School Reform Commission\\u2019s \\u201cdoomsday budget\\u201d on students and parents. We will visualize complaints filed with the Pennsylvania Department of Education.' , categories = u'Education, CivicEngagement' , type = u'' , link_url = u'http://phillymapofshame.org' , status = u'In Progress' )", "after": "old_project = ProjectFactory ( name = u'Philly Map of Shame' , organization_name = u'Code for Philly' , description = u'PHL Map of Shame is a citizen-led project to map the impact of the School Reform Commission\\u2019s \\u201cdoomsday budget\\u201d on students and parents. We will visualize complaints filed with the Pennsylvania Department of Education.' , categories = u'Education, CivicEngagement' , type = u'' , link_url = u'http://phillymapofshame.org' , code_url = u'' , status = u'In Progress' )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 37, 3, 470], [\"keyword_argument\", \"N0\"], 13], [\"Insert\", [\"argument_list\", 3, 37, 3, 470], [\",:,\", \"T\"], 14], [\"Insert\", \"N0\", [\"identifier:code_url\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"string:u''\", \"T\"], 2]]"}
{"project": "ykdl", "commit_sha": "f7d3af7c2dc812c9fbb845e99949feff2e35fe30", "parent_sha": "fc99fcb182405382266a5cd78f017df8fdbddc3d", "file_path": "ykdl/util/download.py", "project_url": "https://github.com/YU-zreo/ykdl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -66,7 +66,7 @@ def save_url(url, name, ext, part = None, reporthook = simple_hook):\n \n def save_urls(urls, name, ext, jobs=1):\n     if len(urls) == 1:\n-        save_url(urls[0], name)\n+        save_url(urls[0], name, ext)\n     if not MultiThread:\n         for no, u in enumerate(urls):\n             save_url(u, name, ext, part = no)\n", "before": "save_url ( urls [ 0 ] , name )", "after": "save_url ( urls [ 0 ] , name , ext )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 17, 3, 32], [\",:,\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 17, 3, 32], [\"identifier:ext\", \"T\"], 5]]"}
{"project": "tardis", "commit_sha": "938eb505bccd2bd043bdea0f800f7a5b4acd334e", "parent_sha": "4cc574c60fc64b07c43db858d0e283e3e0dd9f25", "file_path": "tardis/simulation.py", "project_url": "https://github.com/vg3095/tardis", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ def run_radial1d(radial1d_model, history_fname=None):\n         history_buffer = HDFStore(history_fname)\n \n     start_time = time.time()\n-    radial1d_model.simulate(update_radiation_field=False, enable_virtual=True, initialize_j_blues=True)\n+    radial1d_model.simulate(update_radiation_field=False, enable_virtual=True, initialize_j_blues=True, initialize_nlte=True)\n     if history_fname:\n         radial1d_model.to_hdf5(history_buffer, path='model%03d' % radial1d_model.iterations_executed, close_h5=False)\n \n", "before": "radial1d_model . simulate ( update_radiation_field = False , enable_virtual = True , initialize_j_blues = True )", "after": "radial1d_model . simulate ( update_radiation_field = False , enable_virtual = True , initialize_j_blues = True , initialize_nlte = True )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 28, 3, 104], [\",:,\", \"T\"], 6], [\"Insert\", [\"argument_list\", 3, 28, 3, 104], [\"keyword_argument\", \"N0\"], 7], [\"Insert\", \"N0\", [\"identifier:initialize_nlte\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"true:True\", \"T\"], 2]]"}
{"project": "pokeminer", "commit_sha": "3a775e59aedb6e1fb6c77818a386ec020d4b1c33", "parent_sha": "76a20bc18aaae3d1c577756fc48f81ede81dc89d", "file_path": "db.py", "project_url": "https://github.com/pogosandbox/pokeminer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ class Team(enum.Enum):\n \n \n def get_engine():\n-    return create_engine(DB_ENGINE)\n+    return create_engine(DB_ENGINE,pool_size=config.GRID[0]*config.GRID[1]+5)\n \n \n def get_engine_name(session):\n", "before": "return create_engine ( DB_ENGINE )", "after": "return create_engine ( DB_ENGINE , pool_size = config . GRID [ 0 ] * config . GRID [ 1 ] + 5 )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 25, 3, 36], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 25, 3, 36], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:pool_size\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"binary_operator\", \"N1\"], 2], [\"Insert\", \"N1\", [\"binary_operator\", \"N2\"], 0], [\"Insert\", \"N1\", [\"+:+\", \"T\"], 1], [\"Insert\", \"N1\", [\"integer:5\", \"T\"], 2], [\"Insert\", \"N2\", [\"subscript\", \"N3\"], 0], [\"Insert\", \"N2\", [\"*:*\", \"T\"], 1], [\"Insert\", \"N2\", [\"subscript\", \"N4\"], 2], [\"Insert\", \"N3\", [\"attribute\", \"N5\"], 0], [\"Insert\", \"N3\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N3\", [\"integer:0\", \"T\"], 2], [\"Insert\", \"N3\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N4\", [\"attribute\", \"N6\"], 0], [\"Insert\", \"N4\", [\"[:[\", \"T\"], 1], [\"Insert\", \"N4\", [\"integer:1\", \"T\"], 2], [\"Insert\", \"N4\", [\"]:]\", \"T\"], 3], [\"Insert\", \"N5\", [\"identifier:config\", \"T\"], 0], [\"Insert\", \"N5\", [\".:.\", \"T\"], 1], [\"Insert\", \"N5\", [\"identifier:GRID\", \"T\"], 2], [\"Insert\", \"N6\", [\"identifier:config\", \"T\"], 0], [\"Insert\", \"N6\", [\".:.\", \"T\"], 1], [\"Insert\", \"N6\", [\"identifier:GRID\", \"T\"], 2]]"}
{"project": "python-freshdesk", "commit_sha": "7d102a5c175d872657c0cc01f4a52fac950ef4c6", "parent_sha": "88ac09aec383be9c27c719bd93ac547059607d21", "file_path": "freshdesk/v2/api.py", "project_url": "https://github.com/alkivi-sas/python-freshdesk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -45,7 +45,7 @@ class TicketAPI(object):\n \n         for attachment in attachments:\n             file_name = attachment.split(\"/\")[-1:][0]\n-            multipart_data.append(('attachments[]', (file_name, open(attachment), None)))\n+            multipart_data.append(('attachments[]', (file_name, open(attachment, 'rb'), None)))\n \n         ticket = self._api._post(url, data=data, files=multipart_data)\n         return ticket\n", "before": "multipart_data . append ( ( 'attachments[]' , ( file_name , open ( attachment ) , None ) ) )", "after": "multipart_data . append ( ( 'attachments[]' , ( file_name , open ( attachment , 'rb' ) , None ) ) )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 69, 3, 81], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 69, 3, 81], [\"string:'rb'\", \"T\"], 3]]"}
{"project": "cclib", "commit_sha": "4d42a288bfefbbebc14b057492070e52405ee361", "parent_sha": "624d6438057d401dab835882dca5861df3c4a776", "file_path": "src/cclib/parser/adfparser.py", "project_url": "https://github.com/chemistry-scripts/cclib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -485,7 +485,7 @@ class ADF(logfileparser.Logfile):\n                 self.mosyms[0].append('A')\r\n                 self.moenergies[0].append(utils.convertor(float(info[2]), 'hartree', 'eV'))\r\n                 if info[1] == '0.000' and not hasattr(self, 'homos'):\r\n-                    self.set_attribute([len(self.moenergies[0]) - 2])\r\n+                    self.set_attribute('homos', [len(self.moenergies[0]) - 2])\r\n                 line = next(inputfile)\r\n \r\n             self.moenergies = [numpy.array(self.moenergies[0], \"d\")]\r\n", "before": "self . set_attribute ( [ len ( self . moenergies [ 0 ] ) - 2 ] )", "after": "self . set_attribute ( 'homos' , [ len ( self . moenergies [ 0 ] ) - 2 ] )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 39, 3, 70], [\"string:'homos'\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 39, 3, 70], [\",:,\", \"T\"], 2]]"}
{"project": "burp_server_reports", "commit_sha": "c7a27154fba535756b50d092c230d22b04e2ce79", "parent_sha": "d7c0fddd3af38b915caa49f005ce313f4ddf17dd", "file_path": "burp_reports/lib/txt.py", "project_url": "https://github.com/pablodav/burp_server_reports", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -226,7 +226,7 @@ class TxtReports:\n             if print_text:\n                 self.print_text(client)\n             else:\n-                text_body += self.print_text(client)\n+                text_body += self.print_text(client, print_text=None)\n             \n             if self.detail:\n                 total_taken += int(client_data.get('backup_report', {}).get('duration', 0))\n", "before": "text_body += self . print_text ( client )", "after": "text_body += self . print_text ( client , print_text = None )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 45, 3, 53], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 45, 3, 53], [\"keyword_argument\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:print_text\", \"T\"], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Insert\", \"N0\", [\"none:None\", \"T\"], 2]]"}
{"project": "tvm", "commit_sha": "2bc090fe7ecb4cf928d7d220396aeece652e839d", "parent_sha": "ce2d1bda7ed0ba78b52bb4fbcf6afa0484d0a4ee", "file_path": "python/tvm/relay/frontend/tensorflow.py", "project_url": "https://github.com/neo-ai/tvm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2835,7 +2835,7 @@ class GraphProto(object):\n \n             array_ndim = len(np_array.shape)\n             if array_ndim == 0:\n-                self._nodes[name] = [tvm.relay.const(np_array)]\n+                self._nodes[name] = [tvm.relay.const(np_array, np_array.dtype)]\n             else:\n                 self._params[name] = tvm.nd.array(np_array)\n                 self._nodes[name] = [_expr.var(name,\n", "before": "self . _nodes [ name ] = [ tvm . relay . const ( np_array ) ]", "after": "self . _nodes [ name ] = [ tvm . relay . const ( np_array , np_array . dtype ) ]", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 53, 3, 63], [\",:,\", \"T\"], 2], [\"Insert\", [\"argument_list\", 3, 53, 3, 63], [\"attribute\", \"N0\"], 3], [\"Insert\", \"N0\", [\"identifier:np_array\", \"T\"], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:dtype\", \"T\"], 2]]"}
{"project": "edx-platform", "commit_sha": "9266bcca6d4e6a0e5af10f227a62d122a7bfa6e0", "parent_sha": "317e2c345e028cb12c1d95b4962615cba30ecb44", "file_path": "common/lib/xmodule/xmodule/course_module.py", "project_url": "https://github.com/easy-edx/edx-platform", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -106,7 +106,7 @@ class CourseDescriptor(SequenceDescriptor):\n                 # the rest of the courseware.\n                 log.exception(\"Couldn't load textbook\")\n                 continue\n-            textbooks.append()\n+            textbooks.append(txt)\n             xml_object.remove(textbook)\n \n         #Load the wiki tag if it exists\n", "before": "textbooks . append ( )", "after": "textbooks . append ( txt )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 29, 3, 31], [\"identifier:txt\", \"T\"], 1]]"}
{"project": "edx-platform", "commit_sha": "00156fd600751c495cb50838de8be83845067b5d", "parent_sha": "2d105265f95c8843c1a28adc286caf4a8be068ed", "file_path": "common/lib/xmodule/xmodule/course_module.py", "project_url": "https://github.com/easy-edx/edx-platform", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -106,7 +106,7 @@ class CourseDescriptor(SequenceDescriptor):\n                 # the rest of the courseware.\n                 log.exception(\"Couldn't load textbook\")\n                 continue\n-            textbooks.append()\n+            textbooks.append(txt)\n             xml_object.remove(textbook)\n \n         #Load the wiki tag if it exists\n", "before": "textbooks . append ( )", "after": "textbooks . append ( txt )", "sstub_pattern": "SAME_FUNCTION_MORE_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 29, 3, 31], [\"identifier:txt\", \"T\"], 1]]"}
{"project": "splinter", "commit_sha": "7ef846f0fc789393d1361289bebd3b4d1270250f", "parent_sha": "692bb8c885844eda7018e05922d9a47ea4f0d013", "file_path": "tests/status_code.py", "project_url": "https://github.com/underdogio/splinter", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -11,4 +11,4 @@ class StatusCodeTest(object):\n \n     def test_should_visit_index_of_example_app_and_get_200_status_code(self):\n         self.browser.visit(EXAMPLE_APP)\n-        assert_equals(self.browser.status_code, 200)\n+        assert_equals(200, self.browser.status_code)\n", "before": "assert_equals ( self . browser . status_code , 200 )", "after": "assert_equals ( 200 , self . browser . status_code )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 22, 3, 53], [\"integer:200\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 22, 3, 53], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 47, 3, 48]], [\"Delete\", [\"integer:200\", 3, 49, 3, 52]]]"}
{"project": "librosa", "commit_sha": "27abd4aa825fef2e7e04f4925d331159a49a4c77", "parent_sha": "0c02cc7712dcf1c08a95b50b6fcbbaa1c1022bdc", "file_path": "tests/test_features.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -814,7 +814,7 @@ def test_fourier_tempogram_invert(sr, hop_length, win_length, center, window):\n \n     odf_inv = librosa.istft(tempogram, hop_length=1, center=center, window=window,\n                             length=len(odf))\n-    assert np.allclose(odf[sl], odf_inv[sl])\n+    assert np.allclose(odf_inv[sl], odf[sl])\n \n \n def test_cens():\n", "before": "assert np . allclose ( odf [ sl ] , odf_inv [ sl ] )", "after": "assert np . allclose ( odf_inv [ sl ] , odf [ sl ] )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"subscript\", 3, 24, 3, 31], [\"argument_list\", 3, 23, 3, 45], 2], [\"Move\", [\"subscript\", 3, 33, 3, 44], [\"argument_list\", 3, 23, 3, 45], 1]]"}
{"project": "librosa", "commit_sha": "f88e6b4b2f0282295c45aa72dd4fe6be126ba367", "parent_sha": "3174f20c2320830528ba8f7268143f076440ebd0", "file_path": "tests/test_features.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -814,7 +814,7 @@ def test_fourier_tempogram_invert(sr, hop_length, win_length, center, window):\n \n     odf_inv = librosa.istft(tempogram, hop_length=1, center=center, window=window,\n                             length=len(odf))\n-    assert np.allclose(odf[sl], odf_inv[sl])\n+    assert np.allclose(odf_inv[sl], odf[sl])\n \n \n def test_cens():\n", "before": "assert np . allclose ( odf [ sl ] , odf_inv [ sl ] )", "after": "assert np . allclose ( odf_inv [ sl ] , odf [ sl ] )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"subscript\", 3, 24, 3, 31], [\"argument_list\", 3, 23, 3, 45], 2], [\"Move\", [\"subscript\", 3, 33, 3, 44], [\"argument_list\", 3, 23, 3, 45], 1]]"}
{"project": "edi-to-csv-converter", "commit_sha": "39f4ebf5b720218f93a63ce43d94b210372a1b72", "parent_sha": "52291d76cfd93c2cff86a262afba6995257924c3", "file_path": "converter.py", "project_url": "https://github.com/dtg01100/edi-to-csv-converter", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -113,7 +113,7 @@ def edi_convert(edi_process, output_filename, calc_upc, inc_arec, inc_crec, inc_\n         else:\r\n             f = open(output_filename, \"w\")\r\n \r\n-        f.write(\"{}\" \",\" \"{}\" \",\" \"{}\" \",\" \"{}\" \",\" \"{}\" \",\" \"{}\" \",\" \"{}\\n\".format(\"UPC\", \"Qty. Shipped\", \"Cost\", \"Description\", \"Suggested Retail\", \"Case Pack\", \"Item Number\"))\r\n+        f.write(\"{}\" \",\" \"{}\" \",\" \"{}\" \",\" \"{}\" \",\" \"{}\" \",\" \"{}\" \",\" \"{}\\n\".format(\"UPC\", \"Qty. Shipped\", \"Cost\", \"Suggested Retail\", \"Description\", \"Case Pack\", \"Item Number\"))\r\n         f.close()\r\n \r\n \r\n", "before": "f . write ( \"{}\" \",\" \"{}\" \",\" \"{}\" \",\" \"{}\" \",\" \"{}\" \",\" \"{}\" \",\" \"{}\\n\" . format ( \"UPC\" , \"Qty. Shipped\" , \"Cost\" , \"Description\" , \"Suggested Retail\" , \"Case Pack\" , \"Item Number\" ) )", "after": "f . write ( \"{}\" \",\" \"{}\" \",\" \"{}\" \",\" \"{}\" \",\" \"{}\" \",\" \"{}\" \",\" \"{}\\n\" . format ( \"UPC\" , \"Qty. Shipped\" , \"Cost\" , \"Suggested Retail\" , \"Description\" , \"Case Pack\" , \"Item Number\" ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"string:\\\"Description\\\"\", 3, 116, 3, 129], [\"argument_list\", 3, 84, 3, 178], 9], [\"Move\", [\",:,\", 3, 129, 3, 130], [\"argument_list\", 3, 84, 3, 178], 10]]"}
{"project": "CloudBot", "commit_sha": "cb7f9b736f54ed78f28b2c26cad2db8a457bf05c", "parent_sha": "ecab6076ea1e85c743078f218b6ed6126233129b", "file_path": "plugins/namegen.py", "project_url": "https://github.com/MrW24/CloudBot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ GEN_DIR = \"./plugins/data/name_files/\"\n def get_generator(_json):\n     data = json.loads(_json)\n     return textgen.TextGenerator(data[\"name\"], data[\"templates\"],\n-        data[\"default_templates\"], data[\"parts\"])\n+        data[\"parts\"], data[\"default_templates\"])\n \n \n @hook.command(autohelp=False)\n", "before": "return textgen . TextGenerator ( data [ \"name\" ] , data [ \"templates\" ] , data [ \"default_templates\" ] , data [ \"parts\" ] )", "after": "return textgen . TextGenerator ( data [ \"name\" ] , data [ \"templates\" ] , data [ \"parts\" ] , data [ \"default_templates\" ] )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"subscript\", 3, 9, 3, 34], [\"argument_list\", 2, 33, 3, 50], 6], [\"Move\", [\"subscript\", 3, 36, 3, 49], [\"argument_list\", 2, 33, 3, 50], 5]]"}
{"project": "pegleg", "commit_sha": "865c9207605425ca21e0d3e37fa51027090603b7", "parent_sha": "c7d745fdbee8308c727ddf3bfd630f698bff0860", "file_path": "pegleg/cli.py", "project_url": "https://github.com/airshipit/pegleg", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -669,7 +669,7 @@ def decrypt(*, path, save_location, overwrite, site_name):\n     decrypted = engine.secrets.decrypt(path, site_name=site_name)\n     if overwrite:\n         for path, data in decrypted.items():\n-            files.write(path, data)\n+            files.write(data, path)\n     elif save_location is None:\n         for data in decrypted.values():\n             click.echo(data)\n", "before": "files . write ( path , data )", "after": "files . write ( data , path )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:path\", 3, 25, 3, 29], [\"argument_list\", 3, 24, 3, 36], 3], [\"Move\", [\",:,\", 3, 29, 3, 30], [\"argument_list\", 3, 24, 3, 36], 4]]"}
{"project": "cc-utils", "commit_sha": "b26c0ad20feeac8bd217583b17f9cd32cf8de9ef", "parent_sha": "5d8c5d031489df3ade8752253a8695e7d2fa0f40", "file_path": "concourse/replicator.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -388,7 +388,7 @@ class ReplicationResultProcessor(object):\n     def _notify_broken_definition_owners(self, failed_descriptor):\n         definition_descriptor = failed_descriptor.definition_descriptor\n         main_repo = definition_descriptor.main_repo\n-        github_cfg = ccc.github.github_cfg_for_hostname(self._cfg_set, main_repo['hostname'])\n+        github_cfg = ccc.github.github_cfg_for_hostname(main_repo['hostname'], self._cfg_set)\n         github_api = ccc.github.github_api(github_cfg)\n         repo_owner, repo_name = main_repo['path'].split('/')\n \n", "before": "github_cfg = ccc . github . github_cfg_for_hostname ( self . _cfg_set , main_repo [ 'hostname' ] )", "after": "github_cfg = ccc . github . github_cfg_for_hostname ( main_repo [ 'hostname' ] , self . _cfg_set )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"subscript\", 3, 72, 3, 93], [\"argument_list\", 3, 56, 3, 94], 1], [\"Insert\", [\"argument_list\", 3, 56, 3, 94], [\",:,\", \"T\"], 4], [\"Delete\", [\",:,\", 3, 70, 3, 71]]]"}
{"project": "kaggle-carvana-2017", "commit_sha": "9be79473a93cae55d665ad8610595d01e4a3af0c", "parent_sha": "8897c921e6cec1ebbd6e5196b627bd3c94a8c746", "file_path": "train.py", "project_url": "https://github.com/killthekitten/kaggle-carvana-2017", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ def main():\n \n     # @TODO: add clipped `val_dice` to the filename\n     best_model_file =\\\n-        '{}/{}-loss-{}-fold_{}-{}{:.6f}'.format(args.network, args.models_dir, args.loss_function, args.fold, args.input_width, args.learning_rate) +\\\n+        '{}/{}-loss-{}-fold_{}-{}{:.6f}'.format(args.models_dir, args.network, args.loss_function, args.fold, args.input_width, args.learning_rate) +\\\n         '-{epoch:d}-{val_loss:0.7f}-{val_dice_coef_clipped:0.7f}.h5'\n \n     model = make_model((None, None, 3))\n", "before": "best_model_file = '{}/{}-loss-{}-fold_{}-{}{:.6f}' . format ( args . network , args . models_dir , args . loss_function , args . fold , args . input_width , args . learning_rate ) + '-{epoch:d}-{val_loss:0.7f}-{val_dice_coef_clipped:0.7f}.h5'", "after": "best_model_file = '{}/{}-loss-{}-fold_{}-{}{:.6f}' . format ( args . models_dir , args . network , args . loss_function , args . fold , args . input_width , args . learning_rate ) + '-{epoch:d}-{val_loss:0.7f}-{val_dice_coef_clipped:0.7f}.h5'", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"attribute\", 3, 49, 3, 61], [\"argument_list\", 3, 48, 3, 148], 2], [\"Move\", [\"attribute\", 3, 63, 3, 78], [\"argument_list\", 3, 48, 3, 148], 1]]"}
{"project": "sipa", "commit_sha": "d09b07178f1869d9419aae23391f81268f682f4c", "parent_sha": "184dff72cd56795939705f1bd5ada43f3928a22f", "file_path": "sipa/utils/git_utils.py", "project_url": "https://github.com/agdsn/sipa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -23,7 +23,7 @@ def init_repo(repo_dir, repo_url):\n         return\n \n     repo.git.reset('--hard', 'origin/master')\n-    logger.info(\"Initialized git repository %s in %s\", repo_dir, repo_url)\n+    logger.info(\"Initialized git repository %s in %s\", repo_url, repo_dir)\n \n \n def update_repo(repo_dir):\n", "before": "logger . info ( \"Initialized git repository %s in %s\" , repo_dir , repo_url )", "after": "logger . info ( \"Initialized git repository %s in %s\" , repo_url , repo_dir )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:repo_dir\", 3, 56, 3, 64], [\"argument_list\", 3, 16, 3, 75], 5], [\"Move\", [\",:,\", 3, 64, 3, 65], [\"argument_list\", 3, 16, 3, 75], 6]]"}
{"project": "bot", "commit_sha": "84a99ef4502e5dfdc75422e846770743cea08556", "parent_sha": "3830f7b43c69c188bc62f16357eac93be3edfa14", "file_path": "bot.py", "project_url": "https://github.com/trackmastersteve/bot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -173,7 +173,7 @@ def main():\n                         message = \"The mode \" + mode + \" was set on \" + target + \"!\"\n                     else:\n                         message = \"Could not parse. The message should be in the format of '.mode [target] [mode]' to work properly.\"\n-                    setmode(target, mode)\n+                    setmode(mode, target)\n                     sendmsg(message, adminname)\n                 \n                 # Respond to the '.join [channel]' command from admin.\n", "before": "setmode ( target , mode )", "after": "setmode ( mode , target )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:target\", 3, 29, 3, 35], [\"argument_list\", 3, 28, 3, 42], 3], [\"Move\", [\",:,\", 3, 35, 3, 36], [\"argument_list\", 3, 28, 3, 42], 4]]"}
{"project": "plugin.video.mediathekview", "commit_sha": "60a2af1c22fbe70994769420592539b9da2f3a4d", "parent_sha": "959a210fd94e6a12c666a3bfd0ab911929045476", "file_path": "resources/lib/updateFileImport.py", "project_url": "https://github.com/mediathekview/plugin.video.mediathekview", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -220,7 +220,7 @@ class UpdateFileImport(object):\n             ##\n             ufp.close()\n             self._update_end()\n-            self.logger.info('{} records processed in {} sec. Updated: {} Inserted: {}',self.count, int(time.time() - starttime), self.insertCount, self.updateCount)           \n+            self.logger.info('{} records processed in {} sec. Updated: {} Inserted: {}',self.count, int(time.time() - starttime), self.updateCount, self.insertCount)           \n             self.notifier.close_update_progress()\n             if self.errorCount > 0:\n                 self.logger.info('Update finished with error(s)')\n", "before": "self . logger . info ( '{} records processed in {} sec. Updated: {} Inserted: {}' , self . count , int ( time . time ( ) - starttime ) , self . insertCount , self . updateCount )", "after": "self . logger . info ( '{} records processed in {} sec. Updated: {} Inserted: {}' , self . count , int ( time . time ( ) - starttime ) , self . updateCount , self . insertCount )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"attribute\", 3, 131, 3, 147], [\"argument_list\", 3, 29, 3, 166], 8], [\"Move\", [\"attribute\", 3, 149, 3, 165], [\"argument_list\", 3, 29, 3, 166], 7]]"}
{"project": "erpnext-v7", "commit_sha": "067559ca9d1f93dffcf9d85a4ca42f1b25bb1e12", "parent_sha": "d89d59bcb2a02492fc846a299d33ea65bd3babcb", "file_path": "patches/patch.py", "project_url": "https://github.com/YefriTavarez/erpnext-v7", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -291,5 +291,5 @@ def execute(patch_no):\n \t\t\tch.format = 'Delivery Note Packing List Wise'\n \t\t\tch.save(1)\n \telif patch_no == 353:\n-\t\treload_doc('doctype', 'core', 'doctype')\n+\t\treload_doc('core', 'doctype', 'doctype')\n \t\tsql(\"update `tabDocType` set default_print_format = 'Standard' where name = 'Delivery Note'\")\n", "before": "elif patch_no == 353 : reload_doc ( 'doctype' , 'core' , 'doctype' )", "after": "elif patch_no == 353 : reload_doc ( 'core' , 'doctype' , 'doctype' )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"string:'doctype'\", 3, 14, 3, 23], [\"argument_list\", 3, 13, 3, 43], 3], [\"Move\", [\",:,\", 3, 23, 3, 24], [\"argument_list\", 3, 13, 3, 43], 4]]"}
{"project": "erpnext-v7", "commit_sha": "332d56db387db1aafe751e87b0e793f1ebaf9631", "parent_sha": "687d4b1834a80a8b8456a111e8aedc78b9849452", "file_path": "patches/patch.py", "project_url": "https://github.com/YefriTavarez/erpnext-v7", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -306,7 +306,7 @@ def execute(patch_no):\n \t\treload_doc('hr', 'doctype', 'salary_slip')\n \t\tdelete_doc('DocType', 'Salary Control Panel')\n \telif patch_no == 356:\n-\t\treload_doc('doctype', 'core', 'doctype')\n+\t\treload_doc('core', 'doctype', 'doctype')\n \t\tsql(\"update `tabDocType` set default_print_format = 'Standard' where name = 'Delivery Note'\")\n \telif patch_no == 357:\n \t\tsql(\"delete from `tabDocField` where (fieldname in ('client_string', 'server_code_error', 'server_code_compiled', 'server_code', 'server_code_core', 'client_script', 'client_script_core', 'dt_template', change_log) or label = 'Template') and parent = 'DocType'\")\n", "before": "elif patch_no == 356 : reload_doc ( 'doctype' , 'core' , 'doctype' )", "after": "elif patch_no == 356 : reload_doc ( 'core' , 'doctype' , 'doctype' )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"string:'doctype'\", 3, 14, 3, 23], [\"argument_list\", 3, 13, 3, 43], 3], [\"Move\", [\",:,\", 3, 23, 3, 24], [\"argument_list\", 3, 13, 3, 43], 4]]"}
{"project": "erpnext-v7", "commit_sha": "c6b506158b36aed51d479c1c45c419c54e9c4540", "parent_sha": "687d4b1834a80a8b8456a111e8aedc78b9849452", "file_path": "patches/patch.py", "project_url": "https://github.com/YefriTavarez/erpnext-v7", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -306,7 +306,7 @@ def execute(patch_no):\n \t\treload_doc('hr', 'doctype', 'salary_slip')\n \t\tdelete_doc('DocType', 'Salary Control Panel')\n \telif patch_no == 356:\n-\t\treload_doc('doctype', 'core', 'doctype')\n+\t\treload_doc('core', 'doctype', 'doctype')\n \t\tsql(\"update `tabDocType` set default_print_format = 'Standard' where name = 'Delivery Note'\")\n \telif patch_no == 357:\n \t\tsql(\"delete from `tabDocField` where (fieldname in ('client_string', 'server_code_error', 'server_code_compiled', 'server_code', 'server_code_core', 'client_script', 'client_script_core', 'dt_template', change_log) or label = 'Template') and parent = 'DocType'\")\n", "before": "elif patch_no == 356 : reload_doc ( 'doctype' , 'core' , 'doctype' )", "after": "elif patch_no == 356 : reload_doc ( 'core' , 'doctype' , 'doctype' )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"string:'doctype'\", 3, 14, 3, 23], [\"argument_list\", 3, 13, 3, 43], 3], [\"Move\", [\",:,\", 3, 23, 3, 24], [\"argument_list\", 3, 13, 3, 43], 4]]"}
{"project": "addmeta", "commit_sha": "a2bc28d8fd508988d3ddbb85b02b01e3f5c1c60b", "parent_sha": "125d5b90259050b8242459a3285cb8f16e03b828", "file_path": "test/test_read_yaml.py", "project_url": "https://github.com/coecms/addmeta", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -113,4 +113,4 @@ def test_add_meta():\n \n def test_find_add_meta():\n     \n-    find_and_add_meta(['test/test.nc'], ['test/meta2.yaml','test/meta1.yaml'])\n+    find_and_add_meta(['test/meta2.yaml','test/meta1.yaml'], ['test/test.nc'])\n", "before": "find_and_add_meta ( [ 'test/test.nc' ] , [ 'test/meta2.yaml' , 'test/meta1.yaml' ] )", "after": "find_and_add_meta ( [ 'test/meta2.yaml' , 'test/meta1.yaml' ] , [ 'test/test.nc' ] )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"list\", 3, 23, 3, 39], [\"argument_list\", 3, 22, 3, 79], 2], [\"Move\", [\"list\", 3, 41, 3, 78], [\"argument_list\", 3, 22, 3, 79], 1]]"}
{"project": "salt", "commit_sha": "c1f210e31f659fa99952c51a686a55c29762cdd1", "parent_sha": "349d8802519a19e5475947e75c22e70a50a3d785", "file_path": "salt/modules/win_lgpo.py", "project_url": "https://github.com/kraney/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2477,7 +2477,7 @@ class _policy_info(object):\n         minimum = 0\n         maximum = 1\n-        if isinstance(string_types, val):\n+        if isinstance(val, string_types):\n             if val.lower() == 'not defined':\n                 return True\n             else:\n", "before": "if isinstance ( string_types , val ) : if val . lower ( ) == 'not defined' : return True else : ", "after": "if isinstance ( val , string_types ) : if val . lower ( ) == 'not defined' : return True else : ", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:string_types\", 2, 23, 2, 35], [\"argument_list\", 2, 22, 2, 41], 3], [\"Move\", [\",:,\", 2, 35, 2, 36], [\"argument_list\", 2, 22, 2, 41], 4]]"}
{"project": "openstates", "commit_sha": "1f6a8951aadf2262cec8627e8d26bb9124b0d640", "parent_sha": "953016dfc5a86853bf6924838ca8d8f0f78629fe", "file_path": "fiftystates/scrape/in/bills.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -68,7 +68,7 @@ class INBillScraper(BillScraper):\n             for sponsor in slist:\n                 name = sponsor.strip()\n                 if name:\n-                    bill.add_sponsor(name, 'author')\n+                    bill.add_sponsor('author', name)\n \n             act_table = page.xpath(\"//table\")[1]\n             read_yet = False\n", "before": "bill . add_sponsor ( name , 'author' )", "after": "bill . add_sponsor ( 'author' , name )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:name\", 3, 38, 3, 42], [\"argument_list\", 3, 37, 3, 53], 3], [\"Move\", [\",:,\", 3, 42, 3, 43], [\"argument_list\", 3, 37, 3, 53], 4]]"}
{"project": "spyne", "commit_sha": "040ae0ed8bdcdf9c6a5d94baba87254ddec1bf0b", "parent_sha": "df9b3fe7309a1cbebf597c9258118e06fd6a7c16", "file_path": "spyne/protocol/html/table.py", "project_url": "https://github.com/duixteam/spyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -226,7 +226,7 @@ class HtmlColumnTable(HtmlTableBase):\n                     header_name = self.trc(cls, ctx.locale, name)\n                     parent.write(E.th(header_name, **th_attrs))\n \n-                self.extend_header_row(ctx, cls, name, parent)\n+                self.extend_header_row(ctx, cls, parent, name)\n \n     @coroutine\n     def _gen_table(self, ctx, cls, inst, parent, name, gen_rows, **kwargs):\n", "before": "self . extend_header_row ( ctx , cls , name , parent )", "after": "self . extend_header_row ( ctx , cls , parent , name )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:name\", 3, 50, 3, 54], [\"argument_list\", 3, 39, 3, 63], 7], [\"Move\", [\",:,\", 3, 54, 3, 55], [\"argument_list\", 3, 39, 3, 63], 8]]"}
{"project": "webdav", "commit_sha": "45374ee2b360e7641a691a6e96f8e9bcd694c40a", "parent_sha": "cf946f0f0ee35985a0d9e893f85093be8613ae10", "file_path": "src/webdav/client.py", "project_url": "https://github.com/kamikaze/webdav", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -378,7 +378,7 @@ class Client(object):\n                 yield f\n \n             if 'w' in mode or 'a' in mode or 'x' in mode:\n-                self.upload_file(local_path, file)\n+                self.upload_file(file, local_path)\n \n     @wrap_connection_error\n     def download_file(self, remote_path, local_path, progress=None):\n", "before": "self . upload_file ( local_path , file )", "after": "self . upload_file ( file , local_path )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:local_path\", 3, 34, 3, 44], [\"argument_list\", 3, 33, 3, 51], 3], [\"Move\", [\",:,\", 3, 44, 3, 45], [\"argument_list\", 3, 33, 3, 51], 4]]"}
{"project": "scipy", "commit_sha": "372704e452f4eb7fb03d2fdb6628b1910e634801", "parent_sha": "619d5b73d94cb4d4dfdafd99dae170c78ab468c0", "file_path": "scipy/signal/wavelets.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -322,7 +322,7 @@ def cwt(data, wavelet, widths):\n     wavelet : function\n         Wavelet function, which should take 2 arguments.\n         The first argument is the number of points that the returned vector\n-        will have (len(wavelet(width,length)) == length).\n+        will have (len(wavelet(length,width)) == length).\n         The second is a width parameter, defining the size of the wavelet\n         (e.g. standard deviation of a gaussian). See `ricker`, which\n         satisfies these requirements.\n", "before": "will have ( len ( wavelet ( width , length ) ) == length ) . The second is a width parameter , defining the size of the wavelet", "after": "will have ( len ( wavelet ( length , width ) ) == length ) . The second is a width parameter , defining the size of the wavelet", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:width\", 3, 32, 3, 37], [\"argument_list\", 3, 31, 3, 45], 3], [\"Move\", [\",:,\", 3, 37, 3, 38], [\"argument_list\", 3, 31, 3, 45], 4]]"}
{"project": "vmware-nsx", "commit_sha": "bb17694a553a672f732f56c6cdc9b15cfebe5355", "parent_sha": "1cb3ccd1965cfe2404a16aabc655f1f483d55702", "file_path": "neutron/plugins/vmware/plugins/base.py", "project_url": "https://github.com/gkotton/vmware-nsx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2324,7 +2324,7 @@ class NsxPluginV2(addr_pair_db.AllowedAddressPairsMixin,\n         # NOTE(salv-orlando): Pre-generating Neutron ID for security group.\n         neutron_id = str(uuid.uuid4())\n         nsx_secgroup = secgrouplib.create_security_profile(\n-            self.cluster, neutron_id, tenant_id, s)\n+            self.cluster, tenant_id, neutron_id, s)\n         with context.session.begin(subtransactions=True):\n             s['id'] = neutron_id\n             sec_group = super(NsxPluginV2, self).create_security_group(\n", "before": "nsx_secgroup = secgrouplib . create_security_profile ( self . cluster , neutron_id , tenant_id , s )", "after": "nsx_secgroup = secgrouplib . create_security_profile ( self . cluster , tenant_id , neutron_id , s )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Update\", [\"identifier:neutron_id\", 3, 27, 3, 37], \"tenant_id\"], [\"Update\", [\"identifier:tenant_id\", 3, 39, 3, 48], \"neutron_id\"]]"}
{"project": "scipy", "commit_sha": "45bd13d2681115e11322d8ba3873f45d353a09d4", "parent_sha": "9e5ea8a056cf39b828bf634e8457173c5f205ce8", "file_path": "scipy/signal/wavelets.py", "project_url": "https://github.com/GregoryEAllen/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -332,7 +332,7 @@ def cwt(data, wavelet, widths):\n     Returns\n     -------\n     cwt: (M, N) ndarray\n-        Will have shape of (len(data), len(widths)).\n+        Will have shape of (len(widths), len(data)).\n \n     Notes\n     -----\n", "before": "shape of ( len ( data ) , len ( widths ) ) . Notes", "after": "shape of ( len ( widths ) , len ( data ) ) . Notes", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"call\", 3, 29, 3, 38], [\"argument_list\", 3, 28, 3, 52], 2], [\"Move\", [\"call\", 3, 40, 3, 51], [\"argument_list\", 3, 28, 3, 52], 1]]"}
{"project": "scipy", "commit_sha": "3c36215c8af3afa51ba2b65cccb51b1da48608be", "parent_sha": "b7542e4615dffa97768943acf677b0dffdfb3adc", "file_path": "Lib/stats/tests/test_stats.py", "project_url": "https://github.com/GregoryEAllen/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -363,7 +363,7 @@ class test_regression(unittest.TestCase):\n-        y = scipy.stats.linregress(BIG,X)\n+        y = scipy.stats.linregress(X,BIG)\n         intercept = y[1]\n         r=y[2]\n         assert_almost_equal(intercept,99999990)\n", "before": "y = scipy . stats . linregress ( BIG , X )", "after": "y = scipy . stats . linregress ( X , BIG )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:BIG\", 0, 36, 0, 39], [\"argument_list\", 0, 35, 0, 42], 3], [\"Move\", [\",:,\", 0, 39, 0, 40], [\"argument_list\", 0, 35, 0, 42], 4]]"}
{"project": "okd-orchestrator", "commit_sha": "b16cf9cbb39ca4583559248a270660b13e2b8705", "parent_sha": "242acc5b0de9e2a8279bfb5d0375cb207493cf9c", "file_path": "create.py", "project_url": "https://github.com/InformaticsMatters/okd-orchestrator", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -197,7 +197,7 @@ def _main(cli_args, deployment_name):\n \n         for play in deployment['openshift']['play']:\n             cmd = 'ansible-playbook ../openshift-ansible/playbooks/{}' \\\n-                  ' -i inventories/{}/inventory'.format(deployment_name, play)\n+                  ' -i inventories/{}/inventory'.format(play, deployment_name)\n             cwd = 'openshift'\n             rv, _ = io.run(cmd, cwd, cli_args.quiet)\n             if not rv:\n", "before": "cmd = 'ansible-playbook ../openshift-ansible/playbooks/{}' ' -i inventories/{}/inventory' . format ( deployment_name , play )", "after": "cmd = 'ansible-playbook ../openshift-ansible/playbooks/{}' ' -i inventories/{}/inventory' . format ( play , deployment_name )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:deployment_name\", 3, 57, 3, 72], [\"argument_list\", 3, 56, 3, 79], 3], [\"Move\", [\",:,\", 3, 72, 3, 73], [\"argument_list\", 3, 56, 3, 79], 4]]"}
{"project": "ansible-1", "commit_sha": "9f90f0e85683a26f349f4b1823d6427bbaa64514", "parent_sha": "fcc2a753b7a9e92072d4b90123a1b4f20df56af2", "file_path": "lib/ansible/runner/lookup_plugins/env.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ class LookupModule(object):\n \n         terms = utils.listify_lookup_plugin_terms(terms, self.basedir, inject) \n \n-        if isinstance(basestring, terms):\n+        if isinstance(terms, basestring):\n             terms = [ terms ]\n \n         ret = []\n", "before": "if isinstance ( basestring , terms ) : terms = [ terms ]", "after": "if isinstance ( terms , basestring ) : terms = [ terms ]", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:basestring\", 3, 23, 3, 33], [\"argument_list\", 3, 22, 3, 41], 3], [\"Move\", [\",:,\", 3, 33, 3, 34], [\"argument_list\", 3, 22, 3, 41], 4]]"}
{"project": "ansible-1", "commit_sha": "9694d60af5e9cde7aa684e9795b79f9fbb928ce5", "parent_sha": "db276373e5b40b9a11796bbac9a386aa79c998b7", "file_path": "lib/ansible/module_utils/netcli.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -296,5 +296,5 @@ class Conditional(object):\n         return str(self.value) in value\n \n     def matches(self, value):\n-        match = re.search(value, self.value, re.M)\n+        match = re.search(self.value, value, re.M)\n         return match is not None\n", "before": "match = re . search ( value , self . value , re . M )", "after": "match = re . search ( self . value , value , re . M )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 51], [\"identifier:value\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 26, 3, 51], [\",:,\", \"T\"], 5], [\"Delete\", [\"identifier:value\", 3, 27, 3, 32]], [\"Delete\", [\",:,\", 3, 32, 3, 33]]]"}
{"project": "ansible-1", "commit_sha": "75a9357e5e97b11b8cc3048afe8c0fcf30e4d606", "parent_sha": "294451d00243b7caf3c0aaae8476ec2a96149bdb", "file_path": "lib/ansible/playbook/play.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -164,7 +164,7 @@ class Play(object):\n             raise errors.AnsibleError(\"too many levels of recursion while resolving role dependencies\")\n         for role in roles:\n             role_path,role_vars = self._get_role_path(role)\n-            role_vars = utils.combine_vars(role_vars, passed_vars)\n+            role_vars = utils.combine_vars(passed_vars, role_vars)\n             vars = self._resolve_main(utils.path_dwim(self.basedir, os.path.join(role_path, 'vars')))\n             vars_data = {}\n             if os.path.isfile(vars):\n", "before": "role_vars = utils . combine_vars ( role_vars , passed_vars )", "after": "role_vars = utils . combine_vars ( passed_vars , role_vars )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:role_vars\", 3, 44, 3, 53], [\"argument_list\", 3, 43, 3, 67], 3], [\"Move\", [\",:,\", 3, 53, 3, 54], [\"argument_list\", 3, 43, 3, 67], 4]]"}
{"project": "ansible-1", "commit_sha": "242f20c29722695dfe90a3331464604b5b026020", "parent_sha": "12eaefb7e6ec193bef83df1a866c6a9670100dc0", "file_path": "lib/ansible/runner/lookup_plugins/dnstxt.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ class LookupModule(object):\n \n         terms = utils.listify_lookup_plugin_terms(terms, self.basedir, inject) \n \n-        if isinstance(basestring, terms):\n+        if isinstance(terms, basestring):\n             terms = [ terms ]\n \n         ret = []\n", "before": "if isinstance ( basestring , terms ) : terms = [ terms ]", "after": "if isinstance ( terms , basestring ) : terms = [ terms ]", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:basestring\", 3, 23, 3, 33], [\"argument_list\", 3, 22, 3, 41], 3], [\"Move\", [\",:,\", 3, 33, 3, 34], [\"argument_list\", 3, 22, 3, 41], 4]]"}
{"project": "brute", "commit_sha": "9b616e9cc386b451db364250e7dfdefc31dfdea1", "parent_sha": "a6919eb1b26fa057c772fceb02206b646c12d445", "file_path": "test_brute.py", "project_url": "https://github.com/Krafty-Coder/brute", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -17,4 +17,4 @@ class TestBrute(TestCase):\n         self.assertEqual(len(last_str), 3)\n \n     def test_brute_returns_generator(self):\n-        self.assertIsInstance(GeneratorType, brute())\n+        self.assertIsInstance(brute(), GeneratorType)\n", "before": "self . assertIsInstance ( GeneratorType , brute ( ) )", "after": "self . assertIsInstance ( brute ( ) , GeneratorType )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 54], [\",:,\", \"T\"], 3], [\"Insert\", [\"argument_list\", 3, 30, 3, 54], [\"identifier:GeneratorType\", \"T\"], 4], [\"Delete\", [\"identifier:GeneratorType\", 3, 31, 3, 44]], [\"Delete\", [\",:,\", 3, 44, 3, 45]]]"}
{"project": "mxnet", "commit_sha": "305f7534f13ee875543859ec3be0c072440803f7", "parent_sha": "df9f6129f3f5da56894cd8c5507c342532cc7ffe", "file_path": "example/ssd/dataset/iterator.py", "project_url": "https://github.com/zhiiker/mxnet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -173,7 +173,7 @@ class DetIter(mx.io.DataIter):\n         else:\n             interp_methods = [cv2.INTER_LINEAR]\n         interp_method = interp_methods[int(np.random.uniform(0, 1) * len(interp_methods))]\n-        data = mx.img.imresize(data, self._data_shape[0], self._data_shape[1], interp_method)\n+        data = mx.img.imresize(data, self._data_shape[1], self._data_shape[0], interp_method)\n         if self.is_train and self._rand_mirror:\n             if np.random.uniform(0, 1) > 0.5:\n                 data = mx.nd.flip(data, axis=1)\n", "before": "data = mx . img . imresize ( data , self . _data_shape [ 0 ] , self . _data_shape [ 1 ] , interp_method )", "after": "data = mx . img . imresize ( data , self . _data_shape [ 1 ] , self . _data_shape [ 0 ] , interp_method )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"subscript\", 3, 38, 3, 57], [\"argument_list\", 3, 31, 3, 94], 4], [\"Move\", [\"subscript\", 3, 59, 3, 78], [\"argument_list\", 3, 31, 3, 94], 3]]"}
{"project": "millegrilles.consignation.python", "commit_sha": "99bfece4d85e198f6e4ff7bd368f3f931bf8634f", "parent_sha": "d182ac7c398990c3779dc40695e84b9a0d8bf4cf", "file_path": "millegrilles/Declencheur.py", "project_url": "https://github.com/dugrema/millegrilles.consignation.python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -20,4 +20,4 @@ class Declencheur:\n     def transmettre_declencheur_domaine(self, domaine, dict_message):\n         nom_millegrille = self.configuration.nom_millegrille\n         routing_key = '%s.destinataire.domaine.%s' % (nom_millegrille, domaine)\n-        self.message_dao.transmettre_message(routing_key, dict_message)\n+        self.message_dao.transmettre_message(dict_message, routing_key)\n", "before": "self . message_dao . transmettre_message ( routing_key , dict_message )", "after": "self . message_dao . transmettre_message ( dict_message , routing_key )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:routing_key\", 3, 46, 3, 57], [\"argument_list\", 3, 45, 3, 72], 3], [\"Move\", [\",:,\", 3, 57, 3, 58], [\"argument_list\", 3, 45, 3, 72], 4]]"}
{"project": "salt", "commit_sha": "759a9ee0f47eb52008c9061a07210366e32f7679", "parent_sha": "27d844ce0029554ac2957fa40ad344ce893da3e4", "file_path": "salt/utils/process.py", "project_url": "https://github.com/StepOneInc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -89,7 +89,7 @@ def clean_proc(proc, wait_for_kill=10):\n                         proc.pid\n                     )\n                 )\n-                os.kill(signal.SIGKILL, proc.pid)\n+                os.kill(proc.pid, signal.SIGKILL)\n     except (AssertionError, AttributeError):\n         # Catch AssertionError when the proc is evaluated inside the child\n         # Catch AttributeError when the process dies between proc.is_alive()\n", "before": "os . kill ( signal . SIGKILL , proc . pid )", "after": "os . kill ( proc . pid , signal . SIGKILL )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"attribute\", 3, 25, 3, 39], [\"argument_list\", 3, 24, 3, 50], 2], [\"Move\", [\"attribute\", 3, 41, 3, 49], [\"argument_list\", 3, 24, 3, 50], 1]]"}
{"project": "salt", "commit_sha": "1c4c63428babc7de4542764bffa77f8a0c2c6955", "parent_sha": "9acf13bf39aeec63ad25129ec2b9d974d0fcf6ae", "file_path": "salt/utils/process.py", "project_url": "https://github.com/StepOneInc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -89,7 +89,7 @@ def clean_proc(proc, wait_for_kill=10):\n                         proc.pid\n                     )\n                 )\n-                os.kill(signal.SIGKILL, proc.pid)\n+                os.kill(proc.pid, signal.SIGKILL)\n     except (AssertionError, AttributeError):\n         # Catch AssertionError when the proc is evaluated inside the child\n         # Catch AttributeError when the process dies between proc.is_alive()\n", "before": "os . kill ( signal . SIGKILL , proc . pid )", "after": "os . kill ( proc . pid , signal . SIGKILL )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"attribute\", 3, 25, 3, 39], [\"argument_list\", 3, 24, 3, 50], 2], [\"Move\", [\"attribute\", 3, 41, 3, 49], [\"argument_list\", 3, 24, 3, 50], 1]]"}
{"project": "https-github.com-fchollet-keras", "commit_sha": "46a2fb6fd8e52b02df78f1416cc9fbd4b3156604", "parent_sha": "b6d8e9dd4e52f7d8bb58a3d9b341261a2fab84b0", "file_path": "keras/optimizers.py", "project_url": "https://github.com/amongstar/https-github.com-fchollet-keras", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ class Optimizer(object):\n             grads = [clip_norm(g, self.clipnorm, norm) for g in grads]\n \n         if hasattr(self, 'clipvalue') and self.clipvalue > 0:\n-            grads = [T.clip(g, self.clipvalue, -self.clipvalue) for g in grads]\n+            grads = [T.clip(g, -self.clipvalue, self.clipvalue) for g in grads]\n \n         return grads\n \n", "before": "grads = [ T . clip ( g , self . clipvalue , - self . clipvalue ) for g in grads ]", "after": "grads = [ T . clip ( g , - self . clipvalue , self . clipvalue ) for g in grads ]", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"attribute\", 3, 32, 3, 46], [\"argument_list\", 3, 28, 3, 64], 4], [\"Move\", [\"unary_operator\", 3, 48, 3, 63], [\"argument_list\", 3, 28, 3, 64], 3]]"}
{"project": "Qcodes", "commit_sha": "fb8240b5775dda37fd6820cd1d80746ccb8bf1e0", "parent_sha": "a62a22f17c28d32e9e0c72470f7918ef1b36c0d3", "file_path": "qcodes/instrument_drivers/Keysight/Keysight_E8267D.py", "project_url": "https://github.com/jenshnielsen/Qcodes", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -63,7 +63,7 @@ class Keysight_E8267D(VisaInstrument):\n         # .upper val for Enum or string\n         on_off_validator = vals.Enum('on', 'On', 'ON',\n                                      'off', 'Off', 'OFF')\n-        on_off_mapping = create_on_off_val_mapping(0, 1)\n+        on_off_mapping = create_on_off_val_mapping(1, 0)\n \n         self.add_parameter(name='frequency',\n                            label='Frequency',\n", "before": "on_off_mapping = create_on_off_val_mapping ( 0 , 1 )", "after": "on_off_mapping = create_on_off_val_mapping ( 1 , 0 )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"integer:0\", 3, 52, 3, 53], [\"argument_list\", 3, 51, 3, 57], 3], [\"Move\", [\",:,\", 3, 53, 3, 54], [\"argument_list\", 3, 51, 3, 57], 4]]"}
{"project": "openobject-server", "commit_sha": "1dc02cfce6c27cbed086abded2ffce11b67cb315", "parent_sha": "f7ba8f1d3252fd28f7d5bf77ce4aae10e150d4b6", "file_path": "bin/addons/base/ir/ir_cron.py", "project_url": "https://github.com/gisce/openobject-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -93,7 +93,7 @@ class ir_cron(osv.osv, netsvc.Agent):\n \tdef _callback(self, cr, uid, model, func, args):\n \t\targs = (args or []) and eval(args)\n \t\tm=self.pool.get(model)\n-\t\tif m and hasattr(func, m):\n+\t\tif m and hasattr(m, func):\n \t\t\tf = getattr(m, func)\n \t\t\tf(cr, uid, *args)\n \n", "before": "if m and hasattr ( func , m ) : f = getattr ( m , func ) f ( cr , uid , * args )", "after": "if m and hasattr ( m , func ) : f = getattr ( m , func ) f ( cr , uid , * args )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:func\", 3, 20, 3, 24], [\"argument_list\", 3, 19, 3, 28], 3], [\"Move\", [\",:,\", 3, 24, 3, 25], [\"argument_list\", 3, 19, 3, 28], 4]]"}
{"project": "bro-tools", "commit_sha": "a1030970573da135a34e7200c5828ef1b9467444", "parent_sha": "c681201de662554549dcdaf22c16225678e5c87a", "file_path": "stuffing/affiliate.py", "project_url": "https://github.com/snyderp/bro-tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -386,7 +386,7 @@ class AffiliateHistory(object):\n             # the cart, then automatically start a new checkout\n             # collection to track what happens to this this request\n             if t == CART:\n-                checkouts.append(AffiliateCheckout(r, g, cookie_ttl, self))\n+                checkouts.append(AffiliateCheckout(r, g, self, cookie_ttl))\n                 continue\n \n             # Otherwise, if this is not a request to add something to a cart,\n", "before": "checkouts . append ( AffiliateCheckout ( r , g , cookie_ttl , self ) )", "after": "checkouts . append ( AffiliateCheckout ( r , g , self , cookie_ttl ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:cookie_ttl\", 3, 58, 3, 68], [\"argument_list\", 3, 51, 3, 75], 7], [\"Move\", [\",:,\", 3, 68, 3, 69], [\"argument_list\", 3, 51, 3, 75], 8]]"}
{"project": "tarnow", "commit_sha": "b5c6aa26ffb69d6202272da87110e8f712b037dd", "parent_sha": "ead907c09fa1a138523856e3706fa7c9a7b5883e", "file_path": "tarnow_switch.py", "project_url": "https://github.com/steffenschroeder/tarnow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,7 +14,7 @@ def main():\n         syslog.syslog(syslog.LOG_ERR, \"Wrong number of arguments: expected: 2 , got %d\" % (len(sys.argv) - 1))\n         exit(1)\n     switch_name, status = sys.argv[1:]\n-    toggle(status, switch_name)\n+    toggle(switch_name, status)\n \n \n if __name__ == '__main__':\n", "before": "toggle ( status , switch_name )", "after": "toggle ( switch_name , status )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:status\", 3, 12, 3, 18], [\"argument_list\", 3, 11, 3, 32], 3], [\"Move\", [\",:,\", 3, 18, 3, 19], [\"argument_list\", 3, 11, 3, 32], 4]]"}
{"project": "neutron", "commit_sha": "8d5dd751fa72611046d8dd48011e5b1b63e8511c", "parent_sha": "e65b06f458f179c50f7b4d4f7ba269d7343ef461", "file_path": "neutron/plugins/vmware/plugins/base.py", "project_url": "https://github.com/noironetworks/neutron", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2324,7 +2324,7 @@ class NsxPluginV2(addr_pair_db.AllowedAddressPairsMixin,\n         # NOTE(salv-orlando): Pre-generating Neutron ID for security group.\n         neutron_id = str(uuid.uuid4())\n         nsx_secgroup = secgrouplib.create_security_profile(\n-            self.cluster, neutron_id, tenant_id, s)\n+            self.cluster, tenant_id, neutron_id, s)\n         with context.session.begin(subtransactions=True):\n             s['id'] = neutron_id\n             sec_group = super(NsxPluginV2, self).create_security_group(\n", "before": "nsx_secgroup = secgrouplib . create_security_profile ( self . cluster , neutron_id , tenant_id , s )", "after": "nsx_secgroup = secgrouplib . create_security_profile ( self . cluster , tenant_id , neutron_id , s )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Update\", [\"identifier:neutron_id\", 3, 27, 3, 37], \"tenant_id\"], [\"Update\", [\"identifier:tenant_id\", 3, 39, 3, 48], \"neutron_id\"]]"}
{"project": "gitlab2prov", "commit_sha": "6efc6d5419e5c0bed3455dc996f46c8cdd64b013", "parent_sha": "b0c544c76d726c0ee0c2de447edd39b0fafb4c37", "file_path": "gitlab2prov/models/__init__.py", "project_url": "https://github.com/DLR-SC/gitlab2prov", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -237,7 +237,7 @@ def release_tag_model(graph: ProvDocument, packages: ReleaseTagPackage):\n \n             if package.release_package is not None:\n                 graph.hadMember(tag.id, release.id)\n-            graph.wasGeneratedBy(tag_event.id, tag.id)\n+            graph.wasGeneratedBy(tag.id, tag_event.id)\n             graph.wasAttributedTo(tag.id, t_user.id)\n             graph.wasAssociatedWith(tag_event.id, t_user.id)\n \n", "before": "graph . wasGeneratedBy ( tag_event . id , tag . id )", "after": "graph . wasGeneratedBy ( tag . id , tag_event . id )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"attribute\", 3, 34, 3, 46], [\"argument_list\", 3, 33, 3, 55], 2], [\"Move\", [\"attribute\", 3, 48, 3, 54], [\"argument_list\", 3, 33, 3, 55], 1]]"}
{"project": "pip", "commit_sha": "65d8b62548203178c0f90853181e8708616b34f6", "parent_sha": "6a830765964402cb00469183c02263b5e2bd0e5a", "file_path": "tests/git_submodule_helpers.py", "project_url": "https://github.com/jiahillegass/pip", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -21,7 +21,7 @@ def _change_test_package_submodule(env, submodule_path):\n             '-am', 'submodule change', cwd=submodule_path)\n \n def _pull_in_submodule_changes_to_module(env, module_path):\n-    env.run(*('git submodule foreach git pull -q origin master'.split(' ')), cwd=module_path) # this only exists in git > 1.7.3\n+    env.run(cwd=module_path, *('git submodule foreach git pull -q origin master'.split(' '))) # this only exists in git > 1.7.3\n     env.run('git', 'commit', '-q',\n             '--author', 'Pip <python-virtualenv@googlegroups.com>',\n             '-am', 'submodule change', cwd=module_path)\n", "before": "env . run ( * ( 'git submodule foreach git pull -q origin master' . split ( ' ' ) ) , cwd = module_path )", "after": "env . run ( cwd = module_path , * ( 'git submodule foreach git pull -q origin master' . split ( ' ' ) ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"keyword_argument\", 3, 78, 3, 93], [\"argument_list\", 3, 12, 3, 94], 1], [\"Insert\", [\"argument_list\", 3, 12, 3, 94], [\",:,\", \"T\"], 4], [\"Delete\", [\",:,\", 3, 76, 3, 77]]]"}
{"project": "searx", "commit_sha": "2fab23ab9a9288fb2ca4e9fb094075410b0995d3", "parent_sha": "e1bb0e33f23f7cf089f24b536283bac67cc09528", "file_path": "searx/webapp.py", "project_url": "https://github.com/MarcAbonce/searx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -916,7 +916,7 @@ def page_not_found(e):\n \n \n def run():\n-    logger.debug('starting webserver on %s:%s', settings['server']['port'], settings['server']['bind_address'])\n+    logger.debug('starting webserver on %s:%s', settings['server']['bind_address'], settings['server']['port'])\n     app.run(\n         debug=searx_debug,\n         use_debugger=searx_debug,\n", "before": "logger . debug ( 'starting webserver on %s:%s' , settings [ 'server' ] [ 'port' ] , settings [ 'server' ] [ 'bind_address' ] )", "after": "logger . debug ( 'starting webserver on %s:%s' , settings [ 'server' ] [ 'bind_address' ] , settings [ 'server' ] [ 'port' ] )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"subscript\", 3, 49, 3, 75], [\"argument_list\", 3, 17, 3, 112], 4], [\"Move\", [\"subscript\", 3, 77, 3, 111], [\"argument_list\", 3, 17, 3, 112], 3]]"}
{"project": "pytorch", "commit_sha": "c5b021cc88df6e970d644050a3e2a3744bc4a4eb", "parent_sha": "7e2136c2b5944914540d6c2b5da9735178cb82f6", "file_path": "torch/nn/modules/module.py", "project_url": "https://github.com/ezyang/pytorch", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -650,7 +650,7 @@ class Module(object):\n                     # local shape should match the one in checkpoint\n                     error_msgs.append('size mismatch for {}: copying a param of {} from checkpoint, '\n                                       'where the shape is {} in current model.'\n-                                      .format(key, param.shape, input_param.shape))\n+                                      .format(key, input_param.shape, param.shape))\n                     continue\n \n                 if isinstance(input_param, Parameter):\n", "before": "error_msgs . append ( 'size mismatch for {}: copying a param of {} from checkpoint, ' 'where the shape is {} in current model.' . format ( key , param . shape , input_param . shape ) )", "after": "error_msgs . append ( 'size mismatch for {}: copying a param of {} from checkpoint, ' 'where the shape is {} in current model.' . format ( key , input_param . shape , param . shape ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"attribute\", 3, 52, 3, 63], [\"argument_list\", 3, 46, 3, 83], 4], [\"Move\", [\"attribute\", 3, 65, 3, 82], [\"argument_list\", 3, 46, 3, 83], 3]]"}
{"project": "tensorpack", "commit_sha": "6ba19a977509e911daaea2367cd0aaa62936b37e", "parent_sha": "460addf8739cda837d3ad583bfa8b4ff6a2f72a9", "file_path": "examples/CTC-TIMIT/train-timit.py", "project_url": "https://github.com/KuribohG/tensorpack", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ class Model(ModelDesc):\n                                 W_init=tf.truncated_normal_initializer(stddev=0.01))\n         logits = tf.reshape(logits, (BATCH, -1, NR_CLASS))\n \n-        loss = tf.nn.ctc_loss(logits, label, seqlen, time_major=False)\n+        loss = tf.nn.ctc_loss(label, logits, seqlen, time_major=False)\n \n         self.cost = tf.reduce_mean(loss, name='cost')\n \n", "before": "loss = tf . nn . ctc_loss ( logits , label , seqlen , time_major = False )", "after": "loss = tf . nn . ctc_loss ( label , logits , seqlen , time_major = False )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Update\", [\"identifier:logits\", 3, 31, 3, 37], \"label\"], [\"Update\", [\"identifier:label\", 3, 39, 3, 44], \"logits\"]]"}
{"project": "PyBNF", "commit_sha": "42cd1fa8de125cfee11296269c676c87d46289a7", "parent_sha": "3a9f6c3c7ce121e3500a9e7535bf9d6a675f9a4f", "file_path": "pybnf/pybnf.py", "project_url": "https://github.com/lanl/PyBNF", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -189,7 +189,7 @@ def main():\n                 config.config['simplex_start_point'] = alg.trajectory.best_fit()\n                 simplex = algs.SimplexAlgorithm(config)\n                 simplex.trajectory = alg.trajectory  # Reuse existing trajectory; don't start a new one.\n-                simplex.run(scheduler_node, log_prefix)\n+                simplex.run(log_prefix, scheduler_node)\n         print0('Fitting complete')\n         success = True\n \n", "before": "simplex . run ( scheduler_node , log_prefix )", "after": "simplex . run ( log_prefix , scheduler_node )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:scheduler_node\", 3, 29, 3, 43], [\"argument_list\", 3, 28, 3, 56], 3], [\"Move\", [\",:,\", 3, 43, 3, 44], [\"argument_list\", 3, 28, 3, 56], 4]]"}
{"project": "youtube-dl", "commit_sha": "374560f0181423be530660fd4b2e1a685e6648f8", "parent_sha": "ff99fe529e52b2465f1d973e69df01a6391568d6", "file_path": "test/test_download.py", "project_url": "https://github.com/ozburo/youtube-dl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -225,7 +225,7 @@ def generator(test_case, tname):\n                                 format_bytes(got_fsize)))\n                     if 'md5' in tc:\n                         md5_for_file = _file_md5(tc_filename)\n-                        self.assertEqual(md5_for_file, tc['md5'])\n+                        self.assertEqual(tc['md5'], md5_for_file)\n                 # Finally, check test cases' data again but this time against\n                 # extracted data from info JSON file written during processing\n                 info_json_fn = os.path.splitext(tc_filename)[0] + '.info.json'\n", "before": "self . assertEqual ( md5_for_file , tc [ 'md5' ] )", "after": "self . assertEqual ( tc [ 'md5' ] , md5_for_file )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 41, 3, 66], [\",:,\", \"T\"], 3], [\"Insert\", [\"argument_list\", 3, 41, 3, 66], [\"identifier:md5_for_file\", \"T\"], 4], [\"Delete\", [\"identifier:md5_for_file\", 3, 42, 3, 54]], [\"Delete\", [\",:,\", 3, 54, 3, 55]]]"}
{"project": "libsaas", "commit_sha": "43f90e6c0e0a63b63693d6b07db935629577114c", "parent_sha": "c7eab5d04ba09d66d2c7e9ba53efffbe9048af30", "file_path": "libsaas/executors/urllib2_executor.py", "project_url": "https://github.com/uberVU/libsaas", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -70,7 +70,7 @@ def urllib2_executor(request, parser):\n     body = resp.read()\n     headers = dict(resp.info())\n     logger.debug('response code: %r, body: %r, headers: %r',\n-                 body, resp.code, headers)\n+                 resp.code, body, headers)\n \n     return parser(body, resp.code, headers)\n \n", "before": "logger . debug ( 'response code: %r, body: %r, headers: %r' , body , resp . code , headers )", "after": "logger . debug ( 'response code: %r, body: %r, headers: %r' , resp . code , body , headers )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 17, 3, 43], [\"identifier:body\", \"T\"], 6], [\"Insert\", [\"argument_list\", 2, 17, 3, 43], [\",:,\", \"T\"], 7], [\"Delete\", [\"identifier:body\", 3, 18, 3, 22]], [\"Delete\", [\",:,\", 3, 22, 3, 23]]]"}
{"project": "buildbot", "commit_sha": "71b899d172e099b2f935e61165dd05121173d3d5", "parent_sha": "ae9fd6a63500ab9b5b397e0ab3801e8cbf6133c8", "file_path": "master/buildbot/db/buildrequests.py", "project_url": "https://github.com/longaccess/buildbot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ def with_master_objectid(fn):\n     def wrap(self, *args, **kwargs):\n         d = self.db.master.getObjectId()\n         d.addCallback(lambda master_objectid :\n-                fn(self, *args, _master_objectid=master_objectid, **kwargs))\n+                fn(self, _master_objectid=master_objectid, *args, **kwargs))\n         return d\n     wrap.__name__ = fn.__name__\n     wrap.__doc__ = fn.__doc__\n", "before": "d . addCallback ( lambda master_objectid : fn ( self , * args , _master_objectid = master_objectid , ** kwargs ) )", "after": "d . addCallback ( lambda master_objectid : fn ( self , _master_objectid = master_objectid , * args , ** kwargs ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"list_splat\", 3, 26, 3, 31], [\"argument_list\", 3, 19, 3, 76], 6], [\"Insert\", [\"argument_list\", 3, 19, 3, 76], [\",:,\", \"T\"], 4], [\"Delete\", [\",:,\", 3, 31, 3, 32]]]"}
{"project": "mapproxy", "commit_sha": "180883d00b192121082fc32571d5b1a4b66dacc9", "parent_sha": "81b7fd8f60dbb6e5e17997bfdfea722856bc52ca", "file_path": "mapproxy/test/http.py", "project_url": "https://github.com/camptocamp/mapproxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -190,7 +190,7 @@ def mock_http_handler(requests_responses, unordered=False, query_comparator=None\n                 query_actual = set(query_to_dict(self.query_data).items())\n                 query_expected = set(query_to_dict(req['path']).items())\n                 self.server.assertions.append(\n-                    RequestMissmatch('requests params differ', query_actual - query_expected, query_expected - query_actual)\n+                    RequestMissmatch('requests params differ', query_expected - query_actual, query_actual - query_expected)\n                 )\n                 self.server.shutdown = True\n             if 'req_assert_function' in req:\n", "before": "self . server . assertions . append ( RequestMissmatch ( 'requests params differ' , query_actual - query_expected , query_expected - query_actual ) )", "after": "self . server . assertions . append ( RequestMissmatch ( 'requests params differ' , query_expected - query_actual , query_actual - query_expected ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"binary_operator\", 3, 64, 3, 93], [\"argument_list\", 3, 37, 3, 125], 4], [\"Move\", [\"binary_operator\", 3, 95, 3, 124], [\"argument_list\", 3, 37, 3, 125], 3]]"}
{"project": "meson", "commit_sha": "d61656d43c509832c972a5dfdd9b0efbb0d4f0df", "parent_sha": "b6e8809f25d5b86ccd8cf6c4532778a74e214c18", "file_path": "run_tests.py", "project_url": "https://github.com/rindeal/meson", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -263,7 +263,7 @@ def _run_test(testdir, test_build_dir, install_dir, extra_args, flags, compile_c\n     stdo += o.decode(sys.stdout.encoding)\n     stde += e.decode(sys.stdout.encoding)\n     if pc.returncode != 0:\n-        return TestResult('Compiling source code failed.', stdo, stde, gen_time, mesonlog, build_time)\n+        return TestResult('Compiling source code failed.', stdo, stde, mesonlog, gen_time, build_time)\n     test_start = time.time()\n     # Note that we don't test that running e.g. 'ninja test' actually\n     # works. One hopes that this is a common enough happening that\n", "before": "return TestResult ( 'Compiling source code failed.' , stdo , stde , gen_time , mesonlog , build_time )", "after": "return TestResult ( 'Compiling source code failed.' , stdo , stde , mesonlog , gen_time , build_time )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:gen_time\", 3, 72, 3, 80], [\"argument_list\", 3, 26, 3, 103], 9], [\"Move\", [\",:,\", 3, 80, 3, 81], [\"argument_list\", 3, 26, 3, 103], 10]]"}
{"project": "TXPipe", "commit_sha": "3b6e4a4f7100a2759eb66b487c96c9d1f010e2be", "parent_sha": "c06f83ef079a5956a911d59db1bdfadf3ca01714", "file_path": "txpipe/metacal_gcr_input.py", "project_url": "https://github.com/LSSTDESC/TXPipe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -147,7 +147,7 @@ class TXMetacalGCRInput(PipelineStage):\n         Ixx = data['IxxPSF']\n         Ixy = data['IxyPSF']\n         Iyy = data['IyyPSF']\n-        data['psf_g1'], data['psf_g2'] = moments_to_shear(Ixx, Ixy, Iyy)\n+        data['psf_g1'], data['psf_g2'] = moments_to_shear(Ixx, Iyy, Ixy)\n \n     def setup_output(self, name, group, cat, cols, n):\n         import h5py\n", "before": "data [ 'psf_g1' ] , data [ 'psf_g2' ] = moments_to_shear ( Ixx , Ixy , Iyy )", "after": "data [ 'psf_g1' ] , data [ 'psf_g2' ] = moments_to_shear ( Ixx , Iyy , Ixy )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:Ixy\", 3, 64, 3, 67], [\"argument_list\", 3, 58, 3, 73], 5], [\"Move\", [\",:,\", 3, 67, 3, 68], [\"argument_list\", 3, 58, 3, 73], 6]]"}
{"project": "salt", "commit_sha": "dd8599309b864a92781547799e9b41d83a5104d1", "parent_sha": "b33df7daddd8fd4f015a9b8f7d82068d348919ab", "file_path": "salt/cli/daemons.py", "project_url": "https://github.com/Mattlk13/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -82,7 +82,7 @@ class DaemonsMixin(object):  # pylint: disable=no-init\n         :param action\n         :return:\n         '''\n-        log.info('%s the Salt %s', self.__class__.__name__, action)\n+        log.info('%s the Salt %s', action, self.__class__.__name__)\n \n     def start_log_info(self):\n         '''\n", "before": "log . info ( '%s the Salt %s' , self . __class__ . __name__ , action )", "after": "log . info ( '%s the Salt %s' , action , self . __class__ . __name__ )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 17, 3, 68], [\"identifier:action\", \"T\"], 3], [\"Insert\", [\"argument_list\", 3, 17, 3, 68], [\",:,\", \"T\"], 4], [\"Delete\", [\",:,\", 3, 59, 3, 60]], [\"Delete\", [\"identifier:action\", 3, 61, 3, 67]]]"}
{"project": "tflearn", "commit_sha": "462b1694ea95e09f46695dc30c2587f85d196806", "parent_sha": "f3dcd09d1c3a6452042d2a1c39793c75d9e58c55", "file_path": "tflearn/layers/core.py", "project_url": "https://github.com/Genius38/tflearn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -291,7 +291,7 @@ def reshape(incoming, new_shape, name=\"Reshape\"):\n     with tf.name_scope(name) as scope:\n         inference = incoming\n         if isinstance(inference, list):\n-            inference = tf.concat(inference, 0)\n+            inference = tf.concat(0, inference)\n             inference = tf.cast(inference, tf.float32)\n         inference = tf.reshape(inference, shape=new_shape)\n \n", "before": "inference = tf . concat ( inference , 0 )", "after": "inference = tf . concat ( 0 , inference )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:inference\", 3, 35, 3, 44], [\"argument_list\", 3, 34, 3, 48], 3], [\"Move\", [\",:,\", 3, 44, 3, 45], [\"argument_list\", 3, 34, 3, 48], 4]]"}
{"project": "secutils", "commit_sha": "a00d66caf719467a0667b3130e09ae6760a0e199", "parent_sha": "cd3d4da0b9278e87b0a042023ec35c3ccd81202f", "file_path": "mkhosts/mkhosts.py", "project_url": "https://github.com/foxcpp/secutils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -86,7 +86,7 @@ def extract_domains(source):\n def download_and_extract(sources, log_tag='blacklisted'):\n     domains = set()\n     status_format = '\\rCollected {} {} domains. Processed {}/{} sources.'\n-    print(status_format.format(log_tag, len(domains), 0, len(sources)), end='', file=sys.stderr)\n+    print(status_format.format(len(domains), log_tag, 0, len(sources)), end='', file=sys.stderr)\n     for i, url in enumerate(sources):\n         try:\n             domains.update(extract_domains(get_by_url(url)))\n", "before": "print ( status_format . format ( log_tag , len ( domains ) , 0 , len ( sources ) ) , end = '' , file = sys . stderr )", "after": "print ( status_format . format ( len ( domains ) , log_tag , 0 , len ( sources ) ) , end = '' , file = sys . stderr )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 31, 3, 71], [\"identifier:log_tag\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 31, 3, 71], [\",:,\", \"T\"], 5], [\"Delete\", [\"identifier:log_tag\", 3, 32, 3, 39]], [\"Delete\", [\",:,\", 3, 39, 3, 40]]]"}
{"project": "secutils", "commit_sha": "3bfe54288d3d9da14f0a0b40c9946376f8bc216e", "parent_sha": "72b3c1cd58c2c809b890474b17c2feb85343cf74", "file_path": "mkhosts/mkhosts.py", "project_url": "https://github.com/foxcpp/secutils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -93,7 +93,7 @@ def download_and_extract(sources, log_tag='blacklisted'):\n         except Exception as e:\n             print('\\nFailed to process list', url, file=sys.stderr)\n             print(type(e).__qualname__ + ': ' + str(e), file=sys.stderr)\n-        print(status_format.format(log_tag, len(domains), i + 1, len(sources)), end='', file=sys.stderr)\n+        print(status_format.format(len(domains), log_tag, i + 1, len(sources)), end='', file=sys.stderr)\n     print(file=sys.stderr)\n     return domains\n \n", "before": "print ( status_format . format ( log_tag , len ( domains ) , i + 1 , len ( sources ) ) , end = '' , file = sys . stderr )", "after": "print ( status_format . format ( len ( domains ) , log_tag , i + 1 , len ( sources ) ) , end = '' , file = sys . stderr )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 35, 3, 79], [\"identifier:log_tag\", \"T\"], 4], [\"Insert\", [\"argument_list\", 3, 35, 3, 79], [\",:,\", \"T\"], 5], [\"Delete\", [\"identifier:log_tag\", 3, 36, 3, 43]], [\"Delete\", [\",:,\", 3, 43, 3, 44]]]"}
{"project": "fieldsight-kobocat", "commit_sha": "d37ac402c77b6dc8e264050043d0825dba539995", "parent_sha": "9b083c09f131295b09d0d3633de8c7e2e69f6238", "file_path": "onadata/apps/fieldsight/serializers/SiteSerializer.py", "project_url": "https://github.com/awemulya/fieldsight-kobocat", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -70,7 +70,7 @@ class SiteUpdateSerializer(serializers.ModelSerializer):\n         if lat and long:\n             lat = float(lat)\n             long = float(long)\n-            location = Point(round(lat, 6), round(long, 6), srid=4326)\n+            location = Point(round(long, 6), round(lat, 6), srid=4326)\n             site.location = location\n         if type_id:\n             site.type = SiteType.objects.get(pk=type_id)\n", "before": "location = Point ( round ( lat , 6 ) , round ( long , 6 ) , srid = 4326 )", "after": "location = Point ( round ( long , 6 ) , round ( lat , 6 ) , srid = 4326 )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"call\", 3, 30, 3, 43], [\"argument_list\", 3, 29, 3, 71], 2], [\"Move\", [\"call\", 3, 45, 3, 59], [\"argument_list\", 3, 29, 3, 71], 1]]"}
{"project": "prysm", "commit_sha": "4b8f8a9d60e9b73f27a5dbc66c11e0772427a7e5", "parent_sha": "d701abb069f6d9842cb02a379a68d972122ba6a5", "file_path": "prysm/interferogram.py", "project_url": "https://github.com/brandondube/prysm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -119,7 +119,7 @@ def make_window(signal, sample_spacing, which=None, alpha=4):\n         else:\n             # if not circular, square data; use Hanning window\n             y, x = (e.hanning(N) for N in s)\n-            which = e.outer(x, y)\n+            which = e.outer(y, x)\n     else:\n         if type(which) is str:\n             # known window type\n", "before": "which = e . outer ( x , y )", "after": "which = e . outer ( y , x )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:x\", 3, 29, 3, 30], [\"argument_list\", 3, 28, 3, 34], 3], [\"Move\", [\",:,\", 3, 30, 3, 31], [\"argument_list\", 3, 28, 3, 34], 4]]"}
{"project": "NodeGraphQt", "commit_sha": "ccd8f1f30c648710005e6b1eaaf606aef88be26a", "parent_sha": "4ce1413f6f57f3223ded6999845724c190b610e9", "file_path": "NodeGraphQt/base/menu_setup.py", "project_url": "https://github.com/jchanvfx/NodeGraphQt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -117,7 +117,7 @@ def save_session_as(graph):\n \n def clear_session(graph):\n     viewer = graph.viewer()\n-    if viewer.question_dialog('Clear Session', 'Clear Current Session?'):\n+    if viewer.question_dialog('Clear Current Session?', 'Clear Session'):\n         graph.clear_session()\n \n \n", "before": "if viewer . question_dialog ( 'Clear Session' , 'Clear Current Session?' ) : graph . clear_session ( )", "after": "if viewer . question_dialog ( 'Clear Current Session?' , 'Clear Session' ) : graph . clear_session ( )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"string:'Clear Session'\", 3, 31, 3, 46], [\"argument_list\", 3, 30, 3, 73], 3], [\"Move\", [\",:,\", 3, 46, 3, 47], [\"argument_list\", 3, 30, 3, 73], 4]]"}
{"project": "gchatautorespond", "commit_sha": "86b55f0e60de216f37d8027cdba48596f415406c", "parent_sha": "7d84a0fcb60e81f89bcbd9ad3decfb01b195302c", "file_path": "gchatautorespond/lib/__init__.py", "project_url": "https://github.com/simon-weber/gchatautorespond", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -26,7 +26,7 @@ def report_ga_event_async(client_id, **event_kwargs):\n \n     if settings.SEND_GA_EVENTS:\n         logger.info(\"queueing event %s: %r\", client_id, event_kwargs)\n-        thread_pool.submit(settings.GA_CODE, _report_event, client_id, **event_kwargs)\n+        thread_pool.submit(_report_event, settings.GA_CODE, client_id, **event_kwargs)\n \n \n def _report_event(ga_code, client_id, **event_kwargs):\n", "before": "thread_pool . submit ( settings . GA_CODE , _report_event , client_id , ** event_kwargs )", "after": "thread_pool . submit ( _report_event , settings . GA_CODE , client_id , ** event_kwargs )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 27, 3, 87], [\"identifier:_report_event\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 27, 3, 87], [\",:,\", \"T\"], 2], [\"Delete\", [\"identifier:_report_event\", 3, 46, 3, 59]], [\"Delete\", [\",:,\", 3, 59, 3, 60]]]"}
{"project": "data-act-broker-backend", "commit_sha": "17087ef9e362f18ac352c9ca6eb7fbec694f4b2e", "parent_sha": "71560a2785db808e0ace64e68b1398b881acaeaf", "file_path": "tests/integration/fileTypeTests.py", "project_url": "https://github.com/fedspendingtransparency/data-act-broker-backend", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -91,7 +91,7 @@ class FileTypeTests(BaseTestValidator):\n         \"\"\"Test valid job.\"\"\"\n         jobId = self.jobIdDict[\"valid\"]\n         self.passed = self.run_test(\n-            jobId, 200, \"finished\", 63, 10, \"complete\", 0, False)\n+            jobId, 200, \"finished\", 63, 0, \"complete\", 10, False)\n \n     def test_program_valid(self):\n         \"\"\"Test valid job.\"\"\"\n", "before": "self . passed = self . run_test ( jobId , 200 , \"finished\" , 63 , 10 , \"complete\" , 0 , False )", "after": "self . passed = self . run_test ( jobId , 200 , \"finished\" , 63 , 0 , \"complete\" , 10 , False )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"integer:10\", 3, 41, 3, 43], [\"argument_list\", 2, 36, 3, 66], 12], [\"Move\", [\"integer:0\", 3, 57, 3, 58], [\"argument_list\", 2, 36, 3, 66], 9]]"}
{"project": "docutils", "commit_sha": "cd63bb588d3d78db411b6f4705a85fd0b2d69244", "parent_sha": "17542fcf0178eb0c6b8b9adc286a24b941fc65d0", "file_path": "docutils/writers/html4css1.py", "project_url": "https://github.com/ericholscher/docutils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -838,7 +838,7 @@ class HTMLTranslator(nodes.NodeVisitor):\n                     i += 1\n                 backref_text = '%s; ' % ', '.join(backlinks)\n         if attr:\n-            self.body.append(self.starttag({}, 'a', attr, ''))\n+            self.body.append(self.starttag({}, 'a', '', attr))\n             a_end = '</a>'\n         self.body.append('%s%s (%slevel %s system message)</p>\\n'\n                          % (node['type'], a_end, backref_text,\n", "before": "self . body . append ( self . starttag ( { } , 'a' , attr , '' ) )", "after": "self . body . append ( self . starttag ( { } , 'a' , '' , attr ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 43, 3, 62], [\"string:''\", \"T\"], 5], [\"Insert\", [\"argument_list\", 3, 43, 3, 62], [\"identifier:attr\", \"T\"], 8], [\"Delete\", [\"identifier:attr\", 3, 53, 3, 57]], [\"Delete\", [\"string:''\", 3, 59, 3, 61]]]"}
{"project": "Nuke", "commit_sha": "96d02de6589f1d1bc48fe241454b8025ff5b9b6c", "parent_sha": "c8bc54526aa6e387f6a93847d135baf2c676cc8f", "file_path": "lib/init.py", "project_url": "https://github.com/WuLiFang/Nuke", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,7 +25,7 @@ def setup_prefix_filter():\n     cgtwq.helper.wlf.CGTWQHelper.prefix_filters.append(\n         lambda x: x.replace('QNPV', 'QNYH'))\n     cgtwq.helper.wlf.CGTWQHelper.prefix_filters.append(\n-        lambda x: x.replace('YLDE', 'YLDL'))\n+        lambda x: x.replace('YLDL', 'YLDE'))\n \n \n setup_site()\n", "before": "cgtwq . helper . wlf . CGTWQHelper . prefix_filters . append ( lambda x : x . replace ( 'YLDE' , 'YLDL' ) )", "after": "cgtwq . helper . wlf . CGTWQHelper . prefix_filters . append ( lambda x : x . replace ( 'YLDL' , 'YLDE' ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"string:'YLDE'\", 3, 29, 3, 35], [\"argument_list\", 3, 28, 3, 44], 3], [\"Move\", [\",:,\", 3, 35, 3, 36], [\"argument_list\", 3, 28, 3, 44], 4]]"}
{"project": "astropy", "commit_sha": "ee6e1c023e8b97ae41769bdbf5810035579623d0", "parent_sha": "1cb6c81e874a785e2d7a3075a75a372188b0d844", "file_path": "astropy/cosmology/funcs.py", "project_url": "https://github.com/mirca/astropy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -85,7 +85,7 @@ def z_at_value(func, fval, zmin=1e-8, zmax=1000, ztol=1e-8, maxfun=500):\n \n     Finally interpolate to find the redshift at each distance modulus:\n \n-    >>> zvals = np.interp(Dvals.value, zgrid, Dgrid.value)\n+    >>> zvals = np.interp(Dvals.value, Dgrid.value, zgrid)\n \n     Examples\n     --------\n", "before": "modulus : >> > zvals = np . interp ( Dvals . value , zgrid , Dgrid . value )", "after": "modulus : >> > zvals = np . interp ( Dvals . value , Dgrid . value , zgrid )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 26, 3, 59], [\",:,\", \"T\"], 5], [\"Insert\", [\"argument_list\", 3, 26, 3, 59], [\"identifier:zgrid\", \"T\"], 6], [\"Delete\", [\"identifier:zgrid\", 3, 40, 3, 45]], [\"Delete\", [\",:,\", 3, 45, 3, 46]]]"}
{"project": "AIS-home-assistant", "commit_sha": "917db18b29e37685517bde78b827c41729f3512d", "parent_sha": "152fd9cb28d9a35bee4c43e152ac9b5ac41f3381", "file_path": "homeassistant/components/device_tracker/netgear.py", "project_url": "https://github.com/sviete/AIS-home-assistant", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ def get_scanner(hass, config):\n         _LOGGER.warning('Found username or password but no host')\n         return None\n \n-    scanner = NetgearDeviceScanner(host, password, username)\n+    scanner = NetgearDeviceScanner(host, username, password)\n \n     return scanner if scanner.success_init else None\n \n", "before": "scanner = NetgearDeviceScanner ( host , password , username )", "after": "scanner = NetgearDeviceScanner ( host , username , password )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:password\", 3, 42, 3, 50], [\"argument_list\", 3, 35, 3, 61], 5], [\"Move\", [\",:,\", 3, 50, 3, 51], [\"argument_list\", 3, 35, 3, 61], 6]]"}
{"project": "shadowsocks", "commit_sha": "f19d0ea6fdc4dba41fb3a0cc2454e1888efa984b", "parent_sha": "a2bc6e19457f51a421b7d2866be5903e0d71fd2f", "file_path": "shadowsocks/daemon.py", "project_url": "https://github.com/evenX86/shadowsocks", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -117,7 +117,7 @@ def daemon_start(pid_file, log_file):\n         sys.exit(1)\n \n     os.setsid()\n-    signal.signal(signal.SIG_IGN, signal.SIGHUP)\n+    signal.signal(signal.SIGHUP, signal.SIG_IGN)\n \n     print('started')\n     os.kill(ppid, signal.SIGTERM)\n", "before": "signal . signal ( signal . SIG_IGN , signal . SIGHUP )", "after": "signal . signal ( signal . SIGHUP , signal . SIG_IGN )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"attribute\", 3, 19, 3, 33], [\"argument_list\", 3, 18, 3, 49], 2], [\"Move\", [\"attribute\", 3, 35, 3, 48], [\"argument_list\", 3, 18, 3, 49], 1]]"}
{"project": "django", "commit_sha": "3074c5b19e2da5f7a5359c3cf3c5308eb194cdf9", "parent_sha": "c21b832c1260c6ad4bd8527338a65f6d8930feaf", "file_path": "tests/settings_tests/tests.py", "project_url": "https://github.com/leon-song2000/django", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -112,7 +112,7 @@ class ClassDecoratedTestCase(ClassDecoratedTestCaseSuper):\n \n     @classmethod\n     def setUpClass(cls):\n-        super(cls, ClassDecoratedTestCase).setUpClass()\n+        super(ClassDecoratedTestCase, cls).setUpClass()\n         cls.foo = getattr(settings, 'TEST', 'BUG')\n \n     def test_override(self):\n", "before": "super ( cls , ClassDecoratedTestCase ) . setUpClass ( )", "after": "super ( ClassDecoratedTestCase , cls ) . setUpClass ( )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:cls\", 3, 15, 3, 18], [\"argument_list\", 3, 14, 3, 43], 3], [\"Move\", [\",:,\", 3, 18, 3, 19], [\"argument_list\", 3, 14, 3, 43], 4]]"}
{"project": "rpress", "commit_sha": "ec7463508e607d6866838cfcac07f6aa8f57a7be", "parent_sha": "8db90a5f325eab5229d44b3179ee2e53e52c9319", "file_path": "rpress/views/profiles_admin.py", "project_url": "https://github.com/rexzhang/rpress", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -45,7 +45,7 @@ def change_password():\n     form = PasswordForm()\n \n     if form.validate_on_submit():\n-        if check_password_hash(form.data['password_old'], user.password):\n+        if check_password_hash(user.password, form.data['password_old']):\n             user.password = form.data['password_new']\n \n             db.session.add(user)\n", "before": "if check_password_hash ( form . data [ 'password_old' ] , user . password ) : user . password = form . data [ 'password_new' ] db . session . add ( user )", "after": "if check_password_hash ( user . password , form . data [ 'password_old' ] ) : user . password = form . data [ 'password_new' ] db . session . add ( user )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"attribute\", 3, 59, 3, 72], [\"argument_list\", 3, 31, 3, 73], 1], [\"Insert\", [\"argument_list\", 3, 31, 3, 73], [\",:,\", \"T\"], 4], [\"Delete\", [\",:,\", 3, 57, 3, 58]]]"}
{"project": "django", "commit_sha": "5fadc862007a967dcb66774a78fee7c4808c6a69", "parent_sha": "29c4a578af58f6da7c77830a0ff99260f2338d36", "file_path": "django/utils/log.py", "project_url": "https://github.com/leon-song2000/django", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -87,7 +87,7 @@ class AdminEmailHandler(logging.Handler):\n             stack_trace = 'No stack trace available'\n \n         message = \"%s\\n\\n%s\" % (stack_trace, request_repr)\n-        reporter = ExceptionReporter(request, *exc_info, is_email=True)\n+        reporter = ExceptionReporter(request, is_email=True, *exc_info)\n         html_message = reporter.get_traceback_html()\n         mail.mail_admins(subject, message, fail_silently=True,\n                          html_message=html_message)\n", "before": "reporter = ExceptionReporter ( request , * exc_info , is_email = True )", "after": "reporter = ExceptionReporter ( request , is_email = True , * exc_info )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"keyword_argument\", 3, 58, 3, 71], [\"argument_list\", 3, 37, 3, 72], 3], [\"Insert\", [\"argument_list\", 3, 37, 3, 72], [\",:,\", \"T\"], 6], [\"Delete\", [\",:,\", 3, 56, 3, 57]]]"}
{"project": "PyFR", "commit_sha": "11ff1bc0769e67123b4c36d1f43d25153e35b562", "parent_sha": "647e04a463c4782656b6209e33ae8252c077537b", "file_path": "pyfr/elements.py", "project_url": "https://github.com/PyFR/PyFR", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -256,7 +256,7 @@ class BaseAdvectionElements(object):\n         jac = jac.reshape(npts, ndims, neles, ndims)\n \n         # Transpose to get (npts, neles, ndims, ndims) \u2245 (npts, neles, J)\n-        jac = jac.transpose(0, 2, 1, 3)\n+        jac = jac.transpose(0, 2, 3, 1)\n \n         return jac.reshape(-1, ndims, ndims)\n \n", "before": "jac = jac . transpose ( 0 , 2 , 1 , 3 )", "after": "jac = jac . transpose ( 0 , 2 , 3 , 1 )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"integer:1\", 3, 35, 3, 36], [\"argument_list\", 3, 28, 3, 40], 7], [\"Move\", [\",:,\", 3, 36, 3, 37], [\"argument_list\", 3, 28, 3, 40], 8]]"}
{"project": "argonne", "commit_sha": "ad0b8d612e9fff4938d27dbe1b0a9b7bd3247f7a", "parent_sha": "c7ada18f9b2acb79b8630f0ca2362ac1c96514b6", "file_path": "grain-boundary/structure.py", "project_url": "https://github.com/josh-mutian/argonne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -297,7 +297,7 @@ class Structure(object):\n                 # If we have searched the position, just skip.\n                 continue\n             searched_pos.add(tuple(current_pos.tolist()))\n-            shift_vector = np.dot(current_pos, self.coordinates)\n+            shift_vector = np.dot(self.coordinates, current_pos)\n             shifted = copy.deepcopy(self.cartesian)\n             shifted['position'] += shift_vector\n             # Convert the shifted vectors into direct with respect to the \n", "before": "shift_vector = np . dot ( current_pos , self . coordinates )", "after": "shift_vector = np . dot ( self . coordinates , current_pos )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 34, 3, 65], [\",:,\", \"T\"], 3], [\"Insert\", [\"argument_list\", 3, 34, 3, 65], [\"identifier:current_pos\", \"T\"], 4], [\"Delete\", [\"identifier:current_pos\", 3, 35, 3, 46]], [\"Delete\", [\",:,\", 3, 46, 3, 47]]]"}
{"project": "GitPython", "commit_sha": "82ae723c8c283970f75c0f4ce097ad4c9734b233", "parent_sha": "15b6bbac7bce15f6f7d72618f51877455f3e0ee5", "file_path": "git/remote.py", "project_url": "https://github.com/scls19fr/GitPython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -468,7 +468,7 @@ class Remote(LazyMixin, Iterable):\n         scmd = 'set-url'\n         kwargs['insert_kwargs_after'] = scmd\n         if old_url:\n-            self.repo.git.remote(scmd, self.name, old_url, new_url, **kwargs)\n+            self.repo.git.remote(scmd, self.name, new_url, old_url, **kwargs)\n         else:\n             self.repo.git.remote(scmd, self.name, new_url, **kwargs)\n         return self\n", "before": "self . repo . git . remote ( scmd , self . name , old_url , new_url , ** kwargs )", "after": "self . repo . git . remote ( scmd , self . name , new_url , old_url , ** kwargs )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Update\", [\"identifier:old_url\", 3, 51, 3, 58], \"new_url\"], [\"Update\", [\"identifier:new_url\", 3, 60, 3, 67], \"old_url\"]]"}
{"project": "GitPython", "commit_sha": "ddffe26850e8175eb605f975be597afc3fca8a03", "parent_sha": "3d6e1731b6324eba5abc029b26586f966db9fa4f", "file_path": "git/test/test_remote.py", "project_url": "https://github.com/scls19fr/GitPython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -613,7 +613,7 @@ class TestRemote(TestBase):\n         remote.set_url(test2, delete=True)\n         self.assertEqual(list(remote.urls), [test1, test3])\n         # Testing changing an URL\n-        remote.set_url(test3, test2)\n+        remote.set_url(test2, test3)\n         self.assertEqual(list(remote.urls), [test1, test2])\n \n         # will raise: fatal: --add --delete doesn't make sense\n", "before": "remote . set_url ( test3 , test2 )", "after": "remote . set_url ( test2 , test3 )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:test3\", 3, 24, 3, 29], [\"argument_list\", 3, 23, 3, 37], 3], [\"Move\", [\",:,\", 3, 29, 3, 30], [\"argument_list\", 3, 23, 3, 37], 4]]"}
{"project": "gtabview", "commit_sha": "6f0b826d9b5143a0011b4e51b07a2e409de9b078", "parent_sha": "1a87133525662e84f2714597d0d42eb93caca639", "file_path": "gtabview/viewer.py", "project_url": "https://github.com/scls19fr/gtabview", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -241,7 +241,7 @@ class Viewer(QtGui.QMainWindow):\n \n         model = table.model()\n         shape = model.shape()\n-        self.setWindowTitle(\"{} rows, {} columns\".format(shape[1], shape[0]))\n+        self.setWindowTitle(\"{} rows, {} columns\".format(shape[0], shape[1]))\n         if shape[0] * shape[1] < 1e5:\n             # resizing materializes the contents and might actually take longer\n             # than loading all the data itself, so do it for small tables only\n", "before": "self . setWindowTitle ( \"{} rows, {} columns\" . format ( shape [ 1 ] , shape [ 0 ] ) )", "after": "self . setWindowTitle ( \"{} rows, {} columns\" . format ( shape [ 0 ] , shape [ 1 ] ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"subscript\", 3, 58, 3, 66], [\"argument_list\", 3, 57, 3, 77], 2], [\"Move\", [\"subscript\", 3, 68, 3, 76], [\"argument_list\", 3, 57, 3, 77], 1]]"}
{"project": "statsmodels", "commit_sha": "e2e40c4c53e8e87c98423da5c648c25d1ed24799", "parent_sha": "1b12824f53b1f24411d4bf471255db41b464d5b9", "file_path": "statsmodels/tsa/filters/bk_filter.py", "project_url": "https://github.com/galenwilkerson/statsmodels", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -69,5 +69,5 @@ def bkfilter(X, low=6, high=32, K=12):\n     bweights -= bweights.mean() # make sure weights sum to zero\n     if X.ndim == 2:\n         bweights = bweights[:,None]\n-    return fftconvolve(bweights, X, mode='valid') # get a centered moving avg/\n+    return fftconvolve(X, bweights, mode='valid') # get a centered moving avg/\n                                                   # convolution\n", "before": "return fftconvolve ( bweights , X , mode = 'valid' )", "after": "return fftconvolve ( X , bweights , mode = 'valid' )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Update\", [\"identifier:bweights\", 3, 24, 3, 32], \"X\"], [\"Update\", [\"identifier:X\", 3, 34, 3, 35], \"bweights\"]]"}
{"project": "BuildingMachineLearningSystemsWithPython", "commit_sha": "c71430360ececfe2bbe7dbc79add793dab85e5d9", "parent_sha": "db795e08dc720fce5a1f327f1ce3de154cf2303c", "file_path": "ch02/figure4_5_no_sklearn.py", "project_url": "https://github.com/akshayjh/BuildingMachineLearningSystemsWithPython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -45,7 +45,7 @@ def plot_decision(features, labels):\n \n     model = fit_model(1, features[:, (0, 2)], np.array(labels))\n     C = predict(\n-        np.vstack([X.ravel(), Y.ravel()]).T, model).reshape(X.shape)\n+        model, np.vstack([X.ravel(), Y.ravel()]).T).reshape(X.shape)\n     if COLOUR_FIGURE:\n         cmap = ListedColormap([(1., .6, .6), (.6, 1., .6), (.6, .6, 1.)])\n     else:\n", "before": "C = predict ( np . vstack ( [ X . ravel ( ) , Y . ravel ( ) ] ) . T , model ) . reshape ( X . shape )", "after": "C = predict ( model , np . vstack ( [ X . ravel ( ) , Y . ravel ( ) ] ) . T ) . reshape ( X . shape )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 16, 3, 52], [\"identifier:model\", \"T\"], 1], [\"Insert\", [\"argument_list\", 2, 16, 3, 52], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 44, 3, 45]], [\"Delete\", [\"identifier:model\", 3, 46, 3, 51]]]"}
{"project": "rasa_nlu", "commit_sha": "9a06d81201ca84812540bc4128111c55e22ffca7", "parent_sha": "571c59bc9fccca87aa1c29b56ddf874fce9b111a", "file_path": "rasa_nlu/config.py", "project_url": "https://github.com/mukesh-mehta/rasa_nlu", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -156,7 +156,7 @@ class RasaNLUModelConfig(object):\n         return json_to_string(self.__dict__, indent=4)\n \n     def for_component(self, name, defaults=None):\n-        return component_config_from_pipeline(self.pipeline, name, defaults)\n+        return component_config_from_pipeline(name, self.pipeline, defaults)\n \n     @property\n     def component_names(self):\n", "before": "return component_config_from_pipeline ( self . pipeline , name , defaults )", "after": "return component_config_from_pipeline ( name , self . pipeline , defaults )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 46, 3, 77], [\"identifier:name\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 46, 3, 77], [\",:,\", \"T\"], 2], [\"Delete\", [\"identifier:name\", 3, 62, 3, 66]], [\"Delete\", [\",:,\", 3, 66, 3, 67]]]"}
{"project": "MuddisSpielplanPlaner", "commit_sha": "689bb8d5899c8019b484cc13b1578dece37a5bf8", "parent_sha": "e3b258dcf5f639af03d5d9a6d48f87075083a9f0", "file_path": "DataAPITest.py", "project_url": "https://github.com/NeuralNetwork/MuddisSpielplanPlaner", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -49,7 +49,7 @@ class TestConnectionHandling(unittest.TestCase):\n     def test_getListOfGames(self):\n         print(\"testing gettingListOfPlayedGames\")\n         gameStates = [GameState.COMPLETED, GameState.RUNNING]\n-        self.instance.getListOfGames(divisionId_Swissdraw,8,gameStates)\n+        self.instance.getListOfGames(divisionId_Swissdraw, gameStates, 8)\n         print(\"#####################################################################\")\n \n     def test_getGames(self):\n", "before": "self . instance . getListOfGames ( divisionId_Swissdraw , 8 , gameStates )", "after": "self . instance . getListOfGames ( divisionId_Swissdraw , gameStates , 8 )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"integer:8\", 3, 59, 3, 60], [\"argument_list\", 3, 37, 3, 72], 5], [\"Move\", [\",:,\", 3, 60, 3, 61], [\"argument_list\", 3, 37, 3, 72], 6]]"}
{"project": "allennlp", "commit_sha": "eb24cad9baed4dee31c5b2524544fa71eaeef0be", "parent_sha": "8957c86012e774714f8e73c215f1a2f54a10a3d8", "file_path": "scripts/write_srl_predictions_to_conll_format.py", "project_url": "https://github.com/mhrmm/allennlp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -57,7 +57,7 @@ def main(serialization_directory, device):\n         sentence = fields[\"tokens\"].tokens\n \n         write_to_conll_eval_file(prediction_file, gold_file,\n-                                 verb_index, sentence, gold_tags, predicted_tags)\n+                                 verb_index, sentence, predicted_tags, gold_tags)\n     prediction_file.close()\n     gold_file.close()\n \n", "before": "write_to_conll_eval_file ( prediction_file , gold_file , verb_index , sentence , gold_tags , predicted_tags )", "after": "write_to_conll_eval_file ( prediction_file , gold_file , verb_index , sentence , predicted_tags , gold_tags )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\",:,\", 2, 49, 2, 50], [\"argument_list\", 2, 33, 3, 82], 7], [\"Move\", [\"identifier:gold_tags\", 3, 56, 3, 65], [\"argument_list\", 2, 33, 3, 82], 10], [\"Move\", [\",:,\", 3, 65, 3, 66], [\"argument_list\", 2, 33, 3, 82], 11], [\"Insert\", [\"argument_list\", 2, 33, 3, 82], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 54, 3, 55]]]"}
{"project": "firedrake", "commit_sha": "ed4630d2024e013f8e7aaa779f285a76269a9a67", "parent_sha": "3d3fee4c5cb00ee665de7bdb12e898e8c726fd7d", "file_path": "tests/regression/test_nested_fieldsplit_solves.py", "project_url": "https://github.com/firedrakeproject/firedrake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -148,7 +148,7 @@ def test_nested_fieldsplit_solve_parallel(W, A, b, expect):\n \n \n def test_matrix_types(W):\n-    a = inner(TestFunction(W), TrialFunction(W))*dx\n+    a = inner(TrialFunction(W), TestFunction(W))*dx\n \n     with pytest.raises(ValueError):\n         assemble(a, mat_type=\"baij\")\n", "before": "a = inner ( TestFunction ( W ) , TrialFunction ( W ) ) * dx", "after": "a = inner ( TrialFunction ( W ) , TestFunction ( W ) ) * dx", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"call\", 3, 15, 3, 30], [\"argument_list\", 3, 14, 3, 49], 2], [\"Move\", [\"call\", 3, 32, 3, 48], [\"argument_list\", 3, 14, 3, 49], 1]]"}
{"project": "tensorflow", "commit_sha": "d1d5fc27ad8d84f1468ce459ba8fab208b174c6f", "parent_sha": "ec3566d06ef7133b3b045cf01667abf07f47a48e", "file_path": "tensorflow/python/keras/_impl/keras/engine/training_eager.py", "project_url": "https://github.com/b0noI/tensorflow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -96,7 +96,7 @@ def _eager_metrics_fn(model, outputs, targets):\n           model.metrics_names.append(metric_name)\n \n       with backend.name_scope(metric_name):\n-        metric_result = metric_fn(outputs[i], targets[i])\n+        metric_result = metric_fn(targets[i], outputs[i])\n         metric_names.append(metric_name)\n         metric_results.append(backend.mean(metric_result))\n \n", "before": "metric_result = metric_fn ( outputs [ i ] , targets [ i ] )", "after": "metric_result = metric_fn ( targets [ i ] , outputs [ i ] )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"subscript\", 3, 35, 3, 45], [\"argument_list\", 3, 34, 3, 58], 2], [\"Move\", [\"subscript\", 3, 47, 3, 57], [\"argument_list\", 3, 34, 3, 58], 1]]"}
{"project": "tensorflow", "commit_sha": "10ea32657868f0ef60cb583d64abaea389a67a68", "parent_sha": "adf045607cc4126366ebb84ee2109f88c6ab25fc", "file_path": "tensorflow/python/keras/_impl/keras/engine/training_eager.py", "project_url": "https://github.com/b0noI/tensorflow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -96,7 +96,7 @@ def _eager_metrics_fn(model, outputs, targets):\n           model.metrics_names.append(metric_name)\n \n       with backend.name_scope(metric_name):\n-        metric_result = metric_fn(outputs[i], targets[i])\n+        metric_result = metric_fn(targets[i], outputs[i])\n         metric_names.append(metric_name)\n         metric_results.append(backend.mean(metric_result))\n \n", "before": "metric_result = metric_fn ( outputs [ i ] , targets [ i ] )", "after": "metric_result = metric_fn ( targets [ i ] , outputs [ i ] )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"subscript\", 3, 35, 3, 45], [\"argument_list\", 3, 34, 3, 58], 2], [\"Move\", [\"subscript\", 3, 47, 3, 57], [\"argument_list\", 3, 34, 3, 58], 1]]"}
{"project": "superset", "commit_sha": "efaef8fe0924ff39e77edbe8fe5e2ed337adccf3", "parent_sha": "8757a24d89e44c13b44b8ae84be9ae12a50b8d48", "file_path": "superset/models/core.py", "project_url": "https://github.com/tc-dc/superset", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -628,7 +628,7 @@ class Database(Model, AuditMixinNullable):\n                 self, 'table', force=force)\n             return tables_dict.get(\"\", [])\n         return sorted(\n-            self.db_engine_spec.get_table_names(self.inspector, schema))\n+            self.db_engine_spec.get_table_names(schema, self.inspector))\n \n     def all_view_names(self, schema=None, force=False):\n         if not schema:\n", "before": "return sorted ( self . db_engine_spec . get_table_names ( self . inspector , schema ) )", "after": "return sorted ( self . db_engine_spec . get_table_names ( schema , self . inspector ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 48, 3, 72], [\"identifier:schema\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 48, 3, 72], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 63, 3, 64]], [\"Delete\", [\"identifier:schema\", 3, 65, 3, 71]]]"}
{"project": "matplotlib", "commit_sha": "02fa43014ca1fe9a1784c4b5922f65735b263136", "parent_sha": "f6f1f1316f81725c855534e6c33ef64ad67fe562", "file_path": "setupext.py", "project_url": "https://github.com/phoenixlqh/matplotlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1064,7 +1064,7 @@ class FreeType(SetupPackage):\n                     try:\n                         # this will fail on LPy, oh well\n                         os.makedirs(tarball_cache_dir, exist_ok=True)\n-                        shutil.copy(tarball_cache_path, tarball_path)\n+                        shutil.copy(tarball_path, tarball_cache_path)\n                         print('Cached tarball at: {}'\n                               .format(tarball_cache_path))\n                     except:\n", "before": "shutil . copy ( tarball_cache_path , tarball_path )", "after": "shutil . copy ( tarball_path , tarball_cache_path )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:tarball_cache_path\", 3, 37, 3, 55], [\"argument_list\", 3, 36, 3, 70], 3], [\"Move\", [\",:,\", 3, 55, 3, 56], [\"argument_list\", 3, 36, 3, 70], 4]]"}
{"project": "CommunityCellularManager", "commit_sha": "4a9e3d64543daadcbd8d8b34db8a1fd8fe63b82c", "parent_sha": "c937e7e5866d7356af9375dd88fbb3998d733f07", "file_path": "client/core/checkin.py", "project_url": "https://github.com/aricent-ccm/CommunityCellularManager", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -84,7 +84,7 @@ class CheckinHandler(object):\n             elif section == \"openbts\":\n                 bts.process_bts_settings(config_dict[section])\n             elif section == \"prices\":\n-                process_prices(self.conf, config_dict['prices'])\n+                process_prices(config_dict['prices'], self.conf)\n             elif section == \"autoupgrade\":\n                 self.process_autoupgrade(config_dict['autoupgrade'])\n \n", "before": "elif section == \"prices\" : process_prices ( self . conf , config_dict [ 'prices' ] )", "after": "elif section == \"prices\" : process_prices ( config_dict [ 'prices' ] , self . conf )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"subscript\", 3, 43, 3, 64], [\"argument_list\", 3, 31, 3, 65], 1], [\"Insert\", [\"argument_list\", 3, 31, 3, 65], [\",:,\", \"T\"], 4], [\"Delete\", [\",:,\", 3, 41, 3, 42]]]"}
{"project": "re-lab", "commit_sha": "44ded80d998063294450b4326d0533e8d712c35e", "parent_sha": "70e351b45d4ddb2c6e9c5ecff4b0e2ef8d57d9da", "file_path": "oletoy/wls.py", "project_url": "https://github.com/renyxa/re-lab", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -387,7 +387,7 @@ def add_formula_cell(hd, size, data, off):\n \t\t(row, off) = rdata(data, off, '<H')\n \t\tadd_iter(hd, 'Row', format_row(row & 0x3fff), off - 2, 2, '<H')\n \t\trel = (row >> 14) & 0x3\n-\t\tadd_iter(hd, 'Relative', key2txt(rel_map, rel), off - 1, 1, '<B')\n+\t\tadd_iter(hd, 'Relative', key2txt(rel, rel_map), off - 1, 1, '<B')\n \t\t(col, off) = rdata(data, off, '<B')\n \t\tadd_iter(hd, 'Column', format_column(col), off - 1, 1, '<B')\n \t\treturn off\n", "before": "add_iter ( hd , 'Relative' , key2txt ( rel_map , rel ) , off - 1 , 1 , '<B' )", "after": "add_iter ( hd , 'Relative' , key2txt ( rel , rel_map ) , off - 1 , 1 , '<B' )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:rel_map\", 3, 36, 3, 43], [\"argument_list\", 3, 35, 3, 49], 3], [\"Move\", [\",:,\", 3, 43, 3, 44], [\"argument_list\", 3, 35, 3, 49], 4]]"}
{"project": "metadataproxy", "commit_sha": "439f0d94bea193b9b764fa0b5a93dcc09b894863", "parent_sha": "ce8f49f4560d23375925aa989f3f8142655a4fd2", "file_path": "metadataproxy/roles.py", "project_url": "https://github.com/Chillibean/metadataproxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -223,7 +223,7 @@ def get_role_arn(role_name):\n     # in and use that.\n     account_id = app.config['AWS_ACCOUNT_MAP'].get(account_name, account_name)\n     # Return a generated ARN\n-    return 'arn:aws:iam::{0}:role/{1}'.format(assume_role, account_id)\n+    return 'arn:aws:iam::{0}:role/{1}'.format(account_id, assume_role)\n \n \n @log_exec_time\n", "before": "return 'arn:aws:iam::{0}:role/{1}' . format ( assume_role , account_id )", "after": "return 'arn:aws:iam::{0}:role/{1}' . format ( account_id , assume_role )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:assume_role\", 3, 47, 3, 58], [\"argument_list\", 3, 46, 3, 71], 3], [\"Move\", [\",:,\", 3, 58, 3, 59], [\"argument_list\", 3, 46, 3, 71], 4]]"}
{"project": "nova", "commit_sha": "1b5cde761bd699f6fec207f4b1b41d8c63ea1ec7", "parent_sha": "b186f7ae1515b8296f5fdb7f86b67c07973bb463", "file_path": "nova/api/openstack/images.py", "project_url": "https://github.com/bigswitch/nova", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -262,7 +262,7 @@ def create_resource(version='1.0'):\n     }\n \n     xml_serializer = {\n-        '1.0': wsgi.XMLDictSerializer(wsgi.XMLNS_V10, metadata),\n+        '1.0': wsgi.XMLDictSerializer(metadata, wsgi.XMLNS_V10),\n         '1.1': ImageXMLSerializer(),\n     }[version]\n \n", "before": "xml_serializer = { '1.0' : wsgi . XMLDictSerializer ( wsgi . XMLNS_V10 , metadata ) , '1.1' : ImageXMLSerializer ( ) , } [ version ]", "after": "xml_serializer = { '1.0' : wsgi . XMLDictSerializer ( metadata , wsgi . XMLNS_V10 ) , '1.1' : ImageXMLSerializer ( ) , } [ version ]", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 38, 3, 64], [\"identifier:metadata\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 38, 3, 64], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 53, 3, 54]], [\"Delete\", [\"identifier:metadata\", 3, 55, 3, 63]]]"}
{"project": "ckan", "commit_sha": "73c5a82f9b2d2060aab24f4063d2e11cfc9e0698", "parent_sha": "502b0ceeea7dcb142d39d8092ca4b96244203ca0", "file_path": "ckan/lib/alphabet_paginate.py", "project_url": "https://github.com/ohsu-comp-bio/ckan", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ class AlphaPage(object):\n             else:\n                 page = HTML.span(class_='pager_curpage', c=letter)\n             pages.append(page)                           \n-        div = HTML.tag('div', *pages, class_='pager')\n+        div = HTML.tag('div', class_='pager', *pages)\n         return div\n \n \n", "before": "div = HTML . tag ( 'div' , * pages , class_ = 'pager' )", "after": "div = HTML . tag ( 'div' , class_ = 'pager' , * pages )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"keyword_argument\", 3, 39, 3, 53], [\"argument_list\", 3, 23, 3, 54], 3], [\"Insert\", [\"argument_list\", 3, 23, 3, 54], [\",:,\", \"T\"], 6], [\"Delete\", [\",:,\", 3, 37, 3, 38]]]"}
{"project": "databroker", "commit_sha": "65f0f650ee0b8fe571b2a41d32e06d0865d03ed3", "parent_sha": "9d1a01ff33b796b443d88368ee775e2370451b32", "file_path": "metadatastore/doc.py", "project_url": "https://github.com/danielballan/databroker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -87,7 +87,7 @@ class Document(dict):\n         try:\n             return vstr(self)\n         except ImportError:\n-            return super(self, Document).__str__()\n+            return super(Document, self).__str__()\n \n     def to_name_dict_pair(self):\n", "before": "return super ( self , Document ) . __str__ ( )", "after": "return super ( Document , self ) . __str__ ( )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:self\", 3, 26, 3, 30], [\"argument_list\", 3, 25, 3, 41], 3], [\"Move\", [\",:,\", 3, 30, 3, 31], [\"argument_list\", 3, 25, 3, 41], 4]]"}
{"project": "flask-admin", "commit_sha": "68469536173cda8f5692be52a8e9f15339d7b19c", "parent_sha": "2f14840c6b44543f12ef35d01c8e0e4df3cef3ff", "file_path": "flask_admin/contrib/sqla/filters.py", "project_url": "https://github.com/bryhoyt/flask-admin", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ class BaseSQLAFilter(filters.BaseFilter):\n         return self.column if alias is None else getattr(alias, self.column.key)\n \n     def apply(self, query, value, alias=None):\n-        return super(self, BaseSQLAFilter).apply(query, value)\n+        return super(BaseSQLAFilter, self).apply(query, value)\n \n \n # Common filters\n", "before": "return super ( self , BaseSQLAFilter ) . apply ( query , value )", "after": "return super ( BaseSQLAFilter , self ) . apply ( query , value )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:self\", 3, 22, 3, 26], [\"argument_list\", 3, 21, 3, 43], 3], [\"Move\", [\",:,\", 3, 26, 3, 27], [\"argument_list\", 3, 21, 3, 43], 4]]"}
{"project": "twisted", "commit_sha": "74d9526f65ed75e3da9b6b77377a4a4ca3814f8f", "parent_sha": "cd19fb019d2e7ff8ff70c981e10f7091ce229728", "file_path": "twisted/protocols/socks.py", "project_url": "https://github.com/tomprince/twisted", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -151,7 +151,7 @@ class SOCKSv4(protocol.Protocol):\n         elif code == 2: # BIND\n             d = self.listenClass(0, SOCKSv4IncomingFactory, self, server)\n             d.addCallback(lambda x,\n-                          self = self: self.makeReply(90, 0, x[0], x[1]))\n+                          self = self: self.makeReply(90, 0, x[1], x[0]))\n         else:\n             raise RuntimeError(\"Bad Connect Code: %s\" % (code,))\n         assert self.buf == \"\", \"hmm, still stuff in buffer... %s\" % repr(\n", "before": "d . addCallback ( lambda x , self = self : self . makeReply ( 90 , 0 , x [ 0 ] , x [ 1 ] ) )", "after": "d . addCallback ( lambda x , self = self : self . makeReply ( 90 , 0 , x [ 1 ] , x [ 0 ] ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"subscript\", 3, 62, 3, 66], [\"argument_list\", 3, 54, 3, 73], 6], [\"Move\", [\"subscript\", 3, 68, 3, 72], [\"argument_list\", 3, 54, 3, 73], 5]]"}
{"project": "xqueue", "commit_sha": "201e691bfb00f7b4503904dd8d870a1d0f1696a5", "parent_sha": "f05bbd795404d5d2522f7b5b4c16319a58b9a5ce", "file_path": "queue/consumer.py", "project_url": "https://github.com/open-craft/xqueue", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -174,7 +174,7 @@ class SingleChannel(multiprocessing.Process):\n     def __init__(self, worker_id, queues):\n-        super(self, SingleChannel).__init__(self)\n+        super(SingleChannel, self).__init__(self)\n         self.worker_id = worker_id\n         self.queues = queues\n \n", "before": "super ( self , SingleChannel ) . __init__ ( self )", "after": "super ( SingleChannel , self ) . __init__ ( self )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:self\", 1, 15, 1, 19], [\"argument_list\", 1, 14, 1, 35], 3], [\"Move\", [\",:,\", 1, 19, 1, 20], [\"argument_list\", 1, 14, 1, 35], 4]]"}
{"project": "Deluge", "commit_sha": "50e6b343c32f0287119b96854015280726d3e946", "parent_sha": "e231621e12dde9c054c957fb2fd0af1425216fec", "file_path": "deluge/ui/webui/webui_plugin/pages.py", "project_url": "https://github.com/cas--/Deluge", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -248,7 +248,7 @@ def POST(self, name):\n         vars = web.input(data_also = None, torrent_also = None)\n         data_also = bool(vars.data_also)\n         torrent_also = bool(vars.torrent_also)\n-        ws.proxy.remove_torrent(torrent_ids, data_also, torrent_also)\n+        ws.proxy.remove_torrent(torrent_ids, torrent_also, data_also)\n         do_redirect()\n \n class torrent_queue_up:\n", "before": "ws . proxy . remove_torrent ( torrent_ids , data_also , torrent_also )", "after": "ws . proxy . remove_torrent ( torrent_ids , torrent_also , data_also )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:data_also\", 3, 46, 3, 55], [\"argument_list\", 3, 32, 3, 70], 5], [\"Move\", [\",:,\", 3, 55, 3, 56], [\"argument_list\", 3, 32, 3, 70], 6]]"}
{"project": "C-PAC", "commit_sha": "c66930d68a2edc6aa93e33b303e71dc3bbb3d8ad", "parent_sha": "87c14c1f8623814fb7a975a4e6a2eb227426e854", "file_path": "CPAC/cwas/utils.py", "project_url": "https://github.com/florisvanvugt/C-PAC", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -74,6 +74,6 @@ def calc_mdmrs(D, regressor, cols, iter, strata=None):\n     p_set = np.zeros(nVoxels)\n     \n     for i in range(nVoxels):\n-        p_set[i], F_set[i], _, _ = mdmr(D[i].reshape(1,nSubjects**2), regressor, cols, iter, strata)\n+        p_set[i], F_set[i], _, _ = mdmr(D[i].reshape(nSubjects**2,1), regressor, cols, iter, strata)\n     \n     return F_set, p_set\n", "before": "p_set [ i ] , F_set [ i ] , _ , _ = mdmr ( D [ i ] . reshape ( 1 , nSubjects ** 2 ) , regressor , cols , iter , strata )", "after": "p_set [ i ] , F_set [ i ] , _ , _ = mdmr ( D [ i ] . reshape ( nSubjects ** 2 , 1 ) , regressor , cols , iter , strata )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 53, 3, 69], [\",:,\", \"T\"], 3], [\"Insert\", [\"argument_list\", 3, 53, 3, 69], [\"integer:1\", \"T\"], 4], [\"Delete\", [\"integer:1\", 3, 54, 3, 55]], [\"Delete\", [\",:,\", 3, 55, 3, 56]]]"}
{"project": "BayesianOptimization", "commit_sha": "ba4aab6460c1afb1cb496a2077fbf252114430d3", "parent_sha": "361aa72d8854256243b73ea4d91e1845b73e2893", "file_path": "bayes_opt/bayesian_optimization.py", "project_url": "https://github.com/ml-lab/BayesianOptimization", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,7 +41,7 @@ def acq_max(ac, gp, ymax, restarts, bounds):\n         x_try = numpy.asarray([numpy.random.uniform(x[0], x[1], size=1) for x in bounds]).T\n \n         #Find the minimum of minus the acquisition function\n-        res = minimize(lambda x: -ac(x.reshape(-1, 1), gp=gp, ymax=ymax), x_try, bounds=bounds, method='L-BFGS-B')\n+        res = minimize(lambda x: -ac(x.reshape(1, -1), gp=gp, ymax=ymax), x_try, bounds=bounds, method='L-BFGS-B')\n \n         #Store it if better than previous minimum(maximum).\n         if -res.fun >= ei_max:\n", "before": "res = minimize ( lambda x : - ac ( x . reshape ( - 1 , 1 ) , gp = gp , ymax = ymax ) , x_try , bounds = bounds , method = 'L-BFGS-B' )", "after": "res = minimize ( lambda x : - ac ( x . reshape ( 1 , - 1 ) , gp = gp , ymax = ymax ) , x_try , bounds = bounds , method = 'L-BFGS-B' )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 47, 3, 54], [\"integer:1\", \"T\"], 1], [\"Insert\", [\"argument_list\", 3, 47, 3, 54], [\",:,\", \"T\"], 2], [\"Delete\", [\",:,\", 3, 50, 3, 51]], [\"Delete\", [\"integer:1\", 3, 52, 3, 53]]]"}
{"project": "erpnext", "commit_sha": "113b4c1a218674f944934c229551a2d81a0f3d9b", "parent_sha": "cbf2e44f0eba1947988a9cdd423597477e98b933", "file_path": "accounts/report/accounts_payable/accounts_payable.py", "project_url": "https://github.com/andyzsf/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -54,7 +54,7 @@ def execute(filters=None):\n \t\t\t\telse:\n \t\t\t\t\tageing_based_on_date = gle.posting_date\n \t\t\t\t\t\n-\t\t\t\trow += get_ageing_data(ageing_based_on_date, age_on, outstanding_amount)\n+\t\t\t\trow += get_ageing_data(age_on, ageing_based_on_date, outstanding_amount)\n \t\t\t\tdata.append(row)\n \t\t\t\t\n \treturn columns, data\n", "before": "row += get_ageing_data ( ageing_based_on_date , age_on , outstanding_amount )", "after": "row += get_ageing_data ( age_on , ageing_based_on_date , outstanding_amount )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:ageing_based_on_date\", 3, 28, 3, 48], [\"argument_list\", 3, 27, 3, 77], 3], [\"Move\", [\",:,\", 3, 48, 3, 49], [\"argument_list\", 3, 27, 3, 77], 4]]"}
{"project": "LiveRemoteScripts", "commit_sha": "03d1aba2cbd0c11aa1039da8008c007b00c63e3b", "parent_sha": "f54c8d17df58c11bed7efc64e3be9ba02c7b6404", "file_path": "aumhaa/v2/control_surface/components/mono_mixer.py", "project_url": "https://github.com/LividInstruments/LiveRemoteScripts", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -438,7 +438,7 @@ class MonoMixerComponent(MixerComponentBase):\n \t\tself._send_controls = controls\n \t\tif controls:\n \t\t\tfor index in range(len(self._channel_strips)):\n-\t\t\t\tsend_controls = [controls.get_button(index, row) for row in range(controls.height())]\n+\t\t\t\tsend_controls = [controls.get_button(row, index) for row in range(controls.height())]\n \t\t\t\tif self.send_index > controls.height:\n \t\t\t\t\tsend_controls = send_controls + [None for _ in range(self.send_index - controls.height)]\n \t\t\t\tself._channel_strips[index].set_send_controls(send_controls)\n", "before": "send_controls = [ controls . get_button ( index , row ) for row in range ( controls . height ( ) ) ]", "after": "send_controls = [ controls . get_button ( row , index ) for row in range ( controls . height ( ) ) ]", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:index\", 3, 42, 3, 47], [\"argument_list\", 3, 41, 3, 53], 3], [\"Move\", [\",:,\", 3, 47, 3, 48], [\"argument_list\", 3, 41, 3, 53], 4]]"}
{"project": "mcn-projects", "commit_sha": "844a15230da133dcc3589644b54152d12c6fb048", "parent_sha": "81410eefa382c3b449746b75c33e1aba90ee357d", "file_path": "package/load_balancer.py", "project_url": "https://github.com/ah450/mcn-projects", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,7 +31,7 @@ class LoadBalancer(EventMixin):\n     for i in xrange(1,6) :\n       ethaddr = '00:00:00:00:00:%02x' % i\n       ipaddr = '10.0.0.%d' % i\n-      self.servers.append(self.Server(ethaddr, ipaddr, i))\n+      self.servers.append(self.Server(ipaddr, ethaddr, i))\n     self.last_server = 0\n \n     def get_next_server(self):\n", "before": "self . servers . append ( self . Server ( ethaddr , ipaddr , i ) )", "after": "self . servers . append ( self . Server ( ipaddr , ethaddr , i ) )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:ethaddr\", 3, 39, 3, 46], [\"argument_list\", 3, 38, 3, 58], 3], [\"Move\", [\",:,\", 3, 46, 3, 47], [\"argument_list\", 3, 38, 3, 58], 4]]"}
{"project": "taiga-back-", "commit_sha": "69bd2f5746a70b514881b3906a845e364285f5b9", "parent_sha": "74d453a316109c4e9f15007a993ee57a804e2f2d", "file_path": "greenmine/scrum/serializers.py", "project_url": "https://github.com/andyzsf/taiga-back-", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -117,7 +117,7 @@ class IssueSerializer(serializers.ModelSerializer):\n \n         for version in reversed(list(reversion.get_for_object(obj))):\n             if current:\n-                issues_diff = self.get_issues_diff(version, current)\n+                issues_diff = self.get_issues_diff(current, version)\n                 diff_list.append(issues_diff)\n \n             current = version\n", "before": "issues_diff = self . get_issues_diff ( version , current )", "after": "issues_diff = self . get_issues_diff ( current , version )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"identifier:version\", 3, 52, 3, 59], [\"argument_list\", 3, 51, 3, 69], 3], [\"Move\", [\",:,\", 3, 59, 3, 60], [\"argument_list\", 3, 51, 3, 69], 4]]"}
{"project": "Trellonos", "commit_sha": "f051fe7e3194a7771d3ab586a9294b389394a846", "parent_sha": "c27eccc628a0b97cf6f468aa9db5d486bb9f82f1", "file_path": "trellonos/trellotools.py", "project_url": "https://github.com/Natman64/Trellonos", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -164,7 +164,7 @@ class Trello(object):\n \n     def remove_card_member(self, card, member):\n         \"\"\" Removes a member from a Trello card \"\"\"\n-        self.__trello.cards.delete_member_idMember(card['id'], member['id'])\n+        self.__trello.cards.delete_member_idMember(member['id'], card['id'])\n \n     def unsubscribe_card(self, card):\n         \"\"\" Removes the member running Trellonos from a card \"\"\"\n", "before": "self . __trello . cards . delete_member_idMember ( card [ 'id' ] , member [ 'id' ] )", "after": "self . __trello . cards . delete_member_idMember ( member [ 'id' ] , card [ 'id' ] )", "sstub_pattern": "SAME_FUNCTION_SWAP_ARGS", "edit_script": "[[\"Move\", [\"subscript\", 3, 52, 3, 62], [\"argument_list\", 3, 51, 3, 77], 2], [\"Move\", [\"subscript\", 3, 64, 3, 76], [\"argument_list\", 3, 51, 3, 77], 1]]"}
{"project": "nixops", "commit_sha": "b19c31f5f3f18244a247b81c697d03aa5b9f35d6", "parent_sha": "feccce6349843cc502a96bd838815ccbec02df63", "file_path": "nixops/resources/s3_bucket.py", "project_url": "https://github.com/zalora/nixops", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -96,7 +96,7 @@ class S3BucketState(nixops.resources.ResourceState):\n                     bucket.delete()\n                 except boto.exception.S3ResponseError as e:\n                     if e.error_code != \"BucketNotEmpty\": raise\n-                    if not self.depl.confirm(\"are you sure you want to destroy S3 bucket \u2018{0}\u2019?\".format(self.bucket_name)): return False\n+                    if not self.depl.logger.confirm(\"are you sure you want to destroy S3 bucket \u2018{0}\u2019?\".format(self.bucket_name)): return False\n                     keys = bucket.list()\n                     bucket.delete_keys(keys)\n                     bucket.delete()\n", "before": "if not self . depl . confirm ( \"are you sure you want to destroy S3 bucket \u2018{0}\u2019?\".for m at(sel f .buc k et_name)):  r e t rn Fal e", "after": "if not self . depl . logger . confirm ( \"are you sure you want to destroy S3 bucket \u2018{0}\u2019?\".for m at(sel f .buc k et_name)):  r e t rn Fal e", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 28, 3, 37], [\"attribute\", 3, 28, 3, 37], 0], [\"Insert\", [\"attribute\", 3, 28, 3, 37], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 28, 3, 37], [\"identifier:logger\", \"T\"], 2]]"}
{"project": "carbon", "commit_sha": "f7f1d67f2a11432c210f30cebc9fdbb92141ef8b", "parent_sha": "ced113a93c8abf645cebf782a6d2935bb832bba2", "file_path": "lib/carbon/aggregator/rules.py", "project_url": "https://github.com/jfarrell/carbon", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -85,7 +85,7 @@ class AggregationRule:\n       try:\n         result = self.output_template % extracted_fields\n       except:\n-        log(\"Failed to interpolate template %s with fields %s\" % (self.output_template, extracted_fields))\n+        log.err(\"Failed to interpolate template %s with fields %s\" % (self.output_template, extracted_fields))\n \n     self.cache[metric_path] = result\n     return result\n", "before": "log ( \"Failed to interpolate template %s with fields %s\" % ( self . output_template , extracted_fields ) )", "after": "log . err ( \"Failed to interpolate template %s with fields %s\" % ( self . output_template , extracted_fields ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"call\", 3, 9, 3, 107], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:log\", 3, 9, 3, 12], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:err\", \"T\"], 2]]"}
{"project": "stoq", "commit_sha": "c342048fe36e807090e08b23bf5a686aa436a0fb", "parent_sha": "82ca165570e6d3e452819837e49cdb57a95131ba", "file_path": "stoq/gui/slaves/payment.py", "project_url": "https://github.com/bellini666/stoq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -320,7 +320,7 @@ class CheckDataSlave(BillDataSlave):\n \n     def setup_proxies(self):\n         self._setup_widgets()\n-        self.add_proxy(self.model, BillDataSlave.payment_widgets)\n+        self.add_proxy(self.model.payment, BillDataSlave.payment_widgets)\n \n \n class BasePaymentMethodSlave(BaseEditorSlave):\n", "before": "self . add_proxy ( self . model , BillDataSlave . payment_widgets )", "after": "self . add_proxy ( self . model . payment , BillDataSlave . payment_widgets )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 24, 3, 34], [\"attribute\", 3, 24, 3, 34], 0], [\"Insert\", [\"attribute\", 3, 24, 3, 34], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 24, 3, 34], [\"identifier:payment\", \"T\"], 2]]"}
{"project": "PyMonopoly", "commit_sha": "7e8652c4571c2f2ca7950b924a380597607ab94f", "parent_sha": "1fc566f632840b9acf9cc6a16e4ba12494fce10e", "file_path": "LIB/modules/ScreenData.py", "project_url": "https://github.com/Kycko/PyMonopoly", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -626,7 +626,7 @@ class MainScreen():\n         Globals.TEMP_VARS.pop('save_step_indicators_state')\n     def show_property_management_menuitems(self, number, condition=True):\n         if condition:\n-            trader_name = self.trader_for_cur_player_or_for_birthday()\n+            trader_name = self.trader_for_cur_player_or_for_birthday().name\n             if check_if_anybody_can_trade():\n                 if len(Globals.PLAYERS) == 2:\n                     type = 'enter_the_trade_menu_' + find_player_obj_by_name(trader_name, True).name\n", "before": "trader_name = self . trader_for_cur_player_or_for_birthday ( )", "after": "trader_name = self . trader_for_cur_player_or_for_birthday ( ) . name", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"assignment\", 3, 13, 3, 71], [\"attribute\", \"N0\"], 2], [\"Move\", \"N0\", [\"call\", 3, 27, 3, 71], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:name\", \"T\"], 2]]"}
{"project": "tribler", "commit_sha": "df513d9d712cbd68e826699343990dae0a19ec1e", "parent_sha": "f0077c351d27aa25fe08768363f14d305afe8c1e", "file_path": "Tribler/Dialogs/abcbuddyframe.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -195,6 +195,6 @@ class ABCBuddyFrame(wx.Frame):\n         \n     def OnCloseWindow(self, event = None):\n         self.parent.utility.frame.buddyFrame = None\n-        self.utility.abcbuddyframe = None\n+        self.parent.utility.abcbuddyframe = None\n         self.Destroy()        \n \n", "before": "self . utility . abcbuddyframe = None", "after": "self . parent . utility . abcbuddyframe = None", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 9, 3, 21], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 9, 3, 21], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 9, 3, 13], 0], [\"Move\", \"N0\", [\".:.\", 3, 13, 3, 14], 1], [\"Insert\", \"N0\", [\"identifier:parent\", \"T\"], 2]]"}
{"project": "tribler", "commit_sha": "2322bf92617975f49b021770f71ab0aefea88ce3", "parent_sha": "a3ac183a8ef689ac3b08923dc499dca52452b94c", "file_path": "Tribler/Community/allchannel/community.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ class AllChannelCommunity(Community):\n                                       (my_member.database_id, cls.get_classification(), buffer(cid), buffer(master_key)))\n \n             # new community instance\n-            community = cls(cid, master_key, *args, **kargs)\n+            community = cls.load_community(cid, master_key, *args, **kargs)\n \n             # send out my initial dispersy-identity\n             community.create_dispersy_identity()\n", "before": "community = cls ( cid , master_key , * args , ** kargs )", "after": "community = cls . load_community ( cid , master_key , * args , ** kargs )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"call\", 3, 25, 3, 61], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:cls\", 3, 25, 3, 28], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:load_community\", \"T\"], 2]]"}
{"project": "tribler", "commit_sha": "269f968dd208dfdf395e814b79868cfb08858a28", "parent_sha": "fdfd8db9ccccc1229bdf1be2b0908664f57613ad", "file_path": "Tribler/Core/Upgrade/pickle_converter.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -133,7 +133,7 @@ class PickleConverter(object):\n             dlconfig = pickle.load(old_file)\n \n         # Upgrade to new config\n-        ddsconfig = DefaultDownloadStartupConfig()\n+        ddsconfig = DefaultDownloadStartupConfig.getInstance()\n         for key, value in dlconfig.iteritems():\n             if key in ['saveas', 'max_upload_rate', 'max_download_rate', 'super_seeder', 'mode', 'selected_files',\n                        'correctedfilename']:\n", "before": "ddsconfig = DefaultDownloadStartupConfig ( )", "after": "ddsconfig = DefaultDownloadStartupConfig . getInstance ( )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"call\", 3, 21, 3, 51], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:DefaultDownloadStartupConfig\", 3, 21, 3, 49], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:getInstance\", \"T\"], 2]]"}
{"project": "tribler", "commit_sha": "8e1776a4f77c59fa67f60e0ac68f44b8258d08c2", "parent_sha": "8ea4d6ee48836bce99aba8307a4e65f2f3cdffd5", "file_path": "Tribler/Core/CacheDB/SqliteCacheDBHandler.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1795,7 +1795,7 @@ class MyPreferenceDBHandler(BasicDBHandler):\n     def updateProgressByHash(self, hash, progress):\n         torrent_id = self._torrent_db.getTorrentID(hash)\n         if not torrent_id:\n-            torrent_id = self.getTorrentIDRoot(hash)\n+            torrent_id = self._torrent_db.getTorrentIDRoot(hash)\n \n         if torrent_id:\n             self.updateProgress(torrent_id, progress)\n", "before": "torrent_id = self . getTorrentIDRoot ( hash )", "after": "torrent_id = self . _torrent_db . getTorrentIDRoot ( hash )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 26, 3, 47], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 26, 3, 47], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 26, 3, 30], 0], [\"Move\", \"N0\", [\".:.\", 3, 30, 3, 31], 1], [\"Insert\", \"N0\", [\"identifier:_torrent_db\", \"T\"], 2]]"}
{"project": "python-openid", "commit_sha": "03e4d0e12912f7337637643257a53a3b7c4d6648", "parent_sha": "2c5b50cffe92bbf3894e2414901d09c9c998fab1", "file_path": "util.py", "project_url": "https://github.com/ziima/python-openid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ class UTC(datetime.tzinfo):\n utc = UTC()\n \n def utc_now():\n-    return utc.fromutc(datetime.utcnow().replace(tzinfo=utc))\n+    return utc.fromutc(datetime.datetime.utcnow().replace(tzinfo=utc))\n \n def sha1(s):\n     return sha.new(s).digest()\n", "before": "return utc . fromutc ( datetime . utcnow ( ) . replace ( tzinfo = utc ) )", "after": "return utc . fromutc ( datetime . datetime . utcnow ( ) . replace ( tzinfo = utc ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 24, 3, 39], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 24, 3, 39], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:datetime\", 3, 24, 3, 32], 0], [\"Move\", \"N0\", [\".:.\", 3, 32, 3, 33], 1], [\"Insert\", \"N0\", [\"identifier:datetime\", \"T\"], 2]]"}
{"project": "hyperdock", "commit_sha": "71e1bbe7b479307c6caadaa721170debee145519", "parent_sha": "30f378ae8727be0df7829aac63ab4e4df70db9e9", "file_path": "tests/worker/test_worker.py", "project_url": "https://github.com/ErikGartner/hyperdock", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,7 +41,7 @@ class TestWorker(HyperdockBaseTest):\n         \"\"\"\n         test worker run loop and stopping it\n         \"\"\"\n-        self._sleep_time = 0.1\n+        self.worker._sleep_time = 0.1\n         self.worker._register_worker = mock.MagicMock()\n         self.worker._monitor_experiments = mock.MagicMock()\n         self.worker._kill_orphans = mock.MagicMock()\n", "before": "self . _sleep_time = 0.1", "after": "self . worker . _sleep_time = 0.1", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 9, 3, 25], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 9, 3, 25], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 9, 3, 13], 0], [\"Move\", \"N0\", [\".:.\", 3, 13, 3, 14], 1], [\"Insert\", \"N0\", [\"identifier:worker\", \"T\"], 2]]"}
{"project": "qats", "commit_sha": "d3769bb9612f09e42c1ad954aa862916e35c5333", "parent_sha": "7e8b1c48b2d8c707fec6683e3f4b2373cd1cc54c", "file_path": "qats/ts.py", "project_url": "https://github.com/dnvgl/qats", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -500,7 +500,7 @@ class TimeSeries(object):\n \n         The fit in example above is equivalent to:\n \n-        >>> from qats.weibull import Weibull\n+        >>> from qats.stats.weibull import Weibull\n         >>> maxima = ts.maxima(local=False, threshold=None, twin=(200., 1e12), rettime=False)\n         >>> weib = Weibull.fit(maxima, method='msm')\n \n", "before": "to : >> > from qats . weibull", "after": "to : >> > from qats . stats . weibull", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 18, 3, 30], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 18, 3, 30], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:qats\", 3, 18, 3, 22], 0], [\"Move\", \"N0\", [\".:.\", 3, 22, 3, 23], 1], [\"Insert\", \"N0\", [\"identifier:stats\", \"T\"], 2]]"}
{"project": "pyconkr-api", "commit_sha": "5b77becc4b888a9cbe01cf84f2ca74b84e24ef86", "parent_sha": "cbe79347a0c2c609e68638ccade66d94e21123ea", "file_path": "ticket/models.py", "project_url": "https://github.com/pythonkr/pyconkr-api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -200,7 +200,7 @@ class Ticket(TransactionMixin, models.Model):\n     def registered_at(self):\n         registrations = Registration.objects.filter(ticket=self)\n         if registrations.exists():\n-            return registrations.first()\n+            return registrations.first().registered_at\n         return None\n \n     def set_issue(self):\n", "before": "return registrations . first ( )", "after": "return registrations . first ( ) . registered_at", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 13, 3, 41], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 20, 3, 41], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:registered_at\", \"T\"], 2]]"}
{"project": "cc-utils", "commit_sha": "5c8b8af70f9415dc65ff4a3b29a24aa1cb228346", "parent_sha": "9b228c13671fbd5376537f25d1856ea887a926b8", "file_path": "concourse/pipelines/enumerator.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -135,7 +135,7 @@ class SimpleFileDefinitionEnumerator(DefinitionEnumerator):\n         self.repo_host = repo_host\n         self.cfg_set = cfg_set\n         import model\n-        self.job_mapping = model.JobMapping(\n+        self.job_mapping = model.concourse.JobMapping(\n             name='dummy',\n             raw_dict={'concourse_target_team': 'dummy'},\n         )\n", "before": "self . job_mapping = model . JobMapping ( name = 'dummy' , raw_dict = { 'concourse_target_team' : 'dummy' } , )", "after": "self . job_mapping = model . concourse . JobMapping ( name = 'dummy' , raw_dict = { 'concourse_target_team' : 'dummy' } , )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 28, 3, 44], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 28, 3, 44], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:model\", 3, 28, 3, 33], 0], [\"Move\", \"N0\", [\".:.\", 3, 33, 3, 34], 1], [\"Insert\", \"N0\", [\"identifier:concourse\", \"T\"], 2]]"}
{"project": "cc-utils", "commit_sha": "273c55bee105ad0a88cd63cb6037982dec6b311d", "parent_sha": "a6ffe9e0adc57406c0f91a77fa3bc8876cef20a8", "file_path": "concourse/steps/__init__.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,5 +30,5 @@ def step_template(name):\n def step_def(name):\n     template = step_template(name)\n \n-    return template.get_def(name + '_step')\n+    return template.get_def(name + '_step').render\n \n", "before": "return template . get_def ( name + '_step' )", "after": "return template . get_def ( name + '_step' ) . render", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 5, 3, 44], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 44], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:render\", \"T\"], 2]]"}
{"project": "cc-utils", "commit_sha": "62d80abd3f5afd7755bf8d3ce39e39460fe5d1f9", "parent_sha": "fc741a7a80d036df1bfa04cd44529e484c73e65b", "file_path": "model/container_registry.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ class ContainerRegistryConfig(NamedModelElement, ModelDefaultsMixin):\n     def _defaults_dict(self):\n         return {\n-            'privileges': Privileges.READ_ONLY,\n+            'privileges': Privileges.READ_ONLY.value,\n         }\n \n     def _optional_attributes(self):\n", "before": "return { 'privileges' : Privileges . READ_ONLY , }", "after": "return { 'privileges' : Privileges . READ_ONLY . value , }", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 2, 27, 2, 47], [\"attribute\", 2, 27, 2, 47], 0], [\"Insert\", [\"attribute\", 2, 27, 2, 47], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 2, 27, 2, 47], [\"identifier:value\", \"T\"], 2]]"}
{"project": "cc-utils", "commit_sha": "2a82042d4ec7b267f4a0bff0ffd4087378f77056", "parent_sha": "7fc649cdfdb7ed50e44fa1a9ed756aa1cb281b73", "file_path": "container/registry.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -122,7 +122,7 @@ def retrieve_container_image(image_reference: str, outfileobj=None):\n \n def publish_container_image(image_reference: str, image_file_obj):\n   image_file_obj.seek(0)\n-  _push_image(image_reference=image_reference, image_file=image_file_obj)\n+  _push_image(image_reference=image_reference, image_file=image_file_obj.name)\n   image_file_obj.seek(0)\n \n \n", "before": "_push_image ( image_reference = image_reference , image_file = image_file_obj )", "after": "_push_image ( image_reference = image_reference , image_file = image_file_obj . name )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 48, 3, 73], [\"attribute\", \"N0\"], 2], [\"Move\", \"N0\", [\"identifier:image_file_obj\", 3, 59, 3, 73], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:name\", \"T\"], 2]]"}
{"project": "cc-utils", "commit_sha": "aec44ac43a7576a60aef4fb1927073c5eb275d38", "parent_sha": "e19bbfe75e421738013143643ef9b659828cd536", "file_path": "concourse/enumerator.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -327,7 +327,7 @@ class GithubOrganisationDefinitionEnumerator(GithubDefinitionEnumeratorBase):\n                 scan_repository_for_definitions,\n                 (\n                     repo for repo in github_org.repositories()\n-                    if github_org_cfg.repository_matches(repo)\n+                    if github_org_cfg.repository_matches(repo.name)\n                 ),\n             ):\n                 yield from definition_descriptors\n", "before": "( repo for repo in github_org . repositories ( ) if github_org_cfg . repository_matches ( repo ) ) ,", "after": "( repo for repo in github_org . repositories ( ) if github_org_cfg . repository_matches ( repo . name ) ) ,", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 57, 3, 63], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:repo\", 3, 58, 3, 62], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:name\", \"T\"], 2]]"}
{"project": "cc-utils", "commit_sha": "ae275d2395db16d5ffa00dd7748de747bffa4ff1", "parent_sha": "0730df0ab11dd15ea76278ac76eadf092d13c319", "file_path": "model/delivery.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ class MongoDbConfig(ModelBase):\n         return self.raw.get('configmap')\n \n     def database_name(self):\n-        return self.raw('database_name', 'delivery')\n+        return self.raw.get('database_name', 'delivery')\n \n     def service_port(self):\n", "before": "return self . raw ( 'database_name' , 'delivery' )", "after": "return self . raw . get ( 'database_name' , 'delivery' )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 16, 3, 24], [\"attribute\", 3, 16, 3, 24], 0], [\"Insert\", [\"attribute\", 3, 16, 3, 24], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 16, 3, 24], [\"identifier:get\", \"T\"], 2]]"}
{"project": "WMAS", "commit_sha": "cbdc02add6916c19afdc3cad022019184c6eb3d3", "parent_sha": "501edafdaba1be4c57c82edc2a3a1b0db260f0ad", "file_path": "wptserve/stash.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -119,7 +119,7 @@ class Stash(object):\n         if internal_key in self.data:\n             raise StashError(\"Tried to overwrite existing shared stash value \"\n                              \"for key %s (old value was %s, new value is %s)\" %\n-                             (internal_key, self[str(internal_key)], value))\n+                             (internal_key, self.data[str(internal_key)], value))\n         else:\n             self.data[internal_key] = value\n \n", "before": "raise StashError ( \"Tried to overwrite existing shared stash value \" \"for key %s (old value was %s, new value is %s)\" % ( internal_key , self [ str ( internal_key ) ] , value ) )", "after": "raise StashError ( \"Tried to overwrite existing shared stash value \" \"for key %s (old value was %s, new value is %s)\" % ( internal_key , self . data [ str ( internal_key ) ] , value ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"subscript\", 3, 45, 3, 68], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:self\", 3, 45, 3, 49], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:data\", \"T\"], 2]]"}
{"project": "pyMaid", "commit_sha": "25241b07e40896d36f2636496d0a49f8e3f799ee", "parent_sha": "a998830ed401c5caf49ad4afb4a2827a35e9f85e", "file_path": "pymaid/fetch.py", "project_url": "https://github.com/schlegelp/pyMaid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1919,7 +1919,7 @@ def get_connector_links(x, with_tags=False, chunk_size=50, remote_instance=None)\n \r\n     # Cater for cases in which the original neurons have been edited\r\n     if isinstance(x, (core.CatmaidNeuron, core.CatmaidNeuronList)):\r\n-        df = df[df.connector_id.isin(x.connectors)]\r\n+        df = df[df.connector_id.isin(x.connectors.connector_id)]\r\n \r\n     # Convert to timestamps\r\n     df['creation_time'] = [datetime.datetime.strptime(\r\n", "before": "df = df [ df . connector_id . isin ( x . connectors ) ]", "after": "df = df [ df . connector_id . isin ( x . connectors . connector_id ) ]", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 38, 3, 50], [\"attribute\", 3, 38, 3, 50], 0], [\"Insert\", [\"attribute\", 3, 38, 3, 50], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 38, 3, 50], [\"identifier:connector_id\", \"T\"], 2]]"}
{"project": "Visual_Script", "commit_sha": "8dbb7dfa0cc62ee4de85b316fa529a3b6707cd70", "parent_sha": "d1b4efae59b34bc8d8ed5093f9079c2d877f2338", "file_path": "src/Controller/FileLoader.py", "project_url": "https://github.com/NTUTVisualScript/Visual_Script", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -127,7 +127,7 @@ class LoadFile:\n \n     def modelConnect(self):\n         from TestCaseUI import TestCaseUI\n-        TestCaseUI.getTestCaseUI().ctrl = self.case\n+        TestCaseUI.getTestCaseUI().ctrl.case = self.case\n \n     def getTestCase(self):\n         return self.case\n", "before": "TestCaseUI . getTestCaseUI ( ) . ctrl = self . case", "after": "TestCaseUI . getTestCaseUI ( ) . ctrl . case = self . case", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 9, 3, 40], [\"attribute\", 3, 9, 3, 40], 0], [\"Insert\", [\"attribute\", 3, 9, 3, 40], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 9, 3, 40], [\"identifier:case\", \"T\"], 2]]"}
{"project": "openshift-components", "commit_sha": "34ebb77fec72e49f31e6489682e0fa1f3f9d1cb5", "parent_sha": "aff835e52cb4bedcb5f486bba4c7daf3399dc60a", "file_path": "apps/taiga/back/django/taiga/taiga_contrib_github_extended_auth/services.py", "project_url": "https://github.com/BCDevOps/openshift-components", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -75,7 +75,7 @@ def github_login_func(request):\n \n         emails = connector.get_user_emails(headers=headers)\n \n-        primary_email = next(filter(lambda x: x.is_primary, emails))\n+        primary_email = next(filter(lambda x: x.is_primary, emails)).email\n \n         logger.debug(\"Primary email is {}\".format(primary_email))\n \n", "before": "primary_email = next ( filter ( lambda x : x . is_primary , emails ) )", "after": "primary_email = next ( filter ( lambda x : x . is_primary , emails ) ) . email", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 69], [\"attribute\", \"N0\"], 2], [\"Move\", \"N0\", [\"call\", 3, 25, 3, 69], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:email\", \"T\"], 2]]"}
{"project": "angr", "commit_sha": "0d862741b0aef2261d79083b81711df764a9790c", "parent_sha": "25b065ce1bff27b438206badfc684f61b6df9ad6", "file_path": "simuvex/procedures/libc___so___6/strstr.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ class strstr(simuvex.SimProcedure):\n             return haystack_addr\n         elif haystack_maxlen == 0:\n             l.debug(\"... zero-length haystack.\")\n-            return self.state.BitVecVal(0, self.state.arch.bits)\n+            return self.state.se.BitVecVal(0, self.state.arch.bits)\n \n         if self.state.se.symbolic(needle_strlen.ret_expr):\n             cases = [ [ needle_strlen.ret_expr == 0, haystack_addr ] ]\n", "before": "return self . state . BitVecVal ( 0 , self . state . arch . bits )", "after": "return self . state . se . BitVecVal ( 0 , self . state . arch . bits )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 20, 3, 30], [\"attribute\", 3, 20, 3, 30], 0], [\"Insert\", [\"attribute\", 3, 20, 3, 30], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 20, 3, 30], [\"identifier:se\", \"T\"], 2]]"}
{"project": "angr", "commit_sha": "c09a1f8b793f53f8dc24afe735fe07937e3b0ee5", "parent_sha": "e20a11bac97f013f35890f6b191b2821da885319", "file_path": "simuvex/procedures/cgc/receive.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ class receive(simuvex.SimProcedure):\n                 read_length = self.state.posix.read(fd, buf, actual_size)\n                 list(self.state.log.actions)[-1].size.ast = actual_size\n                 list(self.state.log.actions)[-2].data.ast = list(self.state.log.actions)[-1].actual_value.ast\n-                self.data = self.memory.load(buf, read_length)\n+                self.data = self.state.memory.load(buf, read_length)\n             else:\n                 self.data = None\n \n", "before": "self . data = self . memory . load ( buf , read_length )", "after": "self . data = self . state . memory . load ( buf , read_length )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 29, 3, 40], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 29, 3, 40], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 29, 3, 33], 0], [\"Move\", \"N0\", [\".:.\", 3, 33, 3, 34], 1], [\"Insert\", \"N0\", [\"identifier:state\", \"T\"], 2]]"}
{"project": "django-pyodbc-azure", "commit_sha": "7ead2c601e6336f64ffed4937c0e7b4d13c77b46", "parent_sha": "1d281a967a38dfcc1705e18879b21ae50f67cf35", "file_path": "sql_server/pyodbc/creation.py", "project_url": "https://github.com/mejimaru/django-pyodbc-azure", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ class DatabaseCreation(BaseDatabaseCreation):\n         # ourselves. Connect to the previous database (not the test database)\n         # to do so, because it's not allowed to delete a database while being\n         # connected to it.\n-        with self._nodb_connection.cursor() as cursor:\n+        with self.connection._nodb_connection.cursor() as cursor:\n             # Wait to avoid \"database is being accessed by other users\" errors.\n             time.sleep(1)\n             to_azure_sql_db = self.connection.to_azure_sql_db\n", "before": "with self . _nodb_connection . cursor ( ) as cursor : time . sleep ( 1 ) to_azure_sql_db = self . connection . to_azure_sql_db", "after": "with self . connection . _nodb_connection . cursor ( ) as cursor : time . sleep ( 1 ) to_azure_sql_db = self . connection . to_azure_sql_db", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 14, 3, 35], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 14, 3, 35], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 14, 3, 18], 0], [\"Move\", \"N0\", [\".:.\", 3, 18, 3, 19], 1], [\"Insert\", \"N0\", [\"identifier:connection\", \"T\"], 2]]"}
{"project": "OpenNMT-entmax", "commit_sha": "6710519262c5bd1c0f1b16f10ff76d63299b4d79", "parent_sha": "149512939fb4cf59d6ac89aea063473d8019bf7c", "file_path": "train.py", "project_url": "https://github.com/deep-spin/OpenNMT-entmax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -369,7 +369,7 @@ def main():\n             nn.Linear(opt.rnn_size, dicts['tgt'].size()),\n             nn.LogSoftmax())\n         if opt.share_decoder_embeddings:\n-            generator[0].weight = decoder.word_lut.weight\n+            generator[0].weight = decoder.embeddings.word_lut.weight\n \n     model = onmt.Models.NMTModel(encoder, decoder, len(opt.gpus) > 1)\n \n", "before": "generator [ 0 ] . weight = decoder . word_lut . weight", "after": "generator [ 0 ] . weight = decoder . embeddings . word_lut . weight", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 35, 3, 51], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 35, 3, 51], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:decoder\", 3, 35, 3, 42], 0], [\"Move\", \"N0\", [\".:.\", 3, 42, 3, 43], 1], [\"Insert\", \"N0\", [\"identifier:embeddings\", \"T\"], 2]]"}
{"project": "OpenNMT-entmax", "commit_sha": "1b0025973a0cd7f26f3b6a5a4c73ed9ca108ddea", "parent_sha": "3fc1db7454bfe9e378dc7a8f321ac22dfe8b0ea7", "file_path": "train.py", "project_url": "https://github.com/deep-spin/OpenNMT-entmax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ def eval(model, criterion, data, fields):\n     stats = onmt.Loss.Statistics()\n     model.eval()\n     loss = onmt.Loss.LossCompute(model.generator, criterion,\n-                                 fields[\"tgt\"].vocab, data, 0, opt)\n+                                 fields[\"tgt\"].vocab, data, 0, opt.copy_attn)\n     for batch in valid_data:\n         _, src_lengths = batch.src\n         src = onmt.IO.make_features(batch, 'src')\n", "before": "loss = onmt . Loss . LossCompute ( model . generator , criterion , fields [ \"tgt\" ] . vocab , data , 0 , opt )", "after": "loss = onmt . Loss . LossCompute ( model . generator , criterion , fields [ \"tgt\" ] . vocab , data , 0 , opt . copy_attn )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 33, 3, 68], [\"attribute\", \"N0\"], 11], [\"Move\", \"N0\", [\"identifier:opt\", 3, 64, 3, 67], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:copy_attn\", \"T\"], 2]]"}
{"project": "weather_display", "commit_sha": "82afedbbdafadc37ac461fad650c23aec71b14a6", "parent_sha": "21d210a33dd5ebe0c30ff83705b7cd69c8c4a85d", "file_path": "weather_display.py", "project_url": "https://github.com/NeonSpork/weather_display", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -95,7 +95,7 @@ def parseXmlAndDrawToMask():\n     # The following changes the root if the country is not Norway\n     # Since less detailed information is published, changing\n     # country results in an IndexError.\n-    if root[0][2] == \"Norway\":\n+    if root[0][2].text == \"Norway\":\n         secondRoot = 1\n     else:\n         secondRoot = 0\n", "before": "if root [ 0 ] [ 2 ] == \"Norway\" : secondRoot = 1 else : secondRoot = 0", "after": "if root [ 0 ] [ 2 ] . text == \"Norway\" : secondRoot = 1 else : secondRoot = 0", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 8, 3, 30], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"subscript\", 3, 8, 3, 18], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:text\", \"T\"], 2]]"}
{"project": "sympy", "commit_sha": "a77e7b42be5d55e895326ab8a172b651daf35b7f", "parent_sha": "892d1ad031982641123e581bbcf7e5be4e0608ed", "file_path": "sympy/integrals/risch.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -908,7 +908,7 @@ def get_case(d, t):\n-    if not d.has(t):\n+    if not d.expr.has(t):\n         if d.is_one:\n             return 'base'\n         return 'primitive'\n", "before": "if not d . has ( t ) : if d . is_one : return 'base' return 'primitive'", "after": "if not d . expr . has ( t ) : if d . is_one : return 'base' return 'primitive'", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 0, 12, 0, 17], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 0, 12, 0, 17], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:d\", 0, 12, 0, 13], 0], [\"Move\", \"N0\", [\".:.\", 0, 13, 0, 14], 1], [\"Insert\", \"N0\", [\"identifier:expr\", \"T\"], 2]]"}
{"project": "sympy", "commit_sha": "6d22cd9039636a89e82361e41b45c10627cecd4a", "parent_sha": "aa8f1bfd1d5f903694724f8bcb153b3c1c95f537", "file_path": "sympy/physics/units/dimensions.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -387,7 +387,7 @@ def parse_dict(d):\n                 raise ValueError(\"Dimension %s both in base and derived\" % dim)\n             if dim.name not in dimensional_dependencies:\n                 # TODO: should this raise a warning?\n-                dimensional_dependencies[dim] = Dict({dim.name: 1})\n+                dimensional_dependencies[dim.name] = Dict({dim.name: 1})\n \n         base_dims.sort(key=default_sort_key)\n         derived_dims.sort(key=default_sort_key)\n", "before": "dimensional_dependencies [ dim ] = Dict ( { dim . name : 1 } )", "after": "dimensional_dependencies [ dim . name ] = Dict ( { dim . name : 1 } )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"subscript\", 3, 17, 3, 46], [\"attribute\", \"N0\"], 2], [\"Move\", \"N0\", [\"identifier:dim\", 3, 42, 3, 45], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:name\", \"T\"], 2]]"}
{"project": "bokeh", "commit_sha": "4fccfe43e3edc0e704fb64841e92c27311c1411f", "parent_sha": "3fe3502b7466ed72cf9996e6e7a5bb34cc51ffb1", "file_path": "bokeh/server/zmq/forwarder.py", "project_url": "https://github.com/suqi/bokeh", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,5 +33,5 @@ class Forwarder(object):\n         self.device.start()\n \n     def stop(self):\n-        self.ctx.term()\n+        self.device.ctx.term()\n         self.device.join()\n", "before": "self . ctx . term ( )", "after": "self . device . ctx . term ( )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 9, 3, 17], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 9, 3, 17], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 9, 3, 13], 0], [\"Move\", \"N0\", [\".:.\", 3, 13, 3, 14], 1], [\"Insert\", \"N0\", [\"identifier:device\", \"T\"], 2]]"}
{"project": "django-pagination", "commit_sha": "5b7e3b9bd88a06b63d810a2843409b00779d1426", "parent_sha": "02add123b2953173031b6cfe31ec6b896343df6b", "file_path": "pagination/middleware.py", "project_url": "https://github.com/moshthepitt/django-pagination", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -5,6 +5,6 @@ class PaginationMiddleware(object):\n     def process_request(self, request):\n         try:\n-            request.page = int(request['page'])\n+            request.page = int(request.REQUEST['page'])\n         except (KeyError, ValueError):\n             request.page = 1\n\\ No newline at end of file\n", "before": "request . page = int ( request [ 'page' ] )", "after": "request . page = int ( request . REQUEST [ 'page' ] )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"subscript\", 2, 32, 2, 47], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:request\", 2, 32, 2, 39], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:REQUEST\", \"T\"], 2]]"}
{"project": "flutterfuck", "commit_sha": "acd36abac93d3445ac0b5a9745cc1bb83f99fd94", "parent_sha": "ef7d90de570d8eceb9d8406b877fc860706ef9a5", "file_path": "willie/modules/url.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ def setup(bot=None):\n \n     if bot.config.has_option('url', 'exclude'):\n         regexes = [re.compile(s) for s in\n-                   bot.config.url.get_list(bot.config.exclude)]\n+                   bot.config.url.get_list(bot.config.url.exclude)]\n     else:\n         regexes = []\n \n", "before": "regexes = [ re . compile ( s ) for s in bot . config . url . get_list ( bot . config . exclude ) ]", "after": "regexes = [ re . compile ( s ) for s in bot . config . url . get_list ( bot . config . url . exclude ) ]", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 44, 3, 54], [\"attribute\", 3, 44, 3, 54], 0], [\"Insert\", [\"attribute\", 3, 44, 3, 54], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 44, 3, 54], [\"identifier:url\", \"T\"], 2]]"}
{"project": "flutterfuck", "commit_sha": "aa1d1ceeafa5ef346c3895341f4433a5d7db7e6d", "parent_sha": "3ca1280351406ce2c05d613296fc003056916be7", "file_path": "willie/bot.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -567,7 +567,7 @@ class Willie(irc.Bot):\n             self.origin = origin\n \n         def __dir__(self):\n-            classattrs = [attr for attr in self.__dict__\n+            classattrs = [attr for attr in self.__class__.__dict__\n                           if not attr.startswith('__')]\n             return list(self.__dict__)+classattrs+dir(self.bot)\n \n", "before": "classattrs = [ attr for attr in self . __dict__ if not attr . startswith ( '__' ) ]", "after": "classattrs = [ attr for attr in self . __class__ . __dict__ if not attr . startswith ( '__' ) ]", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 44, 3, 57], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 44, 3, 57], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 44, 3, 48], 0], [\"Move\", \"N0\", [\".:.\", 3, 48, 3, 49], 1], [\"Insert\", \"N0\", [\"identifier:__class__\", \"T\"], 2]]"}
{"project": "edx-platform", "commit_sha": "684f901760911f98419fc6bafcef801cd8fe3630", "parent_sha": "7c0663f25e4d5fe5f119e16d281c2e9afa6f48ea", "file_path": "cms/djangoapps/contentstore/management/commands/tests/test_fix_not_found.py", "project_url": "https://github.com/easy-edx/edx-platform", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,7 +16,7 @@ class TestFixNotFound(ModuleStoreTestCase):\n         \"\"\"\n         The management command doesn't work on non split courses\n         \"\"\"\n-        course = CourseFactory(default_store=ModuleStoreEnum.Type.mongo)\n+        course = CourseFactory.create(default_store=ModuleStoreEnum.Type.mongo)\n         with self.assertRaises(SystemExit):\n             call_command(\"fix_not_found\", unicode(course.id))\n \n", "before": "course = CourseFactory ( default_store = ModuleStoreEnum . Type . mongo )", "after": "course = CourseFactory . create ( default_store = ModuleStoreEnum . Type . mongo )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"call\", 3, 18, 3, 73], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:CourseFactory\", 3, 18, 3, 31], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:create\", \"T\"], 2]]"}
{"project": "weblyzard_api", "commit_sha": "85b7b985a0f68afcbc83060844bec0bf3497780b", "parent_sha": "7e94072accbfca373f13b95dda975a3d94830099", "file_path": "src/python/weblyzard_api/model/parsers/__init__.py", "project_url": "https://github.com/weblyzard/weblyzard_api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -377,7 +377,7 @@ class XMLParser(object):\n                 del sent_attributes['id']\n             else:\n                 sent_id = hashlib.md5(\n-                    sent_value('utf-8')).hexdigest()\n+                    sent_value.encode('utf-8')).hexdigest()\n                 sent_attributes['md5sum'] = sent_id\n \n             if not sent_value:\n", "before": "else : sent_id = hashlib . md5 ( sent_value ( 'utf-8' ) ) . hexdigest ( )", "after": "else : sent_id = hashlib . md5 ( sent_value . encode ( 'utf-8' ) ) . hexdigest ( )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"call\", 3, 21, 3, 40], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:sent_value\", 3, 21, 3, 31], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:encode\", \"T\"], 2]]"}
{"project": "GRIDOPT", "commit_sha": "8d3704f53e06df547d192dbb731e775580ded184", "parent_sha": "7584dd61a8a0ab08cd1949e37e99ecefc9703234", "file_path": "gridopt/power_flow/augl_opf.py", "project_url": "https://github.com/ttinoco/GRIDOPT", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -95,7 +95,7 @@ class AugLOPF(PFmethod):\n     def get_info_printer(self):\n \n         def info_printer(solver,header):\n-            net = solver.problem.network\n+            net = solver.problem.wrapped_problem.network\n             if header:\n                 print('{0:^5}'.format('vmax'), end=' ')\n                 print('{0:^5}'.format('vmin'), end=' ')\n", "before": "net = solver . problem . network", "after": "net = solver . problem . wrapped_problem . network", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 19, 3, 33], [\"attribute\", 3, 19, 3, 33], 0], [\"Insert\", [\"attribute\", 3, 19, 3, 33], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 19, 3, 33], [\"identifier:wrapped_problem\", \"T\"], 2]]"}
{"project": "mldata", "commit_sha": "f80d7fc17b8279d66cfafda8f892e04815bbe0c4", "parent_sha": "d7d2b142b6777174ff965a6af130a2c4003c73f8", "file_path": "blog/feeds.py", "project_url": "https://github.com/open-machine-learning/mldata", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -20,7 +20,7 @@ def RssBlogFeed(request):\n         #comments=commentlink,\n         feed.add_item( object.headline.encode('utf-8'),\n                 link, markdown(object.body),\n-                author_name=object.author.encode('utf-8'),\n+                author_name=object.author.username.encode('utf-8'),\n                 pubdate=object.pub_date, unique_id=link)\n     response = HttpResponse(mimetype='application/xml')\n     feed.write(response, 'utf-8')\n", "before": "feed . add_item ( object . headline . encode ( 'utf-8' ) , link , markdown ( object . body ) , author_name = object . author . encode ( 'utf-8' ) , pubdate = object . pub_date , unique_id = link )", "after": "feed . add_item ( object . headline . encode ( 'utf-8' ) , link , markdown ( object . body ) , author_name = object . author . username . encode ( 'utf-8' ) , pubdate = object . pub_date , unique_id = link )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 29, 3, 42], [\"attribute\", 3, 29, 3, 42], 0], [\"Insert\", [\"attribute\", 3, 29, 3, 42], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 29, 3, 42], [\"identifier:username\", \"T\"], 2]]"}
{"project": "hmm", "commit_sha": "eeac71b9ac029e9e41ad08de4de2db84278b5b01", "parent_sha": "e5a0aafbfec8eafddc7411eddf0cc1cb1fbf8535", "file_path": "util.py", "project_url": "https://github.com/choge/hmm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,7 +34,7 @@ def load_ghmmxml(filename):\n         transitions.append(transition_prob)\n \n     return (np.array(transitions, dtype=float),\n-            np.array(emissions, dtype=float),\n+            np.array(emissions, dtype=float).T,\n             np.array(initials, dtype=float))\n \n \n", "before": "return ( np . array ( transitions , dtype = float ) , np . array ( emissions , dtype = float ) , np . array ( initials , dtype = float ) )", "after": "return ( np . array ( transitions , dtype = float ) , np . array ( emissions , dtype = float ) . T , np . array ( initials , dtype = float ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"tuple\", 2, 12, 4, 45], [\"attribute\", \"N0\"], 3], [\"Move\", \"N0\", [\"call\", 3, 13, 3, 45], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:T\", \"T\"], 2]]"}
{"project": "Pyglet", "commit_sha": "e122a6c1140577b32e8fe4db6c905fc43c6f3b9f", "parent_sha": "ef058c299b1a88c0c36bda1d5800c51f857378b3", "file_path": "pyglet/text/caret.py", "project_url": "https://github.com/adamlwgriffiths/Pyglet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -139,7 +139,7 @@ class Caret(object):\n-        self.delete()\n+        self._list.delete()\n         self._layout.remove_handlers(self)\n \n     def _blink(self, dt):\n", "before": "self . delete ( )", "after": "self . _list . delete ( )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 0, 9, 0, 20], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 0, 9, 0, 20], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 0, 9, 0, 13], 0], [\"Move\", \"N0\", [\".:.\", 0, 13, 0, 14], 1], [\"Insert\", \"N0\", [\"identifier:_list\", \"T\"], 2]]"}
{"project": "common_crawl", "commit_sha": "85f475972e4250c22fc7b8f202b5af1750e2df05", "parent_sha": "8b242e0eae557a32e097dc58e6ce65ae1cec6b54", "file_path": "common_crawl/base.py", "project_url": "https://github.com/openvenues/common_crawl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -97,7 +97,7 @@ class CommonCrawlJob(MRJob):\n         try:\n            \n             doc = UnicodeDammit(content, is_html=True)\n-            if not doc.unicode_markup or not self.filter(url, headers, doc):\n+            if not doc.unicode_markup or not self.filter(url, headers, doc.unicode_markup):\n                 self.increment_counter('common_crawl', 'filter_not_matched', 1)\n                 return\n \n", "before": "if not doc . unicode_markup or not self . filter ( url , headers , doc ) : self . increment_counter ( 'common_crawl' , 'filter_not_matched' , 1 ) return", "after": "if not doc . unicode_markup or not self . filter ( url , headers , doc . unicode_markup ) : self . increment_counter ( 'common_crawl' , 'filter_not_matched' , 1 ) return", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 57, 3, 76], [\"attribute\", \"N0\"], 5], [\"Move\", \"N0\", [\"identifier:doc\", 3, 72, 3, 75], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:unicode_markup\", \"T\"], 2]]"}
{"project": "aes-lac-2018", "commit_sha": "865230418b6559ae21081f4d001031c8071b22d0", "parent_sha": "f3a71085c71ccf48cfc089ea6ff5e7013e751f79", "file_path": "train.py", "project_url": "https://github.com/igormq/aes-lac-2018", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -64,7 +64,7 @@ def finetune_model(model, num_classes, freeze_layers, map_fc):\n             num_classes,\n             bias=False)\n \n-        model.fc[0].module[1] = new_weight\n+        model.fc[0].module[1].weight = new_weight\n \n         if map_fc is not None:\n             print('\\t Mapping FC weights')\n", "before": "bias = False ) model . fc [ 0 ] . module [ 1 ] = new_weight", "after": "bias = False ) model . fc [ 0 ] . module [ 1 ] . weight = new_weight", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 43], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"subscript\", 3, 9, 3, 30], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:weight\", \"T\"], 2]]"}
{"project": "vermouth-martinize", "commit_sha": "091abf07d9b35d1d67931fb30d7dff473542dea3", "parent_sha": "07c62a47ce0b12f267c3681f796e8c549b4aceeb", "file_path": "vermouth/ffinput.py", "project_url": "https://github.com/marrink-lab/vermouth-martinize", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -170,7 +170,7 @@ class FFDirector(SectionLineParser):\n \n         if self.current_modification is not None:\n             # add FF wide citations\n-            self.current_modification.update(self.citations)\n+            self.current_modification.citations.update(self.citations)\n             self.force_field.modifications[self.current_modification.name] = self.current_modification\n \n     def get_context(self, context_type):\n", "before": "self . current_modification . update ( self . citations )", "after": "self . current_modification . citations . update ( self . citations )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 13, 3, 38], [\"attribute\", 3, 13, 3, 38], 0], [\"Insert\", [\"attribute\", 3, 13, 3, 38], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 13, 3, 38], [\"identifier:citations\", \"T\"], 2]]"}
{"project": "Assassinbility", "commit_sha": "27cc6b7d5ccb9399248258cdfcd5ce5cc02eee80", "parent_sha": "2ab06d767231322eea8afb61332e9d672920f26f", "file_path": "app.py", "project_url": "https://github.com/doboy/Assassinbility", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -210,7 +210,7 @@ def poststartgame():\n \n         for i, user in enumerate(users_list):\n             sendSMS(user.number,\n-                    \"Welcome to the game, your target is: \" + Users[user.target_number].name + \". Your secret word is: \" + Users[user].secret_word)\n+                    \"Welcome to the game, your target is: \" + Users[user.target_number].name + \". Your secret word is: \" + Users[user.number].secret_word)\n         \n     return 'ok'\n \n", "before": "sendSMS ( user . number , \"Welcome to the game, your target is: \" + Users [ user . target_number ] . name + \". Your secret word is: \" + Users [ user ] . secret_word )", "after": "sendSMS ( user . number , \"Welcome to the game, your target is: \" + Users [ user . target_number ] . name + \". Your secret word is: \" + Users [ user . number ] . secret_word )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"subscript\", 3, 124, 3, 135], [\"attribute\", \"N0\"], 2], [\"Move\", \"N0\", [\"identifier:user\", 3, 130, 3, 134], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:number\", \"T\"], 2]]"}
{"project": "google-cluster-prediction", "commit_sha": "d9019d1c0a6dd30c71fd58c5dd286b73e48522de", "parent_sha": "3123a7256bcb3f86054c3ba5e271de77294c087a", "file_path": "bin/task_usage_learn.py", "project_url": "https://github.com/learning-on-chip/google-cluster-prediction", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -331,7 +331,7 @@ class Target:\n                 if length > config.max_length:\n                     continue\n                 sample = (record[0], int(record[1]), int(record[2]))\n-                if np.rand() < config.train_fraction:\n+                if np.random.rand() < config.train_fraction:\n                     self.train_samples.append(sample)\n                 else:\n                     self.test_samples.append(sample)\n", "before": "if np . rand ( ) < config . train_fraction : self . train_samples . append ( sample ) else : self . test_samples . append ( sample )", "after": "if np . random . rand ( ) < config . train_fraction : self . train_samples . append ( sample ) else : self . test_samples . append ( sample )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 20, 3, 27], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 20, 3, 27], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:np\", 3, 20, 3, 22], 0], [\"Move\", \"N0\", [\".:.\", 3, 22, 3, 23], 1], [\"Insert\", \"N0\", [\"identifier:random\", \"T\"], 2]]"}
{"project": "xos-1", "commit_sha": "c4ec14b02d9c12a3d510a793d03fefa366e8e77d", "parent_sha": "cbc865c384512ae95608d03594893cba3940324d", "file_path": "planetstack/core/models/sliver.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -109,7 +109,7 @@ class Sliver(PlCoreBase):\n         self.name = self.slice.slicename\n         if not self.creator and hasattr(self, 'caller'):\n             self.creator = self.caller\n-        self.controllerNetwork = self.node.controller\n+        self.controllerNetwork = self.node.site_deployment.controller\n \n # XXX smbaker - disabled for now, was causing fault in tenant view create slice\n #        if not self.controllerNetwork.test_acl(slice=self.slice):\n", "before": "self . controllerNetwork = self . node . controller", "after": "self . controllerNetwork = self . node . site_deployment . controller", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 34, 3, 43], [\"attribute\", 3, 34, 3, 43], 0], [\"Insert\", [\"attribute\", 3, 34, 3, 43], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 34, 3, 43], [\"identifier:site_deployment\", \"T\"], 2]]"}
{"project": "django-shop", "commit_sha": "24e2bfe184274b116f4e3b304b56761b55bf1b1e", "parent_sha": "83c42bb705237f4664c78a1c0e0da3e06ca94d0d", "file_path": "shop/forms/checkout.py", "project_url": "https://github.com/haricot/django-shop", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -69,7 +69,7 @@ class GuestForm(UniqueEmailValidationMixin, DialogModelForm):\n     def form_factory(cls, request, data, cart):\n         customer_form = cls(data=data, instance=request.customer.user)\n         if customer_form.is_valid():\n-            customer_form.instance.recognize_as_guest(request, commit=False)\n+            customer_form.instance.customer.recognize_as_guest(request, commit=False)\n             customer_form.save()\n         return customer_form\n \n", "before": "customer_form . instance . recognize_as_guest ( request , commit = False )", "after": "customer_form . instance . customer . recognize_as_guest ( request , commit = False )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 13, 3, 35], [\"attribute\", 3, 13, 3, 35], 0], [\"Insert\", [\"attribute\", 3, 13, 3, 35], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 13, 3, 35], [\"identifier:customer\", \"T\"], 2]]"}
{"project": "django-shop", "commit_sha": "eb8446a117e7b7847e61e9f7e363304dbe9c3eb8", "parent_sha": "499091d7d2c65b283c426690e6e8979528567351", "file_path": "shop/models/notification.py", "project_url": "https://github.com/haricot/django-shop", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -129,7 +129,7 @@ def order_event_notification(sender, instance=None, target=None, **kwargs):\n     from shop.models.order import OrderModel\n     from shop.serializers.order import OrderDetailSerializer\n \n-    if not isinstance(instance, OrderModel):\n+    if not isinstance(instance, OrderModel._materialized_model):\n         return\n     for notification in Notification.objects.filter(transition_target=target):\n         recipient = notification.get_recipient(instance)\n", "before": "if not isinstance ( instance , OrderModel ) : return", "after": "if not isinstance ( instance , OrderModel . _materialized_model ) : return", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 22, 3, 44], [\"attribute\", \"N0\"], 3], [\"Move\", \"N0\", [\"identifier:OrderModel\", 3, 33, 3, 43], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:_materialized_model\", \"T\"], 2]]"}
{"project": "xos-1", "commit_sha": "28897e18068a21ad271adc8200560775512a405c", "parent_sha": "44187013d70d0ed5362f90baa237223c12c9324e", "file_path": "planetstack/openstack/driver.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ class OpenStackDriver:\n             # so we manually delete instances before deleteing the tenant   \n             instances = self.shell.nova_db.instance_get_all_by_filters(ctx, \n                        {'project_id': tenant.id}, 'id', 'asc')\n-            client = OpenStackClient(tenant=tenant)\n+            client = OpenStackClient(tenant=tenant.name)\n             driver = OpenStackDriver(client=client)\n             for instance in instances:\n                 driver.destroy_instance(instance.id)\n", "before": "client = OpenStackClient ( tenant = tenant )", "after": "client = OpenStackClient ( tenant = tenant . name )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 38, 3, 51], [\"attribute\", \"N0\"], 2], [\"Move\", \"N0\", [\"identifier:tenant\", 3, 45, 3, 51], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:name\", \"T\"], 2]]"}
{"project": "flocker", "commit_sha": "cba6e6f2e178395eb5c7d0e75211e8d997ed02fa", "parent_sha": "57faed094becc6c291475fdf5112a760c2409fb7", "file_path": "flocker/route/_iptables.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -251,7 +251,7 @@ def delete_open_port(logger, port):\n     action = DELETE_OPEN_PORT(\n-        logger=logger, target_port=port)\n+        logger=logger, target_port=port.port)\n \n     with action:\n         encoded_port = unicode(port.port).encode(\"ascii\")\n", "before": "action = DELETE_OPEN_PORT ( logger = logger , target_port = port )", "after": "action = DELETE_OPEN_PORT ( logger = logger , target_port = port . port )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"keyword_argument\", 1, 24, 1, 40], [\"attribute\", \"N0\"], 2], [\"Move\", \"N0\", [\"identifier:port\", 1, 36, 1, 40], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:port\", \"T\"], 2]]"}
{"project": "beets", "commit_sha": "540cae0de453de0373958669eda3ddfba10c89c0", "parent_sha": "180a3ece3bcf5527c61d1f987a268128b8670721", "file_path": "beetsplug/thumbnails.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -69,7 +69,7 @@ class ThumbnailsPlugin(BeetsPlugin):\n-        if not ArtResizer.local:\n+        if not ArtResizer.shared.local:\n             self._log.warning(\"No local image resizing capabilities, \"\n                               \"cannot generate thumbnails\")\n             return False\n", "before": "if not ArtResizer . local : self . _log . warning ( \"No local image resizing capabilities, \" \"cannot generate thumbnails\" ) return False", "after": "if not ArtResizer . shared . local : self . _log . warning ( \"No local image resizing capabilities, \" \"cannot generate thumbnails\" ) return False", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 0, 16, 0, 32], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 0, 16, 0, 32], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:ArtResizer\", 0, 16, 0, 26], 0], [\"Move\", \"N0\", [\".:.\", 0, 26, 0, 27], 1], [\"Insert\", \"N0\", [\"identifier:shared\", \"T\"], 2]]"}
{"project": "beets", "commit_sha": "ee6fba1e821792112ddaf9c891b05572c1012fc3", "parent_sha": "f6c6c35614d99a724dfe8b29cae0db953077af0b", "file_path": "beetsplug/missing.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -100,7 +100,7 @@ class MissingPlugin(BeetsPlugin):\n         self._command.parser.add_option('-t', '--total', dest='total',\n                                         action='store_true',\n                                         help='count total of missing tracks')\n-        self._command.add_format_option()\n+        self._command.parser.add_format_option()\n \n     def commands(self):\n         def _miss(lib, opts, args):\n", "before": "self . _command . add_format_option ( )", "after": "self . _command . parser . add_format_option ( )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 9, 3, 22], [\"attribute\", 3, 9, 3, 22], 0], [\"Insert\", [\"attribute\", 3, 9, 3, 22], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 9, 3, 22], [\"identifier:parser\", \"T\"], 2]]"}
{"project": "beets", "commit_sha": "2fe30f11950e4513f09021a44dd708c18852953b", "parent_sha": "f4b95ea1b500dda9257c286277f5e176f93b71a0", "file_path": "beets/library.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -545,7 +545,7 @@ class Library(object):\n         \n         for root, dirs, files in os.walk(path):\n             for filebase in files:\n-                filepath = os.join(root, filebase)\n+                filepath = os.path.join(root, filebase)\n                 try:\n                     Item.from_path(_normpath(filepath), self)\n                 except FileTypeError:\n", "before": "filepath = os . join ( root , filebase )", "after": "filepath = os . path . join ( root , filebase )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 28, 3, 35], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 28, 3, 35], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:os\", 3, 28, 3, 30], 0], [\"Move\", \"N0\", [\".:.\", 3, 30, 3, 31], 1], [\"Insert\", \"N0\", [\"identifier:path\", \"T\"], 2]]"}
{"project": "larray", "commit_sha": "4a3d7602a9d1b456958831f43a67c7fdb2fc8678", "parent_sha": "76be58a6a059ff2dc92e6edb8f46e27a090f664f", "file_path": "larray/core.py", "project_url": "https://github.com/alixdamman/larray", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -874,7 +874,7 @@ class LArray(object):\n         axis = self.get_axis(axis)\n         axes = [Axis(newname, a.labels) if a is axis else a\n                 for a in self.axes]\n-        return LArray(self, axes)\n+        return LArray(self.data, axes)\n \n     def full_key(self, key):\n", "before": "return LArray ( self , axes )", "after": "return LArray ( self . data , axes )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 22, 3, 34], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 23, 3, 27], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:data\", \"T\"], 2]]"}
{"project": "kafka-python", "commit_sha": "e8283958e42047a31bc914fe53b2060fa5e4481b", "parent_sha": "103ac7eb11071395fb566495a4c1e0eb62482263", "file_path": "kafka/conn.py", "project_url": "https://github.com/DataDog/kafka-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -274,7 +274,7 @@ class BrokerConnection(object):\n                     self.afi = self._sock.family\n                     self._gai = None\n             except socket.error as err:\n-                ret = err\n+                ret = err.errno\n \n             # Connection succeeded\n             if not ret or ret == errno.EISCONN:\n", "before": "except socket . error as err : ret = err", "after": "except socket . error as err : ret = err . errno", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"assignment\", 2, 13, 3, 26], [\"attribute\", \"N0\"], 5], [\"Move\", \"N0\", [\"identifier:err\", 3, 23, 3, 26], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:errno\", \"T\"], 2]]"}
{"project": "MCPS-CTFd", "commit_sha": "3a2323b0ae1bbc1ff8c1717ce5f8b8e93acae652", "parent_sha": "be6430be4f685c2297d3816eb4cdf60dc5ac990b", "file_path": "CTFd/admin.py", "project_url": "https://github.com/breadchris/MCPS-CTFd", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -335,7 +335,7 @@ def init_admin(app):\n                 user.name = name\n                 user.email = email\n                 if password:\n-                    user.password = bcrypt_sha256(password)\n+                    user.password = bcrypt_sha256.encrypt(password)\n                 user.website = website\n                 user.affiliation = affiliation\n                 user.country = country\n", "before": "user . password = bcrypt_sha256 ( password )", "after": "user . password = bcrypt_sha256 . encrypt ( password )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"call\", 3, 37, 3, 60], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:bcrypt_sha256\", 3, 37, 3, 50], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:encrypt\", \"T\"], 2]]"}
{"project": "BiblioPixel2", "commit_sha": "ef40d7daa3e2a57b6689b2461cc40ae105ea2a7f", "parent_sha": "9c86a01be6664c4a6bcf718dc6e0f505161a7576", "file_path": "bibliopixel/serial_gamepad.py", "project_url": "https://github.com/ManiacalLabs/BiblioPixel2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -136,7 +136,7 @@ class SerialGamePad(BaseGamePad):\n \n             bits = ord(resp[0]) + (ord(resp[1]) << 8)\n         except IOError:\n-            log.error(\"IO Error Communicatng With Game Pad!\")\n+            log.logger.error(\"IO Error Communicatng With Game Pad!\")\n \n         index = 0\n         result = {}\n", "before": "except IOError : log . error ( \"IO Error Communicatng With Game Pad!\" )", "after": "except IOError : log . logger . error ( \"IO Error Communicatng With Game Pad!\" )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 13, 3, 22], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 13, 3, 22], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:log\", 3, 13, 3, 16], 0], [\"Move\", \"N0\", [\".:.\", 3, 16, 3, 17], 1], [\"Insert\", \"N0\", [\"identifier:logger\", \"T\"], 2]]"}
{"project": "amepah", "commit_sha": "f92d76ecb4ae2f09f79fae2b5b4df19358ada2d7", "parent_sha": "d07f216dd70095bcab1dee06a6982e0b55a1c72c", "file_path": "calibrate_zodi_time.py", "project_url": "https://github.com/berkelem/amepah", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -21,7 +21,7 @@ class Coadder:\n         self.galaxy_mask_inds = np.arange(len(self.galaxy_mask))[self.galaxy_mask]\n \n         self.south_pole_mask = HealpixMap(\"/home/users/mberkeley/wisemapper/data/masks/south_pole_mask.fits\").read_data()\n-        self.south_pole_mask_inds = np.arange(len(self.south_pole_mask))[self.south_pole_mask.mapdata.astype(bool)]\n+        self.south_pole_mask_inds = np.arange(len(self.south_pole_mask.mapdata))[self.south_pole_mask.mapdata.astype(bool)]\n \n         self.numerator = np.zeros_like(self.fsm.mapdata)\n         self.denominator = np.zeros_like(self.fsm.mapdata)\n", "before": "self . south_pole_mask_inds = np . arange ( len ( self . south_pole_mask ) ) [ self . south_pole_mask . mapdata . astype ( bool ) ]", "after": "self . south_pole_mask_inds = np . arange ( len ( self . south_pole_mask . mapdata ) ) [ self . south_pole_mask . mapdata . astype ( bool ) ]", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 51, 3, 71], [\"attribute\", 3, 51, 3, 71], 0], [\"Insert\", [\"attribute\", 3, 51, 3, 71], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 51, 3, 71], [\"identifier:mapdata\", \"T\"], 2]]"}
{"project": "amepah", "commit_sha": "76eb0bf9b134ff3bc4dd02ecd014fb84f9d046a4", "parent_sha": "94c87b57fc875f8b80671e9f75afedca7b408e67", "file_path": "calibrate_zodi_time.py", "project_url": "https://github.com/berkelem/amepah", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -144,7 +144,7 @@ class Coadder:\n             self.normalize()\n             self.save_maps()\n \n-            setattr(Orbit, \"coadd_map\", self.fsm)\n+            setattr(Orbit, \"coadd_map\", self.fsm.mapdata)\n             self.iter += 1\n \n \n", "before": "setattr ( Orbit , \"coadd_map\" , self . fsm )", "after": "setattr ( Orbit , \"coadd_map\" , self . fsm . mapdata )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 41, 3, 49], [\"attribute\", 3, 41, 3, 49], 0], [\"Insert\", [\"attribute\", 3, 41, 3, 49], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 41, 3, 49], [\"identifier:mapdata\", \"T\"], 2]]"}
{"project": "gevent", "commit_sha": "57c4a0930aaa91a51c8e0b60c9802c45f12351d1", "parent_sha": "52824f1820286e2caa4f0623616c72d2c0ca09e3", "file_path": "gevent/_socket3.py", "project_url": "https://github.com/gevent/gevent", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ class socket(object):\n         # Only defined under Linux\n         @property\n         def type(self):\n-            return _socket.socket.type.__get__(self) & ~_socket.SOCK_NONBLOCK\n+            return _socket.socket.type.__get__(self._sock) & ~_socket.SOCK_NONBLOCK\n \n     def __enter__(self):\n         return self\n", "before": "return _socket . socket . type . __get__ ( self ) & ~ _socket . SOCK_NONBLOCK", "after": "return _socket . socket . type . __get__ ( self . _sock ) & ~ _socket . SOCK_NONBLOCK", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 47, 3, 53], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 48, 3, 52], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:_sock\", \"T\"], 2]]"}
{"project": "spiderfoot", "commit_sha": "2a113171e71eb58e72f9d79f4cee1968939ccf99", "parent_sha": "21a16867ae5b74fb433d27d01680dd2e0ef38d9e", "file_path": "modules/sfp_ir.py", "project_url": "https://github.com/smicallef/spiderfoot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -254,7 +254,7 @@ class sfp_ir(SpiderFootPlugin):\n         if eventName.startswith(\"BGP_AS_\"):\r\n             neighs = self.asNeighbours(eventData)\r\n             if neighs == None:\r\n-                self.debug(\"No neighbors found to AS \" + eventData)\r\n+                self.sf.debug(\"No neighbors found to AS \" + eventData)\r\n                 return None\r\n \r\n", "before": "self . debug ( \"No neighbors found to AS \" + eventData )", "after": "self . sf . debug ( \"No neighbors found to AS \" + eventData )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 17, 3, 27], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 17, 3, 27], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 17, 3, 21], 0], [\"Move\", \"N0\", [\".:.\", 3, 21, 3, 22], 1], [\"Insert\", \"N0\", [\"identifier:sf\", \"T\"], 2]]"}
{"project": "spiderfoot", "commit_sha": "0867726bdc1a2b137011dcf045a3df8182b64119", "parent_sha": "8fb7456a5ff726994da96f92543f8c90c9b3022f", "file_path": "modules/sfp_dnsresolve.py", "project_url": "https://github.com/smicallef/spiderfoot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -172,7 +172,7 @@ class sfp_dnsresolve(SpiderFootPlugin):\n                                     m = match[1]\n                                 self.processHost(m, parentEvent, False)\n                     except Exception as e:\n-                        self.error(\"Error applying regex to data (\" + str(e) + \")\", False)\n+                        self.sf.error(\"Error applying regex to data (\" + str(e) + \")\", False)\n \n                     offset += len(name)\n \n", "before": "except Exception as e : self . error ( \"Error applying regex to data (\" + str ( e ) + \")\" , False )", "after": "except Exception as e : self . sf . error ( \"Error applying regex to data (\" + str ( e ) + \")\" , False )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 25, 3, 35], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 25, 3, 35], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 25, 3, 29], 0], [\"Move\", \"N0\", [\".:.\", 3, 29, 3, 30], 1], [\"Insert\", \"N0\", [\"identifier:sf\", \"T\"], 2]]"}
{"project": "spiderfoot", "commit_sha": "5a655a89606eeb1ddff6fd03a660ed366f5ece4d", "parent_sha": "461f03553f20b12f8bc07467f0935955eb69c628", "file_path": "modules/sfp_dnsresolve.py", "project_url": "https://github.com/smicallef/spiderfoot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -175,7 +175,7 @@ class sfp_dnsresolve(SpiderFootPlugin):\n                                     m = match[1]\n                                 self.processHost(m, parentEvent, False)\n                     except Exception as e:\n-                        self.error(\"Error applying regex to data (\" + str(e) + \")\", False)\n+                        self.sf.error(\"Error applying regex to data (\" + str(e) + \")\", False)\n \n                     offset += len(name)\n \n", "before": "except Exception as e : self . error ( \"Error applying regex to data (\" + str ( e ) + \")\" , False )", "after": "except Exception as e : self . sf . error ( \"Error applying regex to data (\" + str ( e ) + \")\" , False )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 25, 3, 35], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 25, 3, 35], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 25, 3, 29], 0], [\"Move\", \"N0\", [\".:.\", 3, 29, 3, 30], 1], [\"Insert\", \"N0\", [\"identifier:sf\", \"T\"], 2]]"}
{"project": "spiderfoot", "commit_sha": "74fb2ea5eb83f8f29456dab7809cc5083abad3bc", "parent_sha": "7e3905cb9d8dc24e142e4796313891347e3ebba1", "file_path": "modules/sfp_countryname.py", "project_url": "https://github.com/smicallef/spiderfoot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -178,7 +178,7 @@ class sfp_countryname(SpiderFootPlugin):\n             return abbvCountryCodes[countryCode.upper()]\n         except:\n             # Region code not present in source phone number\n-            self.debug(\"Skipped invalid phone number: \" + srcPhoneNumber)\n+            self.sf.debug(\"Skipped invalid phone number: \" + srcPhoneNumber)\n             return None\n \n     \n", "before": "except : self . debug ( \"Skipped invalid phone number: \" + srcPhoneNumber )", "after": "except : self . sf . debug ( \"Skipped invalid phone number: \" + srcPhoneNumber )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 13, 3, 23], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 13, 3, 23], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 13, 3, 17], 0], [\"Move\", \"N0\", [\".:.\", 3, 17, 3, 18], 1], [\"Insert\", \"N0\", [\"identifier:sf\", \"T\"], 2]]"}
{"project": "pritunl", "commit_sha": "d4a383f0834067dc2e4785673bc0d1672ce7f5d3", "parent_sha": "f47dd36f90973bc9bda600183d887ccbc3a75f98", "file_path": "pritunl/queue_init_org_pooled.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,7 +52,7 @@ class QueueInitOrgPooled(Queue):\n \n         self.org.running.clear()\n \n-        for process in copy.copy(self.org.processes):\n+        for process in copy.copy(self.org.queue_com.processes):\n             if not process[1]:\n                 process[1] = True\n                 process[0].kill() # TODO test process[0].terminate()\n", "before": "for process in copy . copy ( self . org . processes ) : if not process [ 1 ] : process [ 1 ] = True process [ 0 ] . kill ( )", "after": "for process in copy . copy ( self . org . queue_com . processes ) : if not process [ 1 ] : process [ 1 ] = True process [ 0 ] . kill ( )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 34, 3, 42], [\"attribute\", 3, 34, 3, 42], 0], [\"Insert\", [\"attribute\", 3, 34, 3, 42], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 34, 3, 42], [\"identifier:queue_com\", \"T\"], 2]]"}
{"project": "androguard", "commit_sha": "4af3cfc3928a6b6addd5f5a84c861c7bd541c85b", "parent_sha": "38b208126a03b2e05366e5e9494a263257373849", "file_path": "androguard/core/analysis/sign.py", "project_url": "https://github.com/Ever-Never/androguard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -212,7 +212,7 @@ class Signature(object):\n         strings_method = self.tainted_variables.get_strings_by_method( analysis_method.get_method() )\n         for s in strings_method:\n             for path in strings_method[s]:\n-                l.append( ( path[1], \"S%d\" % len(s) ) )\n+                l.append( ( path[1], \"S%d\" % len(s.var) ) )\n         return l\n \n \n", "before": "l . append ( ( path [ 1 ] , \"S%d\" % len ( s ) ) )", "after": "l . append ( ( path [ 1 ] , \"S%d\" % len ( s . var ) ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 49, 3, 52], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:s\", 3, 50, 3, 51], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:var\", \"T\"], 2]]"}
{"project": "openstates", "commit_sha": "ddace79fe9cd3daa67e30d50633d59f917075a2e", "parent_sha": "ffaa81ed19d260665344564d49e454bd813f8804", "file_path": "openstates/ar/events.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ class AREventScraper(EventScraper):\n \n         url = \"ftp://www.arkleg.state.ar.us/dfadooas/ScheduledMeetings.txt\"\n         page = self.urlopen(url)\n-        page = csv.reader(StringIO.StringIO(page), delimiter='|')\n+        page = csv.reader(StringIO.StringIO(page.bytes), delimiter='|')\n \n         for row in page:\n             desc = row[7].strip()\n", "before": "page = csv . reader ( StringIO . StringIO ( page ) , delimiter = '|' )", "after": "page = csv . reader ( StringIO . StringIO ( page . bytes ) , delimiter = '|' )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 44, 3, 50], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:page\", 3, 45, 3, 49], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:bytes\", \"T\"], 2]]"}
{"project": "molotov", "commit_sha": "1d2dca05758195c113d36666d3fc3ace0a6af8af", "parent_sha": "585f645e37b891326fc4dfbdd9bae20081580a71", "file_path": "molotov/fmwk.py", "project_url": "https://github.com/loads/molotov", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -332,7 +332,7 @@ def runner(args):\n         try:\n             global_setup(args)\n         except Exception as e:\n-            args.shared_console(\"The global_setup() fixture failed\")\n+            args.shared_console.print(\"The global_setup() fixture failed\")\n             args.shared_console.print_error(e)\n             raise\n \n", "before": "args . shared_console ( \"The global_setup() fixture failed\" )", "after": "args . shared_console . print ( \"The global_setup() fixture failed\" )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 13, 3, 32], [\"attribute\", 3, 13, 3, 32], 0], [\"Insert\", [\"attribute\", 3, 13, 3, 32], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 13, 3, 32], [\"identifier:print\", \"T\"], 2]]"}
{"project": "spyne", "commit_sha": "d38faa1cca66f82e14f00e5d5fa5b90382634e8d", "parent_sha": "ca98d47a14a37e3c07dec37819a4156a784fa966", "file_path": "spyne/interface/xml_schema/parser.py", "project_url": "https://github.com/duixteam/spyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -242,7 +242,7 @@ def process_element(ctx, e):\n def process_attribute(ctx, a):\n     if a.ref is not None:\n         t = get_type(ctx, a.ref)\n-        return t.get_type_name(), t\n+        return t.type.get_type_name(), t\n \n     if a.type is not None:\n         t = get_type(ctx, a.type)\n", "before": "return t . get_type_name ( ) , t", "after": "return t . type . get_type_name ( ) , t", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 16, 3, 31], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 16, 3, 31], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:t\", 3, 16, 3, 17], 0], [\"Move\", \"N0\", [\".:.\", 3, 17, 3, 18], 1], [\"Insert\", \"N0\", [\"identifier:type\", \"T\"], 2]]"}
{"project": "pandas", "commit_sha": "da8bc6c47a3d1f772d3e5cec00966b58c646a800", "parent_sha": "cc21b3f94914709a2f7a8ac705d7a623569f4bea", "file_path": "pandas/core/internals.py", "project_url": "https://github.com/jmwoloso/pandas", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1135,7 +1135,7 @@ def _consolidate(blocks, items):\n     \"\"\"\n     Merge blocks having same dtype\n     \"\"\"\n-    get_dtype = lambda x: x.dtype\n+    get_dtype = lambda x: x.dtype.name\n \n     # sort by dtype\n     grouper = itertools.groupby(sorted(blocks, key=get_dtype),\n", "before": "get_dtype = lambda x : x . dtype", "after": "get_dtype = lambda x : x . dtype . name", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 27, 3, 34], [\"attribute\", 3, 27, 3, 34], 0], [\"Insert\", [\"attribute\", 3, 27, 3, 34], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 27, 3, 34], [\"identifier:name\", \"T\"], 2]]"}
{"project": "i3-tomaatti", "commit_sha": "15b364d0dff79eac260792d920ab2b8023615c57", "parent_sha": "ede3631b416adc18be92d04e1c9fa7fdafd6a7ce", "file_path": "tomaatti/internal/tomaatti.py", "project_url": "https://github.com/thuetz/i3-tomaatti", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -59,7 +59,7 @@ class Tomaatti(object):\n \t\t\t\tperiod = self._config.break_duration\n \t\t\ttime_period = timedelta(minutes=period)\n \t\t\tend_time = current_time + time_period\n-\t\t\tself._config = end_time\n+\t\t\tself._config.end_time = end_time\n \n \tdef show_message(self, message: str) -> None:\n \t\tif not self._config.use_overlay:\n", "before": "self . _config = end_time", "after": "self . _config . end_time = end_time", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 4, 3, 16], [\"attribute\", 3, 4, 3, 16], 0], [\"Insert\", [\"attribute\", 3, 4, 3, 16], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 4, 3, 16], [\"identifier:end_time\", \"T\"], 2]]"}
{"project": "i3-tomaatti", "commit_sha": "6a5eb0838d52a911437cae2e08765ccc3b27df29", "parent_sha": "2206c91cb629b3ae74bbeff4b556a8592cf05f4d", "file_path": "tomaatti/internal/configuration.py", "project_url": "https://github.com/thuetz/i3-tomaatti", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -63,7 +63,7 @@ class Configuration(object):\n \n \t@mode.setter\n \tdef mode(self, value: TimerType) -> None:\n-\t\tself._application_config.set('timer', 'mode', str(value))\n+\t\tself._application_config.set('timer', 'mode', str(value.value))\n \t\tself._persist_current_state()\n \n \t@property\n", "before": "self . _application_config . set ( 'timer' , 'mode' , str ( value ) )", "after": "self . _application_config . set ( 'timer' , 'mode' , str ( value . value ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 52, 3, 59], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:value\", 3, 53, 3, 58], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:value\", \"T\"], 2]]"}
{"project": "i3-tomaatti", "commit_sha": "0cdba0cfe7a24b7ef38cb782e3b3cb110e2fbe76", "parent_sha": "6a5eb0838d52a911437cae2e08765ccc3b27df29", "file_path": "tomaatti/internal/configuration.py", "project_url": "https://github.com/thuetz/i3-tomaatti", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -45,7 +45,7 @@ class Configuration(object):\n \t\tself._application_config.add_section('ui')\n \n \t\t# assign the default values to the configuration sections\n-\t\tself._application_config.set('timer', 'mode', str(TimerType.WORKING))\n+\t\tself._application_config.set('timer', 'mode', str(TimerType.WORKING.value))\n \t\tself._application_config.set('timer', 'is_running', ConfigHelper.bool_to_config_str(False))\n \t\tself._application_config.set('timer', 'end_time', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n \n", "before": "self . _application_config . set ( 'timer' , 'mode' , str ( TimerType . WORKING ) )", "after": "self . _application_config . set ( 'timer' , 'mode' , str ( TimerType . WORKING . value ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 53, 3, 70], [\"attribute\", 3, 53, 3, 70], 0], [\"Insert\", [\"attribute\", 3, 53, 3, 70], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 53, 3, 70], [\"identifier:value\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "c43fc2646ef82f663f63b855ada9fa6bb11d165e", "parent_sha": "c7262ff076df07b0d4c062fc4085bac14f9f6b52", "file_path": "Lib/test/test_support.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -106,7 +106,7 @@ def bind_port(sock, host='', preferred_port=54321):\n             sock.bind((host, port))\n             return port\n         except socket.error as e:\n-            (err, msg) = e\n+            (err, msg) = e.args\n             if err != errno.EADDRINUSE:\n                 raise\n             print('  WARNING: failed to listen on port %d, trying another' % port, file=sys.__stderr__)\n", "before": "except socket . error as e : ( err , msg ) = e", "after": "except socket . error as e : ( err , msg ) = e . args", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"assignment\", 2, 9, 3, 27], [\"attribute\", \"N0\"], 5], [\"Move\", \"N0\", [\"identifier:e\", 3, 26, 3, 27], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:args\", \"T\"], 2]]"}
{"project": "cpython", "commit_sha": "a39dd956cd54f0524df91020cbe76ae2b766125e", "parent_sha": "646b1e74d82a584e1979986884e2bdedfa48e1ad", "file_path": "Lib/test/test_logging.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -901,7 +901,7 @@ if threading:\n                     except socket.error:\n                         msg = ('Error during finish, while sending %r, '\n                                'closed = %s')\n-                        print(msg % (data, self._closed), file=sys.stderr)\n+                        print(msg % (data, self.server._closed), file=sys.stderr)\n                         raise\n \n             ThreadingUDPServer.__init__(self, addr, DelegatingUDPRequestHandler,\n", "before": "print ( msg % ( data , self . _closed ) , file = sys . stderr )", "after": "print ( msg % ( data , self . server . _closed ) , file = sys . stderr )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 44, 3, 56], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 44, 3, 56], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 44, 3, 48], 0], [\"Move\", \"N0\", [\".:.\", 3, 48, 3, 49], 1], [\"Insert\", \"N0\", [\"identifier:server\", \"T\"], 2]]"}
{"project": "coursebuilder-core", "commit_sha": "e41919f2d8f62422d8705fda1ef39b2142ef35e2", "parent_sha": "3c598d966529b59c7cbf6e923fe84f3e12805269", "file_path": "coursebuilder/models/entity_transforms.py", "project_url": "https://github.com/imisi-akande/coursebuilder-core", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -74,7 +74,7 @@ def get_schema_for_entity(clazz):\n     suppressed = clazz._get_export_blacklist()\n     registry = schema_fields.FieldRegistry(clazz.__name__)\n     for property_type in available_properties.values():\n-        if property_type not in suppressed:\n+        if property_type.name not in suppressed:\n             registry.add_property(_get_schema_field(property_type))\n     return registry\n \n", "before": "if property_type not in suppressed : registry . add_property ( _get_schema_field ( property_type ) )", "after": "if property_type . name not in suppressed : registry . add_property ( _get_schema_field ( property_type ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 43], [\"attribute\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:property_type\", 3, 12, 3, 25], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:name\", \"T\"], 2]]"}
{"project": "segmentation_simple", "commit_sha": "015d6f904599c75709d66fe584e62139305127fb", "parent_sha": "5735004d6fa0355d5a0a6f809c7f42f802d73ed0", "file_path": "analysis_scripts/Segmentation_Simple.py", "project_url": "https://github.com/glencoesoftware/segmentation_simple", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -153,7 +153,7 @@ def script_main():\n             save_rois = True\n             threshold = DEFAULT_THRESHOLD\n             object_id = '%s:%s' % \\\n-                (script_params['Data_Type'], script_params['IDs'])\n+                (script_params['Data_Type'], script_params['IDs'].val)\n         analyse(client, Arguments())\n     finally:\n         client.closeSession()\n", "before": "object_id = '%s:%s' % ( script_params [ 'Data_Type' ] , script_params [ 'IDs' ] )", "after": "object_id = '%s:%s' % ( script_params [ 'Data_Type' ] , script_params [ 'IDs' ] . val )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"tuple\", 3, 17, 3, 67], [\"attribute\", \"N0\"], 3], [\"Move\", \"N0\", [\"subscript\", 3, 46, 3, 66], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:val\", \"T\"], 2]]"}
{"project": "zipline", "commit_sha": "9e31d830847252923b2512926056a2359b0abbb3", "parent_sha": "dbcfc0a2a588675aa6c2359a1742630229d3fe8c", "file_path": "zipline/transforms/stddev.py", "project_url": "https://github.com/andportnoy/zipline", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -147,7 +147,7 @@ class MovingStandardDevWindow(EventWindow):\n         # Sample standard deviation is undefined for a single event or\n         # no events.\n-        if len(self) <= 1:\n+        if len(self.ticks) <= 1:\n             return None\n \n         else:\n", "before": "if len ( self ) <= 1 : return None else : ", "after": "if len ( self . ticks ) <= 1 : return None else : ", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 15, 2, 21], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 2, 16, 2, 20], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:ticks\", \"T\"], 2]]"}
{"project": "impact-api", "commit_sha": "20acdc021a200a2b771ff51a9b2950a7545cbe16", "parent_sha": "68f3c179f315c69505164581606d133dfb63abc2", "file_path": "web/impact/impact/v1/helpers/model_helper.py", "project_url": "https://github.com/masschallenge/impact-api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -110,7 +110,7 @@ def validate_regex(helper, field, value, regex):\n     if not regex.match(value):\n         helper.errors.append(INVALID_REGEX_ERROR.format(field=field,\n                                                         value=value,\n-                                                        regex=regex))\n+                                                        regex=regex.pattern))\n     return value\n \n \n", "before": "helper . errors . append ( INVALID_REGEX_ERROR . format ( field = field , value = value , regex = regex ) )", "after": "helper . errors . append ( INVALID_REGEX_ERROR . format ( field = field , value = value , regex = regex . pattern ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 57, 3, 68], [\"attribute\", \"N0\"], 2], [\"Move\", \"N0\", [\"identifier:regex\", 3, 63, 3, 68], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:pattern\", \"T\"], 2]]"}
{"project": "smart-cache", "commit_sha": "b0d8ea4d98ed87df2f5476b9e6567f682e8dc0d6", "parent_sha": "d1415ad2c45dbe217390e69c8de8b97c5d9eb72c", "file_path": "Probe/converter/utils.py", "project_url": "https://github.com/Cloud-PG/smart-cache", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ def sort_from_avro(df: 'pd.DataFrame', cur_filename: str, order_folder: str) ->\n     df = df.set_index(\"Filename\")\n     ord_df = ord_df.set_index(\"Filename\")\n     # Reindex\n-    new_index = df.reindex_like(ord_df, method=None).dropna()\n+    new_index = df.reindex_like(ord_df.index, method=None).dropna()\n     df.set_index(new_index, inplace=True)\n     df.reset_index(inplace=True)\n     # Remove duplicate counters\n", "before": "new_index = df . reindex_like ( ord_df , method = None ) . dropna ( )", "after": "new_index = df . reindex_like ( ord_df . index , method = None ) . dropna ( )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 32, 3, 53], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"identifier:ord_df\", 3, 33, 3, 39], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:index\", \"T\"], 2]]"}
{"project": "django-lfs", "commit_sha": "033ac2d4283f86c0c5d7dbeb3f64da1ecc396b38", "parent_sha": "1416afda9b7d83cdad9da4da6f8140078d06886a", "file_path": "lfs/cart/models.py", "project_url": "https://github.com/baffolobill/django-lfs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -95,7 +95,7 @@ class Cart(models.Model):\n         for item in CartItem.objects.filter(cart=self, product=product):\n             item_props = {}\n             for pv in item.properties.all():\n-                item_props[unicode(pv.id)] = pv.value\n+                item_props[unicode(pv.property.id)] = pv.value\n \n             if item_props == properties:\n                 return item\n", "before": "item_props [ unicode ( pv . id ) ] = pv . value", "after": "item_props [ unicode ( pv . property . id ) ] = pv . value", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 36, 3, 41], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 36, 3, 41], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:pv\", 3, 36, 3, 38], 0], [\"Move\", \"N0\", [\".:.\", 3, 38, 3, 39], 1], [\"Insert\", \"N0\", [\"identifier:property\", \"T\"], 2]]"}
{"project": "django-lfs", "commit_sha": "7592fcd8c8d0177ecf7887c0584a4546d55b1e8d", "parent_sha": "1e3334f1ba4d042510add11fbe837ad2521fe02d", "file_path": "lfs/cart/utils.py", "project_url": "https://github.com/baffolobill/django-lfs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ def get_cart(request):\n \n     if user.is_authenticated():\n         try:\n-            cache_key = \"%s-cart-%s\" % (settings.CACHE_MIDDLEWARE_KEY_PREFIX, user)\n+            cache_key = \"%s-cart-%s\" % (settings.CACHE_MIDDLEWARE_KEY_PREFIX, user.pk)\n             cart = cache.get(cache_key)\n             if cart is None:\n                 cart = Cart.objects.get(user=user)\n", "before": "cache_key = \"%s-cart-%s\" % ( settings . CACHE_MIDDLEWARE_KEY_PREFIX , user )", "after": "cache_key = \"%s-cart-%s\" % ( settings . CACHE_MIDDLEWARE_KEY_PREFIX , user . pk )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"tuple\", 3, 40, 3, 84], [\"attribute\", \"N0\"], 3], [\"Move\", \"N0\", [\"identifier:user\", 3, 79, 3, 83], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:pk\", \"T\"], 2]]"}
{"project": "django-lfs", "commit_sha": "036393feb5bbd25d92e3c168d9bb48416bc0eea4", "parent_sha": "398da2ceb2282870f3de5dc1183e3ccec0772f71", "file_path": "lfs/caching/listeners.py", "project_url": "https://github.com/baffolobill/django-lfs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -243,7 +243,7 @@ def update_product_cache(instance):\n def update_cart_cache(instance):\n     \"\"\"Deletes all cart relevant caches.\n     \"\"\"\n-    cache.delete(\"%s-cart-%s\" % (settings.CACHE_MIDDLEWARE_KEY_PREFIX, instance.user))\n+    cache.delete(\"%s-cart-%s\" % (settings.CACHE_MIDDLEWARE_KEY_PREFIX, instance.user.pk))\n     cache.delete(\"%s-cart-%s\" % (settings.CACHE_MIDDLEWARE_KEY_PREFIX, instance.session))\n     cache.delete(\"%s-cart-items-%s\" % (settings.CACHE_MIDDLEWARE_KEY_PREFIX, instance.id))\n     cache.delete(\"%s-cart-costs-True-%s\" % (settings.CACHE_MIDDLEWARE_KEY_PREFIX, instance.id))\n", "before": "cache . delete ( \"%s-cart-%s\" % ( settings . CACHE_MIDDLEWARE_KEY_PREFIX , instance . user ) )", "after": "cache . delete ( \"%s-cart-%s\" % ( settings . CACHE_MIDDLEWARE_KEY_PREFIX , instance . user . pk ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 72, 3, 85], [\"attribute\", 3, 72, 3, 85], 0], [\"Insert\", [\"attribute\", 3, 72, 3, 85], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 72, 3, 85], [\"identifier:pk\", \"T\"], 2]]"}
{"project": "django-lfs", "commit_sha": "9f3c67d9886eae32d5d5bd8ae7e9ed875f870f72", "parent_sha": "e8d345c698583f74e6ad14c3a4a4b0c5dd5d8022", "file_path": "lfs/manage/product/product.py", "project_url": "https://github.com/baffolobill/django-lfs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -452,7 +452,7 @@ def edit_product_data(request, product_id, template_name=\"manage/product/data.ht\n     else:\n         message = _(u\"Please correct the indicated errors.\")\n \n-    pagination_form = PaginationDataForm(data={'page': page})\n+    pagination_form = PaginationDataForm(data={'page': page.number})\n \n     form_html = render_to_string(template_name, RequestContext(request, {\n         \"product\": product,\n", "before": "pagination_form = PaginationDataForm ( data = { 'page' : page } )", "after": "pagination_form = PaginationDataForm ( data = { 'page' : page . number } )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"pair\", 3, 48, 3, 60], [\"attribute\", \"N0\"], 2], [\"Move\", \"N0\", [\"identifier:page\", 3, 56, 3, 60], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:number\", \"T\"], 2]]"}
{"project": "beba-ctrl", "commit_sha": "c46fdc6bf1327100567b91d5f4986aaa35950660", "parent_sha": "fc05f44eaf9580c90a1df94990d2c4b6e3822dad", "file_path": "ryu/app/simple_switch.py", "project_url": "https://github.com/beba-eu/beba-ctrl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -84,7 +84,7 @@ class SimpleSwitch(app_manager.RyuApp):\n     def _port_status_handler(self, ev):\n         msg = ev.msg\n         reason = msg.reason\n-        port_no = msg.port_no\n+        port_no = msg.desc.port_no\n \n         ofproto = msg.datapath.ofproto\n         if reason == ofproto.OFPPR_ADD:\n", "before": "port_no = msg . port_no", "after": "port_no = msg . desc . port_no", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 19, 3, 30], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 19, 3, 30], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:msg\", 3, 19, 3, 22], 0], [\"Move\", \"N0\", [\".:.\", 3, 22, 3, 23], 1], [\"Insert\", \"N0\", [\"identifier:desc\", \"T\"], 2]]"}
{"project": "tomes-tagger", "commit_sha": "9627f4938d18d95a3eb3487aaf9e33e6c76c9b53", "parent_sha": "9035968a0972b14c15287347aeb9aed18b735097", "file_path": "html_to_text/html_to_text.py", "project_url": "https://github.com/StateArchivesOfNorthCarolina/tomes-tagger", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -17,7 +17,7 @@ class BeautifulSoup_TOMES(BeautifulSoup):\n \n         a_tags = self.find_all(\"a\")\n         for a_tag in a_tags:\n-            if \"href\" not in a_tag:\n+            if \"href\" not in a_tag.attrs:\n                 continue\n             href = a_tag[\"href\"]\n             text = a_tag.string + \" [\" + href + \"]\"  \n", "before": "if \"href\" not in a_tag : continue", "after": "if \"href\" not in a_tag . attrs : continue", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 35], [\"attribute\", \"N0\"], 3], [\"Move\", \"N0\", [\"identifier:a_tag\", 3, 30, 3, 35], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:attrs\", \"T\"], 2]]"}
{"project": "praw", "commit_sha": "fc6c3a7f68252710861bcda25d7535876d13d983", "parent_sha": "8039e71069e326751a02435f1f68ce4952135919", "file_path": "reddit/redditor.py", "project_url": "https://github.com/SIlver--/praw", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -64,7 +64,7 @@ class Redditor(RedditContentObject):\n     @require_login\n     def get_my_reddits(self, limit=DEFAULT_CONTENT_LIMIT):\n         \"\"\"Return all of the current user's subreddits.\"\"\"\n-        return self._get_content(urls[\"my_reddits\"], limit=limit)\n+        return self.reddit_session._get_content(urls[\"my_reddits\"], limit=limit)\n \n     @require_login\n     def friend(self):\n", "before": "return self . _get_content ( urls [ \"my_reddits\" ] , limit = limit )", "after": "return self . reddit_session . _get_content ( urls [ \"my_reddits\" ] , limit = limit )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 16, 3, 33], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 16, 3, 33], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:self\", 3, 16, 3, 20], 0], [\"Move\", \"N0\", [\".:.\", 3, 20, 3, 21], 1], [\"Insert\", \"N0\", [\"identifier:reddit_session\", \"T\"], 2]]"}
{"project": "ubuntu-tweak", "commit_sha": "a9306f01fb0d5a6530de43c8e32f007e13cbd430", "parent_sha": "4962ab91868342c13101bbe123b71929f7786b2d", "file_path": "src/cleaner.py", "project_url": "https://github.com/muzena/ubuntu-tweak", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -253,7 +253,7 @@ class PackageView(gtk.TreeView):\n             model.set(iter,\n                    COLUMN_CHECK, False,\n                    COLUMN_ICON, icon,\n-                   COLUMN_NAME, pkg,\n+                   COLUMN_NAME, pkg.name,\n                    COLUMN_DESC, 0,\n                    COLUMN_DISPLAY, '<b>%s</b>\\n%s' % (pkg.name, pkg.des),\n                 )\n", "before": "model . set ( iter , COLUMN_CHECK , False , COLUMN_ICON , icon , COLUMN_NAME , pkg , COLUMN_DESC , 0 , COLUMN_DISPLAY , '<b>%s</b>\\n%s' % ( pkg . name , pkg . des ) , )", "after": "model . set ( iter , COLUMN_CHECK , False , COLUMN_ICON , icon , COLUMN_NAME , pkg . name , COLUMN_DESC , 0 , COLUMN_DISPLAY , '<b>%s</b>\\n%s' % ( pkg . name , pkg . des ) , )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 0, 22, 6, 18], [\"attribute\", \"N0\"], 13], [\"Move\", \"N0\", [\"identifier:pkg\", 3, 33, 3, 36], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:name\", \"T\"], 2]]"}
{"project": "electrum", "commit_sha": "29b9d6fa6109fcf931c28199382cc020acb01c7c", "parent_sha": "2ea78f7f3b233cfcd85742e746c61d53d3254cfe", "file_path": "plugins/email_requests/qt.py", "project_url": "https://github.com/UnitedBitcoin/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -127,7 +127,7 @@ class Plugin(BasePlugin):\n             self.processor = Processor(self.imap_server, self.username, self.password, self.on_receive)\n             self.processor.start()\n         self.obj = QEmailSignalObject()\n-        self.obj.email_new_invoice_signal(self.new_invoice)\n+        self.obj.email_new_invoice_signal.connect(self.new_invoice)\n \n     def on_receive(self, pr_str):\n         self.print_error('received payment request')\n", "before": "self . obj . email_new_invoice_signal ( self . new_invoice )", "after": "self . obj . email_new_invoice_signal . connect ( self . new_invoice )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 9, 3, 42], [\"attribute\", 3, 9, 3, 42], 0], [\"Insert\", [\"attribute\", 3, 9, 3, 42], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 9, 3, 42], [\"identifier:connect\", \"T\"], 2]]"}
{"project": "electrum", "commit_sha": "5059898af2c012050fe2aabcce12dfe5f1078820", "parent_sha": "5e61ff18ac29ae303fbb0d9479d2824d7fcaf6ec", "file_path": "lib/util.py", "project_url": "https://github.com/UnitedBitcoin/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -602,7 +602,7 @@ def create_URI(addr, amount, message):\n     if message:\n         if six.PY2 and type(message) == unicode:\n             message = message.encode('utf8')\n-        query.append('message=%s'%urllib.quote(message))\n+        query.append('message=%s'%urllib.parse.quote(message))\n     p = urllib_parse.ParseResult(scheme='bitcoin', netloc='', path=addr, params='', query='&'.join(query), fragment='')\n     return urllib_parse.urlunparse(p)\n \n", "before": "query . append ( 'message=%s' % urllib . quote ( message ) )", "after": "query . append ( 'message=%s' % urllib . parse . quote ( message ) )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 35, 3, 47], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 35, 3, 47], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:urllib\", 3, 35, 3, 41], 0], [\"Move\", \"N0\", [\".:.\", 3, 41, 3, 42], 1], [\"Insert\", \"N0\", [\"identifier:parse\", \"T\"], 2]]"}
{"project": "electrum", "commit_sha": "9302cea7254f08ac5bc471eb34e76d4dbbcde56a", "parent_sha": "a62dab9962c809de762530affa809ed51b20f879", "file_path": "lib/wallet.py", "project_url": "https://github.com/UnitedBitcoin/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -452,7 +452,7 @@ class Abstract_Wallet(PrintError):\n                     if fee:\n                         size = tx.estimated_size()\n                         fee_per_kb = fee * 1000 / size\n-                        exp_n = self.network.reverse_dynfee(fee_per_kb)\n+                        exp_n = self.network.config.reverse_dynfee(fee_per_kb)\n                     can_bump = is_mine and not tx.is_final()\n             else:\n                 status = _(\"Signed\")\n", "before": "exp_n = self . network . reverse_dynfee ( fee_per_kb )", "after": "exp_n = self . network . config . reverse_dynfee ( fee_per_kb )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 33, 3, 45], [\"attribute\", 3, 33, 3, 45], 0], [\"Insert\", [\"attribute\", 3, 33, 3, 45], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 33, 3, 45], [\"identifier:config\", \"T\"], 2]]"}
{"project": "electrum", "commit_sha": "cbeaa52101994374b991633c49090e47ca03e39d", "parent_sha": "50fdc6fe4eb4d3fc4bd927468a5ecbab315d0e8c", "file_path": "gui/kivy/uix/screens.py", "project_url": "https://github.com/UnitedBitcoin/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -435,7 +435,7 @@ class InvoicesScreen(CScreen):\n         amount = pr.get_amount()\n         if amount:\n             ci.amount = self.app.format_amount_and_units(amount)\n-            status = self.app.invoices.get_status(ci.key)\n+            status = self.app.wallet.invoices.get_status(ci.key)\n             ci.status = invoice_text[status]\n             ci.icon = pr_icon[status]\n         else:\n", "before": "status = self . app . invoices . get_status ( ci . key )", "after": "status = self . app . wallet . invoices . get_status ( ci . key )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 22, 3, 30], [\"attribute\", 3, 22, 3, 30], 0], [\"Insert\", [\"attribute\", 3, 22, 3, 30], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 22, 3, 30], [\"identifier:wallet\", \"T\"], 2]]"}
{"project": "dat-banana-bot", "commit_sha": "cb14c316894c26d25ffa9a3d4f886c3f25a57631", "parent_sha": "bb72b1c7534b02fac2a667f7b07889ada63b17c2", "file_path": "cogs/cr.py", "project_url": "https://github.com/bananaboy21/dat-banana-bot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ class CR:\n         with open('data/apikeys.json') as f:\r\n             lol = json.load(f)\r\n             self.token = lol['crapi']\r\n-        self.client = clashroyale.Client(token=self.token, is_async=True)\r\n+        self.client = clashroyale.royaleapi.Client(token=self.token, is_async=True)\r\n         self.cards = ['Ice Wizard', 'Hunter', 'Dart Goblin', 'Balloon', 'Skeleton Army', 'Royal Giant', 'Battle Ram', 'Minions', 'Bandit', 'Arrows', 'Mega Knight', 'Baby Dragon', 'Heal', 'Witch', 'Archers', 'Barbarians', 'Wizard', 'Rage', 'Guards', 'Giant Skeleton', 'Skeletons', 'Inferno Tower', 'Spear Goblins', 'Furnace', 'Cannon Cart', 'P.E.K.K.A', 'Bomber', 'Sparky', 'Ice Golem', 'Graveyard', 'Clone', 'Poison', 'Lightning', 'Cannon', 'Knight', 'Royal Ghost', 'Tesla', 'Dark Prince', 'Bomb Tower', 'Skeleton Barrel', 'Prince', 'Electro Wizard', 'Mega Minion',\r\n                       'Musketeer', 'Giant', 'Mirror', 'Bowler', 'Mortar', 'Lava Hound', 'Rocket', 'Tornado', 'Night Witch', 'Goblin Hut', 'Fire Spirits', 'Tombstone', 'Princess', 'Barbarian Hut', 'Goblins', 'Valkyrie', 'The Log', 'Freeze', 'Inferno Dragon', 'Goblin Barrel', 'Lumberjack', 'Three Musketeers', 'Miner', 'X-Bow', 'Ice Spirit', 'Flying Machine', 'Executioner', 'Zappies', 'Elixir Collector', 'Golem', 'Magic Archer', 'Barbarian Barrel', 'Rascals', 'Mini P.E.K.K.A', 'Hog Rider', 'Minion Horde', 'Fireball', 'Goblin Gang', 'Elite Barbarians', 'Bats', 'Zap']\r\n \r\n", "before": "self . client = clashroyale . Client ( token = self . token , is_async = True )", "after": "self . client = clashroyale . royaleapi . Client ( token = self . token , is_async = True )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 23, 3, 41], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 23, 3, 41], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:clashroyale\", 3, 23, 3, 34], 0], [\"Move\", \"N0\", [\".:.\", 3, 34, 3, 35], 1], [\"Insert\", \"N0\", [\"identifier:royaleapi\", \"T\"], 2]]"}
{"project": "sunpy", "commit_sha": "4ea8c8e241dcbee6fc6b85c55d57ae61c92ec354", "parent_sha": "2f1008f4d3bcf5c69d7427a3e606b33f94a76657", "file_path": "sunpy/tests/map/test_map_factory.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -62,10 +62,10 @@ class TestMap:\n         #Custom Map\n         data = np.arange(0,100).reshape(10,10)\n         header = {'cdelt1': 10, 'cdelt2': 10, 'telescop':'sunpy'}\n-        pair_map = sunpy.Map(data, header)\n+        pair_map = sunpy.map.Map(data, header)\n         assert isinstance(pair_map, sunpy.map.GenericMap)\n-         \n-    \n+\n+\n     def test_save(self):\n         #Test save out\n", "before": "pair_map = sunpy . Map ( data , header )", "after": "pair_map = sunpy . map . Map ( data , header )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 20, 3, 29], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 20, 3, 29], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:sunpy\", 3, 20, 3, 25], 0], [\"Move\", \"N0\", [\".:.\", 3, 25, 3, 26], 1], [\"Insert\", \"N0\", [\"identifier:map\", \"T\"], 2]]"}
{"project": "sunpy", "commit_sha": "ef8a2e74477871cf8301d7cddd1602b388ee98d0", "parent_sha": "51b2f4540bbcc65bb2e1815c552d4414e63411b6", "file_path": "sunpy/tests/net/test_helioviewer.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,5 +56,5 @@ class TestHelioviewerClient:\n         filepath = self.client.download_jp2('2020/01/01', observatory='SOHO', \n                                             instrument='MDI', detector='MDI',\n                                             measurement='continuum')\n-        map_ = sunpy.Map(filepath)\n+        map_ = sunpy.map.Map(filepath)\n         assert isinstance(map_, sunpy.map.GenericMap)\n", "before": "map_ = sunpy . Map ( filepath )", "after": "map_ = sunpy . map . Map ( filepath )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 16, 3, 25], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 16, 3, 25], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:sunpy\", 3, 16, 3, 21], 0], [\"Move\", \"N0\", [\".:.\", 3, 21, 3, 22], 1], [\"Insert\", \"N0\", [\"identifier:map\", \"T\"], 2]]"}
{"project": "sunpy", "commit_sha": "d10b784c8af71a8ec36bac74d38a3a565b6e2161", "parent_sha": "62fb4b32afadfb2f2aafa680e57e30a44980ed7d", "file_path": "sunpy/map/tests/test_mapbase.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -416,7 +416,7 @@ def test_plot_aia171(aia171_test_map):\n \n @figure_test\n def test_plot_masked_aia171(aia171_test_map):\n-    shape = aia171_test_map.shape\n+    shape = aia171_test_map.data.shape\n     mask = np.zeros_like(aia171_test_map.data, dtype=bool)\n     mask[0:shape[0]/2, 0:shape[1]/2] = True\n     masked_map = sunpy.map.Map(np.ma.array(aia171_test_map.data, mask=mask), aia171_test_map.meta)\n", "before": "shape = aia171_test_map . shape", "after": "shape = aia171_test_map . data . shape", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"attribute\", 3, 13, 3, 34], [\"attribute\", \"N0\"], 0], [\"Insert\", [\"attribute\", 3, 13, 3, 34], [\".:.\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:aia171_test_map\", 3, 13, 3, 28], 0], [\"Move\", \"N0\", [\".:.\", 3, 28, 3, 29], 1], [\"Insert\", \"N0\", [\"identifier:data\", \"T\"], 2]]"}
{"project": "sunpy", "commit_sha": "626a70c4836737c254aa09d228d63875a709346a", "parent_sha": "9e8fa8ac37e87d2acd1e9c861f70be6bf625a4ca", "file_path": "sunpy/timeseries/sources/fermi_gbm.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -120,7 +120,7 @@ class GBMSummaryTimeSeries(GenericTimeSeries):\n         gbm_times = []\n         # get the time information in datetime format with the correct MET adjustment\n         for t in count_data['time']:\n-            gbm_times.append(fermi.met_to_utc(t))\n+            gbm_times.append(fermi.met_to_utc(t).datetime)\n         column_labels = ['4-15 keV', '15-25 keV', '25-50 keV', '50-100 keV',\n                          '100-300 keV', '300-800 keV', '800-2000 keV']\n \n", "before": "gbm_times . append ( fermi . met_to_utc ( t ) )", "after": "gbm_times . append ( fermi . met_to_utc ( t ) . datetime )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 29, 3, 50], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 30, 3, 49], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:datetime\", \"T\"], 2]]"}
{"project": "astroid", "commit_sha": "9e066881ffaacc4df1d7d470df0324ea57ee5aff", "parent_sha": "0d829e6d17b915421cf39897fe528ff029fe39ab", "file_path": "brain/py2stdlib.py", "project_url": "https://github.com/PCManticore/astroid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -201,7 +201,7 @@ def infer_named_tuple(node, context=None):\n     # we want to return a Class node instance with proper attributes set\n     class_node = nodes.Class(name, 'docstring')\n     # set base class=tuple\n-    class_node.bases.append(nodes.Tuple)\n+    class_node.bases.append(nodes.Tuple._proxied)\n     # XXX add __init__(*attributes) method\n     for attr in attributes:\n         fake_node = nodes.EmptyNode()\n", "before": "class_node . bases . append ( nodes . Tuple )", "after": "class_node . bases . append ( nodes . Tuple . _proxied )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Move\", [\"attribute\", 3, 29, 3, 40], [\"attribute\", 3, 29, 3, 40], 0], [\"Insert\", [\"attribute\", 3, 29, 3, 40], [\".:.\", \"T\"], 1], [\"Insert\", [\"attribute\", 3, 29, 3, 40], [\"identifier:_proxied\", \"T\"], 2]]"}
{"project": "OoT-Randomizer", "commit_sha": "bf1ba754c08e1af44162dd03e5b593ac497f7614", "parent_sha": "6c0319bdc004eaaa961c34650046e4360b11987b", "file_path": "Patches.py", "project_url": "https://github.com/TestRunnerSRL/OoT-Randomizer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1637,7 +1637,7 @@ def place_shop_items(rom, world, shop_items, messages, locations, init_shop_id=F\n \n             # bottles in shops should look like empty bottles\n             # so that that are different than normal shop refils\n-            if 'Bottle' in item_display:\n+            if 'Bottle' in item_display.name:\n                 rom_item = read_rom_item(rom, 0x0F)\n             else:\n                 rom_item = read_rom_item(rom, item_display.index)\n", "before": "if 'Bottle' in item_display : rom_item = read_rom_item ( rom , 0x0F ) else : rom_item = read_rom_item ( rom , item_display . index )", "after": "if 'Bottle' in item_display . name : rom_item = read_rom_item ( rom , 0x0F ) else : rom_item = read_rom_item ( rom , item_display . index )", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 40], [\"attribute\", \"N0\"], 2], [\"Move\", \"N0\", [\"identifier:item_display\", 3, 28, 3, 40], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:name\", \"T\"], 2]]"}
{"project": "toppra", "commit_sha": "8de2167f0046daa2100dcfc92d9dc075752c3daa", "parent_sha": "214942d122d85dd33107f0d7a96332bd89f2a831", "file_path": "toppra/simplepath.py", "project_url": "https://github.com/hungpham2511/toppra", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ class SimplePath(AbstractGeometricPath):\n     def __call__(self, xi, order=0):\n         \"\"\"Evaluate the path at given position.\"\"\"\n         ret = [poly.derivative(order)(xi) for poly in self._polys]\n-        return np.array(ret)\n+        return np.array(ret).T\n \n     @property\n     def dof(self):\n", "before": "return np . array ( ret )", "after": "return np . array ( ret ) . T", "sstub_pattern": "ADD_ATTRIBUTE_ACCESS", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 9, 3, 29], [\"attribute\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 29], 0], [\"Insert\", \"N0\", [\".:.\", \"T\"], 1], [\"Insert\", \"N0\", [\"identifier:T\", \"T\"], 2]]"}
{"project": "alipay-python-sdk", "commit_sha": "d9427fdba85e948d1cd3e4547186ca2d8223eaa7", "parent_sha": "af6dfa18ba410a4dc3b08d831caa196f88228ac5", "file_path": "src/alipay/__init__.py", "project_url": "https://github.com/bowenpay/alipay-python-sdk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -127,7 +127,7 @@ class Alipay(object):\n     def check_notify_remotely(self, **kw):\n         remote_result = requests.get(self.NOTIFY_GATEWAY_URL % (self.pid, kw['notify_id']),\n                                      headers={'connection': 'close'}).text\n-        return remote_result is 'true'\n+        return remote_result == 'true'\n \n '''Wap\u652f\u4ed8\u63a5\u53e3'''\n \n", "before": "return remote_result is 'true'", "after": "return remote_result == 'true'", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 39], [\"==:==\", \"T\"], 1], [\"Delete\", [\"is:is\", 3, 30, 3, 32]]]"}
{"project": "CloudBot", "commit_sha": "6ce8476e06c75539acf5bd219d0079b3414527b7", "parent_sha": "a8342bd37b5faee65753e915949c3162463627b4", "file_path": "plugins/github.py", "project_url": "https://github.com/MrW24/CloudBot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ def issues(text):\n         user         = j[\"user\"][\"login\"]\n         title        = j[\"title\"]\n         summary      = textutils.truncate(j[\"body\"])\n-        if j[\"state\"] is \"open\":\n+        if j[\"state\"] == \"open\":\n             state    = \"\\x033\\x02OPEN\\x02\\x0f\"\n         else:\n             state    = \"\\x034\\x02CLOSED\\x02\\x0f by {}\".format(j[\"closed_by\"][\"login\"])\n", "before": "if j [ \"state\" ] is \"open\" : state = \"\\x033\\x02OPEN\\x02\\x0f\" else : state = \"\\x034\\x02CLOSED\\x02\\x0f by {}\" . format ( j [ \"closed_by\" ] [ \"login\" ] )", "after": "if j [ \"state\" ] == \"open\" : state = \"\\x033\\x02OPEN\\x02\\x0f\" else : state = \"\\x034\\x02CLOSED\\x02\\x0f by {}\" . format ( j [ \"closed_by\" ] [ \"login\" ] )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 32], [\"==:==\", \"T\"], 1], [\"Delete\", [\"is:is\", 3, 23, 3, 25]]]"}
{"project": "tribler", "commit_sha": "247b83c697fd30a28acee1b4e4341001ae3ccb16", "parent_sha": "c1f113efbe469bdcac76426394b63fcb0902f73c", "file_path": "Tribler/Core/dispersy/timeline.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ class Timeline(object):\n             from message import Message\n         assert isinstance(meta, Message)\n         assert isinstance(global_time, (int, long))\n-        assert global_time > 0\n+        assert global_time >= 0\n         assert isinstance(permission, unicode)\n         assert permission in (u'permit', u'authorize', u'revoke')\n         return self._check(self._community.my_member, global_time if global_time else self._community.global_time, permission)\n", "before": "assert global_time > 0", "after": "assert global_time >= 0", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 31], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 28, 3, 29]]]"}
{"project": "mwhois", "commit_sha": "b1142adf3d88c054ebecd89cbfadea10145424e7", "parent_sha": "dbdff0642e7e89a22692bc183ee45b629328c8a3", "file_path": "src/whoconnect.py", "project_url": "https://github.com/jrosco/mwhois", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ class WhoisServerConnection():\n         \n         self.whoinfo.get_whois_server()\n         \n-        if self.whoinfo.whoisserver != None or self.whoinfo.whoiserver == '':\n+        if self.whoinfo.whoisserver != None or self.whoinfo.whoiserver != '':\n             \n             self.logger.debug('sleep for %f', self.sleep)\n             time.sleep(self.sleep)\n", "before": "if self . whoinfo . whoisserver != None or self . whoinfo . whoiserver == '' : self . logger . debug ( 'sleep for %f' , self . sleep ) time . sleep ( self . sleep )", "after": "if self . whoinfo . whoisserver != None or self . whoinfo . whoiserver != '' : self . logger . debug ( 'sleep for %f' , self . sleep ) time . sleep ( self . sleep )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 48, 3, 77], [\"!=:!=\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 72, 3, 74]]]"}
{"project": "tribler", "commit_sha": "803a134153d974983d222755d1e84681e23507f0", "parent_sha": "16c8cefa30e983963c94de4fb1e551a00e01b0b4", "file_path": "Tribler/Core/RemoteTorrentHandler.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -144,7 +144,7 @@ class RemoteTorrentHandler(TaskManager):\n         infohash = tdef.get_infohash()\n         infohash_str = hexlify(infohash)\n \n-        if self.session.lm.torrent_store == None:\n+        if self.session.lm.torrent_store is None:\n             self._logger.error(\"Torrent store is not loaded\")\n             return\n \n", "before": "if self . session . lm . torrent_store == None : self . _logger . error ( \"Torrent store is not loaded\" ) return", "after": "if self . session . lm . torrent_store is None : self . _logger . error ( \"Torrent store is not loaded\" ) return", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 49], [\"is:is\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 42, 3, 44]]]"}
{"project": "tribler", "commit_sha": "dca03aae82ee73208a777135043405e7297605be", "parent_sha": "cc0beadd9fb71a82bfe9d71af7346f6fa10c7edb", "file_path": "Tribler/TrackerChecking/TrackerSession.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -745,7 +745,7 @@ class UdpTrackerSession(TrackerSession):\n             return\n \n         # get results\n-        if len(response) - 8 < len(self._infohash_list) * 12:\n+        if len(response) - 8 != len(self._infohash_list) * 12:\n             self._logger.debug('UDP SCRAPE response mismatch: [%s]', response)\n             self.setFailed()\n             return\n", "before": "if len ( response ) - 8 < len ( self . _infohash_list ) * 12 : self . _logger . debug ( 'UDP SCRAPE response mismatch: [%s]' , response ) self . setFailed ( ) return", "after": "if len ( response ) - 8 != len ( self . _infohash_list ) * 12 : self . _logger . debug ( 'UDP SCRAPE response mismatch: [%s]' , response ) self . setFailed ( ) return", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 61], [\"!=:!=\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 30, 3, 31]]]"}
{"project": "more-executors", "commit_sha": "1bd40bf1e19cf43c3c825ed0b1632559c189dec5", "parent_sha": "a450ff62d3825de2f9d53bab730213aeea01ffc2", "file_path": "more_executors/retry.py", "project_url": "https://github.com/rohanpm/more-executors", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -253,7 +253,7 @@ class RetryExecutor(Executor):\n                 continue\n \n             now = monotonic()\n-            if job.when < now:\n+            if job.when <= now:\n                 # Can submit immediately and check for next job\n                 self._submit_now(job)\n                 continue\n", "before": "if job . when < now : self . _submit_now ( job ) continue", "after": "if job . when <= now : self . _submit_now ( job ) continue", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 30], [\"<=:<=\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 25, 3, 26]]]"}
{"project": "pycocoevalcap", "commit_sha": "e68226536d283a16aa8e6ea5c4cd80d8b1cdca11", "parent_sha": "3121d7edbd3d9af5b99ef5494798916204761c4c", "file_path": "pycocoevalcap/cider/cider_scorer.py", "project_url": "https://github.com/salaniz/pycocoevalcap", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -174,7 +174,7 @@ class CiderScorer(object):\n         # compute idf\n         self.compute_doc_freq()\n         # assert to check document frequency\n-        assert(len(self.ctest)>max(self.document_frequency.values()))\n+        assert(len(self.ctest)>=max(self.document_frequency.values()))\n         # compute cider score\n         score = self.compute_cider()\n \n", "before": "assert ( len ( self . ctest ) > max ( self . document_frequency . values ( ) ) )", "after": "assert ( len ( self . ctest ) >= max ( self . document_frequency . values ( ) ) )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 69], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 31, 3, 32]]]"}
{"project": "bdd-data", "commit_sha": "f41aef478e6543a8c20912c1a45fb26dca34b483", "parent_sha": "a4d82b4b006a15a92a97a6488805b87f1f391f1d", "file_path": "bdd_data/label2det.py", "project_url": "https://github.com/ucbdrive/bdd-data", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ def label2det(label):\n             if 'box2d' not in obj:\n                 continue\n             xy = obj['box2d']\n-            if xy['x1'] >= xy['x2'] and xy['y1'] >= xy['y2']:\n+            if xy['x1'] >= xy['x2'] or xy['y1'] >= xy['y2']:\n                 continue\n             box = {'name': label['name'],\n                    'timestamp': frame['timestamp'],\n", "before": "if xy [ 'x1' ] >= xy [ 'x2' ] and xy [ 'y1' ] >= xy [ 'y2' ] : continue", "after": "if xy [ 'x1' ] >= xy [ 'x2' ] or xy [ 'y1' ] >= xy [ 'y2' ] : continue", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 16, 3, 61], [\"or:or\", \"T\"], 1], [\"Delete\", [\"and:and\", 3, 37, 3, 40]]]"}
{"project": "cc-utils", "commit_sha": "cc29650bd965937a47dd8c3720cde589bd4a188c", "parent_sha": "a968068420d63445fbb28da14d1a4949125fb42d", "file_path": "ctx.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ args=None # the parsed command line arguments\n \n def _cfg_factory_from_dir():\n     # XXX: args does always have a cfg_dir attribute, but pylint does not always understand this\n-    if not args or not hasattr(args, 'cfg_dir') and not getattr(args, 'cfg_dir'):\n+    if not args or not hasattr(args, 'cfg_dir') or not getattr(args, 'cfg_dir'):\n         return None\n \n     from util import ensure_directory_exists\n", "before": "if not args or not hasattr ( args , 'cfg_dir' ) and not getattr ( args , 'cfg_dir' ) : return None", "after": "if not args or not hasattr ( args , 'cfg_dir' ) or not getattr ( args , 'cfg_dir' ) : return None", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 24, 3, 81], [\"or:or\", \"T\"], 1], [\"Delete\", [\"and:and\", 3, 49, 3, 52]]]"}
{"project": "pros-cli3", "commit_sha": "d5d1b78a5671f099fbdfeb3916e052f19782897c", "parent_sha": "048124667863189baf045fc7164b1f7d8524c766", "file_path": "pros/serial/devices/vex/v5_device.py", "project_url": "https://github.com/purduesigbots/pros-cli3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -490,7 +490,7 @@ class V5Device(VEXDevice, SystemDevice):\n             payload = bytearray()\n         payload_length = len(payload)\n         assert payload_length <= 0x7f_ff\n-        if payload_length > 0x80:\n+        if payload_length >= 0x80:\n             payload_length = [(payload_length >> 8) | 0x80, payload_length & 0xff]\n         else:\n             payload_length = [payload_length]\n", "before": "if payload_length > 0x80 : payload_length = [ ( payload_length >> 8 ) | 0x80 , payload_length & 0xff ] else : payload_length = [ payload_length ]", "after": "if payload_length >= 0x80 : payload_length = [ ( payload_length >> 8 ) | 0x80 , payload_length & 0xff ] else : payload_length = [ payload_length ]", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 33], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 27, 3, 28]]]"}
{"project": "pyMaid", "commit_sha": "815bcce09327baa266e6617c4b7f9247d1ff04b3", "parent_sha": "afb8d92a7387c45388625ec0fa6f40ec7b918f24", "file_path": "pymaid/rmaid.py", "project_url": "https://github.com/schlegelp/pyMaid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -439,7 +439,7 @@ def neuron2r(neuron, convert_to_um=False):\n         # replaced with -1\n         parents = np.array(n.nodes.parent_id.values)\n         # should technically be robjects.r('-1L')\n-        parents[parents is None] = -1\n+        parents[parents == None] = -1 # DO NOT turn this into \"parents is None\"!\n \n         swc = robjects.DataFrame({'PointNo': robjects.IntVector(n.nodes.treenode_id.tolist()),\n                                   'Label': robjects.IntVector([0] * n.nodes.shape[0]),\n", "before": "parents [ parents is None ] = - 1", "after": "parents [ parents == None ] = - 1", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 17, 3, 32], [\"==:==\", \"T\"], 1], [\"Delete\", [\"is:is\", 3, 25, 3, 27]]]"}
{"project": "angr", "commit_sha": "e3e9fdc60bbd424f393b0b2ba9596d54786cd3c1", "parent_sha": "62649b55ea60119f8f330b5c5b979346a18fa791", "file_path": "simuvex/s_state.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -284,7 +284,7 @@ class SimState(object): # pylint: disable=R0904\n         e = self._do_load(self.registers, offset, length)\n \n         if endness is None: endness = self.arch.register_endness\n-        if endness in \"Iend_LE\": e = flip_bytes(e)\n+        if endness == \"Iend_LE\": e = flip_bytes(e)\n \n         self._inspect('reg_read', BP_AFTER, reg_read_expr=e)\n         return e\n", "before": "if endness in \"Iend_LE\" : e = flip_bytes ( e )", "after": "if endness == \"Iend_LE\" : e = flip_bytes ( e )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 32], [\"==:==\", \"T\"], 1], [\"Delete\", [\"in:in\", 3, 20, 3, 22]]]"}
{"project": "quaternions", "commit_sha": "5fa4f5843945f977c50e28acf240580a03e76f9a", "parent_sha": "df4485f5a333a2ec6115b24c06d21eefdc0ce238", "file_path": "quaternions/utils.py", "project_url": "https://github.com/AmitAronovitch/quaternions", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -7,7 +7,7 @@ def covariance_matrix_from_angles(angles_list):\n     covariance_matrix = sum(np.outer(angles, angles) for angles in angles_list)\n-    covariance_matrix /= (len(angles_list) + 1)\n+    covariance_matrix /= (len(angles_list) - 1)\n     return covariance_matrix\n \n \n", "before": "covariance_matrix /= ( len ( angles_list ) + 1 )", "after": "covariance_matrix /= ( len ( angles_list ) - 1 )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 1, 27, 1, 47], [\"-:-\", \"T\"], 1], [\"Delete\", [\"+:+\", 1, 44, 1, 45]]]"}
{"project": "OpenNMT-entmax", "commit_sha": "1e424b8e2aef13025a0bcfea60e8c0cbaf88d7a8", "parent_sha": "20f835b1cde538fe4c78431b5c8af10e635c909a", "file_path": "onmt/Trainer.py", "project_url": "https://github.com/deep-spin/OpenNMT-entmax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -202,7 +202,7 @@ class Trainer(object):\n \n             truebatch.append(batch_)\n             accum += 1\n-            if self.normalization is \"tokens\":\n+            if self.normalization == \"tokens\":\n                 normalization += batch_.tgt[1:].data.view(-1) \\\n                                        .ne(self.padding_idx).sum()\n             else:\n", "before": "if self . normalization is \"tokens\" : normalization += batch_ . tgt [ 1 : ] . data . view ( - 1 ) . ne ( self . padding_idx ) . sum ( ) else : ", "after": "if self . normalization == \"tokens\" : normalization += batch_ . tgt [ 1 : ] . data . view ( - 1 ) . ne ( self . padding_idx ) . sum ( ) else : ", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 46], [\"==:==\", \"T\"], 1], [\"Delete\", [\"is:is\", 3, 35, 3, 37]]]"}
{"project": "sympy", "commit_sha": "8f39fc1cf4d9cdad2dcd604c8eb75624dbf0badf", "parent_sha": "4ef6ef8f3b50ea114729758bd2346759d009ef19", "file_path": "sympy/core/tests/test_numbers.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -335,7 +335,7 @@ def test_Rational_cmp():\n     assert (n1 < S.NaN) is S.false\n     assert (n1 <= S.NaN) is S.false\n     assert (n1 > S.NaN) is S.false\n-    assert (n1 <= S.NaN) is S.false\n+    assert (n1 >= S.NaN) is S.false\n \n \n def test_Float():\n", "before": "assert ( n1 <= S . NaN ) is S . false", "after": "assert ( n1 >= S . NaN ) is S . false", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 13, 3, 24], [\">=:>=\", \"T\"], 1], [\"Delete\", [\"<=:<=\", 3, 16, 3, 18]]]"}
{"project": "bokeh", "commit_sha": "0a56c656d7d9dc5c2967f90e8af7818b40803cb0", "parent_sha": "f8d6463da9d531ed87ccf14d8ac5d269c3d56f78", "file_path": "bokeh/embed.py", "project_url": "https://github.com/suqi/bokeh", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -138,7 +138,7 @@ def autoload_static(plot_object, resources, script_path):\n-    if resources.mode != 'inline':\n+    if resources.mode == 'inline':\n         raise ValueError(\"autoload_static() requires non-inline resources\")\n \n     if resources.dev:\n", "before": "if resources . mode != 'inline' : raise ValueError ( \"autoload_static() requires non-inline resources\" )", "after": "if resources . mode == 'inline' : raise ValueError ( \"autoload_static() requires non-inline resources\" )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 0, 8, 0, 34], [\"==:==\", \"T\"], 1], [\"Delete\", [\"!=:!=\", 0, 23, 0, 25]]]"}
{"project": "cclib", "commit_sha": "9606d1971b8c4b430c2db43639b83669df36a420", "parent_sha": "5bab739f6fb08c88e38fa145e730a4ca55ce1292", "file_path": "src/cclib/parser/qchemparser.py", "project_url": "https://github.com/chemistry-scripts/cclib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -663,7 +663,7 @@ class QChem(logfileparser.Logfile):\n                         continue\n \n                     # The moment come in pairs (label and value).\n-                    for i in range(len(cols)/2):\n+                    for i in range(len(cols)//2):\n                         multipole.append(cols[2*i:2*(i+1)])\n \n                     line = inputfile.next()\n", "before": "for i in range ( len ( cols ) / 2 ) : multipole . append ( cols [ 2 * i : 2 * ( i + 1 ) ] )", "after": "for i in range ( len ( cols ) // 2 ) : multipole . append ( cols [ 2 * i : 2 * ( i + 1 ) ] )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 36, 3, 47], [\"//://\", \"T\"], 1], [\"Delete\", [\"/:/\", 3, 45, 3, 46]]]"}
{"project": "cloudwatch-fluent-metrics", "commit_sha": "a8be8131ca9bb64a5506fbe716495b00cb890722", "parent_sha": "bc58ff13c218a74f00acdaf0b20d25efd55e8086", "file_path": "fluentmetrics/buffer.py", "project_url": "https://github.com/awslabs/cloudwatch-fluent-metrics", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ class BufferedFluentMetric(FluentMetric):\n         for namespace, buffer in self.buffers.items():\n-            full_pages = len(buffer) / PAGE_SIZE\n+            full_pages = len(buffer) // PAGE_SIZE\n             for i in range(full_pages):\n                 start = i * PAGE_SIZE\n                 end = (i + 1) * PAGE_SIZE\n", "before": "full_pages = len ( buffer ) / PAGE_SIZE", "after": "full_pages = len ( buffer ) // PAGE_SIZE", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 1, 26, 1, 49], [\"//://\", \"T\"], 1], [\"Delete\", [\"/:/\", 1, 38, 1, 39]]]"}
{"project": "nci-webtools-dceg-linkage", "commit_sha": "b97215bb131fc92093380c0acc1505ce2ff285b3", "parent_sha": "a00824d5ff76aaf60c05d04a782b44d3cafc5124", "file_path": "LDlink/LDassoc.py", "project_url": "https://github.com/CBIIT/nci-webtools-dceg-linkage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -547,7 +547,7 @@ def calculate_assoc(file, region, pop, request, web, myargs):\n \telse:\n \t\tthreads=4\n \n-\tblock=len(assoc_coords)/threads\n+\tblock=len(assoc_coords)//threads\n \tcommands=[]\n \tprint(\"Create LDassoc_sub subprocesses\")\n \tfor i in range(threads):\n", "before": "block = len ( assoc_coords ) / threads", "after": "block = len ( assoc_coords ) // threads", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 8, 3, 33], [\"//://\", \"T\"], 1], [\"Delete\", [\"/:/\", 3, 25, 3, 26]]]"}
{"project": "nci-webtools-dceg-linkage", "commit_sha": "cb7b7e3b9951806ee9a60554fdb7ab98a40af775", "parent_sha": "02605b5b1f1b8dbd0eb42a449a5eaf09502e0d1e", "file_path": "LDlink/LDassoc_plot_sub.py", "project_url": "https://github.com/CBIIT/nci-webtools-dceg-linkage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -386,7 +386,7 @@ def calculate_assoc_svg(file, region, pop, request, myargs, myargsName, myargsOr\n     else:\n         threads=4\n \n-    block=len(assoc_coords)/threads\n+    block=len(assoc_coords)//threads\n     commands=[]\n     for i in range(threads):\n         if i==min(range(threads)) and i==max(range(threads)):\n", "before": "block = len ( assoc_coords ) / threads", "after": "block = len ( assoc_coords ) // threads", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 11, 3, 36], [\"//://\", \"T\"], 1], [\"Delete\", [\"/:/\", 3, 28, 3, 29]]]"}
{"project": "pants", "commit_sha": "33b6eb8685a765c0ca26e060cce36e4213205e1c", "parent_sha": "32932acfc2581a2a78fa856b445ce49c86125dcd", "file_path": "src/python/twitter/pants/python/resolver.py", "project_url": "https://github.com/square/pants", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -87,7 +87,7 @@ def resolve_multi(config,\n \n     def has_expired_ttl(self, dist):\n       now = time.time()\n-      return now - os.path.getmtime(dist.location) < ttl\n+      return now - os.path.getmtime(dist.location) >= ttl\n \n     def __call__(self, requirement):\n       cached_dist = self._egg_cache_obtainer.obtain(requirement)\n", "before": "return now - os . path . getmtime ( dist . location ) < ttl", "after": "return now - os . path . getmtime ( dist . location ) >= ttl", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 14, 3, 57], [\">=:>=\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 52, 3, 53]]]"}
{"project": "haxe-sublime2-bundle", "commit_sha": "1f6f412169c7eee3ae69e7b4b23c78c5590d29f8", "parent_sha": "980aed00296040f46f95602f53be6334cc1e743b", "file_path": "HaxeComplete.py", "project_url": "https://github.com/joa/haxe-sublime2-bundle", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -785,7 +785,7 @@ class HaxeComplete( sublime_plugin.EventListener ):\n         self.highlight_errors( view )\n \n     def on_pre_save( self , view ) :\n-        if view.score_selector(0,'source.haxe.2') > 0 :\n+        if view.score_selector(0,'source.haxe.2') == 0 :\n             return []\n \n         fn = view.file_name()\n", "before": "if view . score_selector ( 0 , 'source.haxe.2' ) > 0 : return [ ]", "after": "if view . score_selector ( 0 , 'source.haxe.2' ) == 0 : return [ ]", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 54], [\"==:==\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 51, 3, 52]]]"}
{"project": "feedsubs", "commit_sha": "e60e53cb3253fc675c9a39f9177ea9a1f43594ce", "parent_sha": "cfdda867967b6be34ed06e5b2431ef45e397f74c", "file_path": "reader/image_processing.py", "project_url": "https://github.com/NicolasLM/feedsubs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ def process_image_data(data: bytes) -> ImageProcessingResult:\n         if (width * height) < MIN_AREA_TRACKING_PIXEL:\n             raise ImageProcessingError('Tracking pixel')\n \n-        if image.format != 'GIF':\n+        if image.format == 'GIF':\n             # Gif are weird, saving them often fails and the result after\n             # compression is sometimes bigger than the original file.\n             # Let's just keep the original file.\n", "before": "if image . format != 'GIF' : ", "after": "if image . format == 'GIF' : ", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 33], [\"==:==\", \"T\"], 1], [\"Delete\", [\"!=:!=\", 3, 25, 3, 27]]]"}
{"project": "strax", "commit_sha": "091211a9dce1015c12300dac016cb6b082d227a0", "parent_sha": "d3a646e78e594bdef954802b764f7d2cd4fd87ab", "file_path": "strax/processing/pulse_processing.py", "project_url": "https://github.com/AxFoundation/strax", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -275,7 +275,7 @@ def _baseline_rms(rr, n_samples=40):\n     n = 0\n     rms = 0\n     for s in d_b[:n_samples]:\n-        if s < 0:\n+        if s <= 0:\n             rms += s**2\n             n += 1\n     # TODO: Ask maybe other fall back solution?\n", "before": "if s < 0 : rms += s ** 2 n += 1", "after": "if s <= 0 : rms += s ** 2 n += 1", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 17], [\"<=:<=\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 14, 3, 15]]]"}
{"project": "wger_stark", "commit_sha": "9648444b8ffd4c87dfb5e2ce6f16425193195a41", "parent_sha": "39351132f86c40c3b8028874e97ee2e1142c1d28", "file_path": "wger/gym/views/export.py", "project_url": "https://github.com/andela/wger_stark", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,7 +38,7 @@ def users(request, gym_pk):\n     gym = get_object_or_404(Gym, pk=gym_pk)\n \n     if not request.user.has_perm('gym.manage_gyms') \\\n-            and not request.user.has_perm('gym.manage_gym'):\n+            or not request.user.has_perm('gym.manage_gym'):\n         return HttpResponseForbidden()\n \n     if request.user.has_perm('gym.manage_gym') \\\n", "before": "if not request . user . has_perm ( 'gym.manage_gyms' ) and not request . user . has_perm ( 'gym.manage_gym' ) : return HttpResponseForbidden ( )", "after": "if not request . user . has_perm ( 'gym.manage_gyms' ) or not request . user . has_perm ( 'gym.manage_gym' ) : return HttpResponseForbidden ( )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 2, 12, 3, 60], [\"or:or\", \"T\"], 1], [\"Delete\", [\"and:and\", 3, 13, 3, 16]]]"}
{"project": "OpenTidalFarm", "commit_sha": "7dc08557a9685ebcb19b4b1f37590fe058b2516f", "parent_sha": "c55ed3155ef2e4bfe2e6cc741aa3270bbd2eb271", "file_path": "turbine_optimisation/dirichlet_bc.py", "project_url": "https://github.com/baba-mpe/OpenTidalFarm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -10,7 +10,7 @@ def ConstantFlowBoundaryCondition(config):\n             self.eta0 = config.params[\"eta0\"]\n \n         def eval(self, values, X):\n-            values[0] = self.eta0 * sqrt(self.g * self.depth) \n+            values[0] = self.eta0 * sqrt(self.g / self.depth) \n             values[1] = 0.\n         def value_shape(self):\n             return (2,)\n", "before": "values [ 0 ] = self . eta0 * sqrt ( self . g * self . depth )", "after": "values [ 0 ] = self . eta0 * sqrt ( self . g / self . depth )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 42, 3, 61], [\"/:/\", \"T\"], 1], [\"Delete\", [\"*:*\", 3, 49, 3, 50]]]"}
{"project": "speech2text", "commit_sha": "2180a4d54b474f7b553a0bb2d730b10336fc4f55", "parent_sha": "af8838c14832af41c519322eabb7c997b54158c9", "file_path": "splitor.py", "project_url": "https://github.com/datar/speech2text", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ def get_pos_from_file(pos_file):\n     with open(pos_file) as infile:\n         for i, line in enumerate(infile.readlines()):\n             people, end = line.split(' ')\n-            end = int(end)/100000*60000 + int(end)%100000\n+            end = int(end)//100000*60000 + int(end)%100000\n             positions.append([i, people, start, end])\n             start = end\n     infile.close()\n", "before": "end = int ( end ) / 100000 * 60000 + int ( end ) % 100000", "after": "end = int ( end ) // 100000 * 60000 + int ( end ) % 100000", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 19, 3, 34], [\"//://\", \"T\"], 1], [\"Delete\", [\"/:/\", 3, 27, 3, 28]]]"}
{"project": "larray", "commit_sha": "3256c401fe24c92751a185a74a50da629d1f1dc3", "parent_sha": "69524f8ce19c9295ad40f52f97da3591cd3219c5", "file_path": "larray/core.py", "project_url": "https://github.com/alixdamman/larray", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1808,7 +1808,7 @@ class LArray(object):\n \n         # 1) append length-1 axes for other-only axes\n         # TODO: factorize with make_numpy_broadcastable\n-        otheronly_axes = [Axis(axis.name, 1) if len(axis) > 1 else axis\n+        otheronly_axes = [Axis(axis.name, 1) if len(axis) != 1 else axis\n                           for axis in other_axes if axis not in self.axes]\n         array = self.reshape(self.axes + otheronly_axes)\n         # 2) reorder axes to target order (move source-only axes to the front)\n", "before": "otheronly_axes = [ Axis ( axis . name , 1 ) if len ( axis ) > 1 else axis for axis in other_axes if axis not in self . axes ]", "after": "otheronly_axes = [ Axis ( axis . name , 1 ) if len ( axis ) != 1 else axis for axis in other_axes if axis not in self . axes ]", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 49, 3, 62], [\"!=:!=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 59, 3, 60]]]"}
{"project": "PyNN", "commit_sha": "6e0bd1d01a979785f69eac4c3c6c69710b95f572", "parent_sha": "b3e851409100ae5e1da9e2167c24c2a6f4b09bd3", "file_path": "pyNN/random.py", "project_url": "https://github.com/pgleeson/PyNN", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -118,7 +118,7 @@ class WrappedRNG(AbstractRNG):\n                 # number of processors (m), we only need generate n/m+1 per node\n                 # (assuming round-robin distribution of cells between processors)\n                 if mask_local is None:\n-                    n = n / self.num_processes + 1\n+                    n = n // self.num_processes + 1\n                 elif mask_local is not False:\n                     n = mask_local.sum()\n             rarr = self._next(distribution, n, parameters)\n", "before": "n = n / self . num_processes + 1", "after": "n = n // self . num_processes + 1", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 25, 3, 47], [\"//://\", \"T\"], 1], [\"Delete\", [\"/:/\", 3, 27, 3, 28]]]"}
{"project": "cvxpy", "commit_sha": "28fe206819bbfdc6fb1c90400b999148d69dbba4", "parent_sha": "7f98ac39d19db3bd1989b5f2996dc07b74050d98", "file_path": "cvxpy/interface/cvxopt_interface/sparse_matrix_interface.py", "project_url": "https://github.com/zqcr/cvxpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -74,6 +74,6 @@ class SparseMatrixInterface(DenseMatrixInterface):\n         for v,i,j in zip(matrix.V, matrix.I, matrix.J):\n             pos = i + old_size[0]*j\n             new_row = pos % size[0]\n-            new_col = pos / size[0]\n+            new_col = pos // size[0]\n             new_mat[new_row, new_col] = v\n         return new_mat\n", "before": "new_col = pos / size [ 0 ]", "after": "new_col = pos // size [ 0 ]", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 23, 3, 36], [\"//://\", \"T\"], 1], [\"Delete\", [\"/:/\", 3, 27, 3, 28]]]"}
{"project": "h", "commit_sha": "056cf1b4765998bd09c4fd2e03f6086248dd24b7", "parent_sha": "d73b60d954ed7838326cf5d05a19977192c6f85d", "file_path": "tests/h/views/panels_test.py", "project_url": "https://github.com/project-star/h", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ from h.views import panels\n class TestNavbar(object):\n     def test_it_sets_null_username_when_logged_out(self, req):\n         result = panels.navbar({}, req)\n-        assert result['username'] == None\n+        assert result['username'] is None\n \n     def test_it_sets_username_when_logged_in(self, req, authenticated_user):\n         req.authenticated_user = authenticated_user\n", "before": "assert result [ 'username' ] == None", "after": "assert result [ 'username' ] is None", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 42], [\"is:is\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 35, 3, 37]]]"}
{"project": "kafka-python", "commit_sha": "efc03d083d323e35a2d32bcbdbccc053f737836e", "parent_sha": "63992f907aaabc4055d02de60f789443fcb4b54f", "file_path": "kafka/consumer/fetcher.py", "project_url": "https://github.com/DataDog/kafka-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -701,7 +701,7 @@ class Fetcher(six.Iterator):\n                 if error_type is Errors.NoError:\n                     if response.API_VERSION == 0:\n                         offsets = partition_info[2]\n-                        assert len(offsets) > 1, 'Expected OffsetResponse with one offset'\n+                        assert len(offsets) <= 1, 'Expected OffsetResponse with one offset'\n                         if offsets:\n                             offset = offsets[0]\n                             log.debug(\"Handling v0 ListOffsetResponse response for %s. \"\n", "before": "assert len ( offsets ) > 1 , 'Expected OffsetResponse with one offset'", "after": "assert len ( offsets ) <= 1 , 'Expected OffsetResponse with one offset'", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 32, 3, 48], [\"<=:<=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 45, 3, 46]]]"}
{"project": "kafe", "commit_sha": "ddc2800732ab5b0bac68b1c7be437023b0259c77", "parent_sha": "c5d0ad463395d8498ab9c4383425dc7c193c15ac", "file_path": "kafe/dataset.py", "project_url": "https://github.com/dsavoiu/kafe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -622,7 +622,7 @@ class Dataset(object):\n         _mats = [np.matrix(np.zeros((_size, _size))),\n                  np.matrix(np.zeros((_size, _size)))]\n \n-        if axis is 'all':\n+        if axis == 'all':\n             _axes_list = list(range(self.__n_axes))\n         else:\n             _axes_list = [self.get_axis(axis)]\n", "before": "if axis is 'all' : _axes_list = list ( range ( self . __n_axes ) ) else : _axes_list = [ self . get_axis ( axis ) ]", "after": "if axis == 'all' : _axes_list = list ( range ( self . __n_axes ) ) else : _axes_list = [ self . get_axis ( axis ) ]", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 25], [\"==:==\", \"T\"], 1], [\"Delete\", [\"is:is\", 3, 17, 3, 19]]]"}
{"project": "TAMProxy-pyHost", "commit_sha": "20b77b9838767e5258d09b81be40e41077ff17c5", "parent_sha": "09c3296383df933375333dd81fcb0b66d2703ebc", "file_path": "tamproxy/devices/color.py", "project_url": "https://github.com/skrub-wreckers/TAMProxy-pyHost", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -62,7 +62,7 @@ class Color(Device):\n \n     def handle_update(self, request, response):\n         assert len(response) == 12\n-        self.r = (ord(response[0])<8) + ord(response[1])\n+        self.r = (ord(response[0])<<8) + ord(response[1])\n         self.g = (ord(response[2])<<8) + ord(response[3])\n         self.b = (ord(response[4])<<8) + ord(response[5])\n         self.c = (ord(response[6])<<8) + ord(response[7])\n", "before": "self . r = ( ord ( response [ 0 ] ) < 8 ) + ord ( response [ 1 ] )", "after": "self . r = ( ord ( response [ 0 ] ) << 8 ) + ord ( response [ 1 ] )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"parenthesized_expression\", 3, 18, 3, 38], [\"binary_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"call\", 3, 19, 3, 35], 0], [\"Insert\", \"N0\", [\"<<:<<\", \"T\"], 1], [\"Move\", \"N0\", [\"integer:8\", 3, 36, 3, 37], 2], [\"Delete\", [\"<:<\", 3, 35, 3, 36]], [\"Delete\", [\"comparison_operator\", 3, 19, 3, 37]]]"}
{"project": "kafka-python", "commit_sha": "7008fd44f545f0794030dc73d9e1d3115ec9e88d", "parent_sha": "385f60316eef4f16922c56a4b0f1a0e0891530d2", "file_path": "test/test_coordinator.py", "project_url": "https://github.com/DataDog/kafka-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -55,7 +55,7 @@ def test_autocommit_enable_api_version(client, api_version):\n \n \n def test_protocol_type(coordinator):\n-    assert coordinator.protocol_type() is 'consumer'\n+    assert coordinator.protocol_type() == 'consumer'\n \n \n def test_group_protocols(coordinator):\n", "before": "assert coordinator . protocol_type ( ) is 'consumer'", "after": "assert coordinator . protocol_type ( ) == 'consumer'", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 53], [\"==:==\", \"T\"], 1], [\"Delete\", [\"is:is\", 3, 40, 3, 42]]]"}
{"project": "snake", "commit_sha": "87a26066f333431c18bad90cb34fcde60c9cfe81", "parent_sha": "b6a8a00d3e6e6038be623427bc31ef81285c37f6", "file_path": "snake.py", "project_url": "https://github.com/TwoAnts/snake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -399,7 +399,7 @@ def keyRelease(event):\n     \r\n     key_release_history.append(keysym)\r\n     key = None\r\n-    if len(key_release_history) == len(key_press_history):\r\n+    if len(key_release_history) >= len(key_press_history):\r\n         if len(key_press_history) == 2:\r\n             key_press_history.sort(key=lambda x: ALLOW_DIRECT_KEYS.index(x) \\\r\n                                                           if x in ALLOW_DIRECT_KEYS else x)\r\n", "before": "if len ( key_release_history ) == len ( key_press_history ) : if len ( key_press_history ) == 2 : key_press_history . sort ( key = lambda x : ALLOW_DIRECT_KEYS . index ( x ) if x in ALLOW_DIRECT_KEYS else x )", "after": "if len ( key_release_history ) >= len ( key_press_history ) : if len ( key_press_history ) == 2 : key_press_history . sort ( key = lambda x : ALLOW_DIRECT_KEYS . index ( x ) if x in ALLOW_DIRECT_KEYS else x )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 8, 3, 58], [\">=:>=\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 33, 3, 35]]]"}
{"project": "security_monkey", "commit_sha": "6dc55275086146dacc1159dc90e264a18ec2554a", "parent_sha": "6a52f8b33ed48fc584ee9c0b2cf33e0c41ceec47", "file_path": "security_monkey/views/distinct.py", "project_url": "https://github.com/Gnostech/security_monkey", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -114,7 +114,7 @@ class Distinct(AuthenticatedService):\n                 query = query.distinct(Technology.name)\n         elif key_id == 'account':\n             if select2:\n-                query = query.filter(Account.third_party is False)\n+                query = query.filter(Account.third_party == False)\n                 query = query.distinct(Account.name).filter(func.lower(Account.name).like('%' + q + '%'))\n             else:\n                 query = query.distinct(Account.name)\n", "before": "query = query . filter ( Account . third_party is False )", "after": "query = query . filter ( Account . third_party == False )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 38, 3, 66], [\"==:==\", \"T\"], 1], [\"Delete\", [\"is:is\", 3, 58, 3, 60]]]"}
{"project": "amepah", "commit_sha": "30ab4414ae1ac44d6867c9162e525a00dcf46db7", "parent_sha": "accf36a712caeda8fbda03098a1ace510b65eb7a", "file_path": "calibrate_zodi_time.py", "project_url": "https://github.com/berkelem/amepah", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -63,7 +63,7 @@ class Orbit:\n         orig_param[first_val:last_val+1] = smooth_param[first_val:last_val+1]\n         if first_val != 0 and orig_param[first_val-1] != orig_param[first_val]:\n             orig_param[:first_val] = orig_param[first_val]\n-        if last_val+1 != len(orig_param) and orig_param[last_val - 1] != orig_param[last_val]:\n+        if last_val+1 != len(orig_param) and orig_param[last_val + 1] != orig_param[last_val]:\n             orig_param[last_val + 1:] = orig_param[last_val]\n \n         return orig_param\n", "before": "if last_val + 1 != len ( orig_param ) and orig_param [ last_val - 1 ] != orig_param [ last_val ] : orig_param [ last_val + 1 : ] = orig_param [ last_val ]", "after": "if last_val + 1 != len ( orig_param ) and orig_param [ last_val + 1 ] != orig_param [ last_val ] : orig_param [ last_val + 1 : ] = orig_param [ last_val ]", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 57, 3, 69], [\"+:+\", \"T\"], 1], [\"Delete\", [\"-:-\", 3, 66, 3, 67]]]"}
{"project": "androguard", "commit_sha": "6da297df3775f865f54baf7fabd268b7cd224222", "parent_sha": "c1229bd3a66d884877df8ca7d252bf8c9ae12d25", "file_path": "androguard/decompiler/dad/writer.py", "project_url": "https://github.com/Ever-Never/androguard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -515,7 +515,7 @@ class Writer(object):\n             return arg.visit(self)\n         atype = arg.get_type()\n         if atype == 'Z':\n-            if op is Op.EQUAL:\n+            if op == Op.EQUAL:\n                 self.write('!')\n             arg.visit(self)\n         else:\n", "before": "if op is Op . EQUAL : self . write ( '!' )", "after": "if op == Op . EQUAL : self . write ( '!' )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 30], [\"==:==\", \"T\"], 1], [\"Delete\", [\"is:is\", 3, 19, 3, 21]]]"}
{"project": "molotov", "commit_sha": "542a38d96336223ab95fe370823ba747c0e47ffd", "parent_sha": "86d25a4ca1b70faa6b100a923b3c1613e2fe1524", "file_path": "molotov/runner.py", "project_url": "https://github.com/loads/molotov", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -143,7 +143,7 @@ class Runner(object):\n                 cancelled = object()\n                 res = await cancellable_sleep(self.args.duration,\n                                               result=cancelled)\n-                if res == cancelled or (res and not res.canceled()):\n+                if res is cancelled or (res and not res.canceled()):\n                     self._shutdown(None, None)\n             _duration_killer = self.ensure_future(_duration_killer())\n         else:\n", "before": "if res == cancelled or ( res and not res . canceled ( ) ) : self . _shutdown ( None , None )", "after": "if res is cancelled or ( res and not res . canceled ( ) ) : self . _shutdown ( None , None )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 20, 3, 36], [\"is:is\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 24, 3, 26]]]"}
{"project": "pandas", "commit_sha": "149a8f30091496b35f41c03b9e2bc2947a1ebb9b", "parent_sha": "ca8f3f8339704cff916d63de5e50df1c16809251", "file_path": "pandas/tools/rplot.py", "project_url": "https://github.com/jmwoloso/pandas", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -132,7 +132,7 @@ class ScaleShape(Scale):\n \n \tdef __call__(self, data, index):\n \t\tvalues = sorted(list(set(data[self.column])))\n-\t\tif len(values) != len(self.shapes):\n+\t\tif len(values) > len(self.shapes):\n \t\t\traise ValueError(\"Too many different values of the categorical attribute for ScaleShape\")\n \t\tx = data[self.column].iget(index)\n \t\treturn self.shapes[values.index(x)]\n", "before": "if len ( values ) != len ( self . shapes ) : raise ValueError ( \"Too many different values of the categorical attribute for ScaleShape\" )", "after": "if len ( values ) > len ( self . shapes ) : raise ValueError ( \"Too many different values of the categorical attribute for ScaleShape\" )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 6, 3, 37], [\">:>\", \"T\"], 1], [\"Delete\", [\"!=:!=\", 3, 18, 3, 20]]]"}
{"project": "pyspider", "commit_sha": "bc8985408a8fd8fb51ad8fb31f8a3b2b110df19f", "parent_sha": "384097df408ae62b94594d0ac1f91778f612b69f", "file_path": "pyspider/processor/project_module.py", "project_url": "https://github.com/atlas555/pyspider", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ class ProjectManager(object):\n             return True\n         if updatetime and updatetime > self.projects[project_name]['info'].get('updatetime', 0):\n             return True\n-        if time.time() - self.projects[project_name]['load_time'] < self.RELOAD_PROJECT_INTERVAL:\n+        if time.time() - self.projects[project_name]['load_time'] > self.RELOAD_PROJECT_INTERVAL:\n             return True\n         return False\n \n", "before": "if time . time ( ) - self . projects [ project_name ] [ 'load_time' ] < self . RELOAD_PROJECT_INTERVAL : return True", "after": "if time . time ( ) - self . projects [ project_name ] [ 'load_time' ] > self . RELOAD_PROJECT_INTERVAL : return True", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 97], [\">:>\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 67, 3, 68]]]"}
{"project": "psutil", "commit_sha": "23a02aea9b933fea695f1221888a0a8206078815", "parent_sha": "f65c0c58cd3dd6e5c60706a965e0d49a0f88fbde", "file_path": "test/test_psutil.py", "project_url": "https://github.com/mindw/psutil", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -437,7 +437,7 @@ class TestCase(unittest.TestCase):\n \n     def test_swap_memory(self):\n         mem = psutil.swap_memory()\n-        assert mem.total > 0, mem\n+        assert mem.total >= 0, mem\n         assert mem.used >= 0, mem\n         assert mem.free > 0, mem\n         assert 0 <= mem.percent <= 100, mem\n", "before": "assert mem . total > 0 , mem", "after": "assert mem . total >= 0 , mem", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 29], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 26, 3, 27]]]"}
{"project": "cpython", "commit_sha": "76119768b677a3a6efcbcc47b63b1fbbd6ca8e15", "parent_sha": "d2cd2c29e86cff5bef2c0d0f84add2dc53e90303", "file_path": "Lib/test/test__locale.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -45,7 +45,7 @@ class _LocaleTests(unittest.TestCase):\n         except Error:\n             set_locale = \"<not able to determine>\"\n         known_value = known_numerics.get(used_locale,\n-                                    ('', ''))[data_type is 'thousands_sep']\n+                                    ('', ''))[data_type == 'thousands_sep']\n         if known_value and calc_value:\n             self.assertEquals(calc_value, known_value,\n                                 self.lc_numeric_err_msg % (\n", "before": "known_value = known_numerics . get ( used_locale , ( '' , '' ) ) [ data_type is 'thousands_sep' ]", "after": "known_value = known_numerics . get ( used_locale , ( '' , '' ) ) [ data_type == 'thousands_sep' ]", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 47, 3, 75], [\"==:==\", \"T\"], 1], [\"Delete\", [\"is:is\", 3, 57, 3, 59]]]"}
{"project": "cpython", "commit_sha": "50dd1f92e58089c596425bd8e85f23fb59d54e44", "parent_sha": "43b2f784ed11ae21f8afde4855075929b3cbec89", "file_path": "Lib/_abcoll.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -382,7 +382,7 @@ class Mapping(metaclass=ABCMeta):\n         return set(self) == set(other)\n \n     def __ne__(self, other):\n-        return set(self) == set(other)\n+        return set(self) != set(other)\n \n class MappingView(metaclass=ABCMeta):\n \n", "before": "return set ( self ) == set ( other )", "after": "return set ( self ) != set ( other )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 39], [\"!=:!=\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 26, 3, 28]]]"}
{"project": "cpython", "commit_sha": "b05a95bd6ce97af452e829b7fc3691c3a8c9040a", "parent_sha": "9fed4247adf51cf7925e004399c03f0a8f0419ba", "file_path": "Lib/unittest/test/test_case.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -597,7 +597,7 @@ class Test_TestCase(unittest.TestCase, TestEquality, TestHashing):\n         diff = '\\n'.join(difflib.ndiff(pprint.pformat(seq1).splitlines(),\n                                        pprint.pformat(seq2).splitlines()))\n         try:\n-            self.assertSequenceEqual(seq1, seq2, max_diff=len(diff)/2)\n+            self.assertSequenceEqual(seq1, seq2, max_diff=len(diff)//2)\n         except AssertionError as e:\n             msg = e.args[0]\n         self.assertTrue(len(msg) < len(diff))\n", "before": "self . assertSequenceEqual ( seq1 , seq2 , max_diff = len ( diff ) / 2 )", "after": "self . assertSequenceEqual ( seq1 , seq2 , max_diff = len ( diff ) // 2 )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 59, 3, 70], [\"//://\", \"T\"], 1], [\"Delete\", [\"/:/\", 3, 68, 3, 69]]]"}
{"project": "cpython", "commit_sha": "1c3dde829a818057b108c6945b6689e058b9df99", "parent_sha": "8fc5fc74340f9702cd4295c2d4eae5689f9e495e", "file_path": "Lib/distutils/command/install_data.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ class install_data (Command):\n     def run (self):\n         self.mkpath(self.install_dir)\n         for f in self.data_files:\n-            if type(f) == StringType:\n+            if type(f) is StringType:\n                 # it's a simple file, so copy it\n                 f = convert_path(f)\n                 if self.warn_dir:\n", "before": "if type ( f ) == StringType : f = convert_path ( f ) if self . warn_dir : ", "after": "if type ( f ) is StringType : f = convert_path ( f ) if self . warn_dir : ", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 37], [\"is:is\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 24, 3, 26]]]"}
{"project": "cdiff", "commit_sha": "18b3b85be7495f71eef02b135011ac902b1fabed", "parent_sha": "e3e838d8fb75b6ad2a2ffe54b6566d358a681f8f", "file_path": "cdiff.py", "project_url": "https://github.com/googlecode-copy/cdiff", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -508,7 +508,7 @@ class DiffMarker(object):\n                 # [terminal size minus the line number columns and 3 separating\n                 # spaces\n                 #\n-                width = (terminal_size()[0] - num_width * 2 - 3) / 2\n+                width = (terminal_size()[0] - num_width * 2 - 3) // 2\n             except Exception:\n                 # If terminal detection failed, set back to default\n                 width = 80\n", "before": "width = ( terminal_size ( ) [ 0 ] - num_width * 2 - 3 ) / 2", "after": "width = ( terminal_size ( ) [ 0 ] - num_width * 2 - 3 ) // 2", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 25, 3, 69], [\"//://\", \"T\"], 1], [\"Delete\", [\"/:/\", 3, 66, 3, 67]]]"}
{"project": "fabric8-analytics-common", "commit_sha": "4f3587d29ff2e231d6c3ef631892121f7465f177", "parent_sha": "841fd0a82ae127e645be938c1339a5c3717f2658", "file_path": "e2e_tests_bot/src/e2e_tests_checker.py", "project_url": "https://github.com/fabric8-analytics/fabric8-analytics-common", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -82,7 +82,7 @@ def main():\n     last_build, last_build_status, total_builds_cnt, success_builds_cnt = \\\n         read_build_history(master_build_url)\n \n-    if last_build >= last_processed_build:\n+    if last_build > last_processed_build:\n         log.info(\"New build(s) detected!\")\n         with log.indent():\n             process_new_build(config, last_build, last_build_status, jenkins_url, master_build_url)\n", "before": "if last_build >= last_processed_build : log . info ( \"New build(s) detected!\" ) with log . indent ( ) : process_new_build ( config , last_build , last_build_status , jenkins_url , master_build_url )", "after": "if last_build > last_processed_build : log . info ( \"New build(s) detected!\" ) with log . indent ( ) : process_new_build ( config , last_build , last_build_status , jenkins_url , master_build_url )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 8, 3, 42], [\">:>\", \"T\"], 1], [\"Delete\", [\">=:>=\", 3, 19, 3, 21]]]"}
{"project": "fabric8-analytics-common", "commit_sha": "66041c845cb67cde892f138b9bc99f78da127627", "parent_sha": "0e7fca1e973176ef84ccb623afa98b1095630a4f", "file_path": "integration-tests/features/steps/common.py", "project_url": "https://github.com/fabric8-analytics/fabric8-analytics-common", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -252,7 +252,7 @@ def compare_value_from_json(value, expected):\n     \"\"\"Compare value read from JSON with the expected value, ignoring the type.\"\"\"\n     # fallback for int value in the JSON file\n     if type(value) is int:\n-        assert value == int(expected)\n+        assert value <= int(expected)\n     else:\n         assert value == expected\n \n", "before": "assert value == int ( expected )", "after": "assert value <= int ( expected )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 38], [\"<=:<=\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 22, 3, 24]]]"}
{"project": "populo", "commit_sha": "31d094b5b4b3e9ff86203568d6e3d3576b4429f3", "parent_sha": "74f61875c728810d9389b2f7d4e55c13b5e331b1", "file_path": "lms/djangoapps/django_comment_client/utils.py", "project_url": "https://github.com/chauhanhardik/populo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -123,7 +123,7 @@ def _filter_unstarted_categories(category_map):\n def _sort_map_entries(category_map, sort_alpha):\n     things = []\n     for title, entry in category_map[\"entries\"].items():\n-        if entry[\"sort_key\"] == None and sort_alpha:\n+        if entry[\"sort_key\"] is None and sort_alpha:\n             entry[\"sort_key\"] = title\n         things.append((title, entry))\n     for title, category in category_map[\"subcategories\"].items():\n", "before": "if entry [ \"sort_key\" ] == None and sort_alpha : entry [ \"sort_key\" ] = title", "after": "if entry [ \"sort_key\" ] is None and sort_alpha : entry [ \"sort_key\" ] = title", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 37], [\"is:is\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 30, 3, 32]]]"}
{"project": "enigma2", "commit_sha": "b7bc48591d6c61ba70cf68cd1d356c6abb1d9f2e", "parent_sha": "a80c8953ab5dafd0eb96b9cc19f8c5cb84dcd8e2", "file_path": "lib/python/Components/MovieList.py", "project_url": "https://github.com/sotocirus/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -61,7 +61,7 @@ class MovieList(HTMLComponent, GUIComponent):\n \n \tdef getCurrent(self):\n \t\tl = self.l.getCurrentSelection()\n-\t\treturn l or l[0]\n+\t\treturn l and l[0]\n \n \tdef GUIcreate(self, parent):\n \t\tself.instance = eListbox(parent)\n", "before": "return l or l [ 0 ]", "after": "return l and l [ 0 ]", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 10, 3, 19], [\"and:and\", \"T\"], 1], [\"Delete\", [\"or:or\", 3, 12, 3, 14]]]"}
{"project": "enigma2", "commit_sha": "9ede0c7dfec7b949e13970725e370189035eb4c7", "parent_sha": "c1742b2d2c072ddd0e3ceb4b2227120cd308a278", "file_path": "lib/python/Components/MediaPlayer.py", "project_url": "https://github.com/sotocirus/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -79,7 +79,7 @@ class PlayList(HTMLComponent, GUIComponent, MenuList):\n \t\tself.list.append(PlaylistEntryComponent(serviceref, STATE_NONE))\n \n \tdef deleteFile(self, index):\n-\t\tif self.currPlaying > index:\n+\t\tif self.currPlaying >= index:\n \t\t\tself.currPlaying -= 1\n \t\tself.list = self.list[:index] + self.list[index + 1:]\n \t\n", "before": "if self . currPlaying > index : self . currPlaying -= 1", "after": "if self . currPlaying >= index : self . currPlaying -= 1", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 6, 3, 30], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 23, 3, 24]]]"}
{"project": "scipy", "commit_sha": "f8a6c4339fbc7a901e79b6b517f6faddafa34a4e", "parent_sha": "ecabc8e2382be89a1b4a14cb2d8c00f777970102", "file_path": "Lib/io/tests/test_recaster.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,7 +52,7 @@ class test_recaster(ScipyTestCase):\n                 tdtsz = N.dtype(T).itemsize\n                 ok_T = T in R.sctype_list\n                 expect_none = ((req_type is None) or \n-                               ((tdtsz < rdtsz) and not ok_T))\n+                               ((tdtsz <= rdtsz) and not ok_T))\n                 A = N.array(value, T)\n                 C = R.smallest_same_kind(A)\n                 if expect_none:\n", "before": "expect_none = ( ( req_type is None ) or ( ( tdtsz < rdtsz ) and not ok_T ) )", "after": "expect_none = ( ( req_type is None ) or ( ( tdtsz <= rdtsz ) and not ok_T ) )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 34, 3, 47], [\"<=:<=\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 40, 3, 41]]]"}
{"project": "scipy", "commit_sha": "0c1e666a1264f7e4d51a59487064fc52b5aa03d7", "parent_sha": "f9b9268175f503cbc6521d666acdcfcab849d994", "file_path": "scipy/ndimage/morphology.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -111,7 +111,7 @@ def iterate_structure(structure, iterations, origin = None):\n         return structure.copy()\n     ni = iterations - 1\n     shape = [ii + ni * (ii - 1) for ii in structure.shape]\n-    pos = [ni * (structure.shape[ii] / 2) for ii in range(len(shape))]\n+    pos = [ni * (structure.shape[ii] // 2) for ii in range(len(shape))]\n     slc = [slice(pos[ii], pos[ii] + structure.shape[ii], None)\n            for ii in range(len(shape))]\n     out = numpy.zeros(shape, bool)\n", "before": "pos = [ ni * ( structure . shape [ ii ] / 2 ) for ii in range ( len ( shape ) ) ]", "after": "pos = [ ni * ( structure . shape [ ii ] // 2 ) for ii in range ( len ( shape ) ) ]", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 18, 3, 41], [\"//://\", \"T\"], 1], [\"Delete\", [\"/:/\", 3, 38, 3, 39]]]"}
{"project": "scipy", "commit_sha": "3a08f05190898bf408fdac620341a3266108b81b", "parent_sha": "b9ef5eea40ddad1d9bc155d7fbb1a61d918331de", "file_path": "scipy/optimize/_differentialevolution.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -703,7 +703,7 @@ class DifferentialEvolutionSolver(object):\n \n         fill_point = rng.randint(0, self.parameter_count)\n \n-        if self.strategy == ['currenttobest1exp', 'currenttobest1bin']:\n+        if self.strategy in ['currenttobest1exp', 'currenttobest1bin']:\n             bprime = self.mutation_func(candidate,\n                                         self._select_samples(candidate, 5))\n         else:\n", "before": "if self . strategy == [ 'currenttobest1exp' , 'currenttobest1bin' ] : bprime = self . mutation_func ( candidate , self . _select_samples ( candidate , 5 ) ) else : ", "after": "if self . strategy in [ 'currenttobest1exp' , 'currenttobest1bin' ] : bprime = self . mutation_func ( candidate , self . _select_samples ( candidate , 5 ) ) else : ", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 71], [\"in:in\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 26, 3, 28]]]"}
{"project": "smart-cache", "commit_sha": "a77cef500956bf212382f9f8b933913a9675af17", "parent_sha": "43ddcb0dd14e49b9ec5c96b2f8b43efbc811b576", "file_path": "scripts/DataAnalysis/simulator.py", "project_url": "https://github.com/Cloud-PG/smart-cache", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1026,7 +1026,7 @@ def roulette_wheel(fitness: list, extractions: int = 1):\n         while(True):\n             idx = randint(0, len(probabilities) - 1)\n             cur_probability = probabilities[idx]\n-            if random() >= cur_probability:\n+            if random() <= cur_probability:\n                 candidates.append(idx)\n             if len(candidates) == 2:\n                 yield candidates\n", "before": "if random ( ) >= cur_probability : candidates . append ( idx )", "after": "if random ( ) <= cur_probability : candidates . append ( idx )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 43], [\"<=:<=\", \"T\"], 1], [\"Delete\", [\">=:>=\", 3, 25, 3, 27]]]"}
{"project": "scipy", "commit_sha": "a229776039832e43b9ebd42837246676122a1bfe", "parent_sha": "b5b5ed6556bc7f2292957f2e8075e4417aad12ac", "file_path": "scipy/stats/_continuous_distns.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -4647,7 +4647,7 @@ class mielke_gen(rv_continuous):\n             # n-th moment is defined for -k < n < s\n             return sc.gamma((k+n)/s)*sc.gamma(1-n/s)/sc.gamma(k/s)\n \n-        return _lazywhere(n > s, (n, k, s), nth_moment, np.inf)\n+        return _lazywhere(n < s, (n, k, s), nth_moment, np.inf)\n \n \n mielke = mielke_gen(a=0.0, name='mielke')\n", "before": "return _lazywhere ( n > s , ( n , k , s ) , nth_moment , np . inf )", "after": "return _lazywhere ( n < s , ( n , k , s ) , nth_moment , np . inf )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 27, 3, 32], [\"<:<\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 29, 3, 30]]]"}
{"project": "scipy", "commit_sha": "845d3115dffe0f5883f90b406010d4a818ab8a70", "parent_sha": "7a39da6916506055a8af37a8b8fb25dd70d5bdeb", "file_path": "scipy/optimize/_dual_annealing.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -208,7 +208,7 @@ class MarkovChain(object):\n         pqv_temp = (self.acceptance_param - 1.0) * (\n             e - self.energy_state.current_energy) / (\n                 self.temperature_step + 1.)\n-        if pqv_temp < 0.:\n+        if pqv_temp <= 0.:\n             pqv = 0.\n         else:\n             pqv = np.exp(np.log(pqv_temp) / (\n", "before": "if pqv_temp < 0. : pqv = 0.", "after": "if pqv_temp <= 0. : pqv = 0.", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 25], [\"<=:<=\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 21, 3, 22]]]"}
{"project": "registration", "commit_sha": "b80151a62721f6f0bcc918fef65522aad949d290", "parent_sha": "68587680d97c98f48ab8fc7c6d5cdda236e2b9c3", "file_path": "register/models.py", "project_url": "https://github.com/HackCU/registration", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -62,7 +62,7 @@ class Application(models.Model):\n         self.save()\n \n     def cancel(self):\n-        if self.status != 'C' or self.status != 'I':\n+        if self.status != 'C' and self.status != 'I':\n             raise ValidationError('Application can\\'t be cancelled. Current status: %s' % self.status)\n         self.status = 'X'\n         self.save()\n", "before": "if self . status != 'C' or self . status != 'I' : raise ValidationError ( 'Application can\\'t be cancelled. Current status: %s' % self . status )", "after": "if self . status != 'C' and self . status != 'I' : raise ValidationError ( 'Application can\\'t be cancelled. Current status: %s' % self . status )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 52], [\"and:and\", \"T\"], 1], [\"Delete\", [\"or:or\", 3, 31, 3, 33]]]"}
{"project": "electrum", "commit_sha": "348f66b8a5746e8ca789ab311b4bd5f6743705d6", "parent_sha": "a1f91ee49ece33e6319cfec18b4a1e1b6bd3e2f2", "file_path": "lib/storage.py", "project_url": "https://github.com/UnitedBitcoin/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -249,7 +249,7 @@ class WalletStorage(PrintError):\n         return result\n \n     def requires_upgrade(self):\n-        return self.file_exists() and self.get_seed_version() != FINAL_SEED_VERSION\n+        return self.file_exists() and self.get_seed_version() < FINAL_SEED_VERSION\n \n     def upgrade(self):\n         self.print_error('upgrading wallet format')\n", "before": "return self . file_exists ( ) and self . get_seed_version ( ) != FINAL_SEED_VERSION", "after": "return self . file_exists ( ) and self . get_seed_version ( ) < FINAL_SEED_VERSION", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 39, 3, 84], [\"<:<\", \"T\"], 1], [\"Delete\", [\"!=:!=\", 3, 63, 3, 65]]]"}
{"project": "electrum", "commit_sha": "31cd9753aad82de5e02c6379a78e6feea8e89f44", "parent_sha": "c506c3e720ea44a974415f443be87df65a90048e", "file_path": "lib/coinchooser.py", "project_url": "https://github.com/UnitedBitcoin/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -223,7 +223,7 @@ class CoinChooserOldestFirst(CoinChooserBase):\n     def choose_buckets(self, buckets, sufficient_funds, penalty_func):\n         '''Spend the oldest buckets first.'''\n         # Unconfirmed coins are young, not old\n-        adj_height = lambda height: 99999999 if height == 0 else height\n+        adj_height = lambda height: 99999999 if height <= 0 else height\n         buckets.sort(key = lambda b: max(adj_height(coin['height'])\n                                          for coin in b.coins))\n         selected = []\n", "before": "adj_height = lambda height : 99999999 if height == 0 else height", "after": "adj_height = lambda height : 99999999 if height <= 0 else height", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 49, 3, 60], [\"<=:<=\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 56, 3, 58]]]"}
{"project": "sunpy", "commit_sha": "9ffa69f36163f1f2e3f156e9c426453aa3055039", "parent_sha": "058694f087df93de7f3e3b1b9d523a1066fed72d", "file_path": "sunpy/time/timerange.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -86,7 +86,7 @@ class TimeRange(object):\n \n         # Timedelta\n         if isinstance(y, timedelta):\n-            if y.days > 0:\n+            if y.days >= 0:\n                 self._t1 = x\n                 self._t2 = x + y\n             else:\n", "before": "if y . days > 0 : self . _t1 = x self . _t2 = x + y else : ", "after": "if y . days >= 0 : self . _t1 = x self . _t2 = x + y else : ", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 26], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 23, 3, 24]]]"}
{"project": "remi", "commit_sha": "81529e712c766e8d1809d8f5f47dc9d37f215832", "parent_sha": "d46164a1414af9e4fc7c56e9fac6fc89997c6dc2", "file_path": "remi/server.py", "project_url": "https://github.com/loopbio/remi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -549,7 +549,7 @@ ws.onerror = function(evt){\n                     log.debug('post: %s=%s\\n' % (field, form[field].value))\n \n             if file_data is not None:\n-                log.debug('GUI - server.py do_POST: fileupload path= %s name= %s' + (savepath, filename))\n+                log.debug('GUI - server.py do_POST: fileupload path= %s name= %s' % (savepath, filename))\n                 with open(savepath+filename,'wb') as f:\n                     f.write(file_data)\n                     self.send_response(200)\n", "before": "log . debug ( 'GUI - server.py do_POST: fileupload path= %s name= %s' + ( savepath , filename ) )", "after": "log . debug ( 'GUI - server.py do_POST: fileupload path= %s name= %s' % ( savepath , filename ) )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 27, 3, 105], [\"%:%\", \"T\"], 1], [\"Delete\", [\"+:+\", 3, 83, 3, 84]]]"}
{"project": "sympy", "commit_sha": "095e01ac6cbc7a46f64549ea23c3c4283ac02cd5", "parent_sha": "24300dd6bde0b53900e3e246b3f281386e2f64dd", "file_path": "sympy/core/tests/test_complex.py", "project_url": "https://github.com/sampadsaha5/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -84,7 +84,7 @@ def test_evalc():\n def test_pythoncomplex():\n     x = Symbol(\"x\")\n     assert 4j*x == 4*x*I\n-    assert 4j*x != 4.0*x*I\n+    assert 4j*x == 4.0*x*I\n     assert 4.1j*x != 4*x*I\n \n def test_rootcomplex():\n", "before": "assert 4j * x != 4.0 * x * I", "after": "assert 4j * x == 4.0 * x * I", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 27], [\"==:==\", \"T\"], 1], [\"Delete\", [\"!=:!=\", 3, 17, 3, 19]]]"}
{"project": "OoT-Randomizer", "commit_sha": "7780da2a5806c7bd8a7a8a3c6667566f8cdd194b", "parent_sha": "527afed8df42f092bd223a0ca7ada35b85e1a1a2", "file_path": "Main.py", "project_url": "https://github.com/TestRunnerSRL/OoT-Randomizer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -105,7 +105,7 @@ def resolve_settings(settings, window=dummy_window()):\n         settings.player_num = settings.world_count\n \n     # Set to a custom hint distribution if plando is overriding the distro\n-    if len(settings.hint_dist_user) == 0:\n+    if len(settings.hint_dist_user) != 0:\n         settings.hint_dist = 'custom'\n \n     logger.info('OoT Randomizer Version %s  -  Seed: %s', __version__, settings.seed)\n", "before": "if len ( settings . hint_dist_user ) == 0 : settings . hint_dist = 'custom'", "after": "if len ( settings . hint_dist_user ) != 0 : settings . hint_dist = 'custom'", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 8, 3, 41], [\"!=:!=\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 37, 3, 39]]]"}
{"project": "metanl", "commit_sha": "709f68c9bb7aac85387f5ffb81cfd6e0028aeae7", "parent_sha": "9cc0888315182ea1ca9f82e60e2df955d004eb9f", "file_path": "metanl/wordlist.py", "project_url": "https://github.com/commonsense/metanl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -201,7 +201,7 @@ def get_frequency(word, lang, default_freq=0, scale=1e9):\n                          \"but %r contains a space\" % word)\n \n     lookup = preprocess_text(word).lower()\n-    return factor * freqs[lookup] or default_freq\n+    return factor * freqs[lookup] + default_freq\n \n def multilingual_word_frequency(multiword, default_freq=0):\n", "before": "return factor * freqs [ lookup ] or default_freq", "after": "return factor * freqs [ lookup ] + default_freq", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"return_statement\", 3, 5, 3, 50], [\"binary_operator\", \"N0\"], 1], [\"Move\", \"N0\", [\"binary_operator\", 3, 12, 3, 34], 0], [\"Insert\", \"N0\", [\"+:+\", \"T\"], 1], [\"Move\", \"N0\", [\"identifier:default_freq\", 3, 38, 3, 50], 2], [\"Delete\", [\"or:or\", 3, 35, 3, 37]], [\"Delete\", [\"boolean_operator\", 3, 12, 3, 50]]]"}
{"project": "mollyproject", "commit_sha": "28c195f3f5b2d5fa60c19a40eaad211b686ec423", "parent_sha": "84278cc4fb4497d2fd5728cfa99130183169530d", "file_path": "molly/apps/weather/models.py", "project_url": "https://github.com/mollyproject/mollyproject", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -108,7 +108,7 @@ class Weather(models.Model):\n \n     def icon(self):\n         now = datetime.now().time()\n-        if now > time(7) or now > time(21):\n+        if now < time(7) or now > time(21):\n             night = '_night'\n         else:\n             night = ''\n", "before": "if now > time ( 7 ) or now > time ( 21 ) : night = '_night' else : night = ''", "after": "if now < time ( 7 ) or now > time ( 21 ) : night = '_night' else : night = ''", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 25], [\"<:<\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 16, 3, 17]]]"}
{"project": "spaCy", "commit_sha": "c5a407e95af8127fff0e5e5c8e0ebcaeed0288e1", "parent_sha": "25cb764e64814aa1ad61b8a854cb6404b38f9753", "file_path": "spacy/tests/vocab_vectors/test_vocab_api.py", "project_url": "https://github.com/connorbrinton/spaCy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -49,4 +49,4 @@ def test_vocab_api_contains(en_vocab, text):\n \n def test_vocab_writing_system(en_vocab):\n     assert en_vocab.writing_system[\"direction\"] == \"ltr\"\n-    assert en_vocab.writing_system[\"has_case\"] == True\n+    assert en_vocab.writing_system[\"has_case\"] is True\n", "before": "assert en_vocab . writing_system [ \"has_case\" ] == True", "after": "assert en_vocab . writing_system [ \"has_case\" ] is True", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 55], [\"is:is\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 48, 3, 50]]]"}
{"project": "airflow", "commit_sha": "111dea274f91a0aed4c8fdf1e3c05585d86eb838", "parent_sha": "3f0fb0582c90943a0cb2d94b3630cfe37c433532", "file_path": "airflow/utils/dag_processing.py", "project_url": "https://github.com/costrouc/airflow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -578,7 +578,7 @@ class DagFileProcessorManager(LoggingMixin):\n         if self._max_runs == -1:  # Unlimited runs.\n             return False\n         for file_path in self._file_paths:\n-            if self._run_count[file_path] != self._max_runs:\n+            if self._run_count[file_path] < self._max_runs:\n                 return False\n         if self._run_count[self._heart_beat_key] < self._max_runs:\n             return False\n", "before": "if self . _run_count [ file_path ] != self . _max_runs : return False", "after": "if self . _run_count [ file_path ] < self . _max_runs : return False", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 60], [\"<:<\", \"T\"], 1], [\"Delete\", [\"!=:!=\", 3, 43, 3, 45]]]"}
{"project": "spaCy", "commit_sha": "a82c3153ada16aeb9a3e34b9400084d1b5c3d546", "parent_sha": "9af46b4f1b138df6a34c7303fd4a118bef2b29e7", "file_path": "spacy/displacy/render.py", "project_url": "https://github.com/connorbrinton/spaCy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -136,7 +136,7 @@ class DependencyRenderer(object):\n-        if direction is 'left':\n+        if direction == 'left':\n             pos1, pos2, pos3 = (x, x-self.arrow_width+2, x+self.arrow_width-2)\n         else:\n             pos1, pos2, pos3 = (end, end+self.arrow_width-2,\n", "before": "if direction is 'left' : pos1 , pos2 , pos3 = ( x , x - self . arrow_width + 2 , x + self . arrow_width - 2 )", "after": "if direction == 'left' : pos1 , pos2 , pos3 = ( x , x - self . arrow_width + 2 , x + self . arrow_width - 2 )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 0, 12, 0, 31], [\"==:==\", \"T\"], 1], [\"Delete\", [\"is:is\", 0, 22, 0, 24]]]"}
{"project": "unknown-horizons", "commit_sha": "18a59ae605609414f2515af88ce54fc42efb0d0e", "parent_sha": "6678111978bf61c7c5bd46feb7126f48954e43d6", "file_path": "horizons/scheduler.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -187,7 +187,7 @@ class Scheduler(LivingObject):\n \t\t\t\t\tremoved_calls += 1\n \n \t\ttest = 0\n-\t\tif removed_calls >= 0: # there also must be calls in the calls_by_instance dict\n+\t\tif removed_calls > 0: # there also must be calls in the calls_by_instance dict\n \t\t\tfor i in xrange(len(self.calls_by_instance[instance]) - 1, -1, -1):\n \t\t\t\tobj = self.calls_by_instance[instance][i]\n \t\t\t\tif obj.callback == callback:\n", "before": "if removed_calls >= 0 : for i in xrange ( len ( self . calls_by_instance [ instance ] ) - 1 , - 1 , - 1 ) : obj = self . calls_by_instance [ instance ] [ i ] if obj . callback == callback : ", "after": "if removed_calls > 0 : for i in xrange ( len ( self . calls_by_instance [ instance ] ) - 1 , - 1 , - 1 ) : obj = self . calls_by_instance [ instance ] [ i ] if obj . callback == callback : ", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 6, 3, 24], [\">:>\", \"T\"], 1], [\"Delete\", [\">=:>=\", 3, 20, 3, 22]]]"}
{"project": "unknown-horizons", "commit_sha": "496d991711fe086d50c180e490689add5972b437", "parent_sha": "9e7f7d921c950dad25d142d23c315303e7c99200", "file_path": "horizons/world/production/utilisation.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,7 +33,7 @@ class Utilisation(object):\n \t\tfor production in productions:\n \t\t\tstate_history = production.get_state_history_times(False)\n \t\t\ttotal += state_history[PRODUCTION.STATES.producing.index]\n-\t\treturn total // len(productions)\n+\t\treturn total / len(productions)\n \n \tdef capacity_utilisation_below(self, limit, instance):\n", "before": "return total // len ( productions )", "after": "return total / len ( productions )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 10, 3, 35], [\"/:/\", \"T\"], 1], [\"Delete\", [\"//://\", 3, 16, 3, 18]]]"}
{"project": "python-graphenelib", "commit_sha": "4fda7fdd50a6f47ecfbbc0224fc1cd782f3153df", "parent_sha": "ad42f4034c316ac850e8abc1f6519243bf3f46f5", "file_path": "graphenebase/account.py", "project_url": "https://github.com/blckchnd/python-graphenelib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -178,7 +178,7 @@ class PublicKey(Address):\n         a, b, p = curve.a(), curve.b(), curve.p()\n         alpha = (pow(x, 3, p) + a * x + b) % p\n         beta = ecdsa.numbertheory.square_root_mod_prime(alpha, p)\n-        if (beta % 2) != is_even :\n+        if (beta % 2) == is_even :\n             beta = p - beta\n         return beta\n \n", "before": "if ( beta % 2 ) != is_even : beta = p - beta", "after": "if ( beta % 2 ) == is_even : beta = p - beta", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 33], [\"==:==\", \"T\"], 1], [\"Delete\", [\"!=:!=\", 3, 23, 3, 25]]]"}
{"project": "Zappa", "commit_sha": "513bfe44f24cee37e8dc720f3a55c8f8d0c73163", "parent_sha": "aa513bd5ba72504a743d374f6862e5a1dd7a02d3", "file_path": "zappa/zappa.py", "project_url": "https://github.com/tripliks/Zappa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1053,7 +1053,7 @@ class Zappa(object):\n                 if count:\n                     # We can end up in a situation where we have more resources being created\n                     # than anticipated.\n-                    if (count - current_resources) >= 0:\n+                    if (count - current_resources) > 0:\n                         progress.update(count - current_resources)\n                 current_resources = count\n             progress.close()\n", "before": "if ( count - current_resources ) >= 0 : progress . update ( count - current_resources )", "after": "if ( count - current_resources ) > 0 : progress . update ( count - current_resources )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 24, 3, 56], [\">:>\", \"T\"], 1], [\"Delete\", [\">=:>=\", 3, 52, 3, 54]]]"}
{"project": "2018-2-OSS-E5--", "commit_sha": "8d479d830df903c3d506e7e173c0717795dbe936", "parent_sha": "3c2c6b140bebd0f3abd4f96d7a167b30f14bbb54", "file_path": "Maths/absMax.py", "project_url": "https://github.com/18-2-SKKU-OSS/2018-2-OSS-E5--", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ def absMax(x):\n     j = x[0]#compare from the first element to the last one\n \n     for i in x:\n-        if absVal(i) < j:#if absolute value of x[i] is smaller than absolute Max value, swap them\n+        if absVal(i) > j:#if absolute value of x[i] is smaller than absolute Max value, swap them\n             j = i\n     return j\n     #BUG: i is apparently a list, TypeError: '<' not supported between instances of 'list' and 'int' in absVal\n", "before": "if absVal ( i ) < j : j = i", "after": "if absVal ( i ) > j : j = i", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 25], [\">:>\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 22, 3, 23]]]"}
{"project": "ansible-1", "commit_sha": "e401b4e424bf95c5fb62806909c6951160cadc8b", "parent_sha": "511f2b7907704f61ca170e7c095c2361161d416d", "file_path": "contrib/inventory/ec2.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -251,7 +251,7 @@ class Ec2Inventory(object):\n             self.regions = configRegions.split(\",\")\n         if 'auto' in self.regions:\n             env_region = os.environ.get('AWS_REGION')\n-            if env_region == None:\n+            if env_region is None:\n                 env_region = os.environ.get('AWS_DEFAULT_REGION')\n             self.regions = [ env_region ]\n \n", "before": "if env_region == None : env_region = os . environ . get ( 'AWS_DEFAULT_REGION' )", "after": "if env_region is None : env_region = os . environ . get ( 'AWS_DEFAULT_REGION' )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 34], [\"is:is\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 27, 3, 29]]]"}
{"project": "pritunl", "commit_sha": "91c255e6640ea162b557a0553cec92d3b75c4a2a", "parent_sha": "c920d1145342bc1e41aaaf10b93ad5d41c43a296", "file_path": "pritunl/setup/dns.py", "project_url": "https://github.com/security-geeks/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -8,7 +8,7 @@ import threading\n \n @interrupter\n def _dns_thread():\n-    while not settings.local.sub_active and \\\n+    while not settings.local.sub_active or \\\n             settings.local.sub_plan != 'enterprise':\n         time.sleep(1)\n \n", "before": "while not settings . local . sub_active and settings . local . sub_plan != 'enterprise' : time . sleep ( 1 )", "after": "while not settings . local . sub_active or settings . local . sub_plan != 'enterprise' : time . sleep ( 1 )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 15, 4, 52], [\"or:or\", \"T\"], 1], [\"Delete\", [\"and:and\", 3, 41, 3, 44]]]"}
{"project": "moto", "commit_sha": "3373c5bf13edf2dfe1eb9dd6e493630c387e8729", "parent_sha": "94ba2e68bdca09a48114723eedb40d38a75b6ba6", "file_path": "moto/sns/models.py", "project_url": "https://github.com/kidomine/moto", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -315,7 +315,8 @@ class SNSBackend(BaseBackend):\n             return self._get_values_nexttoken(self.subscriptions, next_token)\n \n     def publish(self, arn, message, subject=None, message_attributes=None):\n-        if subject is not None and len(subject) >= 100:\n+        if subject is not None and len(subject) > 100:\n+            # Note that the AWS docs around length are wrong: https://github.com/spulec/moto/issues/1503\n             raise ValueError('Subject must be less than 100 characters')\n \n         try:\n", "before": "if subject is not None and len ( subject ) >= 100 : raise ValueError ( 'Subject must be less than 100 characters' )", "after": "if subject is not None and len ( subject ) > 100 : raise ValueError ( 'Subject must be less than 100 characters' )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 36, 3, 55], [\">:>\", \"T\"], 1], [\"Delete\", [\">=:>=\", 3, 49, 3, 51]]]"}
{"project": "django-celery-beat", "commit_sha": "8d8bc8bf6ee7d269f5cd18bba5ba8277abfe9175", "parent_sha": "f927cde4463165b2fada2cc9f21e2ad5d5ddcedc", "file_path": "django_celery_beat/models.py", "project_url": "https://github.com/saxix/django-celery-beat", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -325,7 +325,7 @@ class PeriodicTask(models.Model):\n             raise ValidationError({\n                 'crontab': [err_msg]\n             })\n-        if self.interval or self.solar:\n+        if self.interval and self.solar:\n             raise ValidationError({\n                 'solar': [err_msg]\n             })\n", "before": "if self . interval or self . solar : raise ValidationError ( { 'solar' : [ err_msg ] } )", "after": "if self . interval and self . solar : raise ValidationError ( { 'solar' : [ err_msg ] } )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 39], [\"and:and\", \"T\"], 1], [\"Delete\", [\"or:or\", 3, 26, 3, 28]]]"}
{"project": "django-celery-beat", "commit_sha": "279c75059159678e4b138ef579559ba9a442bdbb", "parent_sha": "8d8bc8bf6ee7d269f5cd18bba5ba8277abfe9175", "file_path": "django_celery_beat/models.py", "project_url": "https://github.com/saxix/django-celery-beat", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -325,7 +325,7 @@ class PeriodicTask(models.Model):\n             raise ValidationError({\n                 'crontab': [err_msg]\n             })\n-        if self.interval and self.solar:\n+        if self.interval or self.solar:\n             raise ValidationError({\n                 'solar': [err_msg]\n             })\n", "before": "if self . interval and self . solar : raise ValidationError ( { 'solar' : [ err_msg ] } )", "after": "if self . interval or self . solar : raise ValidationError ( { 'solar' : [ err_msg ] } )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 40], [\"or:or\", \"T\"], 1], [\"Delete\", [\"and:and\", 3, 26, 3, 29]]]"}
{"project": "ansible-modules-core", "commit_sha": "5559e6a669ca7a4ed72e20a3300f8968a3203a82", "parent_sha": "1eb01d761221138f3f33f03a07658fa1f8e04a9d", "file_path": "files/unarchive.py", "project_url": "https://github.com/drewp/ansible-modules-core", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -733,7 +733,7 @@ def main():\n     file_args = module.load_file_common_arguments(module.params)\n     # did tar file arrive?\n     if not os.path.exists(src):\n-        if not remote_src or copy:\n+        if not remote_src and copy:\n             module.fail_json(msg=\"Source '%s' failed to transfer\" % src)\n         # If copy=false, and src= contains ://, try and download the file to a temp directory.\n         elif '://' in src:\n", "before": "if not remote_src or copy : module . fail_json ( msg = \"Source '%s' failed to transfer\" % src ) elif '://' in src : ", "after": "if not remote_src and copy : module . fail_json ( msg = \"Source '%s' failed to transfer\" % src ) elif '://' in src : ", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 16, 3, 34], [\"and:and\", \"T\"], 1], [\"Delete\", [\"or:or\", 3, 27, 3, 29]]]"}
{"project": "fuel-web", "commit_sha": "d0b3fc5bd4da3445ed4b5551bdd108ee9153ad62", "parent_sha": "56d4c5c98edadebefb24abd208d4e687941f09a8", "file_path": "nailgun/nailgun/api/validators.py", "project_url": "https://github.com/ytyanghm/fuel-web", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -59,7 +59,7 @@ class MetaInterfacesValidator(BasicValidator):\n                 )\n             for key in ('max_speed', 'current_speed'):\n                 if key not in nic or isinstance(nic[key], types.NoneType) or\\\n-                        (isinstance(nic[key], int) and nic[key] > 0):\n+                        (isinstance(nic[key], int) and nic[key] >= 0):\n                     continue\n                 raise web.webapi.badrequest(\n                     message=\"Interface in meta.interfaces should have key %r\"\n", "before": "if key not in nic or isinstance ( nic [ key ] , types . NoneType ) or ( isinstance ( nic [ key ] , int ) and nic [ key ] > 0 ) : continue", "after": "if key not in nic or isinstance ( nic [ key ] , types . NoneType ) or ( isinstance ( nic [ key ] , int ) and nic [ key ] >= 0 ) : continue", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 56, 3, 68], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 65, 3, 66]]]"}
{"project": "ansible-1", "commit_sha": "faf82bf84184872f25f27e6e2e65d766384f5127", "parent_sha": "ffb4d480cf89ccfd12ace5bf61339884ba64df66", "file_path": "lib/ansible/runner/action_plugins/fetch.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,7 +73,7 @@ class ActionModule(object):\n \n         # use slurp if sudo and permissions are lacking\n         remote_data = None\n-        if remote_md5 in ('1', '2') and self.runner.sudo:\n+        if remote_md5 in ('1', '2') or self.runner.sudo:\n             slurpres = self.runner._execute_module(conn, tmp, 'slurp', 'src=%s' % source, inject=inject)\n             if slurpres.is_successful():\n                 if slurpres.result['encoding'] == 'base64':\n", "before": "if remote_md5 in ( '1' , '2' ) and self . runner . sudo : slurpres = self . runner . _execute_module ( conn , tmp , 'slurp' , 'src=%s' % source , inject = inject ) if slurpres . is_successful ( ) : if slurpres . result [ 'encoding' ] == 'base64' : ", "after": "if remote_md5 in ( '1' , '2' ) or self . runner . sudo : slurpres = self . runner . _execute_module ( conn , tmp , 'slurp' , 'src=%s' % source , inject = inject ) if slurpres . is_successful ( ) : if slurpres . result [ 'encoding' ] == 'base64' : ", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 57], [\"or:or\", \"T\"], 1], [\"Delete\", [\"and:and\", 3, 37, 3, 40]]]"}
{"project": "ansible-1", "commit_sha": "5d1641051886e9b55060f06f82d42c88e8e8a9f5", "parent_sha": "9de01b8e1079f3defbee1a97f7d80c9d2e4ca94f", "file_path": "lib/ansible/modules/packaging/os/apt.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -525,7 +525,7 @@ def main():\n                     p['default_release'], dpkg_options)\n \n         if p['deb']:\n-            if p['state'] == 'present':\n+            if p['state'] != 'present':\n                 module.fail_json(msg=\"deb only supports state=present\")\n             install_deb(module, p['deb'], cache,\n                         install_recommends=install_recommends,\n", "before": "if p [ 'state' ] == 'present' : module . fail_json ( msg = \"deb only supports state=present\" )", "after": "if p [ 'state' ] != 'present' : module . fail_json ( msg = \"deb only supports state=present\" )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 39], [\"!=:!=\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 27, 3, 29]]]"}
{"project": "sanic", "commit_sha": "e2e25eb751beb4879be6b64ddb2ded6c48301c96", "parent_sha": "9572ecc5ea2f6346c9a7879b1093719fd8b6b495", "file_path": "sanic/config.py", "project_url": "https://github.com/haoguangli/sanic", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -131,7 +131,7 @@ class Config(dict):\n         self.GRACEFUL_SHUTDOWN_TIMEOUT = 15.0  # 15 sec\n \n         if load_env:\n-            prefix = SANIC_PREFIX if load_env == True else load_env\n+            prefix = SANIC_PREFIX if load_env is True else load_env\n             self.load_environment_vars(prefix=prefix)\n \n     def __getattr__(self, attr):\n", "before": "prefix = SANIC_PREFIX if load_env == True else load_env", "after": "prefix = SANIC_PREFIX if load_env is True else load_env", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 38, 3, 54], [\"is:is\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 47, 3, 49]]]"}
{"project": "ansible-1", "commit_sha": "6aeea1fe7e56621d377cf8d221202271228501e8", "parent_sha": "16ccde49ad6704c41be41cf1a5ccd0f702d1882e", "file_path": "lib/ansible/modules/files/unarchive.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -733,7 +733,7 @@ def main():\n     file_args = module.load_file_common_arguments(module.params)\n     # did tar file arrive?\n     if not os.path.exists(src):\n-        if not remote_src or copy:\n+        if not remote_src and copy:\n             module.fail_json(msg=\"Source '%s' failed to transfer\" % src)\n         # If copy=false, and src= contains ://, try and download the file to a temp directory.\n         elif '://' in src:\n", "before": "if not remote_src or copy : module . fail_json ( msg = \"Source '%s' failed to transfer\" % src ) elif '://' in src : ", "after": "if not remote_src and copy : module . fail_json ( msg = \"Source '%s' failed to transfer\" % src ) elif '://' in src : ", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 16, 3, 34], [\"and:and\", \"T\"], 1], [\"Delete\", [\"or:or\", 3, 27, 3, 29]]]"}
{"project": "conda-smithy", "commit_sha": "059bfe92e03303141f640f78f6ae01e4a7cb7a52", "parent_sha": "01e3d61b239baecd50aacf0349e1750b91b6d554", "file_path": "conda_smithy/cli.py", "project_url": "https://github.com/isuruf/conda-smithy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -275,7 +275,7 @@ def main():\n         args = parser.parse_args()\n \n     # Check conda version for compatibility\n-    if LooseVersion(conda.__version__) < LooseVersion('4.3'):\n+    if LooseVersion(conda.__version__) >= LooseVersion('4.3'):\n         print('You appear to be using conda {}, but conda-smithy {} is\\ncurrently only compatible with conda versions < 4.3.'.format(\n             conda.__version__, __version__))\n         sys.exit(2)\n", "before": "if LooseVersion ( conda . __version__ ) < LooseVersion ( '4.3' ) : print ( 'You appear to be using conda {}, but conda-smithy {} is\\ncurrently only compatible with conda versions < 4.3.' . format ( conda . __version__ , __version__ ) ) sys . exit ( 2 )", "after": "if LooseVersion ( conda . __version__ ) >= LooseVersion ( '4.3' ) : print ( 'You appear to be using conda {}, but conda-smithy {} is\\ncurrently only compatible with conda versions < 4.3.' . format ( conda . __version__ , __version__ ) ) sys . exit ( 2 )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 8, 3, 61], [\">=:>=\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 40, 3, 41]]]"}
{"project": "mxnet", "commit_sha": "d9979ea70cb719c42184a4ed740723871045adcd", "parent_sha": "c06562ca7b0dcd927db436b59b12a8eb9948c735", "file_path": "python/mxnet/io.py", "project_url": "https://github.com/zhiiker/mxnet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -162,7 +162,7 @@ class NDArrayIter(DataIter):\n             for k, _ in self.label:\n                 self.label[k] = self.label[k][:new_n]\n         self.num_data = self.data_list[0].shape[0]\n-        assert self.num_data > batch_size, \\\n+        assert self.num_data >= batch_size, \\\n             \"batch_size need to be smaller than data size when not padding.\"\n         self.cursor = -batch_size\n         self.batch_size = batch_size\n", "before": "assert self . num_data > batch_size , \"batch_size need to be smaller than data size when not padding.\"", "after": "assert self . num_data >= batch_size , \"batch_size need to be smaller than data size when not padding.\"", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 42], [\">=:>=\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 30, 3, 31]]]"}
{"project": "leanbase-python", "commit_sha": "96cfcfca268bce3a9ec93b46671b39b7ec2f9aba", "parent_sha": "fb5cd2a0b7f6e45c6b41c140727012bf2e49a8cf", "file_path": "leanbase/models/condition.py", "project_url": "https://github.com/Leanbase/leanbase-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -86,7 +86,7 @@ class Condition(object):\n         if kind == Kinds.BOOLEAN:\n             value = value in TRUISH\n         elif kind == Kinds.NUMERIC:\n-            value == float(value)\n+            value = float(value)\n             if abs(value) - math.floor(abs(value))  < FLOAT_TOLERANCE:\n                 value = int(value)\n         elif kind == Kinds.DATE:\n", "before": "value == float ( value )", "after": "value = float ( value )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"expression_statement\", 3, 13, 3, 34], [\"assignment\", \"N0\"], 0], [\"Move\", \"N0\", [\"identifier:value\", 3, 13, 3, 18], 0], [\"Insert\", \"N0\", [\"=:=\", \"T\"], 1], [\"Move\", \"N0\", [\"call\", 3, 22, 3, 34], 2], [\"Delete\", [\"==:==\", 3, 19, 3, 21]], [\"Delete\", [\"comparison_operator\", 3, 13, 3, 34]]]"}
{"project": "pysmurf", "commit_sha": "ba04e250a2bfad2d16a2c7cba558b83dfedaa2ee", "parent_sha": "0cf0c547d7206895d93fdd796aacfc0ff02c3a67", "file_path": "python/pysmurf/client/command/smurf_command.py", "project_url": "https://github.com/slaclab/pysmurf", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -3872,7 +3872,7 @@ class SmurfCommandMixin(SmurfBase):\n         assert (dac in range(1,33)),'dac must be an integer and in [1,32]'\n \n         # only ever set this to 0x2 or 0xE\n-        if (val != 0x2) or (val != 0xE):\n+        if (val != 0x2) and (val != 0xE):\n             val = 0x2\n \n         self._caput(\n", "before": "if ( val != 0x2 ) or ( val != 0xE ) : val = 0x2", "after": "if ( val != 0x2 ) and ( val != 0xE ) : val = 0x2", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 40], [\"and:and\", \"T\"], 1], [\"Delete\", [\"or:or\", 3, 25, 3, 27]]]"}
{"project": "pysmurf", "commit_sha": "3ee378c30d1b334fc508bf06b5854111c4e62b9a", "parent_sha": "f7010a64c3af8703834a4202b7512ab1e6f0e3ae", "file_path": "python/pysmurf/client/util/smurf_util.py", "project_url": "https://github.com/slaclab/pysmurf", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -893,7 +893,7 @@ class SmurfUtilMixin(SmurfBase):\n                     # Skip for now\n                     chunk = file.read(rogue_header['length']-4)\n \n-                elif rogue_header['channel'] == 0:\n+                elif rogue_header['channel'] != 0:\n                     # Skip data on unknown channels, but print\n                     # a warning message\n                     self.log(f\"WARNING. Data present on an unknown channel: {rogue_header['channel']}\")\n", "before": "rogue_header [ 'channel' ] == 0 : self . log ( f\"WARNING. Data present on an unknown channel: {rogue_header['channel']}\" )", "after": "rogue_header [ 'channel' ] != 0 : self . log ( f\"WARNING. Data present on an unknown channel: {rogue_header['channel']}\" )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 22, 6, 104], [\"!=:!=\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 46, 3, 48]]]"}
{"project": "bitbake", "commit_sha": "34145b950be03aff8f9b88207cf843abf002ab13", "parent_sha": "6e001410854792f9bb66a0409a2ac176171b0507", "file_path": "lib/bb/__init__.py", "project_url": "https://github.com/YoeDistro/bitbake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ class BBLoggerMixin(object):\n         if not bb.event.worker_pid:\n             if self.name in bb.msg.loggerDefaultDomains and loglevel > (bb.msg.loggerDefaultDomains[self.name]):\n                 return\n-            if loglevel > bb.msg.loggerDefaultLogLevel:\n+            if loglevel < bb.msg.loggerDefaultLogLevel:\n                 return\n         return self.log(loglevel, msg, *args, **kwargs)\n \n", "before": "if loglevel > bb . msg . loggerDefaultLogLevel : return", "after": "if loglevel < bb . msg . loggerDefaultLogLevel : return", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 55], [\"<:<\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 25, 3, 26]]]"}
{"project": "bitbake", "commit_sha": "f30b3af975a071d1584817054a2996f08a3aba4f", "parent_sha": "e4db09fd123100960f2e7c0a5a228d13010d11d8", "file_path": "lib/bb/fetch/__init__.py", "project_url": "https://github.com/YoeDistro/bitbake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -699,7 +699,7 @@ class Fetch(object):\n             raise InvalidSRCREV(\"Please set SRCREV to a valid value\")\n         if not rev:\n             return False\n-        if rev is \"SRCREVINACTION\":\n+        if rev == \"SRCREVINACTION\":\n             return True\n         return rev\n \n", "before": "if rev is \"SRCREVINACTION\" : return True", "after": "if rev == \"SRCREVINACTION\" : return True", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 35], [\"==:==\", \"T\"], 1], [\"Delete\", [\"is:is\", 3, 16, 3, 18]]]"}
{"project": "bitbake", "commit_sha": "2cce5bd9dd93321ad159454d49760254c10a9ff6", "parent_sha": "d761cf98284b02eb3d3a1f879782c501c284b698", "file_path": "lib/bb/__init__.py", "project_url": "https://github.com/YoeDistro/bitbake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ class BBLogger(Logger):\n         Logger.__init__(self, name)\n \n     def bbdebug(self, level, msg, *args, **kwargs):\n-        return self.log(logging.DEBUG - level - 1, msg, *args, **kwargs)\n+        return self.log(logging.DEBUG - level + 1, msg, *args, **kwargs)\n \n     def plain(self, msg, *args, **kwargs):\n         return self.log(logging.INFO + 1, msg, *args, **kwargs)\n", "before": "return self . log ( logging . DEBUG - level - 1 , msg , * args , ** kwargs )", "after": "return self . log ( logging . DEBUG - level + 1 , msg , * args , ** kwargs )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 25, 3, 50], [\"+:+\", \"T\"], 1], [\"Delete\", [\"-:-\", 3, 47, 3, 48]]]"}
{"project": "bitbake", "commit_sha": "d98bded97c7e5423ce674205236025ce8d1914b3", "parent_sha": "584df1efa04efbe51671e4911810dbdd0dee22d3", "file_path": "lib/bb/fetch2/local.py", "project_url": "https://github.com/YoeDistro/bitbake", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -66,7 +66,7 @@ class Local(FetchMethod):\n         return newpath\n \n     def need_update(self, url, ud, d):\n-        if url.find(\"*\") == -1:\n+        if url.find(\"*\") != -1:\n             return False\n         if os.path.exists(ud.localpath):\n             return False\n", "before": "if url . find ( \"*\" ) == - 1 : return False", "after": "if url . find ( \"*\" ) != - 1 : return False", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 31], [\"!=:!=\", \"T\"], 1], [\"Delete\", [\"==:==\", 3, 26, 3, 28]]]"}
{"project": "conda-build", "commit_sha": "c14bb7f03e24e60f83335c56c5be134945599ffa", "parent_sha": "da369b3d0a1e53ac7a1fb762a81c030f13ed7aaf", "file_path": "conda_build/index.py", "project_url": "https://github.com/bgruening/conda-build", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -712,7 +712,7 @@ def _add_prev_ver_for_features(new_r, orig_r):\n             for i in range(len(orig_r.groups[g_name])):\n                 _m = orig_r.groups[g_name][i]\n                 if (\n-                    VersionOrder(_m.version) < latest_version and\n+                    VersionOrder(_m.version) <= latest_version and\n                     not (_m.track_features or _m.features)\n                 ):\n                     keep_m = _m\n", "before": "if ( VersionOrder ( _m . version ) < latest_version and not ( _m . track_features or _m . features ) ) : keep_m = _m", "after": "if ( VersionOrder ( _m . version ) <= latest_version and not ( _m . track_features or _m . features ) ) : keep_m = _m", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 21, 3, 62], [\"<=:<=\", \"T\"], 1], [\"Delete\", [\"<:<\", 3, 46, 3, 47]]]"}
{"project": "CS-Build-Week-1", "commit_sha": "385c42dacb580fae814ef7a2d12891924eb3a221", "parent_sha": "0bd53cbdaa99bf83403d4c403ab9c24cd4f9b797", "file_path": "adventure/api.py", "project_url": "https://github.com/cs23-bw1-team9/CS-Build-Week-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ import json\n # pusher = Pusher(app_id=config('PUSHER_APP_ID'), key=config('PUSHER_KEY'), secret=config('PUSHER_SECRET'), cluster=config('PUSHER_CLUSTER'))\n \n def map(new=False, result=[]):\n-    if len(result) > 0 or new is True:\n+    if len(result) == 0 or new is True:\n         result = []\n         rooms = Room.objects.all().order_by('id')\n         for room in rooms:\n", "before": "if len ( result ) > 0 or new is True : result = [ ] rooms = Room . objects . all ( ) . order_by ( 'id' ) for room in rooms : ", "after": "if len ( result ) == 0 or new is True : result = [ ] rooms = Room . objects . all ( ) . order_by ( 'id' ) for room in rooms : ", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 8, 3, 23], [\"==:==\", \"T\"], 1], [\"Delete\", [\">:>\", 3, 20, 3, 21]]]"}
{"project": "CentralPerk", "commit_sha": "df09a1766f110e9a451ca5fae61d3f6e7b896f43", "parent_sha": "7f04a518d292fca2e28c6771db259368563cf97f", "file_path": "Profile/views.py", "project_url": "https://github.com/SoullessCoder/CentralPerk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -8,7 +8,7 @@ from AUth.models import User\n # Create your views here.\n \n def view_profile(request, username=None):\n-    user = request.user if username != request.user.username else User.objects.get(username=username)\n+    user = request.user if username == request.user.username else User.objects.get(username=username)\n     return render(request, 'profile.html', { 'profile':user })\n \n class edit_profile(TemplateView):\n", "before": "user = request . user if username != request . user . username else User . objects . get ( username = username )", "after": "user = request . user if username == request . user . username else User . objects . get ( username = username )", "sstub_pattern": "CHANGE_BINARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 28, 3, 61], [\"==:==\", \"T\"], 1], [\"Delete\", [\"!=:!=\", 3, 37, 3, 39]]]"}
{"project": "carbon", "commit_sha": "7ec883247a5074617dd614c787db942fa49e0810", "parent_sha": "da59ba1733b676724223209b755fae0c1c02d29b", "file_path": "lib/carbon/log.py", "project_url": "https://github.com/jfarrell/carbon", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -37,7 +37,7 @@ def logToDir(logDir):\n     if logType is not None and logType not in customLogs:\n       customLogs[logType] = DailyLogFile(logType + '.log', logDir)\n \n-    logfile = customLogFiles.get(logType, consoleLogFile)\n+    logfile = customLogs.get(logType, consoleLogFile)\n     logfile.write(message + '\\n')\n     logfile.flush()\n \n", "before": "logfile = customLogFiles . get ( logType , consoleLogFile )", "after": "logfile = customLogs . get ( logType , consoleLogFile )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:customLogFiles\", 3, 15, 3, 29], \"customLogs\"]]"}
{"project": "ncclient", "commit_sha": "b58bb60bfe548b40e8cf1a867c4c24a549159eea", "parent_sha": "8edc9de030baf2bb680670ca46705d83e60ddf71", "file_path": "ncclient/content.py", "project_url": "https://github.com/morgabra/ncclient", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -115,7 +115,7 @@ class Element:\n             'attributes': ele.attrib,\n             'text': ele.text,\n             'tail': ele.tail,\n-            'subtree': [ Element.DictTree(child) for child in root.getchildren() ]\n+            'subtree': [ Element.DictTree(child) for child in ele.getchildren() ]\n         }\n \n     @staticmethod\n", "before": "'subtree' : [ Element . DictTree ( child ) for child in root . getchildren ( ) ]", "after": "'subtree' : [ Element . DictTree ( child ) for child in ele . getchildren ( ) ]", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:root\", 3, 63, 3, 67], \"ele\"]]"}
{"project": "SleekXMPP", "commit_sha": "a1ece44368c472bb5ae61e0c4e4a244c07908a6e", "parent_sha": "ce8bf4a367af313dbf53e4a6ff2ee04a131f7cff", "file_path": "sleekxmpp/plugins/xep_0050.py", "project_url": "https://github.com/mayflower/SleekXMPP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -85,7 +85,7 @@ class xep_0050(base.base_plugin):\n \t\tresults.fromXML(in_command.find('{jabber:x:data}x'))\n \t\tapply(pointer, (results,sessionid))\n \t\tself.xmpp.send(self.makeCommand(xml.attrib['from'], in_command.attrib['node'], form=None, id=xml.attrib['id'], sessionid=sessionid, status='completed', actions=[]))\n-\t\tdel self.sessions[command.get('sessionid')]\n+\t\tdel self.sessions[in_command.get('sessionid')]\n \t\t\n \t\n \tdef handler_command_next(self, xml):\n", "before": "del self . sessions [ command . get ( 'sessionid' ) ]", "after": "del self . sessions [ in_command . get ( 'sessionid' ) ]", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:command\", 3, 21, 3, 28], \"in_command\"]]"}
{"project": "mdtraj", "commit_sha": "2c49c6e36871d4972bfb42587a276220492d9034", "parent_sha": "c1996e286999ffbecbac8249738e7441866405e2", "file_path": "MDTraj/tests/test_nmr.py", "project_url": "https://github.com/Eigenstate/mdtraj", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -6,7 +6,7 @@ from mdtraj.nmr.shift_wrappers import find_executable, SPARTA_PLUS\n @skipif(not find_executable(SPARTA_PLUS), 'SPARTA+ binary not found')\n def test_1():\n     t = md.load(get_fn('2EQQ.pdb'))\n-    result = nmr.chemical_shifts_spartaplus(t)\n+    result = md.chemical_shifts_spartaplus(t)\n \n     print(result)\n \n", "before": "result = nmr . chemical_shifts_spartaplus ( t )", "after": "result = md . chemical_shifts_spartaplus ( t )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:nmr\", 3, 14, 3, 17], \"md\"]]"}
{"project": "sensoredweb", "commit_sha": "54519b03628ea170848f17bd83d4b452482e9f06", "parent_sha": "1b4fbcafed029b43f0ffd233ba2349536f9c7f38", "file_path": "sensordata/tasks.py", "project_url": "https://github.com/borand/sensoredweb", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -119,5 +119,5 @@ def run_cmd(*arg, **kwargs):\n @shared_task\n def publish(*arg, **kwargs):\n \tr = redis.Redis()\n-\tp.publish(arg[0], arg[1])\n+\tr.publish(arg[0], arg[1])\n \n", "before": "p . publish ( arg [ 0 ] , arg [ 1 ] )", "after": "r . publish ( arg [ 0 ] , arg [ 1 ] )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:p\", 3, 2, 3, 3], \"r\"]]"}
{"project": "python-openid", "commit_sha": "b4b669abffabac29bd0c94efe4862351781857db", "parent_sha": "68e232a63d3cdab77659b56ce62b0cc9f5489472", "file_path": "openid/consumer/impl.py", "project_url": "https://github.com/ziima/python-openid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -131,7 +131,7 @@ class OpenIDConsumerImpl(object):\n         if ret is None:\n             return FAILURE, consumer_id\n \n-        results = oidutil.kvToDict(ret[1])\n+        results = kvform.kvToDict(ret[1])\n         is_valid = results.get('is_valid', 'false')\n \n         if is_valid == 'true':\n", "before": "results = oidutil . kvToDict ( ret [ 1 ] )", "after": "results = kvform . kvToDict ( ret [ 1 ] )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:oidutil\", 3, 19, 3, 26], \"kvform\"]]"}
{"project": "hyperdock", "commit_sha": "c74ab7fd94adccd647424d4fcd0d7aa568efa367", "parent_sha": "a8c6d1c9d3edc49cc68f1641758fd5867693a7fa", "file_path": "hyperdock/worker/worker.py", "project_url": "https://github.com/ErikGartner/hyperdock", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ class Worker(Thread):\n             self._run()\n         except:\n             print_crash_analysis()\n-            worker._shutdown()\n+            self._shutdown()\n \n     def _run(self):\n", "before": "worker . _shutdown ( )", "after": "self . _shutdown ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:worker\", 3, 13, 3, 19], \"self\"]]"}
{"project": "cc-utils", "commit_sha": "7b354d70ad5e9fb1a4c43de538e690e48ededb92", "parent_sha": "1fb4bf2b4a03bf45a08d6faae3e8330beb970288", "file_path": "clamav/util.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -85,7 +85,7 @@ def scan_container_image(image_reference: str):\n                 continue # only layer files may contain relevant data\n             with tarfile.open(mode='r|', fileobj=tf.extractfile(ti)) as inner_tf:\n                 for inner_ti in inner_tf:\n-                    if not inner_tf.isfile():\n+                    if not inner_ti.isfile():\n                         continue\n                     status, signature = scan_stream(fileobj=inner_tf.extractfile(inner_ti))\n                     if result_ok(status, signature):\n", "before": "if not inner_tf . isfile ( ) : continue", "after": "if not inner_ti . isfile ( ) : continue", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:inner_tf\", 3, 28, 3, 36], \"inner_ti\"]]"}
{"project": "cc-utils", "commit_sha": "85cabe1ea4f3a860a005e18d3482fec63d88c49d", "parent_sha": "8e484cd0e142df9855358c00355e3bd4a722c983", "file_path": "concourse/enumerator.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -275,7 +275,7 @@ class GithubRepositoryDefinitionEnumerator(GithubDefinitionEnumeratorBase):\n             for org in job_mapping.github_organisations():\n                 if org.org_name() != org_name:\n                     continue\n-                if not job_mapping.repository_matches(repo_name):\n+                if not org.repository_matches(repo_name):\n                     continue\n                 github_cfg = cfg_set.github(org.github_cfg_name())\n                 if github_cfg.matches_hostname(self._repo_host):\n", "before": "if not job_mapping . repository_matches ( repo_name ) : continue", "after": "if not org . repository_matches ( repo_name ) : continue", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:job_mapping\", 3, 24, 3, 35], \"org\"]]"}
{"project": "cc-utils", "commit_sha": "f82e5bcf9cd64d702a15e9cb6f0f72a783d3a08a", "parent_sha": "47d944f6903f3ba6f3583aac0c8681dc11e86606", "file_path": "protecode/client.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ class ProtecodeApi(object):\n     def list_apps(self, group_id, custom_attribs={}):\n         url = self._routes.apps(group_id=group_id, custom_attribs=custom_attribs)\n \n-        result = requsts.get(\n+        result = requests.get(\n             url=url,\n             auth=self._auth,\n         )\n", "before": "result = requsts . get ( url = url , auth = self . _auth , )", "after": "result = requests . get ( url = url , auth = self . _auth , )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:requsts\", 3, 18, 3, 25], \"requests\"]]"}
{"project": "betaisbetterthanalpha", "commit_sha": "8b367dbc07e886a1d096d124ceaca30cc4218779", "parent_sha": "e73a1dcb3184e2ab52914d704566aa058c2e6fb0", "file_path": "front/bot.py", "project_url": "https://github.com/bcho/betaisbetterthanalpha", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,4 +29,4 @@ def dispatch(message):\n     if op and obj:\n         return msg.op(op, obj)\n \n-    return message.show_help()\n+    return msg.show_help()\n", "before": "return message . show_help ( )", "after": "return msg . show_help ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:message\", 3, 12, 3, 19], \"msg\"]]"}
{"project": "QCG-PilotJob", "commit_sha": "295334e594f410bfc49b32277cc59b2497ad38c9", "parent_sha": "2ed936929154f8b9c6d0cd2fec19bb3daf16e1c3", "file_path": "src/qcg/pilotjob/api/manager.py", "project_url": "https://github.com/vecma-project/QCG-PilotJob", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -589,7 +589,7 @@ class Manager:\n             if not_finished:\n                 time.sleep(self._poll_delay)\n \n-        logging.info(\"all jobs finished in manager\")\n+        _logger.info(\"all jobs finished in manager\")\n \n     @staticmethod\n     def is_status_finished(status):\n", "before": "logging . info ( \"all jobs finished in manager\" )", "after": "_logger . info ( \"all jobs finished in manager\" )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:logging\", 3, 9, 3, 16], \"_logger\"]]"}
{"project": "RxPY", "commit_sha": "2962f6517cda43decebba78ec6954173fafc18c9", "parent_sha": "7933d6db83c22debf53f2cf1516dd7d7f2750ac7", "file_path": "rx/linq/observable/sequenceequal.py", "project_url": "https://github.com/mako-taco/RxPY", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -59,7 +59,7 @@ class ObservableSequenceEqual(Observable):\n         first = self\n         comparer = comparer or default_comparer\n         if isinstance(second, list):\n-            return ObservableAggregates.sequence_equal_array(first, second, comparer)\n+            return Observable.sequence_equal_array(first, second, comparer)\n         \n         def subscribe(observer):\n             donel = [False]\n", "before": "return ObservableAggregates . sequence_equal_array ( first , second , comparer )", "after": "return Observable . sequence_equal_array ( first , second , comparer )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:ObservableAggregates\", 3, 20, 3, 40], \"Observable\"]]"}
{"project": "sympy", "commit_sha": "a970d95779d28ef09344e90a41ded83e313577d7", "parent_sha": "663e66b017697a0f1b2cabfd086808ec5b995603", "file_path": "sympy/solvers/ode/systems.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -518,7 +518,7 @@ def _neq_linear_first_order_nonconst_coeff_homogeneous(match_):\n \n     sol_vector = B.exp() * Cvect\n \n-    sol_vector = [collect(s, ordered(J.atoms(exp)), exact=True) for s in sol_vector]\n+    sol_vector = [collect(s, ordered(s.atoms(exp)), exact=True) for s in sol_vector]\n \n     sol_dict = [Eq(func[i], sol_vector[i]) for i in range(n)]\n     return sol_dict\n", "before": "sol_vector = [ collect ( s , ordered ( J . atoms ( exp ) ) , exact = True ) for s in sol_vector ]", "after": "sol_vector = [ collect ( s , ordered ( s . atoms ( exp ) ) , exact = True ) for s in sol_vector ]", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:J\", 3, 38, 3, 39], \"s\"]]"}
{"project": "flutterfuck", "commit_sha": "37cbda4f8fcbdc063bf2d9951447236728ff0b26", "parent_sha": "1972e63ee08b9ce6099db038047c0f658e07e153", "file_path": "willie/modules/rss.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -355,7 +355,7 @@ def read_feeds(bot, force=False):\n \n         # check HTTP status\n         if status == 301:  # MOVED_PERMANENTLY\n-            bot.warning(\n+            LOGGER.warning(\n                 \"Got HTTP 301 (Moved Permanently) on %s, updating URI to %s\",\n                 feed.name, fp.href\n             )\n", "before": "bot . warning ( \"Got HTTP 301 (Moved Permanently) on %s, updating URI to %s\" , feed . name , fp . href )", "after": "LOGGER . warning ( \"Got HTTP 301 (Moved Permanently) on %s, updating URI to %s\" , feed . name , fp . href )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:bot\", 3, 13, 3, 16], \"LOGGER\"]]"}
{"project": "easybuild-easyconfigs", "commit_sha": "0fddb7c21010dba740ada4e7ceeaaaa77add9e3a", "parent_sha": "6fd8af410ddd207ac304bc2b2c0c6ef7cc6e5c06", "file_path": "easybuild/easyblocks/h/hdf5.py", "project_url": "https://github.com/schiotz/easybuild-easyconfigs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -35,7 +35,7 @@ class HDF5(Application):\n             else:\n                 self.log.error(\"Dependency module %s not loaded.\" % dep)\n \n-        fcomp = \"FC=%s\" % self.getenv('F77')\n+        fcomp = \"FC=%s\" % os.getenv('F77')\n \n         self.updatecfg('configopts', \"--enable-cxx --enable-fortran %s\" % fcomp)\n         self.updatecfg('configopts', \"--with-pic --with-pthread --enable-shared\")\n", "before": "fcomp = \"FC=%s\" % self . getenv ( 'F77' )", "after": "fcomp = \"FC=%s\" % os . getenv ( 'F77' )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:self\", 3, 27, 3, 31], \"os\"]]"}
{"project": "nci-webtools-dceg-linkage", "commit_sha": "b0189585356da5e27f2d64522828a259e61c3a32", "parent_sha": "e4b8fb4eef54a7db2e03459ee2d4c911cd366d87", "file_path": "LDlink/LDlink.py", "project_url": "https://github.com/CBIIT/nci-webtools-dceg-linkage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -827,7 +827,7 @@ def ldtrait():\n         web = False\n         reference = str(time.strftime(\"%I%M%S\")) + str(random.randint(0, 10000))\n         snpfile = str(tmp_dir + 'snps' + reference + '.txt')\n-        snplist = thinned_snps.splitlines()\n+        snplist = snps.splitlines()\n         with open(snpfile, 'w') as f:\n             for s in snplist:\n                 s = s.lstrip()\n", "before": "snplist = thinned_snps . splitlines ( )", "after": "snplist = snps . splitlines ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:thinned_snps\", 3, 19, 3, 31], \"snps\"]]"}
{"project": "cdlib", "commit_sha": "dcbcff0bfc2eb9f09b53eb4256037813c743b43d", "parent_sha": "fb7d64cb07fb05391754565c2ffeff9658cd9d9e", "file_path": "cdlib/evaluation/fitness.py", "project_url": "https://github.com/GiulioRossetti/cdlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -711,7 +711,7 @@ def z_modularity(graph, communities, **kwargs):\n         dc = 0\n \n         for node in c:\n-            dc += c.degree(node)\n+            dc += graph.degree(node)\n \n         mmc += (mc / m)\n         dc2m += (dc / (2 * m)) ** 2\n", "before": "dc += c . degree ( node )", "after": "dc += graph . degree ( node )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:c\", 3, 19, 3, 20], \"graph\"]]"}
{"project": "vermouth-martinize", "commit_sha": "d5df09431af044b6a58b428a8fe8303ea66e3691", "parent_sha": "c8d7c362f1543409e93ca331ebfe71ea0e05f173", "file_path": "vermouth/processors/canonicalize_modifications.py", "project_url": "https://github.com/marrink-lab/vermouth-martinize", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -263,7 +263,7 @@ def fix_ptm(molecule):\n                         if attr_name == 'atomname' and val is None:\n                             # DEBUG output\n                             print('Removing node {}, {}'.format(mol_idx, mol_node['atomname']))\n-                            mol_node.remove_node(mol_idx)\n+                            molecule.remove_node(mol_idx)\n                             n_idxs.remove(mol_idx)\n                             break\n                         if mol_node[attr_name] != val:\n", "before": "mol_node . remove_node ( mol_idx )", "after": "molecule . remove_node ( mol_idx )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:mol_node\", 3, 29, 3, 37], \"molecule\"]]"}
{"project": "LogESP", "commit_sha": "053c4680875214d4844de0a639143d46ed766ca8", "parent_sha": "3eee3a63d51428136ee9070ddb689cc38969fe0b", "file_path": "daemons/sentry/rules/limit/limit.py", "project_url": "https://github.com/dogoncouch/LogESP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -754,7 +754,7 @@ class Sentry:\n                         else:\n                             sleep(0.2)\n                         dbtries -= 1\n-                self.lasteventid = e.latest('id').id\n+                self.lasteventid = events.latest('id').id\n                 if self.rule.email_alerts:\n                     self.send_email_alerts(magnitude, totalevents,\n                             numlogsources, numsourcehosts, numdesthosts)\n", "before": "self . lasteventid = e . latest ( 'id' ) . id", "after": "self . lasteventid = events . latest ( 'id' ) . id", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:e\", 3, 36, 3, 37], \"events\"]]"}
{"project": "graphtools", "commit_sha": "afe46f11fd7bfb9222ac50ad5216e6a98cd59c05", "parent_sha": "37fc848d7d6d529b2f56799891a8aab73730f95d", "file_path": "graphtools/estimator.py", "project_url": "https://github.com/KrishnaswamyLab/graphtools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -328,7 +328,7 @@ class GraphEstimator(object, metaclass=abc.ABCMeta):\n         return X, n_pca, self._parse_n_landmark(X), precomputed, update_graph\n \n     def _update_graph(self, X, precomputed, n_pca, n_landmark, **kwargs):\n-        if self.X is not None and not utils.matrix_is_equivalent(X, self.X):\n+        if self.X is not None and not matrix.matrix_is_equivalent(X, self.X):\n", "before": "if self . X is not None and not utils . matrix_is_equivalent ( X , self . X ) : ", "after": "if self . X is not None and not matrix . matrix_is_equivalent ( X , self . X ) : ", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:utils\", 3, 39, 3, 44], \"matrix\"]]"}
{"project": "wtk", "commit_sha": "559571c0bcbe7af5f27778adffae4ff4d842cba8", "parent_sha": "de8a338379703047c17997f5035e94ad0b0bafa9", "file_path": "update_copyright/vcs/git.py", "project_url": "https://github.com/Warbo/wtk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ class GitBackend (_VCSBackend):\n \n     def _years(self, filename=None):\n         dates = self._dates(filename=filename)\n-        years = set(int(line.split('-', 1)[0]) for date in dates)\n+        years = set(int(date.split('-', 1)[0]) for date in dates)\n         return years\n \n     def _authors(self, filename=None):\n", "before": "years = set ( int ( line . split ( '-' , 1 ) [ 0 ] ) for date in dates )", "after": "years = set ( int ( date . split ( '-' , 1 ) [ 0 ] ) for date in dates )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:line\", 3, 25, 3, 29], \"date\"]]"}
{"project": "google-cluster-prediction", "commit_sha": "6fe30d1952d20d105e9ccae52b048482a07919dc", "parent_sha": "ed3b051647fcf3901bf8b1d4ccca9e9357e4d379", "file_path": "prediction/experiment.py", "project_url": "https://github.com/learning-on-chip/google-cluster-prediction", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ class Experiment:\n \n     def run_comparison(self, target):\n         errors = getattr(self, 'run_' + target)(summarize=False)\n-        self.summarize_static(self.summarer, errors, 'comparison_' + target)\n+        support.summarize_static(self.summarer, errors, 'comparison_' + target)\n \n     def run_saving(self):\n         self.state.save(self.session)\n", "before": "self . summarize_static ( self . summarer , errors , 'comparison_' + target )", "after": "support . summarize_static ( self . summarer , errors , 'comparison_' + target )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:self\", 3, 9, 3, 13], \"support\"]]"}
{"project": "charm-neutron-openvswitch", "commit_sha": "0990ac13b331c2c5e84e940f94816cfdb622387e", "parent_sha": "f5321e3f5076388b18551b7844a6113b7716d58b", "file_path": "hooks/neutron_ovs_utils.py", "project_url": "https://github.com/CanonicalBootStack/charm-neutron-openvswitch", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -105,7 +105,7 @@ def restart_map():\n def configure_ovs():\n     add_bridge(INT_BRIDGE)\n     add_bridge(EXT_BRIDGE)\n-    ext_port_ctx = neutron_ovs_context.ExternalPortContext()()\n+    ext_port_ctx = context.ExternalPortContext()()\n     if ext_port_ctx and ext_port_ctx['ext_port']:\n         add_bridge_port(EXT_BRIDGE, ext_port_ctx['ext_port'])\n \n", "before": "ext_port_ctx = neutron_ovs_context . ExternalPortContext ( ) ( )", "after": "ext_port_ctx = context . ExternalPortContext ( ) ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:neutron_ovs_context\", 3, 20, 3, 39], \"context\"]]"}
{"project": "xos-1", "commit_sha": "a512ff11e0c1d88a247d132e7e942541ac927eef", "parent_sha": "be7f22af8c002e4444c3407f99ba46c8b1aff846", "file_path": "xos/observers/vpn/steps/sync_vpntenant.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ class SyncVPNTenant(SyncInstanceUsingAnsible):\n             objs = VPNTenant.get_tenant_objects().filter(\n                 Q(enacted__lt=F('updated')) | Q(enacted=None), Q(lazy_blocked=False))\n             for tenant in objs:\n-                tenant.client_conf = this.generate_client_conf(tenant)\n+                tenant.client_conf = self.generate_client_conf(tenant)\n         else:\n             objs = VPNTenant.get_deleted_tenant_objects()\n \n", "before": "tenant . client_conf = this . generate_client_conf ( tenant )", "after": "tenant . client_conf = self . generate_client_conf ( tenant )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:this\", 3, 38, 3, 42], \"self\"]]"}
{"project": "xos-1", "commit_sha": "7b0dad04ce42339833b38e5e4c655bcf3cf394cb", "parent_sha": "0f521bb7500792d126355be3e8e21aa361fbc19b", "file_path": "planetstack/openstack/client.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -117,7 +117,7 @@ class NovaDB(Client):\n         Client.__init__(self, *args, **kwds)\n         if has_openstack:\n             self.ctx = get_admin_context()\n-            api.FLAGS(default_config_files=['/etc/nova/nova.conf'])\n+            nova_db_api.FLAGS(default_config_files=['/etc/nova/nova.conf'])\n             self.client = nova_db_api\n \n \n", "before": "api . FLAGS ( default_config_files = [ '/etc/nova/nova.conf' ] )", "after": "nova_db_api . FLAGS ( default_config_files = [ '/etc/nova/nova.conf' ] )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:api\", 3, 13, 3, 16], \"nova_db_api\"]]"}
{"project": "Cura", "commit_sha": "d907bfb5e35c767ab7f07aeb7b8f0d39bff8632a", "parent_sha": "ebd933282346d3b4595eb9079d05c7a29026423c", "file_path": "plugins/LayerView/LayerView.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ class LayerView(View):\n         self._only_show_top_layers = bool(Preferences.getInstance().getValue(\"view/only_show_top_layers\"))\n         self._busy = False\n \n-        self.wireprint_warning_message = Message(i18n_catalog.i18nc(\"@info:status\", \"Cura does not accurately display layers when Wire Printing is enabled\"))\n+        self.wireprint_warning_message = Message(catalog.i18nc(\"@info:status\", \"Cura does not accurately display layers when Wire Printing is enabled\"))\n \n     def getActivity(self):\n         return self._activity\n", "before": "self . wireprint_warning_message = Message ( i18n_catalog . i18nc ( \"@info:status\" , \"Cura does not accurately display layers when Wire Printing is enabled\" ) )", "after": "self . wireprint_warning_message = Message ( catalog . i18nc ( \"@info:status\" , \"Cura does not accurately display layers when Wire Printing is enabled\" ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:i18n_catalog\", 3, 50, 3, 62], \"catalog\"]]"}
{"project": "Cura", "commit_sha": "77370d85997e08ef869cbcbda288b0558dd1aef3", "parent_sha": "7b42f52be9e7ad03955dcf5bca3189e50dc1b46a", "file_path": "cura/Settings/ContainerManager.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -668,7 +668,7 @@ class ContainerManager(QObject):\n             new_unique_id = self._createUniqueId(container.getId(), base_name)\n             new_container = container.duplicate(new_unique_id, base_name)\n             if profile_index >= 0:\n-                new_changes.setMetaDataEntry(\"global_profile\", global_changes_id)\n+                new_container.setMetaDataEntry(\"global_profile\", global_changes_id)\n             else:\n                 global_changes_id = new_unique_id\n             new_change_instances.append(new_container)\n", "before": "new_changes . setMetaDataEntry ( \"global_profile\" , global_changes_id )", "after": "new_container . setMetaDataEntry ( \"global_profile\" , global_changes_id )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:new_changes\", 3, 17, 3, 28], \"new_container\"]]"}
{"project": "beets", "commit_sha": "506f1b7351ce70e3e730a277a85fe3b17fbe52c4", "parent_sha": "d13022e51975c0f1c38e85a0ff1b594cecd93e54", "file_path": "test/test_hidden.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -70,5 +70,5 @@ class HiddenFileTest(unittest.TestCase):\n             self.skipTest('sys.platform is known')\n             return\n \n-        with temfile.NamedTemporaryFile(prefix='.tmp') as f:\n+        with tempfile.NamedTemporaryFile(prefix='.tmp') as f:\n             self.assertTrue(hidden.is_hidden(f.name))\n", "before": "with temfile . NamedTemporaryFile ( prefix = '.tmp' ) as f : self . assertTrue ( hidden . is_hidden ( f . name ) )", "after": "with tempfile . NamedTemporaryFile ( prefix = '.tmp' ) as f : self . assertTrue ( hidden . is_hidden ( f . name ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:temfile\", 3, 14, 3, 21], \"tempfile\"]]"}
{"project": "beets", "commit_sha": "9f8b81a5ad1b91f72ddd14ef8aa16c413ce2bb42", "parent_sha": "e8c8f9fb1403ada512fb2564854cb7556d180058", "file_path": "test/rsrc/convert_stub.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -20,7 +20,7 @@ def convert(in_file, out_file, tag):\n     # as UTF-8 bytes.)\n     if platform.system() == 'Windows':\n         in_file = in_file.decode('utf8')\n-        out_file = in_file.decode('utf8')\n+        out_file = out_file.decode('utf8')\n \n     with open(out_file, 'wb') as out_f:\n         with open(in_file, 'rb') as in_f:\n", "before": "out_file = in_file . decode ( 'utf8' )", "after": "out_file = out_file . decode ( 'utf8' )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:in_file\", 3, 20, 3, 27], \"out_file\"]]"}
{"project": "KittiSeg", "commit_sha": "8b5b26fd07c5f415228ca0076c7e758847b89314", "parent_sha": "e82d1674520730daa8fa0ad41fb103434e79baf7", "file_path": "model/segmentation/kitti_seg_input.py", "project_url": "https://github.com/ThinkBigAnalytics/KittiSeg", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ def _make_data_gen(hypes, phase, data_dir):\n \n         yield np.fliplr(image), np.fliplr(gt_image)\n \n-        yield np.flipud(image), npy.flipud(gt_image)\n+        yield np.flipud(image), np.flipud(gt_image)\n \n         yield np.flipud(np.fliplr(image)), np.flipud(np.fliplr(gt_image))\n \n", "before": "yield np . flipud ( image ) , npy . flipud ( gt_image )", "after": "yield np . flipud ( image ) , np . flipud ( gt_image )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:npy\", 3, 33, 3, 36], \"np\"]]"}
{"project": "h", "commit_sha": "0a1494b2d35097b4ae62dae92677af4f35b10f74", "parent_sha": "680161e2a1fb93fd0257dd16cf10857bf258606c", "file_path": "h/api.py", "project_url": "https://github.com/project-star/h", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -232,7 +232,7 @@ def _search(request_params, user = None):\n \n     log.debug(\"Searching with user=%s, for uri=%s\",\n               user.id if user else 'None',\n-              search_params.get('uri'))\n+              request_params.get('uri'))\n \n     if 'any' in search_params['query']:\n         # Handle any field parameters\n", "before": "log . debug ( \"Searching with user=%s, for uri=%s\" , user . id if user else 'None' , search_params . get ( 'uri' ) )", "after": "log . debug ( \"Searching with user=%s, for uri=%s\" , user . id if user else 'None' , request_params . get ( 'uri' ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:search_params\", 3, 15, 3, 28], \"request_params\"]]"}
{"project": "requests-html", "commit_sha": "34dcd78ba14733589066ed9cdc497fad4c1822e8", "parent_sha": "e5a7be391beb1afe97bf61677fcfbfd42908e32c", "file_path": "requests_html.py", "project_url": "https://github.com/wuqiangroy/requests-html", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -418,7 +418,7 @@ class HTML(BaseParser):\n         while True:\n             yield next\n             try:\n-                next = self.next(fetch=True).html\n+                next = next.next(fetch=True).html\n             except AttributeError:\n                 break\n \n", "before": "next = self . next ( fetch = True ) . html", "after": "next = next . next ( fetch = True ) . html", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:self\", 3, 24, 3, 28], \"next\"]]"}
{"project": "script.skin.helper.service", "commit_sha": "e73a9bf6f3c66b1b44adadbe918546f71a62f263", "parent_sha": "7b9ec2a21e3a302c78690c1540b8a92bce7fba94", "file_path": "resources/lib/PluginContent.py", "project_url": "https://github.com/mgonzales71/script.skin.helper.service", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -134,7 +134,7 @@ def doMainListing(mode=\"\"):\n     #music nodes\n     if xbmc.getCondVisibility(\"Library.HasContent(music)\"):\n         addDirectoryItem(xbmc.getLocalizedString(359), \"plugin://script.skin.helper.service/?action=recentalbums&limit=100\")\n-        addDirectoryItem(xbmc.getLocalizedString(32187), \"plugin://script.skin.helper.service/?action=randomalbums&limit=100\")\n+        addDirectoryItem(ADDON.getLocalizedString(32187), \"plugin://script.skin.helper.service/?action=randomalbums&limit=100\")\n         addDirectoryItem(ADDON.getLocalizedString(32087), \"plugin://script.skin.helper.service/?action=recentsongs&limit=100\")\n         addDirectoryItem(ADDON.getLocalizedString(32188), \"plugin://script.skin.helper.service/?action=randomsongs&limit=100\")\n         addDirectoryItem(xbmc.getLocalizedString(517), \"plugin://script.skin.helper.service/?action=recentplayedalbums&limit=100\")\n", "before": "addDirectoryItem ( xbmc . getLocalizedString ( 32187 ) , \"plugin://script.skin.helper.service/?action=randomalbums&limit=100\" )", "after": "addDirectoryItem ( ADDON . getLocalizedString ( 32187 ) , \"plugin://script.skin.helper.service/?action=randomalbums&limit=100\" )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:xbmc\", 3, 26, 3, 30], \"ADDON\"]]"}
{"project": "large-events", "commit_sha": "d51981715ea51707f276ba740d0c79d0806e24ba", "parent_sha": "6d5e4f71edd98443dff4fbe8bc602e3a3136e601", "file_path": "events/app.py", "project_url": "https://github.com/knative-portability/large-events", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -75,7 +75,7 @@ def edit_event(event_id):\n def get_all_events():\n     \"\"\"Return a list of all events currently in the DB.\"\"\"\n     try:\n-        events = events_collection.find()\n+        events = EVENTS_COLL.find()\n         events_dict = build_events_dict(events)\n         # TODO(cmei4444): test with pageserve to make sure the json format is\n         # correct in the response\n", "before": "events = events_collection . find ( )", "after": "events = EVENTS_COLL . find ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:events_collection\", 3, 18, 3, 35], \"EVENTS_COLL\"]]"}
{"project": "stock-logistics-warehouse", "commit_sha": "2bbca9cb96f56ad40a11dbbff2df827d5188263a", "parent_sha": "ae9db31026e19bc5f0cd6f130e9def924c46ee7e", "file_path": "stock_quant_merge/models/stock.py", "project_url": "https://github.com/kmee/stock-logistics-warehouse", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ class StockQuant(models.Model):\n         pending_quants = self.browse(self.ids)\n         for quant2merge in self.filtered(lambda x: not x.reservation_id):\n             if quant2merge in pending_quants:\n-                quants = self.search(self._mergeable_domain())\n+                quants = self.search(quant2merge._mergeable_domain())\n                 cont = 1\n                 cost = quant2merge.cost\n                 for quant in quants:\n", "before": "quants = self . search ( self . _mergeable_domain ( ) )", "after": "quants = self . search ( quant2merge . _mergeable_domain ( ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:self\", 3, 38, 3, 42], \"quant2merge\"]]"}
{"project": "pritunl", "commit_sha": "35b94b3d5969855e3221238b087335cac2d53234", "parent_sha": "73c2ce617ac32b308c45c9e4f04a1432e4beb08e", "file_path": "pritunl/handlers/host.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ def host_put(host_id=None):\n     hst.commit(hst.changed)\n     event.Event(type=HOSTS_UPDATED)\n \n-    return utils.jsonify(host.dict())\n+    return utils.jsonify(hst.dict())\n \n @app.app.route('/host/<host_id>', methods=['DELETE'])\n @auth.session_auth\n", "before": "return utils . jsonify ( host . dict ( ) )", "after": "return utils . jsonify ( hst . dict ( ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:host\", 3, 26, 3, 30], \"hst\"]]"}
{"project": "pritunl", "commit_sha": "79f540f8aed9dc59b850770687ff1be7f1b39725", "parent_sha": "fa4a7c3cbd043fa3299ca71df1179f6bd95c503f", "file_path": "pritunl/auth_token.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -21,4 +21,4 @@ class AuthToken(CacheObject):\n     def __getattr__(self, name):\n         if name == 'valid':\n             return bool(self.time)\n-        return CacheDatabaseObject.__getattr__(self, name)\n+        return CacheObject.__getattr__(self, name)\n", "before": "return CacheDatabaseObject . __getattr__ ( self , name )", "after": "return CacheObject . __getattr__ ( self , name )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:CacheDatabaseObject\", 3, 16, 3, 35], \"CacheObject\"]]"}
{"project": "pritunl", "commit_sha": "83dd2edbf01ad9e74575b7bafe2cbb7a99ae05a4", "parent_sha": "c0c3dda136328f33faa84dc9f44460d569e44bfc", "file_path": "pritunl/handlers/host.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -17,7 +17,7 @@ import collections\n @app_server.auth\n def host_get(host_id=None):\n     if host_id:\n-        return tils.jsonify(Host.get_host(id=host_id).dict())\n+        return utils.jsonify(Host.get_host(id=host_id).dict())\n \n     hosts = []\n \n", "before": "return tils . jsonify ( Host . get_host ( id = host_id ) . dict ( ) )", "after": "return utils . jsonify ( Host . get_host ( id = host_id ) . dict ( ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:tils\", 3, 16, 3, 20], \"utils\"]]"}
{"project": "openstates", "commit_sha": "e19e80c2e347edc99a40d7a90722e7bd8532f167", "parent_sha": "cb40a13e89dcfb98c5932a882e34fd2758989a55", "file_path": "fiftystates/backend/utils.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -147,7 +147,7 @@ def convert_timestamps(obj):\n     for vote in obj.get('votes', []):\n         vote['date'] = timestamp_to_dt(vote['date'])\n \n-        for source in obj.get('sources', []):\n+        for source in vote.get('sources', []):\n             source['retrieved'] = timestamp_to_dt(source['retrieved'])\n \n     if 'date' in obj:\n", "before": "for source in obj . get ( 'sources' , [ ] ) : source [ 'retrieved' ] = timestamp_to_dt ( source [ 'retrieved' ] )", "after": "for source in vote . get ( 'sources' , [ ] ) : source [ 'retrieved' ] = timestamp_to_dt ( source [ 'retrieved' ] )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:obj\", 3, 23, 3, 26], \"vote\"]]"}
{"project": "openstates", "commit_sha": "d3fc8ded0d39e8be91e5fe09b149b8bbf45b98b3", "parent_sha": "7f2e968afe381a5abee6182429fa07a5f9bb8652", "file_path": "openstates/il/legislators.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ class ILLegislatorScraper(LegislatorScraper):\n             leg.add_source(leg_url)\n \n             # email\n-            email = doc.xpath('//b[text()=\"Email: \"]')\n+            email = leg_doc.xpath('//b[text()=\"Email: \"]')\n             if email:\n                 leg['email'] = email[0].tail\n \n", "before": "email = doc . xpath ( '//b[text()=\"Email: \"]' )", "after": "email = leg_doc . xpath ( '//b[text()=\"Email: \"]' )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:doc\", 3, 21, 3, 24], \"leg_doc\"]]"}
{"project": "openstates", "commit_sha": "6301152080ac12be5ae0dd26e1ea0a1597426248", "parent_sha": "640022da43b6e81cad30806920046ae5c4fcf718", "file_path": "openstates/sc/bills.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -484,7 +484,7 @@ class SCBillScraper(BillScraper):\n         version_html = self.urlopen(version_url)\n         version_doc = lxml.html.fromstring(version_html)\n         version_doc.make_links_absolute(bill_detail_url)\n-        for version in doc.xpath('//a[contains(@href, \"/prever/\")]'):\n+        for version in version_doc.xpath('//a[contains(@href, \"/prever/\")]'):\n             bill.add_version(version.text, version.get('href'))\n \n         # actions\n", "before": "for version in doc . xpath ( '//a[contains(@href, \"/prever/\")]' ) : bill . add_version ( version . text , version . get ( 'href' ) )", "after": "for version in version_doc . xpath ( '//a[contains(@href, \"/prever/\")]' ) : bill . add_version ( version . text , version . get ( 'href' ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:doc\", 3, 24, 3, 27], \"version_doc\"]]"}
{"project": "openstates", "commit_sha": "5c9f6e869c00d45cddbbed6a624d9047757432a3", "parent_sha": "77b37a119b51d5cb4d13195dab65046147154ebe", "file_path": "openstates/wv/bills.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -82,7 +82,7 @@ class WVBillScraper(BillScraper):\n         else:\n             # sometimes (resolutions only?) there aren't links so we have to\n             # use a regex to get sponsors\n-            block = doc.xpath('//div[@id=\"bhistleft\"]')[0].text_content()\n+            block = page.xpath('//div[@id=\"bhistleft\"]')[0].text_content()\n             # just text after sponsors\n             lines = block.split('SPONSOR(S):\\r\\n')[1].splitlines()\n             for line in lines:\n", "before": "else : block = doc . xpath ( '//div[@id=\"bhistleft\"]' ) [ 0 ] . text_content ( )", "after": "else : block = page . xpath ( '//div[@id=\"bhistleft\"]' ) [ 0 ] . text_content ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:doc\", 3, 21, 3, 24], \"page\"]]"}
{"project": "anki-addons-dae", "commit_sha": "bd1cf539cc83cab0191ec1f9f1c7566b29a68add", "parent_sha": "cfc1ada285c45d8978ca8c6215a40d3f76982897", "file_path": "cardstats.py", "project_url": "https://github.com/glutanimate/anki-addons-dae", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ class CardStats(object):\n         dock.setFeatures(QDockWidget.DockWidgetClosable)\n         dock.setWidget(w)\n         if mw.width() < 600:\n-            mw.resize(QSize(600, self.height()))\n+            mw.resize(QSize(600, mw.height()))\n         mw.addDockWidget(Qt.RightDockWidgetArea, dock)\n         return dock\n \n", "before": "mw . resize ( QSize ( 600 , self . height ( ) ) )", "after": "mw . resize ( QSize ( 600 , mw . height ( ) ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:self\", 3, 34, 3, 38], \"mw\"]]"}
{"project": "cpython", "commit_sha": "9f7f05c79909bb48788498a9dbbab11c31f92f3c", "parent_sha": "8ebbf1dd0958eafab8d14af6a6c15191cc140aa0", "file_path": "Lib/test/test_shelve.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -99,7 +99,7 @@ class TestShelveBase(mapping_tests.BasicTestMappingProtocol):\n         self._db = []\n         if not self._in_mem:\n             for f in glob.glob(self.fn+\"*\"):\n-                os.unlink(f)\n+                test_support.unlink(f)\n \n class TestAsciiFileShelve(TestShelveBase):\n     _args={'protocol':0}\n", "before": "os . unlink ( f )", "after": "test_support . unlink ( f )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:os\", 3, 17, 3, 19], \"test_support\"]]"}
{"project": "cpython", "commit_sha": "af35c33eae9d7fccba2904301c78f9798cc8d9d8", "parent_sha": "f9b483f7abbed78f9ead8e696920970fcbb01288", "file_path": "Lib/test/test_audioop.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ class TestAudioop(unittest.TestCase):\n \n     def test_minmax(self):\n         self.assertEqual(audioop.minmax(data[0], 1), (0, 2))\n-        Self.assertEqual(audioop.minmax(data[1], 2), (0, 2))\n+        self.assertEqual(audioop.minmax(data[1], 2), (0, 2))\n         self.assertEqual(audioop.minmax(data[2], 4), (0, 2))\n \n     def test_maxpp(self):\n", "before": "Self . assertEqual ( audioop . minmax ( data [ 1 ] , 2 ) , ( 0 , 2 ) )", "after": "self . assertEqual ( audioop . minmax ( data [ 1 ] , 2 ) , ( 0 , 2 ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:Self\", 3, 9, 3, 13], \"self\"]]"}
{"project": "cpython", "commit_sha": "e46e4bd303c936f9ef0cd4a691eebceb8485828e", "parent_sha": "062ad89c41640dc7d00712f65e9a797327ee0eb4", "file_path": "Lib/importlib/test/util.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -11,7 +11,7 @@ def case_insensitive_tests(class_):\n     if sys.platform not in ('win32', 'darwin', 'cygwin'):\n         original_name = os.listdir('.')[0]\n-        if name.upper() != original_name:\n+        if orignal_name.upper() != original_name:\n             changed_name = original_name.upper()\n         else:\n             changed_name = original_name.lower()\n", "before": "if name . upper ( ) != original_name : changed_name = original_name . upper ( ) else : changed_name = original_name . lower ( )", "after": "if orignal_name . upper ( ) != original_name : changed_name = original_name . upper ( ) else : changed_name = original_name . lower ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:name\", 2, 12, 2, 16], \"orignal_name\"]]"}
{"project": "cpython", "commit_sha": "9d258fc4a6716d9549e2546e93ba1eddfee5a138", "parent_sha": "e46e4bd303c936f9ef0cd4a691eebceb8485828e", "file_path": "Lib/importlib/test/util.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -11,7 +11,7 @@ def case_insensitive_tests(class_):\n     if sys.platform not in ('win32', 'darwin', 'cygwin'):\n         original_name = os.listdir('.')[0]\n-        if orignal_name.upper() != original_name:\n+        if original_name.upper() != original_name:\n             changed_name = original_name.upper()\n         else:\n             changed_name = original_name.lower()\n", "before": "if orignal_name . upper ( ) != original_name : changed_name = original_name . upper ( ) else : changed_name = original_name . lower ( )", "after": "if original_name . upper ( ) != original_name : changed_name = original_name . upper ( ) else : changed_name = original_name . lower ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:orignal_name\", 2, 12, 2, 24], \"original_name\"]]"}
{"project": "cpython", "commit_sha": "9165ab7d31252dec4feb1cceeed129daa386be7d", "parent_sha": "d9ff4bd6240088e17dbd4b015634ee0df6e749ed", "file_path": "Lib/test/test_descr.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1020,7 +1020,7 @@ order (MRO) for bases \"\"\"\n             def __del__(self_):\n                 self.assertEqual(self_.a, 1)\n                 self.assertEqual(self_.b, 2)\n-        with test_support.captured_output('stderr') as s:\n+        with support.captured_output('stderr') as s:\n             h = H()\n             del h\n         self.assertEqual(s.getvalue(), '')\n", "before": "with test_support . captured_output ( 'stderr' ) as s : h = H ( ) del h", "after": "with support . captured_output ( 'stderr' ) as s : h = H ( ) del h", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:test_support\", 3, 14, 3, 26], \"support\"]]"}
{"project": "cpython", "commit_sha": "82b4c0dc65b4b34df28565868e3edcc025b0e96e", "parent_sha": "33bffc3510ffbe564beda4aeb146596a7e513bb8", "file_path": "Lib/packaging/util.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -782,7 +782,7 @@ def spawn(cmd, search_path=True, verbose=0, dry_run=False, env=None):\n     logger.debug('spawn: running %r', cmd)\n     if dry_run:\n-        logging.debug('dry run, no process actually spawned')\n+        logger.debug('dry run, no process actually spawned')\n         return\n     if sys.platform == 'darwin':\n         global _cfg_target, _cfg_target_split\n", "before": "logging . debug ( 'dry run, no process actually spawned' )", "after": "logger . debug ( 'dry run, no process actually spawned' )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:logging\", 2, 9, 2, 16], \"logger\"]]"}
{"project": "cpython", "commit_sha": "643a01518bc6f656e11946f735be3a35806c5c8f", "parent_sha": "89a60b49c48a47dd46334a9573650ddd4d7eb7b0", "file_path": "Lib/test/test_platform.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -134,7 +134,7 @@ class PlatformTest(unittest.TestCase):\n         # using it, per\n         # http://blogs.msdn.com/david.wang/archive/2006/03/26/HOWTO-Detect-Process-Bitness.aspx\n         try:\n-            with test_support.EnvironmentVarGuard() as environ:\n+            with support.EnvironmentVarGuard() as environ:\n                 if 'PROCESSOR_ARCHITEW6432' in environ:\n                     del environ['PROCESSOR_ARCHITEW6432']\n                 environ['PROCESSOR_ARCHITECTURE'] = 'foo'\n", "before": "with test_support . EnvironmentVarGuard ( ) as environ : if 'PROCESSOR_ARCHITEW6432' in environ : del environ [ 'PROCESSOR_ARCHITEW6432' ] environ [ 'PROCESSOR_ARCHITECTURE' ] = 'foo'", "after": "with support . EnvironmentVarGuard ( ) as environ : if 'PROCESSOR_ARCHITEW6432' in environ : del environ [ 'PROCESSOR_ARCHITEW6432' ] environ [ 'PROCESSOR_ARCHITECTURE' ] = 'foo'", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:test_support\", 3, 18, 3, 30], \"support\"]]"}
{"project": "cpython", "commit_sha": "c87ca37017f336a19675412b393df168031ec258", "parent_sha": "3324188b226b2bc20b82bffb2feebd16f6c502a4", "file_path": "Lib/distutils/tests/test_build_ext.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,7 +52,7 @@ class BuildExtTestCase(TempdirManager, LoggingSilencer, unittest.TestCase):\n     def tearDown(self):\n         # Get everything back to normal\n         if os.path.exists(_XX_MODULE_PATH):\n-            test_support.unload('xx')\n+            support.unload('xx')\n             sys.path[:] = self.sys_path\n             # XXX on Windows the test leaves a directory\n             # with xx module in TEMP\n", "before": "test_support . unload ( 'xx' )", "after": "support . unload ( 'xx' )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:test_support\", 3, 13, 3, 25], \"support\"]]"}
{"project": "cpython", "commit_sha": "7f78eeb879d03c98802968f82a9c59507c9a89ba", "parent_sha": "bc489a494dcd6de8ed001da63d635198e588f7eb", "file_path": "Tools/scripts/pycolorize.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ default_html = '''\\\n \n def build_page(source, html=default_html, css=default_css):\n     'Create a complete HTML page with colorized Python source code'\n-    css_str = ''.join(['%s %s\\n' % item for item in default_css.items()])\n+    css_str = ''.join(['%s %s\\n' % item for item in css.items()])\n     result = colorize(source)\n     return html % (css_str, result)\n \n", "before": "css_str = '' . join ( [ '%s %s\\n' % item for item in default_css . items ( ) ] )", "after": "css_str = '' . join ( [ '%s %s\\n' % item for item in css . items ( ) ] )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:default_css\", 3, 53, 3, 64], \"css\"]]"}
{"project": "cpython", "commit_sha": "dc52a3eb5a79c276542b901f5e43472b06fd0010", "parent_sha": "6c737683087ba396178a0b55c7b7f97dfd806842", "file_path": "Lib/site.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -465,7 +465,7 @@ def venv(known_paths):\n         with open(virtual_conf) as f:\n             for line in f:\n                 line = line.strip()\n-                m = CONFIG_LINE.match(line)\n+                m = config_line.match(line)\n                 if m:\n                     d = m.groupdict()\n                     key, value = d['key'].lower(), d['value']\n", "before": "m = CONFIG_LINE . match ( line )", "after": "m = config_line . match ( line )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:CONFIG_LINE\", 3, 21, 3, 32], \"config_line\"]]"}
{"project": "cpython", "commit_sha": "b63d8233577beda992fca22f185a103d73a69da4", "parent_sha": "b1e736aa30f2df99c4ed00c1a2d343381d183a94", "file_path": "Lib/xml/sax/saxutils.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -218,7 +218,7 @@ def prepare_input_source(source, base = \"\"):\n         source = xmlreader.InputSource()\n         source.setByteStream(f)\n         if hasattr(f, \"name\"):\n-            f.setSystemId(f.name)\n+            source.setSystemId(f.name)\n \n     if source.getByteStream() is None:\n         sysid = source.getSystemId()\n", "before": "f . setSystemId ( f . name )", "after": "source . setSystemId ( f . name )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:f\", 3, 13, 3, 14], \"source\"]]"}
{"project": "populo", "commit_sha": "daf35bed8fd156acc6d6cd9dbb9488b1feb7c894", "parent_sha": "2a4b3c969afd7e294201733d4363d8b66669aa8b", "file_path": "lms/djangoapps/instructor/views/legacy.py", "project_url": "https://github.com/chauhanhardik/populo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -694,7 +694,7 @@ def instructor_dashboard(request, course_id):\n \n         datatable = {'header': ['User ID', 'Anonymized user ID', 'Course Specific Anonymized user ID']}\n         datatable['data'] = [[s.id, unique_id_for_user(s), anonymous_id_for_user(s, course_id)] for s in students]\n-        return return_csv(course_id.to_deprecated_string().replace('/', '-') + '-anon-ids.csv', datatable)\n+        return return_csv(course_key.to_deprecated_string().replace('/', '-') + '-anon-ids.csv', datatable)\n \n     #----------------------------------------\n     # Group management\n", "before": "return return_csv ( course_id . to_deprecated_string ( ) . replace ( '/' , '-' ) + '-anon-ids.csv' , datatable )", "after": "return return_csv ( course_key . to_deprecated_string ( ) . replace ( '/' , '-' ) + '-anon-ids.csv' , datatable )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:course_id\", 3, 27, 3, 36], \"course_key\"]]"}
{"project": "smart-cache", "commit_sha": "ebbb8091da8020dac54b8bba89a4c2f7381d6f4f", "parent_sha": "cb377a82d3ca3e4874c15b943c90c6cd7666b231", "file_path": "scripts/test_lstm.py", "project_url": "https://github.com/Cloud-PG/smart-cache", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -131,7 +131,7 @@ def period(start_date, num_days):\n \n \n def convert_record(record, max_depth: int = 7):\n-    tmp = \"/\".join(s.split(\"/\")[:max_depth])\n+    tmp = \"/\".join(record.split(\"/\")[:max_depth])\n     for elm in string.punctuation:\n         tmp = tmp.replace(elm, \" \")\n     return tmp + \"\\n\"\n", "before": "tmp = \"/\" . join ( s . split ( \"/\" ) [ : max_depth ] )", "after": "tmp = \"/\" . join ( record . split ( \"/\" ) [ : max_depth ] )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:s\", 3, 20, 3, 21], \"record\"]]"}
{"project": "politwoops-hogar-bot", "commit_sha": "d2fe3e6307784d281813e8490fd627b0b71696f7", "parent_sha": "18c60d59fe53fb105cb5c5fa4bf79719e9d568b1", "file_path": "hogar/Utils/Telegram.py", "project_url": "https://github.com/breyten/politwoops-hogar-bot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -137,7 +137,7 @@ def send_message(recipient, message_type, message):\n     }\n \n     # Log the sending of a message\n-    logging.info('Sending {message_type} message to {recipient}'.format(\n+    logger.info('Sending {message_type} message to {recipient}'.format(\n         message_type = message_type,\n         recipient = recipient['first_name']\n     ))\n", "before": "logging . info ( 'Sending {message_type} message to {recipient}' . format ( message_type = message_type , recipient = recipient [ 'first_name' ] ) )", "after": "logger . info ( 'Sending {message_type} message to {recipient}' . format ( message_type = message_type , recipient = recipient [ 'first_name' ] ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:logging\", 3, 5, 3, 12], \"logger\"]]"}
{"project": "hownix", "commit_sha": "d7e57081438947d3bde250ca257e06025be567a3", "parent_sha": "54595c0963c5cc9c4039b8bd627dc0b7bbbb68c8", "file_path": "hownix/hownix.py", "project_url": "https://github.com/cappachu/hownix", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,7 +31,7 @@ def retrieve_so_page_links(query):\n def load_commands():\n     \"\"\"Load unix/linux commands names from text file\"\"\"\n     command_data = pkgutil.get_data('hownix', 'nix_commands.txt')\n-    return [l.strip() for l in data.split('\\n')]\n+    return [l.strip() for l in command_data.split('\\n')]\n            \n \n def line_2_cmd(line):\n", "before": "return [ l . strip ( ) for l in data . split ( '\\n' ) ]", "after": "return [ l . strip ( ) for l in command_data . split ( '\\n' ) ]", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:data\", 3, 32, 3, 36], \"command_data\"]]"}
{"project": "python-swjsq", "commit_sha": "e2764ac263897ca5d76c55a231d645ccc09af8d1", "parent_sha": "978b3d8a6d629719b3d40e570ca1d56c7ce80150", "file_path": "swjsq/cli.py", "project_url": "https://github.com/timothyqiu/python-swjsq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -101,7 +101,7 @@ def load_credentials_from_env():\n         raise RuntimeError('Environment variables not set')\n     # type of environment variable is different between PY2 and PY3\n     if uid is text_type:\n-        uid = pwd.encode(sys.getfilesystemencoding())\n+        uid = uid.encode(sys.getfilesystemencoding())\n     if pwd is text_type:\n         pwd = pwd.encode(sys.getfilesystemencoding())\n     pwd = hashlib.md5(pwd).hexdigest()\n", "before": "uid = pwd . encode ( sys . getfilesystemencoding ( ) )", "after": "uid = uid . encode ( sys . getfilesystemencoding ( ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:pwd\", 3, 15, 3, 18], \"uid\"]]"}
{"project": "electrum", "commit_sha": "d3465bb60ab8f48e6e7657651aa4373abb6efbc3", "parent_sha": "f5ade2da86200ea477a5e984d159cad493c7a42d", "file_path": "plugins/ledger/ledger.py", "project_url": "https://github.com/UnitedBitcoin/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ class Ledger_Client():\n         #self.get_client() # prompt for the PIN before displaying the dialog if necessary\n         #self.handler.show_message(\"Computing master public key\")\n         try:\n-            if xtype in ['p2wpkh', 'p2wsh'] and not nelf.supports_native_segwit():\n+            if xtype in ['p2wpkh', 'p2wsh'] and not self.supports_native_segwit():\n                 raise Exception(\"Firmware version too old for Segwit support. Please update at https://www.ledgerwallet.com\")\n             if xtype in ['p2wpkh-p2sh', 'p2wsh-p2sh'] and not self.supports_segwit():\n                 raise Exception(\"Firmware version too old for Segwit support. Please update at https://www.ledgerwallet.com\")\n", "before": "if xtype in [ 'p2wpkh' , 'p2wsh' ] and not nelf . supports_native_segwit ( ) : raise Exception ( \"Firmware version too old for Segwit support. Please update at https://www.ledgerwallet.com\" )", "after": "if xtype in [ 'p2wpkh' , 'p2wsh' ] and not self . supports_native_segwit ( ) : raise Exception ( \"Firmware version too old for Segwit support. Please update at https://www.ledgerwallet.com\" )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:nelf\", 3, 53, 3, 57], \"self\"]]"}
{"project": "sunpy", "commit_sha": "b7aaf7a11a6c508364ed5f6077e9746fcdc891fe", "parent_sha": "19f11b64516625b9c793723e9dcbac24bb3a8621", "file_path": "sunpy/spectra/spectrogram.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -388,7 +388,7 @@ class Spectrogram(Parent):\n     def peek(self, *args, **kwargs):\n         figure()\n         ret = self.plot(*args, **kwargs)\n-        ret.show()\n+        plt.show()\n         return ret\n \n     def plot(self, figure=None, overlays=[], colorbar=True, min_=None, max_=None,\n", "before": "ret . show ( )", "after": "plt . show ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:ret\", 3, 9, 3, 12], \"plt\"]]"}
{"project": "condex", "commit_sha": "9a839dae5974987c5440986fbc0e0b67e16ac60a", "parent_sha": "312e07b2323e221fb8a72d577258f8b0fbe9a6dc", "file_path": "managers/ShowCommandManager.py", "project_url": "https://github.com/R4stl1n/condex", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -59,7 +59,7 @@ class ShowCommandManager:\n             coinBalance = CoinBalanceModel.get(CoinBalanceModel.Coin == coin.Ticker)\r\n \r\n             newArray = [coin.Ticker, coinBalance.TotalCoins, coinBalance.BTCBalance, round(coinBalance.USDBalance, 2),\r\n-                        coin.Locked, coin.DesiredPercentage, coin.get_current_percentage(indexInfo.TotalBTCVal), coin.get_percent_from_coin_target(coinBalance,indexInfo.TotalBTCVal)]\r\n+                        coin.Locked, coin.DesiredPercentage, coinBalance.get_current_percentage(indexInfo.TotalBTCVal), coin.get_percent_from_coin_target(coinBalance,indexInfo.TotalBTCVal)]\r\n             cointTableData.append(newArray)\r\n \r\n         # Create the summary table\r\n", "before": "newArray = [ coin . Ticker , coinBalance . TotalCoins , coinBalance . BTCBalance , round ( coinBalance . USDBalance , 2 ) , coin . Locked , coin . DesiredPercentage , coin . get_current_percentage ( indexInfo . TotalBTCVal ) , coin . get_percent_from_coin_target ( coinBalance , indexInfo . TotalBTCVal ) ]", "after": "newArray = [ coin . Ticker , coinBalance . TotalCoins , coinBalance . BTCBalance , round ( coinBalance . USDBalance , 2 ) , coin . Locked , coin . DesiredPercentage , coinBalance . get_current_percentage ( indexInfo . TotalBTCVal ) , coin . get_percent_from_coin_target ( coinBalance , indexInfo . TotalBTCVal ) ]", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:coin\", 3, 62, 3, 66], \"coinBalance\"]]"}
{"project": "condex", "commit_sha": "1c7bb4934bd93f746075019724becc57e7e066dc", "parent_sha": "82b98e3d1a3cc96c940306e9c4a5d57d9e710045", "file_path": "managers/ShowCommandManager.py", "project_url": "https://github.com/R4stl1n/condex", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -59,7 +59,7 @@ class ShowCommandManager:\n             coinBalance = CoinBalanceModel.get(CoinBalanceModel.Coin == coin.Ticker)\r\n \r\n             newArray = [coin.Ticker, coinBalance.TotalCoins, coinBalance.BTCBalance, round(coinBalance.USDBalance, 2),\r\n-                        coin.Locked, coin.DesiredPercentage, coin.get_current_percentage(indexInfo.TotalBTCVal), coin.get_percent_from_coin_target(coinBalance,indexInfo.TotalBTCVal)]\r\n+                        coin.Locked, coin.DesiredPercentage, coinBalance.get_current_percentage(indexInfo.TotalBTCVal), coin.get_percent_from_coin_target(coinBalance,indexInfo.TotalBTCVal)]\r\n             cointTableData.append(newArray)\r\n \r\n         # Create the summary table\r\n", "before": "newArray = [ coin . Ticker , coinBalance . TotalCoins , coinBalance . BTCBalance , round ( coinBalance . USDBalance , 2 ) , coin . Locked , coin . DesiredPercentage , coin . get_current_percentage ( indexInfo . TotalBTCVal ) , coin . get_percent_from_coin_target ( coinBalance , indexInfo . TotalBTCVal ) ]", "after": "newArray = [ coin . Ticker , coinBalance . TotalCoins , coinBalance . BTCBalance , round ( coinBalance . USDBalance , 2 ) , coin . Locked , coin . DesiredPercentage , coinBalance . get_current_percentage ( indexInfo . TotalBTCVal ) , coin . get_percent_from_coin_target ( coinBalance , indexInfo . TotalBTCVal ) ]", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:coin\", 3, 62, 3, 66], \"coinBalance\"]]"}
{"project": "python_utilities", "commit_sha": "30ff5f32e7fd7c06254eecc083c9b852613c75b9", "parent_sha": "c25d9a8f3d38708594305e0274cbe3d6260be25b", "file_path": "database/psycopg2_helper.py", "project_url": "https://github.com/jonathanmorgan/python_utilities", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -236,7 +236,7 @@ class psycopg2_Helper( python_utilities.database.database_helper.Database_Helper\n         # use them to create a connection.  For now, no error checking.  If it\n         #     gets screwed up because the object isn't initialized right, calling\n         #     program will figure it out pretty quickly.\n-        connection_OUT = MySQLdb.connect( host = my_host, port = my_port, user = my_username, password = my_password, database = my_database )\n+        connection_OUT = psycopg2.connect( host = my_host, port = my_port, user = my_username, password = my_password, database = my_database )\n         \n         return connection_OUT\n     \n", "before": "connection_OUT = MySQLdb . connect ( host = my_host , port = my_port , user = my_username , password = my_password , database = my_database )", "after": "connection_OUT = psycopg2 . connect ( host = my_host , port = my_port , user = my_username , password = my_password , database = my_database )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:MySQLdb\", 3, 26, 3, 33], \"psycopg2\"]]"}
{"project": "wxfixboot", "commit_sha": "8dfd5d7221b92f5e4ddbb3b6779ceadf3904869e", "parent_sha": "a6e78d6c21d0a36c8cf97d9e0b77030d5b7b24e9", "file_path": "Tools/BackendTools/BootloaderTools/main.py", "project_url": "https://github.com/hamishmb/wxfixboot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -169,7 +169,7 @@ class Main(): #*** Refactor and test all of these ***\n             wx.CallAfter(ParentWindow.UpdateCurrentProgress, 50)\n \n             #Set the bootloaders new config.\n-            BootloaderConfigSettingTools.SetNewBootloaderConfig()\n+            MainBackendTools.SetNewBootloaderConfig()\n             wx.CallAfter(ParentWindow.UpdateCurrentProgress, 100)\n \n             logger.info(\"MainBootloaderTools: Main().UpdateBootloader(): Done!\")\n", "before": "BootloaderConfigSettingTools . SetNewBootloaderConfig ( )", "after": "MainBackendTools . SetNewBootloaderConfig ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:BootloaderConfigSettingTools\", 3, 13, 3, 41], \"MainBackendTools\"]]"}
{"project": "OpenReliability", "commit_sha": "8912aa9e1bff58365c72569bc09884ce2b9218cb", "parent_sha": "b0595a50409a8cd8803ded74d4f3d4e912e79983", "file_path": "veusz/windows/plotwindow.py", "project_url": "https://github.com/OpenReliability/OpenReliability", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -537,7 +537,7 @@ class PlotWindow( qt4.QGraphicsView ):\n         # convert points on plotter to points on axis for each axis\n         # we also add a neighbouring pixel for the rounding calculation\n         xpts = N.array( [pt1.x(), pt2.x(), pt1.x()+1, pt2.x()-1] )\n-        ypts = N.array( [pt1.y(), pt2.y(), pt2.y()+1, pt2.y()-1] )\n+        ypts = N.array( [pt1.y(), pt2.y(), pt1.y()+1, pt2.y()-1] )\n \n         # build up operation list to do zoom\n         operations = []\n", "before": "ypts = N . array ( [ pt1 . y ( ) , pt2 . y ( ) , pt2 . y ( ) + 1 , pt2 . y ( ) - 1 ] )", "after": "ypts = N . array ( [ pt1 . y ( ) , pt2 . y ( ) , pt1 . y ( ) + 1 , pt2 . y ( ) - 1 ] )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:pt2\", 3, 44, 3, 47], \"pt1\"]]"}
{"project": "PersonalAssistant", "commit_sha": "9d8eb1ed688c6022f6c6315e95dd2f546abb82f7", "parent_sha": "e10776b7a8dc4dd6b430bbc27a10a675464043bb", "file_path": "Samantha/plugins/images_plugin.py", "project_url": "https://github.com/Sirs0ri/PersonalAssistant", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -96,7 +96,7 @@ def generate_wallpaper(background_path, mask_path, destination_path=\"/data/wallp\n \n     core.log(name, \"      Creating the big masks\")\n     mask_BoW_big = mask_BoW.convert(\"RGBA\")\n-    shadow_layer.putalpha(mask_WoB)\n+    mask_BoW_big.putalpha(mask_WoB)\n     offset_layers = []\n     offsets = [(2,2),(-2,2),(2,-2),(-2,-2)]     #offset is defined in the definition of the function. Default is 2.\n     for (x, y) in offsets:\n", "before": "shadow_layer . putalpha ( mask_WoB )", "after": "mask_BoW_big . putalpha ( mask_WoB )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:shadow_layer\", 3, 5, 3, 17], \"mask_BoW_big\"]]"}
{"project": "mercury", "commit_sha": "96babeeeae3084149e23b551cec9a4085240c6a6", "parent_sha": "d86c6cbfae178dc8d962e46fada3af24f6ad61b3", "file_path": "fabric/update.py", "project_url": "https://github.com/pantheon-deprecated/mercury", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -86,7 +86,7 @@ def update_data(source_project=None, source_environment=None, target_project=Non\n        print(target_project + '/' + target_environment + ' database updated with database from ' + source_project + '/' + source_environment)\n \n def update_code(source_project=None, source_environment=None, target_project=None, target_environment=None):\n-       server = python.InstallTools()\n+       server = pantheon.InstallTools()\n \n        if (source_project == None):\n               print(\"No source_project selected. Using 'pantheon'\")\n", "before": "server = python . InstallTools ( )", "after": "server = pantheon . InstallTools ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:python\", 3, 17, 3, 23], \"pantheon\"]]"}
{"project": "mercury", "commit_sha": "815d072fa561eb6608b13e27bca702fe3bfd2e9d", "parent_sha": "814b8566730bf6f5fb1e1653d09ae18b34c994a7", "file_path": "fabric/update.py", "project_url": "https://github.com/pantheon-deprecated/mercury", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -37,7 +37,7 @@ def update_code(project, environment, tag=None, message=None):\n         message = 'Tagging as %s for release.' % tag\n \n     updater = update.Updater(project, environment)\n-    update.test_tag(tag)\n+    updater.test_tag(tag)\n     updater.code_update(tag, message)\n     updater.permissions_update()\n \n", "before": "update . test_tag ( tag )", "after": "updater . test_tag ( tag )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:update\", 3, 5, 3, 11], \"updater\"]]"}
{"project": "scout", "commit_sha": "3d18137c1abc2fff616dc5705898c3efcfcf87c7", "parent_sha": "9d72b8b0e3eeb4c0d2d2a6363fa8255766180a86", "file_path": "scout/commands/load/load_database.py", "project_url": "https://github.com/Clinical-Genomics/scout", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ def user(context, institute_name, user_name, user_mail):\n         context.abort()\n \n     user_info = dict(email=user_mail, name=user_name, roles=['admin'], institutes=[institute])\n-    user.add_user(user_info)\n+    adapter.add_user(user_info)\n \n \n @click.group()\n", "before": "user . add_user ( user_info )", "after": "adapter . add_user ( user_info )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:user\", 3, 5, 3, 9], \"adapter\"]]"}
{"project": "honeybee-radiance-command", "commit_sha": "fe62562a0b228b8e46309aa88c116882247c89b9", "parent_sha": "2515e6d94ff955fc7c6431f3d5afa2ab74d7d689", "file_path": "honeybee_radiance_command/_command_util.py", "project_url": "https://github.com/ladybug-tools/honeybee-radiance-command", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -18,7 +18,7 @@ def run_command(input_command, env=None, cwd=None):\n     if platform.system() == 'Windows':\n         command = input_command.replace('\\'', '\"')\n     else:\n-        command = command.replace('\"', '\\'')\n+        command = input_command.replace('\"', '\\'')\n \n     # change cwd - Popen cwd input simply doesn't work.\n     cur_dir = os.getcwd()\n", "before": "command = command . replace ( '\"' , '\\'' )", "after": "command = input_command . replace ( '\"' , '\\'' )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:command\", 3, 19, 3, 26], \"input_command\"]]"}
{"project": "Zappa", "commit_sha": "b5a1ec65ec87dad837cfbb643d32332da4cd6278", "parent_sha": "dc0fb0bcf7ae83944a207fee3e8f6dae391ed295", "file_path": "zappa/core.py", "project_url": "https://github.com/tripliks/Zappa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2178,7 +2178,7 @@ class Zappa(object):\n             return\n         base_path_mappings = self.apigateway_client.get_base_path_mappings(domainName=domain_name)\n         found = False\n-        for base_path_mapping in base_path_mappingss.get('items', []):\n+        for base_path_mapping in base_path_mappings.get('items', []):\n             if base_path_mapping['restApiId'] == api_id and base_path_mapping['stage'] == stage:\n                 found = True\n                 if base_path_mapping['basePath'] != base_path:\n", "before": "for base_path_mapping in base_path_mappingss . get ( 'items' , [ ] ) : if base_path_mapping [ 'restApiId' ] == api_id and base_path_mapping [ 'stage' ] == stage : found = True if base_path_mapping [ 'basePath' ] != base_path : ", "after": "for base_path_mapping in base_path_mappings . get ( 'items' , [ ] ) : if base_path_mapping [ 'restApiId' ] == api_id and base_path_mapping [ 'stage' ] == stage : found = True if base_path_mapping [ 'basePath' ] != base_path : ", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:base_path_mappingss\", 3, 34, 3, 53], \"base_path_mappings\"]]"}
{"project": "autotest-", "commit_sha": "c5fcdf4e73185a29392eff27af26a6d2da7804ab", "parent_sha": "cb98439e96add0a2815a3b5d7738f364bd8ed564", "file_path": "client/common_lib/error.py", "project_url": "https://github.com/bobby0809/autotest-", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -45,7 +45,7 @@ class UnhandledJobError(JobError):\n     \"\"\"Indicates an unhandled error in a job.\"\"\"\n     def __init__(self, unhandled_exception):\n         if isinstance(unhandled_exception, JobError):\n-            TestError.__init__(self, *unhandled_exception.args)\n+            JobError.__init__(self, *unhandled_exception.args)\n         else:\n             msg = \"Unhandled %s: %s\"\n             msg %= (unhandled_exception.__class__.__name__,\n", "before": "TestError . __init__ ( self , * unhandled_exception . args )", "after": "JobError . __init__ ( self , * unhandled_exception . args )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:TestError\", 3, 13, 3, 22], \"JobError\"]]"}
{"project": "quickrpc", "commit_sha": "1775cec6dc3826ea667c307757abe4d4ca201c98", "parent_sha": "9df08c6c16787b53a3f7eafb8d95697bc3515cdc", "file_path": "quickrpc/transports.py", "project_url": "https://github.com/loehnertj/quickrpc", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -385,7 +385,7 @@ class RestartingTransport(Transport):\n             \n         \n     def open(self):\n-        sel._try_start()\n+        self._try_start()\n \n     def run(self):\n         self.running = True\n", "before": "sel . _try_start ( )", "after": "self . _try_start ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:sel\", 3, 9, 3, 12], \"self\"]]"}
{"project": "depmap_analysis", "commit_sha": "aeb9abc541291a89549e902cef8f8e03f41334e0", "parent_sha": "f1f98e86accce3c9b597486455c6d908a8ff8c22", "file_path": "depmap_network_functions.py", "project_url": "https://github.com/indralab/depmap_analysis", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -603,7 +603,7 @@ def nx_directed_graph_from_sif_dataframe(fname):\n                         weight=row['evidence_count'],\n                         stmt_type=row['stmt_type'],\n                         stmt_hash=row['hash'])\n-    logging.info('Loaded %i statements into directed multigraph' % index)\n+    dnf_logger.info('Loaded %i statements into directed multigraph' % index)\n \n     return nx_dir\n \n", "before": "weight = row [ 'evidence_count' ] , stmt_type = row [ 'stmt_type' ] , stmt_hash = row [ 'hash' ] ) logging . info ( 'Loaded %i statements into directed multigraph' % index )", "after": "weight = row [ 'evidence_count' ] , stmt_type = row [ 'stmt_type' ] , stmt_hash = row [ 'hash' ] ) dnf_logger . info ( 'Loaded %i statements into directed multigraph' % index )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:logging\", 3, 5, 3, 12], \"dnf_logger\"]]"}
{"project": "BeepBeep-training-objectives", "commit_sha": "8cb4199cbab44e2c0df51538a66e6fded642b060", "parent_sha": "cda44540c2b780a02a40582021c967a03c3451ec", "file_path": "beepbeep/trainingobjectiveservice/views/swagger.py", "project_url": "https://github.com/MFranceschi6/BeepBeep-training-objectives", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -61,7 +61,7 @@ def update_distance(training_objectives, runner_id):\n         status_code = runs_response.status_code\n \n         if status_code != 200:\n-            abort(status_code, response.json().get('message'))\n+            abort(status_code, runs_response.json().get('message'))\n \n \n         partial_sum = 0\n", "before": "abort ( status_code , response . json ( ) . get ( 'message' ) )", "after": "abort ( status_code , runs_response . json ( ) . get ( 'message' ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:response\", 3, 32, 3, 40], \"runs_response\"]]"}
{"project": "ansible-1", "commit_sha": "62c97cdd3e62db2d90388168ca988a521a414f85", "parent_sha": "1df7d95cec36ac22929c8559f89be14346930138", "file_path": "lib/ansible/module_utils/ios_cli.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -149,7 +149,7 @@ def load_config(module, commands):\n     for command in to_list(commands):\n         if command == 'end':\n             continue\n-        rc, out, err = module.exec_command(command)\n+        rc, out, err = conn.exec_command(command)\n         if rc != 0:\n             module.fail_json(msg=err, command=command, rc=rc)\n \n", "before": "rc , out , err = module . exec_command ( command )", "after": "rc , out , err = conn . exec_command ( command )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:module\", 3, 24, 3, 30], \"conn\"]]"}
{"project": "ansible-1", "commit_sha": "fb2b3de5e4bb40b2344fd708c47f5b942bfa6d17", "parent_sha": "0ebc80cbd66a4c171396812ef9fb9b1a20e3e497", "file_path": "lib/ansible/modules/network/nxos/nxos_vxlan_vtep.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -285,7 +285,7 @@ def main():\n \n     state = module.params['state']\n \n-    args = PARAM_TO_DEFAULT_KEYMAP.keys()\n+    args = PARAM_TO_COMMAND_KEYMAP.keys()\n \n     existing = get_existing(module, args)\n     proposed_args = dict((k, v) for k, v in module.params.items()\n", "before": "args = PARAM_TO_DEFAULT_KEYMAP . keys ( )", "after": "args = PARAM_TO_COMMAND_KEYMAP . keys ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:PARAM_TO_DEFAULT_KEYMAP\", 3, 12, 3, 35], \"PARAM_TO_COMMAND_KEYMAP\"]]"}
{"project": "ansible-1", "commit_sha": "e35a757ee7cbb02e152698518e40af72d26b28f9", "parent_sha": "1e2bd3d4835556c717ba31c9af38f54222404992", "file_path": "lib/ansible/plugins/action/network.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -46,7 +46,7 @@ class ActionModule(ActionBase):\n             result.update(exc.result)\n             for field in ('_ansible_notify',):\n                 if field in result:\n-                    results.pop(field)\n+                    result.pop(field)\n \n         except Exception as exc:\n             if display.verbosity > 2:\n", "before": "results . pop ( field )", "after": "result . pop ( field )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:results\", 3, 21, 3, 28], \"result\"]]"}
{"project": "pritunl", "commit_sha": "1f903b783889a7550af816970d6ae1dfda308adf", "parent_sha": "24a7146759a1f3561237a8b365ae9001e36848ff", "file_path": "pritunl/setup/mongo.py", "project_url": "https://github.com/security-geeks/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -101,7 +101,7 @@ def setup_mongo():\n \n     cur_collections = secondary_database.collection_names()\n     if prefix + 'messages' not in cur_collections:\n-        database.create_collection(prefix + 'messages', capped=True,\n+        secondary_database.create_collection(prefix + 'messages', capped=True,\n             size=200192, max=1500)\n \n     mongo.collections.update({\n", "before": "database . create_collection ( prefix + 'messages' , capped = True , size = 200192 , max = 1500 )", "after": "secondary_database . create_collection ( prefix + 'messages' , capped = True , size = 200192 , max = 1500 )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:database\", 3, 9, 3, 17], \"secondary_database\"]]"}
{"project": "fuel-web", "commit_sha": "b3610d17ebc6dbbc1fb4e0cbaad4577d7f2747b2", "parent_sha": "653dbab90f2c9f40444cf183ab5fc57c42688639", "file_path": "nailgun/nailgun/api/handlers/node.py", "project_url": "https://github.com/ytyanghm/fuel-web", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -305,7 +305,7 @@ class NodeCollectionHandler(JSONHandler):\n                 db().commit()\n             old_cluster_id = node.cluster_id\n \n-            if data.get(\"pending_roles\") == [] and node.cluster:\n+            if nd.get(\"pending_roles\") == [] and node.cluster:\n                 node.cluster.clear_pending_changes(node_id=node.id)\n \n             if \"cluster_id\" in nd:\n", "before": "if data . get ( \"pending_roles\" ) == [ ] and node . cluster : node . cluster . clear_pending_changes ( node_id = node . id )", "after": "if nd . get ( \"pending_roles\" ) == [ ] and node . cluster : node . cluster . clear_pending_changes ( node_id = node . id )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:data\", 3, 16, 3, 20], \"nd\"]]"}
{"project": "ansible-1", "commit_sha": "6b6e3c64c841e688f5146f235d73513de664f80c", "parent_sha": "27d3ac9dc6c2707508893b5afd6482d83f9e6936", "file_path": "lib/ansible/playbook/play.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -165,7 +165,7 @@ class Play(object):\n                     raise errors.AnsibleError(\"'vars_prompt' item is missing 'name:'\")\n \n                 vname = var['name']\n-                prompt = util.template(None, \"%s: \" % var.get(\"prompt\", vname), self.vars)\n+                prompt = utils.template(None, \"%s: \" % var.get(\"prompt\", vname), self.vars)\n                 private = var.get(\"private\", True)\n \n                 confirm = var.get(\"confirm\", False)\n", "before": "prompt = util . template ( None , \"%s: \" % var . get ( \"prompt\" , vname ) , self . vars )", "after": "prompt = utils . template ( None , \"%s: \" % var . get ( \"prompt\" , vname ) , self . vars )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:util\", 3, 26, 3, 30], \"utils\"]]"}
{"project": "ansible-1", "commit_sha": "f1b16119561aa6ab42aa85c0c1ad2aebf1e2dfcd", "parent_sha": "3c2cbae68eb33468e69bfa64a089501370dcc2f9", "file_path": "lib/ansible/playbook/__init__.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -221,7 +221,7 @@ class PlayBook(object):\n \n         # add facts to the global setup cache\n         for host, result in results['contacted'].iteritems():\n-            facts = results.get('ansible_facts', {})\n+            facts = result.get('ansible_facts', {})\n             self.SETUP_CACHE[host].update(facts)\n \n         self.stats.compute(results)\n", "before": "facts = results . get ( 'ansible_facts' , { } )", "after": "facts = result . get ( 'ansible_facts' , { } )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:results\", 3, 21, 3, 28], \"result\"]]"}
{"project": "ansible-1", "commit_sha": "65630d2ce16e39f724a7f3fbdf6bef91afc81cfb", "parent_sha": "cbbb27076152dd1a3bbce58f7fdba58237672896", "file_path": "lib/ansible/plugins/lookup/__init__.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ class LookupBase(with_metaclass(ABCMeta, object)):\n         results = []\n         for x in a:\n             for y in b:\n-                results.append(self._flatten([x,y]))\n+                results.append(LookupBase._flatten([x,y]))\n         return results\n \n     @staticmethod\n", "before": "results . append ( self . _flatten ( [ x , y ] ) )", "after": "results . append ( LookupBase . _flatten ( [ x , y ] ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:self\", 3, 32, 3, 36], \"LookupBase\"]]"}
{"project": "dpo-replication", "commit_sha": "64dc2af34f12ea7d098fb964f41ace6afba9c61b", "parent_sha": "9fd65358f8e54c2c939d90112b6cd4a6900fccae", "file_path": "GAC/networks.py", "project_url": "https://github.com/gwbcho/dpo-replication", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -373,7 +373,7 @@ class Critic(tf.Module):\n \r\n         with tf.GradientTape() as tape2:\r\n             loss2 = tf.reduce_mean((forward_pass(self.layers2, x) - yQ)**2)\r\n-        gradients2 = tape1.gradient(loss2, self.trainable_variables)\r\n+        gradients2 = tape2.gradient(loss2, self.trainable_variables)\r\n         self.optimizer2.apply_gradients(zip(gradients2, self.trainable_variables))\r\n \r\n \r\n", "before": "gradients2 = tape1 . gradient ( loss2 , self . trainable_variables )", "after": "gradients2 = tape2 . gradient ( loss2 , self . trainable_variables )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:tape1\", 3, 22, 3, 27], \"tape2\"]]"}
{"project": "dpo-replication", "commit_sha": "7bc23c68f901cad281b1de50942eeac6a6016427", "parent_sha": "d41331f3129368d4655f281ee3db23793710de55", "file_path": "main.py", "project_url": "https://github.com/gwbcho/dpo-replication", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -198,7 +198,7 @@ def main():\n                 if total_steps % args.eval_freq == 0:\r\n                     eval_rewards = evaluate_policy(gac, eval_env, args.eval_episodes)\r\n                     eval_reward = sum(eval_rewards) / args.eval_episodes\r\n-                    eval_variance = float(numpy.var(eval_rewards))\r\n+                    eval_variance = float(np.var(eval_rewards))\r\n                     results_dict['eval_rewards'].append({\r\n                         'total_steps': total_steps,\r\n                         'average_eval_reward': eval_rewards,\r\n", "before": "eval_variance = float ( numpy . var ( eval_rewards ) )", "after": "eval_variance = float ( np . var ( eval_rewards ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:numpy\", 3, 43, 3, 48], \"np\"]]"}
{"project": "aiida-max-examples", "commit_sha": "275460adcc80b5679e8d0fa756b2a6b1c543274a", "parent_sha": "cbe0fa312204174ea6b54994de92fbb4badd86fb", "file_path": "run.py", "project_url": "https://github.com/aiidateam/aiida-max-examples", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ def load_example_structures():\n             name = os.path.splitext(fname)[0]\n \n             cif = CifData()\n-            structure = c.read_cif(path)\n+            structure = cif.read_cif(path)\n             if \"ML\" in name:\n                 # surface normal of monolayers should be oriented along z\n", "before": "structure = c . read_cif ( path )", "after": "structure = cif . read_cif ( path )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:c\", 3, 25, 3, 26], \"cif\"]]"}
{"project": "pynytimes", "commit_sha": "1c842f33e4372d6c58f8cda86333d0f092592441", "parent_sha": "1aaa42cf5c670474a86bbca9ebd9d8e012bebd9f", "file_path": "pynytimes/api.py", "project_url": "https://github.com/michadenheijer/pynytimes", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -399,7 +399,7 @@ class NYTAPI:\n             if not isinstance(end_date, datetime.datetime):\n                 raise Exception(\"End date has to be datetime\")\n \n-            _end_date = _end_date.strftime(\"%Y%m%d\")\n+            _end_date = end_date.strftime(\"%Y%m%d\")\n \n         if query is not None:\n             options[\"q\"] = query\n", "before": "_end_date = _end_date . strftime ( \"%Y%m%d\" )", "after": "_end_date = end_date . strftime ( \"%Y%m%d\" )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:_end_date\", 3, 25, 3, 34], \"end_date\"]]"}
{"project": "vocabquiz", "commit_sha": "6af68c5e70080cf6150b99c77d811d4073478a44", "parent_sha": "27cf026ce30d1fba13d34f4f0a70800b911a2e99", "file_path": "vocab_quiz.py", "project_url": "https://github.com/din14970/vocabquiz", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -26,11 +26,11 @@ def get_vocablist(list_file = None):\n         allvoc = [filename for filename in allfiles if filename.endswith(\".csv\") or filename.endswith(\".xls\") or filename.endswith(\".xlsx\")]\n         list_file = allvoc[0]\n \n-    if list_file.endswith(\".xls\") or filename.endswith(\".xlsx\"):\n+    if list_file.endswith(\".xls\") or list_file.endswith(\".xlsx\"):\n         vocab_list = pd.read_excel(list_file)\n     else:\n         vocab_list = pd.read_csv(list_file)\n-    \n+\n     print(\"Imported {}\".format(list_file))\n     return vocab_list\n \n", "before": "if list_file . endswith ( \".xls\" ) or filename . endswith ( \".xlsx\" ) : vocab_list = pd . read_excel ( list_file ) else : vocab_list = pd . read_csv ( list_file )", "after": "if list_file . endswith ( \".xls\" ) or list_file . endswith ( \".xlsx\" ) : vocab_list = pd . read_excel ( list_file ) else : vocab_list = pd . read_csv ( list_file )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:filename\", 3, 38, 3, 46], \"list_file\"]]"}
{"project": "gecco", "commit_sha": "24453474ab7f5796990b48521797612af464ec03", "parent_sha": "4ab5d8b57b799a972a8f53ef340c37d7ccef7ed9", "file_path": "gecco/gecco.py", "project_url": "https://github.com/MeTavi/gecco", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -365,7 +365,7 @@ class Corrector:\n         inputqueue.join()\n         duration = time.time() - begintime\n         self.log(\"Input queue processed (\" + str(duration) + \"s)\")\n-        outputqueue.join()\n+        datathread.join()\n         duration = time.time() - begintime\n         self.log(\"Processing done (\" + str(duration) + \"s)\")\n \n", "before": "outputqueue . join ( )", "after": "datathread . join ( )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:outputqueue\", 3, 9, 3, 20], \"datathread\"]]"}
{"project": "salt", "commit_sha": "62185d922b248c04ab31c89424fe9bd134841bdd", "parent_sha": "8c4ff791a7f687cbd439c6b69fd623f7886eed27", "file_path": "salt/client/ssh/shell.py", "project_url": "https://github.com/StepOneInc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -88,7 +88,7 @@ class Shell(object):\n         if self.passwd:\n             options.append('PasswordAuthentication=yes')\n         else:\n-            option.append('PasswordAuthentication=no')\n+            options.append('PasswordAuthentication=no')\n         if self.opts['_ssh_version'] > '4.9':\n             options.append('GSSAPIAuthentication=no')\n         options.append('ConnectTimeout={0}'.format(self.timeout))\n", "before": "option . append ( 'PasswordAuthentication=no' )", "after": "options . append ( 'PasswordAuthentication=no' )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:option\", 3, 13, 3, 19], \"options\"]]"}
{"project": "celery", "commit_sha": "d2ac7cd486633db1df2c5a5ebe422e45e86ee166", "parent_sha": "b33eaf85913b87d16cbe229fcb11057ba24cf406", "file_path": "celery/bin/celeryev.py", "project_url": "https://github.com/sisyfuss/celery", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -37,7 +37,7 @@ class EvCommand(Command):\n     def set_process_status(self, prog, info=\"\"):\n         prog = \"%s:%s\" % (self.prog_name, prog)\n         info = \"%s %s\" % (info, platforms.strargv(sys.argv))\n-        return platform.set_process_title(prog, info=info)\n+        return platforms.set_process_title(prog, info=info)\n \n     def get_options(self):\n         return (\n", "before": "return platform . set_process_title ( prog , info = info )", "after": "return platforms . set_process_title ( prog , info = info )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:platform\", 3, 16, 3, 24], \"platforms\"]]"}
{"project": "chainercv", "commit_sha": "c908712540040b64a924a2ada107a3ec1497f691", "parent_sha": "ad70ebdf47682dff2ad8d2aaf04a76cc9c1f1b11", "file_path": "chainercv/links/ssd.py", "project_url": "https://github.com/yuyu2172/chainercv", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -180,7 +180,7 @@ class _SSDVGG16(chainer.Chain):\n         bbox[:, :2] -= bbox[:, 2:] / 2\n         bbox[:, 2:] += bbox[:, :2]\n         score = np.exp(conf)\n-        score /= conf.sum(axis=1, keepdims=True)\n+        score /= score.sum(axis=1, keepdims=True)\n         return bbox, score\n \n     def _prepare(self, img):\n", "before": "score /= conf . sum ( axis = 1 , keepdims = True )", "after": "score /= score . sum ( axis = 1 , keepdims = True )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:conf\", 3, 18, 3, 22], \"score\"]]"}
{"project": "dj-stripe", "commit_sha": "526026447fdd34b3323be273967c3f9fd06800be", "parent_sha": "1f2898708f5316ddefc168a624dfb4a1a795a7fa", "file_path": "djstripe/templatetags/djstripe_tags.py", "project_url": "https://github.com/v-kopitsa/dj-stripe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,7 +34,7 @@ def djstripe_plan_level(name):\n     level = -1\n-    for config_level in HIERARCHY_PLANS.values():\n+    for config_level in DJSTRIPE_PLAN_HIERARCHY.values():\n         if name in config_level[\"plans\"]:\n             level = config_level[\"level\"]\n \n", "before": "for config_level in HIERARCHY_PLANS . values ( ) : if name in config_level [ \"plans\" ] : level = config_level [ \"level\" ]", "after": "for config_level in DJSTRIPE_PLAN_HIERARCHY . values ( ) : if name in config_level [ \"plans\" ] : level = config_level [ \"level\" ]", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:HIERARCHY_PLANS\", 1, 25, 1, 40], \"DJSTRIPE_PLAN_HIERARCHY\"]]"}
{"project": "portage", "commit_sha": "ee7ee34f4669cfdef6867952b6830d15e4caae01", "parent_sha": "35d900fab79b934517a2bf611bd919cb6a99aa7d", "file_path": "pym/portage/util/env_update.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -50,7 +50,7 @@ def env_update(makelinks=1, target_root=None, prev_mtimes=None, contents=None,\n \telse:\n \t\tsettings = env\n \n-\teprefix = env.get(\"EPREFIX\", \"\")\n+\teprefix = settings.get(\"EPREFIX\", \"\")\n \teprefix_lstrip = eprefix.lstrip(os.sep)\n \tenvd_dir = os.path.join(target_root, eprefix_lstrip, \"etc\", \"env.d\")\n \tensure_dirs(envd_dir, mode=0o755)\n", "before": "eprefix = env . get ( \"EPREFIX\" , \"\" )", "after": "eprefix = settings . get ( \"EPREFIX\" , \"\" )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:env\", 3, 12, 3, 15], \"settings\"]]"}
{"project": "reviewboard", "commit_sha": "c8bab63874e27bd74ae022d6d996da04b926b573", "parent_sha": "2a1c51429998a9ce1e6ca5160f10b3860214023d", "file_path": "reviewboard/hostingsvcs/github.py", "project_url": "https://github.com/iosphere/reviewboard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -699,7 +699,7 @@ class GitHub(HostingService):\n         data = e.read()\n \n         try:\n-            rsp = simplejson.loads(data)\n+            rsp = json.loads(data)\n         except:\n             rsp = None\n \n", "before": "rsp = simplejson . loads ( data )", "after": "rsp = json . loads ( data )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:simplejson\", 3, 19, 3, 29], \"json\"]]"}
{"project": "pyexchange", "commit_sha": "99bce65225ce702d7fae5fbe37b1c658b42a40d6", "parent_sha": "8a3e3ab24d0c3d1fa427f8b9082ed7a391947a94", "file_path": "tests/exchange2010/test_get_folder.py", "project_url": "https://github.com/OptimalBPM/pyexchange", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -78,7 +78,7 @@ class Test_FailingToGetFolders():\n \n     httpretty.register_uri(\n       httpretty.POST, FAKE_EXCHANGE_URL,\n-      body=ITEM_DOES_NOT_EXIST.encode('utf-8'),\n+      body=FOLDER_DOES_NOT_EXIST.encode('utf-8'),\n       content_type='text/xml; charset=utf-8',\n     )\n \n", "before": "httpretty . register_uri ( httpretty . POST , FAKE_EXCHANGE_URL , body = ITEM_DOES_NOT_EXIST . encode ( 'utf-8' ) , content_type = 'text/xml; charset=utf-8' , )", "after": "httpretty . register_uri ( httpretty . POST , FAKE_EXCHANGE_URL , body = FOLDER_DOES_NOT_EXIST . encode ( 'utf-8' ) , content_type = 'text/xml; charset=utf-8' , )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:ITEM_DOES_NOT_EXIST\", 3, 12, 3, 31], \"FOLDER_DOES_NOT_EXIST\"]]"}
{"project": "GamesmanMPI", "commit_sha": "e7827b581e5b576d30c1f156b0e6095fdfd29ff4", "parent_sha": "9600c9964a2add292a7a581671e31bb40291c598", "file_path": "test_games/othello_bit.py", "project_url": "https://github.com/swerwath/GamesmanMPI", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -270,7 +270,7 @@ def incr_pass(board):\n     new_pass = pass_count(board) + 1\n     start = 2 * area + 8\n     a = bitarray(endian='big')\n-    a.frombytes(new_turn.tobytes(1, byteorder='big', signed=False))\n+    a.frombytes(new_pass.tobytes(1, byteorder='big', signed=False))\n     board[start:start + 8] = a\n \n def reset_pass(board):\n", "before": "a . frombytes ( new_turn . tobytes ( 1 , byteorder = 'big' , signed = False ) )", "after": "a . frombytes ( new_pass . tobytes ( 1 , byteorder = 'big' , signed = False ) )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:new_turn\", 3, 17, 3, 25], \"new_pass\"]]"}
{"project": "notebooks", "commit_sha": "f8e195d7ad4443400ff987ad6b7510ed00bf2dc2", "parent_sha": "2efdcb551809dba03b5f7015b4f5370304a02b32", "file_path": "scripts/csv2prov.py", "project_url": "https://github.com/nicholsn/notebooks", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -21,7 +21,7 @@ def safe_encode(x):\n         return prov.Literal(int(x), prov.XSD['integer'])\n     if isinstance(x, (float,)):\n         return prov.Literal(x, prov.XSD['float'])\n-    return pm.Literal(json.dumps(x), prov.XSD['string'])\n+    return prov.Literal(json.dumps(x), prov.XSD['string'])\n \n def csv2provgraph(filename, n_rows=None):\n", "before": "return pm . Literal ( json . dumps ( x ) , prov . XSD [ 'string' ] )", "after": "return prov . Literal ( json . dumps ( x ) , prov . XSD [ 'string' ] )", "sstub_pattern": "SAME_FUNCTION_WRONG_CALLER", "edit_script": "[[\"Update\", [\"identifier:pm\", 3, 12, 3, 14], \"prov\"]]"}
{"project": "librosa", "commit_sha": "5e006b5f47e8f9b0be318c9acc40082d418ab8a9", "parent_sha": "9e4b31a7989c5f78000f576d8a25d51cdd0d2be9", "file_path": "librosa/core/spectrum.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -481,7 +481,7 @@ def phase_vocoder(D, rate, hop_length=None):\n \n     .. [1] Ellis, D. P. W. \"A phase vocoder in Matlab.\"\n         Columbia University, 2002.\n-        http://www.ee.columbia.edu/dpwe/resources/matlab/pvoc/\n+        http://www.ee.columbia.edu/~dpwe/resources/matlab/pvoc/\n \n     Examples\n     --------\n", "before": "http : // www . ee . columbia . edu / dpwe / resources / matlab / pvoc / Examples", "after": "http : // www . ee . columbia . edu / ~ dpwe / resources / matlab / pvoc / Examples", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 16, 3, 40], [\"unary_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"~:~\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:dpwe\", 3, 36, 3, 40], 1]]"}
{"project": "ansible-bender", "commit_sha": "b0d5c98f5500f91d64c7b7d8e5d4a8da33693157", "parent_sha": "759bc9b46f3966bb5b485e3a4167eff2c7e4def1", "file_path": "ansible_bender/db.py", "project_url": "https://github.com/TomasTomecek/ansible-bender", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -158,7 +158,7 @@ class Database:\n         \"\"\" return id for next build id and increment the one in DB \"\"\"\n         next_build_id = data[\"next_build_id\"]\n         data[\"next_build_id\"] += 1\n-        if data[\"builds\"].get[next_build_id]:\n+        if not data[\"builds\"].get[next_build_id]:\n             return str(next_build_id)\n         else:\n             raise Exception('Build ID already exists')\n", "before": "if data [ \"builds\" ] . get [ next_build_id ] : return str ( next_build_id ) else : raise Exception ( 'Build ID already exists' )", "after": "if not data [ \"builds\" ] . get [ next_build_id ] : return str ( next_build_id ) else : raise Exception ( 'Build ID already exists' )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 55], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"subscript\", 3, 12, 3, 45], 1]]"}
{"project": "cc-utils", "commit_sha": "7bb16be61e4a068afc3b670fedbb1d07ea5a24bb", "parent_sha": "964a2fb128c50a1605407ac16757a56d00f084bf", "file_path": "concourse/steps/scan_container_images.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ class MailRecipients(object):\n     def add_protecode_results(self, results: typing.Iterable[typing.Tuple[UploadResult, int]]):\n         for result in results:\n             if self._result_filter:\n-                if self._result_filter(component=result[0].component):\n+                if not self._result_filter(component=result[0].component):\n                     continue\n             self._protecode_results.append(result)\n \n", "before": "if self . _result_filter ( component = result [ 0 ] . component ) : continue", "after": "if not self . _result_filter ( component = result [ 0 ] . component ) : continue", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 17, 4, 29], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 20, 3, 70], 1]]"}
{"project": "WMAS", "commit_sha": "959e99440855634d19d33e44b51a5910bb4843c3", "parent_sha": "6d5735ed886b147b87d09c2aa13b6b82d1700470", "file_path": "tools/CSSTestLib/OutputFormats.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ class XHTMLFormat(BasicFormat):\n     BasicFormat.__init__(self, join(destroot, self.formatDirName), extMap)\n   def write(self, source):\n     # skip HTMLonly tests\n-    if hasattr(source, 'hasFlag') and not source.hasFlag('HTMLonly'):\n+    if hasattr(source, 'hasFlag') and source.hasFlag('HTMLonly'):\n       return\n     source.write(self)\n \n", "before": "if hasattr ( source , 'hasFlag' ) and not source . hasFlag ( 'HTMLonly' ) : return", "after": "if hasattr ( source , 'hasFlag' ) and source . hasFlag ( 'HTMLonly' ) : return", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 8, 3, 69], [\"call\", 3, 43, 3, 69], 2], [\"Delete\", [\"not:not\", 3, 39, 3, 42]], [\"Delete\", [\"not_operator\", 3, 39, 3, 69]]]"}
{"project": "FreeCAD_assembly3", "commit_sha": "03d9121351d28283993a346df65a6ecf3bde77c1", "parent_sha": "530eff04755e2aa1ddb060808978e4913691b7aa", "file_path": "assembly.py", "project_url": "https://github.com/realthunder/FreeCAD_assembly3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1252,7 +1252,7 @@ class ViewProviderAsmElementLink(ViewProviderAsmOnTop):\n             subname += elements[0]\n         obj = self.ViewObject.Object\n         msg = 'Cannot drop to AsmElementLink {}'.format(objName(obj))\n-        if not logger.catchTrace(msg, obj.Proxy.setLink,owner,subname,True):\n+        if logger.catchTrace(msg, obj.Proxy.setLink,owner,subname,True):\n             return True\n         return False\n \n", "before": "if not logger . catchTrace ( msg , obj . Proxy . setLink , owner , subname , True ) : return True", "after": "if logger . catchTrace ( msg , obj . Proxy . setLink , owner , subname , True ) : return True", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 9, 4, 24], [\"call\", 3, 16, 3, 76], 1], [\"Delete\", [\"not:not\", 3, 12, 3, 15]], [\"Delete\", [\"not_operator\", 3, 12, 3, 76]]]"}
{"project": "arfit", "commit_sha": "d0446065b1498fb79ca3eb0431e7164d3dd5d033", "parent_sha": "b468dd7208df89b856a66b5634a4f79b55b9bc45", "file_path": "arfit/arn_posterior.py", "project_url": "https://github.com/farr/arfit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -745,7 +745,7 @@ class Posterior(object):\n         rp = self.frequency_parameters(p)\n \n         if self.nc == 0:\n-            rp[1:] = 1.0/rp[1:]\n+            rp[1:] = -1.0/rp[1:]\n             return rp\n         elif self.nc == self.p:\n             rp[1::2] = -1.0/rp[1::2]\n", "before": "rp [ 1 : ] = 1.0 / rp [ 1 : ]", "after": "rp [ 1 : ] = - 1.0 / rp [ 1 : ]", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 22, 3, 32], [\"unary_operator\", \"N0\"], 0], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"float:1.0\", 3, 22, 3, 25], 1]]"}
{"project": "angr", "commit_sha": "af7e099e548a141ebaa1e9810111b3693622a4b1", "parent_sha": "c60388cddc93ec2c11a28bd0ff95b4cd5ba979f2", "file_path": "angr/analyses/cfg_base.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1183,7 +1183,7 @@ class CFGBase(Analysis):\n             else:\n                 target_function = blockaddr_to_function[dst_addr]\n \n-            to_outside = target_function is src_function\n+            to_outside = not target_function is src_function\n \n             self.kb.functions._add_fakeret_to(src_function.addr, src_addr, dst_addr, confirmed=True,\n                                               to_outside=to_outside\n", "before": "to_outside = target_function is src_function", "after": "to_outside = not target_function is src_function", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"assignment\", 3, 13, 3, 57], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"comparison_operator\", 3, 26, 3, 57], 1]]"}
{"project": "netpyne", "commit_sha": "073e7ac1e989f0b3ec2b5133075d63c1c190c002", "parent_sha": "0f0af57441e2778d2b5422805d91f6017158b9c9", "file_path": "netpyne/cell/compartCell.py", "project_url": "https://github.com/rodriguez-facundo/netpyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -330,7 +330,7 @@ class CompartCell (Cell):\n                 if 'pt3d' in sectParams['geom']:  \n                     h.pt3dclear(sec=sec['hObj'])\n                     x = self.tags['x']\n-                    y = -self.tags['y'] # Neuron y-axis positive = upwards, so assume pia=0 and cortical depth = neg\n+                    y = self.tags['y'] # Neuron y-axis positive = upwards, so assume pia=0 and cortical depth = neg\n                     z = self.tags['z']\n                     for pt3d in sectParams['geom']['pt3d']:\n                         #h.pt3dadd(x+pt3d[0], y+pt3d[1], z+pt3d[2], pt3d[3], sec=sec['hObj'])\n", "before": "y = - self . tags [ 'y' ]", "after": "y = self . tags [ 'y' ]", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"assignment\", 3, 21, 3, 40], [\"subscript\", 3, 26, 3, 40], 2], [\"Delete\", [\"-:-\", 3, 25, 3, 26]], [\"Delete\", [\"unary_operator\", 3, 25, 3, 40]]]"}
{"project": "openCEM", "commit_sha": "ce1d287d705e9c653ff1fc6547c6e16562b9fc38", "parent_sha": "d37bf7003f711dad5b4990ee41668b78b7215839", "file_path": "cemo/jsonify.py", "project_url": "https://github.com/openCEMorg/openCEM", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -240,7 +240,7 @@ def fill_complex_var(var):\n     '''Return complex variable dictionary'''\n     out = []\n     for i in var.keys():\n-        out.append({'index': i, 'value': 0 if 1e-6 < var[i].value < 0 else var[i].value})\n+        out.append({'index': i, 'value': 0 if -1e-6 < var[i].value < 0 else var[i].value})\n \n     return out\n \n", "before": "out . append ( { 'index' : i , 'value' : 0 if 1e-6 < var [ i ] . value < 0 else var [ i ] . value } )", "after": "out . append ( { 'index' : i , 'value' : 0 if - 1e-6 < var [ i ] . value < 0 else var [ i ] . value } )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 47, 3, 70], [\"unary_operator\", \"N0\"], 0], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"float:1e-6\", 3, 47, 3, 51], 1]]"}
{"project": "sympy", "commit_sha": "f97c95ca897726cc022c477546cd71011194a602", "parent_sha": "047a9a746ab31e76c641af9b90c79c034294cb44", "file_path": "sympy/sets/handlers/add.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -72,4 +72,4 @@ def _set_sub(x, y):\n def _set_sub(x, y):\n     if x.start is S.NegativeInfinity:\n         return Interval(-oo, oo)\n-    return FiniteSet(-oo)\n+    return FiniteSet(oo)\n", "before": "return FiniteSet ( - oo )", "after": "return FiniteSet ( oo )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"argument_list\", 3, 21, 3, 26], [\"identifier:oo\", 3, 23, 3, 25], 1], [\"Delete\", [\"-:-\", 3, 22, 3, 23]], [\"Delete\", [\"unary_operator\", 3, 22, 3, 25]]]"}
{"project": "flutterfuck", "commit_sha": "788a995b6d5ffe19199265953b371c5f40db47b1", "parent_sha": "0f673b96afc578484fec224f6603cfba68483d9f", "file_path": "willie/module.py", "project_url": "https://github.com/CoRD-Dev/flutterfuck", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -316,7 +316,7 @@ def require_chanmsg(message=None):\n         def _nop(*args, **kwargs):\n             # Assign trigger and bot for easy access later\n             bot, trigger = args[0:2]\n-            if trigger.is_privmsg:\n+            if not trigger.is_privmsg:\n                 return function(*args, **kwargs)\n             else:\n                 if message and not callable(message):\n", "before": "if trigger . is_privmsg : return function ( * args , ** kwargs ) else : if message and not callable ( message ) : ", "after": "if not trigger . is_privmsg : return function ( * args , ** kwargs ) else : if message and not callable ( message ) : ", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 54], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"attribute\", 3, 16, 3, 34], 1]]"}
{"project": "course-management", "commit_sha": "9848dc777a0ca6cedcb2bc0fe7a5db05a3ab6618", "parent_sha": "a028943a896e94cd9375401149b568c56fede35a", "file_path": "src/course/views/enroll.py", "project_url": "https://github.com/fsr/course-management", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ def add(request, course_id):\n \n     if course.is_participant(stud):\n         session['enroll-error'] = 'You are already enrolled in this course.'\n-    elif course.joinable:\n+    elif not course.joinable:\n         session['enroll-error'] = 'Sorry, this course is full.'\n     else:\n         if 'enroll-error' in session:\n", "before": "if course . is_participant ( stud ) : session [ 'enroll-error' ] = 'You are already enrolled in this course.' elif course . joinable : session [ 'enroll-error' ] = 'Sorry, this course is full.' else : if 'enroll-error' in session : ", "after": "if course . is_participant ( stud ) : session [ 'enroll-error' ] = 'You are already enrolled in this course.' elif not course . joinable : session [ 'enroll-error' ] = 'Sorry, this course is full.' else : if 'enroll-error' in session : ", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"elif_clause\", 3, 5, 4, 64], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"attribute\", 3, 10, 3, 25], 1]]"}
{"project": "pyGAlib", "commit_sha": "d82dc50fb571d1f4cde6ad772386df1eba0baa5c", "parent_sha": "99dd63963b9daa87afa708ae45ec1ba474123b80", "file_path": "galib/models.py", "project_url": "https://github.com/gorkazl/pyGAlib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -873,7 +873,7 @@ def ModularHeterogeneousGraph(Nsizelist, pintlist, pext, directed=False, selfloo\n \n     # 3) IF GRAPH SHOULD BE UNDIRECTED...\n     if not directed:\n-        adjmatrix[np.tril_indices(N, k=1)] = 0\n+        adjmatrix[np.tril_indices(N, k=-1)] = 0\n         adjmatrix += adjmatrix.T\n \n     # 4) Remove the diagonal if no self-loops are desired\n", "before": "adjmatrix [ np . tril_indices ( N , k = 1 ) ] = 0", "after": "adjmatrix [ np . tril_indices ( N , k = - 1 ) ] = 0", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 38, 3, 41], [\"unary_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"integer:1\", 3, 40, 3, 41], 1]]"}
{"project": "katal", "commit_sha": "8ac6a7f0fe2f7368aeb3459d058e41d3a7562161", "parent_sha": "b59d0775a0b5a1c150900e0a7fa3aac0bdd1f79d", "file_path": "katal/katal.py", "project_url": "https://github.com/suizokukan/katal", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1549,7 +1549,7 @@ def fill_select__checks(_number_of_discarded_files, _prefix, _fullname):\n \n     # (2) future filename's can't be in conflict with another file already\n     # stored in the target path :\n-    if ARGS.mirroronly:\n+    if not ARGS.mirroronly:\n         msg(\"    ... future filename's can't be in conflict with another file already\")\n         msg(\"        stored in the target path...\")\n         for selectedfile_hash in SELECT:\n", "before": "if ARGS . mirroronly : msg ( \"    ... future filename's can't be in conflict with another file already\" ) msg ( \"        stored in the target path...\" ) for selectedfile_hash in SELECT : ", "after": "if not ARGS . mirroronly : msg ( \"    ... future filename's can't be in conflict with another file already\" ) msg ( \"        stored in the target path...\" ) for selectedfile_hash in SELECT : ", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 6, 41], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"attribute\", 3, 8, 3, 23], 1]]"}
{"project": "hnn", "commit_sha": "23e4830f6a9328b0f85c9c0d3eadacda28d7dc7b", "parent_sha": "e4c07b8915c45567a47f3528ea9489041ef1a2dd", "file_path": "hnn.py", "project_url": "https://github.com/jonescompneurolab/hnn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -57,7 +57,7 @@ dfile = {}\n def getinputfiles (paramf):\n   global dfile\n   dfile = {}\n-  basedir = os.path.join('data',paramf.split(os.path.sep)[1].split('.param')[0])\n+  basedir = os.path.join('data',paramf.split(os.path.sep)[-1].split('.param')[0])\n   dfile['dpl'] = os.path.join(basedir,'dpl.txt')\n   dfile['spec'] = os.path.join(basedir,'rawspec.npz')\n   dfile['spk'] = os.path.join(basedir,'spk.txt')\n", "before": "basedir = os . path . join ( 'data' , paramf . split ( os . path . sep ) [ 1 ] . split ( '.param' ) [ 0 ] )", "after": "basedir = os . path . join ( 'data' , paramf . split ( os . path . sep ) [ - 1 ] . split ( '.param' ) [ 0 ] )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"subscript\", 3, 33, 3, 61], [\"unary_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"integer:1\", 3, 59, 3, 60], 1]]"}
{"project": "horizon", "commit_sha": "dfc9a402218300c28c299786eeec1fc6e4cd15bb", "parent_sha": "bd80fb930be6b8e605e11d9ee9dd36d5b3571ca4", "file_path": "openstack_dashboard/test/integration_tests/basewebobject.py", "project_url": "https://github.com/mkowalski/horizon", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,5 +92,5 @@ class BaseWebObject(unittest.TestCase):\n                          timeout)\n \n     def _wait_till_element_disappears(self, element, timeout=None):\n-        self._wait_until(lambda x: self._is_element_displayed(element),\n+        self._wait_until(lambda x: not self._is_element_displayed(element),\n                          timeout)\n", "before": "self . _wait_until ( lambda x : self . _is_element_displayed ( element ) , timeout )", "after": "self . _wait_until ( lambda x : not self . _is_element_displayed ( element ) , timeout )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"lambda\", 3, 26, 3, 71], [\"not_operator\", \"N0\"], 3], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 36, 3, 71], 1]]"}
{"project": "neural-doodle", "commit_sha": "3547a6d2f94517871e4df081c89ce54a5a4aa4cc", "parent_sha": "29147a3aa65afeb7e114ba807cf6f7baff13d2c8", "file_path": "doodle.py", "project_url": "https://github.com/Ericnano/neural-doodle", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -376,7 +376,7 @@ class NeuralGenerator(object):\n         current_img = Xn.reshape(self.content_image.shape).astype(np.float32) - self.model.pixel_mean\n         grads, *losses = self.compute_grad_and_losses(current_img, self.content_map)\n         \n-        if not np.isnan(grads).any():\n+        if np.isnan(grads).any():\n             raise RuntimeError(\"Optimization diverged; try using different device or parameters.\")\n \n         # Use gradients as an estimate for overall quality.\n", "before": "if not np . isnan ( grads ) . any ( ) : raise RuntimeError ( \"Optimization diverged; try using different device or parameters.\" )", "after": "if np . isnan ( grads ) . any ( ) : raise RuntimeError ( \"Optimization diverged; try using different device or parameters.\" )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 9, 4, 99], [\"call\", 3, 16, 3, 37], 1], [\"Delete\", [\"not:not\", 3, 12, 3, 15]], [\"Delete\", [\"not_operator\", 3, 12, 3, 37]]]"}
{"project": "askbot-devel", "commit_sha": "efb3120e2c752f4e55d49fd09e5c7584905ad09c", "parent_sha": "8a65ad5dfd0b13834711edd0fd148832fcca6689", "file_path": "askbot/auth.py", "project_url": "https://github.com/kingctan/askbot-devel", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -111,7 +111,7 @@ def onUnFlaggedItem(post, user, timestamp=None):\n     flagged_user = post.author\n \n     flagged_user.receive_reputation(\n-        - askbot_settings.REP_LOSS_FOR_RECEIVING_FLAG\n+        askbot_settings.REP_LOSS_FOR_RECEIVING_FLAG\n     )\n     flagged_user.save()\n \n", "before": "flagged_user . receive_reputation ( - askbot_settings . REP_LOSS_FOR_RECEIVING_FLAG )", "after": "flagged_user . receive_reputation ( askbot_settings . REP_LOSS_FOR_RECEIVING_FLAG )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"argument_list\", 2, 36, 4, 6], [\"attribute\", 3, 11, 3, 54], 1], [\"Delete\", [\"-:-\", 3, 9, 3, 10]], [\"Delete\", [\"unary_operator\", 3, 9, 3, 54]]]"}
{"project": "Cura", "commit_sha": "ea73f00aacc9dc024f544b385dec7f285dd5c18a", "parent_sha": "b6b154e153e92dab90a59ab10e1d062453662e2e", "file_path": "cura/MachineManagerModel.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ class MachineManagerModel(QObject):\n             Preferences.getInstance().setValue(\"cura/active_machine\", self._global_container_stack.getId())\n             self._global_container_stack.containersChanged.connect(self._onInstanceContainersChanged)\n             self._global_container_stack.propertyChanged.connect(self._onGlobalPropertyChanged)\n-            self._global_stack_valid = self._checkStackForErrors(self._global_container_stack)\n+            self._global_stack_valid = not self._checkStackForErrors(self._global_container_stack)\n \n     def _onInstanceContainersChanged(self, container):\n         container_type = container.getMetaDataEntry(\"type\")\n", "before": "self . _global_stack_valid = self . _checkStackForErrors ( self . _global_container_stack )", "after": "self . _global_stack_valid = not self . _checkStackForErrors ( self . _global_container_stack )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"assignment\", 3, 13, 3, 95], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 40, 3, 95], 1]]"}
{"project": "RatticWeb", "commit_sha": "09ff6c16e8a900a3b8407a5a4491b86f63158b72", "parent_sha": "8830d4df3bc416efb7b46c30279701c9e43644ae", "file_path": "staff/views.py", "project_url": "https://github.com/efornal/RatticWeb", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,7 +31,7 @@ def home(request):\n @staff_member_required\n def userdetail(request, uid):\n     user = get_object_or_404(User, pk=uid)\n-    if settings.LDAP_ENABLED and not settings.USE_LDAP_GROUPS:\n+    if settings.LDAP_ENABLED and settings.USE_LDAP_GROUPS:\n         from django_auth_ldap.backend import LDAPBackend\n         popuser = LDAPBackend().populate_user(user.username)\n         if popuser is None:\n", "before": "if settings . LDAP_ENABLED and not settings . USE_LDAP_GROUPS : from django_auth_ldap . backend import LDAPBackend popuser = LDAPBackend ( ) . populate_user ( user . username ) if popuser is None : ", "after": "if settings . LDAP_ENABLED and settings . USE_LDAP_GROUPS : from django_auth_ldap . backend import LDAPBackend popuser = LDAPBackend ( ) . populate_user ( user . username ) if popuser is None : ", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 8, 3, 62], [\"attribute\", 3, 38, 3, 62], 2], [\"Delete\", [\"not:not\", 3, 34, 3, 37]], [\"Delete\", [\"not_operator\", 3, 34, 3, 62]]]"}
{"project": "beets", "commit_sha": "55c68536c2adcc75216e2e2f9c76f08d6fb4fb56", "parent_sha": "3be24110d720e3c4151ee60730c7bd5b12427a2b", "file_path": "beets/mediafile.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -547,7 +547,7 @@ class MediaField(object):\n             # Remove suffix.\n             if style.suffix and isinstance(out, (str, unicode)):\n                 if out.endswith(style.suffix):\n-                    out = out[:len(style.suffix)]\n+                    out = out[:-len(style.suffix)]\n \n             # MPEG-4 freeform frames are (should be?) encoded as UTF-8.\n             if obj.type == 'mp4' and style.key.startswith('----:') and \\\n", "before": "out = out [ : len ( style . suffix ) ]", "after": "out = out [ : - len ( style . suffix ) ]", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"slice\", 3, 31, 3, 49], [\"unary_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 32, 3, 49], 1]]"}
{"project": "Products.PluggableAuthService", "commit_sha": "512eea03ba57367b0e4d8d1077358e1f66dfc412", "parent_sha": "8e93d3420827a9396a3d3bf50cc3845f0d647cf7", "file_path": "Products/PluggableAuthService/plugins/RequestTypeSniffer.py", "project_url": "https://github.com/gbastien/Products.PluggableAuthService", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -138,7 +138,7 @@ if HAVE_ZSERVER:\n \n def browserSniffer(request):\n     # If it's none of the above, it's very likely a browser request.\n-    if HAVE_ZSERVER:\n+    if not HAVE_ZSERVER:\n         return True\n     for sniffer in (webdavSniffer, ftpSniffer, xmlrpcSniffer):\n         if sniffer(request):\n", "before": "if HAVE_ZSERVER : return True", "after": "if not HAVE_ZSERVER : return True", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 4, 20], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:HAVE_ZSERVER\", 3, 8, 3, 20], 1]]"}
{"project": "spiderfoot", "commit_sha": "21ba7c143fc2c155ecfc891b5f102a61bdc5515e", "parent_sha": "83db7b66aea2dfe77ecb9aa908e19081739a9425", "file_path": "modules/sfp_yandexdns.py", "project_url": "https://github.com/smicallef/spiderfoot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -94,7 +94,7 @@ class sfp_yandexdns(SpiderFootPlugin):\n \n         found = self.queryAddr(eventData)\n \n-        if not found:\n+        if found:\n             return None\n \n         if eventName == \"CO_HOSTED_SITE\":\n", "before": "if not found : return None", "after": "if found : return None", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 9, 4, 24], [\"identifier:found\", 3, 16, 3, 21], 1], [\"Delete\", [\"not:not\", 3, 12, 3, 15]], [\"Delete\", [\"not_operator\", 3, 12, 3, 21]]]"}
{"project": "nitime", "commit_sha": "d2ed2cd616706f9d267fc64b16bf097e07ef5be4", "parent_sha": "745c0dcf3af2ebd98cc9c19ed67ecd0598bc255a", "file_path": "nitime/algorithms.py", "project_url": "https://github.com/ilustreous/nitime", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2423,7 +2423,7 @@ def autocov(x):\n     autocov = np.empty((n,n))\n \n     for i in range(n):\n-        autocov[i] = np.correlate(x,np.roll(x,i),'same') - x.mean()**2\n+        autocov[i] = np.correlate(x,np.roll(x,-i),'same') - x.mean()**2\n \n     return autocov\n         \n", "before": "autocov [ i ] = np . correlate ( x , np . roll ( x , i ) , 'same' ) - x . mean ( ) ** 2", "after": "autocov [ i ] = np . correlate ( x , np . roll ( x , - i ) , 'same' ) - x . mean ( ) ** 2", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 44, 3, 49], [\"unary_operator\", \"N0\"], 3], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:i\", 3, 47, 3, 48], 1]]"}
{"project": "nitime", "commit_sha": "affc5c7662f2cc3071d24f9153a233199ce0cf5f", "parent_sha": "0790e5a7a4c1fca4a09c48010525ab862055aa04", "file_path": "nitime/algorithms.py", "project_url": "https://github.com/ilustreous/nitime", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2423,7 +2423,7 @@ def autocov(x):\n     autocov = np.empty((n,n))\n \n     for i in range(n):\n-        autocov[i] = np.correlate(x,np.roll(x,i),'same') - x.mean()**2\n+        autocov[i] = np.correlate(x,np.roll(x,-i),'same') - x.mean()**2\n \n     return autocov\n         \n", "before": "autocov [ i ] = np . correlate ( x , np . roll ( x , i ) , 'same' ) - x . mean ( ) ** 2", "after": "autocov [ i ] = np . correlate ( x , np . roll ( x , - i ) , 'same' ) - x . mean ( ) ** 2", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 44, 3, 49], [\"unary_operator\", \"N0\"], 3], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:i\", 3, 47, 3, 48], 1]]"}
{"project": "spyne", "commit_sha": "31ed2c53370a43ad06a4e8cbff392b4b90359b1f", "parent_sha": "105a03ff814efb0707d666118414c9a447291a5f", "file_path": "spyne/interface/_base.py", "project_url": "https://github.com/duixteam/spyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -295,7 +295,7 @@ class Interface(object):\n         if not (extends is None):\n             self.add_class(extends)\n             parent_ns = extends.get_namespace()\n-            if parent_ns != ns and not not parent_ns in self.imports[ns]:\n+            if parent_ns != ns and not parent_ns in self.imports[ns]:\n                 self.imports[ns].add(parent_ns)\n                 logger.debug(\"\\timporting %r to %r because %r extends %r\" % (\n                     parent_ns, ns, cls.get_type_name(), extends.get_type_name()))\n", "before": "if parent_ns != ns and not not parent_ns in self . imports [ ns ] : self . imports [ ns ] . add ( parent_ns ) logger . debug ( \"\\timporting %r to %r because %r extends %r\" % ( parent_ns , ns , cls . get_type_name ( ) , extends . get_type_name ( ) ) )", "after": "if parent_ns != ns and not parent_ns in self . imports [ ns ] : self . imports [ ns ] . add ( parent_ns ) logger . debug ( \"\\timporting %r to %r because %r extends %r\" % ( parent_ns , ns , cls . get_type_name ( ) , extends . get_type_name ( ) ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Delete\", [\"not:not\", 3, 36, 3, 39]]]"}
{"project": "enigma2", "commit_sha": "39627668ca36cecbc78ec5f677061f128957b550", "parent_sha": "0a35f28652b7c5c175f4d90d9cce7c21c544db99", "file_path": "lib/python/Components/RFmod.py", "project_url": "https://github.com/sotocirus/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,7 +14,7 @@ class RFmod:\n \tdef setTestmode(self, value):\n \t\teRFmod.getInstance().setTestmode(value)\n \tdef setSoundFunction(self, value):\n-\t\teRFmod.getInstance().setSoundFunction(value)\n+\t\teRFmod.getInstance().setSoundFunction(not value)\n \tdef setSoundCarrier(self, value):\n \t\teRFmod.getInstance().setSoundCarrier(value)\n \tdef setChannel(self, value):\n", "before": "eRFmod . getInstance ( ) . setSoundFunction ( value )", "after": "eRFmod . getInstance ( ) . setSoundFunction ( not value )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 40, 3, 47], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:value\", 3, 41, 3, 46], 1]]"}
{"project": "fragalysis-api", "commit_sha": "127acb5daac229e16edb2c3df9a885fdbefa9e9c", "parent_sha": "d508c188b664d05377fdd81143ab8bee922accbe", "file_path": "fragalysis_api/xcimporter/xcimporter.py", "project_url": "https://github.com/xchem/fragalysis-api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ def xcimporter(user_id, in_dir, out_dir):\n     validation = Validate(os.path.join(in_dir, str(user_id)))\n \n-    if bool(validation.is_pdbs_valid):\n+    if not bool(validation.is_pdbs_valid):\n         print('Input files are invalid!!')\n         exit()\n \n", "before": "if bool ( validation . is_pdbs_valid ) : print ( 'Input files are invalid!!' ) exit ( )", "after": "if not bool ( validation . is_pdbs_valid ) : print ( 'Input files are invalid!!' ) exit ( )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 2, 5, 4, 15], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 2, 8, 2, 38], 1]]"}
{"project": "registration", "commit_sha": "18419d853aaa9dac73c47e59546eb62af1b4d8e3", "parent_sha": "5b47cd78546820c2b5de37f1b6ee890141c021eb", "file_path": "register/views.py", "project_url": "https://github.com/HackCU/registration", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -229,7 +229,7 @@ class ProfileHacker(LoginRequiredMixin, TemplateView):\n                 )\n                 if current_app.status in [models.APP_CONFIRMED, models.APP_ATTENDED]:\n                     phases.append(\n-                        create_phase('attend', \"Attend\", lambda x: current_app.is_confirmed(),\n+                        create_phase('attend', \"Attend\", lambda x: not current_app.is_confirmed(),\n                                      self.request.user)\n                     )\n         except:\n", "before": "phases . append ( create_phase ( 'attend' , \"Attend\" , lambda x : current_app . is_confirmed ( ) , self . request . user ) )", "after": "phases . append ( create_phase ( 'attend' , \"Attend\" , lambda x : not current_app . is_confirmed ( ) , self . request . user ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"lambda\", 3, 58, 3, 94], [\"not_operator\", \"N0\"], 3], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 68, 3, 94], 1]]"}
{"project": "sunpy", "commit_sha": "35bf45d89737f3764d14bdf95a8e4a2feabea73e", "parent_sha": "03cfff2d19ef1e526eaa9e65d955bbbf103afd7c", "file_path": "sunpy/lightcurve/tests/test_rhessi.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ class TestRHESSISummaryLightCurve():\n         lc1 = sunpy.lightcurve.RHESSISummaryLightCurve.create(timerange_a)\n         lc2 = sunpy.lightcurve.RHESSISummaryLightCurve.create(timerange_b)\n-        assert all(lc1.data == lc2.data)\n+        assert not all(lc1.data == lc2.data)\n \n     def test_get_url(self, timerange_a, timerange_b):\n         \"\"\"Test the getting of urls\"\"\"\n", "before": "assert all ( lc1 . data == lc2 . data )", "after": "assert not all ( lc1 . data == lc2 . data )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"assert_statement\", 2, 9, 2, 41], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 2, 16, 2, 41], 1]]"}
{"project": "airflow", "commit_sha": "7da9bb68ce9ad08b3a648b49d52eddd1cc153137", "parent_sha": "94bfeef7cbc3d790ac0337a7e087c1bd8150ccee", "file_path": "airflow/api/common/experimental/delete_dag.py", "project_url": "https://github.com/costrouc/airflow", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,7 +41,7 @@ def delete_dag(dag_id, keep_records_in_log=True):\n     if dag is None:\n         raise DagNotFound(\"Dag id {} not found\".format(dag_id))\n \n-    if dag.fileloc and not os.path.exists(dag.fileloc):\n+    if dag.fileloc and os.path.exists(dag.fileloc):\n         raise DagFileExists(\"Dag id {} is still in DagBag. \"\n                             \"Remove the DAG file first: {}\".format(dag_id, dag.fileloc))\n \n", "before": "if dag . fileloc and not os . path . exists ( dag . fileloc ) : raise DagFileExists ( \"Dag id {} is still in DagBag. \" \"Remove the DAG file first: {}\" . format ( dag_id , dag . fileloc ) )", "after": "if dag . fileloc and os . path . exists ( dag . fileloc ) : raise DagFileExists ( \"Dag id {} is still in DagBag. \" \"Remove the DAG file first: {}\" . format ( dag_id , dag . fileloc ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"boolean_operator\", 3, 8, 3, 55], [\"call\", 3, 28, 3, 55], 2], [\"Delete\", [\"not:not\", 3, 24, 3, 27]], [\"Delete\", [\"not_operator\", 3, 24, 3, 55]]]"}
{"project": "blaze", "commit_sha": "1cb2f0f2c9beaaeb4cb7779e623af4fc9ab2e2c9", "parent_sha": "470ae84c10d889b725316f6f19b1049af0c87125", "file_path": "blaze/tests/test_numpy_ufunc_compat.py", "project_url": "https://github.com/TomAugspurger/blaze", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -461,7 +461,7 @@ class TestTrig(unittest.TestCase):\n         a = blaze.array([0, blaze.pi/6, blaze.pi/3, 0.5*blaze.pi, blaze.pi, 1.5*blaze.pi, 2*blaze.pi])\n         b = blaze.array([1, 0.5*blaze.sqrt(3), 0.5, 0, -1, 0, 1])\n         assert_allclose(blaze.cos(a), b, rtol=1e-15, atol=1e-15)\n-        assert_allclose(blaze.cos(-a), -b, rtol=1e-15, atol=1e-15)\n+        assert_allclose(blaze.cos(-a), b, rtol=1e-15, atol=1e-15)\n \n def _check_branch_cut(f, x0, dx, re_sign=1, im_sign=-1, sig_zero_ok=False,\n                       dtype=np.complex):\n", "before": "assert_allclose ( blaze . cos ( - a ) , - b , rtol = 1e-15 , atol = 1e-15 )", "after": "assert_allclose ( blaze . cos ( - a ) , b , rtol = 1e-15 , atol = 1e-15 )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"argument_list\", 3, 24, 3, 67], [\"identifier:b\", 3, 41, 3, 42], 3], [\"Delete\", [\"-:-\", 3, 40, 3, 41]], [\"Delete\", [\"unary_operator\", 3, 40, 3, 42]]]"}
{"project": "galaxy-importer", "commit_sha": "bbcaf8bbe7de4a01b93b1795d18efb8c93a9e4a4", "parent_sha": "4a1f778d53f777561e91c333a056e2c0a5e0151d", "file_path": "galaxy_importer/loaders.py", "project_url": "https://github.com/ansible/galaxy-importer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -89,7 +89,7 @@ class ContentLoader(metaclass=abc.ABCMeta):\n     @staticmethod\n     def _get_tmp_dir(root):\n         root_parts = Path(root).parts\n-        return os.path.join(*root_parts[:3])\n+        return os.path.join(*root_parts[:-3])\n \n     @staticmethod\n     def _get_fq_collection_name(root):\n", "before": "return os . path . join ( * root_parts [ : 3 ] )", "after": "return os . path . join ( * root_parts [ : - 3 ] )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"slice\", 3, 41, 3, 43], [\"unary_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"integer:3\", 3, 42, 3, 43], 1]]"}
{"project": "unknown-horizons", "commit_sha": "47c6ea5e78d687490709654f87fe52282efe28bb", "parent_sha": "fb30c51ae11a32bad4050e3d15ae8b627dea1318", "file_path": "horizons/gui/ingamegui.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -445,7 +445,7 @@ class IngameGui(LivingObject):\n \t\tnew_name = self.widgets['change_name'].collectData('new_name')\n \t\tself.widgets['change_name'].findChild(name='new_name').text = u''\n-\t\tif not new_name or new_name.isspace():\n+\t\tif not new_name or not new_name.isspace():\n \t\t\t# different namedcomponent classes share the name\n \t\t\tRenameObject(instance.get_component_by_name(NamedComponent.NAME), new_name).execute(self.session)\n \t\tself._hide_change_name_dialog()\n", "before": "if not new_name or new_name . isspace ( ) : RenameObject ( instance . get_component_by_name ( NamedComponent . NAME ) , new_name ) . execute ( self . session )", "after": "if not new_name or not new_name . isspace ( ) : RenameObject ( instance . get_component_by_name ( NamedComponent . NAME ) , new_name ) . execute ( self . session )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 2, 10, 2, 40], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 2, 22, 2, 40], 1]]"}
{"project": "unknown-horizons", "commit_sha": "6d02d039ec6d8ed7ba1bf56989bb7732346cee43", "parent_sha": "8737b4990be2a3343f3147a0a7d68e452cd45698", "file_path": "horizons/world/building/storages.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,7 +52,7 @@ class StorageBuilding(SelectableBuilding, BuildableSingle, StorageResourceHandle\n \t\t# this shouldn't be absolutely necessary since the changelistener uses weak references\n \t\tself.inventory.remove_change_listener(self._changed)\n \n-\t\tself.inventory.adjust_limit(self.session.db.get_storage_building_capacity(self.id))\n+\t\tself.inventory.adjust_limit(-self.session.db.get_storage_building_capacity(self.id))\n \t\tsuper(StorageBuilding, self).remove()\n \n \tdef load(self, db, worldid):\n", "before": "self . inventory . adjust_limit ( self . session . db . get_storage_building_capacity ( self . id ) )", "after": "self . inventory . adjust_limit ( - self . session . db . get_storage_building_capacity ( self . id ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 30, 3, 86], [\"unary_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 31, 3, 85], 1]]"}
{"project": "unknown-horizons", "commit_sha": "1bc23e679904c700cc03092767552ced8b1e791c", "parent_sha": "3f2ae1477f0a2f208bdcbd9a8d87e317ddce0cc4", "file_path": "horizons/ai/aiplayer/productionbuilder.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -160,7 +160,7 @@ class ProductionBuilder(AreaBuilder):\n \n \t\t\tdistance = distances.distance_rect_rect(target_position, builder.position)\n \t\t\tvalue = distance - alignment * 0.7\n-\t\t\toptions.append((value, builder))\n+\t\t\toptions.append((-value, builder))\n \t\treturn self.build_best_option(options, BUILDING_PURPOSE.STORAGE)\n \n \tdef get_collector_area(self):\n", "before": "options . append ( ( value , builder ) )", "after": "options . append ( ( - value , builder ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"tuple\", 3, 19, 3, 35], [\"unary_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:value\", 3, 20, 3, 25], 1]]"}
{"project": "depmap_analysis", "commit_sha": "55490bd2e38fe780891cbb9a12595d1e32cadf8c", "parent_sha": "9799335a9d0217663ae69f225fb8e8a81cb03ddb", "file_path": "depmap_script.py", "project_url": "https://github.com/indralab/depmap_analysis", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -570,7 +570,7 @@ def main(args):\n     nx_expl_dir_graph = dnf.nx_directed_graph_from_nested_dict_3layer(\n         nest_d=explained_nested_dict)\n \n-    if not args.no_web_files:\n+    if args.no_web_files:\n         # 'explained_nodes' are used to produce first drop down\n         explained_nodes = list(nx_expl_dir_graph.nodes)\n         logger.info('Dumping json \"explainable_ids.json\" for first dropdown.')\n", "before": "if not args . no_web_files : explained_nodes = list ( nx_expl_dir_graph . nodes ) logger . info ( 'Dumping json \"explainable_ids.json\" for first dropdown.' )", "after": "if args . no_web_files : explained_nodes = list ( nx_expl_dir_graph . nodes ) logger . info ( 'Dumping json \"explainable_ids.json\" for first dropdown.' )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 5, 6, 79], [\"attribute\", 3, 12, 3, 29], 1], [\"Delete\", [\"not:not\", 3, 8, 3, 11]], [\"Delete\", [\"not_operator\", 3, 8, 3, 29]]]"}
{"project": "ansible-1", "commit_sha": "e151e5324efea00802a9a5196a43f5ea62484acc", "parent_sha": "53fe20f1dabc59590ff55522bcc94ca37587a1da", "file_path": "lib/ansible/modules/extras/cloud/lxd/lxd_container.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -444,7 +444,7 @@ class LxdContainerManagement(object):\n         if key not in self.config:\n             return False\n         if key == 'config':\n-            old_configs = dict((k, v) for k, v in self.old_container_json['metadata'][key].items() if k.startswith('volatile.'))\n+            old_configs = dict((k, v) for k, v in self.old_container_json['metadata'][key].items() if not k.startswith('volatile.'))\n         else:\n             old_configs = self.old_container_json['metadata'][key]\n         return self.config[key] != old_configs\n", "before": "old_configs = dict ( ( k , v ) for k , v in self . old_container_json [ 'metadata' ] [ key ] . items ( ) if k . startswith ( 'volatile.' ) )", "after": "old_configs = dict ( ( k , v ) for k , v in self . old_container_json [ 'metadata' ] [ key ] . items ( ) if not k . startswith ( 'volatile.' ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_clause\", 3, 100, 3, 128], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 103, 3, 128], 1]]"}
{"project": "ansible-1", "commit_sha": "4337b7a7770123e1634ccc13f55c321b89667bdf", "parent_sha": "2e4dcc9dda8a1cac000ea9eca32625cd3ba1b5d1", "file_path": "lib/ansible/modules/packaging/os/rpm_key.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -183,7 +183,7 @@ class RpmKey(object):\n \n     def drop_key(self, keyid):\n         if not self.module.check_mode:\n-            self.execute_command([self.rpm, '--erase', '--allmatches', \"gpg-pubkey-%s\" % keyid[8:].lower()])\n+            self.execute_command([self.rpm, '--erase', '--allmatches', \"gpg-pubkey-%s\" % keyid[-8:].lower()])\n \n \n def main():\n", "before": "self . execute_command ( [ self . rpm , '--erase' , '--allmatches' , \"gpg-pubkey-%s\" % keyid [ 8 : ] . lower ( ) ] )", "after": "self . execute_command ( [ self . rpm , '--erase' , '--allmatches' , \"gpg-pubkey-%s\" % keyid [ - 8 : ] . lower ( ) ] )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"slice\", 3, 96, 3, 98], [\"unary_operator\", \"N0\"], 0], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"integer:8\", 3, 96, 3, 97], 1]]"}
{"project": "pritunl", "commit_sha": "2bc29e400ed2fea2ec7bf9fd62268775fdee4fc4", "parent_sha": "d52a732b77a27e86f9aef27ba7aa6d951f5948b3", "file_path": "pritunl/utils/aws.py", "project_url": "https://github.com/security-geeks/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,7 +33,7 @@ def add_vpc_route(region, vpc_id, network, resource_id):\n     )\n \n     tables = vpc_conn.get_all_route_tables(filters={'vpc-id': vpc_id})\n-    if tables:\n+    if not tables:\n         raise VpcRouteTableNotFound('Failed to find VPC routing table')\n     table = tables[0]\n \n", "before": "if tables : raise VpcRouteTableNotFound ( 'Failed to find VPC routing table' )", "after": "if not tables : raise VpcRouteTableNotFound ( 'Failed to find VPC routing table' )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 5, 4, 72], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:tables\", 3, 8, 3, 14], 1]]"}
{"project": "ksvd", "commit_sha": "dce1d2ad8b7b7f62f6a14a49c2b5b1a8a95dfd7f", "parent_sha": "704c6470359c3728ac757b5c5756334ad1852d76", "file_path": "ksvd/__init__.py", "project_url": "https://github.com/LyqSpace/ksvd", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -85,7 +85,7 @@ class ApproximateKSVD(object):\n         for i in range(self.max_iter):\n             gamma = self._transform(D, X)\n             e = np.linalg.norm(X - gamma.dot(D))\n-            if not verbose_log:\n+            if verbose_log:\n                 print('Iter: %d, Err: %.4f' % (i, e))\n             if e < self.tol:\n                 break\n", "before": "if not verbose_log : print ( 'Iter: %d, Err: %.4f' % ( i , e ) )", "after": "if verbose_log : print ( 'Iter: %d, Err: %.4f' % ( i , e ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 13, 4, 54], [\"identifier:verbose_log\", 3, 20, 3, 31], 1], [\"Delete\", [\"not:not\", 3, 16, 3, 19]], [\"Delete\", [\"not_operator\", 3, 16, 3, 31]]]"}
{"project": "ansible-1", "commit_sha": "b2a9111b22dcd9662c0ae1537913a810e70b5c5c", "parent_sha": "473730583703dee1c1f3f22f46f8d1b8f20f786e", "file_path": "contrib/inventory/ec2.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1294,7 +1294,7 @@ class Ec2Inventory(object):\n     def to_safe(self, word):\n         ''' Converts 'bad' characters in a string to underscores so they can be used as Ansible groups '''\n         regex = \"[^A-Za-z0-9\\_\"\n-        if self.replace_dash_in_groups:\n+        if not self.replace_dash_in_groups:\n             regex += \"\\-\"\n         return re.sub(regex + \"]\", \"_\", word)\n \n", "before": "if self . replace_dash_in_groups : regex += \"\\-\"", "after": "if not self . replace_dash_in_groups : regex += \"\\-\"", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 26], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"attribute\", 3, 12, 3, 39], 1]]"}
{"project": "ansible-1", "commit_sha": "26a4761d0f40b539025974792e24efccac89f094", "parent_sha": "e003ef93fc97e4714a36bb37da8bd1a914f1274b", "file_path": "lib/ansible/plugins/action/script.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ class ActionModule(ActionBase):\n             # do not run the command if the line contains removes=filename\n             # and the filename does not exist. This allows idempotence\n             # of command executions.\n-            if self._remote_file_exists(removes):\n+            if not self._remote_file_exists(removes):\n                 return dict(skipped=True, msg=(\"skipped, since %s does not exist\" % removes))\n \n         # the script name is the first item in the raw params, so we split it\n", "before": "if self . _remote_file_exists ( removes ) : return dict ( skipped = True , msg = ( \"skipped, since %s does not exist\" % removes ) )", "after": "if not self . _remote_file_exists ( removes ) : return dict ( skipped = True , msg = ( \"skipped, since %s does not exist\" % removes ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 94], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 49], 1]]"}
{"project": "ansible-1", "commit_sha": "2db3f290ba81a0be7e1145c35aaeecfb431ebcbd", "parent_sha": "9de24a373522d1bef803c23e38fc989cd82852bf", "file_path": "lib/ansible/plugins/action/copy.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -184,7 +184,7 @@ class ActionModule(ActionBase):\n                     dest_file = self._connection._shell.join_path(dest, source_rel)\n                     dest_status = self._execute_remote_stat(dest_file, all_vars=task_vars, follow=follow)\n \n-            if not dest_status['exists'] and not force:\n+            if dest_status['exists'] and not force:\n                 # remote_file does not exist so continue to next iteration.\n                 continue\n \n", "before": "if not dest_status [ 'exists' ] and not force : continue", "after": "if dest_status [ 'exists' ] and not force : continue", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 13, 5, 25], [\"boolean_operator\", 3, 20, 3, 55], 1], [\"Delete\", [\"not:not\", 3, 16, 3, 19]], [\"Delete\", [\"not_operator\", 3, 16, 3, 55]]]"}
{"project": "conda-build", "commit_sha": "7978f4b13ed2b061d9ce16f71cf54d2672a7c99c", "parent_sha": "9c67704404795b09229bb4a5a24c473cb9e46447", "file_path": "conda_build/variants.py", "project_url": "https://github.com/bgruening/conda-build", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -555,7 +555,7 @@ def find_used_variables_in_text(variant, recipe_text, selectors=False):\n         conditional_regex = r\"(?:^|[^\\{])\\{%\\s*(?:el)?if\\s*\" + v_regex + r\"\\s*(?:[^%]*?)?%\\}\"\n         # plain req name, no version spec.  Look for end of line after name, or comment or selector\n         requirement_regex = r\"^\\s+\\-\\s+%s\\s*(?:\\s[\\[#]|$)\" % v_req_regex\n-        if not selectors:\n+        if selectors:\n             all_res.extend([selector_regex])\n         else:\n             all_res.extend([variant_regex, requirement_regex, conditional_regex])\n", "before": "if not selectors : all_res . extend ( [ selector_regex ] ) else : all_res . extend ( [ variant_regex , requirement_regex , conditional_regex ] )", "after": "if selectors : all_res . extend ( [ selector_regex ] ) else : all_res . extend ( [ variant_regex , requirement_regex , conditional_regex ] )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 9, 6, 82], [\"identifier:selectors\", 3, 16, 3, 25], 1], [\"Delete\", [\"not:not\", 3, 12, 3, 15]], [\"Delete\", [\"not_operator\", 3, 12, 3, 25]]]"}
{"project": "conda-build", "commit_sha": "bbcaf1d65f587a89482103149aeaefe994cd1804", "parent_sha": "b0265142f50da99aea76d31e5a6999d4f1ca3577", "file_path": "conda_build/source.py", "project_url": "https://github.com/bgruening/conda-build", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -594,7 +594,7 @@ def _get_patch_attributes(path, patch_exe, git, src_dir, stdout, stderr, retaine\n         amalgamated = True\n     strip_level, strip_level_guessed = _guess_patch_strip_level(files, src_dir)\n     if strip_level:\n-        files = [f.split('/', strip_level)[1] for f in files]\n+        files = [f.split('/', strip_level)[-1] for f in files]\n \n     # Defaults\n     result = {'patch': path,\n", "before": "files = [ f . split ( '/' , strip_level ) [ 1 ] for f in files ]", "after": "files = [ f . split ( '/' , strip_level ) [ - 1 ] for f in files ]", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"subscript\", 3, 18, 3, 46], [\"unary_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"integer:1\", 3, 44, 3, 45], 1]]"}
{"project": "sf-exporter", "commit_sha": "65bd7e4e0b608529cd95b1f2ca8a1eed6b9ec452", "parent_sha": "739b5fe9c4a5a595f101003d82ac609735d427e6", "file_path": "src/exporter.py", "project_url": "https://github.com/sysflow-telemetry/sf-exporter", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -101,7 +101,7 @@ def export_to_syslogger(args, logger):\n     try:\n         traces = [f for f in files(args.dir)]\n         traces.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n-        fields = args.exportfields.split(',') if not args.exportfields else None \n+        fields = args.exportfields.split(',') if args.exportfields else None \n         # send complete traces, exclude most recent log\n         for trace in traces[:-1]:\n             reader = FlattenedSFReader(trace, False)\n", "before": "fields = args . exportfields . split ( ',' ) if not args . exportfields else None", "after": "fields = args . exportfields . split ( ',' ) if args . exportfields else None", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"conditional_expression\", 3, 18, 3, 81], [\"attribute\", 3, 54, 3, 71], 2], [\"Delete\", [\"not:not\", 3, 50, 3, 53]], [\"Delete\", [\"not_operator\", 3, 50, 3, 71]]]"}
{"project": "django-rest-framework", "commit_sha": "d2ae41529c2319e1b67f05464b7e543cfb2adc2c", "parent_sha": "63d8dc0b9bbac3b6c0315dbb5017f77ba31a3d80", "file_path": "tests/test_relations_slug.py", "project_url": "https://github.com/Benoss/django-rest-framework", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -178,7 +178,7 @@ class SlugForeignKeyTests(TestCase):\n         data = {'id': 1, 'name': 'source-1', 'target': None}\n         instance = ForeignKeySource.objects.get(pk=1)\n         serializer = ForeignKeySourceSerializer(instance, data=data)\n-        assert serializer.is_valid()\n+        assert not serializer.is_valid()\n         assert serializer.errors == {'target': ['This field may not be null.']}\n \n \n", "before": "assert serializer . is_valid ( )", "after": "assert not serializer . is_valid ( )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"assert_statement\", 3, 9, 3, 37], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 37], 1]]"}
{"project": "DeepLearningTutorials", "commit_sha": "42568775afbff5baf301cae7a6676fc5aca49aaf", "parent_sha": "39333dd7f34772ac6987fc778344b57c59d52604", "file_path": "code/mlp.py", "project_url": "https://github.com/reference-project/DeepLearningTutorials", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -83,7 +83,7 @@ class MLP(object):\n         # the output of uniform if converted using asarray to dtype \n         # theano.config.floatX so that the code is runable on GPU\n         W2_values = numpy.asarray( numpy.random.uniform( \n-              low = numpy.sqrt(6./(n_hidden+n_out)), \\\n+              low = -numpy.sqrt(6./(n_hidden+n_out)), \\\n               high= numpy.sqrt(6./(n_hidden+n_out)),\\\n               size= (n_hidden, n_out)), dtype = theano.config.floatX)\n \n", "before": "W2_values = numpy . asarray ( numpy . random . uniform ( low = numpy . sqrt ( 6. / ( n_hidden + n_out ) ) , high = numpy . sqrt ( 6. / ( n_hidden + n_out ) ) , size = ( n_hidden , n_out ) ) , dtype = theano . config . floatX )", "after": "W2_values = numpy . asarray ( numpy . random . uniform ( low = - numpy . sqrt ( 6. / ( n_hidden + n_out ) ) , high = numpy . sqrt ( 6. / ( n_hidden + n_out ) ) , size = ( n_hidden , n_out ) ) , dtype = theano . config . floatX )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 15, 3, 52], [\"unary_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 21, 3, 52], 1]]"}
{"project": "pylearn2", "commit_sha": "5e8ac740ad4d56fcfe75f51389cc749ab161a2c6", "parent_sha": "cbe0cf867fde58f35545b27cf9bdec4f2336781a", "file_path": "pylearn2/datasets/dense_design_matrix.py", "project_url": "https://github.com/reference-project/pylearn2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1271,7 +1271,7 @@ class DenseDesignMatrixPyTables(DenseDesignMatrix):\n         fill_hdf5.\n \n         Parameters\n-        ---------\n+        ----------\n         h5file : hdf5 file handle\n             Handle to an hdf5 object.\n         start : int\n", "before": "- - - - - - - - - h5file : hdf5 file handle", "after": "- - - - - - - - - - h5file : hdf5 file handle", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"unary_operator\", 3, 17, 4, 34], [\"-:-\", \"T\"], 0], [\"Move\", [\"unary_operator\", 3, 17, 4, 34], [\"unary_operator\", 3, 17, 4, 34], 1]]"}
{"project": "salt", "commit_sha": "53d8304b158fe65396a445a474a5aff18af0f4f4", "parent_sha": "573390d8adea69b1ec060c1a493cbbbff2e27693", "file_path": "salt/output/highstate.py", "project_url": "https://github.com/StepOneInc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -349,7 +349,7 @@ def _strip_clean(returns):\n     rm_tags = []\n     for tag in returns:\n-        if not isinstance(tag, dict):\n+        if isinstance(tag, dict):\n             continue\n         if returns[tag]['result'] and not returns[tag]['changes']:\n             rm_tags.append(tag)\n", "before": "if not isinstance ( tag , dict ) : continue", "after": "if isinstance ( tag , dict ) : continue", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 2, 9, 3, 21], [\"call\", 2, 16, 2, 37], 1], [\"Delete\", [\"not:not\", 2, 12, 2, 15]], [\"Delete\", [\"not_operator\", 2, 12, 2, 37]]]"}
{"project": "salt", "commit_sha": "f1ec37d328c9fe2f437cd91711e2f94b277f302f", "parent_sha": "4c154fb55b64ab5b25428455555b8400a3e56826", "file_path": "salt/states/lvm.py", "project_url": "https://github.com/StepOneInc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -90,7 +90,7 @@ def pv_absent(name):\n     else:\n         changes = __salt__['lvm.pvremove'](name)\n \n-        if not __salt__['lvm.pvdisplay'](name):\n+        if __salt__['lvm.pvdisplay'](name):\n             ret['comment'] = 'Failed to remove Physical Volume {0}'.format(name)\n             ret['result'] = False\n         else:\n", "before": "if not __salt__ [ 'lvm.pvdisplay' ] ( name ) : ret [ 'comment' ] = 'Failed to remove Physical Volume {0}' . format ( name ) ret [ 'result' ] = False else : ", "after": "if __salt__ [ 'lvm.pvdisplay' ] ( name ) : ret [ 'comment' ] = 'Failed to remove Physical Volume {0}' . format ( name ) ret [ 'result' ] = False else : ", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 9, 6, 14], [\"call\", 3, 16, 3, 47], 1], [\"Delete\", [\"not:not\", 3, 12, 3, 15]], [\"Delete\", [\"not_operator\", 3, 12, 3, 47]]]"}
{"project": "mimicnotes", "commit_sha": "4829698fe8aed86f9a2810fa494c10cb5348ef21", "parent_sha": "6072081fe20d313eb058ebe3cb21c5d11f310e47", "file_path": "reader.py", "project_url": "https://github.com/ankitkv/mimicnotes", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -443,7 +443,7 @@ class NoteReader(object):\n         for note_collection in self.buffered_read_sorted_notes(splits):\n             batches = [note_collection[i:i+self.config.batch_size]\n                        for i in xrange(0, len(note_collection), self.config.batch_size)]\n-            if not self.config.length_sort:\n+            if self.config.length_sort:\n                 random.shuffle(batches)\n             for batch in batches:\n                 yield self.pack(batch)\n", "before": "if not self . config . length_sort : random . shuffle ( batches )", "after": "if self . config . length_sort : random . shuffle ( batches )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 13, 4, 40], [\"attribute\", 3, 20, 3, 43], 1], [\"Delete\", [\"not:not\", 3, 16, 3, 19]], [\"Delete\", [\"not_operator\", 3, 16, 3, 43]]]"}
{"project": "dwc_network_server_emulator", "commit_sha": "3e288b0ba9b266e3983b918b35d9e7682a733154", "parent_sha": "39af2e081cb913294eca26c3cbe5fc395b8da089", "file_path": "internal_stats_server.py", "project_url": "https://github.com/shutterbug2000/dwc_network_server_emulator", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -95,7 +95,7 @@ class StatsPage(resource.Resource):\n             if server_list is not None:\n                 output += \"\".join(self.row % (game, len(server_list[game]))\n                                   for game in server_list\n-                                  if not server_list[game])\n+                                  if server_list[game])\n             output += self.footer % (self.stats.get_last_update_time())\n \n         return output\n", "before": "output += \"\" . join ( self . row % ( game , len ( server_list [ game ] ) ) for game in server_list if not server_list [ game ] )", "after": "output += \"\" . join ( self . row % ( game , len ( server_list [ game ] ) ) for game in server_list if server_list [ game ] )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_clause\", 3, 35, 3, 59], [\"subscript\", 3, 42, 3, 59], 1], [\"Delete\", [\"not:not\", 3, 38, 3, 41]], [\"Delete\", [\"not_operator\", 3, 38, 3, 59]]]"}
{"project": "dwc_network_server_emulator", "commit_sha": "5dbd696c787312ea41851965c373c09676543986", "parent_sha": "7feb4ae0c722d3426fefa7a2d1a80bcc50a55b78", "file_path": "gamespy_natneg_server.py", "project_url": "https://github.com/shutterbug2000/dwc_network_server_emulator", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -180,7 +180,7 @@ class GameSpyNatNegServer(object):\n                            serveraddr, session_id)\n \n                 publicport = client_session['addr'][1]\n-                if not client_session['localaddr'][1]:\n+                if client_session['localaddr'][1]:\n                     publicport = client_session['localaddr'][1]\n \n                 if client_session['serveraddr'] is not None:\n", "before": "if not client_session [ 'localaddr' ] [ 1 ] : publicport = client_session [ 'localaddr' ] [ 1 ]", "after": "if client_session [ 'localaddr' ] [ 1 ] : publicport = client_session [ 'localaddr' ] [ 1 ]", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 17, 4, 64], [\"subscript\", 3, 24, 3, 54], 1], [\"Delete\", [\"not:not\", 3, 20, 3, 23]], [\"Delete\", [\"not_operator\", 3, 20, 3, 54]]]"}
{"project": "portage", "commit_sha": "ffe0e3fb6998c776b08f725c53dfe6c632ce7d02", "parent_sha": "b39ea65b4b40b73a79893f0c8b0c218b3f5ecc42", "file_path": "pym/portage/package/ebuild/config.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/portage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2644,7 +2644,7 @@ class config(object):\n \t\t\tmydict.pop(\"AA\", None)\n \n \t\t# Prefix variables are supported starting with EAPI 3.\n-\t\tif phase == 'depend' or eapi is None or eapi_supports_prefix(eapi):\n+\t\tif phase == 'depend' or eapi is None or not eapi_supports_prefix(eapi):\n \t\t\tmydict.pop(\"ED\", None)\n \t\t\tmydict.pop(\"EPREFIX\", None)\n \t\t\tmydict.pop(\"EROOT\", None)\n", "before": "if phase == 'depend' or eapi is None or eapi_supports_prefix ( eapi ) : mydict . pop ( \"ED\" , None ) mydict . pop ( \"EPREFIX\" , None ) mydict . pop ( \"EROOT\" , None )", "after": "if phase == 'depend' or eapi is None or not eapi_supports_prefix ( eapi ) : mydict . pop ( \"ED\" , None ) mydict . pop ( \"EPREFIX\" , None ) mydict . pop ( \"EROOT\" , None )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 6, 3, 69], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 43, 3, 69], 1]]"}
{"project": "NiftyNet", "commit_sha": "07ce8d4ef8d70bb403edb19cf1b110048a1c76c4", "parent_sha": "4b9bc2a1ae6dafb91a45bae7cc375a1d7afc06e4", "file_path": "engine/inference.py", "project_url": "https://github.com/neo4reo/NiftyNet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -16,7 +16,7 @@ from utilities.input_placeholders import ImagePatch\n \n # run on single GPU with single thread\n def run(net_class, param, volume_loader, device_str):\n-    output_image_channels = param.num_classes if not param.output_prob else 1\n+    output_image_channels = param.num_classes if param.output_prob else 1\n \n     # construct graph\n     graph = tf.Graph()\n", "before": "output_image_channels = param . num_classes if not param . output_prob else 1", "after": "output_image_channels = param . num_classes if param . output_prob else 1", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"conditional_expression\", 3, 29, 3, 78], [\"attribute\", 3, 54, 3, 71], 2], [\"Delete\", [\"not:not\", 3, 50, 3, 53]], [\"Delete\", [\"not_operator\", 3, 50, 3, 71]]]"}
{"project": "osf.io", "commit_sha": "09019094afcfc258194d70cbc115c35233a08d80", "parent_sha": "917c18be84540a871a351b9e3fbeb66c3598c7af", "file_path": "website/mailchimp_utils.py", "project_url": "https://github.com/Vhoakab84/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -63,7 +63,7 @@ def unsubscribe(list_name, user_id):\n @user_confirmed.connect\n def subscribe_on_confirm(user):\n     # Subscribe user to general OSF mailing list upon account confirmation\n-    if not settings.ENABLE_EMAIL_SUBSCRIPTIONS:\n+    if settings.ENABLE_EMAIL_SUBSCRIPTIONS:\n         subscribe_mailchimp(settings.MAILCHIMP_GENERAL_LIST, user._id)\n \n subscribe_mailchimp = (\n", "before": "if not settings . ENABLE_EMAIL_SUBSCRIPTIONS : subscribe_mailchimp ( settings . MAILCHIMP_GENERAL_LIST , user . _id )", "after": "if settings . ENABLE_EMAIL_SUBSCRIPTIONS : subscribe_mailchimp ( settings . MAILCHIMP_GENERAL_LIST , user . _id )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 5, 4, 71], [\"attribute\", 3, 12, 3, 47], 1], [\"Delete\", [\"not:not\", 3, 8, 3, 11]], [\"Delete\", [\"not_operator\", 3, 8, 3, 47]]]"}
{"project": "osf.io", "commit_sha": "5b6273c7926cc29b192e0b6be110b00d5f5bdfd0", "parent_sha": "84673130e0068e7859c34928e0c69fe50f7bd813", "file_path": "scripts/osfstorage/migrate_from_oldels.py", "project_url": "https://github.com/Vhoakab84/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ def migrate_download_counts(node, children, dry=True):\n                 updates.append(result)\n                 # database.pagecounters.insert(result)\n \n-        if dry:\n+        if not dry:\n             try:\n                 database.pagecounters.insert(updates, continue_on_error=True)\n             except DuplicateKeyError:\n", "before": "if dry : try : database . pagecounters . insert ( updates , continue_on_error = True ) except DuplicateKeyError : ", "after": "if not dry : try : database . pagecounters . insert ( updates , continue_on_error = True ) except DuplicateKeyError : ", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 38], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:dry\", 3, 12, 3, 15], 1]]"}
{"project": "pyneo4jet", "commit_sha": "7d54f0b567ca6e1771d483680f3375c26ba89d54", "parent_sha": "9ec035c83ee73526a5af1e911e2d422f2ac06042", "file_path": "model.py", "project_url": "https://github.com/huxuan/pyneo4jet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,7 +52,7 @@ class User(object):\n         if invitation != INVITATION_CODE:\n             return False, 'The invitation code is invalid!'\n         user_node = user_idx['username'][username].single\n-        if not user_node:\n+        if user_node:\n             return False, 'The username %s has been used!' % username\n         user = User(username, password)\n         with db.transaction:\n", "before": "if not user_node : return False , 'The username %s has been used!' % username", "after": "if user_node : return False , 'The username %s has been used!' % username", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 9, 4, 70], [\"identifier:user_node\", 3, 16, 3, 25], 1], [\"Delete\", [\"not:not\", 3, 12, 3, 15]], [\"Delete\", [\"not_operator\", 3, 12, 3, 25]]]"}
{"project": "CSIT_Test", "commit_sha": "032a71e582bb24e9c6a52922057b5ff0db14db96", "parent_sha": "63a0e47e27c33027e0ba02b2a553853c12790321", "file_path": "base/testmodule.py", "project_url": "https://github.com/yeasy/CSIT_Test", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ class TestModule(object):\n         \"\"\"\n         Return all nodes.\n         \"\"\"\n-        if isinstance(content, dict) or not content.has_key(key):\n+        if not isinstance(content, dict) or not content.has_key(key):\n             return None\n         else:\n             return [e.get(property) for e in content[key]]\n", "before": "if isinstance ( content , dict ) or not content . has_key ( key ) : return None else : return [ e . get ( property ) for e in content [ key ] ]", "after": "if not isinstance ( content , dict ) or not content . has_key ( key ) : return None else : return [ e . get ( property ) for e in content [ key ] ]", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 6, 59], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"boolean_operator\", 3, 12, 3, 65], 1]]"}
{"project": "pyfolio", "commit_sha": "5f1634a67c1e687ff0d0f22952ebe4f2ea0e77cc", "parent_sha": "662d4d37884d4b2931f8e0ccc1f8aa394239e52d", "file_path": "pyfolio/txn.py", "project_url": "https://github.com/jaCod3r/pyfolio", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ def make_transaction_frame(transactions):\n             txn = map_transaction(txn)\n             transaction_list.append(txn)\n     df = pd.DataFrame(sorted(transaction_list, key=lambda x: x['dt']))\n-    df['txn_dollars'] = df['amount'] * df['price']\n+    df['txn_dollars'] = -df['amount'] * df['price']\n \n     df.index = list(map(pd.Timestamp, df.dt.values))\n     return df\n", "before": "df [ 'txn_dollars' ] = df [ 'amount' ] * df [ 'price' ]", "after": "df [ 'txn_dollars' ] = - df [ 'amount' ] * df [ 'price' ]", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 25, 3, 51], [\"unary_operator\", \"N0\"], 0], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"subscript\", 3, 25, 3, 37], 1]]"}
{"project": "Tron", "commit_sha": "a14de094e7c70095652f5cc6fb37283ff4bd3075", "parent_sha": "aede24b54d5189e631e54518b29a76f50b28105b", "file_path": "src/pydroid/views.py", "project_url": "https://github.com/matgrioni/Tron", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ class View(utils.EventHandler):\n \n     # Handles basic drawing behavior such as background color\n     def draw(self):\n-        if not self.visible:\n+        if self.visible:\n             bounds = (self.x, self.y, self.size[0], self.size[1])\n             pygame.draw.rect(self.screen, self.background, bounds)\n \n", "before": "if not self . visible : bounds = ( self . x , self . y , self . size [ 0 ] , self . size [ 1 ] ) pygame . draw . rect ( self . screen , self . background , bounds )", "after": "if self . visible : bounds = ( self . x , self . y , self . size [ 0 ] , self . size [ 1 ] ) pygame . draw . rect ( self . screen , self . background , bounds )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 9, 5, 67], [\"attribute\", 3, 16, 3, 28], 1], [\"Delete\", [\"not:not\", 3, 12, 3, 15]], [\"Delete\", [\"not_operator\", 3, 12, 3, 28]]]"}
{"project": "picard", "commit_sha": "99be9dbfe50cad43a2c0022c841e4a2cefde7e64", "parent_sha": "aa2425f229edeb98414b121bf5bf8e1c07c593d9", "file_path": "picard/ui/scripteditor.py", "project_url": "https://github.com/phw/picard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -757,7 +757,7 @@ class ScriptEditorDialog(PicardDialog):\n-        if not self.loading or skip_check or self.unsaved_changes_confirmation():\n+        if self.loading or skip_check or self.unsaved_changes_confirmation():\n             script_item = self.get_selected_item()\n             self.ui.script_title.setText(script_item['title'])\n             self.set_script(script_item['script'])\n", "before": "if not self . loading or skip_check or self . unsaved_changes_confirmation ( ) : script_item = self . get_selected_item ( ) self . ui . script_title . setText ( script_item [ 'title' ] ) self . set_script ( script_item [ 'script' ] )", "after": "if self . loading or skip_check or self . unsaved_changes_confirmation ( ) : script_item = self . get_selected_item ( ) self . ui . script_title . setText ( script_item [ 'title' ] ) self . set_script ( script_item [ 'script' ] )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 0, 9, 3, 51], [\"boolean_operator\", 0, 16, 0, 81], 1], [\"Delete\", [\"not:not\", 0, 12, 0, 15]], [\"Delete\", [\"not_operator\", 0, 12, 0, 81]]]"}
{"project": "api", "commit_sha": "656c3ce12d5109da41a56cdb234cb332df779837", "parent_sha": "643758b71572bc65d16ef4978f0e7e0917f4ee22", "file_path": "cci/modules.py", "project_url": "https://github.com/VUIIS/api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ class Module(object):\n         if not os.path.exists(self.directory):\n             os.mkdir(self.directory)\n         else:\n-            if suffix:\n+            if not suffix:\n                 self.clean_directory()\n             else:\n                 today=datetime.now()\n", "before": "if suffix : self . clean_directory ( ) else : today = datetime . now ( )", "after": "if not suffix : self . clean_directory ( ) else : today = datetime . now ( )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 37], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:suffix\", 3, 16, 3, 22], 1]]"}
{"project": "ulearn.core", "commit_sha": "2e5a0e22143cf22231e387ad4a15a047dce55020", "parent_sha": "6729cdd73bc71678c4a77cf420f421f47b84ce96", "file_path": "ulearn/core/browser/migrations.py", "project_url": "https://github.com/UPCnet/ulearn.core", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -300,7 +300,7 @@ class GiveAllCommunitiesGWUUID(grok.View):\n \n         for community in communities:\n             obj = community.getObject()\n-            if getattr(obj, ATTRIBUTE_NAME, False):\n+            if not getattr(obj, ATTRIBUTE_NAME, False):\n                 uuid = generator()\n                 if not uuid:\n                     return\n", "before": "if getattr ( obj , ATTRIBUTE_NAME , False ) : uuid = generator ( ) if not uuid : return", "after": "if not getattr ( obj , ATTRIBUTE_NAME , False ) : uuid = generator ( ) if not uuid : return", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 6, 27], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 51], 1]]"}
{"project": "cs.recipe.eggpath", "commit_sha": "f80c7786f90eac64f0c1ec049aebcf0c42265f6d", "parent_sha": "0859a7613238afe76ea05a18548095174db9208e", "file_path": "cs/recipe/eggpath/__init__.py", "project_url": "https://github.com/codesyntax/cs.recipe.eggpath", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -20,7 +20,7 @@ class Recipe(object):\n         for k,v in ws.by_key.items():            \n             if k == options['egg'] or k.replace('-', '_') == options['egg']:\n                 loc = [v.location]\n-                if not os.path.isdir(v.location):\n+                if os.path.isdir(v.location):\n                     #not zipped package, append egg name\n                     loc.extend(options['egg'].split('.'))\n                 self.path = os.path.join(*loc)\n", "before": "if not os . path . isdir ( v . location ) : loc . extend ( options [ 'egg' ] . split ( '.' ) )", "after": "if os . path . isdir ( v . location ) : loc . extend ( options [ 'egg' ] . split ( '.' ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 17, 5, 58], [\"call\", 3, 24, 3, 49], 1], [\"Delete\", [\"not:not\", 3, 20, 3, 23]], [\"Delete\", [\"not_operator\", 3, 20, 3, 49]]]"}
{"project": "millifluidics", "commit_sha": "04ecb2fc8b002bef637fa5ef8b6f18d8a0d5a1f6", "parent_sha": "7b09ed38de6cf043833772e92b1fbdf1794f1647", "file_path": "smallscripts/getCovarExp_PVD.py", "project_url": "https://github.com/lukasgeyrhofer/millifluidics", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -61,7 +61,7 @@ def main():\n             Ex    = gc.SeedingAverage(func_x   (m,m,params), inoc)\n             Eexp  = gc.SeedingAverage(func_exp (m,m,params), inoc)\n             \n-            xw1[i,j] = (Exexp - Ex * Eexp) / (params['sigma']/(params['sigma']-1) - Eexp)\n+            xw1[i,j] = -(Exexp - Ex * Eexp) / (params['sigma']/(params['sigma']-1) - Eexp)\n             \n             print(\"{:14.6e} {:14.6e} {:14.6e}\".format(a1,a2,xw1[i,j]))\n         print(\"\")\n", "before": "xw1 [ i , j ] = ( Exexp - Ex * Eexp ) / ( params [ 'sigma' ] / ( params [ 'sigma' ] - 1 ) - Eexp )", "after": "xw1 [ i , j ] = - ( Exexp - Ex * Eexp ) / ( params [ 'sigma' ] / ( params [ 'sigma' ] - 1 ) - Eexp )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 24, 3, 90], [\"unary_operator\", \"N0\"], 0], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"parenthesized_expression\", 3, 24, 3, 43], 1]]"}
{"project": "iterative-Random-Forest", "commit_sha": "7a485af787e244fdb61818f00c83911b5bd3c35e", "parent_sha": "83475803b5508dc58166d49420ecbf6230bf1ab3", "file_path": "scikits/learn/utils/fixes.py", "project_url": "https://github.com/Yu-Group/iterative-Random-Forest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -81,7 +81,7 @@ def qr_economic(A, **kwargs):\n     import scipy.linalg\n     # trick: triangular solve has introduced in 0.9\n-    if not hasattr(scipy.linalg, 'triangular_solve'):\n+    if hasattr(scipy.linalg, 'triangular_solve'):\n         return scipy.linalg.qr(A, mode='economic', **kwargs)\n     else:\n         return scipy.linalg.qr(A, econ=True, **kwargs)\n", "before": "if not hasattr ( scipy . linalg , 'triangular_solve' ) : return scipy . linalg . qr ( A , mode = 'economic' , ** kwargs ) else : return scipy . linalg . qr ( A , econ = True , ** kwargs )", "after": "if hasattr ( scipy . linalg , 'triangular_solve' ) : return scipy . linalg . qr ( A , mode = 'economic' , ** kwargs ) else : return scipy . linalg . qr ( A , econ = True , ** kwargs )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 2, 5, 5, 55], [\"call\", 2, 12, 2, 53], 1], [\"Delete\", [\"not:not\", 2, 8, 2, 11]], [\"Delete\", [\"not_operator\", 2, 8, 2, 53]]]"}
{"project": "iterative-Random-Forest", "commit_sha": "0220e182b8d70086737e0ea668e4fee11f3abf91", "parent_sha": "48021c61bd46c920c95397764d23366900bcf6b4", "file_path": "sklearn/cluster/hierarchical.py", "project_url": "https://github.com/Yu-Group/iterative-Random-Forest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -199,7 +199,7 @@ def _hc_cut(n_clusters, children, n_leaves):\n-    if not n_clusters > n_leaves:\n+    if n_clusters > n_leaves:\n         raise ValueError('Cannot extract more clusters than samples: '\n             '%s clusters where given for a tree with %s leaves.'\n             % (n_clusters, n_leaves))\n", "before": "if not n_clusters > n_leaves : raise ValueError ( 'Cannot extract more clusters than samples: ' '%s clusters where given for a tree with %s leaves.' % ( n_clusters , n_leaves ) )", "after": "if n_clusters > n_leaves : raise ValueError ( 'Cannot extract more clusters than samples: ' '%s clusters where given for a tree with %s leaves.' % ( n_clusters , n_leaves ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 0, 5, 3, 38], [\"comparison_operator\", 0, 12, 0, 33], 1], [\"Delete\", [\"not:not\", 0, 8, 0, 11]], [\"Delete\", [\"not_operator\", 0, 8, 0, 33]]]"}
{"project": "feat", "commit_sha": "3fa7119623acf59ca08c11512a825c4dee3d2016", "parent_sha": "856e43e3e58461186c0fc0f801fdccc9d0bb1969", "file_path": "src/feat/test/integration/test_idatabase_client.py", "project_url": "https://github.com/f3at/feat", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -67,7 +67,7 @@ class FilteringView(view.BaseView):\n     name = 'filter_view'\n \n     def filter(doc, request):\n-        check_request = (not request.get('query') and\n+        check_request = (request.get('query') and\n                          request['query'].get('field') is not None)\n         return (doc.get('.type', None) == 'view-dummy' and\n                 (not check_request or\n", "before": "check_request = ( not request . get ( 'query' ) and request [ 'query' ] . get ( 'field' ) is not None )", "after": "check_request = ( request . get ( 'query' ) and request [ 'query' ] . get ( 'field' ) is not None )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"parenthesized_expression\", 3, 25, 4, 68], [\"boolean_operator\", 3, 30, 4, 67], 1], [\"Delete\", [\"not:not\", 3, 26, 3, 29]], [\"Delete\", [\"not_operator\", 3, 26, 4, 67]]]"}
{"project": "ajenti", "commit_sha": "fa775af8bbe23bff2ed97dc0fa1e201d1d199399", "parent_sha": "b46a6ab01415b060255c1b0d96ad2acdab768b18", "file_path": "ajenti/plugins/packages/pm_apt.py", "project_url": "https://github.com/cliftonclassroom/ajenti", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -54,7 +54,7 @@ class DebianPackageManager (PackageManager):\n \n             p = PackageInfo()\n             p.name = s[0]\n-            p.version = s[1].split(' ')[-1]\n+            p.version = s[-1].split(' ')[-1]\n             r.append(p)\n         return r\n \n", "before": "p . version = s [ 1 ] . split ( ' ' ) [ - 1 ]", "after": "p . version = s [ - 1 ] . split ( ' ' ) [ - 1 ]", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"subscript\", 3, 25, 3, 29], [\"unary_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"integer:1\", 3, 27, 3, 28], 1]]"}
{"project": "kivy", "commit_sha": "e2f0671e700f808bb5d58c1dc7a36e8398f10d8f", "parent_sha": "9fb466ef88389c95733b9ebb0cb7f6cf5e731458", "file_path": "kivy/input/motionevent.py", "project_url": "https://github.com/jofomah/kivy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -284,7 +284,7 @@ class MotionEvent(object):\n-        if self.is_touch:\n+        if not self.is_touch:\n             raise Exception('Grab work only for Touch Motion Event.')\n         if self.grab_exclusive_class is not None:\n             raise Exception('Cannot grab the touch, touch are exclusive')\n", "before": "if self . is_touch : raise Exception ( 'Grab work only for Touch Motion Event.' )", "after": "if not self . is_touch : raise Exception ( 'Grab work only for Touch Motion Event.' )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 0, 9, 1, 70], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"attribute\", 0, 12, 0, 25], 1]]"}
{"project": "youtube-dl", "commit_sha": "753fad4adc32b57a0d18518fddd06d2411d09635", "parent_sha": "34814eb66e948b5d73420e435f3aea7112b243d5", "file_path": "youtube_dl/extractor/commonmistakes.py", "project_url": "https://github.com/ozburo/youtube-dl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,6 +24,6 @@ class CommonMistakesIE(InfoExtractor):\n             'That doesn\\'t make any sense. '\n             'Simply remove the parameter in your command or configuration.'\n         ) % url\n-        if self._downloader.params.get('verbose'):\n+        if not self._downloader.params.get('verbose'):\n             msg += ' Add -v to the command line to see what arguments and configuration youtube-dl got.'\n         raise ExtractorError(msg, expected=True)\n", "before": "if self . _downloader . params . get ( 'verbose' ) : msg += ' Add -v to the command line to see what arguments and configuration youtube-dl got.'", "after": "if not self . _downloader . params . get ( 'verbose' ) : msg += ' Add -v to the command line to see what arguments and configuration youtube-dl got.'", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 105], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 50], 1]]"}
{"project": "youtube-dl", "commit_sha": "f241a97312238a790f7eed927fd3934c491a8fec", "parent_sha": "86c8cfc5558fd73e2c8bd62ea256200ce30e017e", "file_path": "youtube_dl/extractor/afreecatv.py", "project_url": "https://github.com/ozburo/youtube-dl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -200,7 +200,7 @@ class AfreecaTVIE(InfoExtractor):\n             raise ExtractorError(\n                 '%s said: %s' % (self.IE_NAME, flag), expected=True)\n \n-        video_element = video_xml.findall(compat_xpath('./track/video'))[1]\n+        video_element = video_xml.findall(compat_xpath('./track/video'))[-1]\n         if video_element is None or video_element.text is None:\n             raise ExtractorError('Specified AfreecaTV video does not exist',\n                                  expected=True)\n", "before": "video_element = video_xml . findall ( compat_xpath ( './track/video' ) ) [ 1 ]", "after": "video_element = video_xml . findall ( compat_xpath ( './track/video' ) ) [ - 1 ]", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"subscript\", 3, 25, 3, 76], [\"unary_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"integer:1\", 3, 74, 3, 75], 1]]"}
{"project": "weaver", "commit_sha": "0cff368fb8039063ef32d92882cc4a9130a9a1c8", "parent_sha": "e179e3e70bbacbec3665b653cb32228cf9729635", "file_path": "twitcher/processes/wps_process.py", "project_url": "https://github.com/crim-ca/weaver", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -46,7 +46,7 @@ class WpsProcess(object):\n \n     def get_user_auth_header(self):\n         # TODO: find a better way to generalize this to Magpie credentials?\n-        if asbool(self.settings.get('ades.use_auth_token', True)):\n+        if not asbool(self.settings.get('ades.use_auth_token', True)):\n             return {}\n \n         ades_usr = self.settings.get('ades.username', None)\n", "before": "if asbool ( self . settings . get ( 'ades.use_auth_token' , True ) ) : return { }", "after": "if not asbool ( self . settings . get ( 'ades.use_auth_token' , True ) ) : return { }", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 22], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 66], 1]]"}
{"project": "meson", "commit_sha": "eb181485d079991c7e69d229a49dd64422eb3907", "parent_sha": "7aa24c7d0a68959e4d29c41d157ee30ff97153ad", "file_path": "mesonbuild/backend/ninjabackend.py", "project_url": "https://github.com/rindeal/meson", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1397,7 +1397,7 @@ rule FORTRAN_DEP_HACK\n     def get_cross_stdlib_args(self, target, compiler):\n         if not target.is_cross:\n             return []\n-        if self.environment.cross_info.has_stdlib(compiler.language):\n+        if not self.environment.cross_info.has_stdlib(compiler.language):\n             return []\n         return compiler.get_no_stdinc_args()\n \n", "before": "if self . environment . cross_info . has_stdlib ( compiler . language ) : return [ ]", "after": "if not self . environment . cross_info . has_stdlib ( compiler . language ) : return [ ]", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 22], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 69], 1]]"}
{"project": "new_edx", "commit_sha": "a9f94da8ea606663b3ae4889e1f3c07a240ce697", "parent_sha": "6332fd78dd7fb9e00dd459fcf96ef127b33cf5e1", "file_path": "courseware/module_render.py", "project_url": "https://github.com/syjeon/new_edx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -90,7 +90,7 @@ def modx_dispatch(request, module=None, dispatch=None, id=None):\n     ajax_return=instance.handle_ajax(dispatch, request.POST)\n     # Save the state back to the database\n     s.state=instance.get_state()\n-    if not instance.get_score(): \n+    if instance.get_score(): \n         s.grade=instance.get_score()['score']\n     s.save()\n     # Return whatever the module wanted to return to the client/caller\n", "before": "if not instance . get_score ( ) : s . grade = instance . get_score ( ) [ 'score' ]", "after": "if instance . get_score ( ) : s . grade = instance . get_score ( ) [ 'score' ]", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 5, 4, 46], [\"call\", 3, 12, 3, 32], 1], [\"Delete\", [\"not:not\", 3, 8, 3, 11]], [\"Delete\", [\"not_operator\", 3, 8, 3, 32]]]"}
{"project": "new_edx", "commit_sha": "1058b552f2e305748f2702c1fed33026a0d24d71", "parent_sha": "dfd66c652030f2923f346ad49b4a5cb73cabad67", "file_path": "common/lib/xmodule/xmodule/foldit_module.py", "project_url": "https://github.com/syjeon/new_edx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -87,7 +87,7 @@ class FolditModule(XModule):\n         from foldit.models import Score\n \n         leaders = [(e['username'], e['score']) for e in Score.get_tops_n(10)]\n-        leaders.sort(key=lambda x: x[1])\n+        leaders.sort(key=lambda x: -x[1])\n \n         return leaders\n \n", "before": "leaders . sort ( key = lambda x : x [ 1 ] )", "after": "leaders . sort ( key = lambda x : - x [ 1 ] )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"lambda\", 3, 26, 3, 40], [\"unary_operator\", \"N0\"], 3], [\"Insert\", \"N0\", [\"-:-\", \"T\"], 0], [\"Move\", \"N0\", [\"subscript\", 3, 36, 3, 40], 1]]"}
{"project": "osf.io", "commit_sha": "e8fed64c61465afa4c0cfa3755506a5d74e4839f", "parent_sha": "4ad109fe23248de07d0536feea4ace2602cf0034", "file_path": "website/notifications/views.py", "project_url": "https://github.com/kushG/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ def configure_subscription(auth):\n     event = subscription.get('event')\n     notification_type = subscription.get('notification_type')\n \n-    if not event or notification_type:\n+    if not event or not notification_type:\n         raise HTTPError(http.BAD_REQUEST, data=dict(\n             message_long=\"Must provide an event and notification type for subscription.\")\n         )\n", "before": "if not event or notification_type : raise HTTPError ( http . BAD_REQUEST , data = dict ( message_long = \"Must provide an event and notification type for subscription.\" ) )", "after": "if not event or not notification_type : raise HTTPError ( http . BAD_REQUEST , data = dict ( message_long = \"Must provide an event and notification type for subscription.\" ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 38], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:notification_type\", 3, 21, 3, 38], 1]]"}
{"project": "mezzanine", "commit_sha": "fafaa1c412d89272696f3d13d164d3a1e03fd097", "parent_sha": "df769b24f15c1ee7a6cc1d07470714429fdf4b8e", "file_path": "mezzanine/pages/admin.py", "project_url": "https://github.com/solancer/mezzanine", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -69,7 +69,7 @@ class PageAdmin(DisplayableAdmin):\n                 return HttpResponseRedirect(change_url)\n         extra_context = extra_context or {}\n         extra_context[\"hide_delete_link\"] = not page.can_delete(request)\n-        extra_context[\"hide_slug_field\"] = not page.overridden()\n+        extra_context[\"hide_slug_field\"] = page.overridden()\n         return super(PageAdmin, self).change_view(request, object_id,\n                                                   extra_context)\n \n", "before": "extra_context [ \"hide_slug_field\" ] = not page . overridden ( )", "after": "extra_context [ \"hide_slug_field\" ] = page . overridden ( )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"assignment\", 3, 9, 3, 65], [\"call\", 3, 48, 3, 65], 2], [\"Delete\", [\"not:not\", 3, 44, 3, 47]], [\"Delete\", [\"not_operator\", 3, 44, 3, 65]]]"}
{"project": "enigma2", "commit_sha": "f097792b3496b8b07e2b8510aefbb2feb7ae55f0", "parent_sha": "89f71c80a472d4b26241bb5a40f672fc432f2881", "file_path": "lib/python/Screens/About.py", "project_url": "https://github.com/factorybuild/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -188,7 +188,7 @@ class Devices(Screen):\n \t\tf = open('/proc/mounts', 'r')\n \t\tfor line in f.readlines():\n \t\t\tself.parts = line.strip().split()\n-\t\t\tif not self.parts[0] and (self.parts[0].startswith('192') or self.parts[0].startswith('//192')):\n+\t\t\tif self.parts[0] and (self.parts[0].startswith('192') or self.parts[0].startswith('//192')):\n \t\t\t\tself.Console.ePopen(\"df -mh \" + self.parts[1] + \" | grep -v '^Filesystem'\", self.Stage1Complete)\n \t\t\telse:\n \t\t\t\tself[\"mounts\"].setText(_('none'))\n", "before": "if not self . parts [ 0 ] and ( self . parts [ 0 ] . startswith ( '192' ) or self . parts [ 0 ] . startswith ( '//192' ) ) : self . Console . ePopen ( \"df -mh \" + self . parts [ 1 ] + \" | grep -v '^Filesystem'\" , self . Stage1Complete ) else : self [ \"mounts\" ] . setText ( _ ( 'none' ) )", "after": "if self . parts [ 0 ] and ( self . parts [ 0 ] . startswith ( '192' ) or self . parts [ 0 ] . startswith ( '//192' ) ) : self . Console . ePopen ( \"df -mh \" + self . parts [ 1 ] + \" | grep -v '^Filesystem'\" , self . Stage1Complete ) else : self [ \"mounts\" ] . setText ( _ ( 'none' ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 4, 6, 38], [\"boolean_operator\", 3, 11, 3, 99], 1], [\"Delete\", [\"not:not\", 3, 7, 3, 10]], [\"Delete\", [\"not_operator\", 3, 7, 3, 99]]]"}
{"project": "scikit-bio", "commit_sha": "166f0bb852a6316aca3f1956edb4dec53cd94578", "parent_sha": "3afb094d8397358d47733bc3dd5ac91cb2793c46", "file_path": "skbio/sequence/_iupac_sequence.py", "project_url": "https://github.com/iskandr/scikit-bio", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -544,7 +544,7 @@ class IUPACSequence(with_metaclass(ABCMeta, Sequence)):\n \n         Returns\n-        ------\n+        -------\n         regex\n             Pre-compiled regular expression object (as from ``re.compile``)\n             that matches all non-degenerate versions of this sequence, and\n", "before": "- - - - - - regex", "after": "- - - - - - - regex", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"unary_operator\", 2, 14, 3, 14], [\"-:-\", \"T\"], 0], [\"Move\", [\"unary_operator\", 2, 14, 3, 14], [\"unary_operator\", 2, 14, 3, 14], 1]]"}
{"project": "st2", "commit_sha": "12c0a3e952756c17713b713ccc993ef621c89a09", "parent_sha": "09cad0681647fa88fc1f614c3f09e2321d2a4caa", "file_path": "st2reactor/st2reactor/container/utils.py", "project_url": "https://github.com/ojosdegris/st2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ def _validate_trigger_type(trigger_type):\n \n \n def _create_trigger(trigger_type):\n-    if hasattr(trigger_type, 'parameters_schema') and trigger_type['parameters_schema']:\n+    if hasattr(trigger_type, 'parameters_schema') and not trigger_type['parameters_schema']:\n         trigger_db = TriggerService.get_trigger_db(trigger_type)\n         if trigger_db is None:\n             trigger_db = TriggerService.create_trigger_db(trigger_type)\n", "before": "if hasattr ( trigger_type , 'parameters_schema' ) and trigger_type [ 'parameters_schema' ] : trigger_db = TriggerService . get_trigger_db ( trigger_type ) if trigger_db is None : trigger_db = TriggerService . create_trigger_db ( trigger_type )", "after": "if hasattr ( trigger_type , 'parameters_schema' ) and not trigger_type [ 'parameters_schema' ] : trigger_db = TriggerService . get_trigger_db ( trigger_type ) if trigger_db is None : trigger_db = TriggerService . create_trigger_db ( trigger_type )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 8, 3, 88], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"subscript\", 3, 55, 3, 88], 1]]"}
{"project": "TXPipe", "commit_sha": "909f6235a1ad66f897a2e4ae3d8c62a8ba395462", "parent_sha": "3c137e858cb38d0455013f7cedc2e7665ec7b6d6", "file_path": "txpipe/input_cats.py", "project_url": "https://github.com/LSSTDESC/TXPipe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -574,7 +574,7 @@ def make_mock_photometry(n_visit, bands, data):\n         mag_obs = 25 - 2.5*np.log10(n_obs/factor/t_b/n_visit)\n \n         # converting error on n_obs to error on mag\n-        mag_err = -2.5*np.log10(np.e)*(n_obs_err/n_obs)\n+        mag_err = 2.5*np.log10(np.e)*(n_obs_err/n_obs)\n \n         output[f'true_snr_{band}'] = true_snr\n         output[f'snr_{band}'] = obs_snr\n", "before": "mag_err = - 2.5 * np . log10 ( np . e ) * ( n_obs_err / n_obs )", "after": "mag_err = 2.5 * np . log10 ( np . e ) * ( n_obs_err / n_obs )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"binary_operator\", 3, 19, 3, 38], [\"float:2.5\", 3, 20, 3, 23], 0], [\"Delete\", [\"-:-\", 3, 19, 3, 20]], [\"Delete\", [\"unary_operator\", 3, 19, 3, 23]]]"}
{"project": "Chaos", "commit_sha": "6792b31841671809a96e4e8d47c6fd0b19e1600e", "parent_sha": "1911a60c24b4d1d1bbc71b5df327495db789a7dd", "file_path": "github_api/prs.py", "project_url": "https://github.com/Smittyvb/Chaos", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -247,7 +247,7 @@ def merge_random(api, urn, message):\n     open_prs = get_open_prs(api, urn)\n     pr_selected = False\n     pr = {}\n-    while pr_selected:\n+    while not pr_selected:\n         pr = random.choice(open_prs)\n         pr_selected = get_is_mergeable(api, urn, pr['number'])\n     merge_pr_message_only(api, urn, pr, message)\n", "before": "while pr_selected : pr = random . choice ( open_prs ) pr_selected = get_is_mergeable ( api , urn , pr [ 'number' ] )", "after": "while not pr_selected : pr = random . choice ( open_prs ) pr_selected = get_is_mergeable ( api , urn , pr [ 'number' ] )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"while_statement\", 3, 5, 5, 63], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:pr_selected\", 3, 11, 3, 22], 1]]"}
{"project": "tflearn", "commit_sha": "5af44f35186b11b51984800affe9fe371f8d340b", "parent_sha": "d7964075437663c4984e240522aa708831e6edca", "file_path": "tflearn/layers/core.py", "project_url": "https://github.com/Genius38/tflearn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -179,7 +179,7 @@ def fully_connected(incoming, n_units, activation='linear', bias=True,\n \n         inference = tf.matmul(inference, W)\n         if b: inference = tf.nn.bias_add(inference, b)\n-        if not activation:\n+        if activation:\n             if isinstance(activation, str):\n                 inference = activations.get(activation)(inference)\n", "before": "if not activation : if isinstance ( activation , str ) : inference = activations . get ( activation ) ( inference )", "after": "if activation : if isinstance ( activation , str ) : inference = activations . get ( activation ) ( inference )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 9, 5, 67], [\"identifier:activation\", 3, 16, 3, 26], 1], [\"Delete\", [\"not:not\", 3, 12, 3, 15]], [\"Delete\", [\"not_operator\", 3, 12, 3, 26]]]"}
{"project": "zeus", "commit_sha": "e876b633bc62a3f05e3734872c39f1abad1e9901", "parent_sha": "55fde2da499d066849ef612f9110a0c331479b4d", "file_path": "zeus/model_features.py", "project_url": "https://github.com/itminedu/zeus", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -276,7 +276,7 @@ class PollFeatures(FeaturesMixin):\n \n     @poll_feature()\n     def _feature_forum_closed(self):\n-        return not self.election.feature_closed\n+        return self.election.feature_closed\n \n     @poll_feature()\n     def _feature_forum_visible(self):\n", "before": "return not self . election . feature_closed", "after": "return self . election . feature_closed", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"return_statement\", 3, 9, 3, 48], [\"attribute\", 3, 20, 3, 48], 1], [\"Delete\", [\"not:not\", 3, 16, 3, 19]], [\"Delete\", [\"not_operator\", 3, 16, 3, 48]]]"}
{"project": "Miro", "commit_sha": "a913999f0ffccdbc5790e5621a9e97ea3299394c", "parent_sha": "d3d3639981204fd4430f5f3dd77d5173589e63f4", "file_path": "tv/portable/download_utils.py", "project_url": "https://github.com/cool-RR/Miro", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -101,7 +101,7 @@ def parseURL(url, split_path=False):\n     path = path.replace('|', ':') \n     # Windows drive names are often specified as \"C|\\foo\\bar\"\n \n-    if path == '' or path.startswith('/'):\n+    if path == '' or not path.startswith('/'):\n         path = '/' + path\n     elif re.match(r'/[a-zA-Z]:', path):\n         # Fix \"/C:/foo\" paths\n", "before": "if path == '' or path . startswith ( '/' ) : path = '/' + path elif re . match ( r'/[a-zA-Z]:' , path ) : ", "after": "if path == '' or not path . startswith ( '/' ) : path = '/' + path elif re . match ( r'/[a-zA-Z]:' , path ) : ", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 8, 3, 42], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 22, 3, 42], 1]]"}
{"project": "connector-telephony", "commit_sha": "afa2462a4e0c2647945f0ffe79d7264ad54940a2", "parent_sha": "b51f5b3476e842c470d707ff5bc4aa7e09bd3310", "file_path": "asterisk_click2dial/asterisk_click2dial.py", "project_url": "https://github.com/OCA/connector-telephony", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -251,7 +251,7 @@ class asterisk_server(osv.osv):\n                 sock.send('CallerId: '+str(user.callerid)+'\\r\\n')\n                 sock.send('Exten: '+str(ast_number)+'\\r\\n')\n                 sock.send('Context: '+str(ast_server.context)+'\\r\\n')\n-                if not ast_server.alert_info and user.asterisk_chan_type == 'SIP':\n+                if ast_server.alert_info and user.asterisk_chan_type == 'SIP':\n                     sock.send('Variable: SIPAddHeader=Alert-Info: '+str(ast_server.alert_info)+'\\r\\n')\n                 sock.send('Priority: '+str(ast_server.extension_priority)+'\\r\\n\\r\\n')\n                 sock.send('Action: Logoff\\r\\n\\r\\n')\n", "before": "if not ast_server . alert_info and user . asterisk_chan_type == 'SIP' : sock . send ( 'Variable: SIPAddHeader=Alert-Info: ' + str ( ast_server . alert_info ) + '\\r\\n' )", "after": "if ast_server . alert_info and user . asterisk_chan_type == 'SIP' : sock . send ( 'Variable: SIPAddHeader=Alert-Info: ' + str ( ast_server . alert_info ) + '\\r\\n' )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 17, 4, 103], [\"boolean_operator\", 3, 24, 3, 82], 1], [\"Delete\", [\"not:not\", 3, 20, 3, 23]], [\"Delete\", [\"not_operator\", 3, 20, 3, 82]]]"}
{"project": "binderhub", "commit_sha": "a97aec73de98f9454d64fa5bbc7c3ad48bfd9fc7", "parent_sha": "caada72eedc70aa51edc91675518b4ed4f976496", "file_path": "helm-chart/build.py", "project_url": "https://github.com/nikolayvoronchikhin/binderhub", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -49,7 +49,7 @@ def build_images(prefix, images, commit_range=None, push=False):\n     for image in images:\n         image_path = os.path.join(BASEPATH, 'images', image)\n         if commit_range:\n-            if path_changed(IMAGE_FILES, commit_range):\n+            if not path_changed(IMAGE_FILES, commit_range):\n                 print(\"Skipping {}, not touched in {}\".format(image, commit_range))\n                 continue\n         tag = last_git_modified(IMAGE_FILES)\n", "before": "if path_changed ( IMAGE_FILES , commit_range ) : print ( \"Skipping {}, not touched in {}\" . format ( image , commit_range ) ) continue", "after": "if not path_changed ( IMAGE_FILES , commit_range ) : print ( \"Skipping {}, not touched in {}\" . format ( image , commit_range ) ) continue", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 5, 25], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 16, 3, 55], 1]]"}
{"project": "sentry", "commit_sha": "d177353e22ce7617cbd1957edc2859f39a5b84f9", "parent_sha": "606e9c619e3aca7c66f47519449c6c50d57a6158", "file_path": "src/sentry/search/solr/client.py", "project_url": "https://github.com/butorov/sentry", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -128,7 +128,7 @@ class SolrClient(object):\n         elif not isinstance(log_body, str):\n             log_body = repr(body)\n \n-        if any(key.lower() == 'content-type' for key in headers.iterkeys()):\n+        if not any(key.lower() == 'content-type' for key in headers.iterkeys()):\n             headers['Content-Type'] = 'application/xml; charset=UTF-8'\n \n         resp = self.http.urlopen(\n", "before": "if any ( key . lower ( ) == 'content-type' for key in headers . iterkeys ( ) ) : headers [ 'Content-Type' ] = 'application/xml; charset=UTF-8'", "after": "if not any ( key . lower ( ) == 'content-type' for key in headers . iterkeys ( ) ) : headers [ 'Content-Type' ] = 'application/xml; charset=UTF-8'", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 4, 71], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 12, 3, 76], 1]]"}
{"project": "sentry", "commit_sha": "e7d939313980d967676c9e2a236b98c4a8a8259f", "parent_sha": "f628672025cc06b8314f37c08f5cd7a2a2b23f90", "file_path": "src/sentry/plugins/bases/notify.py", "project_url": "https://github.com/butorov/sentry", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -74,7 +74,7 @@ class NotificationPlugin(Plugin):\n             # notification -- we also need to check rate limits, since\n             # ``should_notify`` skips this step if the plugin supports digests.\n             if not features.has('projects:digests:deliver', project):\n-                if not self.__is_rate_limited(event.group, event):\n+                if self.__is_rate_limited(event.group, event):\n                     logger = logging.getLogger('sentry.plugins.{0}'.format(self.get_conf_key()))\n                     logger.info('Notification for project %r dropped due to rate limiting', project)\n                     return\n", "before": "if not self . __is_rate_limited ( event . group , event ) : logger = logging . getLogger ( 'sentry.plugins.{0}' . format ( self . get_conf_key ( ) ) ) logger . info ( 'Notification for project %r dropped due to rate limiting' , project ) return", "after": "if self . __is_rate_limited ( event . group , event ) : logger = logging . getLogger ( 'sentry.plugins.{0}' . format ( self . get_conf_key ( ) ) ) logger . info ( 'Notification for project %r dropped due to rate limiting' , project ) return", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Move\", [\"if_statement\", 3, 17, 6, 27], [\"call\", 3, 24, 3, 66], 1], [\"Delete\", [\"not:not\", 3, 20, 3, 23]], [\"Delete\", [\"not_operator\", 3, 20, 3, 66]]]"}
{"project": "raven", "commit_sha": "18cbdb41094bd0f43a56d831261b5ce898b5da98", "parent_sha": "f162517c3f62a6e414b31ad970d27760efa5ccf8", "file_path": "framework/SupervisedLearning.py", "project_url": "https://github.com/idaholab/raven", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1993,7 +1993,7 @@ class SciKitLearn(superVisedLearning):\n     if self.intrinsicMultiTarget:\n       self.ROM[0].fit(featureVals,targetVals)\n     else:\n-      if all([len(np.unique(targetVals[:,index]))>1 for index in range(len(self.ROM))]):\n+      if not all([len(np.unique(targetVals[:,index]))>1 for index in range(len(self.ROM))]):\n         self.myNumber = [np.unique(targetVals[:,index])[0] for index in range(len(self.ROM)) ]\n         self.evaluate = self._readdressEvaluateConstResponse\n       else:\n", "before": "if all ( [ len ( np . unique ( targetVals [ : , index ] ) ) > 1 for index in range ( len ( self . ROM ) ) ] ) : self . myNumber = [ np . unique ( targetVals [ : , index ] ) [ 0 ] for index in range ( len ( self . ROM ) ) ] self . evaluate = self . _readdressEvaluateConstResponse else : ", "after": "if not all ( [ len ( np . unique ( targetVals [ : , index ] ) ) > 1 for index in range ( len ( self . ROM ) ) ] ) : self . myNumber = [ np . unique ( targetVals [ : , index ] ) [ 0 ] for index in range ( len ( self . ROM ) ) ] self . evaluate = self . _readdressEvaluateConstResponse else : ", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 7, 6, 12], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 10, 3, 88], 1]]"}
{"project": "NodeGraphQt", "commit_sha": "6a80ec870414eedeb3f8714b6ca7ddf3a7e5599b", "parent_sha": "7d51ed44cbc1d571ad582521d33dbb5e22a8e547", "file_path": "NodeGraphQt/widgets/viewer.py", "project_url": "https://github.com/jchanvfx/NodeGraphQt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -564,7 +564,7 @@ class NodeViewer(QtWidgets.QGraphicsView):\n         if not file_path:\n             return\n         ext = ext_map[file_dlg[1]]\n-        if ext and file_path.endswith(ext):\n+        if ext and not file_path.endswith(ext):\n             file_path += ext\n         return file_path\n \n", "before": "if ext and file_path . endswith ( ext ) : file_path += ext", "after": "if ext and not file_path . endswith ( ext ) : file_path += ext", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"boolean_operator\", 3, 12, 3, 43], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 20, 3, 43], 1]]"}
{"project": "Rummage", "commit_sha": "c862a3f7da483ab75c38dbe8dfd76a27b2226e18", "parent_sha": "354c2f30f91e687239830b2c4f239fae66d24550", "file_path": "main.py", "project_url": "https://github.com/facelessuser/Rummage", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -217,7 +217,7 @@ class RummageFrame(gui.RummageFrame, DebugFrameExtender):\n         self.m_logic_choice.SetStringSelection(Settings.get_search_setting(\"size_compare_string\", \"greater than\"))\n         self.m_size_text.SetValue(Settings.get_search_setting(\"size_limit_string\", \"1000\"))\n \n-        self.m_case_checkbox.SetValue(Settings.get_search_setting(\"ignore_case_toggle\", False))\n+        self.m_case_checkbox.SetValue(not Settings.get_search_setting(\"ignore_case_toggle\", False))\n         self.m_dotmatch_checkbox.SetValue(Settings.get_search_setting(\"dotall_toggle\", False))\n         self.m_utf8_checkbox.SetValue(Settings.get_search_setting(\"utf8_toggle\", False))\n \n", "before": "self . m_case_checkbox . SetValue ( Settings . get_search_setting ( \"ignore_case_toggle\" , False ) )", "after": "self . m_case_checkbox . SetValue ( not Settings . get_search_setting ( \"ignore_case_toggle\" , False ) )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 38, 3, 96], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"call\", 3, 39, 3, 95], 1]]"}
{"project": "arlpy", "commit_sha": "231db9df7d83dff4af4f4010c6d4bdbaa2b23e2d", "parent_sha": "ba63e3dda7c5c4ca0a66050e6aadd9cc489f3747", "file_path": "arlpy/plot.py", "project_url": "https://github.com/org-arl/arlpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -125,7 +125,7 @@ def enable_javascript(b):\n     does not affect functionality.\n     \"\"\"\n     global _disable_js\n-    _disable_js = b\n+    _disable_js = not b\n \n def hold(enable):\n     \"\"\"Combine multiple plots into one.\n", "before": "_disable_js = b", "after": "_disable_js = not b", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"assignment\", 3, 5, 3, 20], [\"not_operator\", \"N0\"], 2], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"identifier:b\", 3, 19, 3, 20], 1]]"}
{"project": "cloud-init", "commit_sha": "173863dae49759602691b3658fc27f36c8056218", "parent_sha": "67f2b194290be82e15d503c43685e09487701d44", "file_path": "cloudinit/sources/__init__.py", "project_url": "https://github.com/rightscale/cloud-init", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -166,7 +166,7 @@ class DataSource(object):\n         defhost = \"localhost\"\n         domain = defdomain\n \n-        if self.metadata or 'local-hostname' not in self.metadata:\n+        if not self.metadata or 'local-hostname' not in self.metadata:\n             # this is somewhat questionable really.\n             # the cloud datasource was asked for a hostname\n             # and didn't have one. raising error might be more appropriate\n", "before": "if self . metadata or 'local-hostname' not in self . metadata : ", "after": "if not self . metadata or 'local-hostname' not in self . metadata : ", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 3, 67], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"boolean_operator\", 3, 12, 3, 66], 1]]"}
{"project": "bookshub", "commit_sha": "7f1320bc5145d260a3ade8369bc3bf864a4d454a", "parent_sha": "9072802f0ce71cb1c3621400b7fccd862d1ad6f2", "file_path": "bookshub/users/serializers.py", "project_url": "https://github.com/eluciano11/bookshub", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -337,7 +337,7 @@ class StripeSubscriptionSerializer(serializers.Serializer):\n \n         plans = [\"student\", \"monthly_5\", \"monthly_10\", \"monthly_20\"]\n \n-        if plan in plans:\n+        if not plan in plans:\n             msg = 'Invalid plan name.'\n             raise serializers.ValidationError(msg)\n \n", "before": "if plan in plans : msg = 'Invalid plan name.' raise serializers . ValidationError ( msg )", "after": "if not plan in plans : msg = 'Invalid plan name.' raise serializers . ValidationError ( msg )", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 9, 5, 51], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"comparison_operator\", 3, 12, 3, 25], 1]]"}
{"project": "click", "commit_sha": "336e5e08acf98a4033e5aa4c6fcef118d4f469ec", "parent_sha": "7d0ded687b54e4bad76ddf04315255bdd2c153c9", "file_path": "click/decorators.py", "project_url": "https://github.com/makerdao/click", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -224,7 +224,7 @@ def version_option(version=None, *param_decls, **attrs):\n         message = attrs.pop('message', '%(prog)s, version %(version)s')\n \n         def callback(ctx, param, value):\n-            if value or ctx.resilient_parsing:\n+            if not value or ctx.resilient_parsing:\n                 return\n             prog = prog_name\n             if prog is None:\n", "before": "if value or ctx . resilient_parsing : return", "after": "if not value or ctx . resilient_parsing : return", "sstub_pattern": "CHANGE_UNARY_OPERATOR", "edit_script": "[[\"Insert\", [\"if_statement\", 3, 13, 4, 23], [\"not_operator\", \"N0\"], 1], [\"Insert\", \"N0\", [\"not:not\", \"T\"], 0], [\"Move\", \"N0\", [\"boolean_operator\", 3, 16, 3, 46], 1]]"}
{"project": "librosa", "commit_sha": "b434b1cd64b1ff45afdaa6dac59b7acf9d52f100", "parent_sha": "a50f1e06ce94061efbb7a2ac383e309e942a4f1f", "file_path": "librosa/tf_agc.py", "project_url": "https://github.com/carlthome/librosa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -116,7 +116,7 @@ def tf_agc(frame_iterator, sample_rate=22050, **kwargs):\n \n             #% Remove any zeros in E (shouldn't be any, but who knows?)\n             #E(E(:)<=0) = min(E(E(:)>0));\n-            E[E<=0] = min(E[E>0.0])\n+            E[E<=0.0] = min(E[E>0.0])\n \n             #% invert back to waveform\n             #y = istft(D./E);\n", "before": "E [ E <= 0 ] = min ( E [ E > 0.0 ] )", "after": "E [ E <= 0.0 ] = min ( E [ E > 0.0 ] )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 15, 3, 19], [\"float:0.0\", \"T\"], 2], [\"Delete\", [\"integer:0\", 3, 18, 3, 19]]]"}
{"project": "ZSSR", "commit_sha": "cac32529f88ced1d2468eac35b801f9d0e9b4b91", "parent_sha": "d9f9fb3c718136ebcfb9d60fd70829a56c9d9d5c", "file_path": "imresize.py", "project_url": "https://github.com/assafshocher/ZSSR", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -97,7 +97,7 @@ def contributions(in_length, out_length, scale, kernel, kernel_width, antialiasi\n     # So if we measure distance from the left border, middle of pixel 1 is at distance d=0.5, border between 1 and 2 is\n     # at d=1, and so on (d = p - 0.5).  we calculate (d_new = d_old / sf) which means:\n     # (p_new-0.5 = (p_old-0.5) / sf)     ->          p_new = p_old/sf + 0.5 * (1-1/sf)\n-    match_coordinates = 1.0 * out_coordinates / scale + 0.5 * (1 - 1 / scale)\n+    match_coordinates = 1.0 * out_coordinates / scale + 0.5 * (1 - 1.0 / scale)\n \n     # This is the left boundary to start multiplying the filter from, it depends on the size of the filter\n     left_boundary = np.floor(match_coordinates - kernel_width / 2)\n", "before": "match_coordinates = 1.0 * out_coordinates / scale + 0.5 * ( 1 - 1 / scale )", "after": "match_coordinates = 1.0 * out_coordinates / scale + 0.5 * ( 1 - 1.0 / scale )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 68, 3, 77], [\"float:1.0\", \"T\"], 0], [\"Delete\", [\"integer:1\", 3, 68, 3, 69]]]"}
{"project": "pyfpdf", "commit_sha": "0a0fe33c3512d028136b33f7a8dc4e38848191d8", "parent_sha": "dc23064d14378fcf218102a5d64d703c1a2408d6", "file_path": "fpdf/fpdf.py", "project_url": "https://github.com/scott1028/pyfpdf", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -82,7 +82,7 @@ class FPDF(object):\n         elif(unit=='cm'):\n             self.k=72/2.54\n         elif(unit=='in'):\n-            self.k=72\n+            self.k=72.\n         else:\n             self.error('Incorrect unit: '+unit)\n         # Page format\n", "before": "self . k = 72", "after": "self . k = 72.", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 13, 3, 22], [\"float:72.\", \"T\"], 2], [\"Delete\", [\"integer:72\", 3, 20, 3, 22]]]"}
{"project": "mldata", "commit_sha": "8fdb9802d302d5ca770233f8664e98678b30cbb3", "parent_sha": "224a4726b5e3a0f92627fe745fd32e7928c58910", "file_path": "utils/performance_measure.py", "project_url": "https://github.com/open-machine-learning/mldata", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ class ClassificationErrorRate:\n \n         prediction = 0\n         correct_class = 0\n-        errors = 0\n+        errors = 0.0\n         index = 0\n         size = len(matrix1)\n \n", "before": "errors = 0", "after": "errors = 0.0", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 19], [\"float:0.0\", \"T\"], 2], [\"Delete\", [\"integer:0\", 3, 18, 3, 19]]]"}
{"project": "Algorithms", "commit_sha": "2d1c7e799aae1d285e4b8fffd834bf13daf47740", "parent_sha": "f85ef4b76d7e1ccedb6ca536f26a216bad0ad487", "file_path": "heaps/minheap.py", "project_url": "https://github.com/c-rap/Algorithms", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -23,7 +23,7 @@ class minheap(object):\n \n     def is_leaf(self, i):\n         \"\"\" returns True if i is a leaf node \"\"\"\n-        return i > int(math.ceil( (len(self.heap)- 2) / 2))\n+        return i > int(math.ceil((len(self.heap) - 2) / 2.0))\n \n     def parent(self, i):\n         if i == 0:\n", "before": "return i > int ( math . ceil ( ( len ( self . heap ) - 2 ) / 2 ) )", "after": "return i > int ( math . ceil ( ( len ( self . heap ) - 2 ) / 2.0 ) )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 35, 3, 58], [\"float:2.0\", \"T\"], 2], [\"Delete\", [\"integer:2\", 3, 57, 3, 58]]]"}
{"project": "kafe", "commit_sha": "66dd13aeb8dc47de6c55857b354d8eb214828988", "parent_sha": "e45e221859b1ecc409dc4df5fec245596f22d94f", "file_path": "kafe/plot.py", "project_url": "https://github.com/dsavoiu/kafe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -787,7 +787,7 @@ class Plot(object):\n             # shade confidence band\n             if show_band:\n                 cband = self.axes.fill_between(fxdata, lower_cb, upper_cb,\n-                                              alpha='0.1',\n+                                              alpha=0.1,\n                                               color=_fdata_kw['color'])\n \n             # plot fit function\n", "before": "cband = self . axes . fill_between ( fxdata , lower_cb , upper_cb , alpha = '0.1' , color = _fdata_kw [ 'color' ] )", "after": "cband = self . axes . fill_between ( fxdata , lower_cb , upper_cb , alpha = 0.1 , color = _fdata_kw [ 'color' ] )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 47, 3, 58], [\"float:0.1\", \"T\"], 2], [\"Delete\", [\"string:'0.1'\", 3, 53, 3, 58]]]"}
{"project": "spiderfoot", "commit_sha": "6162e9d3c348a481c909a6e93544995e855d2f33", "parent_sha": "c6a37f697908ae5bd3394ce68373618ca1b870ba", "file_path": "modules/sfp_pwned.py", "project_url": "https://github.com/smicallef/spiderfoot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -69,7 +69,7 @@ class sfp_pwned(SpiderFootPlugin):\n         res = self.sf.fetchUrl(url, timeout=self.opts['_fetchtimeout'], \r\n             useragent=\"SpiderFoot\", headers=hdrs)\r\n \r\n-        if res['code'] == \"404\":\r\n+        if res['code'] == 404:\r\n             return None\r\n \r\n         try:\r\n", "before": "if res [ 'code' ] == \"404\" : return None", "after": "if res [ 'code' ] == 404 : return None", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 32], [\"integer:404\", \"T\"], 2], [\"Delete\", [\"string:\\\"404\\\"\", 3, 27, 3, 32]]]"}
{"project": "fabric8-analytics-common", "commit_sha": "5c1c4ae0ed227eba61e136c6a00b2f667a720407", "parent_sha": "d769dc0de3f050dd18a96c1af28bd927a6ec1c3b", "file_path": "integration-tests/features/steps/common.py", "project_url": "https://github.com/fabric8-analytics/fabric8-analytics-common", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -141,7 +141,7 @@ def finish_analysis_for_component(context, ecosystem, component, version):\n \n @when(\"I wait for stack analysis to finish\")\n @when(\"I wait for stack analysis version {version} to finish\")\n-def wait_for_stack_analysis_completion(context, version=1):\n+def wait_for_stack_analysis_completion(context, version=\"1\"):\n", "before": "def wait_for_stack_analysis_completion ( context , version = 1 ) : ", "after": "def wait_for_stack_analysis_completion ( context , version = \"1\" ) : ", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 49, 3, 58], [\"string:\\\"1\\\"\", \"T\"], 2], [\"Delete\", [\"integer:1\", 3, 57, 3, 58]]]"}
{"project": "scipy", "commit_sha": "ca86f7921bd186cd7ca069a80f1973b713fbd05c", "parent_sha": "b7a7918e27d45384b87ffa7cceaf78657ab25def", "file_path": "scipy/signal/filter_design.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1951,7 +1951,7 @@ def _zpkbilinear(z, p, k, fs):\n \n     degree = _relative_degree(z, p)\n \n-    fs2 = 2*fs\n+    fs2 = 2.0*fs\n \n     # Bilinear transform the poles and zeros\n     z_z = (fs2 + z) / (fs2 - z)\n", "before": "fs2 = 2 * fs", "after": "fs2 = 2.0 * fs", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 11, 3, 15], [\"float:2.0\", \"T\"], 0], [\"Delete\", [\"integer:2\", 3, 11, 3, 12]]]"}
{"project": "scipy", "commit_sha": "f5d58e125fb83bed1ec47f65633dd9b25556512f", "parent_sha": "ab9eff32ef594a59621404ffe18045fd6bd49e1f", "file_path": "scipy/stats/morestats.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2698,7 +2698,7 @@ def _circfuncs_common(samples, high, low):\n     if samples.size == 0:\n         return np.nan, np.nan\n \n-    ang = (samples - low)*2*pi / (high - low)\n+    ang = (samples - low)*2.*pi / (high - low)\n     return samples, ang\n \n \n", "before": "ang = ( samples - low ) * 2 * pi / ( high - low )", "after": "ang = ( samples - low ) * 2. * pi / ( high - low )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 11, 3, 28], [\"float:2.\", \"T\"], 2], [\"Delete\", [\"integer:2\", 3, 27, 3, 28]]]"}
{"project": "sunpy", "commit_sha": "0f034c74ce2a19e386ea727f13952e4a83ec89d4", "parent_sha": "100343d3b0c9f218a7abf8cccaf9fe1d731059a1", "file_path": "sunpy/wcs/wcs.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -230,7 +230,7 @@ def convert_hpc_hg(rsun, dsun, units_x, units_y, b0, l0, x, y):\n \n def get_center(size, scale, crpix, crval):\n     \"\"\"Returns the center of the map.\"\"\"\n-    return scale * (size - 1) / 2 + crval - (crpix - 1) * scale\n+    return scale * (size - 1) / 2. + crval - (crpix - 1) * scale\n \n def proj_tan(x, y, force=False):\n", "before": "return scale * ( size - 1 ) / 2 + crval - ( crpix - 1 ) * scale", "after": "return scale * ( size - 1 ) / 2. + crval - ( crpix - 1 ) * scale", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 12, 3, 34], [\"float:2.\", \"T\"], 2], [\"Delete\", [\"integer:2\", 3, 33, 3, 34]]]"}
{"project": "PySAT", "commit_sha": "58f7d99aaca143e9074c69ece65019f458e32c3c", "parent_sha": "a91258a4dc099476b64f9a52b7b3f4817602e7fc", "file_path": "pysat/spectral/baseline_code/watrous.py", "project_url": "https://github.com/ryanbanderson/PySAT", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ def watrous(z, scale, kernel=numpy.array([1., 4., 6., 4., 1.]) / 16.):\n         w[s[0] + n:, 0] = temp\n         for i in range(0, scale - 1):\n             # print i\n-            k1 = numpy.zeros((sk - 1) * 2. ** i + 1, dtype=numpy.float)\n+            k1 = numpy.zeros((sk - 1) * 2 ** i + 1, dtype=numpy.float)\n             i1 = numpy.array((numpy.arange(sk)) * 2. ** i, dtype=numpy.int)\n             k1[i1] = kernel\n \n", "before": "k1 = numpy . zeros ( ( sk - 1 ) * 2. ** i + 1 , dtype = numpy . float )", "after": "k1 = numpy . zeros ( ( sk - 1 ) * 2 ** i + 1 , dtype = numpy . float )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 41, 3, 48], [\"integer:2\", \"T\"], 0], [\"Delete\", [\"float:2.\", 3, 41, 3, 43]]]"}
{"project": "eng-ops", "commit_sha": "f34d9c17ee37172eaa3c0cdc1c497bafb2e12bf8", "parent_sha": "c260f7ac89bc380715c884e2f86ac3ccad869b29", "file_path": "api/slack_bot.py", "project_url": "https://github.com/FundersClub/eng-ops", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -203,7 +203,7 @@ def _create_label_dict(issues):\n \n def send_weekly_report():\n     end_time = datetime.now()\n-    if end_time.weekday() != '0':\n+    if end_time.weekday() != 0:\n         return\n \n     start_date = end_time - timedelta(days=28)\n", "before": "if end_time . weekday ( ) != '0' : return", "after": "if end_time . weekday ( ) != 0 : return", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 8, 3, 33], [\"integer:0\", \"T\"], 2], [\"Delete\", [\"string:'0'\", 3, 30, 3, 33]]]"}
{"project": "enigma2", "commit_sha": "0da36e8bf31392c23409887c653e3c8a091a777c", "parent_sha": "0e0c8fd964cb3dba3544a1a324443166e65ea122", "file_path": "lib/python/Components/Renderer/Pig.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ class Pig(Renderer):\n \t\tattribs = self.skinAttributes[:]\n \t\tfor (attrib, value) in self.skinAttributes:\n \t\t\tif attrib == \"hidePip\":\n-\t\t\t\tself.hidePip = value == 1\n+\t\t\t\tself.hidePip = value == \"1\"\n \t\t\t\tattribs.remove((attrib,value))\n \t\t\t\tbreak\n \t\tself.skinAttributes = attribs\n", "before": "self . hidePip = value == 1", "after": "self . hidePip = value == \"1\"", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 20, 3, 30], [\"string:\\\"1\\\"\", \"T\"], 2], [\"Delete\", [\"integer:1\", 3, 29, 3, 30]]]"}
{"project": "blaze", "commit_sha": "e1a6572adc5e6ba32d914510bfadb2dad3894d32", "parent_sha": "131d02ae9b4ac78c4f56f52f498082a44e9a8491", "file_path": "blaze/compute/tests/test_numpy_compute.py", "project_url": "https://github.com/TomAugspurger/blaze", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -367,7 +367,7 @@ def test_broadcast_compute_against_numbers_and_arrays():\n \n def test_map():\n     pytest.importorskip('numba')\n-    a = np.arange(10)\n+    a = np.arange(10.0)\n     f = lambda x: np.sin(x) + 1.03 * np.cos(x) ** 2\n     x = symbol('x', discover(a))\n     expr = x.map(f, 'float64')\n", "before": "a = np . arange ( 10 )", "after": "a = np . arange ( 10.0 )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 18, 3, 22], [\"float:10.0\", \"T\"], 1], [\"Delete\", [\"integer:10\", 3, 19, 3, 21]]]"}
{"project": "sanic", "commit_sha": "3a2eeb97095330a95be790c048d982a25d6ec70a", "parent_sha": "3a1ef6bef2b61e6c47c16d4db21dce9d54886067", "file_path": "tests/test_requests.py", "project_url": "https://github.com/haoguangli/sanic", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -56,7 +56,7 @@ def test_query_string():\n     async def handler(request):\n         return text('OK')\n \n-    request, response = sanic_endpoint_test(app, params=[(\"test1\", 1), (\"test2\", \"false\"), (\"test2\", \"true\")])\n+    request, response = sanic_endpoint_test(app, params=[(\"test1\", \"1\"), (\"test2\", \"false\"), (\"test2\", \"true\")])\n \n     assert request.args.get('test1') == '1'\n     assert request.args.get('test2') == 'false'\n", "before": "request , response = sanic_endpoint_test ( app , params = [ ( \"test1\" , 1 ) , ( \"test2\" , \"false\" ) , ( \"test2\" , \"true\" ) ] )", "after": "request , response = sanic_endpoint_test ( app , params = [ ( \"test1\" , \"1\" ) , ( \"test2\" , \"false\" ) , ( \"test2\" , \"true\" ) ] )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 58, 3, 70], [\"string:\\\"1\\\"\", \"T\"], 3], [\"Delete\", [\"integer:1\", 3, 68, 3, 69]]]"}
{"project": "conda-smithy", "commit_sha": "f253a6234ac7a917d170b5e0ddda68cd15f2db99", "parent_sha": "f130c794360a2bce63b6d818416a51a92d673098", "file_path": "tests/test_variant_algebra.py", "project_url": "https://github.com/isuruf/conda-smithy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -121,7 +121,7 @@ def test_ordering_downgrade():\n     )\n \n     res = variant_add(start, mig_compiler)\n-    assert res[\"jpeg\"] == [2.0]\n+    assert res[\"jpeg\"] == ['2.0']\n     print(res)\n \n \n", "before": "assert res [ \"jpeg\" ] == [ 2.0 ]", "after": "assert res [ \"jpeg\" ] == [ '2.0' ]", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"list\", 3, 27, 3, 32], [\"string:'2.0'\", \"T\"], 1], [\"Delete\", [\"float:2.0\", 3, 28, 3, 31]]]"}
{"project": "cms", "commit_sha": "d14f5565634ac7d985ed55802a68a1597d22e42b", "parent_sha": "7f97b525c3f06f71c938af6a458c6cb9743f7d88", "file_path": "cms/grading/tasktypes/OutputOnly.py", "project_url": "https://github.com/igortereshchenko/cms", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -96,7 +96,7 @@ class OutputOnly(TaskType):\n         # present we report that the outcome is 0.\n         if \"output_%03d.txt\" % test_number not in self.job.files:\n             evaluation['success'] = True\n-            evaluation['outcome'] = 0.0\n+            evaluation['outcome'] = \"0.0\"\n             evaluation['text'] = \"File not submitted.\"\n             return True\n \n", "before": "evaluation [ 'outcome' ] = 0.0", "after": "evaluation [ 'outcome' ] = \"0.0\"", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 13, 3, 40], [\"string:\\\"0.0\\\"\", \"T\"], 2], [\"Delete\", [\"float:0.0\", 3, 37, 3, 40]]]"}
{"project": "gensim", "commit_sha": "6ac8089e15f33b6025445166346e069a0a1a5a15", "parent_sha": "aafe36410ef06996364dc8ec84ad4a8e51ca7857", "file_path": "gensim/topic_coherence/direct_confirmation_measure.py", "project_url": "https://github.com/springhser/gensim", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ def log_conditional_probability(segmented_topics, per_topic_postings, num_docs):\n             if  w_star_docs:\n                 m_lc_i = np.log(((len(co_docs) / float(num_docs)) + EPSILON) / (len(w_star_docs) / float(num_docs)))\n             else:\n-                m_lc_i = 0\n+                m_lc_i = 0.0\n             m_lc.append(m_lc_i)\n \n     return m_lc\n", "before": "m_lc_i = 0", "after": "m_lc_i = 0.0", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 17, 3, 27], [\"float:0.0\", \"T\"], 2], [\"Delete\", [\"integer:0\", 3, 26, 3, 27]]]"}
{"project": "flake8", "commit_sha": "573a217d6c7b9978c152a8116e4edea7ce086a4d", "parent_sha": "f40cf8e03019ad85c49f2354cf5ea7611a4ade27", "file_path": "flake8/tests/test_engine.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/flake8", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,7 +34,7 @@ class TestEngine(unittest.TestCase):\n         m = mock.Mock()\n         with mock.patch('flake8.engine.StyleGuide') as StyleGuide:\n             with mock.patch('flake8.engine.get_parser') as get_parser:\n-                StyleGuide.return_value.options.jobs = 42\n+                StyleGuide.return_value.options.jobs = '42'\n                 get_parser.return_value = (m, [])\n                 engine.get_style_guide(foo='bar')\n                 get_parser.assert_called_once_with()\n", "before": "StyleGuide . return_value . options . jobs = 42", "after": "StyleGuide . return_value . options . jobs = '42'", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 17, 3, 58], [\"string:'42'\", \"T\"], 2], [\"Delete\", [\"integer:42\", 3, 56, 3, 58]]]"}
{"project": "facepy", "commit_sha": "38b3cbf97c9f959cb0cca5d7900fbcf2fa0a9196", "parent_sha": "967a43d1f8ec20586da9823493816c835e9cc653", "file_path": "tests/test_graph_api.py", "project_url": "https://github.com/pozytywnie/facepy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -256,7 +256,7 @@ def test_delete():\n \n     mock_request.return_value.content = 'true'\n \n-    graph.delete(1)\n+    graph.delete('1')\n \n     mock_request.assert_called_with('DELETE', 'https://graph.facebook.com/1',\n         allow_redirects = True,\n", "before": "graph . delete ( 1 )", "after": "graph . delete ( '1' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 17, 3, 20], [\"string:'1'\", \"T\"], 1], [\"Delete\", [\"integer:1\", 3, 18, 3, 19]]]"}
{"project": "reviewboard", "commit_sha": "c2b6598e58cd4a677f095d7c6c37692a0b1fbce8", "parent_sha": "e002b3fc4ef4f4870f72ddd56d3dd82c3b987d5a", "file_path": "setup.py", "project_url": "https://github.com/iosphere/reviewboard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ class BuildMedia(Command):\n \n     def run(self):\n         env = os.environ.copy()\n-        env['FORCE_BUILD_MEDIA'] = 1\n+        env['FORCE_BUILD_MEDIA'] = \"1\"\n         retcode = subprocess.call(['./reviewboard/manage.py', 'collectstatic',\n                                    '--noinput'],\n                                   env=env)\n", "before": "env [ 'FORCE_BUILD_MEDIA' ] = 1", "after": "env [ 'FORCE_BUILD_MEDIA' ] = \"1\"", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 37], [\"string:\\\"1\\\"\", \"T\"], 2], [\"Delete\", [\"integer:1\", 3, 36, 3, 37]]]"}
{"project": "amoniak", "commit_sha": "429bca202e12382b9d0510d2ca1d4b84b91dff40", "parent_sha": "4b0b481bba2ed4c5fad07c7f084028da6db7f857", "file_path": "amoniak/tasks.py", "project_url": "https://github.com/gisce/amoniak", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -143,7 +143,7 @@ def enqueue_contracts():\n             # A 404 is possible if we delete empowering contracts in insight engine\n             # but keep etag in our database.\n             # In this case we must force the re-upload as new contract\n-            if e.code != '404':\n+            if e.code != 404:\n                 raise e\n             is_new_contract = True\n             last_updated = '0'\n", "before": "if e . code != '404' : raise e", "after": "if e . code != 404 : raise e", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 31], [\"integer:404\", \"T\"], 2], [\"Delete\", [\"string:'404'\", 3, 26, 3, 31]]]"}
{"project": "face_recognition", "commit_sha": "3f060164d82cea8efbe43569d8c67ea5e87b9b00", "parent_sha": "8322e7c00b7da9cbde8216c01d42330f03c5dcb9", "file_path": "face_recognition/cli.py", "project_url": "https://github.com/airobotsme/face_recognition", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,7 +34,7 @@ def test_image(image_to_check, known_names, known_face_encodings):\n \n     # Scale down image if it's giant so things run a little faster\n     if unknown_image.shape[1] > 1600:\n-        scale_factor = 1600 / unknown_image.shape[1]\n+        scale_factor = 1600.0 / unknown_image.shape[1]\n         with warnings.catch_warnings():\n             warnings.simplefilter(\"ignore\")\n             unknown_image = scipy.misc.imresize(unknown_image, scale_factor)\n", "before": "scale_factor = 1600 / unknown_image . shape [ 1 ]", "after": "scale_factor = 1600.0 / unknown_image . shape [ 1 ]", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 24, 3, 53], [\"float:1600.0\", \"T\"], 0], [\"Delete\", [\"integer:1600\", 3, 24, 3, 28]]]"}
{"project": "osf.io", "commit_sha": "1f386d626f81716e892fc3b1409f8f0515db9409", "parent_sha": "01b94d901d8cffcd1827fcbd25b3431bb2de4ef8", "file_path": "website/project/views/node.py", "project_url": "https://github.com/Vhoakab84/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1070,7 +1070,7 @@ def search_node(**kwargs):\n     auth = kwargs['auth']\n     node = Node.load(request.json.get('nodeId'))\n     include_public = request.json.get('includePublic')\n-    size = float(request.json.get('size', 5).strip())\n+    size = float(request.json.get('size', '5').strip())\n     page = request.json.get('page', 0)\n     query = request.json.get('query', '').strip()\n \n", "before": "size = float ( request . json . get ( 'size' , 5 ) . strip ( ) )", "after": "size = float ( request . json . get ( 'size' , '5' ) . strip ( ) )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 34, 3, 45], [\"string:'5'\", \"T\"], 3], [\"Delete\", [\"integer:5\", 3, 43, 3, 44]]]"}
{"project": "genetargeter", "commit_sha": "2a50543c66fe29cb9da47cfbb789a67245b0e08b", "parent_sha": "c959ae3ff2e28c12df4f4f70853622e66cfaf7eb", "file_path": "py/GeneTargeterMethods.py", "project_url": "https://github.com/pablocarderam/genetargeter", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -384,7 +384,7 @@ end indexes, counted with the last bp in the gene's stop codon as index 0.\n-def chooseGRNA(geneGB, gene, searchRange=[-500,125], PAM=\"NGG\", side3Prime=True, minGCContent=0.3, minOnTargetScore=25, minOffTargetScore=75, maxOffTargetHitScore=35, onTargetMethod=\"azimuth\", offTargetMethod=\"hsu\", gLength=20, maxDistanceBetweenGRNAS=50, enzyme=\"Cas9\", gBlockDefault=True, maxTier1GBlockSize=\"250\", gBlockOverlapSize=40, codingGene=True, filterCutSites=[cut_FseI,cut_AsiSI,cut_IPpoI,cut_ISceI,cut_AflII]): # could've been useful at some point: http://grna.ctegd.uga.edu/ http://www.broadinstitute.org/rnai/public/software/sgrna-scoring-help http://crispr.mit.edu/about\n+def chooseGRNA(geneGB, gene, searchRange=[-500,125], PAM=\"NGG\", side3Prime=True, minGCContent=0.3, minOnTargetScore=25, minOffTargetScore=75, maxOffTargetHitScore=35, onTargetMethod=\"azimuth\", offTargetMethod=\"hsu\", gLength=20, maxDistanceBetweenGRNAS=50, enzyme=\"Cas9\", gBlockDefault=True, maxTier1GBlockSize=250, gBlockOverlapSize=40, codingGene=True, filterCutSites=[cut_FseI,cut_AsiSI,cut_IPpoI,cut_ISceI,cut_AflII]): # could've been useful at some point: http://grna.ctegd.uga.edu/ http://www.broadinstitute.org/rnai/public/software/sgrna-scoring-help http://crispr.mit.edu/about\n     log = \"Choosing gRNA with PAM sequence \" + PAM + \" for use with enzyme \" + enzyme; # init log\n     gRNATable = []; # will store information on each gRNA evaluated. Format: Label, Status, Enzyme, Position, Strand, GC_content, On-target_score, On-target_method, Aggregated_off-target_score, Max_pairwise_off-target_score, Off-target_method, >9_consecutive_A/T, 4-Homopolymer, Triple_T, Sequence, Recoded_sequence, Recoded_sequence_pairwise_off-target_score\n     geneList = geneGB.findAnnsLabel(gene.label); # stores gene annotation\n", "before": "def chooseGRNA ( geneGB , gene , searchRange = [ - 500 , 125 ] , PAM = \"NGG\" , side3Prime = True , minGCContent = 0.3 , minOnTargetScore = 25 , minOffTargetScore = 75 , maxOffTargetHitScore = 35 , onTargetMethod = \"azimuth\" , offTargetMethod = \"hsu\" , gLength = 20 , maxDistanceBetweenGRNAS = 50 , enzyme = \"Cas9\" , gBlockDefault = True , maxTier1GBlockSize = \"250\" , gBlockOverlapSize = 40 , codingGene = True , filterCutSites = [ cut_FseI , cut_AsiSI , cut_IPpoI , cut_ISceI , cut_AflII ] ) : log = \"Choosing gRNA with PAM sequence \" + PAM + \" for use with enzyme \" + enzyme gRNATable = [ ] geneList = geneGB . findAnnsLabel ( gene . label )", "after": "def chooseGRNA ( geneGB , gene , searchRange = [ - 500 , 125 ] , PAM = \"NGG\" , side3Prime = True , minGCContent = 0.3 , minOnTargetScore = 25 , minOffTargetScore = 75 , maxOffTargetHitScore = 35 , onTargetMethod = \"azimuth\" , offTargetMethod = \"hsu\" , gLength = 20 , maxDistanceBetweenGRNAS = 50 , enzyme = \"Cas9\" , gBlockDefault = True , maxTier1GBlockSize = 250 , gBlockOverlapSize = 40 , codingGene = True , filterCutSites = [ cut_FseI , cut_AsiSI , cut_IPpoI , cut_ISceI , cut_AflII ] ) : log = \"Choosing gRNA with PAM sequence \" + PAM + \" for use with enzyme \" + enzyme gRNATable = [ ] geneList = geneGB . findAnnsLabel ( gene . label )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"default_parameter\", 0, 292, 0, 316], [\"integer:250\", \"T\"], 2], [\"Delete\", [\"string:\\\"250\\\"\", 0, 311, 0, 316]]]"}
{"project": "pyfolio", "commit_sha": "7f585f9cca08ade116c851804c6da592af8da064", "parent_sha": "4b8d924e507ec8ccb1f6df9ac5eef2eba9f81eac", "file_path": "pyfolio/timeseries.py", "project_url": "https://github.com/jaCod3r/pyfolio", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -204,7 +204,7 @@ def annual_return(returns, style='compound'):\n         return np.nan\n \n     if style == 'calendar':\n-        num_years = len(returns) / 252\n+        num_years = len(returns) / 252.0\n         df_cum_rets = cum_returns(returns, starting_value=100)\n         start_value = df_cum_rets[0]\n         end_value = df_cum_rets[-1]\n", "before": "num_years = len ( returns ) / 252", "after": "num_years = len ( returns ) / 252.0", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 21, 3, 39], [\"float:252.0\", \"T\"], 2], [\"Delete\", [\"integer:252\", 3, 36, 3, 39]]]"}
{"project": "blackbird-flume-jolokia", "commit_sha": "dc77eb79bf18a8709bc400f41ce35b2a1f21eaf3", "parent_sha": "84f3462821b1f111b8aeb82dfcd238fe73bb810e", "file_path": "flume_jolokia.py", "project_url": "https://github.com/Vagrants/blackbird-flume-jolokia", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -78,7 +78,7 @@ class ConcreteJob(blackbird.plugins.base.JobBase):\n             )\n             result_dict = json.load(result)\n \n-            if result_dict['status'] == '200':\n+            if result_dict['status'] == 200:\n                 return result_dict\n             else:\n                 self.logger.warn('Invalid status code returned from Jolokia.')\n", "before": "if result_dict [ 'status' ] == '200' : return result_dict else : self . logger . warn ( 'Invalid status code returned from Jolokia.' )", "after": "if result_dict [ 'status' ] == 200 : return result_dict else : self . logger . warn ( 'Invalid status code returned from Jolokia.' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 46], [\"integer:200\", \"T\"], 2], [\"Delete\", [\"string:'200'\", 3, 41, 3, 46]]]"}
{"project": "casperfpga", "commit_sha": "328622ded94577b67d62360db4f94ff4dd547675", "parent_sha": "b6e6b648aae86a7791021ea48c3788751df0b475", "file_path": "src/skarab_fpga.py", "project_url": "https://github.com/casper-astro/casperfpga", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -88,7 +88,7 @@ class SkarabFpga(CasperFpga):\n \n         # can only read 32-bits (4 bytes) at a time\n         # work out how many reads we require\n-        num_reads = int(math.ceil(size/4))\n+        num_reads = int(math.ceil(size/4.0))\n \n         # string to store binary data read\n         data = ''\n", "before": "num_reads = int ( math . ceil ( size / 4 ) )", "after": "num_reads = int ( math . ceil ( size / 4.0 ) )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 35, 3, 41], [\"float:4.0\", \"T\"], 2], [\"Delete\", [\"integer:4\", 3, 40, 3, 41]]]"}
{"project": "adb_shell", "commit_sha": "0088f732a9f2fbf7007b6bc19eaae4f827700345", "parent_sha": "34a7157515b55a6b139cc46f3b8fbf47f8f42ecc", "file_path": "tests/test_tcp_handle.py", "project_url": "https://github.com/JeffLIrion/adb_shell", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ class TestTcpHandle(unittest.TestCase):\n         \"\"\"Create a ``TcpHandle`` and connect to a TCP service.\n \n         \"\"\"\n-        self.handle = TcpHandle('host', '5555')\n+        self.handle = TcpHandle('host', 5555)\n         with patchers.PATCH_CREATE_CONNECTION:\n             self.handle.connect()\n \n", "before": "self . handle = TcpHandle ( 'host' , '5555' )", "after": "self . handle = TcpHandle ( 'host' , 5555 )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 32, 3, 48], [\"integer:5555\", \"T\"], 3], [\"Delete\", [\"string:'5555'\", 3, 41, 3, 47]]]"}
{"project": "Diamond", "commit_sha": "b52e38af5cfcd0cb58e1279b94c9375633b82dc9", "parent_sha": "bc9bfd296ce507d5fc6e4aa7117e8679d7caaaac", "file_path": "src/diamond/server.py", "project_url": "https://github.com/TAKEALOT/Diamond", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -255,7 +255,7 @@ class Server(object):\n                           c.__class__.__name__)\n             return\n \n-        if c.config['enabled'] != 'True':\n+        if c.config['enabled'] != True:\n             self.log.warn(\"Skipped loading disabled Collector: %s\",\n                           c.__class__.__name__)\n             return\n", "before": "if c . config [ 'enabled' ] != 'True' : self . log . warn ( \"Skipped loading disabled Collector: %s\" , c . __class__ . __name__ ) return", "after": "if c . config [ 'enabled' ] != True : self . log . warn ( \"Skipped loading disabled Collector: %s\" , c . __class__ . __name__ ) return", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 12, 3, 41], [\"true:True\", \"T\"], 2], [\"Delete\", [\"string:'True'\", 3, 35, 3, 41]]]"}
{"project": "backend", "commit_sha": "290b5b44912db1375faad7e4bcf5f491ea517c66", "parent_sha": "fa748dccebe9b21e18bfbd4031690dd10d2a183b", "file_path": "test/test_lottery.py", "project_url": "https://github.com/Sakuten/backend", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -218,7 +218,7 @@ def test_apply_time_invalid(client):\n     \"\"\"attempt to apply to lottery out of range\n         target_url: /lotteries/<id> [POST]\n     \"\"\"\n-    idx = '1'\n+    idx = 1\n     token = login(client, test_user['secret_id'],\n                   test_user['g-recaptcha-response'])['token']\n \n", "before": "idx = '1'", "after": "idx = 1", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 5, 3, 14], [\"integer:1\", \"T\"], 2], [\"Delete\", [\"string:'1'\", 3, 11, 3, 14]]]"}
{"project": "intelmq", "commit_sha": "1c27bda6d41eaa88f36acde92f7aeadeadea7d2a", "parent_sha": "c0e967bdadeb36c5af3dc7a8b423a069a8107a6e", "file_path": "intelmq/bots/parsers/dragonresearchgroup/parser_ssh.py", "project_url": "https://github.com/kbrajneesh/intelmq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ def process(self):\n             event.add(\"classification.type\", \"brute-force\")\n             event.add(\"protocol.application\", \"ssh\")\n             event.add(\"protocol.transport\", \"tcp\")\n-            event.add(\"destination.port\", \"22\")\n+            event.add(\"destination.port\", 22)\n             event.add(\"raw\", row, sanitize=True)\n \n             self.send_message(event)\n", "before": "event . add ( \"destination.port\" , \"22\" )", "after": "event . add ( \"destination.port\" , 22 )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 22, 3, 48], [\"integer:22\", \"T\"], 3], [\"Delete\", [\"string:\\\"22\\\"\", 3, 43, 3, 47]]]"}
{"project": "dataverse-client-python", "commit_sha": "8f41ca1063960465f33fb265162b0d75d27a1dc9", "parent_sha": "5f20ad7aba11b0ce0bee6e791a91266e7ce4d76a", "file_path": "dataverse/dataset.py", "project_url": "https://github.com/CenterForOpenScience/dataverse-client-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -250,7 +250,7 @@ class Dataset(object):\n \n         resp = requests.post(\n             self.edit_uri,\n-            headers={'In-Progress': 'false', 'Content-Length': 0},\n+            headers={'In-Progress': 'false', 'Content-Length': '0'},\n             auth=self.connection.auth,\n         )\n \n", "before": "resp = requests . post ( self . edit_uri , headers = { 'In-Progress' : 'false' , 'Content-Length' : 0 } , auth = self . connection . auth , )", "after": "resp = requests . post ( self . edit_uri , headers = { 'In-Progress' : 'false' , 'Content-Length' : '0' } , auth = self . connection . auth , )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"pair\", 3, 46, 3, 65], [\"string:'0'\", \"T\"], 2], [\"Delete\", [\"integer:0\", 3, 64, 3, 65]]]"}
{"project": "dataverse-client-python", "commit_sha": "5e754fd5bd85fa76c48bb8c167ef20d1bf90e1c2", "parent_sha": "0730a657d44782fe8f06d72e9a14e975ac8caa50", "file_path": "dataverse/dataset.py", "project_url": "https://github.com/CenterForOpenScience/dataverse-client-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -250,7 +250,7 @@ class Dataset(object):\n \n         resp = requests.post(\n             self.edit_uri,\n-            headers={'In-Progress': 'false', 'Content-Length': 0},\n+            headers={'In-Progress': 'false', 'Content-Length': '0'},\n             auth=self.connection.auth,\n         )\n \n", "before": "resp = requests . post ( self . edit_uri , headers = { 'In-Progress' : 'false' , 'Content-Length' : 0 } , auth = self . connection . auth , )", "after": "resp = requests . post ( self . edit_uri , headers = { 'In-Progress' : 'false' , 'Content-Length' : '0' } , auth = self . connection . auth , )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"pair\", 3, 46, 3, 65], [\"string:'0'\", \"T\"], 2], [\"Delete\", [\"integer:0\", 3, 64, 3, 65]]]"}
{"project": "xml2html", "commit_sha": "12ae895ae3f838e519a74b39df0ff668c9f2d841", "parent_sha": "2a48df17151261387061d1063973f618abd73cbb", "file_path": "xml2html.py", "project_url": "https://github.com/brianvanderburg2/xml2html", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -65,7 +65,7 @@ def handle_error(error, abort=True):\n \n def getbool(b):\n     \"\"\" Test if a value it true or not \"\"\"\n-    return b.lower() in ('yes', 'true', 'on', 1)\n+    return b.lower() in ('yes', 'true', 'on', '1')\n \n # Setup lxml\n ################################################################################\n", "before": "return b . lower ( ) in ( 'yes' , 'true' , 'on' , 1 )", "after": "return b . lower ( ) in ( 'yes' , 'true' , 'on' , '1' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 25, 3, 49], [\"string:'1'\", \"T\"], 7], [\"Delete\", [\"integer:1\", 3, 47, 3, 48]]]"}
{"project": "new_edx", "commit_sha": "7d0bb7b3fe120a6a7e75cba4f40c4bc46d938aeb", "parent_sha": "682ac3455b21387befc718212747cba1bb2fd342", "file_path": "common/lib/xmodule/xmodule/combined_open_ended_module.py", "project_url": "https://github.com/syjeon/new_edx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -173,7 +173,7 @@ class CombinedOpenEndedModule(XModule):\n         loaded_task_state = json.loads(current_task_state)\n         if loaded_task_state['state'] == self.INITIAL:\n             loaded_task_state['state'] = self.ASSESSING\n-            loaded_task_state['created'] = \"True\"\n+            loaded_task_state['created'] = True\n             loaded_task_state['history'].append({'answer': last_response})\n             current_task_state = json.dumps(loaded_task_state)\n         return current_task_state\n", "before": "loaded_task_state [ 'created' ] = \"True\"", "after": "loaded_task_state [ 'created' ] = True", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 13, 3, 50], [\"true:True\", \"T\"], 2], [\"Delete\", [\"string:\\\"True\\\"\", 3, 44, 3, 50]]]"}
{"project": "enigma2", "commit_sha": "572f8f328e90ac71c4f9f2cef18f82f67cb4b0ae", "parent_sha": "2fe66b70e874b048a283d0bd3807cd793a581206", "file_path": "lib/python/Screens/SoftwareUpdate.py", "project_url": "https://github.com/factorybuild/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -248,7 +248,7 @@ class UpdatePlugin(Screen):\n \t\t\t\ttry:\n \t\t\t\t\tconfig.softwareupdate.updateisunstable.setValue(urlopen(\"http://enigma2.world-of-satellite.com/feeds/\" + getImageVersionString() + \"/status\").read())\n \t\t\t\texcept:\n-\t\t\t\t\tconfig.softwareupdate.updateisunstable.setValue(1)\n+\t\t\t\t\tconfig.softwareupdate.updateisunstable.setValue('1')\n \t\t\t\tsocket.setdefaulttimeout(currentTimeoutDefault)\n \t\t\t\tself.total_packages = None\n \t\t\t\tif config.softwareupdate.updateisunstable.getValue() == '1' and config.softwareupdate.updatebeta.getValue():\n", "before": "config . softwareupdate . updateisunstable . setValue ( 1 )", "after": "config . softwareupdate . updateisunstable . setValue ( '1' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 53, 3, 56], [\"string:'1'\", \"T\"], 1], [\"Delete\", [\"integer:1\", 3, 54, 3, 55]]]"}
{"project": "cython", "commit_sha": "a600dc53d86ca8438fa174b7189a76b119b8c7fa", "parent_sha": "acbda9dd636c71184686d47e5671a4862f4e5495", "file_path": "Cython/Compiler/Nodes.py", "project_url": "https://github.com/jdemeyer/cython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -3441,7 +3441,7 @@ class RaiseStatNode(StatNode):\n             self.exc_type.generate_evaluation_code(code)\n             type_code = self.exc_type.py_result()\n         else:\n-            type_code = 0\n+            type_code = \"0\"\n         if self.exc_value:\n             self.exc_value.generate_evaluation_code(code)\n             value_code = self.exc_value.py_result()\n", "before": "else : type_code = 0", "after": "else : type_code = \"0\"", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 2, 9, 3, 26], [\"string:\\\"0\\\"\", \"T\"], 4], [\"Delete\", [\"integer:0\", 3, 25, 3, 26]]]"}
{"project": "trac", "commit_sha": "193676c82e59139fb5db7319db21c89825d47185", "parent_sha": "11deadce4661b591850fc17071045501901cba6d", "file_path": "trac/wiki/web_ui.py", "project_url": "https://github.com/bartsolutions/trac", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -522,7 +522,7 @@ class WikiModule(Component):\n             page.readonly = 'readonly' in req.args\n \n         author = get_reporter_id(req, 'author')\n-        defaults = {'editrows': 20}\n+        defaults = {'editrows': '20'}\n         prefs = dict((key, req.session.get('wiki_%s' % key, defaults.get(key)))\n                      for key in ('editrows', 'sidebyside'))\n \n", "before": "defaults = { 'editrows' : 20 }", "after": "defaults = { 'editrows' : '20' }", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"pair\", 3, 21, 3, 35], [\"string:'20'\", \"T\"], 2], [\"Delete\", [\"integer:20\", 3, 33, 3, 35]]]"}
{"project": "trac", "commit_sha": "e27135018633bccd9e888487b38f5a1083d7ecc8", "parent_sha": "ed94b2ad83ebfb25a41898b0e5680cde658c3054", "file_path": "trac/wiki/web_ui.py", "project_url": "https://github.com/bartsolutions/trac", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -515,7 +515,7 @@ class WikiModule(Component):\n             page.readonly = 'readonly' in req.args\n \n         author = get_reporter_id(req, 'author')\n-        defaults = {'editrows': 20}\n+        defaults = {'editrows': '20'}\n         prefs = dict((key, req.session.get('wiki_%s' % key, defaults.get(key)))\n                      for key in ('editrows', 'sidebyside'))\n \n", "before": "defaults = { 'editrows' : 20 }", "after": "defaults = { 'editrows' : '20' }", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"pair\", 3, 21, 3, 35], [\"string:'20'\", \"T\"], 2], [\"Delete\", [\"integer:20\", 3, 33, 3, 35]]]"}
{"project": "pymacaron", "commit_sha": "868543b913de8c701fb19d65912737ad77b2a2d7", "parent_sha": "4ab90959adef004bec958d082af034d2f9f7ce74", "file_path": "test/test_crash_handler.py", "project_url": "https://github.com/pymacaron/pymacaron", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -145,7 +145,7 @@ class Tests(KlueTestCase):\n \n         self.assertEqual(body['response']['user_message'], '')\n         self.assertEqual(body['response']['type'], 'Response')\n-        self.assertEqual(body['response']['status'], 500)\n+        self.assertEqual(body['response']['status'], '500')\n         self.assertEqual(body['response']['is_error'], 1)\n         self.assertEqual(body['response']['error_code'], 'UNHANDLED_SERVER_ERROR')\n         self.assertEqual(body['response']['error_description'], 'Raising an internal exception')\n", "before": "self . assertEqual ( body [ 'response' ] [ 'status' ] , 500 )", "after": "self . assertEqual ( body [ 'response' ] [ 'status' ] , '500' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 25, 3, 58], [\"string:'500'\", \"T\"], 3], [\"Delete\", [\"integer:500\", 3, 54, 3, 57]]]"}
{"project": "python-instagram-ext", "commit_sha": "f81532a496c35e9a268ca1c986eb254969bce010", "parent_sha": "07c4d5619275b9463fde75832b19dd87d7c09358", "file_path": "instagram/bind.py", "project_url": "https://github.com/Seraphicer/python-instagram-ext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -100,7 +100,7 @@ def bind_method(**config):\n \n             # Handle OAuthRateLimitExceeded from Instagram's Nginx which uses different format to documented api responses\n             if not content_obj.has_key('meta'):\n-                if content_obj.get('code') == '420':\n+                if content_obj.get('code') == 420:\n                     error_message = content_obj.get('error_message') or \"Your client is making too many request per second\"\n                     raise InstagramAPIError(420, \"Rate limited\", error_message)\n                 raise InstagramAPIError(content_obj.has_key('code'), content_obj.has_key('error_type'), content_obj.has_key('error_message'))\n", "before": "if content_obj . get ( 'code' ) == '420' : error_message = content_obj . get ( 'error_message' ) or \"Your client is making too many request per second\" raise InstagramAPIError ( 420 , \"Rate limited\" , error_message )", "after": "if content_obj . get ( 'code' ) == 420 : error_message = content_obj . get ( 'error_message' ) or \"Your client is making too many request per second\" raise InstagramAPIError ( 420 , \"Rate limited\" , error_message )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 20, 3, 52], [\"integer:420\", \"T\"], 2], [\"Delete\", [\"string:'420'\", 3, 47, 3, 52]]]"}
{"project": "will", "commit_sha": "df1d55d40fe331f39fc908cac48870a421072c94", "parent_sha": "999cc11506709e5d80feeb2e4ad5ce01b00c39e8", "file_path": "plugins/axiacore.py", "project_url": "https://github.com/Axiacore/will", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -28,7 +28,7 @@ class AxiaCorePlugin(WillPlugin):\n             )\n             self.say(url, message=message)\n         except JIRAError as exc:\n-            if exc.status_code == '404':\n+            if exc.status_code == 404:\n                 self.say('Issue {0} does not exist'.format(key), color='red')\n             else:\n                 raise\n", "before": "except JIRAError as exc : if exc . status_code == '404' : self . say ( 'Issue {0} does not exist' . format ( key ) , color = 'red' )", "after": "except JIRAError as exc : if exc . status_code == 404 : self . say ( 'Issue {0} does not exist' . format ( key ) , color = 'red' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 16, 3, 40], [\"integer:404\", \"T\"], 2], [\"Delete\", [\"string:'404'\", 3, 35, 3, 40]]]"}
{"project": "os-capacity", "commit_sha": "b3b11f941ceb2767605c8386ba855279eb673d21", "parent_sha": "0cb3fafd0475d9cd06ce53595e41d89c5e04fed2", "file_path": "os_capacity/utils.py", "project_url": "https://github.com/JohnGarbutt/os-capacity", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -242,7 +242,7 @@ def group_usage(app, group_by=\"user\"):\n             if key_name:\n                 dimensions[name_key] = key_name\n             value_meta = {'usage_summary': usage}\n-            dimensions['version'] = 2.0\n+            dimensions['version'] = '2.0'\n \n             metrics_to_send.append(metrics.Metric(\n                 name=\"usage.%s.count\" % group_by,\n", "before": "dimensions [ 'version' ] = 2.0", "after": "dimensions [ 'version' ] = '2.0'", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 13, 3, 40], [\"string:'2.0'\", \"T\"], 2], [\"Delete\", [\"float:2.0\", 3, 37, 3, 40]]]"}
{"project": "erpnext", "commit_sha": "fa8159efa3efef6ac16120c7caa3441d9d196358", "parent_sha": "9964ad787002b4f9b0794280bc6294afa89b6fae", "file_path": "erpnext/regional/doctype/import_supplier_invoice/import_supplier_invoice.py", "project_url": "https://github.com/mudux/erpnext", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ class ImportSupplierInvoice(Document):\n \t\tself.publish(\"File Import\", _(\"Processing XML Files\"), 1, 3)\n \n \t\tpi_count = 0\n-\t\tmop_options = frappe.get_meta('Mode of Payment').fields['4'].options\n+\t\tmop_options = frappe.get_meta('Mode of Payment').fields[4].options\n \t\tmop_str = re.sub('\\n', ',', mop_options)\n \t\tmop_dict = dict(item.split(\"-\") for item in mop_str.split(\",\"))\n \n", "before": "mop_options = frappe . get_meta ( 'Mode of Payment' ) . fields [ '4' ] . options", "after": "mop_options = frappe . get_meta ( 'Mode of Payment' ) . fields [ 4 ] . options", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"subscript\", 3, 17, 3, 63], [\"integer:4\", \"T\"], 2], [\"Delete\", [\"string:'4'\", 3, 59, 3, 62]]]"}
{"project": "cloudkitty", "commit_sha": "32ace95de77e042bbec4b6f18784134114ed92bc", "parent_sha": "007a324def5ca10d8ba3ea9be9c4e7cb65ac112e", "file_path": "cloudkitty/rpc.py", "project_url": "https://github.com/knitmesh/cloudkitty", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ _RPC_TARGET = None\n def get_target():\n     global _RPC_TARGET\n     if _RPC_TARGET is None:\n-        _RPC_TARGET = messaging.Target(topic='cloudkitty', version=1.0)\n+        _RPC_TARGET = messaging.Target(topic='cloudkitty', version='1.0')\n     return _RPC_TARGET\n \n \n", "before": "_RPC_TARGET = messaging . Target ( topic = 'cloudkitty' , version = 1.0 )", "after": "_RPC_TARGET = messaging . Target ( topic = 'cloudkitty' , version = '1.0' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 60, 3, 71], [\"string:'1.0'\", \"T\"], 2], [\"Delete\", [\"float:1.0\", 3, 68, 3, 71]]]"}
{"project": "django", "commit_sha": "394b7f90d324eade4f4d8527e164800b3dbf8c8a", "parent_sha": "d0451e4cadf4277f117b9b581530c68d8dc43c6a", "file_path": "django/core/management/base.py", "project_url": "https://github.com/leon-song2000/django", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -244,7 +244,7 @@ class BaseCommand(object):\n         parser = CommandParser(self, prog=\"%s %s\" % (os.path.basename(prog_name), subcommand),\n             description=self.help or None)\n         parser.add_argument('--version', action='version', version=self.get_version())\n-        parser.add_argument('-v', '--verbosity', action='store', dest='verbosity', default='1',\n+        parser.add_argument('-v', '--verbosity', action='store', dest='verbosity', default=1,\n             type=int, choices=[0, 1, 2, 3],\n             help='Verbosity level; 0=minimal output, 1=normal output, 2=verbose output, 3=very verbose output')\n         parser.add_argument('--settings',\n", "before": "parser . add_argument ( '-v' , '--verbosity' , action = 'store' , dest = 'verbosity' , default = '1' , type = int , choices = [ 0 , 1 , 2 , 3 ] , help = 'Verbosity level; 0=minimal output, 1=normal output, 2=verbose output, 3=very verbose output' )", "after": "parser . add_argument ( '-v' , '--verbosity' , action = 'store' , dest = 'verbosity' , default = 1 , type = int , choices = [ 0 , 1 , 2 , 3 ] , help = 'Verbosity level; 0=minimal output, 1=normal output, 2=verbose output, 3=very verbose output' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 84, 3, 95], [\"integer:1\", \"T\"], 2], [\"Delete\", [\"string:'1'\", 3, 92, 3, 95]]]"}
{"project": "nova", "commit_sha": "470ccb85f2ecaff38973854e209f0fabdb117dc0", "parent_sha": "cf1854946838bf14607d05acd6f347702372b744", "file_path": "nova/tests/test_xensm.py", "project_url": "https://github.com/wgapl/nova", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ class XenSMTestCase(test.TestCase):\n         beconf = db.sm_backend_conf_get(ctxt, beconf['id'])\n         self.assertIsInstance(beconf['sr_uuid'], basestring)\n \n-    def _create_volume(self, size='0'):\n+    def _create_volume(self, size=0):\n         \"\"\"Create a volume object.\"\"\"\n         vol = {}\n         vol['size'] = size\n", "before": "def _create_volume ( self , size = '0' ) : \"\"\"Create a volume object.\"\"\" vol = { } vol [ 'size' ] = size", "after": "def _create_volume ( self , size = 0 ) : \"\"\"Create a volume object.\"\"\" vol = { } vol [ 'size' ] = size", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 30, 3, 38], [\"integer:0\", \"T\"], 2], [\"Delete\", [\"string:'0'\", 3, 35, 3, 38]]]"}
{"project": "mesh-announce", "commit_sha": "4fd2e3e6eb15c2a52b7401c88a105ff483934689", "parent_sha": "34f8f3cf1c8904eaa15c6ba93b09ad3495bf9b15", "file_path": "config.py", "project_url": "https://github.com/ffnord/mesh-announce", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,7 +33,7 @@ class DomainOptions():\n         self.hostname = parser.get(name, 'Hostname', fallback=socket.gethostname())\n         self.name = name\n         self.interfaces = list(map(str.strip, parser.get(name, 'Interfaces', fallback='').split(',')))\n-        self.is_gateway = parser.getboolean(name, 'VPN', fallback='True')\n+        self.is_gateway = parser.getboolean(name, 'VPN', fallback=True)\n         self.longitude = parser.getfloat(name, 'Longitude', fallback=None)\n         self.latitude = parser.getfloat(name, 'Latitude', fallback=None)\n         self.mcast_link = parser.get(name, 'MulticastLinkAddress', fallback='ff02::2:1001')\n", "before": "self . is_gateway = parser . getboolean ( name , 'VPN' , fallback = 'True' )", "after": "self . is_gateway = parser . getboolean ( name , 'VPN' , fallback = True )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 58, 3, 73], [\"true:True\", \"T\"], 2], [\"Delete\", [\"string:'True'\", 3, 67, 3, 73]]]"}
{"project": "charmhelpers", "commit_sha": "49559381bc9b2d5a717ddeb2d6b4cba3ddd7d72b", "parent_sha": "e77db615192680caba0820b096ee908fe7285032", "file_path": "tests/contrib/openstack/test_openstack_utils.py", "project_url": "https://github.com/whitmo/charmhelpers", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -622,7 +622,7 @@ class OpenStackHelpersTestCase(TestCase):\n \n     @patch.object(openstack, 'config')\n     def test_git_install_requested_none(self, config):\n-        config.return_value = 'None'\n+        config.return_value = None\n         result = openstack.git_install_requested()\n         self.assertEquals(result, False)\n \n", "before": "config . return_value = 'None'", "after": "config . return_value = None", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 37], [\"none:None\", \"T\"], 2], [\"Delete\", [\"string:'None'\", 3, 31, 3, 37]]]"}
{"project": "charmhelpers", "commit_sha": "5394ce902e62007ced267ff41640df321fd59ccd", "parent_sha": "c3b33729d7ab543d2b9113072d5d59654a4c6437", "file_path": "charmhelpers/contrib/ansible/__init__.py", "project_url": "https://github.com/whitmo/charmhelpers", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -104,7 +104,7 @@ def apply_playbook(playbook, tags=None):\n         allow_hyphens_in_keys=False)\n     # we want ansible's log output to be unbuffered\n     env = os.environ.copy()\n-    env['PYTHONUNBUFFERED'] = 1\n+    env['PYTHONUNBUFFERED'] = \"1\"\n     call = [\n         'ansible-playbook',\n         '-c',\n", "before": "env [ 'PYTHONUNBUFFERED' ] = 1", "after": "env [ 'PYTHONUNBUFFERED' ] = \"1\"", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 5, 3, 32], [\"string:\\\"1\\\"\", \"T\"], 2], [\"Delete\", [\"integer:1\", 3, 31, 3, 32]]]"}
{"project": "statsmodels", "commit_sha": "571c6f15ace7351424507c0d67b899951580c6a2", "parent_sha": "b65a0f053d5dca4c330b141fa38b75debe6702fe", "file_path": "statsmodels/regression/linear_model.py", "project_url": "https://github.com/jarrodmillman/statsmodels", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -439,7 +439,7 @@ class WLS(RegressionModel):\n         llf = -np.log(SSR) * nobs2      # concentrated likelihood\n         llf -= (1+np.log(np.pi/nobs2))*nobs2  # with constant\n         if np.all(self.weights != 1):    #FIXME: is this a robust-enough check?\n-            llf -= .5*np.log(np.multiply.reduce(1/self.weights)) # with weights\n+            llf -= .5*np.log(np.multiply.reduce(1./self.weights)) # with weights\n         return llf\n \n \n", "before": "llf -= .5 * np . log ( np . multiply . reduce ( 1 / self . weights ) )", "after": "llf -= .5 * np . log ( np . multiply . reduce ( 1. / self . weights ) )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 49, 3, 63], [\"float:1.\", \"T\"], 0], [\"Delete\", [\"integer:1\", 3, 49, 3, 50]]]"}
{"project": "sentry", "commit_sha": "1b00f29add08ed2f8d1a6189fa254ecdea231c98", "parent_sha": "51215cdf23e9926019cd9123d975ea95595b4226", "file_path": "src/sentry/web/frontend/groups.py", "project_url": "https://github.com/ornagetreesoft/sentry", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -49,7 +49,7 @@ def _get_group_list(request, project):\n         'project': project,\n     }\n \n-    status = request.GET.get('status', 0)\n+    status = request.GET.get('status', '0')\n     if status:\n         query_kwargs['status'] = int(status)\n \n", "before": "status = request . GET . get ( 'status' , 0 )", "after": "status = request . GET . get ( 'status' , '0' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 29, 3, 42], [\"string:'0'\", \"T\"], 3], [\"Delete\", [\"integer:0\", 3, 40, 3, 41]]]"}
{"project": "rd-addons", "commit_sha": "a53ce069c521f453cab6f24000626f97fb16c38e", "parent_sha": "32bd910917f61c18ead88b9ecfdfa37622389aaa", "file_path": "chricar_partner_parent_companies/partner_parent_companies.py", "project_url": "https://github.com/Khwarizmiat/rd-addons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -106,7 +106,7 @@ class res_partner(osv.osv) :\n         res = {}\n         for partner in self.browse(cr, uid, ids):\n             if context.get('share_owner_id'):\n-               res[partner.id] = self._get_share(cr, uid, context['share_owner_id'], partner.id, None, 0, 'True')\n+               res[partner.id] = self._get_share(cr, uid, context['share_owner_id'], partner.id, None, 0.0, 'True')\n             else:\n                res[partner.id] = 0\n         return res\n", "before": "res [ partner . id ] = self . _get_share ( cr , uid , context [ 'share_owner_id' ] , partner . id , None , 0 , 'True' )", "after": "res [ partner . id ] = self . _get_share ( cr , uid , context [ 'share_owner_id' ] , partner . id , None , 0.0 , 'True' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 49, 3, 114], [\"float:0.0\", \"T\"], 11], [\"Delete\", [\"integer:0\", 3, 104, 3, 105]]]"}
{"project": "freeipa", "commit_sha": "89993d9939e938d7e3305da59c3b61aa84792593", "parent_sha": "c2d2344268831aebb810c1ebef54e0bb456bfc0e", "file_path": "tests/test_ipalib/test_encoder.py", "project_url": "https://github.com/celestian/freeipa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -113,7 +113,7 @@ class test_Encoder(ClassChecker):\n         expected = [u'1', [u'1', u'2', u'3']]\n         assert_equal(o.decode(['1', ['1', '2', '3']]), expected)\n         # tuples\n-        expected = (_test_str_d, '1')\n+        expected = (_test_str_d, 1)\n         assert_equal(o.decode((_test_str_e, 1)), expected)\n         expected = (u'1', (u'1', u'2', u'3'))\n         assert_equal(o.decode(('1', ('1', '2', '3'))), expected)\n", "before": "expected = ( _test_str_d , '1' )", "after": "expected = ( _test_str_d , 1 )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"tuple\", 3, 20, 3, 38], [\"integer:1\", \"T\"], 3], [\"Delete\", [\"string:'1'\", 3, 34, 3, 37]]]"}
{"project": "integrate", "commit_sha": "3939c16e7ac2cdbbf00fa8bc9e8b98ada573c183", "parent_sha": "6be7a5aff81e059f133c97c1f33bfaa170a73c12", "file_path": "integrate/newton_cotes/simpson.py", "project_url": "https://github.com/adabbott/integrate", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -8,7 +8,7 @@ def evaluate(x, f):\n     a = x[0]\n     b = x[1]\n     ya = f(a)\n-    yb = f((a+b)/2)\n+    yb = f((a + b) / 2.0)\n     yc = f(b)\n     I = (b-a) * (ya + 4 * yb + yc) / 6\n     return I\n", "before": "yb = f ( ( a + b ) / 2 )", "after": "yb = f ( ( a + b ) / 2.0 )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 12, 3, 19], [\"float:2.0\", \"T\"], 2], [\"Delete\", [\"integer:2\", 3, 18, 3, 19]]]"}
{"project": "orange3", "commit_sha": "4d98273f7c975bc4169a2047262ec4dc1080771f", "parent_sha": "990733ec25eee7f45ed0b3c932b4dc6aa9b715b1", "file_path": "Orange/widgets/tests/test_itemmodels.py", "project_url": "https://github.com/BlazZupan/orange3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -109,5 +109,5 @@ class TestPyListModel(TestCase):\n \n     def test_data(self):\n         mi = self.model.index(2)\n-        self.assertEqual(self.model.data(mi), '3')\n+        self.assertEqual(self.model.data(mi), 3)\n         self.assertEqual(self.model.data(mi, Qt.EditRole), 3)\n", "before": "self . assertEqual ( self . model . data ( mi ) , '3' )", "after": "self . assertEqual ( self . model . data ( mi ) , 3 )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 25, 3, 51], [\"integer:3\", \"T\"], 3], [\"Delete\", [\"string:'3'\", 3, 47, 3, 50]]]"}
{"project": "freeipa", "commit_sha": "bebe09f3e4ddcc1332395aaa6b662fa4580d8304", "parent_sha": "c709f131712370d567064bb286d32d36f2307e0f", "file_path": "ipaserver/install/server/upgrade.py", "project_url": "https://github.com/Gauravtalreja1/freeipa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -480,7 +480,7 @@ def ca_initialize_hsm_state(ca):\n         section_name = ca.subsystem.upper()\n         config = SafeConfigParser()\n         config.add_section(section_name)\n-        config.set(section_name, 'pki_hsm_enable', False)\n+        config.set(section_name, 'pki_hsm_enable', 'False')\n         ca.set_hsm_state(config)\n \n \n", "before": "config . set ( section_name , 'pki_hsm_enable' , False )", "after": "config . set ( section_name , 'pki_hsm_enable' , 'False' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 19, 3, 58], [\"string:'False'\", \"T\"], 5], [\"Delete\", [\"false:False\", 3, 52, 3, 57]]]"}
{"project": "cassandra-dtest", "commit_sha": "0aefd5f8a83250441db4882bd6e904593360ec45", "parent_sha": "0eeaf3a005ab5bd67c4c213cb96be7e9c0d01fe2", "file_path": "nodetool_test.py", "project_url": "https://github.com/aweisberg/cassandra-dtest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ class TestNodetool(Tester):\n                 for line in [\"dc={}\".format(node.data_center), \"rack=rack{}\".format(i % 2)]:\n                     snitch_file.write(line + os.linesep)\n \n-        cluster.start(wait_for_binary_proto='True')\n+        cluster.start(wait_for_binary_proto=True)\n \n         for i, node in enumerate(cluster.nodelist()):\n             out, err = node.nodetool('info')\n", "before": "cluster . start ( wait_for_binary_proto = 'True' )", "after": "cluster . start ( wait_for_binary_proto = True )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 23, 3, 51], [\"true:True\", \"T\"], 2], [\"Delete\", [\"string:'True'\", 3, 45, 3, 51]]]"}
{"project": "ASteCA", "commit_sha": "97d77f1d7f36adf6af6398a2f4a5b944598fda8f", "parent_sha": "7534f21c6b1df01a3e11b230e07b47128275c876", "file_path": "functions/best_fit/synth_cl_err.py", "project_url": "https://github.com/asteca/ASteCA", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -29,7 +29,7 @@ def get_m_c_errors(mag, mag_value, e_mc_v):\n             # Insert 'b' value into exponential function (not fitted here\n             # because otherwise the number of variables would be larger than\n             # the data points)\n-            popt_mc = np.insert(popt_mc, 1., 1.)\n+            popt_mc = np.insert(popt_mc, 1, 1.)\n \n         # If the 2-param exponential fitting process also fails, try with a\n         # 2P exp but using only two magnitude values, ie: a min and a max.\n", "before": "popt_mc = np . insert ( popt_mc , 1. , 1. )", "after": "popt_mc = np . insert ( popt_mc , 1 , 1. )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 32, 3, 49], [\"integer:1\", \"T\"], 3], [\"Delete\", [\"float:1.\", 3, 42, 3, 44]]]"}
{"project": "ASteCA", "commit_sha": "06e3c285ad3a2c5df2820568e73ef10add196a29", "parent_sha": "ba290c65e1098f646821a9e8a5b8e37fe23bfd35", "file_path": "functions/phot_analysis/get_members_param.py", "project_url": "https://github.com/asteca/ASteCA", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ def mp_members(n_memb, decont_algor_return):\n             if star[7] >= 0.5:\n                 n_memb_da += 1\n \n-        if n_memb != 0 or n_memb_da != 0.:\n+        if n_memb != 0 or n_memb_da != 0:\n             # Obtain parameter.\n             memb_par = (float(n_memb) - float(n_memb_da)) / \\\n                 (float(n_memb) + float(n_memb_da))\n", "before": "if n_memb != 0 or n_memb_da != 0. : memb_par = ( float ( n_memb ) - float ( n_memb_da ) ) / ( float ( n_memb ) + float ( n_memb_da ) )", "after": "if n_memb != 0 or n_memb_da != 0 : memb_par = ( float ( n_memb ) - float ( n_memb_da ) ) / ( float ( n_memb ) + float ( n_memb_da ) )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 27, 3, 42], [\"integer:0\", \"T\"], 2], [\"Delete\", [\"float:0.\", 3, 40, 3, 42]]]"}
{"project": "code", "commit_sha": "98246102068147044ae14ff1abf5365416d26c00", "parent_sha": "b648c716b6969ad28b958a8628347d81cfe6d023", "file_path": "PebbleScores/pebblescores.py", "project_url": "https://github.com/evilrobot69/code", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -129,7 +129,7 @@ class SubmitHandler(webapp.RequestHandler):\n       return\n     score = getTwice(request, \"score\", \"2\")\n     mac = getMac(str(game.name), score, nonce, game.mac_key)\n-    if mac != getTwice(request, \"mac\", 3):\n+    if mac != getTwice(request, \"mac\", \"3\"):\n       logging.error(\n           \"Server MAC %s did not equal request MAC %s, request: %s.\" % (\n               mac, getTwice(request, \"mac\", \"3\"), self.request.body))\n", "before": "if mac != getTwice ( request , \"mac\" , 3 ) : logging . error ( \"Server MAC %s did not equal request MAC %s, request: %s.\" % ( mac , getTwice ( request , \"mac\" , \"3\" ) , self . request . body ) )", "after": "if mac != getTwice ( request , \"mac\" , \"3\" ) : logging . error ( \"Server MAC %s did not equal request MAC %s, request: %s.\" % ( mac , getTwice ( request , \"mac\" , \"3\" ) , self . request . body ) )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 23, 3, 42], [\"string:\\\"3\\\"\", \"T\"], 5], [\"Delete\", [\"integer:3\", 3, 40, 3, 41]]]"}
{"project": "sentry", "commit_sha": "3e04bfdc3de8c3360aa18febfd53e82ef355dec1", "parent_sha": "1d4b4616303ab4729cb5f6766e273ab6e3ffa57e", "file_path": "src/sentry/interfaces/stacktrace.py", "project_url": "https://github.com/ixc/sentry", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -437,7 +437,7 @@ class Stacktrace(Interface):\n         frames = self.frames\n \n         # TODO(dcramer): this should apply only to JS\n-        if len(frames) == 1 and frames[0].lineno == '1' and frames[0].function in ('?', None):\n+        if len(frames) == 1 and frames[0].lineno == 1 and frames[0].function in ('?', None):\n             return []\n \n         output = []\n", "before": "if len ( frames ) == 1 and frames [ 0 ] . lineno == '1' and frames [ 0 ] . function in ( '?' , None ) : return [ ]", "after": "if len ( frames ) == 1 and frames [ 0 ] . lineno == 1 and frames [ 0 ] . function in ( '?' , None ) : return [ ]", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 33, 3, 56], [\"integer:1\", \"T\"], 2], [\"Delete\", [\"string:'1'\", 3, 53, 3, 56]]]"}
{"project": "sentry", "commit_sha": "a3e9c368306437fcaccd3aacb696b088cbaed3bf", "parent_sha": "11acc19006b0bae4178e98178d431941302d7078", "file_path": "sentry/web/forms.py", "project_url": "https://github.com/ixc/sentry", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ class RemoveProjectForm(forms.Form):\n         super(RemoveProjectForm, self).__init__(*args, **kwargs)\n         if not project_list:\n             del self.fields['project']\n-            self.fields['removal_type'].choices = filter(lambda x: x[0] != 2, self.fields['removal_type'].choices)\n+            self.fields['removal_type'].choices = filter(lambda x: x[0] != '2', self.fields['removal_type'].choices)\n         else:\n             self.fields['project'].choices = [(p.pk, p.name) for p in project_list]\n             self.fields['project'].widget.choices = self.fields['project'].choices\n", "before": "self . fields [ 'removal_type' ] . choices = filter ( lambda x : x [ 0 ] != 2 , self . fields [ 'removal_type' ] . choices )", "after": "self . fields [ 'removal_type' ] . choices = filter ( lambda x : x [ 0 ] != '2' , self . fields [ 'removal_type' ] . choices )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 68, 3, 77], [\"string:'2'\", \"T\"], 2], [\"Delete\", [\"integer:2\", 3, 76, 3, 77]]]"}
{"project": "zamboni", "commit_sha": "694e3d987e142f7d6c158653e179b6195c901308", "parent_sha": "e503224f931d993e1900af0692a5871c2bceb915", "file_path": "mkt/search/tests/test_api.py", "project_url": "https://github.com/jobava-mozilla/zamboni", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -253,7 +253,7 @@ class TestApi(BaseOAuth, ESTestCase):\n     @patch.object(mkt.regions.US, 'supports_carrier_billing', False)\n     def test_minimum_price_tier(self):\n         price = Price.objects.create(name=\"5\", price=\"0.50\")\n-        PriceCurrency.objects.create(currency='BRL', price=1.00, tier=price)\n+        PriceCurrency.objects.create(currency='BRL', price=\"1.00\" , tier=price)\n         AddonPremium.objects.create(addon=self.webapp, price=price)\n         self.webapp.save()\n         self.refresh('webapp')\n", "before": "PriceCurrency . objects . create ( currency = 'BRL' , price = 1.00 , tier = price )", "after": "PriceCurrency . objects . create ( currency = 'BRL' , price = \"1.00\" , tier = price )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 54, 3, 64], [\"string:\\\"1.00\\\"\", \"T\"], 2], [\"Delete\", [\"float:1.00\", 3, 60, 3, 64]]]"}
{"project": "lc-simulation", "commit_sha": "a2a4da138992fd9aac91eebf93b4280fa729d467", "parent_sha": "241cc14e155243d2ff450fcfae27910b33a47fba", "file_path": "integrators/polarIntegrator3.py", "project_url": "https://github.com/dmuley/lc-simulation", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -169,7 +169,7 @@ def groupAndIntegrate(bounds, num, star_rad, ld_coeff = [1.],ld_power = [0.]):\n \t\t\t\t\t\n \tfor i in np.arange(0,len(d_theta))[::-1] + 1:\n \t\th = 0;\n-\t\tif ((d_theta[i - 1] < np.pi / (num - 1.)) and d_theta[i - 1] > 3 * np.finfo(np.float32).eps):\n+\t\tif ((d_theta[i - 1] < np.pi / (num - 1.)) and d_theta[i - 1] > 3. * np.finfo(np.float32).eps):\n \t\t\tfor m in s:\n \t\t\t\tn = ld_power[m];\n \t\t\t\tr = 0;\n", "before": "if ( ( d_theta [ i - 1 ] < np . pi / ( num - 1. ) ) and d_theta [ i - 1 ] > 3 * np . finfo ( np . float32 ) . eps ) : for m in s : n = ld_power [ m ] r = 0", "after": "if ( ( d_theta [ i - 1 ] < np . pi / ( num - 1. ) ) and d_theta [ i - 1 ] > 3. * np . finfo ( np . float32 ) . eps ) : for m in s : n = ld_power [ m ] r = 0", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 66, 3, 94], [\"float:3.\", \"T\"], 0], [\"Delete\", [\"integer:3\", 3, 66, 3, 67]]]"}
{"project": "flavio", "commit_sha": "3c3499d32266840f421e2482f4a27f156bd48ddd", "parent_sha": "1bcf23edc2ba9e9ccb261ab8e144bf975fa76649", "file_path": "flavio/physics/bdecays/formfactors/b_p/bcl.py", "project_url": "https://github.com/flav-io/flavio", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -37,7 +37,7 @@ def param_fplusT(mB, mP, a_i, q2, t0=None):\n     Z = z(mB, mP, q2, t0)\n     n = len(a_i)\n     k = np.arange(n)\n-    return ( a_i * (Z**k - (-1)**(k - n) * k/n * Z**n) ).sum()\n+    return ( a_i * (Z**k - (-1.)**(k - n) * k/n * Z**n) ).sum()\n \n def param_f0(mB, mP, a_i, q2, t0=None):\n     Z = z(mB, mP, q2, t0)\n", "before": "return ( a_i * ( Z ** k - ( - 1 ) ** ( k - n ) * k / n * Z ** n ) ) . sum ( )", "after": "return ( a_i * ( Z ** k - ( - 1. ) ** ( k - n ) * k / n * Z ** n ) ) . sum ( )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"unary_operator\", 3, 29, 3, 31], [\"float:1.\", \"T\"], 1], [\"Delete\", [\"integer:1\", 3, 30, 3, 31]]]"}
{"project": "ilastik", "commit_sha": "68b01fa7b0e0c24d1ffa6ef5feb6def76488ae23", "parent_sha": "d97b59cce27fc868b13008122536df1b14b6f59f", "file_path": "ilastik/applets/splitBodyCarving/splitBodyCarvingGui.py", "project_url": "https://github.com/martinsch/ilastik", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -155,7 +155,7 @@ class SplitBodyCarvingGui(CarvingGui):\n \n         # Block must not exceed total bounds.\n         # Shift start up if necessary\n-        rendering_start_3d = TinyVector(self.editor.posModel.slicingPos) - TinyVector(rendered_volume_shape)/2.0\n+        rendering_start_3d = TinyVector(self.editor.posModel.slicingPos) - TinyVector(rendered_volume_shape)/2\n         rendering_start_3d = numpy.maximum( (0,0,0), rendering_start_3d )\n \n         # Compute stop and shift down if necessary\n", "before": "rendering_start_3d = TinyVector ( self . editor . posModel . slicingPos ) - TinyVector ( rendered_volume_shape ) / 2.0", "after": "rendering_start_3d = TinyVector ( self . editor . posModel . slicingPos ) - TinyVector ( rendered_volume_shape ) / 2", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 76, 3, 113], [\"integer:2\", \"T\"], 2], [\"Delete\", [\"float:2.0\", 3, 110, 3, 113]]]"}
{"project": "astropy", "commit_sha": "6126e1bab9a1c489b3069859f29a8160758e7f53", "parent_sha": "455f0e46ee7a3b7564d4e4608e910c6dd0a3fdcb", "file_path": "astropy/units/equivalencies.py", "project_url": "https://github.com/Juanlu001/astropy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -21,7 +21,7 @@ def parallax():\n     \n     return [\n-        (si.arcsecond, astrophys.parsec, lambda x: 1 / x)\n+        (si.arcsecond, astrophys.parsec, lambda x: 1. / x)\n     ]\n \n \n", "before": "return [ ( si . arcsecond , astrophys . parsec , lambda x : 1 / x ) ]", "after": "return [ ( si . arcsecond , astrophys . parsec , lambda x : 1. / x ) ]", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 2, 52, 2, 57], [\"float:1.\", \"T\"], 0], [\"Delete\", [\"integer:1\", 2, 52, 2, 53]]]"}
{"project": "galaxy", "commit_sha": "c96f0e35859beecfc76df92dee4ed11bece438bb", "parent_sha": "43c13ee1626779a4127f67b564ee88bb6b9af3ca", "file_path": "lib/galaxy/web/base/interactive_environments.py", "project_url": "https://github.com/snewhouse/galaxy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -67,7 +67,7 @@ class InteractiveEnviornmentRequest(object):\n         # their defaults dictionary instead.\n         default_dict['command_inject'] = '--sig-proxy=true'\n         default_dict['docker_hostname'] = 'localhost'\n-        default_dict['wx_tempdir'] = False\n+        default_dict['wx_tempdir'] = 'False'\n         viz_config = ConfigParser.SafeConfigParser(default_dict)\n         conf_path = os.path.join( self.attr.our_config_dir, self.attr.viz_id + \".ini\" )\n         if not os.path.exists( conf_path ):\n", "before": "default_dict [ 'wx_tempdir' ] = False", "after": "default_dict [ 'wx_tempdir' ] = 'False'", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 43], [\"string:'False'\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 38, 3, 43]]]"}
{"project": "mycroft-core", "commit_sha": "84b9f925934b9597c258dbcc2519ce723f34c294", "parent_sha": "cd1a36b94a00200791dcecb44f0b8123db2b8c6f", "file_path": "mycroft/client/wifisetup/main.py", "project_url": "https://github.com/Seenivasanseeni/mycroft-core", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -374,7 +374,7 @@ class WiFi:\n                     if \"(incomplete)\" in o:\n                         # ping the IP to get the ARP table entry reloaded\n                         ip_disconnected = o.split(\" \")[0]\n-                        cli_no_output('/bin/ping', '-c', '1', '-W', 3,\n+                        cli_no_output('/bin/ping', '-c', '1', '-W', '3',\n                                       ip_disconnected)\n                     else:\n                         return True  # something on subnet is connected!\n", "before": "cli_no_output ( '/bin/ping' , '-c' , '1' , '-W' , 3 , ip_disconnected )", "after": "cli_no_output ( '/bin/ping' , '-c' , '1' , '-W' , '3' , ip_disconnected )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 38, 4, 55], [\"string:'3'\", \"T\"], 9], [\"Delete\", [\"integer:3\", 3, 69, 3, 70]]]"}
{"project": "kornia", "commit_sha": "557a8eb87c48706bae193adf1aa3ca47ed1b99ea", "parent_sha": "46d3b74cc7e1ed7ee3dc0cb0cb30b1bde60c680f", "file_path": "kornia/color/lab.py", "project_url": "https://github.com/kornia/kornia", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -97,7 +97,7 @@ def lab_to_rgb(image: torch.Tensor, clip: bool = True) -> torch.Tensor:\n     fz = fy - (_b / 200.)\n \n     # if color data out of range: Z < 0\n-    fz = fz.clamp(min=0)\n+    fz = fz.clamp(min=0.)\n \n     fxyz = torch.stack([fx, fy, fz], dim=-3)\n \n", "before": "fz = fz . clamp ( min = 0 )", "after": "fz = fz . clamp ( min = 0. )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"keyword_argument\", 3, 19, 3, 24], [\"float:0.\", \"T\"], 2], [\"Delete\", [\"integer:0\", 3, 23, 3, 24]]]"}
{"project": "sympy", "commit_sha": "01d1f4f9acbf86ef143b10cfd2df4ebb13839c65", "parent_sha": "9511df879534cf851558e49286ccdc2629bcea33", "file_path": "sympy/integrals/integrals.py", "project_url": "https://github.com/jaimahajan1997/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1222,7 +1222,7 @@ def as_sum(self, n, method=\"midpoint\"):\n             raise NotImplementedError(\"Infinite summation not yet implemented\")\n         sym, lower_limit, upper_limit = limit\n         dx = (upper_limit - lower_limit)/n\n-        result = 0.\n+        result = 0\n         for i in range(n):\n             if method == \"midpoint\":\n                 xi = lower_limit + i*dx + dx/2\n", "before": "result = 0.", "after": "result = 0", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 20], [\"integer:0\", \"T\"], 2], [\"Delete\", [\"float:0.\", 3, 18, 3, 20]]]"}
{"project": "beyonwiz-enigma2", "commit_sha": "b7960574b1b0f0f5049d441c721356ba93568c60", "parent_sha": "92cc95201a960942c09de96fd04e45171cb593c3", "file_path": "lib/python/Screens/SoftwareUpdate.py", "project_url": "https://github.com/sklnet/beyonwiz-enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -248,7 +248,7 @@ class UpdatePlugin(Screen):\n \t\t\t\ttry:\n \t\t\t\t\tconfig.softwareupdate.updateisunstable.setValue(urlopen(\"http://enigma2.world-of-satellite.com/feeds/\" + getImageVersionString() + \"/status\").read())\n \t\t\t\texcept:\n-\t\t\t\t\tconfig.softwareupdate.updateisunstable.setValue(1)\n+\t\t\t\t\tconfig.softwareupdate.updateisunstable.setValue('1')\n \t\t\t\tsocket.setdefaulttimeout(currentTimeoutDefault)\n \t\t\t\tself.total_packages = None\n \t\t\t\tif config.softwareupdate.updateisunstable.getValue() == '1' and config.softwareupdate.updatebeta.getValue():\n", "before": "config . softwareupdate . updateisunstable . setValue ( 1 )", "after": "config . softwareupdate . updateisunstable . setValue ( '1' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 53, 3, 56], [\"string:'1'\", \"T\"], 1], [\"Delete\", [\"integer:1\", 3, 54, 3, 55]]]"}
{"project": "Aegean", "commit_sha": "bbf85aac00d52d12f04db7202ba22d6d9248a711", "parent_sha": "6b391824ad4c2f5ed8cc863419603218713bc169", "file_path": "AegeanTools/angle_tools.py", "project_url": "https://github.com/PaulHancock/Aegean", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ def dec2dec(dec):\n     d = dec.replace(':', ' ').split()\n     if len(d) == 2:\n-        d.append(0.0)\n+        d.append('0.0')\n     if d[0].startswith('-') or float(d[0]) < 0:\n         return float(d[0]) - float(d[1]) / 60.0 - float(d[2]) / 3600.0\n     return float(d[0]) + float(d[1]) / 60.0 + float(d[2]) / 3600.0\n", "before": "d . append ( 0.0 )", "after": "d . append ( '0.0' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 17, 2, 22], [\"string:'0.0'\", \"T\"], 1], [\"Delete\", [\"float:0.0\", 2, 18, 2, 21]]]"}
{"project": "Aegean", "commit_sha": "7c792a3a066ea5e7093de6da796c01a60a5810af", "parent_sha": "003b16bf2295fda8defd8398b10392ba7c390f93", "file_path": "AegeanTools/angle_tools.py", "project_url": "https://github.com/PaulHancock/Aegean", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ def dec2dec(dec):\n     d = dec.replace(':', ' ').split()\n     if len(d) == 2:\n-        d.append(0.0)\n+        d.append('0.0')\n     if d[0].startswith('-') or float(d[0]) < 0:\n         return float(d[0]) - float(d[1]) / 60.0 - float(d[2]) / 3600.0\n     return float(d[0]) + float(d[1]) / 60.0 + float(d[2]) / 3600.0\n", "before": "d . append ( 0.0 )", "after": "d . append ( '0.0' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 2, 17, 2, 22], [\"string:'0.0'\", \"T\"], 1], [\"Delete\", [\"float:0.0\", 2, 18, 2, 21]]]"}
{"project": "halftoning", "commit_sha": "921cf6732d03c117fb5ad33ebf22b79f268e8c65", "parent_sha": "94e69beed686735e2dcfabfbc61fa0904c9cf540", "file_path": "functions.py", "project_url": "https://github.com/curegit/halftoning", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -115,7 +115,7 @@ def halftone_image(image, pitch, angle, scale):\n \t\tcontext.fill()\n \treturn Image.frombuffer(\"RGBA\", (width, height), surface.get_data(), \"raw\", \"RGBA\", 0, 1).getchannel(\"G\")\n \n-def halftone_cmyk_image(image, pitch, angles=(15, 75, 30, 45), scale=1.0):\n+def halftone_cmyk_image(image, pitch, angles=(15, 75, 30, 45), scale=1):\n \tc, m, y, k = image.split()\n \tcyan = halftone_image(c, pitch, angles[0], scale)\n \tmagenta = halftone_image(m, pitch, angles[1], scale)\n", "before": "def halftone_cmyk_image ( image , pitch , angles = ( 15 , 75 , 30 , 45 ) , scale = 1.0 ) : c , m , y , k = image . split ( ) cyan = halftone_image ( c , pitch , angles [ 0 ] , scale ) magenta = halftone_image ( m , pitch , angles [ 1 ] , scale )", "after": "def halftone_cmyk_image ( image , pitch , angles = ( 15 , 75 , 30 , 45 ) , scale = 1 ) : c , m , y , k = image . split ( ) cyan = halftone_image ( c , pitch , angles [ 0 ] , scale ) magenta = halftone_image ( m , pitch , angles [ 1 ] , scale )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 64, 3, 73], [\"integer:1\", \"T\"], 2], [\"Delete\", [\"float:1.0\", 3, 70, 3, 73]]]"}
{"project": "diyHue", "commit_sha": "3f2a21bf8c3e1d68ea5da41ff2e629700d6778d9", "parent_sha": "0bf318eab6d2c8b1bda4c88610a5f72497a570cb", "file_path": "BridgeEmulator/HueEmulator3.py", "project_url": "https://github.com/shivasiddharth/diyHue", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1293,7 +1293,7 @@ class S(BaseHTTPRequestHandler):\n         self._set_headers()\n         logging.debug(\"in post method\")\n         logging.debug(self.path)\n-        self.data_string = b\"{}\" if self.headers['Content-Length'] is None or self.headers['Content-Length'] == 0 else self.rfile.read(int(self.headers['Content-Length']))\n+        self.data_string = b\"{}\" if self.headers['Content-Length'] is None or self.headers['Content-Length'] == '0' else self.rfile.read(int(self.headers['Content-Length']))\n         if self.path == \"/updater\":\n             logging.debug(\"check for updates\")\n             update_data = json.loads(sendRequest(\"http://raw.githubusercontent.com/mariusmotea/diyHue/master/BridgeEmulator/updater\", \"GET\", \"{}\"))\n", "before": "self . data_string = b\"{}\" if self . headers [ 'Content-Length' ] is None or self . headers [ 'Content-Length' ] == 0 else self . rfile . read ( int ( self . headers [ 'Content-Length' ] ) )", "after": "self . data_string = b\"{}\" if self . headers [ 'Content-Length' ] is None or self . headers [ 'Content-Length' ] == '0' else self . rfile . read ( int ( self . headers [ 'Content-Length' ] ) )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 79, 3, 114], [\"string:'0'\", \"T\"], 2], [\"Delete\", [\"integer:0\", 3, 113, 3, 114]]]"}
{"project": "addok", "commit_sha": "374db7676d3146d60033efc94d2e5136c463ec1e", "parent_sha": "1b016a3cc64d721b33e49a16464e33658faf0d53", "file_path": "addok/server.py", "project_url": "https://github.com/webgeodatavore/addok", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -173,7 +173,7 @@ class Search(View):\n         except (ValueError, TypeError):\n             limit = 5\n         try:\n-            autocomplete = int(self.request.args.get('autocomplete')) == '1'\n+            autocomplete = int(self.request.args.get('autocomplete')) == 1\n         except (ValueError, TypeError):\n             autocomplete = True\n         try:\n", "before": "autocomplete = int ( self . request . args . get ( 'autocomplete' ) ) == '1'", "after": "autocomplete = int ( self . request . args . get ( 'autocomplete' ) ) == 1", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 3, 28, 3, 77], [\"integer:1\", \"T\"], 2], [\"Delete\", [\"string:'1'\", 3, 74, 3, 77]]]"}
{"project": "platform", "commit_sha": "8e23fb706452cbfe426c384ca8ca8116b47417a2", "parent_sha": "a0b02940432f316396eb5db45bf94be524eb2ddf", "file_path": "wouso/interface/top/models.py", "project_url": "https://github.com/learningparkro/platform", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -61,7 +61,7 @@ class TopUser(ObjectHistory, Player):\n         n = self.played_challenges\n         if n == 0:\n             return 0\n-        return self.won_challenges / n * 100\n+        return self.won_challenges / n * 100.0\n \n     @property\n     def weeklyprogress(self):\n", "before": "return self . won_challenges / n * 100", "after": "return self . won_challenges / n * 100.0", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 16, 3, 45], [\"float:100.0\", \"T\"], 2], [\"Delete\", [\"integer:100\", 3, 42, 3, 45]]]"}
{"project": "platform", "commit_sha": "69519cabaca2cc512ee4bfc1e6d840b1bdb11d35", "parent_sha": "17b46efe212930017e2e3d9053a7bd8e6f2e4a30", "file_path": "wouso/games/workshop/models.py", "project_url": "https://github.com/learningparkro/platform", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -234,7 +234,7 @@ class Assessment(models.Model):\n             self.reviewer_grade *= 2\n \n         try:\n-            self.final_grade = ceil((self.grade * 10 + self.reviewer_grade * 5)/16)\n+            self.final_grade = ceil((self.grade * 10 + self.reviewer_grade * 5)/16.0)\n         except TypeError: # one of the grades is None\n             self.final_grade = None\n         self.save()\n", "before": "self . final_grade = ceil ( ( self . grade * 10 + self . reviewer_grade * 5 ) / 16 )", "after": "self . final_grade = ceil ( ( self . grade * 10 + self . reviewer_grade * 5 ) / 16.0 )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 37, 3, 83], [\"float:16.0\", \"T\"], 2], [\"Delete\", [\"integer:16\", 3, 81, 3, 83]]]"}
{"project": "moodies", "commit_sha": "1287141f7a15047213149fe5f15bdd9729f34806", "parent_sha": "973b1c44a15bda494ff8429e91f6e859bda8f1ac", "file_path": "examples/moodiesclient.py", "project_url": "https://github.com/rawouter/moodies", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -84,7 +84,7 @@ def send_button_pushed(pusher_client, pusher_channel_name):\n     pusher_client.channels[pusher_channel_name].trigger(\n         'client-button-pushed',\n-        {'value': 2, 'user_id': user_data['user_id']}\n+        {'value': '2', 'user_id': user_data['user_id']}\n     )\n     logging.info('send button_pushed')\n \n", "before": "pusher_client . channels [ pusher_channel_name ] . trigger ( 'client-button-pushed' , { 'value' : 2 , 'user_id' : user_data [ 'user_id' ] } )", "after": "pusher_client . channels [ pusher_channel_name ] . trigger ( 'client-button-pushed' , { 'value' : '2' , 'user_id' : user_data [ 'user_id' ] } )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"pair\", 2, 10, 2, 20], [\"string:'2'\", \"T\"], 2], [\"Delete\", [\"integer:2\", 2, 19, 2, 20]]]"}
{"project": "e3fp", "commit_sha": "7e54b5700fa06b5d31b04947a7e402351cbd1a47", "parent_sha": "58cdd2122ebc564bea0f2bb854984299cbf9bbb7", "file_path": "e3fp/fingerprint/fprint.py", "project_url": "https://github.com/keiserlab/e3fp", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -148,7 +148,7 @@ class Fingerprint(object):\n-        indices = [i for i, char in enumerate(bitstring) if char != 0]\n+        indices = [i for i, char in enumerate(bitstring) if char != '0']\n         if kwargs.get(\"bits\", None) is None:\n             kwargs[\"bits\"] = len(bitstring)\n         return cls.from_indices(indices, level=level, **kwargs)\n", "before": "indices = [ i for i , char in enumerate ( bitstring ) if char != 0 ]", "after": "indices = [ i for i , char in enumerate ( bitstring ) if char != '0' ]", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"comparison_operator\", 0, 61, 0, 70], [\"string:'0'\", \"T\"], 2], [\"Delete\", [\"integer:0\", 0, 69, 0, 70]]]"}
{"project": "zulip", "commit_sha": "7fa8bafe81ef851b2dd5a6ede889469f90aef546", "parent_sha": "6684247147a28da007464052b77bf87599d27f5f", "file_path": "zerver/worker/queue_processors.py", "project_url": "https://github.com/amanagr/zulip", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -180,7 +180,7 @@ class QueueProcessingWorker(ABC):\n         self.recent_consume_times: MutableSequence[Tuple[int, float]] = deque(maxlen=50)\n         self.consume_iteration_counter = 0\n         self.idle = True\n-        self.last_statistics_update_time = 0\n+        self.last_statistics_update_time = 0.0\n \n         self.update_statistics(0)\n \n", "before": "self . last_statistics_update_time = 0", "after": "self . last_statistics_update_time = 0.0", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 45], [\"float:0.0\", \"T\"], 2], [\"Delete\", [\"integer:0\", 3, 44, 3, 45]]]"}
{"project": "salt", "commit_sha": "5f7fea05f69438d8283efa6e618a96472450d7ea", "parent_sha": "fce607f057de1eaffe98da2e0b1574665e4aed9a", "file_path": "salt/modules/ddns.py", "project_url": "https://github.com/Mattlk13/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -198,7 +198,7 @@ def update(zone, name, ttl, rdtype, data, nameserver='127.0.0.1', port=53,\n \n \n def delete(zone, name, rdtype=None, data=None, nameserver='127.0.0.1',\n-           port='53', timeout=5, **kwargs):\n+           port=53, timeout=5, **kwargs):\n", "before": "def delete ( zone , name , rdtype = None , data = None , nameserver = '127.0.0.1' , port = '53' , timeout = 5 , ** kwargs ) : ", "after": "def delete ( zone , name , rdtype = None , data = None , nameserver = '127.0.0.1' , port = 53 , timeout = 5 , ** kwargs ) : ", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 12, 3, 21], [\"integer:53\", \"T\"], 2], [\"Delete\", [\"string:'53'\", 3, 17, 3, 21]]]"}
{"project": "compose", "commit_sha": "1512793b30de1c84bff319070c4c4d7f65fd49db", "parent_sha": "ec3af7d49121500dca16ece8da23e1b62591c370", "file_path": "contrib/migration/migrate-compose-file-v1-to-v2.py", "project_url": "https://github.com/DaoCloud/compose", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,7 +33,7 @@ def migrate(content):\n \n     services = {name: data.pop(name) for name in data.keys()}\n \n-    data['version'] = 2\n+    data['version'] = \"2\"\n     data['services'] = services\n     create_volumes_section(data)\n \n", "before": "data [ 'version' ] = 2", "after": "data [ 'version' ] = \"2\"", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 5, 3, 24], [\"string:\\\"2\\\"\", \"T\"], 2], [\"Delete\", [\"integer:2\", 3, 23, 3, 24]]]"}
{"project": "fuglu", "commit_sha": "4375562d09a4d90c8121d7e2535c0fc55136861c", "parent_sha": "ada8d69ebdefbea054e5a03589840204c17ede75", "file_path": "fuglu/tests/unit/plugins_domainauth_test.py", "project_url": "https://github.com/oasiswork/fuglu", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -70,7 +70,7 @@ some <tagged>text</tagged>\n         s.set_source(template)\n         return s\n \n-    def _make_config(self, checkdomains=None, virusname='UNITTEST-SPEARPHISH', virusaction='REJECT', virusenginename='UNIITEST Spearphishing protection', rejectmessage='threat detected: ${virusname}', check_display_part=True ):\n+    def _make_config(self, checkdomains=None, virusname='UNITTEST-SPEARPHISH', virusaction='REJECT', virusenginename='UNIITEST Spearphishing protection', rejectmessage='threat detected: ${virusname}', check_display_part='True' ):\n         config = RawConfigParser()\n         config.add_section('SpearPhishPlugin')\n \n", "before": "def _make_config ( self , checkdomains = None , virusname = 'UNITTEST-SPEARPHISH' , virusaction = 'REJECT' , virusenginename = 'UNIITEST Spearphishing protection' , rejectmessage = 'threat detected: ${virusname}' , check_display_part = True ) : config = RawConfigParser ( ) config . add_section ( 'SpearPhishPlugin' )", "after": "def _make_config ( self , checkdomains = None , virusname = 'UNITTEST-SPEARPHISH' , virusaction = 'REJECT' , virusenginename = 'UNIITEST Spearphishing protection' , rejectmessage = 'threat detected: ${virusname}' , check_display_part = 'True' ) : config = RawConfigParser ( ) config . add_section ( 'SpearPhishPlugin' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"default_parameter\", 3, 202, 3, 225], [\"string:'True'\", \"T\"], 2], [\"Delete\", [\"true:True\", 3, 221, 3, 225]]]"}
{"project": "pytomation", "commit_sha": "fb1386d9eddbbe03c8681f2e18b5aab1488e69ba", "parent_sha": "822b8b32ce63d97b6279da485b78a5f00ebbf311", "file_path": "pytomation/interfaces/insteon.py", "project_url": "https://github.com/zonyl/pytomation", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -559,7 +559,7 @@ class InsteonPLM(HAInterface):\n         # Support levels of lighting\n         if name[0] == 'l' and len(name) == 3:\n             level = name[1:3]\n-            level = int((int(level) / 100) * int(0xFF))\n+            level = int((int(level) / 100.0) * int(0xFF))\n             return lambda x, y=None: self.level(x, level, timeout=y ) \n         \n     def on_fast(self, deviceId, timeout = None):\n", "before": "level = int ( ( int ( level ) / 100 ) * int ( 0xFF ) )", "after": "level = int ( ( int ( level ) / 100.0 ) * int ( 0xFF ) )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 26, 3, 42], [\"float:100.0\", \"T\"], 2], [\"Delete\", [\"integer:100\", 3, 39, 3, 42]]]"}
{"project": "pypipins", "commit_sha": "ed7752ddb448f52c1cb74bb7f6876023694f9648", "parent_sha": "afc1f56b80e9d90044bf1ac1600edcd736aa5ce1", "file_path": "shields/shields.py", "project_url": "https://github.com/badges/pypipins", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -247,7 +247,7 @@ class StatusHandler(PypiHandler):\n             if classifier.startswith(\"Development Status\"):\n                 bits = classifier.split(' :: ')\n                 return bits[1].split(' - ')\n-        return 1, \"unknown\"\n+        return \"1\", \"unknown\"\n \n     def handle_package_data(self, data):\n         statuses = {'1': 'red', '2': 'red', '3': 'red', '4': 'yellow',\n", "before": "return 1 , \"unknown\"", "after": "return \"1\" , \"unknown\"", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"expression_list\", 3, 16, 3, 28], [\"string:\\\"1\\\"\", \"T\"], 0], [\"Delete\", [\"integer:1\", 3, 16, 3, 17]]]"}
{"project": "nibabel", "commit_sha": "d364e993beeaabc0542ea74c91a82458b6a805d7", "parent_sha": "8fa7319c46f6a025fbf4ab1db5c8f7d7abad2dbc", "file_path": "nibabel/nicom/tests/test_dicomwrappers.py", "project_url": "https://github.com/grlee77/nibabel", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -500,7 +500,7 @@ class TestMultiFrameWrapper(TestCase):\n                                  'PixelSpacing',\n                                  [[Decimal('2.1'), Decimal('3.2')]])[0]\n         fake_mf['SharedFunctionalGroupsSequence'] = [fake_frame]\n-        fake_mf['SpacingBetweenSlices'] = Decimal(4.3)\n+        fake_mf['SpacingBetweenSlices'] = Decimal('4.3')\n         assert_array_equal(MFW(fake_mf).voxel_sizes, [2.1, 3.2, 4.3])\n         fake_frame.PixelMeasuresSequence[0].SliceThickness = Decimal('5.4')\n         assert_array_equal(MFW(fake_mf).voxel_sizes, [2.1, 3.2, 5.4])\n", "before": "fake_mf [ 'SpacingBetweenSlices' ] = Decimal ( 4.3 )", "after": "fake_mf [ 'SpacingBetweenSlices' ] = Decimal ( '4.3' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 50, 3, 55], [\"string:'4.3'\", \"T\"], 1], [\"Delete\", [\"float:4.3\", 3, 51, 3, 54]]]"}
{"project": "chaco", "commit_sha": "1cc4712a071e3b5f346cbd5d22a01bb88d0b9f73", "parent_sha": "3a4f31cae23d4c871ea68a38f4f3f659dee8503f", "file_path": "examples/user_guide/grid_plot_container.py", "project_url": "https://github.com/grlee77/chaco", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,7 +41,7 @@ class GridContainerExample(HasTraits):\n                       line_width=3.0)\n \n             # Set each plot's aspect based on its position in the grid\n-            plot.set(height=((i % 3) + 1)*50,\n+            plot.set(height=((i % 3) + 1) * 50.0,\n                      resizable='h')\n \n             # Add to the grid container\n", "before": "line_width = 3.0 ) plot . set ( height = ( ( i % 3 ) + 1 ) * 50 , resizable = 'h' )", "after": "line_width = 3.0 ) plot . set ( height = ( ( i % 3 ) + 1 ) * 50.0 , resizable = 'h' )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 29, 3, 45], [\"float:50.0\", \"T\"], 2], [\"Delete\", [\"integer:50\", 3, 43, 3, 45]]]"}
{"project": "cupy", "commit_sha": "fba2828c3e387f82cafaaf42112ee0dc9573955d", "parent_sha": "bc1ece0502fbb85db4887c9a8f5f088ba16ea624", "file_path": "chainer/utils/type_check.py", "project_url": "https://github.com/grlee77/cupy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ _thread_local = threading.local()\n \n @contextlib.contextmanager\n def get_function_check_context(f):\n-    default = getattr(_thread_local, 'current_function', 'None')\n+    default = getattr(_thread_local, 'current_function', None)\n     _thread_local.current_function = f\n     yield\n     _thread_local.current_function = default\n", "before": "default = getattr ( _thread_local , 'current_function' , 'None' )", "after": "default = getattr ( _thread_local , 'current_function' , None )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 22, 3, 65], [\"none:None\", \"T\"], 5], [\"Delete\", [\"string:'None'\", 3, 58, 3, 64]]]"}
{"project": "cupy", "commit_sha": "a1fd5e11e68074530feea1a51626ce1235da8436", "parent_sha": "e491414b703c1b1ac419f31428bebbd4f468e52d", "file_path": "cupy/math/trigonometric.py", "project_url": "https://github.com/grlee77/cupy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -108,7 +108,7 @@ def _unwrap_correct(dd, discont):\n     ddmod = cupy.mod(dd + numpy.pi, 2*numpy.pi) - numpy.pi\n     cupy.copyto(ddmod, numpy.pi, where=(ddmod == -numpy.pi) & (dd > 0))\n     ph_correct = ddmod - dd\n-    cupy.copyto(ph_correct, 0, where=cupy.abs(dd) < discont)\n+    cupy.copyto(ph_correct, 0., where=cupy.abs(dd) < discont)\n     return ph_correct\n \n \n", "before": "cupy . copyto ( ph_correct , 0 , where = cupy . abs ( dd ) < discont )", "after": "cupy . copyto ( ph_correct , 0. , where = cupy . abs ( dd ) < discont )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 16, 3, 61], [\"float:0.\", \"T\"], 3], [\"Delete\", [\"integer:0\", 3, 29, 3, 30]]]"}
{"project": "dipy", "commit_sha": "f0f4fb7e6e7d095acf0202f32099f316662e5bdb", "parent_sha": "2355db46b23749c475c36c7bdffc7f0f1e09d6bb", "file_path": "dipy/tracking/local/tests/test_local_tracking.py", "project_url": "https://github.com/kesshijordan/dipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -151,7 +151,7 @@ def test_stop_conditions():\n     npt.assert_equal(sl[-1], seeds[y])\n     npt.assert_equal(len(sl), 1)\n \n-    bad_affine = np.eye(3.)\n+    bad_affine = np.eye(3)\n     npt.assert_raises(ValueError, LocalTracking, dg, tc, seeds, bad_affine, 1.)\n \n     bad_affine = np.eye(4.)\n", "before": "bad_affine = np . eye ( 3. )", "after": "bad_affine = np . eye ( 3 )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"argument_list\", 3, 24, 3, 28], [\"integer:3\", \"T\"], 1], [\"Delete\", [\"float:3.\", 3, 25, 3, 27]]]"}
{"project": "mubipy", "commit_sha": "f288999367097d31ec3758a8c9dda7ac8c861c80", "parent_sha": "94fd233290442f2c89c9c3b06f93af77566432bc", "file_path": "test_mubi.py", "project_url": "https://github.com/jbaiter/mubipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,5 +53,5 @@ class TestMubi(object):\n \n     def test_get_watchlist(self):\n         assert ((u'From Morning to Midnight (Germany 1920)',\n-                36051, 'http://s3.amazonaws.com/auteurs_production/images/film/from-morning-to-midnight/w448/from-morning-to-midnight.jpg')\n+                '36051', 'http://s3.amazonaws.com/auteurs_production/images/film/from-morning-to-midnight/w448/from-morning-to-midnight.jpg')\n                 in self.mubi.get_watchlist())\n", "before": "assert ( ( u'From Morning to Midnight (Germany 1920)' , 36051 , 'http://s3.amazonaws.com/auteurs_production/images/film/from-morning-to-midnight/w448/from-morning-to-midnight.jpg' ) in self . mubi . get_watchlist ( ) )", "after": "assert ( ( u'From Morning to Midnight (Germany 1920)' , '36051' , 'http://s3.amazonaws.com/auteurs_production/images/film/from-morning-to-midnight/w448/from-morning-to-midnight.jpg' ) in self . mubi . get_watchlist ( ) )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"tuple\", 2, 17, 3, 140], [\",:,\", \"T\"], 2], [\"Insert\", [\"tuple\", 2, 17, 3, 140], [\"string:'36051'\", \"T\"], 3], [\"Delete\", [\"integer:36051\", 3, 17, 3, 22]], [\"Delete\", [\",:,\", 3, 22, 3, 23]]]"}
{"project": "warriorframework_py3", "commit_sha": "0cf652c2aa79834c37f5b0dbbd70dff95853ac41", "parent_sha": "a464ddff3bbb0cedd813414b2c35bb47b18f4ffc", "file_path": "warrior/Actions/SnmpActions/common_snmp_actions.py", "project_url": "https://github.com/warriorframework/warriorframework_py3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -476,7 +476,7 @@ class CommonSnmpActions(object):\n                  privProtocol=None,\n                  custom_mib_paths=None,\n                  load_mib_modules=None,\n-                 lexicographicMode=False):\n+                 lexicographicMode=\"False\"):\n", "before": "lexicographicMode = False", "after": "lexicographicMode = \"False\"", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 18, 3, 41], [\"string:\\\"False\\\"\", \"T\"], 2], [\"Delete\", [\"false:False\", 3, 36, 3, 41]]]"}
{"project": "Flexget", "commit_sha": "b6aa128b3462ef4d1097c211ed29c8366c3305c0", "parent_sha": "1964bb84bcedff9e3da6855e70f884cc4fdfcdd5", "file_path": "flexget/plugins/api_trakt.py", "project_url": "https://github.com/programatix/Flexget", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -189,7 +189,7 @@ def get_session(account=None, token=None):\n     session = requests.Session()\n     session.headers = {\n         'Content-Type': 'application/json',\n-        'trakt-api-version': 2,\n+        'trakt-api-version': '2',\n         'trakt-api-key': CLIENT_ID,\n     }\n     if account:\n", "before": "session . headers = { 'Content-Type' : 'application/json' , 'trakt-api-version' : 2 , 'trakt-api-key' : CLIENT_ID , }", "after": "session . headers = { 'Content-Type' : 'application/json' , 'trakt-api-version' : '2' , 'trakt-api-key' : CLIENT_ID , }", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"pair\", 3, 9, 3, 31], [\"string:'2'\", \"T\"], 2], [\"Delete\", [\"integer:2\", 3, 30, 3, 31]]]"}
{"project": "django-loci", "commit_sha": "6d9eb02588770a6cf083e09d922ca8a7cbbc3e59", "parent_sha": "13bbe2ffbecaee0ec77c824c236a6b107c86ece8", "file_path": "loci/tests.py", "project_url": "https://github.com/jlecker/django-loci", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ class ModelTests(TestCase):\n class LookupTests(TestCase):\n     def test_request_geolocation(self):\n         # use a consistent default ZIP\n-        settings.DEFAULT_ZIP_CODE = 54403\n+        settings.DEFAULT_ZIP_CODE = '54403'\n         \n         # make a \"request\" to pass to geolocate_request\n         mock_request = _Mock()\n", "before": "settings . DEFAULT_ZIP_CODE = 54403", "after": "settings . DEFAULT_ZIP_CODE = '54403'", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"assignment\", 3, 9, 3, 42], [\"string:'54403'\", \"T\"], 2], [\"Delete\", [\"integer:54403\", 3, 37, 3, 42]]]"}
{"project": "paperwork", "commit_sha": "583e633d220defbdc4eb3300e90b15c38f11f6bf", "parent_sha": "85dbd1fc767831659522a7a51034243722284152", "file_path": "src/paperwork/frontend/util/canvas/__init__.py", "project_url": "https://github.com/awesome-archive/paperwork", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ class Canvas(Gtk.DrawingArea, Gtk.Scrollable):\n \n         self.set_size_request(-1, -1)\n \n-        GLib.timeout_add(1000.0 / 30, self._tick)\n+        GLib.timeout_add(1000 / 30, self._tick)\n \n     def _tick(self):\n         for drawer in self.drawers:\n", "before": "GLib . timeout_add ( 1000.0 / 30 , self . _tick )", "after": "GLib . timeout_add ( 1000 / 30 , self . _tick )", "sstub_pattern": "CHANGE_CONSTANT_TYPE", "edit_script": "[[\"Insert\", [\"binary_operator\", 3, 26, 3, 37], [\"integer:1000\", \"T\"], 0], [\"Delete\", [\"float:1000.0\", 3, 26, 3, 32]]]"}
{"project": "mdtraj", "commit_sha": "1606801b2fdfa8986eaf888719657821b54c5f11", "parent_sha": "4420c18c92763e5e61bacd694cbd13ba22a85499", "file_path": "MDTraj/formats/mol2.py", "project_url": "https://github.com/Eigenstate/mdtraj", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -158,7 +158,7 @@ def mol2_to_dataframes(filename):\n     csv = StringIO()\n     csv.writelines(data[\"@<TRIPOS>ATOM\\n\"][1:])\n     csv.seek(0)\n-    atoms_frame = pd.read_csv(csv, sep=\"\\s*\", names=[\"serial\", \"name\", \"x\", \"y\", \"z\", \"atype\", \"code\", \"resName\", \"charge\"], header=None, usecols=range(1, 10))\n+    atoms_frame = pd.read_csv(csv, sep=\"\\s*\", names=[\"serial\", \"name\", \"x\", \"y\", \"z\", \"atype\", \"code\", \"resName\", \"charge\"], header=None)#, usecols=range(1, 10))  # usecols not available in pandas 0.11\n     return atoms_frame, bonds_frame\n \n \n", "before": "atoms_frame = pd . read_csv ( csv , sep = \"\\s*\" , names = [ \"serial\" , \"name\" , \"x\" , \"y\" , \"z\" , \"atype\" , \"code\" , \"resName\" , \"charge\" ] , header = None , usecols = range ( 1 , 10 ) )", "after": "atoms_frame = pd . read_csv ( csv , sep = \"\\s*\" , names = [ \"serial\" , \"name\" , \"x\" , \"y\" , \"z\" , \"atype\" , \"code\" , \"resName\" , \"charge\" ] , header = None )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Move\", [\"argument_list\", 3, 30, 3, 160], [\"):)\", 3, 158, 3, 159], 8], [\"Delete\", [\",:,\", 3, 137, 3, 138]], [\"Delete\", [\"identifier:usecols\", 3, 139, 3, 146]], [\"Delete\", [\"=:=\", 3, 146, 3, 147]], [\"Delete\", [\"identifier:range\", 3, 147, 3, 152]], [\"Delete\", [\"(:(\", 3, 152, 3, 153]], [\"Delete\", [\"integer:1\", 3, 153, 3, 154]], [\"Delete\", [\",:,\", 3, 154, 3, 155]], [\"Delete\", [\"integer:10\", 3, 156, 3, 158]], [\"Delete\", [\"argument_list\", 3, 152, 3, 159]], [\"Delete\", [\"call\", 3, 147, 3, 159]], [\"Delete\", [\"keyword_argument\", 3, 139, 3, 159]], [\"Delete\", [\"):)\", 3, 159, 3, 160]]]"}
{"project": "tekka", "commit_sha": "d632f672f55af988f3c503c1e6efd7a8f92e2cd8", "parent_sha": "bd136d62b7ae2e0387411c29d13b5a11aadf0547", "file_path": "menus/servertree_menu.py", "project_url": "https://github.com/sushi-irc/tekka", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -224,7 +224,7 @@ class ServerTreeMenu(object):\n \t\t\treturn\n \n \t\tsushi.server_set(self.current_tab.name,\n-\t\t\t\"server\", \"autoconnect\", str(self, item.get_active()).lower())\n+\t\t\t\"server\", \"autoconnect\", str(item.get_active()).lower())\n \n \tdef historyItem_activate_cb(self, item):\n \t\t\"\"\" show up history dialog for current tab. \"\"\"\n", "before": "sushi . server_set ( self . current_tab . name , \"server\" , \"autoconnect\" , str ( self , item . get_active ( ) ) . lower ( ) )", "after": "sushi . server_set ( self . current_tab . name , \"server\" , \"autoconnect\" , str ( item . get_active ( ) ) . lower ( ) )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 33, 3, 37]], [\"Delete\", [\",:,\", 3, 37, 3, 38]]]"}
{"project": "urbanbus-rest", "commit_sha": "9e73b3d18ec3c82c18f405ee98e9d97c0c5f1a9a", "parent_sha": "86b4e5301f84ad6a8335901ba1a71b23a4b0f595", "file_path": "database/database_access.py", "project_url": "https://github.com/LoveXanome/urbanbus-rest", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -442,7 +442,7 @@ def _agency_exist(session, id, name):\n \n \n def _is_urban(route):\n-    urb, dis, rat = decret_2015_1610(route.trips, False)\n+    urb, dis, rat = decret_2015_1610(route.trips)\n     dis = dis if dis else -1\n     rat = rat if rat else -1\n     return urb, dis, rat\n", "before": "urb , dis , rat = decret_2015_1610 ( route . trips , False )", "after": "urb , dis , rat = decret_2015_1610 ( route . trips )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 49, 3, 50]], [\"Delete\", [\"false:False\", 3, 51, 3, 56]]]"}
{"project": "rq", "commit_sha": "23cae3a4209a392617122cc48c8ce8c830e55963", "parent_sha": "16ee71f26de5b0992625442fa59b72c0da928561", "file_path": "tests/test_worker.py", "project_url": "https://github.com/dronedeploy/rq", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -282,7 +282,7 @@ class TestWorker(RQTestCase):\n         \"\"\"Worker processes work, with forking disabled,\n         then returns.\"\"\"\n         fooq, barq = Queue('foo'), Queue('bar')\n-        w = WorkerTest([fooq, barq], fork=False)\n+        w = WorkerTest([fooq, barq])\n         self.assertEquals(w.work(burst=True), False,\n                           'Did not expect any work on the queue.')\n \n", "before": "w = WorkerTest ( [ fooq , barq ] , fork = False )", "after": "w = WorkerTest ( [ fooq , barq ] )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 36, 3, 37]], [\"Delete\", [\"identifier:fork\", 3, 38, 3, 42]], [\"Delete\", [\"=:=\", 3, 42, 3, 43]], [\"Delete\", [\"false:False\", 3, 43, 3, 48]], [\"Delete\", [\"keyword_argument\", 3, 38, 3, 48]]]"}
{"project": "RateMon", "commit_sha": "20a8254522eb5b465a7353f4231b715fb67839cc", "parent_sha": "890241345261b2abb1598b88ff8cee97d896ff1b", "file_path": "ratemon/ShiftMonitorNCR.py", "project_url": "https://github.com/cms-tsg-fog/RateMon", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -113,7 +113,7 @@ class ShiftMonitor:\n         if oldParser:\n             self.parser = OldDBParser.DBParser(dbCfg)\n         else:\n-            self.parser = DBParser.DBParser(dbCfg)   # A database parser\n+            self.parser = DBParser.DBParser()   # A database parser\n \n         # Rates\n         self.HLTRates = None            # HLT rates\n", "before": "self . parser = DBParser . DBParser ( dbCfg )", "after": "self . parser = DBParser . DBParser ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:dbCfg\", 3, 45, 3, 50]]]"}
{"project": "tribler", "commit_sha": "baaf5da1012bf4b6d92190866702c2eaf95345cc", "parent_sha": "64a1d30b3768306ebf6abc339de02a803a41b478", "file_path": "Tribler/Core/dispersy/member.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -146,7 +146,7 @@ class Member(DummyMember):\n                 return member\n \n         # create new Member and store in cache\n-        member = object.__new__(cls, public_key, private_key)\n+        member = object.__new__(cls)\n         if len(cls.__cache) >= cls.__cache_length:\n             del cls.__cache[-1]\n         cls.__cache.insert(cls.__cache_length / 3, member)\n", "before": "member = object . __new__ ( cls , public_key , private_key )", "after": "member = object . __new__ ( cls )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 36, 3, 37]], [\"Delete\", [\"identifier:public_key\", 3, 38, 3, 48]], [\"Delete\", [\",:,\", 3, 48, 3, 49]], [\"Delete\", [\"identifier:private_key\", 3, 50, 3, 61]]]"}
{"project": "SleekXMPP", "commit_sha": "a5d53b3349dc1488da57a7b02758ab1063b4560c", "parent_sha": "4487a90623bfec9deb119074a9e0f65f97003db0", "file_path": "sleekxmpp/roster.py", "project_url": "https://github.com/mayflower/SleekXMPP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -61,7 +61,7 @@ class Roster(object):\n         if key not in self._rosters:\n-            self.add(key, self.db)\n+            self.add(key)\n             self._rosters[key].auto_authorize = self.auto_authorize\n             self._rosters[key].auto_subscribe = self.auto_subscribe\n         return self._rosters[key]\n", "before": "self . add ( key , self . db )", "after": "self . add ( key )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 1, 25, 1, 26]], [\"Delete\", [\"identifier:self\", 1, 27, 1, 31]], [\"Delete\", [\".:.\", 1, 31, 1, 32]], [\"Delete\", [\"identifier:db\", 1, 32, 1, 34]], [\"Delete\", [\"attribute\", 1, 27, 1, 34]]]"}
{"project": "tribler", "commit_sha": "67739cdef75a949177563602b8446de4af98cb33", "parent_sha": "9d14a042f972804f0897fb2188a3c10c73fca5f8", "file_path": "Tribler/Main/Utility/utility.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -36,7 +36,7 @@ class Utility(object):\n \n     def setupConfig(self):\n         self.configfilepath = os.path.join(self.getConfigPath(), STATEDIR_GUICONFIG)\n-        self.config = CallbackConfigParser(tribler_defaults)\n+        self.config = CallbackConfigParser()\n \n         # Load the config file.\n         if os.path.exists(self.configfilepath):\n", "before": "self . config = CallbackConfigParser ( tribler_defaults )", "after": "self . config = CallbackConfigParser ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:tribler_defaults\", 3, 44, 3, 60]]]"}
{"project": "tribler", "commit_sha": "a0ce5100fff0f4a5cff989f19c3a62c334a7cd42", "parent_sha": "465f713a89b42760c62deef30e240d0e31ed68d3", "file_path": "Tribler/Main/Utility/utility.py", "project_url": "https://github.com/mitchellolsthoorn/tribler", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -36,7 +36,7 @@ class Utility(object):\n \n     def setupConfig(self):\n         self.configfilepath = os.path.join(self.getConfigPath(), STATEDIR_GUICONFIG)\n-        self.config = CallbackConfigParser(tribler_defaults)\n+        self.config = CallbackConfigParser()\n \n         # Load the config file.\n         if os.path.exists(self.configfilepath):\n", "before": "self . config = CallbackConfigParser ( tribler_defaults )", "after": "self . config = CallbackConfigParser ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:tribler_defaults\", 3, 44, 3, 60]]]"}
{"project": "python-ivi", "commit_sha": "56bd3ed1269675200f9402612c203b623e8a4a4e", "parent_sha": "58f5d4c98d36f0510777a2e7ebbe1f1fbbca993a", "file_path": "ivi/dmm.py", "project_url": "https://github.com/ianrrees/python-ivi", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -153,7 +153,7 @@ class Base(ivi.IviContainer):\n         pass\n     \n     def _configure(self, function, range, resolution):\n-        self._set_measurement_function(self, function)\n+        self._set_measurement_function(function)\n         if range in Auto:\n             self._set_auto_range(range)\n         else:\n", "before": "self . _set_measurement_function ( self , function )", "after": "self . _set_measurement_function ( function )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 40, 3, 44]], [\"Delete\", [\",:,\", 3, 44, 3, 45]]]"}
{"project": "ecs", "commit_sha": "b5329129ee4d83ffdcc1683973620f36b9dd1611", "parent_sha": "6abea2656bb650425731a78037c7633eb76db9c2", "file_path": "ecs/async_actions.py", "project_url": "https://github.com/simonsdave/ecs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -96,7 +96,7 @@ class AsyncEndToEndContainerRunner(AsyncAction):\n             return\n \n         fmt = '%s - successfully started container - container ID = %s'\n-        _logger.info(fmt, self.cid, self.docker_image, self.tag, self.cmd, self._container_id)\n+        _logger.info(fmt, self.cid, self._container_id)\n \n         fmt = '%s - attempting to get container\\'s exit status - conatiner ID = %s'\n         _logger.error(fmt, self.cid, self._container_id)\n", "before": "_logger . info ( fmt , self . cid , self . docker_image , self . tag , self . cmd , self . _container_id )", "after": "_logger . info ( fmt , self . cid , self . _container_id )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 37, 3, 41]], [\"Delete\", [\".:.\", 3, 41, 3, 42]], [\"Delete\", [\"identifier:docker_image\", 3, 42, 3, 54]], [\"Delete\", [\"attribute\", 3, 37, 3, 54]], [\"Delete\", [\",:,\", 3, 54, 3, 55]], [\"Delete\", [\"identifier:self\", 3, 56, 3, 60]], [\"Delete\", [\".:.\", 3, 60, 3, 61]], [\"Delete\", [\"identifier:tag\", 3, 61, 3, 64]], [\"Delete\", [\"attribute\", 3, 56, 3, 64]], [\"Delete\", [\",:,\", 3, 64, 3, 65]], [\"Delete\", [\"identifier:self\", 3, 66, 3, 70]], [\"Delete\", [\".:.\", 3, 70, 3, 71]], [\"Delete\", [\"identifier:cmd\", 3, 71, 3, 74]], [\"Delete\", [\"attribute\", 3, 66, 3, 74]], [\"Delete\", [\",:,\", 3, 74, 3, 75]]]"}
{"project": "python-openid", "commit_sha": "3b3e230cb723e1a96d106d2c86b8ce24a2c01241", "parent_sha": "ddf7f301470b1994d056d995958780af73610a18", "file_path": "openid/server/trustroot.py", "project_url": "https://github.com/ziima/python-openid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -149,7 +149,7 @@ class TrustRoot(object):\n     def checkURL(cls, trust_root, url):\n         \"\"\"quick func for validating a url against a trust root.  See the\n         TrustRoot class if you need more control.\"\"\"\n-        tr = cls.parse(trust_root, check_sanity=True)\n+        tr = cls.parse(trust_root)\n         return tr is not None and tr.validateURL(url)\n \n     checkURL = classmethod(checkURL)\n", "before": "tr = cls . parse ( trust_root , check_sanity = True )", "after": "tr = cls . parse ( trust_root )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 34, 3, 35]], [\"Delete\", [\"identifier:check_sanity\", 3, 36, 3, 48]], [\"Delete\", [\"=:=\", 3, 48, 3, 49]], [\"Delete\", [\"true:True\", 3, 49, 3, 53]], [\"Delete\", [\"keyword_argument\", 3, 36, 3, 53]]]"}
{"project": "wukong-contrib", "commit_sha": "bda1d2b2b1c9b2291f9a89083fa286d77ef27742", "parent_sha": "ad8d6759938d97317a43f96f8e33e4cce55c823d", "file_path": "Weather.py", "project_url": "https://github.com/wzpan/wukong-contrib", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ class Plugin(AbstractPlugin):\n             'location': location\n         }\n         result = requests.get(api, params=body, timeout=3)\n-        res = json.loads(result.text, encoding='utf-8')\n+        res = json.loads(result.text)\n         return res\n \n \n", "before": "res = json . loads ( result . text , encoding = 'utf-8' )", "after": "res = json . loads ( result . text )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 37, 3, 38]], [\"Delete\", [\"identifier:encoding\", 3, 39, 3, 47]], [\"Delete\", [\"=:=\", 3, 47, 3, 48]], [\"Delete\", [\"string:'utf-8'\", 3, 48, 3, 55]], [\"Delete\", [\"keyword_argument\", 3, 39, 3, 55]]]"}
{"project": "cc-utils", "commit_sha": "32a0b67e2867498ecd638d595f7d9a9e744660aa", "parent_sha": "3d5383756779e137db011554a76a83110d682c0b", "file_path": "concourse/setup.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -347,7 +347,7 @@ def get_cluster_version_info():\n def ensure_cluster_version(kubernetes_config: KubernetesConfig):\n     not_none(kubernetes_config)\n \n-    cluster_version_info = get_cluster_version_info(kube_ctx)\n+    cluster_version_info = get_cluster_version_info()\n     configured_version_info = kubernetes_config.cluster_version()\n \n     if (\n", "before": "cluster_version_info = get_cluster_version_info ( kube_ctx )", "after": "cluster_version_info = get_cluster_version_info ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:kube_ctx\", 3, 53, 3, 61]]]"}
{"project": "pyFDT", "commit_sha": "88a065cb3300487b391ff99e450a9412bcb9c85e", "parent_sha": "1eeeffd7042fd20ff81e3064a587bf5bac393bb8", "file_path": "fdt/__init__.py", "project_url": "https://github.com/molejar/pyFDT", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -90,7 +90,7 @@ class FDT(object):\n                         item = Node(name)\n                         node.append(item)\n                     else:\n-                        raise ValueError(\"Path \\\"{}\\\" doesn't exists\".format(self, path))\n+                        raise ValueError(\"Path \\\"{}\\\" doesn't exists\".format(path))\n                 node = item\n \n         return node\n", "before": "else : raise ValueError ( \"Path \\\"{}\\\" doesn't exists\" . format ( self , path ) )", "after": "else : raise ValueError ( \"Path \\\"{}\\\" doesn't exists\" . format ( path ) )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 78, 3, 82]], [\"Delete\", [\",:,\", 3, 82, 3, 83]]]"}
{"project": "cc-utils", "commit_sha": "6b207578f4e0ac4b099d2ccb44ef741625f68b3c", "parent_sha": "0c02bdea1f78690ed3c15271281fd503081154d4", "file_path": "protecode/client.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,7 +31,7 @@ class ProtecodeApiRoutes(object):\n     def apps(self, group_id, custom_attribs={}):\n         url = self._api_url('apps')\n         if group_id:\n-            url = urljoin(url, 'group', str(group_id))\n+            url = urljoin(url, str(group_id))\n \n         search_query = ' '.join(['meta:' + str(k) + '=' + str(v) for k,v in custom_attribs.items()])\n         if search_query:\n", "before": "url = urljoin ( url , 'group' , str ( group_id ) )", "after": "url = urljoin ( url , str ( group_id ) )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"string:'group'\", 3, 32, 3, 39]], [\"Delete\", [\",:,\", 3, 39, 3, 40]]]"}
{"project": "WMAS", "commit_sha": "339616f46ab0b32256936b3a77d85186a6e85d6c", "parent_sha": "0133203932cba221edacc57e91155f8a3e8bc59a", "file_path": "tools/wptrunner/wptrunner/executors/executormarionette.py", "project_url": "https://github.com/cta-wave/WMAS", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -96,7 +96,7 @@ class MarionetteProtocol(Protocol):\n     def teardown(self):\n         try:\n             self.marionette._request_in_app_shutdown()\n-            self.marionette.delete_session(send_request=False, reset_session_id=True)\n+            self.marionette.delete_session(send_request=False)\n         except Exception:\n             # This is typically because the session never started\n             pass\n", "before": "self . marionette . delete_session ( send_request = False , reset_session_id = True )", "after": "self . marionette . delete_session ( send_request = False )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 62, 3, 63]], [\"Delete\", [\"identifier:reset_session_id\", 3, 64, 3, 80]], [\"Delete\", [\"=:=\", 3, 80, 3, 81]], [\"Delete\", [\"true:True\", 3, 81, 3, 85]], [\"Delete\", [\"keyword_argument\", 3, 64, 3, 85]]]"}
{"project": "rllab-curriculum", "commit_sha": "cac5f1c7166f28476c76cbf8b10eb0544435fc76", "parent_sha": "1581a738f2a24bd9ac0587c0db659803ee19560c", "file_path": "scripts/run_experiment.py", "project_url": "https://github.com/florensacc/rllab-curriculum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -73,8 +73,8 @@ def run_experiment(argv):\n                         help='Name of the text log file.')\n     parser.add_argument('--plot', type=ast.literal_eval, default=False,\n                         help='Whether to plot the iteration results')\n-    parser.add_argument('--seed', type=int, default=False,\n-                                    help='Random seed for numpy')\n+    parser.add_argument('--seed', type=int,\n+                        help='Random seed for numpy')\n \n     args = parser.parse_known_args(argv[1:])[0]\n \n", "before": "parser . add_argument ( '--seed' , type = int , default = False , help = 'Random seed for numpy' )", "after": "parser . add_argument ( '--seed' , type = int , help = 'Random seed for numpy' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:default\", 3, 45, 3, 52]], [\"Delete\", [\"=:=\", 3, 52, 3, 53]], [\"Delete\", [\"false:False\", 3, 53, 3, 58]], [\"Delete\", [\"keyword_argument\", 3, 45, 3, 58]], [\"Delete\", [\",:,\", 3, 58, 3, 59]]]"}
{"project": "pyMaid", "commit_sha": "3061d9b41fa83d104008469b4c5a3254abf93b4e", "parent_sha": "5ef2bec84cfec63ca9211cc3a8408a1130d321ea", "file_path": "pymaid/morpho.py", "project_url": "https://github.com/schlegelp/pyMaid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -912,7 +912,7 @@ def bending_flow(x, polypre=False):\n                          'got \"{}\"'.format(type(x)))\n \n     if isinstance(x, core.CatmaidNeuronList):\n-        return [bending_flow(n, mode=mode, polypre=polypre, ) for n in x]\n+        return [bending_flow(n, polypre=polypre, ) for n in x]\n \n     if x.soma and x.soma not in x.root:\n         logger.warning('Neuron {0} is not rooted to its soma!'.format(x.skeleton_id))\n", "before": "return [ bending_flow ( n , mode = mode , polypre = polypre , ) for n in x ]", "after": "return [ bending_flow ( n , polypre = polypre , ) for n in x ]", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:mode\", 3, 33, 3, 37]], [\"Delete\", [\"=:=\", 3, 37, 3, 38]], [\"Delete\", [\"identifier:mode\", 3, 38, 3, 42]], [\"Delete\", [\"keyword_argument\", 3, 33, 3, 42]], [\"Delete\", [\",:,\", 3, 42, 3, 43]]]"}
{"project": "pros-cli3", "commit_sha": "455e7e5ddc0729af0bdb85ec0522cb77fc9f62b0", "parent_sha": "ff68605299ca1b4492d22e4519b1b7363ca00248", "file_path": "prosconductor/providers/githubreleases.py", "project_url": "https://github.com/purduesigbots/pros-cli3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ class GithubReleasesDepotProvider(DepotProvider):\n     registrar = 'github-releases'\r\n \r\n     def __init__(self, config):\r\n-        super(GithubReleasesDepotProvider, self).__init__(config)\r\n+        super().__init__(config)\r\n \r\n     def create_headers(self, accept='application/vnd.github.v3+json'):\r\n         headers = {'user-agent': 'pros-cli', 'Accept': accept}\r\n", "before": "super ( GithubReleasesDepotProvider , self ) . __init__ ( config )", "after": "super ( ) . __init__ ( config )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:GithubReleasesDepotProvider\", 3, 15, 3, 42]], [\"Delete\", [\",:,\", 3, 42, 3, 43]], [\"Delete\", [\"identifier:self\", 3, 44, 3, 48]]]"}
{"project": "django-profiling-poll", "commit_sha": "05d581e52a6eccd0f98b543dc2f3adc8f2958b2c", "parent_sha": "6ce17f344fbc7263d559d57dadfd049436b2e4c8", "file_path": "profilingpoll/views.py", "project_url": "https://github.com/schmidsi/django-profiling-poll", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ class SingleRedirectToDetailListView(ListView):\n         if Poll.objects.filter(active=True).count() == 1:\n             return redirect(Poll.objects.filter(active=True)[0])\n         else:\n-            return super(ListView, self).render_to_response(self, context, **response_kwargs)\n+            return super(ListView, self).render_to_response(context, **response_kwargs)\n \n \n class RedirectToFirstQuestion(RedirectView):\n", "before": "return super ( ListView , self ) . render_to_response ( self , context , ** response_kwargs )", "after": "return super ( ListView , self ) . render_to_response ( context , ** response_kwargs )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 61, 3, 65]], [\"Delete\", [\",:,\", 3, 65, 3, 66]]]"}
{"project": "Visual_Script", "commit_sha": "306d061ab3b65bcab2040ce9574a5027742b8fd5", "parent_sha": "34b5d05716f40d465cccde3603acf1abcebd0f12", "file_path": "src/Window.py", "project_url": "https://github.com/NTUTVisualScript/Visual_Script", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -825,7 +825,7 @@ class View(Frame, threading.Thread):\n         run_single_action = Button(self.listFrame, command=lambda: self.runActionButtonClick(n), text=\"\u25b6\", width=3)\n         self.runStepList.append(run_single_action)\n \n-        actioncombo = TestCaseAction(self.listFrame, 0, textvariable=action_value, width=10, height=22,\n+        actioncombo = TestCaseAction(self.listFrame, textvariable=action_value, width=10, height=22,\n                                    state='readonly')\n         actioncombo.bind(\"<<ComboboxSelected>>\", lambda event, i=n: self.ActionSelect(i))\n         actioncombo.bind(\"<MouseWheel>\", lambda event, i=n: self.ActionSelect(i))\n", "before": "actioncombo = TestCaseAction ( self . listFrame , 0 , textvariable = action_value , width = 10 , height = 22 , state = 'readonly' )", "after": "actioncombo = TestCaseAction ( self . listFrame , textvariable = action_value , width = 10 , height = 22 , state = 'readonly' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"integer:0\", 3, 54, 3, 55]], [\"Delete\", [\",:,\", 3, 55, 3, 56]]]"}
{"project": "term2048_ai", "commit_sha": "112e94ca11291b217fc8da5c4965dd0cc71bad53", "parent_sha": "c0c272aa1000f33dead5527e924f4c55fcf50b35", "file_path": "term2048/ui.py", "project_url": "https://github.com/lambdafrela/term2048_ai", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ def start_game():\n     if not __has_argparse:\n         __print_argparse_warning()\n         args = {'mode': None}\n-        Game(mode=args.mode, azmode=args.azmode).loop()\n+        Game().loop()\n     else:\n         parser = argparse.ArgumentParser(description='2048 in your terminal')\n         parser.add_argument('--mode', dest='mode',\n", "before": "Game ( mode = args . mode , azmode = args . azmode ) . loop ( )", "after": "Game ( ) . loop ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:mode\", 3, 14, 3, 18]], [\"Delete\", [\"=:=\", 3, 18, 3, 19]], [\"Delete\", [\"identifier:args\", 3, 19, 3, 23]], [\"Delete\", [\".:.\", 3, 23, 3, 24]], [\"Delete\", [\"identifier:mode\", 3, 24, 3, 28]], [\"Delete\", [\"attribute\", 3, 19, 3, 28]], [\"Delete\", [\"keyword_argument\", 3, 14, 3, 28]], [\"Delete\", [\",:,\", 3, 28, 3, 29]], [\"Delete\", [\"identifier:azmode\", 3, 30, 3, 36]], [\"Delete\", [\"=:=\", 3, 36, 3, 37]], [\"Delete\", [\"identifier:args\", 3, 37, 3, 41]], [\"Delete\", [\".:.\", 3, 41, 3, 42]], [\"Delete\", [\"identifier:azmode\", 3, 42, 3, 48]], [\"Delete\", [\"attribute\", 3, 37, 3, 48]], [\"Delete\", [\"keyword_argument\", 3, 30, 3, 48]]]"}
{"project": "iCalendar", "commit_sha": "58d3a181ea57acec3b6683c6ed7a023e50c97278", "parent_sha": "07f23aa503e1cc4eb3e3bfc89badc24bcaa8bf4d", "file_path": "src/icalendar/caselessdict.py", "project_url": "https://github.com/ryba-xek/iCalendar", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ class CaselessDict(dict):\n         return dict.pop(self, key.upper(), default)\n \n     def popitem(self):\n-        return dict.popitem(self, key.upper())\n+        return dict.popitem(self)\n \n     def has_key(self, key):\n         return dict.has_key(self, key.upper())\n", "before": "return dict . popitem ( self , key . upper ( ) )", "after": "return dict . popitem ( self )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Move\", [\"argument_list\", 3, 28, 3, 47], [\"):)\", 3, 45, 3, 46], 2], [\"Delete\", [\",:,\", 3, 33, 3, 34]], [\"Delete\", [\"identifier:key\", 3, 35, 3, 38]], [\"Delete\", [\".:.\", 3, 38, 3, 39]], [\"Delete\", [\"identifier:upper\", 3, 39, 3, 44]], [\"Delete\", [\"attribute\", 3, 35, 3, 44]], [\"Delete\", [\"(:(\", 3, 44, 3, 45]], [\"Delete\", [\"argument_list\", 3, 44, 3, 46]], [\"Delete\", [\"call\", 3, 35, 3, 46]], [\"Delete\", [\"):)\", 3, 46, 3, 47]]]"}
{"project": "angr", "commit_sha": "55a366224c2d11fef71a3c7b0de74ecb4eeae969", "parent_sha": "0b94cbceade27aab1605b35a666bdf133e5c9fe6", "file_path": "angr/functionmanager.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -99,7 +99,7 @@ class Function(object):\n             if addr in memory:\n                 # check that the address isn't an pointing to known executable code\n                 # and that it isn't an indirect pointer to known executable code\n-                possible_pointer = memory.read_addr_at(addr, self._function_manager._project.ld.main_bin.archinfo)\n+                possible_pointer = memory.read_addr_at(addr)\n                 if addr not in known_executable_addresses and possible_pointer not in known_executable_addresses:\n                     # build string\n                     str = \"\"\n", "before": "possible_pointer = memory . read_addr_at ( addr , self . _function_manager . _project . ld . main_bin . archinfo )", "after": "possible_pointer = memory . read_addr_at ( addr )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 60, 3, 61]], [\"Delete\", [\"identifier:self\", 3, 62, 3, 66]], [\"Delete\", [\".:.\", 3, 66, 3, 67]], [\"Delete\", [\"identifier:_function_manager\", 3, 67, 3, 84]], [\"Delete\", [\"attribute\", 3, 62, 3, 84]], [\"Delete\", [\".:.\", 3, 84, 3, 85]], [\"Delete\", [\"identifier:_project\", 3, 85, 3, 93]], [\"Delete\", [\"attribute\", 3, 62, 3, 93]], [\"Delete\", [\".:.\", 3, 93, 3, 94]], [\"Delete\", [\"identifier:ld\", 3, 94, 3, 96]], [\"Delete\", [\"attribute\", 3, 62, 3, 96]], [\"Delete\", [\".:.\", 3, 96, 3, 97]], [\"Delete\", [\"identifier:main_bin\", 3, 97, 3, 105]], [\"Delete\", [\"attribute\", 3, 62, 3, 105]], [\"Delete\", [\".:.\", 3, 105, 3, 106]], [\"Delete\", [\"identifier:archinfo\", 3, 106, 3, 114]], [\"Delete\", [\"attribute\", 3, 62, 3, 114]]]"}
{"project": "bilibili_live_tools", "commit_sha": "e48ab4572e3faa8b6625126f3808801faa43cef8", "parent_sha": "31baff900873d1d663b1bbd65621bf83036c31ad", "file_path": "danmu/utility.py", "project_url": "https://github.com/superway117/bilibili_live_tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,7 +25,7 @@ class Displayer():\n             self.thread.start();\n             self.display = self.threadedDisplay;\n     def commonDisplay(self, *aArgs, **mArgs):\n-        type(self).lock.acquire(timeout=5);\n+        type(self).lock.acquire();\n         try:\n             print(*aArgs, **mArgs);\n         except UnicodeEncodeError as e:\n", "before": "type ( self ) . lock . acquire ( timeout = 5 )", "after": "type ( self ) . lock . acquire ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:timeout\", 3, 33, 3, 40]], [\"Delete\", [\"=:=\", 3, 40, 3, 41]], [\"Delete\", [\"integer:5\", 3, 41, 3, 42]], [\"Delete\", [\"keyword_argument\", 3, 33, 3, 42]]]"}
{"project": "netpyne", "commit_sha": "ca8d732c001365e3a1efc2e91f0d38ca95aa085d", "parent_sha": "7404ded9d40dfacc3ece5bb3f69236fde15e47b8", "file_path": "netpyne/utils.py", "project_url": "https://github.com/rodriguez-facundo/netpyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -169,7 +169,7 @@ def importCell (fileName, cellName, cellArgs = None, cellInstance = False):\n             sys.path.insert(0, filePath)\n         moduleName = fileNameOnly.split('.py')[0]  # remove .py to obtain module name\n         tempModule=None\n-        exec(('import ' + moduleName + ' as tempModule'), globals(), locals()) # import module dynamically\n+        exec('import ' + moduleName + ' as tempModule') #, globals(), locals()) # import module dynamically\n         modulePointer = tempModule\n         print(modulePointer)\n         print(dir(modulePointer))\n", "before": "exec ( ( 'import ' + moduleName + ' as tempModule' ) , globals ( ) , locals ( ) )", "after": "exec ( 'import ' + moduleName + ' as tempModule' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Move\", [\"argument_list\", 3, 13, 3, 79], [\"binary_operator\", 3, 15, 3, 56], 1], [\"Move\", [\"argument_list\", 3, 13, 3, 79], [\"):)\", 3, 56, 3, 57], 2], [\"Delete\", [\"(:(\", 3, 14, 3, 15]], [\"Delete\", [\"parenthesized_expression\", 3, 14, 3, 57]], [\"Delete\", [\",:,\", 3, 57, 3, 58]], [\"Delete\", [\"identifier:globals\", 3, 59, 3, 66]], [\"Delete\", [\"(:(\", 3, 66, 3, 67]], [\"Delete\", [\"):)\", 3, 67, 3, 68]], [\"Delete\", [\"argument_list\", 3, 66, 3, 68]], [\"Delete\", [\"call\", 3, 59, 3, 68]], [\"Delete\", [\",:,\", 3, 68, 3, 69]], [\"Delete\", [\"identifier:locals\", 3, 70, 3, 76]], [\"Delete\", [\"(:(\", 3, 76, 3, 77]], [\"Delete\", [\"):)\", 3, 77, 3, 78]], [\"Delete\", [\"argument_list\", 3, 76, 3, 78]], [\"Delete\", [\"call\", 3, 70, 3, 78]], [\"Delete\", [\"):)\", 3, 78, 3, 79]]]"}
{"project": "dival", "commit_sha": "a64ee41f95e3c77526b5a825c609d46dbeec7d49", "parent_sha": "fa6bab21dec83b462c9c53209f022160e5d8948a", "file_path": "dival/measure.py", "project_url": "https://github.com/jleuschn/dival", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -96,7 +96,7 @@ class Measure(ABC):\n     def __call__(self, reconstruction, ground_truth):\n         \"\"\"Call :meth:`apply`.\n         \"\"\"\n-        return self.apply(self, reconstruction, ground_truth)\n+        return self.apply(reconstruction, ground_truth)\n \n     @classmethod\n     def get_by_short_name(cls, short_name):\n", "before": "return self . apply ( self , reconstruction , ground_truth )", "after": "return self . apply ( reconstruction , ground_truth )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 27, 3, 31]], [\"Delete\", [\",:,\", 3, 31, 3, 32]]]"}
{"project": "django_lucy", "commit_sha": "84e50abf69c9d5b04c3c52d16c2d75531c21842c", "parent_sha": "f8a9708648dbc16369d05793b819391c750f52f7", "file_path": "tests/test_django.py", "project_url": "https://github.com/ncopiy/django_lucy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -147,7 +147,7 @@ class TestMapping(TestCase):\n                 model = None\n \n         mapping = list(NotExcludingFieldsSearchSet.storage.mapping.keys())\n-        self.assertSequenceEqual(mapping, [\"a\", \"b\", \"c\"], NotExcludingFieldsSearchSet.storage.fields_to_exclude_from_mapping)\n+        self.assertSequenceEqual(mapping, [\"a\", \"b\", \"c\"])\n \n     def test_exclude_fields_in_searchset_class(self):\n         class ExcludeFieldsInClassSearchSet(DjangoSearchSet):\n", "before": "self . assertSequenceEqual ( mapping , [ \"a\" , \"b\" , \"c\" ] , NotExcludingFieldsSearchSet . storage . fields_to_exclude_from_mapping )", "after": "self . assertSequenceEqual ( mapping , [ \"a\" , \"b\" , \"c\" ] )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 58, 3, 59]], [\"Delete\", [\"identifier:NotExcludingFieldsSearchSet\", 3, 60, 3, 87]], [\"Delete\", [\".:.\", 3, 87, 3, 88]], [\"Delete\", [\"identifier:storage\", 3, 88, 3, 95]], [\"Delete\", [\"attribute\", 3, 60, 3, 95]], [\"Delete\", [\".:.\", 3, 95, 3, 96]], [\"Delete\", [\"identifier:fields_to_exclude_from_mapping\", 3, 96, 3, 126]], [\"Delete\", [\"attribute\", 3, 60, 3, 126]]]"}
{"project": "semeval19_task3", "commit_sha": "872950725062e7337bffb2bf2b503d051cc966a0", "parent_sha": "53ddc540297976eff15fce9e8ca983d20a720574", "file_path": "san/config.py", "project_url": "https://github.com/baaesh/semeval19_task3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ def model_config(parser):\n     parser.add_argument('--seg_emb', default=False, action='store_true')\n \n     parser.add_argument('--elmo_num', type=int, default=1)\n-    parser.add_argument('--no_elmo_feed_forward', dest='elmo_feed_forward', default=True, action='store_false')\n+    parser.add_argument('--no_elmo_feed_forward', dest='elmo_feed_forward', action='store_false')\n     parser.add_argument('--elmo_dim', type=int, default=1024)\n \n     return parser\n", "before": "parser . add_argument ( '--no_elmo_feed_forward' , dest = 'elmo_feed_forward' , default = True , action = 'store_false' )", "after": "parser . add_argument ( '--no_elmo_feed_forward' , dest = 'elmo_feed_forward' , action = 'store_false' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:default\", 3, 77, 3, 84]], [\"Delete\", [\"=:=\", 3, 84, 3, 85]], [\"Delete\", [\"true:True\", 3, 85, 3, 89]], [\"Delete\", [\"keyword_argument\", 3, 77, 3, 89]], [\"Delete\", [\",:,\", 3, 89, 3, 90]]]"}
{"project": "mopidy-youtube", "commit_sha": "d9fce1e3408bcf10acfc870e1d7f8099f4c1f3cd", "parent_sha": "3e531b4f3295addd4a31347849651b2f33be2da6", "file_path": "mopidy_youtube/backend.py", "project_url": "https://github.com/natumbri/mopidy-youtube", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,7 +52,7 @@ class YouTubeBackend(pykka.ThreadingActor, backend.Backend):\n         youtube.Video.search_results = config['youtube']['search_results']\n         youtube.Playlist.playlist_max_videos = config['youtube']['playlist_max_videos']\n         self.uri_schemes = ['youtube', 'yt']\n-        if youtube.API.test_api_key(self) is False:\n+        if youtube.API.test_api_key() is False:\n             raise exceptions.BackendError('Failed to verify YouTube API key')\n \n \n", "before": "if youtube . API . test_api_key ( self ) is False : raise exceptions . BackendError ( 'Failed to verify YouTube API key' )", "after": "if youtube . API . test_api_key ( ) is False : raise exceptions . BackendError ( 'Failed to verify YouTube API key' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 37, 3, 41]]]"}
{"project": "mopidy-youtube", "commit_sha": "0bce798ddc4fe7e3e8954ad4454f909b8f99d268", "parent_sha": "3e531b4f3295addd4a31347849651b2f33be2da6", "file_path": "mopidy_youtube/backend.py", "project_url": "https://github.com/natumbri/mopidy-youtube", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -52,7 +52,7 @@ class YouTubeBackend(pykka.ThreadingActor, backend.Backend):\n         youtube.Video.search_results = config['youtube']['search_results']\n         youtube.Playlist.playlist_max_videos = config['youtube']['playlist_max_videos']\n         self.uri_schemes = ['youtube', 'yt']\n-        if youtube.API.test_api_key(self) is False:\n+        if youtube.API.test_api_key() is False:\n             raise exceptions.BackendError('Failed to verify YouTube API key')\n \n \n", "before": "if youtube . API . test_api_key ( self ) is False : raise exceptions . BackendError ( 'Failed to verify YouTube API key' )", "after": "if youtube . API . test_api_key ( ) is False : raise exceptions . BackendError ( 'Failed to verify YouTube API key' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 37, 3, 41]]]"}
{"project": "mailman3", "commit_sha": "5c08e3027d42f51608361eb8f4672ccf28d76a79", "parent_sha": "7af22e0d239391cd9f8a49a696486b79632aaa86", "file_path": "src/mailman/rules/administrivia.py", "project_url": "https://github.com/stackexpress-shivam/mailman3", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -74,7 +74,7 @@ class Administrivia:\n         # Search only the first text/plain subpart of the message.  There's\n         # really no good way to find email commands in any other content type.\n         for part in typed_subpart_iterator(msg, 'text', 'plain'):\n-            payload = part.get_payload(decode=True)\n+            payload = part.get_payload()\n             lines = payload.splitlines()\n             # Count lines without using enumerate() because blank lines in the\n             # payload don't count against the maximum examined.\n", "before": "payload = part . get_payload ( decode = True )", "after": "payload = part . get_payload ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:decode\", 3, 40, 3, 46]], [\"Delete\", [\"=:=\", 3, 46, 3, 47]], [\"Delete\", [\"true:True\", 3, 47, 3, 51]], [\"Delete\", [\"keyword_argument\", 3, 40, 3, 51]]]"}
{"project": "sympy", "commit_sha": "90ba3f7a2ab72208cc9f0734fcc3acb661e11780", "parent_sha": "614f39e455d0073ae3689712333109c5b6f4d06d", "file_path": "sympy/combinatorics/perm_groups.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -4099,7 +4099,7 @@ def strong_presentation(G):\n                         f = GroupHomomorphism(G, K_s_act, images)\n \n                         K_act = PermutationGroup([f(g) for g in K.generators])\n-                        success, new_rels = K_s_act._verify(K_act, f.compose(phi, check=False), f(z), d)\n+                        success, new_rels = K_s_act._verify(K_act, f.compose(phi), f(z), d)\n \n                 for n in new_rels:\n                     if not n in rels:\n", "before": "success , new_rels = K_s_act . _verify ( K_act , f . compose ( phi , check = False ) , f ( z ) , d )", "after": "success , new_rels = K_s_act . _verify ( K_act , f . compose ( phi ) , f ( z ) , d )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 81, 3, 82]], [\"Delete\", [\"identifier:check\", 3, 83, 3, 88]], [\"Delete\", [\"=:=\", 3, 88, 3, 89]], [\"Delete\", [\"false:False\", 3, 89, 3, 94]], [\"Delete\", [\"keyword_argument\", 3, 83, 3, 94]]]"}
{"project": "sympy", "commit_sha": "cf7f40bd5162f8e9ab1b4192b35dc0a9f46705f4", "parent_sha": "35d7cd9a5cf9eb1541a296bc9adb77f911a09b42", "file_path": "sympy/printing/latex.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2556,7 +2556,7 @@ def multiline_latex(lhs, rhs, terms_per_line=1, environment=\"align\", use_dots=Fa\n     \\end{eqnarray}\n \n     Using \"IEEEeqnarray\":\n-    >>> print(multiline_latex(x, expr, terms_per_line=2, environment=\"IEEEeqnarray\"))\n+    >>> print(multiline_latex(x, expr, environment=\"IEEEeqnarray\"))\n     \\begin{IEEEeqnarray}{rCl}\n     x & = & e^{i \\alpha} \\nonumber\\\\\n     & & + \\sin{\\left(\\alpha y \\right)} \\nonumber\\\\\n", "before": "\"IEEEeqnarray\" : >> > print ( multiline_latex ( x , expr , terms_per_line = 2 , environment = \"IEEEeqnarray\" ) ) b egin { IEEEeqnarray } { rCl }", "after": "\"IEEEeqnarray\" : >> > print ( multiline_latex ( x , expr , environment = \"IEEEeqnarray\" ) ) b egin { IEEEeqnarray } { rCl }", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:terms_per_line\", 3, 40, 3, 54]], [\"Delete\", [\"=:=\", 3, 54, 3, 55]], [\"Delete\", [\"integer:2\", 3, 55, 3, 56]], [\"Delete\", [\"keyword_argument\", 3, 40, 3, 56]], [\"Delete\", [\",:,\", 3, 56, 3, 57]]]"}
{"project": "sympy", "commit_sha": "30a71b9c4d23ca8564f11ded5be085bea5d7c93c", "parent_sha": "ce3c217ac6be683adc0a03096c1aafcb5a6c0c91", "file_path": "sympy/geometry/tests/test_polygon.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -227,7 +227,7 @@ def test_polygon():\n     assert are_similar(t1, t3)\n     assert are_similar(t2, t3) is False\n     assert t1.is_similar(Point(0, 0)) is False\n-    assert t1.is_similar(t1, t2) is False\n+    assert t1.is_similar(t2) is False\n \n     # Bisectors\n     bisectors = t1.bisectors()\n", "before": "assert t1 . is_similar ( t1 , t2 ) is False", "after": "assert t1 . is_similar ( t2 ) is False", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:t1\", 3, 26, 3, 28]], [\"Delete\", [\",:,\", 3, 28, 3, 29]]]"}
{"project": "2017-10-03-riverclub", "commit_sha": "1ba97b96c82753464d0c52a040b49f8eefc4941c", "parent_sha": "2f27dfa378e01b594656116f713d83b2b8f2edda", "file_path": "setup/swc-installation-test-2.py", "project_url": "https://github.com/CTPUG/2017-10-03-riverclub", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -416,7 +416,7 @@ class CommandDependency (Dependency):\n             p = _subprocess.Popen(\n                 [command] + list(self.version_options), stdin=popen_stdin,\n                 stdout=_subprocess.PIPE, stderr=_subprocess.PIPE,\n-                close_fds=True, shell=False, universal_newlines=True)\n+                universal_newlines=True)\n         except OSError as e:\n             raise DependencyError(\n                 checker=self,\n", "before": "p = _subprocess . Popen ( [ command ] + list ( self . version_options ) , stdin = popen_stdin , stdout = _subprocess . PIPE , stderr = _subprocess . PIPE , close_fds = True , shell = False , universal_newlines = True )", "after": "p = _subprocess . Popen ( [ command ] + list ( self . version_options ) , stdin = popen_stdin , stdout = _subprocess . PIPE , stderr = _subprocess . PIPE , universal_newlines = True )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:close_fds\", 3, 17, 3, 26]], [\"Delete\", [\"=:=\", 3, 26, 3, 27]], [\"Delete\", [\"true:True\", 3, 27, 3, 31]], [\"Delete\", [\"keyword_argument\", 3, 17, 3, 31]], [\"Delete\", [\",:,\", 3, 31, 3, 32]], [\"Delete\", [\"identifier:shell\", 3, 33, 3, 38]], [\"Delete\", [\"=:=\", 3, 38, 3, 39]], [\"Delete\", [\"false:False\", 3, 39, 3, 44]], [\"Delete\", [\"keyword_argument\", 3, 33, 3, 44]], [\"Delete\", [\",:,\", 3, 44, 3, 45]]]"}
{"project": "pi-listen-send", "commit_sha": "80096824a2b534834f054e9c22a073f582ebcdc0", "parent_sha": "1a340e68ec25f338719988184b5fbe99d0da1f1d", "file_path": "src/listener.py", "project_url": "https://github.com/LasaleFamine/pi-listen-send", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ def handler_listen(channel):\n \t\t\tprint ('An error occured')\n \n def main():\n-\tpi_listen(pin, handler_listen)\n+\tpi_listen(handler_listen)\n \n \twhile True:\n \t\t\tpass\n", "before": "pi_listen ( pin , handler_listen )", "after": "pi_listen ( handler_listen )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:pin\", 3, 12, 3, 15]], [\"Delete\", [\",:,\", 3, 15, 3, 16]]]"}
{"project": "InstaPy", "commit_sha": "d8831efb6dd09077e022703182f85995528354f0", "parent_sha": "afdf91122afb01f9fed08958eed1d35457caba95", "file_path": "proxy_extension.py", "project_url": "https://github.com/anyulled/InstaPy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ def create_proxy_extension(proxy):\n \n     dir_path = 'assets/chrome_extensions'\n-    os.makedirs(dir_path, exist_ok=True)\n+    os.makedirs(dir_path)\n     pluginfile = '%s/proxy_auth_%s:%s.zip' % (dir_path, ip, port)\n     with zipfile.ZipFile(pluginfile, 'w') as zp:\n         zp.writestr(\"manifest.json\", manifest_json)\n", "before": "os . makedirs ( dir_path , exist_ok = True )", "after": "os . makedirs ( dir_path )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 2, 25, 2, 26]], [\"Delete\", [\"identifier:exist_ok\", 2, 27, 2, 35]], [\"Delete\", [\"=:=\", 2, 35, 2, 36]], [\"Delete\", [\"true:True\", 2, 36, 2, 40]], [\"Delete\", [\"keyword_argument\", 2, 27, 2, 40]]]"}
{"project": "edx-platform", "commit_sha": "95c240d576f4016d496a90b027329b1e809be701", "parent_sha": "27223ae80f73f693859f542d9406a45f5bc70d00", "file_path": "lms/djangoapps/bulk_email/tasks.py", "project_url": "https://github.com/easy-edx/edx-platform", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -800,7 +800,7 @@ def _submit_for_retry(entry_id, email_id, to_list, global_email_context, current\n         log.exception(u'Task %s: email with id %d caused send_course_email task to fail to retry. To list: %s',\n                       task_id, email_id, [i['email'] for i in to_list])\n         num_failed = len(to_list)\n-        subtask_status.increment(subtask_status, failed=num_failed, state=FAILURE)\n+        subtask_status.increment(failed=num_failed, state=FAILURE)\n         return subtask_status, retry_exc\n \n \n", "before": "subtask_status . increment ( subtask_status , failed = num_failed , state = FAILURE )", "after": "subtask_status . increment ( failed = num_failed , state = FAILURE )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:subtask_status\", 3, 34, 3, 48]], [\"Delete\", [\",:,\", 3, 48, 3, 49]]]"}
{"project": "Pyglet", "commit_sha": "51009f5e2b8924e2c59a8f27882c45a661899165", "parent_sha": "e728b6d4bb1ec542b01734a4174c9e35591e6916", "file_path": "pyglet/ext/model/obj.py", "project_url": "https://github.com/adamlwgriffiths/Pyglet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -131,7 +131,7 @@ class OBJ:\n                 if material is None:\n                     material = Material()\n                 if group is None:\n-                    group = MaterialGroup(self, material)\n+                    group = MaterialGroup(material)\n                     mesh.groups.append(group)\n \n                 # For fan triangulation, remember first and latest vertices\n", "before": "group = MaterialGroup ( self , material )", "after": "group = MaterialGroup ( material )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 43, 3, 47]], [\"Delete\", [\",:,\", 3, 47, 3, 48]]]"}
{"project": "Pyglet", "commit_sha": "53c9928ae8f5253fa4bd6b433bebfa0b8400f3d5", "parent_sha": "386d7dfee0034f9a5467722194e600d2d234fb21", "file_path": "pyglet/text/__init__.py", "project_url": "https://github.com/adamlwgriffiths/Pyglet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,7 +25,7 @@ class Font(object):\n         l = []\n         for c in text:\n             if c not in self.glyphs:\n-                self.glyphs[c] = freetype2.render_char(self.face, c, debug=1)\n+                self.glyphs[c] = freetype2.render_char(self.face, c)\n             l.append(Glyph(self.face, c, self.glyphs[c]))\n         return Text(l)\n \n", "before": "self . glyphs [ c ] = freetype2 . render_char ( self . face , c , debug = 1 )", "after": "self . glyphs [ c ] = freetype2 . render_char ( self . face , c )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 68, 3, 69]], [\"Delete\", [\"identifier:debug\", 3, 70, 3, 75]], [\"Delete\", [\"=:=\", 3, 75, 3, 76]], [\"Delete\", [\"integer:1\", 3, 76, 3, 77]], [\"Delete\", [\"keyword_argument\", 3, 70, 3, 77]]]"}
{"project": "e2end", "commit_sha": "2c38e40213b9c7f07fe2b6c8c5c3f84974f94516", "parent_sha": "3c858a8bdd7798dbe445bcaa0e133d6a508f7fee", "file_path": "data/dstc2_original_split/validate2dstc.py", "project_url": "https://github.com/oplatek/e2end", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -31,7 +31,7 @@ def convert(val_output, outfile):\n                             slots_dict[k] = tmp[k]\n                     goal_nb.append({\"score\": hyp[\"score\"],\n                             \"slots\": slots_dict})\n-        json.dump(data, w, sort_keys=True, indent=4, separators=(',', ': ')) \n+        json.dump(data, w, indent=4, separators=(',', ': ')) \n \n \n if __name__ == \"__main__\":\n", "before": "json . dump ( data , w , sort_keys = True , indent = 4 , separators = ( ',' , ': ' ) )", "after": "json . dump ( data , w , indent = 4 , separators = ( ',' , ': ' ) )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:sort_keys\", 3, 28, 3, 37]], [\"Delete\", [\"=:=\", 3, 37, 3, 38]], [\"Delete\", [\"true:True\", 3, 38, 3, 42]], [\"Delete\", [\"keyword_argument\", 3, 28, 3, 42]], [\"Delete\", [\",:,\", 3, 42, 3, 43]]]"}
{"project": "aes-lac-2018", "commit_sha": "997c1006e3e67e859da1f8b2e43a0c68705fe6d4", "parent_sha": "19f75b9191cbff1a51f428b1ae8ad066f317f1f2", "file_path": "model.py", "project_url": "https://github.com/igormq/aes-lac-2018", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,7 +41,7 @@ class InferenceBatchLogSoftmax(nn.Module):\n     def forward(self, input_):\n         if not self.training:\n             batch_size = input_.size()[0]\n-            return torch.stack([F.log_softmax(input_[i], dim=1) for i in range(batch_size)], 0)\n+            return torch.stack([F.log_softmax(input_[i]) for i in range(batch_size)], 0)\n         else:\n             return input_\n \n", "before": "return torch . stack ( [ F . log_softmax ( input_ [ i ] , dim = 1 ) for i in range ( batch_size ) ] , 0 )", "after": "return torch . stack ( [ F . log_softmax ( input_ [ i ] ) for i in range ( batch_size ) ] , 0 )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 56, 3, 57]], [\"Delete\", [\"identifier:dim\", 3, 58, 3, 61]], [\"Delete\", [\"=:=\", 3, 61, 3, 62]], [\"Delete\", [\"integer:1\", 3, 62, 3, 63]], [\"Delete\", [\"keyword_argument\", 3, 58, 3, 63]]]"}
{"project": "CopyNet", "commit_sha": "635e1ae67b8cc568a7d007166ffb6c516099f874", "parent_sha": "36778775fb2fd5a4068439b872a590e7bb075b3a", "file_path": "nmt/nmt/nmt.py", "project_url": "https://github.com/lspvic/CopyNet", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -97,7 +97,7 @@ def add_arguments(parser):\n \n   # copynet mechanism\n-  parser.add_argument(\"--copynet\", type=\"bool\", type=\"bool\", nargs=\"?\", const=True,\n+  parser.add_argument(\"--copynet\", type=\"bool\", nargs=\"?\", const=True,\n                       default=False,\n                       help=\"Whether to add copynet mechanism.\")\n \n", "before": "parser . add_argument ( \"--copynet\" , type = \"bool\" , type = \"bool\" , nargs = \"?\" , const = True , default = False , help = \"Whether to add copynet mechanism.\" )", "after": "parser . add_argument ( \"--copynet\" , type = \"bool\" , nargs = \"?\" , const = True , default = False , help = \"Whether to add copynet mechanism.\" )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:type\", 2, 49, 2, 53]], [\"Delete\", [\"=:=\", 2, 53, 2, 54]], [\"Delete\", [\"string:\\\"bool\\\"\", 2, 54, 2, 60]], [\"Delete\", [\"keyword_argument\", 2, 49, 2, 60]], [\"Delete\", [\",:,\", 2, 60, 2, 61]]]"}
{"project": "nyt-fec", "commit_sha": "7e275652e6cf8e5300aa06854b426b585debe9b1", "parent_sha": "81c5da974cc2d47c1a9856efcb8f670167f67506", "file_path": "fec/management/commands/full_load_from_rss.py", "project_url": "https://github.com/newsdev/nyt-fec", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -40,7 +40,7 @@ class Command(BaseCommand):\n         while True:\n             print(\"Pulling filings from RSS feed\")\n             #keep looping if an interval is provided, this is mostly for testing\n-            filings = loader.filing_list_from_rss(log)\n+            filings = loader.filing_list_from_rss()\n             if not filings:\n                 print(\"failed to find any new filings in the RSS feed\")\n             else:\n", "before": "filings = loader . filing_list_from_rss ( log )", "after": "filings = loader . filing_list_from_rss ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:log\", 3, 51, 3, 54]]]"}
{"project": "tweepy", "commit_sha": "dd5d1e30d7d980e64065d94411f3bc100eb69fa9", "parent_sha": "d1f2dc240d612a37d926f823b5ae302704b22045", "file_path": "tweepy/models.py", "project_url": "https://github.com/ZNClub-PA-ML-AI/tweepy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -234,7 +234,7 @@ class SearchResults(ResultSet):\n     @classmethod\n     def parse(cls, api, json):\n         metadata = json['search_metadata']\n-        results = SearchResults(metadata.get('max_id'), metadata.get('since_id'))\n+        results = SearchResults()\n         results.refresh_url = metadata.get('refresh_url')\n         results.completed_in = metadata.get('completed_in')\n         results.query = metadata.get('query')\n", "before": "results = SearchResults ( metadata . get ( 'max_id' ) , metadata . get ( 'since_id' ) )", "after": "results = SearchResults ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Move\", [\"argument_list\", 3, 32, 3, 82], [\"):)\", 3, 54, 3, 55], 1], [\"Delete\", [\"identifier:metadata\", 3, 33, 3, 41]], [\"Delete\", [\".:.\", 3, 41, 3, 42]], [\"Delete\", [\"identifier:get\", 3, 42, 3, 45]], [\"Delete\", [\"attribute\", 3, 33, 3, 45]], [\"Delete\", [\"(:(\", 3, 45, 3, 46]], [\"Delete\", [\"string:'max_id'\", 3, 46, 3, 54]], [\"Delete\", [\"argument_list\", 3, 45, 3, 55]], [\"Delete\", [\"call\", 3, 33, 3, 55]], [\"Delete\", [\",:,\", 3, 55, 3, 56]], [\"Delete\", [\"identifier:metadata\", 3, 57, 3, 65]], [\"Delete\", [\".:.\", 3, 65, 3, 66]], [\"Delete\", [\"identifier:get\", 3, 66, 3, 69]], [\"Delete\", [\"attribute\", 3, 57, 3, 69]], [\"Delete\", [\"(:(\", 3, 69, 3, 70]], [\"Delete\", [\"string:'since_id'\", 3, 70, 3, 80]], [\"Delete\", [\"):)\", 3, 80, 3, 81]], [\"Delete\", [\"argument_list\", 3, 69, 3, 81]], [\"Delete\", [\"call\", 3, 57, 3, 81]], [\"Delete\", [\"):)\", 3, 81, 3, 82]]]"}
{"project": "GMhil", "commit_sha": "dc319382ff9f0422dcd03efb9ad73a4904e89068", "parent_sha": "6b1813cd26c0dbcdf8ebc7c4819c7dc6d07eabda", "file_path": "haas/server.py", "project_url": "https://github.com/gfaline/GMhil", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ def project(projectname):\n     if request.method == 'PUT':\n         return api.project_create(projectname, request.form['groupname'])\n     else: # DELETE\n-        return api.project_delete(projectname, groupname)\n+        return api.project_delete(projectname)\n \n @app.route('/project/<projectname>/deploy', methods=['POST'])\n @api_function\n", "before": "return api . project_delete ( projectname , groupname )", "after": "return api . project_delete ( projectname )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 46, 3, 47]], [\"Delete\", [\"identifier:groupname\", 3, 48, 3, 57]]]"}
{"project": "erpnext-v7", "commit_sha": "06f432f4c752b2ffe54a719fc931907248330f67", "parent_sha": "09dba5cf1da2dc2e1977668bf0e418910c1557c7", "file_path": "erpnext/stock/doctype/valuation_control/valuation_control.py", "project_url": "https://github.com/YefriTavarez/erpnext-v7", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -108,7 +108,7 @@ class DocType:\n \t\t\t\tif not prev_sle:\n \t\t\t\t\treturn 0.0\n \t\t\t\tfcfs_stack = eval(prev_sle.get('fcfs_stack', '[]'))\n-\t\t\t\tin_rate = fcfs_stack and self.get_fifo_rate(fcfs_stack, qty) or 0\n+\t\t\t\tin_rate = fcfs_stack and self.get_fifo_rate(fcfs_stack) or 0\n \t\telif val_method == 'Moving Average':\n \t\t\tprev_sle = bin_obj.get_prev_sle(posting_date, posting_time)\n \t\t\tin_rate = prev_sle and prev_sle.get('valuation_rate', 0) or 0\n", "before": "in_rate = fcfs_stack and self . get_fifo_rate ( fcfs_stack , qty ) or 0", "after": "in_rate = fcfs_stack and self . get_fifo_rate ( fcfs_stack ) or 0", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 59, 3, 60]], [\"Delete\", [\"identifier:qty\", 3, 61, 3, 64]]]"}
{"project": "Cura", "commit_sha": "66fc85c6b2afdedf238af675477a2b1f7f149642", "parent_sha": "1e23141b182998a59135e8529783125e9c6c2fff", "file_path": "plugins/3MFReader/ThreeMFReader.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ class ThreeMFReader(MeshReader):\n                 rotation.setByRotationAxis(-0.5 * math.pi, Vector(1, 0, 0))\n \n                 # TODO: We currently do not check for normals and simply recalculate them.\n-                mesh_builder.calculateNormals(flip = True)\n+                mesh_builder.calculateNormals()\n                 mesh_builder.setFileName(file_name)\n                 node.setMeshData(mesh_builder.build().getTransformed(rotation))\n                 node.setSelectable(True)\n", "before": "mesh_builder . calculateNormals ( flip = True )", "after": "mesh_builder . calculateNormals ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:flip\", 3, 47, 3, 51]], [\"Delete\", [\"=:=\", 3, 52, 3, 53]], [\"Delete\", [\"true:True\", 3, 54, 3, 58]], [\"Delete\", [\"keyword_argument\", 3, 47, 3, 58]]]"}
{"project": "NIPAP", "commit_sha": "5d8ce3c1abccc47e4d18e8d083f5ba41391d3039", "parent_sha": "af8b8d1a77827acb97f5f7dbfca9f3d84ba451b7", "file_path": "nipap/nipap/xmlrpc.py", "project_url": "https://github.com/fredsod/NIPAP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -533,7 +533,7 @@ class NipapXMLRPC:\n         try:\n             res = self.nip.smart_search_pool(args.get('auth'),\n                     args.get('query_string'), args.get('search_options') or {},\n-                    args.get('extra_query', {}))\n+                    args.get('extra_query'))\n \n             # fugly cast from large numbers to string to deal with XML-RPC\n             for pool in res['result']:\n", "before": "res = self . nip . smart_search_pool ( args . get ( 'auth' ) , args . get ( 'query_string' ) , args . get ( 'search_options' ) or { } , args . get ( 'extra_query' , { } ) )", "after": "res = self . nip . smart_search_pool ( args . get ( 'auth' ) , args . get ( 'query_string' ) , args . get ( 'search_options' ) or { } , args . get ( 'extra_query' ) )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 43, 3, 44]], [\"Delete\", [\"{:{\", 3, 45, 3, 46]], [\"Delete\", [\"}:}\", 3, 46, 3, 47]], [\"Delete\", [\"dictionary\", 3, 45, 3, 47]]]"}
{"project": "OpenTidalFarm", "commit_sha": "000656cfdeedb190e5c3e5a6a01cdba10d5157b4", "parent_sha": "8ec25ab6539afc3a40d691d131ce1ddb73196139", "file_path": "opentidalfarm/turbine_cache.py", "project_url": "https://github.com/baba-mpe/OpenTidalFarm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -103,7 +103,7 @@ class TurbineCache(dict):\n             for i in xrange(len(self._parameters[\"friction\"])):\n                 position_cpy = [self._parameters[\"position\"][i]]\n                 friction_cpy = [self._parameters[\"friction\"][i]]\n-                turbine = TurbineFunction(self, self, self._function_space,\n+                turbine = TurbineFunction(self, self._function_space,\n                                           self._specification)\n                 tf = turbine()\n                 self[\"turbine_field_individual\"].append(tf)\n", "before": "turbine = TurbineFunction ( self , self , self . _function_space , self . _specification )", "after": "turbine = TurbineFunction ( self , self . _function_space , self . _specification )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 49, 3, 53]], [\"Delete\", [\",:,\", 3, 53, 3, 54]]]"}
{"project": "OpenTidalFarm", "commit_sha": "d4a01e48b4efa70d3705047930dd3e4027ab55a2", "parent_sha": "fa6239cad6d1e98c4e373cc613dc047a95e9933b", "file_path": "test_mms_wave_strong_dirichlet/sw.py", "project_url": "https://github.com/baba-mpe/OpenTidalFarm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -14,7 +14,7 @@ def error(config):\n   state = Function(config.function_space)\n   state.interpolate(SinusoidalInitialCondition(config)())\n \n-  sw_model.sw_solve(config.function_space, config, state, annotate=False)\n+  sw_model.sw_solve(config, state, annotate=False)\n \n   analytic_sol = Expression((\"eta0*sqrt(g*depth)*cos(k*x[0]-sqrt(g*depth)*k*t)\", \\\n                              \"0\", \\\n", "before": "sw_model . sw_solve ( config . function_space , config , state , annotate = False )", "after": "sw_model . sw_solve ( config , state , annotate = False )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Move\", [\"argument_list\", 3, 20, 3, 74], [\"identifier:config\", 3, 21, 3, 27], 1], [\"Delete\", [\".:.\", 3, 27, 3, 28]], [\"Delete\", [\"identifier:function_space\", 3, 28, 3, 42]], [\"Delete\", [\"attribute\", 3, 21, 3, 42]], [\"Delete\", [\"identifier:config\", 3, 44, 3, 50]], [\"Delete\", [\",:,\", 3, 50, 3, 51]]]"}
{"project": "flocker", "commit_sha": "4c98bf71a888c7ee6a377009fc3d797eca0048b1", "parent_sha": "e1e7c484b3815e9b1e1c4333408186d3677d77b9", "file_path": "flocker/node/functional/test_docker.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -394,7 +394,7 @@ CMD sh -c \"trap \\\"\\\" 2; sleep 3\"\n         name = random_name()\n-        d = self.start_container(name, image_name=u\"busybox\")\n+        d = self.start_container(name)\n \n         def started(client):\n             deferred_units = client.list()\n", "before": "d = self . start_container ( name , image_name = u\"busybox\" )", "after": "d = self . start_container ( name )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 1, 38, 1, 39]], [\"Delete\", [\"identifier:image_name\", 1, 40, 1, 50]], [\"Delete\", [\"=:=\", 1, 50, 1, 51]], [\"Delete\", [\"string:u\\\"busybox\\\"\", 1, 51, 1, 61]], [\"Delete\", [\"keyword_argument\", 1, 40, 1, 61]]]"}
{"project": "flocker", "commit_sha": "b86895fbe089929a14aac7ce9a162d86900a770f", "parent_sha": "7fb87878ad5e09712cc6b1738a1af012c729d04b", "file_path": "flocker/node/functional/test_docker.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -107,7 +107,7 @@ class GenericDockerClientTests(TestCase):\n-        client = DockerClient(base_url=u'unix://var/run/docker.sock')\n+        client = DockerClient()\n         self.assertEqual(client._client.base_url,\n                          u'http+unix://var/run/docker.sock')\n \n", "before": "client = DockerClient ( base_url = u'unix://var/run/docker.sock' )", "after": "client = DockerClient ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:base_url\", 0, 31, 0, 39]], [\"Delete\", [\"=:=\", 0, 39, 0, 40]], [\"Delete\", [\"string:u'unix://var/run/docker.sock'\", 0, 40, 0, 69]], [\"Delete\", [\"keyword_argument\", 0, 31, 0, 69]]]"}
{"project": "beets", "commit_sha": "8773d958c1b591773e3328b3bcc456442a48e794", "parent_sha": "b53798aaf95090f638321088fc8091da6e49a895", "file_path": "beets/art.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -194,4 +194,4 @@ def clear(log, lib, query):\n     log.info(u'Clearing album art from {0} items', len(items))\n     for item in items:\n         log.debug(u'Clearing art for {0}', item)\n-        item.try_write(path=item.path, tags={'images': None})\n+        item.try_write(tags={'images': None})\n", "before": "item . try_write ( path = item . path , tags = { 'images' : None } )", "after": "item . try_write ( tags = { 'images' : None } )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:path\", 3, 24, 3, 28]], [\"Delete\", [\"=:=\", 3, 28, 3, 29]], [\"Delete\", [\"identifier:item\", 3, 29, 3, 33]], [\"Delete\", [\".:.\", 3, 33, 3, 34]], [\"Delete\", [\"identifier:path\", 3, 34, 3, 38]], [\"Delete\", [\"attribute\", 3, 29, 3, 38]], [\"Delete\", [\"keyword_argument\", 3, 24, 3, 38]], [\"Delete\", [\",:,\", 3, 38, 3, 39]]]"}
{"project": "beets", "commit_sha": "9e27c9e5ac54bd9161285b45646a4789b8a69952", "parent_sha": "17681145c2a78d34cd6fa733fc4762ff88b2f989", "file_path": "test/test_convert.py", "project_url": "https://github.com/tigranl/beets", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -185,7 +185,7 @@ class ConvertCliTest(unittest.TestCase, TestHelper, ConvertCommand):\n             image_data = f.read()\n \n         with control_stdin('y'):\n-            self.run_convert(self.item.path)\n+            self.run_convert()\n         converted = os.path.join(self.convert_dest, 'converted.mp3')\n         mediafile = MediaFile(converted)\n         self.assertEqual(mediafile.images[0].data, image_data)\n", "before": "self . run_convert ( self . item . path )", "after": "self . run_convert ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 30, 3, 34]], [\"Delete\", [\".:.\", 3, 34, 3, 35]], [\"Delete\", [\"identifier:item\", 3, 35, 3, 39]], [\"Delete\", [\"attribute\", 3, 30, 3, 39]], [\"Delete\", [\".:.\", 3, 39, 3, 40]], [\"Delete\", [\"identifier:path\", 3, 40, 3, 44]], [\"Delete\", [\"attribute\", 3, 30, 3, 44]]]"}
{"project": "django-ratings", "commit_sha": "e671646680a28d092bdb78ce4bb5e015fe7cd5b2", "parent_sha": "d3d5bb1a14f4701ed1a24c386e077c590963f3ca", "file_path": "djangoratings/__init__.py", "project_url": "https://github.com/eliksir/django-ratings", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -200,7 +200,7 @@ class RatingManager(object):\n \n     def get_content_type(self):\n         if self.content_type is None:\n-            self.content_type = ContentType.objects.get_for_model(self.instance,)\n+            self.content_type = ContentType.objects.get_for_model(self.instance)\n         return self.content_type\n \n class RatingCreator(object):\n", "before": "self . content_type = ContentType . objects . get_for_model ( self . instance , )", "after": "self . content_type = ContentType . objects . get_for_model ( self . instance )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 80, 3, 81]]]"}
{"project": "spaCy", "commit_sha": "dc61056183bb84ca90b5ffb6a07f92d8bfaad394", "parent_sha": "18eaa44835c7a096d3259404e92e946f3a8d505e", "file_path": "examples/parallel_parse.py", "project_url": "https://github.com/CompanyBook/spaCy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ def save_parses(batch_id, input_, out_dir, n_threads, batch_size):\n     if path.exists(out_loc):\n         return None\n     print('Batch', batch_id)\n-    nlp = spacy.en.English(parser=False)\n+    nlp = spacy.en.English()\n     nlp.matcher = None\n     with open(out_loc, 'wb') as file_:\n         texts = (strip_meta(text) for text in input_)\n", "before": "nlp = spacy . en . English ( parser = False )", "after": "nlp = spacy . en . English ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:parser\", 3, 28, 3, 34]], [\"Delete\", [\"=:=\", 3, 34, 3, 35]], [\"Delete\", [\"false:False\", 3, 35, 3, 40]], [\"Delete\", [\"keyword_argument\", 3, 28, 3, 40]]]"}
{"project": "h", "commit_sha": "661e1934a70354cf0e302069cb081e5a735966d6", "parent_sha": "8cc17ddde452ad5d2141a0903b045292df72eb24", "file_path": "h/api/storage.py", "project_url": "https://github.com/project-star/h", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -135,7 +135,7 @@ def _prepare(request, annotation):\n     fetcher = partial(fetch_annotation, request)\n-    transform.set_group_if_reply(request, annotation, fetcher=fetcher)\n+    transform.set_group_if_reply(annotation, fetcher=fetcher)\n     transform.insert_group_if_none(annotation)\n     transform.set_group_permissions(annotation)\n \n", "before": "transform . set_group_if_reply ( request , annotation , fetcher = fetcher )", "after": "transform . set_group_if_reply ( annotation , fetcher = fetcher )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:request\", 1, 34, 1, 41]], [\"Delete\", [\",:,\", 1, 41, 1, 42]]]"}
{"project": "plyer", "commit_sha": "8518547a39c05699319bfd932f71a23409bffd50", "parent_sha": "7d6625e0a4bde57f4b83c55ed3365a3a8d240d4e", "file_path": "examples/bluetooth/main.py", "project_url": "https://github.com/elvis124/plyer", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -34,7 +34,7 @@ class BluetoothInterface(BoxLayout):\n     text = \"Bluetooth: \"\n \n     def get_info(self):\n-        self.info = str(self.bluetooth.info, 'utf-8')\n+        self.info = str(self.bluetooth.info)\n \n \n class BluetoothApp(App):\n", "before": "self . info = str ( self . bluetooth . info , 'utf-8' )", "after": "self . info = str ( self . bluetooth . info )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 44, 3, 45]], [\"Delete\", [\"string:'utf-8'\", 3, 46, 3, 53]]]"}
{"project": "salt", "commit_sha": "0ca44494d163a227c723a75beda00aac82ac5d8e", "parent_sha": "5b7cc65b03a7e7fb38fc4633d2fd3d85a60b6d7d", "file_path": "salt/modules/iptables.py", "project_url": "https://github.com/kraney/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1234,7 +1234,7 @@ def _parser():\n     ## sctp\n     add_arg('--chunk-types', dest='chunk-types', action='append')\n     ## set\n-    add_arg('--match-set', dest='match-set', action='append', nargs=2)\n+    add_arg('--match-set', dest='match-set', action='append')\n     add_arg('--return-nomatch', dest='return-nomatch', action='append')\n     add_arg('--update-counters', dest='update-counters', action='append')\n     add_arg('--update-subcounters', dest='update-subcounters', action='append')\n", "before": "add_arg ( '--match-set' , dest = 'match-set' , action = 'append' , nargs = 2 )", "after": "add_arg ( '--match-set' , dest = 'match-set' , action = 'append' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 61, 3, 62]], [\"Delete\", [\"identifier:nargs\", 3, 63, 3, 68]], [\"Delete\", [\"=:=\", 3, 68, 3, 69]], [\"Delete\", [\"integer:2\", 3, 69, 3, 70]], [\"Delete\", [\"keyword_argument\", 3, 63, 3, 70]]]"}
{"project": "spiderfoot", "commit_sha": "fa3c58d0208838ac357bcfea521259f5d6d0a51f", "parent_sha": "771a9a769a7fc46f32d6dc0eb18856617799905d", "file_path": "modules/sfp_leakix.py", "project_url": "https://github.com/smicallef/spiderfoot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -69,7 +69,7 @@ class sfp_leakix(SpiderFootPlugin):\n     # Parse API response\n     def parseAPIResponse(self, res):\n         if res['code'] == '404':\n-            self.sf.debug(\"Host not found\", False)\n+            self.sf.debug(\"Host not found\")\n             return None\n \n         # Future proofing - LeakIX does not implement rate limiting\n", "before": "self . sf . debug ( \"Host not found\" , False )", "after": "self . sf . debug ( \"Host not found\" )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 43, 3, 44]], [\"Delete\", [\"false:False\", 3, 45, 3, 50]]]"}
{"project": "pritunl", "commit_sha": "816f3c07b8d756b9be93e67af472b3bc26dc7319", "parent_sha": "8a652fc2e4840eee9619dff8bfb032fb5d94cf5d", "file_path": "pritunl/cache.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -24,7 +24,7 @@ class Cache:\n             return\n         ttl = self._data[key]['ttl']\n         if ttl and int(time.time()) > ttl:\n-            self.remove(self, key)\n+            self.remove(key)\n             return True\n         return False\n \n", "before": "self . remove ( self , key )", "after": "self . remove ( key )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 25, 3, 29]], [\"Delete\", [\",:,\", 3, 29, 3, 30]]]"}
{"project": "pritunl", "commit_sha": "57fd85149e636b2cd219348c3b9a9fee3a196c1f", "parent_sha": "327197f38fb2e128367ad18bd77952b9eaa4f7f2", "file_path": "pritunl/event.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -74,6 +74,6 @@ class Event(CacheObject):\n                     new_event = True\n                     break\n             if new_event:\n-                return cls.get_events(cursor, False, False)\n+                return cls.get_events(cursor, False)\n \n         return events\n", "before": "return cls . get_events ( cursor , False , False )", "after": "return cls . get_events ( cursor , False )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 52, 3, 53]], [\"Delete\", [\"false:False\", 3, 54, 3, 59]]]"}
{"project": "lektor", "commit_sha": "5e1bd1de56652279a54bb1261a7fdd19c8311813", "parent_sha": "8b1262707a3da235a5320aeb01f12d49ec4096e9", "file_path": "lektor/project.py", "project_url": "https://github.com/lektor/lektor", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -96,7 +96,7 @@ class Project(object):\n     def get_output_path(self):\n         \"\"\"The path where output files are stored.\"\"\"\n         config = self.open_config()\n-        output_path = config.get('project.output_path', '')\n+        output_path = config.get('project.output_path')\n         if output_path:\n             return os.path.join(self.tree, os.path.normpath(output_path))\n \n", "before": "output_path = config . get ( 'project.output_path' , '' )", "after": "output_path = config . get ( 'project.output_path' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 55, 3, 56]], [\"Delete\", [\"string:''\", 3, 57, 3, 59]]]"}
{"project": "dups", "commit_sha": "a1bbbe03481fe9285e993752252b1e8d86529f85", "parent_sha": "df507b124c3b87bd239bfe31cc7f73bbbc2aa43b", "file_path": "dups/__main__.py", "project_url": "https://github.com/linuxwhatelse/dups", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ def get_arg_parser():\n                                  help='Use this config file instead.')\n \n     subparser = parsers['main'].add_subparsers(\n-        title='Commands', dest='command', metavar='<command>', required=True)\n+        title='Commands', dest='command', metavar='<command>')\n \n     # --- Create backups ---\n     parsers['backup'] = subparser.add_parser('backup', aliases=['b'],\n", "before": "help = 'Use this config file instead.' ) subparser = parsers [ 'main' ] . add_subparsers ( title = 'Commands' , dest = 'command' , metavar = '<command>' , required = True )", "after": "help = 'Use this config file instead.' ) subparser = parsers [ 'main' ] . add_subparsers ( title = 'Commands' , dest = 'command' , metavar = '<command>' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 62, 3, 63]], [\"Delete\", [\"identifier:required\", 3, 64, 3, 72]], [\"Delete\", [\"=:=\", 3, 72, 3, 73]], [\"Delete\", [\"true:True\", 3, 73, 3, 77]], [\"Delete\", [\"keyword_argument\", 3, 64, 3, 77]]]"}
{"project": "pritunl", "commit_sha": "aed4e1b3063b1b16566029e56a6a2152a4d5df49", "parent_sha": "7cddaaccf14f7190345bc202de650f3169d64826", "file_path": "pritunl/organization.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -345,7 +345,7 @@ class Organization(MongoObject):\n \n             if not org:\n                 org = queue.reserve('queued_org', block=block, type=type,\n-                    block=block, **kwargs)\n+                    **kwargs)\n \n                 if org:\n                     logger.debug('Reserved queued org', 'organization',\n", "before": "org = queue . reserve ( 'queued_org' , block = block , type = type , block = block , ** kwargs )", "after": "org = queue . reserve ( 'queued_org' , block = block , type = type , ** kwargs )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:block\", 3, 21, 3, 26]], [\"Delete\", [\"=:=\", 3, 26, 3, 27]], [\"Delete\", [\"identifier:block\", 3, 27, 3, 32]], [\"Delete\", [\"keyword_argument\", 3, 21, 3, 32]], [\"Delete\", [\",:,\", 3, 32, 3, 33]]]"}
{"project": "pritunl", "commit_sha": "a16c4c0474d6e21df4c2e2eb3bf674cefbd2edf2", "parent_sha": "b0fe759765a92065f066236f35b7670257fc0339", "file_path": "pritunl/handlers/auth.py", "project_url": "https://github.com/tomzhang/pritunl", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -42,7 +42,7 @@ def auth_put():\n         email_api_key = flask.request.json['email_api_key']\n         settings.app.email_api_key = email_api_key or None\n     if settings_commit:\n-        settings.commit(settings.changed)\n+        settings.commit()\n \n     administrator.commit(administrator.changed)\n \n", "before": "settings . commit ( settings . changed )", "after": "settings . commit ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:settings\", 3, 25, 3, 33]], [\"Delete\", [\".:.\", 3, 33, 3, 34]], [\"Delete\", [\"identifier:changed\", 3, 34, 3, 41]], [\"Delete\", [\"attribute\", 3, 25, 3, 41]]]"}
{"project": "openstates", "commit_sha": "378f65bf99610bf46b3b2607f506fdfd2153325e", "parent_sha": "74187967a3772e1be650dbe5b42e66fc75ae32b2", "file_path": "openstates/ky/legislators.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -92,7 +92,7 @@ class KYLegislatorScraper(LegislatorScraper):\n \n             if member.has_key('additionalRoles'):\n                 for role in member['additionalRoles']:\n-                    leg.add_role(role, year, member['party'])\n+                    leg.add_role(role, year)\n \n             self.save_legislator(leg)\n \n", "before": "leg . add_role ( role , year , member [ 'party' ] )", "after": "leg . add_role ( role , year )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 44, 3, 45]], [\"Delete\", [\"identifier:member\", 3, 46, 3, 52]], [\"Delete\", [\"[:[\", 3, 52, 3, 53]], [\"Delete\", [\"string:'party'\", 3, 53, 3, 60]], [\"Delete\", [\"]:]\", 3, 60, 3, 61]], [\"Delete\", [\"subscript\", 3, 46, 3, 61]]]"}
{"project": "website", "commit_sha": "a970ad6ccdbb1df1d9a83d57939abd72ad7b1a94", "parent_sha": "9e449dc793386406f7a0c92a17f6afbb7fec19cc", "file_path": "website_event_register_free_with_sale/controllers/website_sale.py", "project_url": "https://github.com/yuanerp/website", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -53,7 +53,7 @@ class WebsiteSale(website_sale):\n             values = self.checkout_values(data={'shipping_id': -1})\n             return request.website.render(\"website_sale.checkout\", values)\n         else:\n-            return super(WebsiteSale, self).checkout(self, **post)\n+            return super(WebsiteSale, self).checkout(**post)\n \n     @http.route(['/shop/confirm_order'], type='http', auth=\"public\",\n                 website=True)\n", "before": "else : return super ( WebsiteSale , self ) . checkout ( self , ** post )", "after": "else : return super ( WebsiteSale , self ) . checkout ( ** post )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 54, 3, 58]], [\"Delete\", [\",:,\", 3, 58, 3, 59]]]"}
{"project": "spyne", "commit_sha": "8ea14809c65d1f40ae26bb432617caa3184415c1", "parent_sha": "6c031ac44722476340736ccd3a69744c4890d008", "file_path": "src/soaplib/serializers/enum.py", "project_url": "https://github.com/duixteam/spyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -25,7 +25,7 @@ class EnumBase(SimpleType):\n         if name is None:\n             name = cls.get_type_name()\n \n-        SimpleType.to_xml(cls, str(value), tns, parent_elt, name)\n+        SimpleType.to_xml(str(value), tns, parent_elt, name)\n \n     @classmethod\n     @nillable_element\n", "before": "SimpleType . to_xml ( cls , str ( value ) , tns , parent_elt , name )", "after": "SimpleType . to_xml ( str ( value ) , tns , parent_elt , name )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:cls\", 3, 27, 3, 30]], [\"Delete\", [\",:,\", 3, 30, 3, 31]]]"}
{"project": "spyne", "commit_sha": "7455425341ac7f8a7f850104169300adb9afa999", "parent_sha": "d68f5f7693bb116967db27d3a0f0b984d8f9eff7", "file_path": "src/rpclib/protocol/xml/_base.py", "project_url": "https://github.com/duixteam/spyne", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -238,7 +238,7 @@ class XmlObject(ProtocolBase):\n \n         if ctx.out_error is not None:\n             # FIXME: There's no way to alter soap response headers for the user.\n-            tmp_elt = etree.Element(ctx.out_document, 'punk')\n+            tmp_elt = etree.Element('punk')\n             self.to_parent_element(ctx.out_error.__class__, ctx.out_error,\n                                     self.app.interface.get_tns(), tmp_elt)\n             ctx.out_document = tmp_elt[0]\n", "before": "tmp_elt = etree . Element ( ctx . out_document , 'punk' )", "after": "tmp_elt = etree . Element ( 'punk' )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:ctx\", 3, 37, 3, 40]], [\"Delete\", [\".:.\", 3, 40, 3, 41]], [\"Delete\", [\"identifier:out_document\", 3, 41, 3, 53]], [\"Delete\", [\"attribute\", 3, 37, 3, 53]], [\"Delete\", [\",:,\", 3, 53, 3, 54]]]"}
{"project": "cpython", "commit_sha": "46192add32436f2e2399da9e03f2bc5b5d5e0ecf", "parent_sha": "6fcd729665a1208dd36be7e4586082b01337de27", "file_path": "Lib/test/test_compileall.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -132,7 +132,7 @@ class CommandLineTests(unittest.TestCase):\n \n     def assertRunNotOK(self, *args, **env_vars):\n         rc, out, err = script_helper.assert_python_failure(\n-                         '-S', '-m', 'compileall', *args, **env_vars)\n+                         '-m', 'compileall', *args, **env_vars)\n         return rc, out, err\n \n     def assertCompiled(self, fn):\n", "before": "rc , out , err = script_helper . assert_python_failure ( '-S' , '-m' , 'compileall' , * args , ** env_vars )", "after": "rc , out , err = script_helper . assert_python_failure ( '-m' , 'compileall' , * args , ** env_vars )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"string:'-S'\", 3, 26, 3, 30]], [\"Delete\", [\",:,\", 3, 30, 3, 31]]]"}
{"project": "cpython", "commit_sha": "beddbac181b86b6619354f7b844ff2b49ab297cf", "parent_sha": "dd6b3ae826b152fcf80b8746d4c185b85ce186a1", "file_path": "Lib/test/test_array.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ class ArraySubclass(array.array):\n \n class ArraySubclassWithKwargs(array.array):\n     def __init__(self, typecode, newarg=None):\n-        array.array.__init__(self, typecode)\n+        array.array.__init__(self)\n \n tests = [] # list to accumulate all tests\n typecodes = \"ubBhHiIlLfd\"\n", "before": "array . array . __init__ ( self , typecode )", "after": "array . array . __init__ ( self )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 34, 3, 35]], [\"Delete\", [\"identifier:typecode\", 3, 36, 3, 44]]]"}
{"project": "cpython", "commit_sha": "7d00a405a1035c4925accb469d39c24a7f9cb850", "parent_sha": "7777a1ae8a383004eeea2eeb4519534e82a2e65c", "file_path": "Lib/random.py", "project_url": "https://github.com/OffByOneStudios/cpython", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -114,7 +114,7 @@ class Random(_random.Random):\n         if version == 2:\n             if isinstance(a, (str, bytes, bytearray)):\n                 if isinstance(a, str):\n-                    a = a.encode(\"utf8\")\n+                    a = a.encode()\n                 a += _sha512(a).digest()\n                 a = int.from_bytes(a, 'big')\n \n", "before": "a = a . encode ( \"utf8\" )", "after": "a = a . encode ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"string:\\\"utf8\\\"\", 3, 34, 3, 40]]]"}
{"project": "coa_tools", "commit_sha": "ed8e9de21b0440fece53bddc7206d73a11fb3628", "parent_sha": "d60a034de3559ea03205a022b48ae6c0e62d4c7e", "file_path": "Blender/coa_tools/operators/edit_mesh.py", "project_url": "https://github.com/tynrare/coa_tools", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -286,7 +286,7 @@ class Fill(bpy.types.Operator):\n         ### assign texture to uv map\r\n         if img != None:\r\n             bpy.ops.object.mode_set(mode=\"OBJECT\")\r\n-            assign_tex_to_uv(self,img,start_obj.data.uv_textures.active)\r\n+            assign_tex_to_uv(img,start_obj.data.uv_textures.active)\r\n             bpy.ops.object.mode_set(mode=\"EDIT\")\r\n         \r\n         bpy.ops.ed.undo_push(message=\"Grid Fill\")\r\n", "before": "assign_tex_to_uv ( self , img , start_obj . data . uv_textures . active )", "after": "assign_tex_to_uv ( img , start_obj . data . uv_textures . active )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 30, 3, 34]], [\"Delete\", [\",:,\", 3, 34, 3, 35]]]"}
{"project": "pyload", "commit_sha": "7885da4c2908b8bb7660275d071f1ed426dbbc5d", "parent_sha": "3f3dd7b0fee3454da489cf35aef8a0cdd46ae562", "file_path": "pyload/api/DownloadApi.py", "project_url": "https://github.com/SeppPenner/pyload", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -63,7 +63,7 @@ class DownloadApi(ApiComponent):\n             folder = \"\"\n \n         pid = self.createPackage(name, folder, root, password, paused=paused)\n-        self.addLinks(pid, links, paused)\n+        self.addLinks(pid, links)\n \n         return pid\n \n", "before": "self . addLinks ( pid , links , paused )", "after": "self . addLinks ( pid , links )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 33, 3, 34]], [\"Delete\", [\"identifier:paused\", 3, 35, 3, 41]]]"}
{"project": "pulp_rpm", "commit_sha": "a9fc91d246f649af1230a06b2431db3c712c06c5", "parent_sha": "83022ae7b15adda3ad2c882a96c5c5c462a8c3d1", "file_path": "plugins/pulp_rpm/plugins/distributors/yum/publish.py", "project_url": "https://github.com/pcreech/pulp_rpm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -449,7 +449,7 @@ class PublishDrpmStep(UnitPublishStep):\n         # skip if there are no DRPMs.\n-        if self._get_total([TYPE_ID_DRPM]) == 0:\n+        if self._get_total() == 0:\n             return True\n \n         return super(PublishDrpmStep, self).is_skipped()\n", "before": "if self . _get_total ( [ TYPE_ID_DRPM ] ) == 0 : return True", "after": "if self . _get_total ( ) == 0 : return True", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"[:[\", 1, 28, 1, 29]], [\"Delete\", [\"identifier:TYPE_ID_DRPM\", 1, 29, 1, 41]], [\"Delete\", [\"]:]\", 1, 41, 1, 42]], [\"Delete\", [\"list\", 1, 28, 1, 42]]]"}
{"project": "pulp_rpm", "commit_sha": "ce2db183188734e9d201f314d3cf843fe7764eba", "parent_sha": "91db4f127c6800c36f2122dc19ce25be8355096a", "file_path": "plugins/pulp_rpm/plugins/importers/yum/repomd/packages.py", "project_url": "https://github.com/pcreech/pulp_rpm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -105,7 +105,7 @@ def element_to_raw_xml(element):\n     strip_ns(element)\n     tree = ElementTree(element)\n     io = StringIO()\n-    tree.write(io, xml_declaration=False)\n+    tree.write(io)\n     return io.getvalue()\n \n \n", "before": "tree . write ( io , xml_declaration = False )", "after": "tree . write ( io )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 18, 3, 19]], [\"Delete\", [\"identifier:xml_declaration\", 3, 20, 3, 35]], [\"Delete\", [\"=:=\", 3, 35, 3, 36]], [\"Delete\", [\"false:False\", 3, 36, 3, 41]], [\"Delete\", [\"keyword_argument\", 3, 20, 3, 41]]]"}
{"project": "petaldata-python", "commit_sha": "27f4279be76a8fed8adca73355b047b74750ee88", "parent_sha": "8b5288e2a82e8a3392c0f9ddccdca3cb668ccc23", "file_path": "petaldata/resource/stripe/reports/abstract_stripe_report.py", "project_url": "https://github.com/petaldata/petaldata-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ class AbstractStripeReport(object):\n \n     self._gsheet_client = None\n \n-    self.end_timestamp = self.setup_time(end_time,tz=tz)\n+    self.end_timestamp = self.setup_time(end_time)\n \n   \n   @staticmethod\n", "before": "self . end_timestamp = self . setup_time ( end_time , tz = tz )", "after": "self . end_timestamp = self . setup_time ( end_time )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 50, 3, 51]], [\"Delete\", [\"identifier:tz\", 3, 51, 3, 53]], [\"Delete\", [\"=:=\", 3, 53, 3, 54]], [\"Delete\", [\"identifier:tz\", 3, 54, 3, 56]], [\"Delete\", [\"keyword_argument\", 3, 51, 3, 56]]]"}
{"project": "genologics", "commit_sha": "564cf105ea62a4ad398b81983d529a7d2abd8893", "parent_sha": "675e923261bbcbec1a34edeb1984d75231f94166", "file_path": "scripts/qc_amount_calculation.py", "project_url": "https://github.com/BigelowLab/genologics", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ def main(lims,args,epp_logger):\n     udf_to_check = 'Conc. Units'\n     value_to_check = 'ng/ul'\n     inputs = p.all_inputs(unique=True)\n-    correct_unit_inputs = check_udf(inputs,udf_to_check,value_to_check,exit=True)\n+    correct_unit_inputs = check_udf(inputs,udf_to_check,value_to_check)\n \n     apply_calculations(lims,correct_unit_inputs,'Concentration','*',\n                        'Volume (ul)','Amount (ng)',epp_logger)\n", "before": "correct_unit_inputs = check_udf ( inputs , udf_to_check , value_to_check , exit = True )", "after": "correct_unit_inputs = check_udf ( inputs , udf_to_check , value_to_check )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 71, 3, 72]], [\"Delete\", [\"identifier:exit\", 3, 72, 3, 76]], [\"Delete\", [\"=:=\", 3, 76, 3, 77]], [\"Delete\", [\"true:True\", 3, 77, 3, 81]], [\"Delete\", [\"keyword_argument\", 3, 72, 3, 81]]]"}
{"project": "genologics", "commit_sha": "1e064976de52895047eb5d56bb1e845a2e30ce81", "parent_sha": "e42ca8e77b7e529499990e10b94a6a187cc97c65", "file_path": "scripts/epp1.py", "project_url": "https://github.com/BigelowLab/genologics", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -118,7 +118,7 @@ def main(lims, pid, epp_logger):\n \n     if 'Sample volume' in qunatit.udfs.keys(): #and result files....\n         for target_file in target_files:\n-            target_file = qunatit.calculate_concentration(mod, target_file)\n+            target_file = qunatit.calculate_concentration(target_file)\n             try:\n                 target_file.put()\n             except (TypeError, HTTPError) as e:\n", "before": "target_file = qunatit . calculate_concentration ( mod , target_file )", "after": "target_file = qunatit . calculate_concentration ( target_file )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:mod\", 3, 59, 3, 62]], [\"Delete\", [\",:,\", 3, 62, 3, 63]]]"}
{"project": "keras-maskrcnn", "commit_sha": "1c51787d8d8a5e4d08667178428cb99e31143713", "parent_sha": "cb7e6bd7f1a1a50780e029aa4628b30b9a208699", "file_path": "coco.py", "project_url": "https://github.com/dishen12/keras-maskrcnn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -272,7 +272,7 @@ class CocoDataset(utils.Dataset):\n         if info[\"source\"] == \"coco\":\n             return \"http://cocodataset.org/#explore?id={}\".format(info[\"id\"])\n         else:\n-            super(CocoDataset, self).image_reference(self, image_id)\n+            super(CocoDataset, self).image_reference(image_id)\n \n     # The following two functions are from pycocotools with a few changes.\n \n", "before": "super ( CocoDataset , self ) . image_reference ( self , image_id )", "after": "super ( CocoDataset , self ) . image_reference ( image_id )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 54, 3, 58]], [\"Delete\", [\",:,\", 3, 58, 3, 59]]]"}
{"project": "DataProcessingForMaserObservation", "commit_sha": "d479527a018a7c83bfe3e086f49114c78b48d302", "parent_sha": "e5e829ce42f4f6d88337a78ca20dd64e43644a80", "file_path": "code/main.py", "project_url": "https://github.com/sklandrausis/DataProcessingForMaserObservation", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -27,7 +27,7 @@ def findLogFile(logList, iteration):\n             tmpL = l\n             break\n     if tmpL == -1:\n-        warnings.warn(\"Warning \" + \"log for iteration \" + iteration + \" do not exist log file \" + logList[-1] + \" will be used instead !\", stacklevel=1, category=\"Warning\")\n+        warnings.warn(\"Warning \" + \"log for iteration \" + iteration + \" do not exist log file \" + logList[-1] + \" will be used instead !\", stacklevel=1)\n         \n     return tmpL\n     \n", "before": "warnings . warn ( \"Warning \" + \"log for iteration \" + iteration + \" do not exist log file \" + logList [ - 1 ] + \" will be used instead !\" , stacklevel = 1 , category = \"Warning\" )", "after": "warnings . warn ( \"Warning \" + \"log for iteration \" + iteration + \" do not exist log file \" + logList [ - 1 ] + \" will be used instead !\" , stacklevel = 1 )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 152, 3, 153]], [\"Delete\", [\"identifier:category\", 3, 154, 3, 162]], [\"Delete\", [\"=:=\", 3, 162, 3, 163]], [\"Delete\", [\"string:\\\"Warning\\\"\", 3, 163, 3, 172]], [\"Delete\", [\"keyword_argument\", 3, 154, 3, 172]]]"}
{"project": "populo", "commit_sha": "a79bf683b0cc1a05646abfc973b89084aa38f6c7", "parent_sha": "0e171be261c99eb691f63593cecf5a24cad37ac4", "file_path": "lms/djangoapps/django_comment_client/tests/test_utils.py", "project_url": "https://github.com/chauhanhardik/populo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -362,7 +362,7 @@ class CategoryMapTestCase(ModuleStoreTestCase):\n         self.create_discussion(\"Chapter 2 / Section 1 / Subsection 1\", \"Discussion\")\n         self.create_discussion(\"Chapter 2 / Section 1 / Subsection 1\", \"Discussion\")  # duplicate\n \n-        category_map = utils.get_discussion_category_map(self.course, self.user)\n+        category_map = utils.get_discussion_category_map(self.course)\n \n         chapter1 = category_map[\"subcategories\"][\"Chapter 1\"]\n         chapter1_discussions = set([\"Discussion A\", \"Discussion B\", \"Discussion A (1)\", \"Discussion A (2)\"])\n", "before": "category_map = utils . get_discussion_category_map ( self . course , self . user )", "after": "category_map = utils . get_discussion_category_map ( self . course )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 69, 3, 70]], [\"Delete\", [\"identifier:self\", 3, 71, 3, 75]], [\"Delete\", [\".:.\", 3, 75, 3, 76]], [\"Delete\", [\"identifier:user\", 3, 76, 3, 80]], [\"Delete\", [\"attribute\", 3, 71, 3, 80]]]"}
{"project": "populo", "commit_sha": "79f9d1a70fe35267ca70a32ba71c902401f65a42", "parent_sha": "e7e9a16379b44807066057bdbefc661c243be407", "file_path": "common/lib/capa/capa/safe_exec/lazymod.py", "project_url": "https://github.com/chauhanhardik/populo", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,5 +39,5 @@ class LazyModule(object):\n                 submod = getattr(mod, name)\n             except ImportError:\n                 raise AttributeError(\"'module' object has no attribute %r\" % name)\n-            self.__dict__[name] = LazyModule(subname, submod)\n+            self.__dict__[name] = LazyModule(subname)\n             return self.__dict__[name]\n", "before": "self . __dict__ [ name ] = LazyModule ( subname , submod )", "after": "self . __dict__ [ name ] = LazyModule ( subname )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 53, 3, 54]], [\"Delete\", [\"identifier:submod\", 3, 55, 3, 61]]]"}
{"project": "capstone", "commit_sha": "95fce2a65400bdd2e3de3f9ce87d79a98711bc5d", "parent_sha": "a90c2c3365bd051b2f6dc7f51e13086222590359", "file_path": "capstone/capapi/views.py", "project_url": "https://github.com/harvard-lil/capstone", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -103,7 +103,7 @@ class CaseViewSet(viewsets.GenericViewSet, mixins.RetrieveModelMixin, mixins.Lis\n         except ValidationError as err:\n             return JsonResponse(err.detail, status=403)\n \n-        response = self.create_download_response(cases, blacklisted_case_count)\n+        response = self.create_download_response(cases)\n         user.update_case_allowance(case_count=blacklisted_case_count)\n \n         return response\n", "before": "response = self . create_download_response ( cases , blacklisted_case_count )", "after": "response = self . create_download_response ( cases )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 55, 3, 56]], [\"Delete\", [\"identifier:blacklisted_case_count\", 3, 57, 3, 79]]]"}
{"project": "impact-api", "commit_sha": "6f3b2a4a1d19ad48aab444a42a9e536dfca5491c", "parent_sha": "d566e10f2afe49fc49f032d2a5931b7036e3f467", "file_path": "web/impact/impact/tests/test_schema_endpoints.py", "project_url": "https://github.com/masschallenge/impact-api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,7 +33,7 @@ class TestSchemaEndpoints(APITestCase):\n         with self.login(username=self.basic_user().username):\n             url = reverse(\"organization_users\", args=[startups[0].pk])\n             response = self.client.options(url)\n-        response_json = json.loads(response.content, encoding='utf8')\n+        response_json = json.loads(response.content)\n         self.assertEqual(\n             ORGANIZATION_USER_FIELDS.keys(),\n             response_json[\"actions\"][\"GET\"][\"properties\"][\"users\"][\"item\"][\n", "before": "response_json = json . loads ( response . content , encoding = 'utf8' )", "after": "response_json = json . loads ( response . content )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 52, 3, 53]], [\"Delete\", [\"identifier:encoding\", 3, 54, 3, 62]], [\"Delete\", [\"=:=\", 3, 62, 3, 63]], [\"Delete\", [\"string:'utf8'\", 3, 63, 3, 69]], [\"Delete\", [\"keyword_argument\", 3, 54, 3, 69]]]"}
{"project": "scipy", "commit_sha": "72f6f5db104518f8d6617cda8207c20c4338c7f1", "parent_sha": "438159fca72c219a0e8e8e8b6e7108363cf2347b", "file_path": "scipy/stats/tests/test_discrete_basic.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -249,7 +249,7 @@ def check_discrete_chisquare(distfn, arg, rvs, alpha, msg):\n     histsupp[0] = distfn.a\n \n     # find sample frequencies and perform chisquare test\n-    freq,hsupp = np.histogram(rvs,histsupp,new=True)\n+    freq,hsupp = np.histogram(rvs,histsupp)\n     cdfs = distfn.cdf(distsupp,*arg)\n     (chis,pval) = stats.chisquare(np.array(freq),n*distmass)\n \n", "before": "freq , hsupp = np . histogram ( rvs , histsupp , new = True )", "after": "freq , hsupp = np . histogram ( rvs , histsupp )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 43, 3, 44]], [\"Delete\", [\"identifier:new\", 3, 44, 3, 47]], [\"Delete\", [\"=:=\", 3, 47, 3, 48]], [\"Delete\", [\"true:True\", 3, 48, 3, 52]], [\"Delete\", [\"keyword_argument\", 3, 44, 3, 52]]]"}
{"project": "scipy", "commit_sha": "0985cc06b743f52d9cbc5cc96b0570bccd0cdbcf", "parent_sha": "9bfb88bd2c2354159c42e546f654d742e92ac1e6", "file_path": "scipy/signal/spectral.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -292,7 +292,7 @@ def welch(x, fs=1.0, window='hanning', nfft=256, noverlap=None, sides='default',\n         x = np.rollaxis(x, axis, len(x.shape))\n \n     if type(window) is str or type(window) is tuple:\n-        win = get_window(window, nfft, False)\n+        win = get_window(window, nfft)\n     else:\n         win = np.asarray(window)\n         if len(win.shape) != 1:\n", "before": "win = get_window ( window , nfft , False )", "after": "win = get_window ( window , nfft )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 38, 3, 39]], [\"Delete\", [\"false:False\", 3, 40, 3, 45]]]"}
{"project": "smart-cache", "commit_sha": "338037b5cbb850083fe1b36686f0d134822907fc", "parent_sha": "ed326f4b1c80b6d3200f11acd7f4cc4b6ab7fa88", "file_path": "DataManager/collector/dataset/stage.py", "project_url": "https://github.com/Cloud-PG/smart-cache", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -58,7 +58,7 @@ class CMSRawStage(Stage):\n                     tasks.append(cur_input)\n                 else:\n                     tasks_results = sc.parallelize(\n-                        tasks, num_process\n+                        tasks\n                     ).map(\n                         self._process\n                     ).collect()\n", "before": "else : tasks_results = sc . parallelize ( tasks , num_process ) . map ( self . _process ) . collect ( )", "after": "else : tasks_results = sc . parallelize ( tasks ) . map ( self . _process ) . collect ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 30, 3, 31]], [\"Delete\", [\"identifier:num_process\", 3, 32, 3, 43]]]"}
{"project": "scipy", "commit_sha": "07730480fe9d6783264afae5d054bd0145322fdc", "parent_sha": "6243d2d61fbc2645b4e5800d8ec8ea7817c0d291", "file_path": "scipy/sparse/linalg/eigen/lobpcg/lobpcg.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -21,7 +21,7 @@ __all__ = ['lobpcg']\n \n def _save(ar, fileName):\n     # Used only when verbosity level > 10.\n-    np.savetxt(fileName, ar, precision=8)\n+    np.savetxt(fileName, ar)\n \n \n def _report_nonhermitian(M, a, b, name):\n", "before": "np . savetxt ( fileName , ar , precision = 8 )", "after": "np . savetxt ( fileName , ar )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 28, 3, 29]], [\"Delete\", [\"identifier:precision\", 3, 30, 3, 39]], [\"Delete\", [\"=:=\", 3, 39, 3, 40]], [\"Delete\", [\"integer:8\", 3, 40, 3, 41]], [\"Delete\", [\"keyword_argument\", 3, 30, 3, 41]]]"}
{"project": "vmware-nsx", "commit_sha": "46129d253b783e13f7e0f777d8b9387630b15ce0", "parent_sha": "ff0623c2d6b8d82a4bfdce97494260067582be63", "file_path": "neutron/db/migration/alembic_migrations/versions/folsom_initial.py", "project_url": "https://github.com/gkotton/vmware-nsx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -459,7 +459,7 @@ def upgrade_cisco():\n         'nexusport_bindings',\n         sa.Column('id', sa.Integer(), primary_key=True, autoincrement=True),\n         sa.Column('port_id', sa.String(255)),\n-        sa.Column('vlan_id', sa.Integer(255)),\n+        sa.Column('vlan_id', sa.Integer()),\n         sa.PrimaryKeyConstraint('id')\n     )\n \n", "before": "sa . Column ( 'vlan_id' , sa . Integer ( 255 ) ) ,", "after": "sa . Column ( 'vlan_id' , sa . Integer ( ) ) ,", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"integer:255\", 3, 41, 3, 44]]]"}
{"project": "stadtgestalten", "commit_sha": "be5f020a166871e5c946f58a8c531cae5dd5c755", "parent_sha": "b6a92893449959cc9385f64aeaffe7782f887f0c", "file_path": "features/tags/models.py", "project_url": "https://github.com/stadtgestalten/stadtgestalten", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ class Tag(models.Model):\n \n     @classmethod\n     def slugify(cls, name):\n-        return slugify(None, None, name, dodging=False)\n+        return slugify(name)\n \n \n class Tagged(models.Model):\n", "before": "return slugify ( None , None , name , dodging = False )", "after": "return slugify ( name )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"none:None\", 3, 24, 3, 28]], [\"Delete\", [\",:,\", 3, 28, 3, 29]], [\"Delete\", [\"none:None\", 3, 30, 3, 34]], [\"Delete\", [\",:,\", 3, 34, 3, 35]], [\"Delete\", [\",:,\", 3, 40, 3, 41]], [\"Delete\", [\"identifier:dodging\", 3, 42, 3, 49]], [\"Delete\", [\"=:=\", 3, 49, 3, 50]], [\"Delete\", [\"false:False\", 3, 50, 3, 55]], [\"Delete\", [\"keyword_argument\", 3, 42, 3, 55]]]"}
{"project": "maidchan-slackbot", "commit_sha": "8da7b621966a92db05304f7c28f5a2dc2213d0a6", "parent_sha": "3044cd9304889617c474267922143b31f4fc2776", "file_path": "maidchan_scheduled.py", "project_url": "https://github.com/susumuishigami/maidchan-slackbot", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -23,7 +23,7 @@ def scheduled_handler(event, context):\n     hour = now.hour\n     \n     if hour == 8:\n-        message(OHAYO_MESSAGE.format(hour, get_weather()))\n+        message(OHAYO_MESSAGE.format(get_weather()))\n \n     if hour == 12:\n         message(OHIRU_MESSAGE.format(hour))\n", "before": "message ( OHAYO_MESSAGE . format ( hour , get_weather ( ) ) )", "after": "message ( OHAYO_MESSAGE . format ( get_weather ( ) ) )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:hour\", 3, 38, 3, 42]], [\"Delete\", [\",:,\", 3, 42, 3, 43]]]"}
{"project": "electrum", "commit_sha": "5cb18f95de03529527eebc0c6d8f3582509e59bd", "parent_sha": "0464a1a6b0afd4222191b1c34d30b91e50ec470d", "file_path": "gui/kivy/uix/dialogs/installwizard.py", "project_url": "https://github.com/UnitedBitcoin/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -185,7 +185,7 @@ class InstallWizard(Widget):\n                 def create(password):\n                     wallet.add_seed(seed, password)\n                     wallet.create_master_keys(password)\n-                    wallet.create_main_account(password)\n+                    wallet.create_main_account()\n                     wallet.synchronize()  # generate first addresses offline\n \n                 self.waiting_dialog(partial(create, password),\n", "before": "wallet . create_main_account ( password )", "after": "wallet . create_main_account ( )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:password\", 3, 48, 3, 56]]]"}
{"project": "electrum", "commit_sha": "2450c1d481cb92c7659ca307a0eef91369442918", "parent_sha": "7af5d42324041204967b7d9c0865ddb8c2eb2712", "file_path": "lib/wallet.py", "project_url": "https://github.com/UnitedBitcoin/electrum", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -533,7 +533,7 @@ class Abstract_Wallet(PrintError):\n         return c, u, x\n \n     def get_spendable_coins(self, domain = None):\n-        return self.get_utxos(self, domain, exclude_frozen=True, mature=True)\n+        return self.get_utxos(domain, exclude_frozen=True, mature=True)\n \n     def get_utxos(self, domain = None, exclude_frozen = False, mature = False):\n         coins = []\n", "before": "return self . get_utxos ( self , domain , exclude_frozen = True , mature = True )", "after": "return self . get_utxos ( domain , exclude_frozen = True , mature = True )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:self\", 3, 31, 3, 35]], [\"Delete\", [\",:,\", 3, 35, 3, 36]]]"}
{"project": "py_fxxk", "commit_sha": "6e763e03b41ed4711279493ddfc23a7cadef8ffa", "parent_sha": "3086beb9b755e89bd1c2e7c6af7385d8cced6fba", "file_path": "sample/default/default.py", "project_url": "https://github.com/FGtatsuro/py_fxxk", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -7,7 +7,7 @@ from py_fxxk import BrainFxxk\n def main():\n     if len(sys.argv) != 2:\n         sys.exit(1)\n-    BrainFxxk(debug=False).fxxk(sys.argv[1])\n+    BrainFxxk().fxxk(sys.argv[1])\n \n if __name__ == '__main__':\n     main()\n", "before": "BrainFxxk ( debug = False ) . fxxk ( sys . argv [ 1 ] )", "after": "BrainFxxk ( ) . fxxk ( sys . argv [ 1 ] )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\"identifier:debug\", 3, 15, 3, 20]], [\"Delete\", [\"=:=\", 3, 20, 3, 21]], [\"Delete\", [\"false:False\", 3, 21, 3, 26]], [\"Delete\", [\"keyword_argument\", 3, 15, 3, 26]]]"}
{"project": "sunpy", "commit_sha": "9d72d0a102f26262f1f472246437b18b222fd3c0", "parent_sha": "be5020f52779161c1d4f0f019019dbcee7062d9e", "file_path": "sunpy/instr/tests/test_fermi.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -20,7 +20,7 @@ def test_detector_angles():\n     #set a test date\n     date = parse_time('2012-02-15')\n     file = fermi.download_weekly_pointing_file(date)\n-    det=fermi.get_detector_sun_angles_for_date(date,file,plot=False)\n+    det=fermi.get_detector_sun_angles_for_date(date,file)\n     assert len(det) == 12\n     #assert type(det) == collections.OrderedDict\n     assert_almost_equal(det['n0'][0], 20.30309,decimal=1)\n", "before": "det = fermi . get_detector_sun_angles_for_date ( date , file , plot = False )", "after": "det = fermi . get_detector_sun_angles_for_date ( date , file )", "sstub_pattern": "SAME_FUNCTION_LESS_ARGS", "edit_script": "[[\"Delete\", [\",:,\", 3, 57, 3, 58]], [\"Delete\", [\"identifier:plot\", 3, 58, 3, 62]], [\"Delete\", [\"=:=\", 3, 62, 3, 63]], [\"Delete\", [\"false:False\", 3, 63, 3, 68]], [\"Delete\", [\"keyword_argument\", 3, 58, 3, 68]]]"}
{"project": "pennyblack", "commit_sha": "e8bf06ce6ddda7e452a5009f2b7b732da01e05d7", "parent_sha": "3319e87b912cdc28fcc444f60dc4d35726f83aa5", "file_path": "pennyblack/models/job.py", "project_url": "https://github.com/nickburlett/pennyblack", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -334,7 +334,7 @@ class JobStatisticAdmin(admin.ModelAdmin):\n     def user_agents_view(self, request, object_id):\n         from pennyblack.models import EmailClient\n         obj = self.get_object(request, unquote(object_id))\n-        user_agents = EmailClient.objects.filter(mail__job_id=obj.id).values('user_agent').annotate(count=models.Count('user_agent')).order_by('-count')\n+        user_agents = EmailClient.objects.filter(mail__job__id=obj.id).values('user_agent').annotate(count=models.Count('user_agent')).order_by('-count')\n         context = {\n             'object': obj,\n             'opts': self.model._meta,\n", "before": "user_agents = EmailClient . objects . filter ( mail__job_id = obj . id ) . values ( 'user_agent' ) . annotate ( count = models . Count ( 'user_agent' ) ) . order_by ( '-count' )", "after": "user_agents = EmailClient . objects . filter ( mail__job__id = obj . id ) . values ( 'user_agent' ) . annotate ( count = models . Count ( 'user_agent' ) ) . order_by ( '-count' )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:mail__job_id\", 3, 50, 3, 62], \"mail__job__id\"]]"}
{"project": "SleekXMPP", "commit_sha": "8ead33fc3bdb75312c3112db5001cf9544566efb", "parent_sha": "ab25301953138343d3d295aaa8872de9c5bc2cf9", "file_path": "sleekxmpp/plugins/xep_0030.py", "project_url": "https://github.com/mayflower/SleekXMPP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -345,7 +345,7 @@ class xep_0030(base.base_plugin):\n     def add_identity(self, category='', itype='', name='', node=''):\n         self.add_node(node)\n         self.nodes[node].addIdentity(category=category,\n-                         id_type=itype,\n+                         itype=itype,\n                          name=name)\n \n     def add_item(self, jid=None, name='', node='', subnode=''):\n", "before": "self . nodes [ node ] . addIdentity ( category = category , id_type = itype , name = name )", "after": "self . nodes [ node ] . addIdentity ( category = category , itype = itype , name = name )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:id_type\", 3, 26, 3, 33], \"itype\"]]"}
{"project": "nintendeals", "commit_sha": "e3538912ce4fc7770022ea5ebdc1144f2ed5c407", "parent_sha": "e7c085b9cd4cd2f3b919511b065369376b1e2367", "file_path": "nintendeals/noe/api/nintendo.py", "project_url": "https://github.com/federicocalendino/nintendeals", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -81,4 +81,4 @@ def search_by_platform(platform: Platforms) -> Iterator[dict]:\n \n \n def search_by_query(query: str, platform: Platforms = None) -> Iterator[dict]:\n-    yield from _search(nsuid=query, platform=platform)\n+    yield from _search(query=query, platform=platform)\n", "before": "yield from _search ( nsuid = query , platform = platform )", "after": "yield from _search ( query = query , platform = platform )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:nsuid\", 3, 24, 3, 29], \"query\"]]"}
{"project": "cc-utils", "commit_sha": "df2344523ee5122d5256bb1e543be8a9c6e3ccd5", "parent_sha": "c66e6510086857511015603ffbb8efaab1c7437f", "file_path": "concourse/model/traits/image_scan.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -227,7 +227,7 @@ class ImageScanTrait(Trait):\n         # XXX remove backward compatibility\n         if not 'protecode' in self.raw:\n             util.warning('legacy protecode cfg - adjust pipeline_definition!')\n-            return ProtecodeScanCfg(raw=self.raw)\n+            return ProtecodeScanCfg(raw_dict=self.raw)\n         # TODO: after schema change, protecode cfg should become optional\n         return ProtecodeScanCfg(raw=self.raw['protecode'])\n \n", "before": "return ProtecodeScanCfg ( raw = self . raw )", "after": "return ProtecodeScanCfg ( raw_dict = self . raw )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:raw\", 3, 37, 3, 40], \"raw_dict\"]]"}
{"project": "cc-utils", "commit_sha": "4d419de7d77c8a12a2415e65b09d1baa78d7a762", "parent_sha": "b41504a1f2f22b9ebdc511bdb8f12b0a0cd6a2cb", "file_path": "util.py", "project_url": "https://github.com/gardener/cc-utils", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -160,7 +160,7 @@ def verbose(msg:str):\n \n def success(msg:str):\n     if msg:\n-        _print('SUCCESS: ' + msg, colour='green', outfs=sys.stdout)\n+        _print('SUCCESS: ' + msg, colour='green', outfh=sys.stdout)\n \n \n def not_empty(value):\n", "before": "_print ( 'SUCCESS: ' + msg , colour = 'green' , outfs = sys . stdout )", "after": "_print ( 'SUCCESS: ' + msg , colour = 'green' , outfh = sys . stdout )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:outfs\", 3, 51, 3, 56], \"outfh\"]]"}
{"project": "gello", "commit_sha": "70b8afd9cd0024c790ca38cbd0a4f6faf80cf983", "parent_sha": "93c701e47d79b56447a317b52bf1d98b73e62a7b", "file_path": "app/tasks/create_pull_request_card.py", "project_url": "https://github.com/DataDog/gello", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -50,6 +50,6 @@ class CreatePullRequestCard(CreateTrelloCard):\n         self._pull_request_service.create(\n             name=self._title,\n             url=self._url,\n-            github_issue_id=self._id,\n+            github_pull_request_id=self._id,\n             repo_id=self._repo_id\n         )\n", "before": "self . _pull_request_service . create ( name = self . _title , url = self . _url , github_issue_id = self . _id , repo_id = self . _repo_id )", "after": "self . _pull_request_service . create ( name = self . _title , url = self . _url , github_pull_request_id = self . _id , repo_id = self . _repo_id )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:github_issue_id\", 3, 13, 3, 28], \"github_pull_request_id\"]]"}
{"project": "django_microsoft_auth", "commit_sha": "5d83314bb462264f52b24ed22a108ffd059f9078", "parent_sha": "77879cf3414e6d23ae79d8576a88e17d699accc9", "file_path": "microsoft_auth/client.py", "project_url": "https://github.com/AngellusMortis/django_microsoft_auth", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -135,7 +135,7 @@ class MicrosoftClient(OAuth2Session):\n                 cache.delete(CACHE_KEY_JWKS)\n                 cache.delete(CACHE_KEY_OPENID)\n \n-                return self.get_claims(allow_refesh=False)\n+                return self.get_claims(allow_refresh=False)\n             else:\n                 logger.warn(\"could not find public key for id_token\")\n                 return None\n", "before": "return self . get_claims ( allow_refesh = False )", "after": "return self . get_claims ( allow_refresh = False )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:allow_refesh\", 3, 40, 3, 52], \"allow_refresh\"]]"}
{"project": "DeepDIVA", "commit_sha": "8ae3d4b05092b8d9c4b9ed0cad09a8d6d34dee0c", "parent_sha": "375b06a273b2592cd99d6a1e95d5c44da6f40b03", "file_path": "template/RunMe.py", "project_url": "https://github.com/DIVA-DIA/DeepDIVA", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -220,7 +220,7 @@ class RunMe:\n             logging.info('Multi-Run: {} of {}'.format(i + 1, args.multi_run))\n             train_scores[i, :], val_scores[i, :], test_scores[i] = runner_class.single_run(writer,\n                                                                                            run=i,\n-                                                                                           log_dir=current_log_folder,\n+                                                                                           current_log_folder=current_log_folder,\n                                                                                            **args.__dict__)\n \n             # Generate and add to tensorboard the shaded plot for train\n", "before": "train_scores [ i , : ] , val_scores [ i , : ] , test_scores [ i ] = runner_class . single_run ( writer , run = i , log_dir = current_log_folder , ** args . __dict__ )", "after": "train_scores [ i , : ] , val_scores [ i , : ] , test_scores [ i ] = runner_class . single_run ( writer , run = i , current_log_folder = current_log_folder , ** args . __dict__ )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:log_dir\", 3, 92, 3, 99], \"current_log_folder\"]]"}
{"project": "pyMaid", "commit_sha": "3492fd3c21731d3daa6fc2a696f166352b46211c", "parent_sha": "62c9574a2c50ac61a3fec77653d5d0af52bfd779", "file_path": "pymaid/plotting.py", "project_url": "https://github.com/schlegelp/pyMaid", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -595,7 +595,7 @@ def plot2d(x, method='2d', **kwargs):\n                 default_settings = dict(\n                     c='black',\n                     zorder=4,\n-                    edge_color='none',\n+                    edgecolor='none',\n                     s=1\n                 )\n                 default_settings.update(scatter_kws)\n", "before": "default_settings = dict ( c = 'black' , zorder = 4 , edge_color = 'none' , s = 1 )", "after": "default_settings = dict ( c = 'black' , zorder = 4 , edgecolor = 'none' , s = 1 )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:edge_color\", 3, 21, 3, 31], \"edgecolor\"]]"}
{"project": "angr", "commit_sha": "eb6b50dc54e68e180d802ffaf1635a8cb692b443", "parent_sha": "47d864cf2931e3fba0ee272d09aa5dd2f7a78602", "file_path": "simuvex/s_irsb.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -113,7 +113,7 @@ class SimIRSB(SimRun):\n \n \t\t\t# ret emulation\n \t\t\tif o.DO_RET_EMULATION in self.options and self.irsb.jumpkind == \"Ijk_Call\":\n-\t\t\t\tself.postcall_exit = s_exit.SimExit(sirsb_postcall = self, static = (o.SYMBOLIC not in self.options))\n+\t\t\t\tself.postcall_exit = s_exit.SimExit(sirsb_postcall = self, simple_postcall = (o.SYMBOLIC not in self.options))\n \t\t\t\tl.debug(\"Adding postcall exit.\")\n \t\t\t\tself.add_exits(self.postcall_exit)\n \t\telse:\n", "before": "self . postcall_exit = s_exit . SimExit ( sirsb_postcall = self , static = ( o . SYMBOLIC not in self . options ) )", "after": "self . postcall_exit = s_exit . SimExit ( sirsb_postcall = self , simple_postcall = ( o . SYMBOLIC not in self . options ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:static\", 3, 64, 3, 70], \"simple_postcall\"]]"}
{"project": "angr", "commit_sha": "3a01fd15ef5d5f526585cb27aeb2f659f0b96ad0", "parent_sha": "51293dd8316c8d2466fea7c89bd9c1c2e692aa99", "file_path": "simuvex/s_exit.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -128,7 +128,7 @@ class SimExit:\n \n \t# Copies the exit (also copying the state).\n \tdef copy(self):\n-\t\treturn SimExit(expr=self.target, state=self.state.copy_exact(), src_addr=self.src_addr, src_stmt_index=self.src_stmt_index, jumpkind=self.jumpkind, simplify=False)\n+\t\treturn SimExit(expr=self.target, state=self.state.copy_exact(), src_addr=self.src_addr, stmt_index=self.src_stmt_index, jumpkind=self.jumpkind, simplify=False)\n \n \t# Splits a multi-valued exit into multiple exits.\n \tdef split(self, maximum=maximum_exit_split):\n", "before": "return SimExit ( expr = self . target , state = self . state . copy_exact ( ) , src_addr = self . src_addr , src_stmt_index = self . src_stmt_index , jumpkind = self . jumpkind , simplify = False )", "after": "return SimExit ( expr = self . target , state = self . state . copy_exact ( ) , src_addr = self . src_addr , stmt_index = self . src_stmt_index , jumpkind = self . jumpkind , simplify = False )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:src_stmt_index\", 3, 91, 3, 105], \"stmt_index\"]]"}
{"project": "angr", "commit_sha": "fcf3b09d401ea5a649da6e890b27fbe9ab9717e6", "parent_sha": "48d408159bce701e671524ccfdd9ac69ae02c188", "file_path": "simuvex/procedures/libc___so___6/strstr.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -62,7 +62,7 @@ class strstr(simuvex.SimProcedure):\n \t\t\tneedle_length = self.state.se.any_int(needle_strlen.ret_expr)\n \t\t\tneedle_str = self.state.mem_expr(needle_addr, needle_length)\n \n-\t\t\tr, c, i = self.state.memory.find(haystack_addr, needle_str, haystack_strlen.max_null_index, max_symbolic=self.state['libc'].max_symbolic_strstr, default=0)\n+\t\t\tr, c, i = self.state.memory.find(haystack_addr, needle_str, haystack_strlen.max_null_index, max_symbolic_bytes=self.state['libc'].max_symbolic_strstr, default=0)\n \n \t\tself.state.add_constraints(*c)\n \t\treturn r\n", "before": "r , c , i = self . state . memory . find ( haystack_addr , needle_str , haystack_strlen . max_null_index , max_symbolic = self . state [ 'libc' ] . max_symbolic_strstr , default = 0 )", "after": "r , c , i = self . state . memory . find ( haystack_addr , needle_str , haystack_strlen . max_null_index , max_symbolic_bytes = self . state [ 'libc' ] . max_symbolic_strstr , default = 0 )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:max_symbolic\", 3, 96, 3, 108], \"max_symbolic_bytes\"]]"}
{"project": "angr", "commit_sha": "a16fe9ce9e3741650c01ae113296892f07b0a5c3", "parent_sha": "931338b396fadacc6e86a1cfe8724e9be2e80d15", "file_path": "angr/analyses/veritesting.py", "project_url": "https://github.com/grimm-co/angr", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -458,7 +458,7 @@ class Veritesting(Analysis):\n         size_of_next_irsb = [ n for n in self._cfg.graph.nodes() if n.addr == ip ][0].size\n         # It has been called by is_path_errored before, but I'm doing it here anyways. Who knows how the logic in\n         # PathGroup will change in the future...\n-        path.step(size=size_of_next_irsb)\n+        path.step(max_size=size_of_next_irsb)\n \n         # Now it's safe to call anything that may access Path.next_run\n         if self._path_callback:\n", "before": "path . step ( size = size_of_next_irsb )", "after": "path . step ( max_size = size_of_next_irsb )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:size\", 3, 19, 3, 23], \"max_size\"]]"}
{"project": "sympy", "commit_sha": "a9818d8b9860b8ebe9d71883791f2fcdafc3affd", "parent_sha": "ca3f04aca1949a7dd2dccbc1db970746802be460", "file_path": "sympy/utilities/tests/test_wester.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -584,7 +584,7 @@ def test_H32():  # issue 6558\n \n \n def test_H33():\n-    A, B, C = symbols('A, B, C', commutatative=False)\n+    A, B, C = symbols('A, B, C', commutative=False)\n     assert (Commutator(A, Commutator(B, C))\n         + Commutator(B, Commutator(C, A))\n         + Commutator(C, Commutator(A, B))).doit().expand() == 0\n", "before": "A , B , C = symbols ( 'A, B, C' , commutatative = False )", "after": "A , B , C = symbols ( 'A, B, C' , commutative = False )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:commutatative\", 3, 34, 3, 47], \"commutative\"]]"}
{"project": "sympy", "commit_sha": "c8c154752b32991148f3c943422495b2cb9a329e", "parent_sha": "f57527e9ed0d930ef074f3ad49850d57949ee879", "file_path": "sympy/plotting/tests/test_plot_implicit.py", "project_url": "https://github.com/schymans/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ def plot_implicit_tests(name):\n             assert \"Adaptive meshing could not be applied\" in str(i.message)\n \n     with warnings.catch_warnings(record=True) as w:\n-        plot_and_save(x**2 - 1, legend='An implicit plot')\n+        plot_and_save(x**2 - 1, title='An implicit plot')\n         for i in w:\n             assert issubclass(i.category, UserWarning)\n             assert 'No labelled objects found' in str(i.message)\n", "before": "plot_and_save ( x ** 2 - 1 , legend = 'An implicit plot' )", "after": "plot_and_save ( x ** 2 - 1 , title = 'An implicit plot' )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:legend\", 3, 33, 3, 39], \"title\"]]"}
{"project": "tardis", "commit_sha": "ea88f9d40ae23253d229add5d782ee64ecb3181a", "parent_sha": "1692e506116cede0842bd240125bb8ccfa7243fe", "file_path": "tardis/tests/integration_tests/test_integration.py", "project_url": "https://github.com/vg3095/tardis", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -133,7 +133,7 @@ class TestIntegration(object):\n                 pytest.skip(\n                     'Reference data {0} does exist and tests will not '\n                     'proceed generating new data'.format(ref_data_path))\n-            self.result.to_hdf(hdf_path_or_buf=ref_data_path,\n+            self.result.to_hdf(path_or_buf=ref_data_path,\n                                suffix_count=False)\n             pytest.skip(\"Reference data saved at {0}\".format(\n                 data_path['gen_ref_path']\n", "before": "self . result . to_hdf ( hdf_path_or_buf = ref_data_path , suffix_count = False )", "after": "self . result . to_hdf ( path_or_buf = ref_data_path , suffix_count = False )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:hdf_path_or_buf\", 3, 32, 3, 47], \"path_or_buf\"]]"}
{"project": "easybuild-easyconfigs", "commit_sha": "ba796bc4b4f09b0e5ae69ad38feb4ed873c42ff3", "parent_sha": "f5d17192e0037e4382155cf0428aad3b4bd62763", "file_path": "easybuild/tools/toolkit.py", "project_url": "https://github.com/schiotz/easybuild-easyconfigs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -435,7 +435,7 @@ class Toolkit:\n             libs = ['compiler/lib/intel64', 'compiler/lib/ia32']\n         else:\n             libs = ['lib/intel64', 'lib/ia32']\n-        self._flagsForSubdirs(root, libs, flag=\"-L%s\", varsKey=\"LDFLAGS\")\n+        self._flagsForSubdirs(root, libs, flag=\"-L%s\", varskey=\"LDFLAGS\")\n \n     def prepareIcc(self):\n", "before": "self . _flagsForSubdirs ( root , libs , flag = \"-L%s\" , varsKey = \"LDFLAGS\" )", "after": "self . _flagsForSubdirs ( root , libs , flag = \"-L%s\" , varskey = \"LDFLAGS\" )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:varsKey\", 3, 56, 3, 63], \"varskey\"]]"}
{"project": "dcos-e2e", "commit_sha": "2554c44c1a29d332bd9bd54dc096d6695afd08dc", "parent_sha": "1fd85303718b731ca9a88afd3e9fc6a50f7aeb47", "file_path": "admin/release.py", "project_url": "https://github.com/dcos/dcos-e2e", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -89,7 +89,7 @@ def update_homebrew(version_str: str, repository: Repository) -> None:\n     archive_url = repository.get_archive_link(\n         archive_format='tarball',\n-        version=version_str,\n+        ref=version_str,\n     )\n \n     homebrew_formula_contents = get_homebrew_formula(\n", "before": "archive_url = repository . get_archive_link ( archive_format = 'tarball' , version = version_str , )", "after": "archive_url = repository . get_archive_link ( archive_format = 'tarball' , ref = version_str , )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:version\", 2, 9, 2, 16], \"ref\"]]"}
{"project": "dcos-e2e", "commit_sha": "55923147800743af45b0f41fb7d08fab552d51d4", "parent_sha": "2a85cde074150a037dafe4d4e5dbfca196a159d0", "file_path": "src/cli/_mac_network.py", "project_url": "https://github.com/dcos/dcos-e2e", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -106,7 +106,7 @@ def create_mac_network(configuration_dst: Path) -> None:\n                 'Error: A DC/OS E2E OpenVPN container is already running. '\n                 'To remove this container, run: '\n                 '\"docker rm -f {openvpn_container_name}\".'\n-            ).format(proxy_container_name=_OPENVPN_CONTAINER_NAME)\n+            ).format(openvpn_container_name=_OPENVPN_CONTAINER_NAME)\n             click.echo(message, err=True)\n             sys.exit(1)\n         raise\n", "before": "format ( proxy_container_name = _OPENVPN_CONTAINER_NAME )", "after": "format ( openvpn_container_name = _OPENVPN_CONTAINER_NAME )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:proxy_container_name\", 3, 22, 3, 42], \"openvpn_container_name\"]]"}
{"project": "databroker", "commit_sha": "dce4a5134b228e5ce84e432b914d53dbd8d4c15e", "parent_sha": "855b8aa0558425f2f304761f4a3ac305d24560f0", "file_path": "metadatastore/commands.py", "project_url": "https://github.com/bluesky/databroker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -773,7 +773,7 @@ def insert_event(descriptor, time, seq_num, data, timestamps, uid):\n     # get the ObjectID so for reference field\n     desc_oid = _DESCRIPTOR_UID_to_OID_MAP[descriptor_uid]\n     # create the Event document\n-    event = Event(descriptor_id=desc_oid, uid=uid,\n+    event = Event(descriptor=desc_oid, uid=uid,\n                   data=val_ts_tuple, time=time, seq_num=seq_num)\n \n     event.save(validate=True, write_concern={\"w\": 1})\n", "before": "event = Event ( descriptor_id = desc_oid , uid = uid , data = val_ts_tuple , time = time , seq_num = seq_num )", "after": "event = Event ( descriptor = desc_oid , uid = uid , data = val_ts_tuple , time = time , seq_num = seq_num )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:descriptor_id\", 3, 19, 3, 32], \"descriptor\"]]"}
{"project": "django-xadmin", "commit_sha": "164f2b9ddb35520097ff8d0df31ec6e3ebaa68ba", "parent_sha": "9f42d3c796ce509de187a2106018f094c2201e33", "file_path": "xadmin/plugins/export.py", "project_url": "https://github.com/scrapinghub/django-xadmin", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -215,7 +215,7 @@ class ExportPlugin(BaseAdminPlugin):\n     def get_response(self, response, context, *args, **kwargs):\n         file_type = self.request.GET.get('export_type', 'csv')\n         response = HttpResponse(\n-            mimetype=\"%s; charset=UTF-8\" % self.export_mimes[file_type])\n+            content_type=\"%s; charset=UTF-8\" % self.export_mimes[file_type])\n \n         file_name = self.opts.verbose_name.replace(' ', '_')\n         response['Content-Disposition'] = ('attachment; filename=%s.%s' % (\n", "before": "response = HttpResponse ( mimetype = \"%s; charset=UTF-8\" % self . export_mimes [ file_type ] )", "after": "response = HttpResponse ( content_type = \"%s; charset=UTF-8\" % self . export_mimes [ file_type ] )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:mimetype\", 3, 13, 3, 21], \"content_type\"]]"}
{"project": "django-xadmin", "commit_sha": "0e3c62e28e27034e5a9c8689a27dc11138899b0a", "parent_sha": "656385744ef6dd57431dbd7d5c9b87d4eccf4429", "file_path": "xadmin/plugins/export.py", "project_url": "https://github.com/scrapinghub/django-xadmin", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -215,7 +215,7 @@ class ExportPlugin(BaseAdminPlugin):\n     def get_response(self, response, context, *args, **kwargs):\n         file_type = self.request.GET.get('export_type', 'csv')\n         response = HttpResponse(\n-            mimetype=\"%s; charset=UTF-8\" % self.export_mimes[file_type])\n+            content_type=\"%s; charset=UTF-8\" % self.export_mimes[file_type])\n \n         file_name = self.opts.verbose_name.replace(' ', '_')\n         response['Content-Disposition'] = ('attachment; filename=%s.%s' % (\n", "before": "response = HttpResponse ( mimetype = \"%s; charset=UTF-8\" % self . export_mimes [ file_type ] )", "after": "response = HttpResponse ( content_type = \"%s; charset=UTF-8\" % self . export_mimes [ file_type ] )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:mimetype\", 3, 13, 3, 21], \"content_type\"]]"}
{"project": "raiden-services", "commit_sha": "c0f34eb6f2e41f43d868205ce46c87d6b2bef27d", "parent_sha": "e71891c023afe955404e3911ca048ae461b4728a", "file_path": "src/monitoring_service/service.py", "project_url": "https://github.com/raiden-network/raiden-services", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -71,7 +71,7 @@ def handle_event(event: Event, context: Context) -> None:\n                     num_scheduled_events=context.database.scheduled_event_count(),\n                 )\n             except Exception as ex:  # pylint: disable=broad-except\n-                log.error(\"Error during event handler\", event=event, exc_info=ex)\n+                log.error(\"Error during event handler\", handled_event=event, exc_info=ex)\n                 sentry_sdk.capture_exception(ex)\n \n \n", "before": "ex : log . error ( \"Error during event handler\" , event = event , exc_info = ex )", "after": "ex : log . error ( \"Error during event handler\" , handled_event = event , exc_info = ex )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:event\", 3, 57, 3, 62], \"handled_event\"]]"}
{"project": "LogESP", "commit_sha": "c9154b1d56c6a0543fc4971d94ea15808bbb1b99", "parent_sha": "1880883d7438ebe2bb1a1a34c83e566bc823fbd2", "file_path": "daemons/sentry/sentry.py", "project_url": "https://github.com/dogoncouch/LogESP", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -76,7 +76,7 @@ class SiemSentry:\n         else:\n             timeint = timedelta(minutes=self.rule.time_int)\n             erange = RuleEvent.objects.filter(\n-                    parsed_at__gt=timezone.localtime(\n+                    date_stamp__gt=timezone.localtime(\n                         timezone.now()) - timeint)\n             if len(erange) == 0:\n                 self.lasteventid = RuleEvent.objects.latest('id').id\n", "before": "erange = RuleEvent . objects . filter ( parsed_at__gt = timezone . localtime ( timezone . now ( ) ) - timeint )", "after": "erange = RuleEvent . objects . filter ( date_stamp__gt = timezone . localtime ( timezone . now ( ) ) - timeint )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:parsed_at__gt\", 3, 21, 3, 34], \"date_stamp__gt\"]]"}
{"project": "tensorflow-sample-code", "commit_sha": "8b0714c393cde899da85c189a6e922e6e9fa2294", "parent_sha": "5f3f752a92b8a5b35f0b5cf00a37b8d40c30ac45", "file_path": "tfjob/docker/v1alpha2/distributed-mnist/main.py", "project_url": "https://github.com/cheyang/tensorflow-sample-code", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -199,7 +199,7 @@ def train():\n   sv = tf.train.Supervisor(is_chief=is_chief,\n \t\t\t\t\t\tglobal_step=global_step,\n \t\t\t\t\t\tinit_op=init_op,\n-\t\t\t\t\t\tlog_dir=FLAGS.log_dir)\n+\t\t\t\t\t\tlogdir=FLAGS.log_dir)\n   # sess_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True,\n   #                               device_filters=[\"/job:ps\", \"/job:worker/task:%d\" % FLAGS.worker_index])\n \n", "before": "sv = tf . train . Supervisor ( is_chief = is_chief , global_step = global_step , init_op = init_op , log_dir = FLAGS . log_dir )", "after": "sv = tf . train . Supervisor ( is_chief = is_chief , global_step = global_step , init_op = init_op , logdir = FLAGS . log_dir )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:log_dir\", 3, 7, 3, 14], \"logdir\"]]"}
{"project": "horizon", "commit_sha": "8164075f5b6b24972503c9d27f78e0228dce9716", "parent_sha": "c88e944b97d37d26663d493eb7b07f0b53d7408e", "file_path": "openstack_dashboard/api/ceilometer.py", "project_url": "https://github.com/mkowalski/horizon", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -281,7 +281,7 @@ def ceilometerclient(request):\n     return ceilometer_client.Client('2', endpoint,\n                                     token=(lambda: request.user.token.id),\n                                     insecure=insecure,\n-                                    ca_file=cacert)\n+                                    cacert=cacert)\n \n \n def resource_list(request, query=None, ceilometer_usage_object=None):\n", "before": "return ceilometer_client . Client ( '2' , endpoint , token = ( lambda : request . user . token . id ) , insecure = insecure , ca_file = cacert )", "after": "return ceilometer_client . Client ( '2' , endpoint , token = ( lambda : request . user . token . id ) , insecure = insecure , cacert = cacert )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:ca_file\", 3, 37, 3, 44], \"cacert\"]]"}
{"project": "charm-hacluster", "commit_sha": "d098d8d9058821c3e61d3190effb0e95a41a3864", "parent_sha": "598546b8b73cfcbe8ee163e752f41c4173879748", "file_path": "hooks/hooks.py", "project_url": "https://github.com/CanonicalBootStack/charm-hacluster", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -358,7 +358,7 @@ def configure_cluster():\n             pcmk.commit(cmd)\n \n     for rel_id in relation_ids('ha'):\n-        relation_set(rid=rel_id,\n+        relation_set(relation_id=rel_id,\n                      clustered=\"yes\")\n \n     with open(HAMARKER, 'w') as marker:\n", "before": "relation_set ( rid = rel_id , clustered = \"yes\" )", "after": "relation_set ( relation_id = rel_id , clustered = \"yes\" )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:rid\", 3, 22, 3, 25], \"relation_id\"]]"}
{"project": "xos-1", "commit_sha": "414e690dc4256f12a73e251858bd6acbb5104f52", "parent_sha": "0856d56a2c9a4a13a116201cf9e7023443f52fce", "file_path": "plstackapi/planetstack/api/roles.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -13,7 +13,7 @@ def add_role(auth, name):\n \n def delete_role(auth, role_id):\n     driver = OpenStackDriver(client = auth_check(auth))   \n-    role = Role.objects.filter(role__id=role_id)\n+    role = Role.objects.filter(role_id=role_id)\n     driver.delete_role(name) \n     role.delete()\n     return 1\n", "before": "role = Role . objects . filter ( role__id = role_id )", "after": "role = Role . objects . filter ( role_id = role_id )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:role__id\", 3, 32, 3, 40], \"role_id\"]]"}
{"project": "xos-1", "commit_sha": "91af54efc6077c56606df32e380c798166a8e047", "parent_sha": "1750f93d5bbdfc426123fd5d8ab34e08388311cc", "file_path": "xos/tosca/resources/node.py", "project_url": "https://github.com/vpramo/xos-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -19,7 +19,7 @@ class XOSNode(XOSResource):\n         site = None\n         siteName = self.get_requirement(\"tosca.relationships.MemberOfSite\", throw_exception=False)\n         if siteName:\n-            site = self.get_xos_object(Site, name=siteName)\n+            site = self.get_xos_object(Site, login_base=siteName)\n             args[\"site\"] = site\n \n         deploymentName = self.get_requirement(\"tosca.relationships.MemberOfDeployment\", throw_exception=False)\n", "before": "site = self . get_xos_object ( Site , name = siteName )", "after": "site = self . get_xos_object ( Site , login_base = siteName )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:name\", 3, 46, 3, 50], \"login_base\"]]"}
{"project": "askbot-devel", "commit_sha": "0d3a224d34b89049482afe27118ebf90c39e0af4", "parent_sha": "4797e9ab404ffa107b7296606690b817b448585b", "file_path": "askbot/api.py", "project_url": "https://github.com/kingctan/askbot-devel", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -60,7 +60,7 @@ def get_admin(seed_user_id = None):\n             return user\n     try:\n         return models.User.objects.filter(\n-                        Q(is_superuser=True) | Q(status='m')\n+                        Q(is_superuser=True) | Q(askbot_profile__status='m')\n                     ).order_by('id')[0]\n     except IndexError:\n         raise models.User.DoesNotExist(\n", "before": "return models . User . objects . filter ( Q ( is_superuser = True ) | Q ( status = 'm' ) ) . order_by ( 'id' ) [ 0 ]", "after": "return models . User . objects . filter ( Q ( is_superuser = True ) | Q ( askbot_profile__status = 'm' ) ) . order_by ( 'id' ) [ 0 ]", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:status\", 3, 50, 3, 56], \"askbot_profile__status\"]]"}
{"project": "askbot-devel", "commit_sha": "faa36bf51cedfd7f8b2acc093fa5beb4f1485849", "parent_sha": "56ce0f73872154fc92c555868084bcf0370fc6a1", "file_path": "askbot/management/commands/askbot_send_moderation_alerts.py", "project_url": "https://github.com/kingctan/askbot-devel", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ from askbot.models import Activity\n from askbot.models import User\n \n def get_moderators():\n-    return User.objects.filter(status__in=('d', 'm'))\n+    return User.objects.filter(askbot_profile__status__in=('d', 'm'))\n \n def get_last_mod_alert_activity():\n     atype = const.TYPE_ACTIVITY_MODERATION_ALERT_SENT\n", "before": "return User . objects . filter ( status__in = ( 'd' , 'm' ) )", "after": "return User . objects . filter ( askbot_profile__status__in = ( 'd' , 'm' ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:status__in\", 3, 32, 3, 42], \"askbot_profile__status__in\"]]"}
{"project": "Cura", "commit_sha": "d6acb78bd4c310b5ded6180e6cc17394872672a6", "parent_sha": "c62ab6e937460e7fe81ca0765fbb3393f9e6e69d", "file_path": "cura/CuraApplication.py", "project_url": "https://github.com/themaninthesuitcase/Cura", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -90,7 +90,7 @@ class CuraApplication(QtApplication):\n         # Need to do this before ContainerRegistry tries to load the machines\n         SettingDefinition.addSupportedProperty(\"global_only\", DefinitionPropertyType.Function, default = False)\n \n-        super().__init__(name = \"cura\", version = CuraVersion, build_type = CuraBuildType)\n+        super().__init__(name = \"cura\", version = CuraVersion, buildtype = CuraBuildType)\n \n         self.setWindowIcon(QIcon(Resources.getPath(Resources.Images, \"cura-icon.png\")))\n \n", "before": "super ( ) . __init__ ( name = \"cura\" , version = CuraVersion , build_type = CuraBuildType )", "after": "super ( ) . __init__ ( name = \"cura\" , version = CuraVersion , buildtype = CuraBuildType )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:build_type\", 3, 64, 3, 74], \"buildtype\"]]"}
{"project": "flocker", "commit_sha": "fc3be727f7ab6a05da3d4e456482205ebb66b41a", "parent_sha": "98e0b4b5bed6ed9a2dc3febf87acc77ccfc96eeb", "file_path": "flocker/node/agents/functional/test_ebs.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -165,7 +165,7 @@ class EBSBlockDeviceAPIInterfaceTests(\n         # first one can't have anything in its cache.\n         another_api = self.blockdevice_api_factory(test_case=self)\n         volume = another_api.create_volume(\n-            dataset_isd=uuid4(), size=self.minimum_allocatable_size\n+            dataset_id=uuid4(), size=self.minimum_allocatable_size\n         )\n         another_api.attach_volume(\n             volume.blockdevice_id, another_api.compute_instance_id()\n", "before": "volume = another_api . create_volume ( dataset_isd = uuid4 ( ) , size = self . minimum_allocatable_size )", "after": "volume = another_api . create_volume ( dataset_id = uuid4 ( ) , size = self . minimum_allocatable_size )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:dataset_isd\", 3, 13, 3, 24], \"dataset_id\"]]"}
{"project": "flocker", "commit_sha": "48550998f4a7991f90e99a06c4b3b7588743bc26", "parent_sha": "d7e155582ac5cff65b45645b03f412432b0b877c", "file_path": "benchmark/cluster_containers_setup.py", "project_url": "https://github.com/datlowe/flocker", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -377,7 +377,7 @@ class ClusterContainerDeployment(object):\n \n         def log_totals(result):\n             Message.log(\n-                action_type='flocker.benchmark.container_setup:finish',\n+                message_type='flocker.benchmark.container_setup:finish',\n                 container_count=self.container_count,\n                 error_count=self.error_count\n             )\n", "before": "Message . log ( action_type = 'flocker.benchmark.container_setup:finish' , container_count = self . container_count , error_count = self . error_count )", "after": "Message . log ( message_type = 'flocker.benchmark.container_setup:finish' , container_count = self . container_count , error_count = self . error_count )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:action_type\", 3, 17, 3, 28], \"message_type\"]]"}
{"project": "curator", "commit_sha": "5104baa451a576dc86a6aa298da4be407818f7b3", "parent_sha": "616941040c5267e075294c65c4c8d1e46cacf4c1", "file_path": "curator/actions.py", "project_url": "https://github.com/mgmonteleone/curator", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -197,7 +197,7 @@ class Allocation(object):\n                         ' {0}'.format(to_csv(l))\n                     )\n                     self.client.cluster.health(index=to_csv(l),\n-                        level='indices', wait_for_relocation_shards=0,\n+                        level='indices', wait_for_relocating_shards=0,\n                         timeout=self.timeout,\n                     )\n         except Exception as e:\n", "before": "self . client . cluster . health ( index = to_csv ( l ) , level = 'indices' , wait_for_relocation_shards = 0 , timeout = self . timeout , )", "after": "self . client . cluster . health ( index = to_csv ( l ) , level = 'indices' , wait_for_relocating_shards = 0 , timeout = self . timeout , )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:wait_for_relocation_shards\", 3, 42, 3, 68], \"wait_for_relocating_shards\"]]"}
{"project": "kafka-python", "commit_sha": "da03827d12520bd9c8c5b35bb43e35168f09771a", "parent_sha": "5d8d5412e576c5514497be3809ea899378f40e56", "file_path": "test/test_protocol.py", "project_url": "https://github.com/DataDog/kafka-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -585,7 +585,7 @@ class TestProtocol(unittest.TestCase):\n \n         results = KafkaProtocol.decode_consumer_metadata_response(encoded)\n         self.assertEqual(results,\n-            ConsumerMetadataResponse(error = 0, node = 1, host = b'brokers1.kafka.rdio.com', port = 1000)\n+            ConsumerMetadataResponse(error = 0, nodeId = 1, host = b'brokers1.kafka.rdio.com', port = 1000)\n         )\n \n     def test_encode_offset_request(self):\n", "before": "self . assertEqual ( results , ConsumerMetadataResponse ( error = 0 , node = 1 , host = b'brokers1.kafka.rdio.com' , port = 1000 ) )", "after": "self . assertEqual ( results , ConsumerMetadataResponse ( error = 0 , nodeId = 1 , host = b'brokers1.kafka.rdio.com' , port = 1000 ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:node\", 3, 49, 3, 53], \"nodeId\"]]"}
{"project": "kitsune", "commit_sha": "96efae9f4d72b1aa9205bb7976fd16ff53ae9ec1", "parent_sha": "18bcb7f39cca4820e063d09c7797f821fd56617b", "file_path": "apps/search/views.py", "project_url": "https://github.com/skcrouch7/kitsune", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -182,7 +182,7 @@ def search(request, template=None):\n                 discussion_s = discussion_s.filter(is_locked=1)\n \n         if cleaned['forum']:\n-            discussion_s = discussion_s.filter(forum_id=cleaned['forum'])\n+            discussion_s = discussion_s.filter(forum_id__in=cleaned['forum'])\n \n     # Filters common to support and discussion forums\n     # Created filter\n", "before": "discussion_s = discussion_s . filter ( forum_id = cleaned [ 'forum' ] )", "after": "discussion_s = discussion_s . filter ( forum_id__in = cleaned [ 'forum' ] )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:forum_id\", 3, 48, 3, 56], \"forum_id__in\"]]"}
{"project": "kitsune", "commit_sha": "86952017045af90ad9dea1800c4d2dfe658e9afd", "parent_sha": "fd3c3621d0869d553e38acee60ab4451239d2632", "file_path": "kitsune/questions/managers.py", "project_url": "https://github.com/skcrouch7/kitsune", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -26,7 +26,7 @@ class QuestionManager(ManagerBase):\n     #      the status is \"Needs Attention\"\n     def needs_attention(self):\n         qs = self.filter(solution__isnull=True, is_locked=False,\n-                         created__gte=datetime.now() - timedelta(days=7))\n+                         updated__gte=datetime.now() - timedelta(days=7))\n         return qs.filter(Q(last_answer__creator=F('creator')) |\n                          Q(last_answer__isnull=True))\n \n", "before": "qs = self . filter ( solution__isnull = True , is_locked = False , created__gte = datetime . now ( ) - timedelta ( days = 7 ) )", "after": "qs = self . filter ( solution__isnull = True , is_locked = False , updated__gte = datetime . now ( ) - timedelta ( days = 7 ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:created__gte\", 3, 26, 3, 38], \"updated__gte\"]]"}
{"project": "salt", "commit_sha": "78e6a392a32770eaf2dc9f46e327691bbfda7b50", "parent_sha": "496fb8ccddae3ce808fa93ab65f52300f3e1031d", "file_path": "salt/minion.py", "project_url": "https://github.com/kraney/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2489,7 +2489,7 @@ class Matcher(object):\n             return False\n         return salt.utils.subdict_match(self.opts['pillar'],\n                                         tgt,\n-                                        delim=delim,\n+                                        delimiter=delim,\n                                         exact_match=True)\n \n     def ipcidr_match(self, tgt):\n", "before": "return salt . utils . subdict_match ( self . opts [ 'pillar' ] , tgt , delim = delim , exact_match = True )", "after": "return salt . utils . subdict_match ( self . opts [ 'pillar' ] , tgt , delimiter = delim , exact_match = True )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:delim\", 3, 41, 3, 46], \"delimiter\"]]"}
{"project": "openstates", "commit_sha": "33fd2257c4a6c2fd379fe589d0e314467631f8d3", "parent_sha": "2696ccdc3376fc71fdcc23ae50dd7f9dfed2630c", "file_path": "openstates/nd/bills.py", "project_url": "https://github.com/opencouncil/openstates", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -43,7 +43,7 @@ class NDBillScraper(BillScraper):\n                 bill_id = bills.text\n                 bill_url = bill_list_url[0: -26] + '/' + bills.attrib['href'][2:len(bills.attrib['href'])]\n                 bill_type = self.bill_type_info(bill_id)\n-                bill = Bill(term, chamber, bill_id, title, bill_type=bill_type)\n+                bill = Bill(term, chamber, bill_id, title, type=bill_type)\n                 \n                 #sources\n                 bill.add_source(bill_url)\n", "before": "bill = Bill ( term , chamber , bill_id , title , bill_type = bill_type )", "after": "bill = Bill ( term , chamber , bill_id , title , type = bill_type )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:bill_type\", 3, 60, 3, 69], \"type\"]]"}
{"project": "django-socialregistration", "commit_sha": "40d300b3fc2e5d2c5671ba5eee013f36f14341f2", "parent_sha": "df96a9e7e4aac8b0c1af66e97c856b58e7e12075", "file_path": "socialregistration/views.py", "project_url": "https://github.com/jpic/django-socialregistration", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -136,7 +136,7 @@ def facebook_connect(request, template='socialregistration/facebook.html',\n         return render_to_response(\n             template,\n             extra_context,\n-            context_dict=RequestContext(request)\n+            context_instance=RequestContext(request)\n         )\n     \n     profile, created = FacebookProfile.objects.get_or_create(\n", "before": "return render_to_response ( template , extra_context , context_dict = RequestContext ( request ) )", "after": "return render_to_response ( template , extra_context , context_instance = RequestContext ( request ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:context_dict\", 3, 13, 3, 25], \"context_instance\"]]"}
{"project": "dit", "commit_sha": "6260d7875595038d917c22532b0d4580a8a4e6f1", "parent_sha": "9625ed64239c5d366cd8e15b679de41ec6135eb0", "file_path": "dit/profiles/tests/test_information_partitions.py", "project_url": "https://github.com/mpeaton37/dit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -93,7 +93,7 @@ def test_dd1():\n     Test against known values.\n     \"\"\"\n     d = n_mod_m(3, 2)\n-    ep = DependencyDecomposition(d, measure={'B': B})\n+    ep = DependencyDecomposition(d, measures={'B': B})\n     string = \"\"\"\\\n +------------+--------+\n | dependency |   B    |\n", "before": "ep = DependencyDecomposition ( d , measure = { 'B' : B } )", "after": "ep = DependencyDecomposition ( d , measures = { 'B' : B } )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:measure\", 3, 37, 3, 44], \"measures\"]]"}
{"project": "scikit-learn", "commit_sha": "ac0f46ff54bbea2db9bc09c972319daf2594c86c", "parent_sha": "e54af6398c75792886d9a3388b4858c1ea4349f9", "file_path": "sklearn/neighbors/classification.py", "project_url": "https://github.com/t-lanigan/scikit-learn", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -214,7 +214,7 @@ class KNeighborsClassifier(NeighborsBase, KNeighborsMixin,\n             # normalize 'votes' into real [0,1] probabilities\n             normalizer = proba_k.sum(axis=1)[:, np.newaxis]\n             normalizer[normalizer == 0.0] = 1.0\n-            with np.errstate(divide='ignore'):\n+            with np.errstate(invalid='ignore'):\n                 proba_k /= normalizer\n             proba_k[np.isnan(proba_k)] = 1.0\n \n", "before": "with np . errstate ( divide = 'ignore' ) : proba_k /= normalizer", "after": "with np . errstate ( invalid = 'ignore' ) : proba_k /= normalizer", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:divide\", 3, 30, 3, 36], \"invalid\"]]"}
{"project": "coursebuilder-core", "commit_sha": "91b39149381c3528c9e571347244c0933e299304", "parent_sha": "cfac62b07f589d83ab7f2e3ca15acc2a92789671", "file_path": "coursebuilder/modules/admin/enrollments.py", "project_url": "https://github.com/imisi-akande/coursebuilder-core", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -666,7 +666,7 @@ class StartComputeCounts(_BaseCronHandler):\n             elif total_dto.is_pending:\n                 logging.warning(\n                     'INTERRUPTING \"%s\" initialization started on %s.', ns,\n-                    utc.to_text(dt=total_dto.last_modified))\n+                    utc.to_text(seconds=total_dto.last_modified))\n             job.cancel()\n         job.submit()\n \n", "before": "total_dto . is_pending : logging . warning ( 'INTERRUPTING \"%s\" initialization started on %s.' , ns , utc . to_text ( dt = total_dto . last_modified ) )", "after": "total_dto . is_pending : logging . warning ( 'INTERRUPTING \"%s\" initialization started on %s.' , ns , utc . to_text ( seconds = total_dto . last_modified ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:dt\", 3, 33, 3, 35], \"seconds\"]]"}
{"project": "fabric8-analytics-common", "commit_sha": "413c0b7f2df43543fd360bca1a9a6b9de4f6f5e8", "parent_sha": "d7721390ce762be4a275612e53cbb264e4e202c3", "file_path": "integration-tests/features/steps/user_intent.py", "project_url": "https://github.com/fabric8-analytics/fabric8-analytics-common", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -15,7 +15,7 @@ def post_data_to_user_intent_endpoint(context, payload=None):\n     if payload is not None:\n         context.response = requests.post(context.coreapi_url + url,\n                                          headers=authorization(context),\n-                                         data=payload)\n+                                         json=payload)\n     else:\n         context.response = requests.post(context.coreapi_url + url,\n                                          headers=authorization(context))\n", "before": "context . response = requests . post ( context . coreapi_url + url , headers = authorization ( context ) , data = payload )", "after": "context . response = requests . post ( context . coreapi_url + url , headers = authorization ( context ) , json = payload )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:data\", 3, 42, 3, 46], \"json\"]]"}
{"project": "polocas-napadu-api", "commit_sha": "cd824c82497bea98200020f222090243370ed32c", "parent_sha": "3a21f142e40dd159c66678a6c09b12c000588f12", "file_path": "fields/visibility.py", "project_url": "https://github.com/just-paja/polocas-napadu-api", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ class VisibilityManager(Manager):\n         abstract = True\n \n     def get_visible(self):\n-        return self.filter(visible=VISIBILITY_PUBLIC)\n+        return self.filter(visibility=VISIBILITY_PUBLIC)\n \n \n class VisibilityMixin(Model):\n", "before": "return self . filter ( visible = VISIBILITY_PUBLIC )", "after": "return self . filter ( visibility = VISIBILITY_PUBLIC )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:visible\", 3, 28, 3, 35], \"visibility\"]]"}
{"project": "scipy", "commit_sha": "9297846990ea0107d5b2dd438e6c1d184fea05b8", "parent_sha": "2cd8d1e54288fc8f28bc69e69c57c469a1ef7d84", "file_path": "Lib/sandbox/timeseries/tsdate.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -165,7 +165,7 @@ def thisday(freq):\n     elif freq == 'M':\r\n         return Date(freq, year=tempDate.year, month=tempDate.month)\r\n     elif freq == 'Q':\r\n-        return Date(freq, yaer=tempDate.year, quarter=monthToQuarter(tempDate.month))\r\n+        return Date(freq, year=tempDate.year, quarter=monthToQuarter(tempDate.month))\r\n     elif freq == 'A':\r\n         return Date(freq, year=tempDate.year)\r\n \r\n", "before": "return Date ( freq , yaer = tempDate . year , quarter = monthToQuarter ( tempDate . month ) )", "after": "return Date ( freq , year = tempDate . year , quarter = monthToQuarter ( tempDate . month ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:yaer\", 3, 27, 3, 31], \"year\"]]"}
{"project": "scipy", "commit_sha": "2459343598e40467909932639e2b05b29501097c", "parent_sha": "090fd4f25fa90aea4547829573266ac9d6f54f45", "file_path": "scipy/cluster/tests/test_hierarchy.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -117,7 +117,7 @@ class TestLinkage(object):\n             assert_allclose(Z_trivial, Z, rtol=1e-14, atol=1e-15)\n \n     def test_optimal_leaf_ordering(self):\n-        Z = linkage(hierarchy_test_data.ytdist, optimal_leaf_ordering=True)\n+        Z = linkage(hierarchy_test_data.ytdist, optimal_ordering=True)\n         expectedZ = getattr(hierarchy_test_data, 'linkage_ytdist_single_olo')\n         assert_allclose(Z, expectedZ, atol=1e-10)\n \n", "before": "Z = linkage ( hierarchy_test_data . ytdist , optimal_leaf_ordering = True )", "after": "Z = linkage ( hierarchy_test_data . ytdist , optimal_ordering = True )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:optimal_leaf_ordering\", 3, 49, 3, 70], \"optimal_ordering\"]]"}
{"project": "scipy", "commit_sha": "6f1be7d61c5a4369bc200750cb700426c9f3b06d", "parent_sha": "7ff4e907d922d07e3e512c42d93e3e5e619713fd", "file_path": "scipy/stats/stats.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -3600,7 +3600,7 @@ def power_divergence(f_obs, f_exp=None, ddof=0, axis=0, lambda_=None):\n     are uniform and given by the mean of the observed frequencies.  Here we\n     perform a G-test (i.e. use the log-likelihood ratio statistic):\n \n-    >>> power_divergence([16, 18, 16, 14, 12, 12], method='log-likelihood')\n+    >>> power_divergence([16, 18, 16, 14, 12, 12], lambda_='log-likelihood')\n     (2.006573162632538, 0.84823476779463769)\n \n     The expected frequencies can be given with the `f_exp` argument:\n", "before": "perform a G - test ( i . e . use the log - likelihood ratio statistic ) : >> > power_divergence ( [ 16 , 18 , 16 , 14 , 12 , 12 ] , method = 'log-likelihood' )", "after": "perform a G - test ( i . e . use the log - likelihood ratio statistic ) : >> > power_divergence ( [ 16 , 18 , 16 , 14 , 12 , 12 ] , lambda_ = 'log-likelihood' )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:method\", 3, 52, 3, 58], \"lambda_\"]]"}
{"project": "scipy", "commit_sha": "7022ef5dd4935a7664f230b6af17bdb4f834e1eb", "parent_sha": "8beb2c37f497aea9be869626b50e2d246dbba866", "file_path": "scipy/_build_utils/compiler_helper.py", "project_url": "https://github.com/Kai-Striega/scipy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -100,6 +100,6 @@ def set_cxx_flags_clib_hook(build_clib, build_info):\n             new_args.append(min_macos_flag)\n             new_link_args.append(min_macos_flag)\n \n-    dict_append(build_info, extra_compile_args=new_args,\n+    dict_append(build_info, extra_compiler_args=new_args,\n                 extra_link_args=new_link_args)\n \n", "before": "dict_append ( build_info , extra_compile_args = new_args , extra_link_args = new_link_args )", "after": "dict_append ( build_info , extra_compiler_args = new_args , extra_link_args = new_link_args )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:extra_compile_args\", 3, 29, 3, 47], \"extra_compiler_args\"]]"}
{"project": "vmware-nsx", "commit_sha": "dbdc379932250f88821cf06aeac2b05e9b4ad74d", "parent_sha": "6f8a914ccfc5bb8865f852205fa291664af864d3", "file_path": "neutron/wsgi.py", "project_url": "https://github.com/gkotton/vmware-nsx", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -907,7 +907,7 @@ class Application(object):\n           res = 'message\\n'\n \n           # Option 2: a nicely formatted HTTP exception page\n-          res = exc.HTTPForbidden(detail='Nice try')\n+          res = exc.HTTPForbidden(explanation='Nice try')\n \n           # Option 3: a webob Response object (in case you need to play with\n           # headers, or you want to be treated like an iterable, or or or)\n", "before": "res = exc . HTTPForbidden ( detail = 'Nice try' )", "after": "res = exc . HTTPForbidden ( explanation = 'Nice try' )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:detail\", 3, 35, 3, 41], \"explanation\"]]"}
{"project": "django-lfs", "commit_sha": "71d1214d87c6737431110baaf0c6c37b505dac1a", "parent_sha": "3072d3e57704a04a25bb915ab66709f809acdb51", "file_path": "lfs/manage/product/properties.py", "project_url": "https://github.com/baffolobill/django-lfs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -254,7 +254,7 @@ def update_property_groups(request, product_id):\n                 property_group.products.add(product_id)\n         else:\n             property_group.products.remove(product_id)\n-            product_removed_property_group.send(send=property_group, product=product)\n+            product_removed_property_group.send(sender=property_group, product=product)\n \n     update_product_cache(product)\n \n", "before": "product_removed_property_group . send ( send = property_group , product = product )", "after": "product_removed_property_group . send ( sender = property_group , product = product )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:send\", 3, 49, 3, 53], \"sender\"]]"}
{"project": "django-lfs", "commit_sha": "3d27a27b886db72ae414ee119e5089bc453a3e54", "parent_sha": "a8d8cbf5ecf895b292ca23612475aafd48f60d9f", "file_path": "lfs/manage/product/properties.py", "project_url": "https://github.com/baffolobill/django-lfs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -254,7 +254,7 @@ def update_property_groups(request, product_id):\n                 property_group.products.add(product_id)\n         else:\n             property_group.products.remove(product_id)\n-            product_removed_property_group.send(send=property_group, product=product)\n+            product_removed_property_group.send(sender=property_group, product=product)\n \n     update_product_cache(product)\n \n", "before": "product_removed_property_group . send ( send = property_group , product = product )", "after": "product_removed_property_group . send ( sender = property_group , product = product )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:send\", 3, 49, 3, 53], \"sender\"]]"}
{"project": "django-lfs", "commit_sha": "7149aae02923073fa29040a10034dcd5ce55a230", "parent_sha": "9e2f5092402d38cf562c45ae8db36fc50899d808", "file_path": "lfs/cart/utils.py", "project_url": "https://github.com/baffolobill/django-lfs", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -113,7 +113,7 @@ def update_cart_after_login(request):\n                 properties = {}\n                 for pv in session_cart_item.properties.all():\n                     properties[unicode(pv.property.id)] = pv.value\n-                user_cart.add(session_cart_item.product, properties=properties, amount=session_cart_item.amount)\n+                user_cart.add(session_cart_item.product, properties_dict=properties, amount=session_cart_item.amount)\n             session_cart.delete()\n     except ObjectDoesNotExist:\n         pass\n", "before": "user_cart . add ( session_cart_item . product , properties = properties , amount = session_cart_item . amount )", "after": "user_cart . add ( session_cart_item . product , properties_dict = properties , amount = session_cart_item . amount )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:properties\", 3, 58, 3, 68], \"properties_dict\"]]"}
{"project": "tomes-tagger", "commit_sha": "2f0db1d284f1100c52e761be51bf27ff2c24d670", "parent_sha": "b9595facd4b1c1e59df8c5fb6d80af54ba85171e", "file_path": "tomes_tool/lib/text_to_nlp.py", "project_url": "https://github.com/StateArchivesOfNorthCarolina/tomes-tagger", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -176,7 +176,7 @@ class TextToNLP():\n         # verify @response is a string; decode @response.\n         if not isinstance(response, str):\n             response = str(response)\n-        response = response.encode(charset, errors=\"ignore\").decode(charset, error=\"ignore\")\n+        response = response.encode(charset, errors=\"ignore\").decode(charset, errors=\"ignore\")\n         \n         # if needed, truncate @response.\n         if len(response) > max_length:\n", "before": "response = response . encode ( charset , errors = \"ignore\" ) . decode ( charset , error = \"ignore\" )", "after": "response = response . encode ( charset , errors = \"ignore\" ) . decode ( charset , errors = \"ignore\" )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:error\", 3, 78, 3, 83], \"errors\"]]"}
{"project": "sunpy", "commit_sha": "9358a9b942b54045e068aaf6477cd7f57420b9e4", "parent_sha": "51d6e10eb566f98ef9b2184db19466790e19e10d", "file_path": "sunpy/image/tests/test_coalignment.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -107,7 +107,7 @@ def test_coalign():\n     # Create the mapcube\n     mc = map.Map([testmap, m1], cube=True)\n     # Do the coalignment\n-    displacements = mc.coalign(displacements_only=True)\n+    displacements = mc.coalign(return_displacements_only=True)\n     # Assert\n     assert_allclose(displacements['x'], known_displacements['x'], rtol=5e-2, atol=0)\n     assert_allclose(displacements['y'], known_displacements['y'], rtol=5e-2, atol=0 )\n", "before": "displacements = mc . coalign ( displacements_only = True )", "after": "displacements = mc . coalign ( return_displacements_only = True )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:displacements_only\", 3, 32, 3, 50], \"return_displacements_only\"]]"}
{"project": "sunpy", "commit_sha": "af6dbb679ca95e2f018c90545d779f4cf6698080", "parent_sha": "c4f1296c8a531c30b89998d16baf1778de063a63", "file_path": "sunpy/net/tests/test_helioviewer.py", "project_url": "https://github.com/ayshih/sunpy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -48,7 +48,7 @@ class TestHelioviewerClient:\n         # result should be same when using source id to query\n         source_id = client.sources['SOHO']['EIT']['304']['sourceId']\n \n-        im2 = client.get_closest_image('1994/01/01', sourceid=source_id)\n+        im2 = client.get_closest_image('1994/01/01', source_id=source_id)\n \n         assert im1 == im2\n \n", "before": "im2 = client . get_closest_image ( '1994/01/01' , sourceid = source_id )", "after": "im2 = client . get_closest_image ( '1994/01/01' , source_id = source_id )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:sourceid\", 3, 54, 3, 62], \"source_id\"]]"}
{"project": "eng-ops", "commit_sha": "4ceb32e3e343cf2753d0fb821266438b802f05a6", "parent_sha": "53842b2bb316cd43a776a3ff8dc7cb1334d07531", "file_path": "api/slack_bot.py", "project_url": "https://github.com/FundersClub/eng-ops", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -39,7 +39,7 @@ def send_standup_messages():\n \n     for user in GithubUser.objects.filter(slack_username__isnull=False):\n         opened_issues = Issue.objects.filter(\n-            assignee=user,\n+            creater=user,\n             closed_at__isnull=True,\n             created_at__range=(start_time, end_time),\n         )\n", "before": "opened_issues = Issue . objects . filter ( assignee = user , closed_at__isnull = True , created_at__range = ( start_time , end_time ) , )", "after": "opened_issues = Issue . objects . filter ( creater = user , closed_at__isnull = True , created_at__range = ( start_time , end_time ) , )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:assignee\", 3, 13, 3, 21], \"creater\"]]"}
{"project": "eng-ops", "commit_sha": "83404a8672ddf0c684f690fe70ad47cdbd0ef6f5", "parent_sha": "c4c2489ed1e154a4958f0b0c9eeb5f6623f33a78", "file_path": "api/handlers.py", "project_url": "https://github.com/FundersClub/eng-ops", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -188,7 +188,7 @@ def repository_handler(data):\n     repository, _ = Repository.objects.update_or_create(\n         id=repository_data['id'],\n         name=repository_data['name'],\n-        default={\n+        defaults={\n             'private': repository_data['private'],\n         }\n     )\n", "before": "repository , _ = Repository . objects . update_or_create ( id = repository_data [ 'id' ] , name = repository_data [ 'name' ] , default = { 'private' : repository_data [ 'private' ] , } )", "after": "repository , _ = Repository . objects . update_or_create ( id = repository_data [ 'id' ] , name = repository_data [ 'name' ] , defaults = { 'private' : repository_data [ 'private' ] , } )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:default\", 3, 9, 3, 16], \"defaults\"]]"}
{"project": "enigma2", "commit_sha": "b784d016b66856c4f3aca2cb9a1c5c7f61f18519", "parent_sha": "8f7dbc5ddb0e674364866b0e41ba42b55c6db8bf", "file_path": "lib/python/Screens/PictureInPicture.py", "project_url": "https://github.com/nx111/enigma2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -8,7 +8,7 @@ class PictureInPicture(Screen):\n \t\tScreen.__init__(self, session)\n \t\tself[\"video\"] = VideoWindow()\n \t\tself.currentService = None\n-\t\tconfig.av.pip = ConfigPosition(default=[-1, -1, -1, -1], limits = (719, 567, 720, 568))\n+\t\tconfig.av.pip = ConfigPosition(default=[-1, -1, -1, -1], args = (719, 567, 720, 568))\n \t\tself.onLayoutFinish.append(self.LayoutFinished)\n \n \tdef LayoutFinished(self):\n", "before": "config . av . pip = ConfigPosition ( default = [ - 1 , - 1 , - 1 , - 1 ] , limits = ( 719 , 567 , 720 , 568 ) )", "after": "config . av . pip = ConfigPosition ( default = [ - 1 , - 1 , - 1 , - 1 ] , args = ( 719 , 567 , 720 , 568 ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:limits\", 3, 60, 3, 66], \"args\"]]"}
{"project": "sympy", "commit_sha": "8841811705ce0ad5acc065cd42eab31a80baa356", "parent_sha": "a5adf10799712da33598304fe24d14d59f90454a", "file_path": "sympy/core/tests/test_args.py", "project_url": "https://github.com/sampadsaha5/sympy", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2450,7 +2450,7 @@ def test_sympy__tensor__indexed__IndexedBase():\n def test_sympy__tensor__tensor__TensorIndexType():\n     from sympy.tensor.tensor import TensorIndexType\n     from sympy import Symbol\n-    assert _test_args(TensorIndexType(Symbol('Lorentz'), metric_sym=S.Zero))\n+    assert _test_args(TensorIndexType(Symbol('Lorentz'), metric_antisym=S.Zero))\n \n @XFAIL\n def test_sympy__tensor__tensor__TensorSymmetry():\n", "before": "assert _test_args ( TensorIndexType ( Symbol ( 'Lorentz' ) , metric_sym = S . Zero ) )", "after": "assert _test_args ( TensorIndexType ( Symbol ( 'Lorentz' ) , metric_antisym = S . Zero ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:metric_sym\", 3, 58, 3, 68], \"metric_antisym\"]]"}
{"project": "asv", "commit_sha": "fd9c60a6f423f0951c5c01fd4a3c81b35193e23d", "parent_sha": "0043c7943fa80e8a725182d507886b1719b820fd", "file_path": "asv/commands/dev.py", "project_url": "https://github.com/TomAugspurger/asv", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -41,5 +41,5 @@ class Dev(Run):\n     @classmethod\n     def run_from_conf_args(cls, conf, args):\n         return cls.run(\n-            conf=conf, bench=args.bench, show_exc=True, quick=True,\n+            conf=conf, bench=args.bench, show_stderr=True, quick=True,\n             python=args.python, dry_run=True)\n", "before": "return cls . run ( conf = conf , bench = args . bench , show_exc = True , quick = True , python = args . python , dry_run = True )", "after": "return cls . run ( conf = conf , bench = args . bench , show_stderr = True , quick = True , python = args . python , dry_run = True )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:show_exc\", 3, 42, 3, 50], \"show_stderr\"]]"}
{"project": "dask-ec2", "commit_sha": "7499d4269387f657a690b3d8d0184c0489a7d88b", "parent_sha": "59f008aff1dcda1effa533fa43779b64ed581b51", "file_path": "dec2/salt.py", "project_url": "https://github.com/TomAugspurger/dask-ec2", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -370,7 +370,7 @@ def upload_pillar(cluster, name, data):\n     import tempfile\n \n     master = cluster.instances[0].ssh_client\n-    f = tempfile.NamedTemporaryFile(\"w\", deleteF=False)\n+    f = tempfile.NamedTemporaryFile(\"w\", delete=False)\n     try:\n         yaml.safe_dump(data, f, default_flow_style=False)\n         f.close()\n", "before": "f = tempfile . NamedTemporaryFile ( \"w\" , deleteF = False )", "after": "f = tempfile . NamedTemporaryFile ( \"w\" , delete = False )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:deleteF\", 3, 42, 3, 49], \"delete\"]]"}
{"project": "unknown-horizons", "commit_sha": "83571c037f8fa9f385b3cdf8e88d330892e1ba06", "parent_sha": "0c5ea3406ff09af75adfe3c758844defbd42e212", "file_path": "horizons/network/networkinterface.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -274,7 +274,7 @@ class NetworkInterface(object):\n \t\t\"\"\"Returns a list of active games or None on fatal error\"\"\"\n \t\tret_mp_games = []\n \t\ttry:\n-\t\t\tgames = self._client.listgames(onlyThisVersion=only_this_version_allowed)\n+\t\t\tgames = self._client.listgames(only_this_version=only_this_version_allowed)\n \t\texcept NetworkException as e:\n \t\t\tfatal = self._handle_exception(e)\n \t\t\treturn [] if not fatal else None\n", "before": "games = self . _client . listgames ( onlyThisVersion = only_this_version_allowed )", "after": "games = self . _client . listgames ( only_this_version = only_this_version_allowed )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:onlyThisVersion\", 3, 35, 3, 50], \"only_this_version\"]]"}
{"project": "unknown-horizons", "commit_sha": "f4b876bc01dfc19ec07158b3f44cad288c6053c6", "parent_sha": "73b49c2f42578a888045cff85e48fe385ddd249b", "file_path": "horizons/gui/widgets/tooltip.py", "project_url": "https://github.com/schittom/unknown-horizons", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -114,7 +114,7 @@ class _Tooltip(object):\n \t\ttop_x, top_y = top_image.position\n \t\ttop_y += self.SIZE_BG_TOP\n \t\tfor i in xrange(0, line_count):\n-\t\t\tmiddle_image = Icon(IMAGE=self.MIDDLE_IMAGE)\n+\t\t\tmiddle_image = Icon(image=self.MIDDLE_IMAGE)\n \t\t\tmiddle_image.position = (top_x, top_y + self.LINE_HEIGHT * i)\n \t\t\tself.gui.addChild(middle_image)\n \t\tbottom_image = Icon(image=self.BOTTOM_IMAGE)\n", "before": "middle_image = Icon ( IMAGE = self . MIDDLE_IMAGE )", "after": "middle_image = Icon ( image = self . MIDDLE_IMAGE )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:IMAGE\", 3, 24, 3, 29], \"image\"]]"}
{"project": "reduction", "commit_sha": "2f5e142c7f0cd8de111de20f4d7ae671d0085545", "parent_sha": "81491df3d4ede0a50a2df2fbf3aac7808cf2d699", "file_path": "analysis/before_after_selfcal_quicklooks.py", "project_url": "https://github.com/ALMA-IMF/reduction", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -77,7 +77,7 @@ def make_comparison_image(preselfcal, postselfcal):\n     pl.subplots_adjust(wspace=0.0)\n \n     cbax = fig.add_axes([0.91,0.18,0.03,0.64])\n-    fig.colorbar(ax=cbax, mappable=im)\n+    fig.colorbar(cax=cbax, mappable=im)\n \n     diffstats = {'mean': np.nanmean(diff),\n                  'max': np.nanmax(diff),\n", "before": "fig . colorbar ( ax = cbax , mappable = im )", "after": "fig . colorbar ( cax = cbax , mappable = im )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:ax\", 3, 18, 3, 20], \"cax\"]]"}
{"project": "Zappa", "commit_sha": "fee4dc0ec9d58c6a3148e93dd146f95446780c95", "parent_sha": "2d1f253521efc67caee70139e8dc3ce98ecc0122", "file_path": "zappa/core.py", "project_url": "https://github.com/tripliks/Zappa", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -1099,7 +1099,7 @@ class Zappa(object):\n             versions_in_lambda.remove('$LATEST')\n             # Delete older revisions if their number exceeds the specified limit\n             for version in versions_in_lambda[::-1][num_revisions:]:\n-                self.lambda_client.delete_function(FunctionNmae=function_name,Qualifier=version)\n+                self.lambda_client.delete_function(FunctionName=function_name,Qualifier=version)\n \n         return response['FunctionArn']\n \n", "before": "self . lambda_client . delete_function ( FunctionNmae = function_name , Qualifier = version )", "after": "self . lambda_client . delete_function ( FunctionName = function_name , Qualifier = version )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:FunctionNmae\", 3, 52, 3, 64], \"FunctionName\"]]"}
{"project": "ansible-1", "commit_sha": "effa235eb67bef44389d5e141dcc0abfa8b9b492", "parent_sha": "e892646bc779601f18c25fda9fbaf09331702e71", "file_path": "lib/ansible/modules/network/edgeos/edgeos_command.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -178,7 +178,7 @@ def main():\n     if conditionals:\n         failed_conditions = [item.raw for item in conditionals]\n         msg = 'One or more conditional statements have not been satisfied'\n-        module.fail_json(msg=msg, falied_conditions=failed_conditions)\n+        module.fail_json(msg=msg, failed_conditions=failed_conditions)\n \n     result = {\n         'changed': False,\n", "before": "module . fail_json ( msg = msg , falied_conditions = failed_conditions )", "after": "module . fail_json ( msg = msg , failed_conditions = failed_conditions )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:falied_conditions\", 3, 35, 3, 52], \"failed_conditions\"]]"}
{"project": "ansible-1", "commit_sha": "b740d68eaa351a130c854cf49849b03a84f38fba", "parent_sha": "8faf9837d0ce612d96e93273a734ac209185e56d", "file_path": "lib/ansible/modules/storage/netapp/netapp_e_host.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -288,7 +288,7 @@ class Host(object):\n     def create_host(self):\n         post_body = dict(\n             name=self.name,\n-            host_type=dict(index=self.host_type_index),\n+            hostType=dict(index=self.host_type_index),\n             groupId=self.group_id,\n             ports=self.ports\n         )\n", "before": "post_body = dict ( name = self . name , host_type = dict ( index = self . host_type_index ) , groupId = self . group_id , ports = self . ports )", "after": "post_body = dict ( name = self . name , hostType = dict ( index = self . host_type_index ) , groupId = self . group_id , ports = self . ports )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:host_type\", 3, 13, 3, 22], \"hostType\"]]"}
{"project": "udacity-cs253-main-project", "commit_sha": "f66deaa61525a381e131df0f91063470ebae6938", "parent_sha": "780dca071223e3de78d058dc83b2c123cea66dc0", "file_path": "models/user_model.py", "project_url": "https://github.com/jeremiahrichter/udacity-cs253-main-project", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -30,7 +30,7 @@ class User(h.db.Model):\n         pw_hash = make_pw_hash(name, password)\n         return User(\n                 parent=users_key(),\n-                name=name,\n+                username=name,\n                 password=pw_hash,\n                 email=email\n         )\n", "before": "return User ( parent = users_key ( ) , name = name , password = pw_hash , email = email )", "after": "return User ( parent = users_key ( ) , username = name , password = pw_hash , email = email )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:name\", 3, 17, 3, 21], \"username\"]]"}
{"project": "ansible-1", "commit_sha": "c3d49d7db072077a8d04f7b7273840784904e3cb", "parent_sha": "52a40510d79189e78b2f149e0aa2a03cb49da04d", "file_path": "lib/ansible/modules/extras/packaging/os/pacman.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -245,7 +245,7 @@ def check_packages(module, pacman_path, packages, state):\n         module.exit_json(changed=True, msg=\"%s package(s) would be %s\" % (\n             len(would_be_changed), state))\n     else:\n-        module.exit_json(change=False, msg=\"package(s) already %s\" % state)\n+        module.exit_json(changed=False, msg=\"package(s) already %s\" % state)\n \n \n def main():\n", "before": "else : module . exit_json ( change = False , msg = \"package(s) already %s\" % state )", "after": "else : module . exit_json ( changed = False , msg = \"package(s) already %s\" % state )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:change\", 3, 26, 3, 32], \"changed\"]]"}
{"project": "ansible-1", "commit_sha": "3bf6c50fa95abcb1ab586f2fce53a99c39854c69", "parent_sha": "c5c78ab045b964fbb048d8a380533a649ad6f5ff", "file_path": "lib/ansible/modules/cloud/misc/terraform.py", "project_url": "https://github.com/drewp/ansible-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -293,7 +293,7 @@ def main():\n     else:\n         outputs = json.loads(outputs_text)\n \n-    module.exit_json(changed=changed, state=state, outputs=outputs, sdtout=out, stderr=err, command=' '.join(command))\n+    module.exit_json(changed=changed, state=state, outputs=outputs, stdout=out, stderr=err, command=' '.join(command))\n \n \n if __name__ == '__main__':\n", "before": "module . exit_json ( changed = changed , state = state , outputs = outputs , sdtout = out , stderr = err , command = ' ' . join ( command ) )", "after": "module . exit_json ( changed = changed , state = state , outputs = outputs , stdout = out , stderr = err , command = ' ' . join ( command ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:sdtout\", 3, 69, 3, 75], \"stdout\"]]"}
{"project": "sentry", "commit_sha": "4e102d13af293ce87b746997e0903b8a76d49f10", "parent_sha": "8110c5e757e6facd9b843a6608165ad05c6f2615", "file_path": "src/sentry/web/forms/add_project.py", "project_url": "https://github.com/noscripter/sentry", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -38,7 +38,7 @@ class AddProjectForm(forms.ModelForm):\n             data=project.get_audit_log_data(),\n         )\n \n-        project_created.send(instance=project, user=actor, sender=self)\n+        project_created.send(project=project, user=actor, sender=self)\n \n         create_sample_event(project, platform='javascript')\n \n", "before": "project_created . send ( instance = project , user = actor , sender = self )", "after": "project_created . send ( project = project , user = actor , sender = self )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:instance\", 3, 30, 3, 38], \"project\"]]"}
{"project": "Index_swap", "commit_sha": "7ca05e1687c2497537d32a3cebec02db1d9a8ad8", "parent_sha": "bf657f246609f37359a9c264ed298bca07c14626", "file_path": "parse_vcf.py", "project_url": "https://github.com/saka0045/Index_swap", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -26,7 +26,7 @@ def ParseArgs():\n     parser = argparse.ArgumentParser(description=\"Help Message\")\n     parser.add_argument(\"-i\", dest=\"inputFile\", required=True, help=\"Input VCF file\")\n     parser.add_argument(\"-o\", dest=\"outPath\", required=True, help=\"Ouput File\")\n-    parser.add_argument(\"-n\", dest=\"sampleName\", require=True, help=\"Name of the sample\")\n+    parser.add_argument(\"-n\", dest=\"sampleName\", required=True, help=\"Name of the sample\")\n     args = parser.parse_args()\n     \n     inputFile = os.path.abspath(args.inputFile)\n", "before": "parser . add_argument ( \"-n\" , dest = \"sampleName\" , require = True , help = \"Name of the sample\" )", "after": "parser . add_argument ( \"-n\" , dest = \"sampleName\" , required = True , help = \"Name of the sample\" )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:require\", 3, 50, 3, 57], \"required\"]]"}
{"project": "leanbase-python", "commit_sha": "05e51549af497c27f157b323bebdca08a6e0e23b", "parent_sha": "a6375650b09d8bfe0aea856384df70726689863f", "file_path": "leanbase/client/lbconvey.py", "project_url": "https://github.com/Leanbase/leanbase-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,7 +33,7 @@ def get_feature_status(team_id:str, feature_id:str)->FeatureDefinition:\n     if response:\n         return FeatureDefinition.from_encoding(\n             gs=response.get('gs'),\n-            _id=response.get('id'),\n+            id=response.get('id'),\n             es=response.get('es', []),\n             ss=response.get('ss', [])\n         )\n\\ No newline at end of file\n", "before": "return FeatureDefinition . from_encoding ( gs = response . get ( 'gs' ) , _id = response . get ( 'id' ) , es = response . get ( 'es' , [ ] ) , ss = response . get ( 'ss' , [ ] ) )   No newline at end of file", "after": "return FeatureDefinition . from_encoding ( gs = response . get ( 'gs' ) , id = response . get ( 'id' ) , es = response . get ( 'es' , [ ] ) , ss = response . get ( 'ss' , [ ] ) )   No newline at end of file", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:_id\", 3, 13, 3, 16], \"id\"]]"}
{"project": "configuration_draft", "commit_sha": "0cc3ccb1ef9ef8f0dcaf6b80314a5860c4b29632", "parent_sha": "1995721ce5917557d5f00def8c2d7536e87583f3", "file_path": "tests/test_export_package.py", "project_url": "https://github.com/bioimage-io/configuration_draft", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -6,7 +6,7 @@ from zipfile import ZipFile\n def test_export_package(unet2d_nuclei_broad_v0_3_path):\n     from bioimageio.spec import export_package\n \n-    package_path = export_package(unet2d_nuclei_broad_v0_3_path, weights_formats_priorities=[\"onnx\"])\n+    package_path = export_package(unet2d_nuclei_broad_v0_3_path, weights_priority_order=[\"onnx\"])\n     assert isinstance(package_path, Path), package_path\n     assert package_path.exists(), package_path\n \n", "before": "package_path = export_package ( unet2d_nuclei_broad_v0_3_path , weights_formats_priorities = [ \"onnx\" ] )", "after": "package_path = export_package ( unet2d_nuclei_broad_v0_3_path , weights_priority_order = [ \"onnx\" ] )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:weights_formats_priorities\", 3, 66, 3, 92], \"weights_priority_order\"]]"}
{"project": "prophetess-netbox", "commit_sha": "f47ff72c695e9eec56b12d7e78dcdf58f2118066", "parent_sha": "06d38af56d8e9d20bf5c59c9cc797736bce7f7e1", "file_path": "prophetess_netbox/client.py", "project_url": "https://github.com/vapor-ware/prophetess-netbox", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -22,7 +22,7 @@ class NetboxClient:\n         self.loop = loop or asyncio.get_event_loop()\n         self.__cache = {} # TODO: make a decorator that caches api classes?\n \n-        self.client = AIONetbox.from_openapi(host=host, api_key=api_key)\n+        self.client = AIONetbox.from_openapi(url=host, api_key=api_key)\n \n     async def close(self):\n         await self.client.close()\n", "before": "self . client = AIONetbox . from_openapi ( host = host , api_key = api_key )", "after": "self . client = AIONetbox . from_openapi ( url = host , api_key = api_key )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:host\", 3, 46, 3, 50], \"url\"]]"}
{"project": "hfsbe", "commit_sha": "2b790b3f8e8a5670c48101113787d9012768ac70", "parent_sha": "8ea826dc0cc9be093dd1b8eebbe1a948d8ac2419", "file_path": "tests/18_Semiconductor_Nk1_50_Nk2_length_user_efield/runscript.py", "project_url": "https://github.com/ccmt-regensburg/hfsbe", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -33,7 +33,7 @@ def semich_bite():\n     muz = 0.033\n \n     semich_bite_system = cued.hamiltonian.Semiconductor(A=A, mz=muz, mx=mx,\n-                                                        a=8.28834, align=True)\n+                                                        a=8.28834, nature=True)\n     return semich_bite_system\n \n \n", "before": "semich_bite_system = cued . hamiltonian . Semiconductor ( A = A , mz = muz , mx = mx , a = 8.28834 , align = True )", "after": "semich_bite_system = cued . hamiltonian . Semiconductor ( A = A , mz = muz , mx = mx , a = 8.28834 , nature = True )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:align\", 3, 68, 3, 73], \"nature\"]]"}
{"project": "soundcloud-python", "commit_sha": "21fb7b7a0ae410f3f58933abade212ce71904d2c", "parent_sha": "0fc08bf414ba4f47700002b22c409eeb42420c9b", "file_path": "soundcloud/tests/test_client.py", "project_url": "https://github.com/mobolic/soundcloud-python", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -79,7 +79,7 @@ def test_disabling_ssl_verification(fake_get):\n     (fake_get.expects_call()\n              .with_args(expected_url,\n                         headers=headers,\n-                        verify_ssl=False,\n+                        verify=False,\n                         allow_redirects=True)\n              .returns(MockResponse(\"{}\")))\n     client.get('tracks', order='hotness', limit=5)\n", "before": "( fake_get . expects_call ( ) . with_args ( expected_url , headers = headers , verify_ssl = False , allow_redirects = True ) . returns ( MockResponse ( \"{}\" ) ) )", "after": "( fake_get . expects_call ( ) . with_args ( expected_url , headers = headers , verify = False , allow_redirects = True ) . returns ( MockResponse ( \"{}\" ) ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:verify_ssl\", 3, 25, 3, 35], \"verify\"]]"}
{"project": "salt", "commit_sha": "7ae519c34e75df33f14492fee990ded225f05d01", "parent_sha": "e4d84c776a17a219512f82ef6b17836f68a679ea", "file_path": "tests/unit/states/rvm_test.py", "project_url": "https://github.com/StepOneInc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -88,7 +88,7 @@ class TestRvmState(TestCase):\n             with patch.object(rvm, '_check_and_install_ruby', new=mock):\n                 rvm.installed('1.9.3', default=True)\n         mock.assert_called_once_with(\n-            {'result': True}, '1.9.3', True, runas=None)\n+            {'result': True}, '1.9.3', True, user=None)\n \n \n if __name__ == '__main__':\n", "before": "mock . assert_called_once_with ( { 'result' : True } , '1.9.3' , True , runas = None )", "after": "mock . assert_called_once_with ( { 'result' : True } , '1.9.3' , True , user = None )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:runas\", 3, 46, 3, 51], \"user\"]]"}
{"project": "salt", "commit_sha": "3d86d2414da5cd085760705b077610f03329074b", "parent_sha": "a46248178ea6f67b30a43cce6b34368b7db9940c", "file_path": "salt/daemons/flo/core.py", "project_url": "https://github.com/StepOneInc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -163,7 +163,7 @@ class SaltRaetRoadStackJoiner(ioflo.base.deeding.Deed):\n         stack = self.stack.value\n         if stack and isinstance(stack, RoadStack):\n-            stack.join(mha=self.mha, timeout=0.0)\n+            stack.join(ha=self.mha, timeout=0.0)\n \n \n class SaltRaetRoadStackJoined(ioflo.base.deeding.Deed):\n", "before": "stack . join ( mha = self . mha , timeout = 0.0 )", "after": "stack . join ( ha = self . mha , timeout = 0.0 )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:mha\", 2, 24, 2, 27], \"ha\"]]"}
{"project": "salt", "commit_sha": "03dbf0ce85db92ff4a1fa3d085d81149e833a0c8", "parent_sha": "d7013a2f64eb4b79592220d76274bc5dde609e08", "file_path": "salt/minion.py", "project_url": "https://github.com/StepOneInc/salt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -2489,7 +2489,7 @@ class Matcher(object):\n             return False\n         return salt.utils.subdict_match(self.opts['pillar'],\n                                         tgt,\n-                                        delim=delim,\n+                                        delimiter=delim,\n                                         exact_match=True)\n \n     def ipcidr_match(self, tgt):\n", "before": "return salt . utils . subdict_match ( self . opts [ 'pillar' ] , tgt , delim = delim , exact_match = True )", "after": "return salt . utils . subdict_match ( self . opts [ 'pillar' ] , tgt , delimiter = delim , exact_match = True )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:delim\", 3, 41, 3, 46], \"delimiter\"]]"}
{"project": "https-github.com-fchollet-keras", "commit_sha": "c57d1a32194983f28cb944722e6f7bc6de82cb10", "parent_sha": "d87148c56b0bb86669a11697b7d94c24a8d4ff86", "file_path": "keras/applications/audio_conv_utils.py", "project_url": "https://github.com/amongstar/https-github.com-fchollet-keras", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -62,7 +62,7 @@ def preprocess_input(audio_path, dim_ordering='default'):\n \n     logam = librosa.logamplitude\n     melgram = librosa.feature.melspectrogram\n-    x = logam(melgram(y=src, sr=sr, hop_lengthgth=hop_length,\n+    x = logam(melgram(y=src, sr=sr, hop_length=hop_length,\n                       n_fft=n_fft, n_mels=n_mels) ** 2,\n               ref_power=1.0)\n \n", "before": "x = logam ( melgram ( y = src , sr = sr , hop_lengthgth = hop_length , n_fft = n_fft , n_mels = n_mels ) ** 2 , ref_power = 1.0 )", "after": "x = logam ( melgram ( y = src , sr = sr , hop_length = hop_length , n_fft = n_fft , n_mels = n_mels ) ** 2 , ref_power = 1.0 )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:hop_lengthgth\", 3, 37, 3, 50], \"hop_length\"]]"}
{"project": "zulip", "commit_sha": "a454417843d9bf59360dc803d05c259da40baf68", "parent_sha": "af401fe659830a93a320047616ee58e45c856fa9", "file_path": "zephyr/forms.py", "project_url": "https://github.com/jjmachan/zulip", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -9,7 +9,7 @@ from models import Realm\n \n def is_unique(value):\n     try:\n-        User.objects.get(email=value)\n+        User.objects.get(email__iexact=value)\n         raise ValidationError(u'%s is already registered' % value)\n     except User.DoesNotExist:\n         pass\n", "before": "User . objects . get ( email = value )", "after": "User . objects . get ( email__iexact = value )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:email\", 3, 26, 3, 31], \"email__iexact\"]]"}
{"project": "ESP-Website-1", "commit_sha": "3a73dd5031d52d6c42ebf398c99161593e44971e", "parent_sha": "ddac1b6f2cbcbf36bd10968f1049ce8b78344b45", "file_path": "esp/esp/program/modules/handlers/financialaidapp.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/ESP-Website-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -44,7 +44,7 @@ from django              import newforms as forms\n class FinancialAidAppModule(ProgramModuleObj):\n \n     def students(self, QObject = False):\n-        Q_students = Q(financialaidapp__program = self.program)\n+        Q_students = Q(financialaidrequest__program = self.program)\n \n         Q_students_complete = Q(financialaidrequest__done = True)\n \n", "before": "Q_students = Q ( financialaidapp__program = self . program )", "after": "Q_students = Q ( financialaidrequest__program = self . program )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:financialaidapp__program\", 3, 24, 3, 48], \"financialaidrequest__program\"]]"}
{"project": "ESP-Website-1", "commit_sha": "9b11c85c31c5bb647d90a6c44b958151925c4ec7", "parent_sha": "afb8fdd61fb4bf1b7464fdf549c472da006aced0", "file_path": "esp/esp/program/modules/handlers/adminvitals.py", "project_url": "https://github.com/UNIVERSAL-IT-SYSTEMS/ESP-Website-1", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -72,7 +72,7 @@ class AdminVitals(ProgramModuleObj):\n         for timeslot in timeslots:\n             curTimeslot = {'slotname': timeslot.short_description}\n             \n-            curclasses = ClassSection.objects.filter(class__parent_program = self.program,\n+            curclasses = ClassSection.objects.filter(classsubject__parent_program = self.program,\n                                               meeting_times  = timeslot)\n \n             curTimeslot['classcount'] = curclasses\n", "before": "curclasses = ClassSection . objects . filter ( class__parent_program = self . program , meeting_times = timeslot )", "after": "curclasses = ClassSection . objects . filter ( classsubject__parent_program = self . program , meeting_times = timeslot )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:class__parent_program\", 3, 54, 3, 75], \"classsubject__parent_program\"]]"}
{"project": "django-taggit", "commit_sha": "6adfb70bb98effea01f98514b210b7971a6bbbf8", "parent_sha": "3c27a56b5957438e145ff56b20c8624bc8db5ab6", "file_path": "taggit/tests/tests.py", "project_url": "https://github.com/thecut/django-taggit", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -148,7 +148,7 @@ class TaggableManagerTestCase(BaseTaggingTestCase):\n         guava = self.food_model.objects.create(name=\"guava\")\n         \n         self.assertEqual(\n-            map(lambda o: o.pk, self.food_model.objects.exclude(tags__in=[\"red\"])),\n+            map(lambda o: o.pk, self.food_model.objects.exclude(tags__name__in=[\"red\"])),\n             [pear.pk, guava.pk],\n         )\n \n", "before": "self . assertEqual ( map ( lambda o : o . pk , self . food_model . objects . exclude ( tags__in = [ \"red\" ] ) ) , [ pear . pk , guava . pk ] , )", "after": "self . assertEqual ( map ( lambda o : o . pk , self . food_model . objects . exclude ( tags__name__in = [ \"red\" ] ) ) , [ pear . pk , guava . pk ] , )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:tags__in\", 3, 65, 3, 73], \"tags__name__in\"]]"}
{"project": "pybbm", "commit_sha": "3092b42231e3e2f4316f571f068e68784b85cad0", "parent_sha": "89b06cf1e82e568eb3259ea17e647579a0f32bb5", "file_path": "pybb/views.py", "project_url": "https://github.com/concentricsky/pybbm", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -247,7 +247,7 @@ class AddPostView(FormChoiceMixin, generic.CreateView):\n                 aformset.save()\n                 return super(ModelFormMixin, self).form_valid(form)\n             else:\n-                return self.render_to_response(self.get_context_data(form=form, aforormset=aformset))\n+                return self.render_to_response(self.get_context_data(form=form, aformset=aformset))\n         return super(AddPostView, self).form_valid(form)\n         \n     @method_decorator(csrf_protect)\n", "before": "else : return self . render_to_response ( self . get_context_data ( form = form , aforormset = aformset ) )", "after": "else : return self . render_to_response ( self . get_context_data ( form = form , aformset = aformset ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:aforormset\", 3, 81, 3, 91], \"aformset\"]]"}
{"project": "reviewboard", "commit_sha": "0174575b187f52c769976b49618232f0c2298585", "parent_sha": "457a1f6b24f4a18ac7ff8e5a1e61ed13ebe955c2", "file_path": "reviewboard/admin/management/evolutions.py", "project_url": "https://github.com/iosphere/reviewboard", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -36,7 +36,7 @@ def init_evolutions(app, created_models, **kwargs):\n         # marked the schemas as being up to date in the stored signature.\n         try:\n             # If this succeeds, we're good.\n-            FileDiff.objects.filter(parent_diff=\"\")\n+            FileDiff.objects.filter(parent_diff64=\"\")\n \n             return\n         except:\n", "before": "FileDiff . objects . filter ( parent_diff = \"\" )", "after": "FileDiff . objects . filter ( parent_diff64 = \"\" )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:parent_diff\", 3, 37, 3, 48], \"parent_diff64\"]]"}
{"project": "django-cart", "commit_sha": "f2c7cc253ed08dd18f6e62b0eb12eaa75297f039", "parent_sha": "935d6823f195cd57cc9a28f776158244dff8dfae", "file_path": "cart/models.py", "project_url": "https://github.com/Akoten/django-cart", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -47,7 +47,7 @@ class Item(models.Model):\n \n     # product\n     def get_product(self):\n-        return self.content_type.get_object_for_this_type(id=self.object_id)\n+        return self.content_type.get_object_for_this_type(pk=self.object_id)\n \n     def set_product(self, product):\n         self.content_type = ContentType.objects.get_for_model(type(product))\n", "before": "return self . content_type . get_object_for_this_type ( id = self . object_id )", "after": "return self . content_type . get_object_for_this_type ( pk = self . object_id )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:id\", 3, 59, 3, 61], \"pk\"]]"}
{"project": "geonode-announcements", "commit_sha": "7021babb424604063f3b4afea715f869039b60b6", "parent_sha": "69da84707c2c67931fe8ca4bf7584ac4832c4f03", "file_path": "announcements/models.py", "project_url": "https://github.com/GeoNode/geonode-announcements", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -79,7 +79,7 @@ class Announcement(models.Model):\n                 users = User.objects.filter(is_staff=True)\n             else:\n                 users = User.objects.all()\n-            notification.send(users, \"announcement\", {\"announcement\": self}, issue_notice=False)\n+            notification.send(users, \"announcement\", {\"announcement\": self}, on_site=False)\n         super(Announcement, self).save(force_insert, force_update)\n \n def current_announcements_for_request(request, **kwargs):\n", "before": "notification . send ( users , \"announcement\" , { \"announcement\" : self } , issue_notice = False )", "after": "notification . send ( users , \"announcement\" , { \"announcement\" : self } , on_site = False )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:issue_notice\", 3, 78, 3, 90], \"on_site\"]]"}
{"project": "geonode-ratings", "commit_sha": "885d9f6e0572b21f94edc6559610a7c695b4d5a9", "parent_sha": "1190af087157e91bb873e624f161b1e13fa7bfab", "file_path": "agon_ratings/views.py", "project_url": "https://github.com/GeoNode/geonode-ratings", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -81,4 +81,4 @@ def rate(request, content_type_id, object_id):\n         overall.update()\n         data[\"overall_rating\"] = str(overall.rating)\n     \n-    return HttpResponse(json.dumps(data), mimetype=\"application/json\")\n+    return HttpResponse(json.dumps(data), content_type=\"application/json\")\n", "before": "return HttpResponse ( json . dumps ( data ) , mimetype = \"application/json\" )", "after": "return HttpResponse ( json . dumps ( data ) , content_type = \"application/json\" )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:mimetype\", 3, 43, 3, 51], \"content_type\"]]"}
{"project": "openobject-server", "commit_sha": "38b97e3c09945a81cae7a8a02e1bae2cdd57114a", "parent_sha": "f0d3fea05f695e99542c4c6a924872bf8fd4cfc4", "file_path": "openerp/addons/base/res/res_users.py", "project_url": "https://github.com/gisce/openobject-server", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -398,7 +398,7 @@ class res_users(osv.osv):\n                 # prevent/delay login in that case. It will also have been logged\n                 # as a SQL error, if anyone cares.\n                 try:\n-                    cr.execute(\"SELECT id FROM res_users WHERE id=%s FOR UPDATE NOWAIT\", (user_id,), log_exception=False)\n+                    cr.execute(\"SELECT id FROM res_users WHERE id=%s FOR UPDATE NOWAIT\", (user_id,), log_exceptions=False)\n                     cr.execute(\"UPDATE res_users SET login_date = now() AT TIME ZONE 'UTC' WHERE id=%s\", (user_id,))\n                 except Exception:\n                     _logger.debug(\"Failed to update last_login for db:%s login:%s\", db, login, exc_info=True)\n", "before": "cr . execute ( \"SELECT id FROM res_users WHERE id=%s FOR UPDATE NOWAIT\" , ( user_id , ) , log_exception = False )", "after": "cr . execute ( \"SELECT id FROM res_users WHERE id=%s FOR UPDATE NOWAIT\" , ( user_id , ) , log_exceptions = False )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:log_exception\", 3, 102, 3, 115], \"log_exceptions\"]]"}
{"project": "osf.io", "commit_sha": "9c7341108b0571372237186ca41b29407222afa7", "parent_sha": "21b63b0cfd50457db334e104a119337b80a977ba", "file_path": "tests/test_views.py", "project_url": "https://github.com/Vhoakab84/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -570,7 +570,7 @@ class TestProjectViews(OsfTestCase):\n         non_contributor = AuthUserFactory()\n         res = self.app.post_json(url, {}, \n                            auth=non_contributor.auth, \n-                           expect_error=True)\n+                           expect_errors=True)\n         assert_equal(res.status_code, http.FORBIDDEN)\n \n class TestUserProfile(OsfTestCase):\n", "before": "res = self . app . post_json ( url , { } , auth = non_contributor . auth , expect_error = True )", "after": "res = self . app . post_json ( url , { } , auth = non_contributor . auth , expect_errors = True )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:expect_error\", 3, 28, 3, 40], \"expect_errors\"]]"}
{"project": "ausgsteckt", "commit_sha": "d0e68df7165d2a75b16155ccd0f0e4a8ee5b843e", "parent_sha": "b32ef7cb9207698c96e0f4acc12fe095129c6d02", "file_path": "ausgsteckt/buschenschank/models.py", "project_url": "https://github.com/kelvan/ausgsteckt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -175,7 +175,7 @@ class Region(OSMItemModel, TimeStampedModel, SoftDeletableModel,\n         return reverse('buschenschank:region_details', kwargs={'pk': self.pk})\n \n     def get_buschenschank(self):\n-        return Buschenschank.objects.filter(coordinates__contained=self.areas)\n+        return Buschenschank.objects.filter(coordinates__intersects=self.areas)\n \n     class Meta:\n         verbose_name = _('Region')\n", "before": "return Buschenschank . objects . filter ( coordinates__contained = self . areas )", "after": "return Buschenschank . objects . filter ( coordinates__intersects = self . areas )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:coordinates__contained\", 3, 45, 3, 67], \"coordinates__intersects\"]]"}
{"project": "ausgsteckt", "commit_sha": "5903cb00a1578071ed7df8310283ce183e2a3ffc", "parent_sha": "1b2bfda37534621407808b8b3a207b000cd31363", "file_path": "ausgsteckt/buschenschank/models.py", "project_url": "https://github.com/kelvan/ausgsteckt", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -235,7 +235,7 @@ class Commune(TimeStampedModel, SoftDeletableModel):\n         return self.name\n \n     def get_buschenschank(self):\n-        return Buschenschank.objects.filter(coordinates__contained=self.mpoly)\n+        return Buschenschank.objects.filter(coordinates__intersects=self.mpoly)\n \n     class Meta:\n         verbose_name = _('Commune')\n", "before": "return Buschenschank . objects . filter ( coordinates__contained = self . mpoly )", "after": "return Buschenschank . objects . filter ( coordinates__intersects = self . mpoly )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:coordinates__contained\", 3, 45, 3, 67], \"coordinates__intersects\"]]"}
{"project": "osf.io", "commit_sha": "fa316a4a934334ba924ccb0883f53905898a5552", "parent_sha": "666bf040aa3e19cd104b2acf38bb8175fdfc8b28", "file_path": "website/views.py", "project_url": "https://github.com/Vhoakab84/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -262,7 +262,7 @@ def get_dashboard_nodes(auth):\n         if perm not in permissions.PERMISSIONS:\n             raise HTTPError(http.BAD_REQUEST, dict(\n                 message_short='Invalid query parameter',\n-                message_oong='{0} is not in {1}'.format(perm, permissions.PERMISSIONS)\n+                message_long='{0} is not in {1}'.format(perm, permissions.PERMISSIONS)\n             ))\n         response_nodes = [node for node in nodes if node.has_permission(user, permission=perm)]\n     else:\n", "before": "raise HTTPError ( http . BAD_REQUEST , dict ( message_short = 'Invalid query parameter' , message_oong = '{0} is not in {1}' . format ( perm , permissions . PERMISSIONS ) ) )", "after": "raise HTTPError ( http . BAD_REQUEST , dict ( message_short = 'Invalid query parameter' , message_long = '{0} is not in {1}' . format ( perm , permissions . PERMISSIONS ) ) )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:message_oong\", 3, 17, 3, 29], \"message_long\"]]"}
{"project": "osf.io", "commit_sha": "81fd73ba840b0a9ef0766cf0080c70d2a524d451", "parent_sha": "6b1ee30f22aab3ad5b351fc2bd7a710307ba88c0", "file_path": "website/preprints/tasks.py", "project_url": "https://github.com/Vhoakab84/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -119,7 +119,7 @@ def format_preprint(preprint):\n         )\n \n     preprint_graph.attrs['tags'] = [\n-        GraphNode('throughtags', creative_work=preprint_graph, subject=GraphNode('tag', name=tag._id))\n+        GraphNode('throughtags', creative_work=preprint_graph, tag=GraphNode('tag', name=tag._id))\n         for tag in preprint.node.tags\n     ]\n \n", "before": "preprint_graph . attrs [ 'tags' ] = [ GraphNode ( 'throughtags' , creative_work = preprint_graph , subject = GraphNode ( 'tag' , name = tag . _id ) ) for tag in preprint . node . tags ]", "after": "preprint_graph . attrs [ 'tags' ] = [ GraphNode ( 'throughtags' , creative_work = preprint_graph , tag = GraphNode ( 'tag' , name = tag . _id ) ) for tag in preprint . node . tags ]", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:subject\", 3, 64, 3, 71], \"tag\"]]"}
{"project": "osf.io", "commit_sha": "433f826ebe472683198c75b0bb4ac3119356c5c0", "parent_sha": "799d3faaa4c085a58d1fb11dd03f009338a51e48", "file_path": "tests/test_views.py", "project_url": "https://github.com/Vhoakab84/osf.io", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -4164,7 +4164,7 @@ class TestDashboardViews(OsfTestCase):\n \n     def test_registered_components_with_are_accessible_from_dashboard(self):\n         project = ProjectFactory(creator=self.creator, is_public=False)\n-        component = NodeFactory(creator=self.creator, is_parent=project)\n+        component = NodeFactory(creator=self.creator, parent=project)\n         component.add_contributor(self.contrib, auth=Auth(self.creator))\n         component.save()\n         project.register_node(\n", "before": "component = NodeFactory ( creator = self . creator , is_parent = project )", "after": "component = NodeFactory ( creator = self . creator , parent = project )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:is_parent\", 3, 55, 3, 64], \"parent\"]]"}
{"project": "my_first_blog", "commit_sha": "da48dd19cd2d35cff6478510916b2affd5c36ccc", "parent_sha": "aed052be537dd5f5a9587ba509e21919382fd3a0", "file_path": "blog/views.py", "project_url": "https://github.com/Asumanz/my_first_blog", "likely_bug": true, "comodified": false, "in_function": true, "diff": "@@ -4,5 +4,5 @@ from .models import Post\n \n # Create your views here.\n def post_list(request):\n-\tposts = Post.objects.filter(published_date_lte=timezone.now()).order_by('published_date')\n+\tposts = Post.objects.filter(published_date__lte=timezone.now()).order_by('published_date')\n \treturn render(request, 'blog/post_list.html', {'posts':posts})\n\\ No newline at end of file\n", "before": "posts = Post . objects . filter ( published_date_lte = timezone . now ( ) ) . order_by ( 'published_date' )", "after": "posts = Post . objects . filter ( published_date__lte = timezone . now ( ) ) . order_by ( 'published_date' )", "sstub_pattern": "CHANGE_KEYWORD_ARGUMENT_USED", "edit_script": "[[\"Update\", [\"identifier:published_date_lte\", 3, 30, 3, 48], \"published_date__lte\"]]"}
