#!/usr/bin/env python

#
# Author: Steven Ludtke, 04/10/2003 (sludtke@bcm.edu)
# Copyright (c) 2000-2006 Baylor College of Medicine
#
# This software is issued under a joint BSD/GNU license. You may use the
# source code in this file under either license. However, note that the
# complete EMAN2 and SPARX software packages have some GPL dependencies,
# so you are responsible for compliance with the licenses of these packages
# if you opt to use BSD licensing. The warranty disclaimer below holds
# in either instance.
#
# This complete copyright notice must be included in any revised version of the
# source code. Additional authorship citations may be added, but existing
# author citations must be preserved.
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  2111-1307 USA
#
#
from EMAN2 import *
from optparse import OptionParser
from math import *
import os
import sys

def main():
	progname = os.path.basename(sys.argv[0])
	usage = """%prog [options] 
	This program will compute a variance map, using the results from an iteration of e2refine.py as a basis
	for the computation. It uses a bootstrap resampling technique, where random particles are excluded from
	the model with replacement. This is repeated N times, producing a new 3-D model each time. The variance of
	the 3-D models is then computed. Note that this program requires a fair bit of memory. If running the entire program
	on a single machine, you will need enough memory to hold ~5 copies of a 3-D map + whatever is required
	by e2classaverage.py. It may be best-used on downsampled data (also for speed)."""
	parser = OptionParser(usage=usage,version=EMANVERSION)
		
	#options associated with e2refinevariance.py
	parser.add_option("--verbose", "-v", dest="verbose", action="store", metavar="n", type="int", default=0, help="verbose level [0-9], higner number means higher level of verboseness")
	parser.add_option("--input", dest="input", default=None,type="string", help="The name of the image containing the particle data")
	parser.add_option("--usefilt", dest="usefilt", type="string",default=None, help="Specify a particle data file that has been low pass or Wiener filtered. Has a one to one correspondence with your particle data. If specified will be used in projection matching routines, and elsewhere.")
	parser.add_option("--path", default=None, type="string",help="The name of a directory where results are placed. If unspecified will generate one automatically of type refine_??.")
	parser.add_option("--mass", default=None, type="float",help="The mass of the particle in kilodaltons, used to run normalize.bymass. If unspecified nothing happens. Requires the --apix argument.")
	parser.add_option("--apix", default=None, type="float",help="The angstrom per pixel of the input particles. This argument is required if you specify the --mass argument. If unspecified, the convergence plot is generated using either the project apix, or if not an apix of 1.")
	parser.add_option("--automask3d", default=None, type="string",help="The 5 parameters of the mask.auto3d processor, applied after 3D reconstruction. These paramaters are, in order, isosurface threshold,radius,nshells, ngaussshells and nmaxseed. From e2proc3d.py you could achieve the same thing using --process=mask.auto3d:threshold=1.1:radius=30:nmaxseed=10:nshells=5:ngaussshells=5.")
	parser.add_option("--nmodels", type="int", help="The number of different bootstrap models to generate for the variance computation. Default=10", default=10)
	parser.add_option("--iteration", type="int", help="The refinement iteration to use as a basis for the variance map", default=-1)
	parser.add_option("--volfiles",action="store_true",help="This will bypass the construction of the individual resampled models, and use files previously generated with the --keep3d options",default=False)

	# options associated with e2project3d.py
	parser.add_option("--sym", dest = "sym", help = "Specify symmetry - choices are: c<n>, d<n>, h<n>, tet, oct, icos",default=c1)
		
	# options associated with e2classaverage.py
	parser.add_option("--classkeep",type="float",help="The fraction of particles to keep in each class, based on the similarity score generated by the --cmp argument.")
	parser.add_option("--classkeepsig", default=False, action="store_true", help="Change the keep (\'--keep\') criterion from fraction-based to sigma-based.")
	parser.add_option("--classiter", type="int", help="The number of iterations to perform. Default is 1.", default=3)
	parser.add_option("--classalign",type="string",help="If doing more than one iteration, this is the name and parameters of the 'aligner' used to align particles to the previous class average.", default="rotate_translate_flip")
	parser.add_option("--classaligncmp",type="string",help="This is the name and parameters of the comparitor used by the fist stage aligner  Default is dot.",default="phase")
	parser.add_option("--classralign",type="string",help="The second stage aligner which refines the results of the first alignment in class averaging. Default is None.", default=None)
	parser.add_option("--classraligncmp",type="string",help="The comparitor used by the second stage aligner in class averageing. Default is dot:normalize=1.",default="dot:normalize=1")
	parser.add_option("--classaverager",type="string",help="The averager used to generate the class averages. Default is \'mean\'.",default="mean")
	parser.add_option("--classcmp",type="string",help="The name and parameters of the comparitor used to generate similarity scores, when class averaging. Default is \'dot:normalize=1\'", default="dot:normalize=1")
	parser.add_option("--classnormproc",type="string",default="normalize.edgemean",help="Normalization applied during class averaging")
	parser.add_option("--classrefsf",default=False, action="store_true", help="Use the setsfref option in class averaging to produce better filtered averages.")
	parser.add_option("--prefilt",action="store_true",help="Filter each reference (c) to match the power spectrum of each particle (r) before alignment and comparison",default=False)
	
	#options associated with e2make3d.py
	parser.add_option("--pad", type=int, dest="pad", help="To reduce Fourier artifacts, the model is typically padded by ~25% - only applies to Fourier reconstruction", default=0)
	parser.add_option("--recon", dest="recon", default="fourier", help="Reconstructor to use see e2help.py reconstructors -v")
	parser.add_option("--m3dkeep", type=float, help="The percentage of slices to keep in e2make3d.py")
	parser.add_option("--m3dkeepsig", default=False, action="store_true", help="The standard deviation alternative to the --m3dkeep argument")
	parser.add_option("--m3dsetsf", default=False, action="store_true", help="The standard deviation alternative to the --m3dkeep argument")
	parser.add_option("--m3diter", type=int, default=4, help="The number of times the 3D reconstruction should be iterated")
	parser.add_option("--m3dpreprocess", type="string", default="normalize.edgemean", help="Normalization processor applied before 3D reconstruction")
	parser.add_option("--m3dpostprocess", type="string", default=None, help="Post processor to be applied to the 3D volume once the reconstruction is completed")
	parser.add_option("--shrink3d",type="int",help="Shrink the class-averages and make a downsampled variance map",default=0)
	parser.add_option("--keep3d",action="store_true",help="Keep all of the individual 3-D models used to make the variance map. This make take substantial disk space.")

	#lowmem!
	parser.add_option("--lowmem", default=False, action="store_true",help="Make limited use of memory when possible - useful on lower end machines")
	parser.add_option("--parallel","-P",type="string",help="Run in parallel, specify type:<option>=<value>:<option>:<value>",default=None)

	
	(options, args) = parser.parse_args()
	if options.sym.lower()=="none" : options.sym="c1"
	
	if options.iteration<0 :
		print "You must specify a refinement iteration to use as a basis for the variance map."
		sys.exit(1)

	if options.automask3d: 
		vals = options.automask3d.split(",")
		mapping = ["threshold","radius","nshells","nshellsgauss","nmaxseed"]
		s = "mask.auto3d"
		try:
			for i,p in enumerate(mapping):
				s += ":"+p+"="+vals[i]
		except:
			print "Error: automask3d requires 5 parameters now. See the Wiki."
			sys.exit(1)
		s+= ":return_mask=1"
		options.automask3d = s

	logid=E2init(sys.argv)
	
	nprogress=options.nmodels*2.0+1.0
	# this loops over each of the n models we create to compute the variance
	for mod in xrange(options.nmodels) :
		if options.volfiles :
			options.model="var3d_%03d.mrc"%mod
		else:
			if options.verbose : print "Class-averaging"
			# Compute class-averages with the --resample option
			options.classifyfile="bdb:%s#classify_%02d"%(options.path,options.iteration)
			options.projfile="bdb:%s#projections_%02d"%(options.path,options.iteration)
			options.cafile="bdb:"+options.path+"#variance_classes_tmp"
			print get_classaverage_cmd(options)
			if ( os.system(get_classaverage_cmd(options)) != 0 ):
				print "Failed to execute %s" %get_classaverage_cmd(options)
				sys.exit(1)
			E2progress(logid,(mod*2.0+1)/nprogress)
			
			# deal with shrink3d
			if options.shrink3d : 
				if options.verbose : print "Shrinking"
				print "e2proc2d.py %s %s --meanshrink=%d --inplace --writejunk"%(options.cafile,options.cafile+"_s",options.shrink3d)
				if ( os.system("e2proc2d.py %s %s --meanshrink=%d --inplace --writejunk"%(options.cafile,options.cafile+"_s",options.shrink3d)) != 0 ):
					print "Failed to execute CA shrink"
					sys.exit(1)
				options.cafile=options.cafile+"_s"
			
			if options.verbose : print "3-D Reconstruction"
			# build a new 3-D map
			options.model="bdb:"+options.path+"#variance_threed_tmp"
			print get_make3d_cmd(options)
			if ( os.system(get_make3d_cmd(options)) != 0 ):
				print "Failed to execute %s" %get_make3d_cmd(options)
				sys.exit(1)
			E2progress(logid,(mod*2.0+2.0)/nprogress)

			# enforce symmetry
			if options.sym.lower()!="c1" :
				os.system("e2proc3d.py %s %s --sym=%s"%(options.model,options.model,options.sym))

		if options.verbose : print "Post-processing"

		cur_map=EMData(options.model,0)
		nx=cur_map["nx"]
		ny=cur_map["ny"]
		nz=cur_map["nz"]
		apix=cur_map["apix_x"]
		
		if options.mass:
			# if options.mass is not none, the check function has already ascertained that it's postivie non zero, and that the 
			# apix argument has been specified.
			cur_map.process_inplace("normalize.bymass",{"apix":options.apix, "mass":options.mass})
			if options.automask3d: 

				automask_parms = parsemodopt(options.automask3d) # this is just so we only ever have to do it

				mask = cur_map.process(automask_parms[0],automask_parms[1])
				cur_map.mult(mask)
		
		# Write the individual models to MRC files
		if options.keep3d and not options.volfiles : cur_map.write_image("var3d_%03d.mrc"%mod,0)
	
		# now keep a sum of all of the maps and all of the maps^2
		if mod==0 :
			mean_map=cur_map
			sqr_map=cur_map.process("math.squared")
		else :
			mean_map.add(cur_map)
			cur_map.process_inplace("math.squared")
			sqr_map.add(cur_map)
			cur_map=None
		
	# Ok, all done, now compute the mean and standard deviation. The mean map should look nearly identical to
	# the original results from the same iteration
	mean_map.mult(1.0/options.nmodels)
	mean_map.write_image("bdb:%s#threed_%02d_mean"%(options.path,options.iteration),0)
	
	# Now compute the variance from the two maps
	sqr_map.mult(1.0/options.nmodels)			# pixels are mean of x^2
	mean_map.process_inplace("math.squared")	
	sqr_map.sub(mean_map)						
	
	### Symmetry downweighting
	weight=EMData(nx,ny,nz)
	weight.to_zero()
	weight["apix_x"]=apix
	weight["apix_y"]=apix
	weight["apix_z"]=apix
	
	w=weight.copy()
	# A line along Z
	for i in xrange(0,nz): w[nx/2,ny/2,i]=1.0

	# replicate the line under symmetry
	t=Transform()
	ns=t.get_nsym(options.sym)
	for i in xrange(ns):
		t2=t.get_sym(options.sym,i)
		wc=w.process("xform",{"transform":t2})		# transformed version of weight
		weight.add(wc)
	
	weight.process_inplace("threshold.clampminmax",{"minval":1.0,"maxval":500.0})	# 60 would really normally be the max here, but with helical symmetry supported...

	# This filters the duplication map similarly to the actual map, approximating the exaggeration in variance
	if options.m3dpostprocess :
		tv=weight[nx/2,ny/2,nz/4]
		(processorname, param_dict) = parsemodopt(options.m3dpostprocess)
		weight.process_inplace(processorname, param_dict)
	
		# Now this is a bit tricky to argue. Along the axis we have n-fold redundancy, so that will define our normalization
		# so, we  a point 1/2 way up the Z axis to its value before filtration. 1/2 way up Z is to deal with things like icosahedral symmetry reasonably
		if weight[nx/2,ny/2,nz/4]>1.0 : rescale=(tv-1.0)/(weight[nx/2,ny/2,nz/4]-1.0)
		else : rescale=1.0
#		print rescale
		
		# now we reprocess with the weighting factor, but don't reweight the 1.0 region...
		weight.add(-1.0)
		weight.mult(rescale)
		weight.add(1.0)
	
#	display(weight)
	weight.process_inplace("math.invert.carefully",{"zero_to":1.0})		# this gives us 1/duplication on the symmetry axes and 1 off of the axes


#	display(weight)
	sqr_map.mult(weight)
	
	# Finally write the result
	sqr_map.write_image("bdb:%s#threed_%02d_variance"%(options.path,options.iteration),0)
	
	E2progress(logid,nprogress/nprogress)
	
	E2end(logid)

def get_make3d_cmd(options,check=False,nofilecheck=False):
	e2make3dcmd = "e2make3d.py --input=%s --sym=%s --iter=%d -f" %(options.cafile,options.sym,options.m3diter)
	
	e2make3dcmd += " --recon=%s --output=%s" %(options.recon,options.model)

	if str(options.m3dpreprocess) != "None":
		e2make3dcmd += " --preprocess=%s" %options.m3dpreprocess
		
	if str(options.m3dpostprocess) != "None":
		e2make3dcmd += " --postprocess=%s" %options.m3dpostprocess

	
	if (options.m3dkeep):
		e2make3dcmd += " --keep=%f" %options.m3dkeep
		if (options.m3dkeepsig): e2make3dcmd += " --keepsig"
	
	if options.m3dsetsf :
		e2make3dcmd += " --setsf=auto"
	
	if (options.lowmem): e2make3dcmd += " --lowmem"

	if (options.pad != 0):
		e2make3dcmd += " --pad=%d" %options.pad
		
	if (options.verbose):
		e2make3dcmd += " --verbose=" + str(options.verbose - 1)
	
	if ( check ):
		e2make3dcmd += " --check"	
			
	if ( nofilecheck ):
		e2make3dcmd += " --nofilecheck"
	
	return e2make3dcmd

def get_classaverage_cmd(options,check=False,nofilecheck=False):
	
	e2cacmd = "e2classaverage.py --resample --input=%s --classmx=%s --output=%s" %(options.input,options.classifyfile,options.cafile)
	
	e2cacmd += " --ref=%s --iter=%d -f --normproc=%s --averager=%s %s" %(options.projfile,options.classiter,options.classnormproc,options.classaverager,options.classrefsf)
	
	e2cacmd += " --dbpath=%s" %options.path
	
	if (options.classkeep):
		e2cacmd += " --keep=%f" %options.classkeep
		
	if (options.classkeepsig):
		e2cacmd += " --keepsig"
	
	if (options.classiter >= 1 ):
		e2cacmd += " --cmp=%s --align=%s --aligncmp=%s" %(options.classcmp,options.classalign,options.classaligncmp)

		if (options.classralign != None):
			e2cacmd += " --ralign=%s --raligncmp=%s" %(options.classralign,options.classraligncmp)
	
	if options.usefilt != None:
		e2cacmd += " --usefilt=%s" %options.usefilt
	
	if (options.verbose):
		e2cacmd += " --verbose=" + str(options.verbose - 1)
	
	if options.prefilt:
		e2cacmd += " --prefilt"
	
	if options.parallel: e2cacmd += " --parallel=%s" %options.parallel

		
	#lowmem becamoe the only supportable behaviour as of May 5th 2009
#	if (options.lowmem): e2cacmd += " --lowmem"
	
	if ( check ):
		e2cacmd += " --check"	
			
	if ( nofilecheck ):
		e2cacmd += " --nofilecheck"
	
	return e2cacmd

if __name__ == "__main__":
    main()
