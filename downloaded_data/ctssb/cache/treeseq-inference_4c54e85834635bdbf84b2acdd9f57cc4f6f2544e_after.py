#!/usr/bin/env python3
"""
Code to run simulations, inference methods and generate all plots
in the paper.

Run as e.g.

./plots.py setup metrics_by_mutation_rate -P
./plots.py infer metrics_by_mutation_rate -P -p 30 -t 8 #this may take a long time
./plots.py figure kc_rooted_by_mutation_rate

"""

import argparse
import collections
import filecmp
import glob
import itertools
import json
import logging
import multiprocessing
import os
import sys
import random
import shutil
import signal
import statistics
import subprocess
import tempfile
import time
import math
import gzip


import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as pyplot
import matplotlib.backends.backend_pdf
import pandas as pd
import tqdm

# import the local copy of msprime in preference to the global one
sys.path.insert(1,os.path.join(sys.path[0],'..','msprime'))
sys.path.insert(1,os.path.join(sys.path[0],'..','ftprime', 'examples'))

import msprime
import _msprime
import msprime_extras
import msprime_fastARG
import msprime_ARGweaver
import msprime_RentPlus
import ARG_metrics


fastARG_executable = os.path.join(sys.path[0],'..','fastARG','fastARG')
ARGweaver_executable = os.path.join(sys.path[0],'..','argweaver','bin','arg-sample')
smc2arg_executable = os.path.join(sys.path[0],'..','argweaver','bin','smc2arg')
RentPlus_executable = os.path.join(sys.path[0],'..','RentPlus','RentPlus.jar')
tsinfer_executable = os.path.join(sys.path[0],'run_tsinfer.py')

#monkey-patch write.nexus into msprime
msprime.TreeSequence.write_nexus_trees = msprime_extras.write_nexus_trees

FASTARG = "fastARG"
ARGWEAVER = "ARGweaver"
RENTPLUS = "RentPlus"
TSINFER = "tsinfer"

#names for optional columns in the dataset
ERROR_COLNAME = 'error_rate'
SUBSAMPLE_COLNAME = 'subsample_size'
SIMTOOL_COLNAME = 'sim_tool' #if column does not exist, default simulation tool = 'msprime'
MUTATION_SEED_COLNAME = 'mut_seed'
SELECTION_COEFF_COLNAME = 'selection_coefficient'
DOMINANCE_COEFF_COLNAME = 'dominance_coefficient'
SELECTED_FREQ_COLNAME = 'output_frequency'
SELECTED_POSTGEN_COLNAME = 'output_after_generations'

#bit flags for metrics
METRICS_OFF = 0
METRICS_ON  = 2**0
METRICS_AT_VARIANT_SITES = 2**1 #should we calculate over all bases, or at variant sites only
METRICS_RANDOMLY_BREAK_POLYTOMIES = 2**2

if sys.version_info[0] < 3:
    raise Exception("Python 3 only")

save_stats = dict(
    cpu = "cputime",
    mem =  "memory",
    n_edges = "edges",
    ts_filesize = "ts_filesize"
)

def nanblank(val):
    """hack around a horrible pandas syntax, which puts nan instead of blank strings"""
    return "" if pd.isnull(val) else val

def always_true(*pargs):
    """
    A func that returns True for any input value
    """
    return True

def ts_has_non_singleton_variants(ts):
    """
    Check if there are any doubletons or higher in a treeseq
    which have not been fixed
    (required for meaningful inference)
    """
    for v in ts.variants():
        if 1 < np.sum(v.genotypes) < ts.num_samples:
            return True
    return False


def make_errors(v, p):
    """
    For each sample an error occurs with probability p. Errors are generated by
    sampling values from the stationary distribution, that is, if we have an
    allele frequency of f, a 1 is emitted with probability f and a
    0 with probability 1 - f. Thus, there is a possibility that an 'error'
    will in fact result in the same value.
    """
    w = np.copy(v)
    if p > 0:
        m = v.shape[0]
        frequency = np.sum(v) / m
        # Randomly choose samples with probability p
        samples = np.where(np.random.random(m) < p)[0]
        # Generate observations from the stationary distribution.
        errors = (np.random.random(samples.shape[0]) < frequency).astype(int)
        w[samples] = errors
    return w

def generate_samples(ts, error_p):
    """
    Returns samples with a bits flipped with a specified probability.

    Rejects any variants that result in a fixed column.
    """
    S = np.zeros((ts.sample_size, ts.num_mutations), dtype="u1")
    if error_p == 0:
        for variant in ts.variants():
            S[:,variant.index] = variant.genotypes
    else:
        for variant in ts.variants():
            done = False
            # Reject any columns that have no 1s or no zeros
            while not done:
                S[:,variant.index] = make_errors(variant.genotypes, error_p)
                s = np.sum(S[:, variant.index])
                done = 0 < s < ts.sample_size
    return S

def mk_sim_name(n, Ne, l, rho, mu, genealogy_seed, mut_seed=None, directory=None, tool="msprime",
    s=None, h=None, freq=None, post_gens=None):
    """
    Create a filename for saving an msprime simulation (without extension)
    Other functions add error rates and/or a subsample sizes to the name
    """
    #format mut rate & recomb rate to print non-exponential notation without
    # trailing zeroes. 12 dp should be ample for these rates
    rho = "{:.12f}".format(float(rho)).rstrip('0')
    mu = "{:.12f}".format(float(mu)).rstrip('0')
    file = "{}-n{}_Ne{}_l{}_rho{}_mu{}-gs{}".format(tool, int(n), \
        Ne if isinstance(Ne, str) else float(Ne), int(l), rho, mu, int(genealogy_seed))
    if mut_seed is not None:
        file += "_ms{}".format(int(mut_seed))
    if s is not None:
        file += "_s{}".format(s)
    if h is not None:
        file += "_h{}".format(h)
    if freq is not None:
        file += "_f{}".format(freq)
        if post_gens is not None:
            file += "+{}".format(post_gens)
    if directory is None:
        return file
    else:
        return os.path.join(directory,file)

def mk_sim_name_from_row(row, directory=None, error_col=ERROR_COLNAME, subsample_col=SUBSAMPLE_COLNAME):
    """
    If error_col and subsample_col are None, this is the same as mk_sim_name()
    but filled out using data from a row. If error_col is a string which exists as
    a column name in the row then add_error_param_to_name() is also called, using
    the error rate specified in that column.
    """
    #fill out optional colnames (these might not exist)
    tool = row.get(SIMTOOL_COLNAME, 'msprime') #default to 'msprime' if tool not specified in row
    mut_seed = row.get(MUTATION_SEED_COLNAME)
    s = row.get(SELECTION_COEFF_COLNAME)
    h = row.get(DOMINANCE_COEFF_COLNAME)
    freq = row.get(SELECTED_FREQ_COLNAME)
    post_gens = row.get(SELECTED_POSTGEN_COLNAME)

    name = mk_sim_name(row.sample_size, row.Ne, row.length, row.recombination_rate,
        row.mutation_rate, row.seed, mut_seed, directory,
        tool=tool, s=s, h=h, freq=freq, post_gens = post_gens)
    #in some cases the original simulation (or results frome the simulation) have been
    # modified and we need a name that reflects that modification
    if subsample_col and subsample_col in row:
        name = add_subsample_param_to_name(name, row[subsample_col])
    if error_col and error_col in row:
        name = add_error_param_to_name(name, row[error_col])
    return(name)

def add_subsample_param_to_name(sim_name, subsample_size=None):
    """
    Mark a filename as containing only a subset of the samples of the full sim
    Can be used on msprime output files but also e.g. tsinfer output files
    """
    if subsample_size is not None and not pd.isnull(subsample_size):
        if sim_name.endswith("+") or sim_name.endswith("-"):
            #this is the first param
            return sim_name + "max{}".format(int(subsample_size))
        else:
            return sim_name + "_max{}".format(int(subsample_size))
    else:
        return sim_name

def add_error_param_to_name(sim_name, error_rate=None):
    """
    Append the error param to the msprime simulation filename.
    Only relevant for files downstream of the step where sequence error is added
    """
    if error_rate is not None and not pd.isnull(error_rate):
        if sim_name.endswith("+") or sim_name.endswith("-"):
            #this is the first param
            return sim_name + "_err{}".format(float(error_rate))
        else:
            #this is the first param
            return sim_name + "err{}".format(float(error_rate))
    else:
        return sim_name

def construct_fastarg_name(sim_name, seed, directory=None):
    """
    Returns a fastARG inference filename (without file extension),
    based on a simulation name
    """
    d,f = os.path.split(sim_name)
    return os.path.join(d,'+'.join(['fastarg', f, "fs"+str(int(seed))]))

def fastarg_name_from_row(row, sim_dir):
    """
    return the fa name based on an sim specified by row
    """
    return construct_fastarg_name(mk_sim_name_from_row(row, sim_dir),
                                  seed=row.seed)


def construct_argweaver_name(sim_name, burnin, ntimes, seed, iteration_number=None):
    """
    Returns an ARGweaver inference filename (without file extension),
    based on a simulation name. The iteration number (used in .smc and .nex output)
    is usually added by the ARGweaver `arg-sample` program,
    in the format .10, .20, etc. (we append an 'i' too, giving
    'i.10', 'i.100', etc
    """
    d,f = os.path.split(sim_name)
    suffix = "burn"+str(int(burnin)) + "nt"+str(int(ntimes)) + "ws"+str(int(seed))
    if iteration_number is not None:
        suffix += "_i."+ str(int(iteration_number))
    return os.path.join(d,'+'.join(['aweaver', f, suffix]))

def argweaver_names_from_row(row, sim_dir):
    """
    return multiple argweaver names based on an sim specified by row
    there is one name per argweaver iteration listed in row.ARGweaver_iterations
    """
    return [construct_argweaver_name(mk_sim_name_from_row(row, sim_dir),
                                     burnin=row.ARGweaver_burnin, ntimes=ARGweaver_ntimes,
                                     seed=row.seed, iteration_number=it)
                for it in nanblank(row.ARGweaver_iterations).split(",") if it]

def construct_rentplus_name(sim_name):
    """
    Returns an RentPlus inference filename (without file extension),
    based on a simulation name.
    """
    d,f = os.path.split(sim_name)
    return os.path.join(d,'+'.join(['rentpls', f, ""]))

def rentplus_name_from_msprime_row(row, sim_dir):
    """
    return the rentplus name based on an msprime sim specified by row
    """
    return construct_rentplus_name(mk_sim_name_from_row(row, sim_dir))

def construct_tsinfer_name(sim_name, subsample_size, shared_breakpoints, shared_lengths):
    """
    Returns a TSinfer filename.
    If the file is a subset of the original, this can be added to the
    basename in this function, or later using the
    add_subsample_param_to_name() routine.
    """
    d,f = os.path.split(sim_name)
    suffix = ""
    if shared_breakpoints is not None:
        suffix += "srb"+str(int(shared_breakpoints))
    if shared_lengths is not None:
        suffix += "sl"+str(int(shared_lengths))
    name = os.path.join(d,'+'.join(['tsinfer', f, suffix]))
    if subsample_size is not None and not pd.isnull(subsample_size):
        name = add_subsample_param_to_name(name, subsample_size)
    return name


def time_cmd(cmd, stdout=sys.stdout):
    """
    Runs the specified command line (a list suitable for subprocess.call)
    and writes the stdout to the specified file object.
    """
    if sys.platform == 'darwin':
        #on OS X, install gtime using `brew install gnu-time`
        time_cmd = "/usr/local/bin/gtime"
    else:
        time_cmd = "/usr/bin/time"
    full_cmd = [time_cmd, "-f%M %S %U"] + cmd
    with tempfile.TemporaryFile() as stderr:
        exit_status = subprocess.call(full_cmd, stderr=stderr, stdout=stdout)
        stderr.seek(0)
        if exit_status != 0:
            raise ValueError(
                "Error running '{}': status={}:stderr{}".format(
                    " ".join(cmd), exit_status, stderr.read()))

        split = stderr.readlines()[-1].split()
        # From the time man page:
        # M: Maximum resident set size of the process during its lifetime,
        #    in Kilobytes.
        # S: Total number of CPU-seconds used by the system on behalf of
        #    the process (in kernel mode), in seconds.
        # U: Total number of CPU-seconds that the process used directly
        #    (in user mode), in seconds.
        max_memory = int(split[0]) * 1024
        system_time = float(split[1])
        user_time = float(split[2])
    return user_time + system_time, max_memory

def ARGmetric_params_from_row(row):
    """
    Create some ARGmetric params (see ARGmetrics.py) from a row
    We hack the same polytomy seed as inference seed

    This stupidly has to be defined at the top level, since it is
    part of the function passed in to a multiprocessing Pool, and
    hence needs to be 'pickle'able :(
    """
    return {'make_bin_seed':row.seed, 'reps':row.tsinfer_biforce_reps}


class InferenceRunner(object):
    """
    Class responsible for running a single inference tool and returning results for
    the dataframe. Should create results files that are bespoke for each tool, and
    also for each tool, convert these into nexus files that can be used for comparing
    metrics.
        """
    def __init__(
            self, tool, row, simulations_dir, num_threads,
            compute_tree_metrics, polytomy_reps):
        """
        Compute_tree_metrics is a combination of bitfields as defined at the start
        or by default, 0, which means calculate all metrics over all bases without
        randomly breaking polytomies
        """
        self.tool = tool
        self.row = row
        self.num_threads = num_threads
        self.compute_tree_metrics = compute_tree_metrics
        self.polytomy_reps = polytomy_reps
        #base_fn is used for haplotype matrices etc from the simulation, so must include error,
        #but not subsample size (as subsampling happens *after* inference, when comparing trees)
        self.base_fn = mk_sim_name_from_row(
            row, simulations_dir, subsample_col = None)
        #original simulation files (e.g. the TS and nex files) must use the subsampled version, if present, but not error
        self.orig_sim_fn = mk_sim_name_from_row(
            row, simulations_dir, error_col=None)
        # This should be set by the run_inference methods. Append ".nex" to
        # get the nexus files, or ".hdf5" to get the TS files
        self.inferred_filenames = None

    def run(self, metrics_only):
        logging.debug("parameters = {}".format(self.row.to_dict()))
        if self.tool == TSINFER:
            ret = self.__run_tsinfer(skip_infer = metrics_only)
        elif self.tool == FASTARG:
            ret = self.__run_fastARG(skip_infer = metrics_only)
        elif self.tool == ARGWEAVER:
            ret = self.__run_ARGweaver(skip_infer = metrics_only)
        elif self.tool == RENTPLUS:
            ret = self.__run_RentPlus(skip_infer = metrics_only)
        else:
            raise ValueError("unknown tool {}".format(self.tool))
        if (self.compute_tree_metrics & METRICS_ON):
            #NB Jerome thinks it may be clearer to have get_metrics() return a single set of metrics
            #rather than an average over multiple inferred nexus files, and do the averaging in python
            if self.inferred_filenames is not None:
                if (self.compute_tree_metrics & METRICS_AT_VARIANT_SITES):
                    positions = np.load(self.orig_sim_fn + ".pos.npy").tolist()
                else:
                    positions = None
                source_nexus_file = self.orig_sim_fn + ".nex"
                inferred_nexus_files = [fn + ".nex" for fn in self.inferred_filenames]
                if self.compute_tree_metrics & METRICS_RANDOMLY_BREAK_POLYTOMIES:
                    metrics = []
                    for i in range(self.polytomy_reps):
                        metrics.append(ARG_metrics.get_metrics(
                            source_nexus_file, inferred_nexus_files, variant_positions = positions,
                            randomly_resolve_inferred = int(self.row.seed)+i*11))
                    metrics = pd.DataFrame(metrics).mean().to_dict()
                else:
                    metrics = ARG_metrics.get_metrics(
                        source_nexus_file, inferred_nexus_files, variant_positions = positions)
                ret.update(metrics)
            else:
                logging.info("No inferred tree files so metrics skipped for {} row {} = {}".format(
                    self.tool, int(self.row[0]), ret))
        logging.debug("returning infer results for {} row {} = {}".format(
            self.tool, int(self.row[0]), ret))
        return ret

    def __run_tsinfer(self, skip_infer=False):
        #default to using srb & but not length breaking if nothing specified in the file
        shared_recombinations = bool(getattr(self.row,'tsinfer_srb', True))
        shared_lengths = bool(getattr(self.row,'tsinfer_sl', False))
        #default to no subsampling
        subsample_size = getattr(self.row,'subsample_size', None)
        #construct filenames - these can be used even if inference does not occur
        samples_fn = self.base_fn + ".npy"
        positions_fn = self.base_fn + ".pos.npy"
        out_fn = construct_tsinfer_name(self.base_fn,
            subsample_size, shared_recombinations, shared_lengths)
        self.inferred_filenames = [out_fn]
        if skip_infer:
            return {}
        #Now perform the inference
        time = memory = fs = counts = None
        logging.debug("reading: variant matrix {} & positions {} for msprime inference".format(
            samples_fn, positions_fn))
        inferred_ts, time, memory = self.run_tsinfer(
            samples_fn, positions_fn, self.row.length, self.row.recombination_rate,
            self.row.error_rate, shared_recombinations, shared_lengths, self.num_threads,
            #inject_real_ancestors_from_ts_fn = self.orig_sim_fn + ".hdf5", #uncomment to inject real ancestors
            )
        if inferred_ts:
            if subsample_size is not None:
                inferred_ts = inferred_ts.simplify(list(range(subsample_size)))
            inferred_ts.dump(out_fn + ".inferred.hdf5")
            fs = os.path.getsize(out_fn + ".inferred.hdf5")
            if self.compute_tree_metrics:
                with open(self.inferred_filenames[0] + ".nex", "w+") as out:
                    #For subsampled trees, the locations of trees along the
                    #genome (the breakpoints) may not correspond to variant positions
                    #on the subsampled trees: indeed , there may be multiple trees
                    #between two adjacent variants, so we cannot reposition breakpoints
                    #between the nearest left and right variant positions
                    tree_labels_between_variants=(True if subsample_size is None else False)
                    inferred_ts.write_nexus_trees(
                        out, tree_labels_between_variants=tree_labels_between_variants)
            unique, counts = np.unique(np.array([e.parent for e in inferred_ts.edges()], dtype="u8"), return_counts=True)
        return  {
            save_stats['cpu']: time,
            save_stats['mem']: memory,
            save_stats['n_edges']: None if counts is None else np.sum(counts),
            save_stats['ts_filesize']: fs,
            'mean_polytomy': None if counts is None else np.mean(counts),
            'var_polytomy': None if counts is None else np.var(counts),
            'max_polytomy': None if counts is None else np.max(counts)
        }

    def __run_fastARG(self, skip_infer=False):
        inference_seed = self.row.seed  # TODO do we need to specify this separately?
        self.inferred_filenames = [construct_fastarg_name(self.base_fn, inference_seed)]
        if skip_infer:
            return {}
        infile = self.base_fn + ".hap"
        time = memory = None
        logging.debug("reading: {} for fastARG inference".format(infile))
        inferred_ts, time, memory = self.run_fastarg(infile, self.row.length, inference_seed)
        edges = inferred_ts.num_edges
        inferred_ts.dump(self.inferred_filenames[0] + ".hdf5")
        fs = os.path.getsize(self.inferred_filenames[0] + ".hdf5")
        if self.compute_tree_metrics:
            for fn in self.inferred_filenames:
                with open(fn + ".nex", "w+") as out:
                    inferred_ts.write_nexus_trees(out)
        return {
            save_stats['cpu']: time,
            save_stats['mem']: memory,
            save_stats['n_edges']: edges,
            save_stats['ts_filesize']: fs,
        }

    def __run_RentPlus(self, skip_infer=False):
        self.inferred_filenames = [construct_rentplus_name(self.base_fn)]
        if skip_infer:
            return {}
        infile = self.base_fn + ".dat"
        time = memory = None
        logging.debug("reading: {} for RentPlus inference".format(infile))
        treefile, num_tips, time, memory = self.run_rentplus(infile, self.row.length)
        if self.compute_tree_metrics:
            for fn in self.inferred_filenames:
                with open(fn + ".nex", "w+") as out:
                    msprime_RentPlus.RentPlus_trees_to_nexus(treefile, out, self.row.length, num_tips)
        return {
            save_stats['cpu']: time,
            save_stats['mem']: memory,
        }


    def __run_ARGweaver(self, skip_infer=False):
        """
        The default values are used if there are no columns which specify the
        number of burn in iterations or number of discretised timesteps
        """
        #set some AW params
        n_out_samples=10
        sample_step=20
        #these ones can be overridden
        default_ARGweaver_burnin=1000
        default_ARGweaver_ntimes=20

        #this is a hack when we specify a complex model which does not have an explicit Ne
        #just set the Ne to something likely (HACK!!)
        ARGweaver_Ne = 10000 if isinstance(self.row.Ne, str) else str(self.row.Ne)
        
        inference_seed = self.row.seed  # TODO do we need to specify this separately?
        burnin = getattr(self.row,'ARGweaver_burnin', default_ARGweaver_burnin)
        n_timesteps = getattr(self.row,'ARGweaver_ntimes', default_ARGweaver_ntimes)
        self.inferred_filenames = []
        iteration_ids = []
        out_fn = construct_argweaver_name(self.base_fn, burnin, n_timesteps, inference_seed)
        if skip_infer:
            #must get the iteration IDs off the row
            if self.row.ARGweaver_iterations:
                iteration_ids = self.row.ARGweaver_iterations.split(",")
        else:
            infile = self.base_fn + ".sites"
            time = memory = None
            filesizes = []
            edges = []
            stats_file = None
            logging.debug("reading: {} for ARGweaver inference".format(infile))
            iteration_ids, stats_file, time, memory = self.run_argweaver(
                infile, ARGweaver_Ne, self.row.recombination_rate, self.row.mutation_rate,
                out_fn, inference_seed, n_out_samples, sample_step, burnin, n_timesteps,
                verbose = logging.getLogger().isEnabledFor(logging.DEBUG))
        for it in iteration_ids:
            base = construct_argweaver_name(self.base_fn, burnin, n_timesteps, inference_seed, it)
            self.inferred_filenames.append(base)
            if skip_infer==False:
                if self.compute_tree_metrics:
                    with open(base + ".nex", "w+") as out:
                        msprime_ARGweaver.ARGweaver_smc_to_nexus(base+".smc.gz", out)
                try:
                    with open(base+".TSnodes", "w+") as msprime_nodes, \
                            open(base+".TSedges", "w+") as msprime_edges:
                        msprime_ARGweaver.ARGweaver_smc_to_msprime_txts(
                            smc2arg_executable, base, msprime_nodes, msprime_edges)
                        inferred_ts = msprime.load_text(
                            nodes=msprime_nodes, edges=msprime_edges).simplify()
                        inferred_ts.dump(base + ".hdf5")
                        filesizes.append(os.path.getsize(base + ".hdf5"))
                        edges.append(inferred_ts.num_edges)
                except msprime_ARGweaver.CyclicalARGError as e:
                    logging.warning("Cyclical ARG Exception when converting {}: {}".format(
                        base + ".msp", e))
        if skip_infer:
            return {}
        else:
            return {
                save_stats['cpu']: time,
                save_stats['mem']: memory,
                save_stats['n_edges']: statistics.mean(edges) if len(edges) else None,
                save_stats['ts_filesize']: statistics.mean(filesizes) if len(filesizes) else None,
                "iterations": ",".join(iteration_ids),
            }

    @staticmethod
    def run_tsinfer(sample_fn, positions_fn, length, rho, error_probability,
        shared_recombinations, shared_lengths, num_threads=1, inject_real_ancestors_from_ts_fn=None):
        try:
            with tempfile.NamedTemporaryFile("w+") as ts_out:
                cmd = [
                    sys.executable, tsinfer_executable, sample_fn, positions_fn,
                    "--length", str(int(length)), "--recombination-rate", str(rho),
                    "--error-probability", str(error_probability),
                    "--threads", str(num_threads), ts_out.name]
                if inject_real_ancestors_from_ts_fn:
                    logging.debug("Injecting real ancestors constructed from {}".format(
                        inject_real_ancestors_from_ts_fn))
                    cmd.extend(["--inject-real-ancestors-from-ts", inject_real_ancestors_from_ts_fn])
                if shared_recombinations:
                    cmd.append("--shared-recombinations")
                if shared_lengths:
                    cmd.append("--shared-lengths")
                cpu_time, memory_use = time_cmd(cmd)
                ts_simplified = msprime.load(ts_out.name)
            return ts_simplified, cpu_time, memory_use
        except ValueError as e:
            # temporary hack around tsinfer bug
            if "time[parent] must be greater than time[child]" in str(e):
                logging.warning("Hit tsinfer bug for {}. Skipping".format(sample_fn))
                return None, None, None
            else:
                raise

    @staticmethod
    def run_fastarg(file_name, seq_length, seed):
        with tempfile.NamedTemporaryFile("w+") as fa_out, \
                tempfile.NamedTemporaryFile("w+") as tree, \
                tempfile.NamedTemporaryFile("w+") as muts:
            cmd = msprime_fastARG.get_cmd(fastARG_executable, file_name, seed)
            cpu_time, memory_use = time_cmd(cmd, fa_out)
            logging.debug("ran fastarg for seq length {} [{} s]: '{}'".format(seq_length, cpu_time, cmd))
            var_pos = msprime_fastARG.variant_positions_from_fastARGin_name(file_name)
            inferred_ts = msprime_fastARG.fastARG_out_to_msprime(fa_out, var_pos, seq_len=seq_length)
            return inferred_ts, cpu_time, memory_use

    @staticmethod
    def run_rentplus(file_name, seq_length):
        """
        runs RentPlus, returning the output filename, the total CPU, & max mem
        must check here if we are using 0..1 positions (infinite sites) or integers
        """
        haplotype_lines = 0
        integer_positions = True
        with open(file_name, "r+") as infile:
            for pos in next(infile).split():
                try:
                    dummy = int(pos)
                except ValueError:
                    integer_positions = False
            for line in infile:
                if line.rstrip():
                    haplotype_lines += 1
        cmd = ["java", "-jar", RentPlus_executable]
        cmd += [file_name] if integer_positions else ['-l', seq_length, file_name]
        with tempfile.NamedTemporaryFile("w+") as script_output:
            cpu_time, memory_use = time_cmd(cmd, script_output)
        logging.debug("ran RentPlus for {} haplotypes with seq length {} [{} s]: '{}'".format(
            haplotype_lines, seq_length, cpu_time, cmd))
        #we cannot back-convert RentPlus output to treeseq form - just return the trees file
        assert os.path.isfile(file_name + ".trees"), 'No trees file created when running Rent+'
        #we might also want to look at TMRCAs (file_name + '.Tmrcas')
        return file_name + ".trees", haplotype_lines, cpu_time, memory_use

    @staticmethod
    def run_argweaver(
            sites_file, Ne, recombination_rate, mutation_rate, path_prefix, seed,
            MSMC_samples, sample_step, burnin_iterations, ntimes, verbose=False):
        """
        this produces a whole load of .smc files labelled <path_prefix>i.0.smc,
        <path_prefix>i.10.smc, etc, which we then convert into sts format

        Returns the iteration numbers ('0', '10', '20' etc), the name of the
        statistics file, the total CPU time, and the max memory usage.
        """
        cpu_time = []
        memory_use = []
        burn_prefix = None
        try:
            exe = [ARGweaver_executable, '--sites', sites_file.name if hasattr(sites_file, "name") else sites_file,
                   '--popsize', str(Ne),
                   '--recombrate', str(recombination_rate),
                   '--mutrate', str(mutation_rate),
                   '--ntimes', str(ntimes),
                   '--overwrite']
            if not verbose:
                exe += ['--quiet']
            if seed is not None:
                exe += ['--randseed', str(int(seed))]
            if burnin_iterations > 0:
                burn_in = str(int(burnin_iterations))
                burn_prefix = path_prefix+"_burn"
                logging.info("== Burning in ARGweaver MCMC using {} steps ==".format(burn_in))
                logging.debug("== ARGweaver burnin command is {} ==".format(" ".join(exe)))
                c, m = time_cmd(exe + ['--iters', burn_in,
                                       '--sample-step', burn_in,
                                       '--output', burn_prefix])
                cpu_time.append(c)
                memory_use.append(m)
                #if burn_in, read from the burn in arg file, rather than the original .sites
                exe += ['--arg', burn_prefix+"."+ burn_in +".smc.gz"]
            else:
                exe += ['--sites', sites_file]

            new_prefix = path_prefix + "_i" #we append a '_i' to mark iteration number
            iterations = int(sample_step * (MSMC_samples-1))
            exe += ['--output', new_prefix]
            exe += ['--iters', str(iterations)]
            exe += ['--sample-step', str(int(sample_step))]
            logging.info("== Running ARGweaver for {} steps to collect {} samples ==".format( \
                int(iterations), MSMC_samples))
            logging.debug("== ARGweaver command is {} ==".format(" ".join(exe)))
            c, m = time_cmd(exe)
            cpu_time.append(c)
            memory_use.append(m)

            smc_prefix = new_prefix + "." #the arg-sample program adds .iteration_num
            saved_iterations = [f[len(smc_prefix):-7] for f in glob.glob(smc_prefix + "*" + ".smc.gz")]
            new_stats_file_name = path_prefix+".stats"

            #concatenate all the stats together
            with open(new_stats_file_name, "w+") as stats:
                if burn_prefix:
                    shutil.copyfileobj(open(burn_prefix + ".stats"), stats)
                    print("\n", file=stats)
                shutil.copyfileobj(open(new_prefix + ".stats"), stats)
            #cannot translate these to msprime ts objects, as smc2arg does not work
            #see https://github.com/mdrasmus/argweaver/issues/20
            return saved_iterations, new_stats_file_name, sum(cpu_time), max(memory_use)
        except ValueError as e:
            if 'src/argweaver/sample_thread.cpp:517:' in str(e):
                logging.warning("Hit argweaver bug " \
                "https://github.com/mcveanlab/treeseq-inference/issues/25" \
                " for {}. Skipping".format(path_prefix))
                return [], "NA", None, None
            elif "Assertion `trans[path[i]] != 0.0' failed" in str(e):
                logging.warning("Hit argweaver bug " \
                "https://github.com/mcveanlab/treeseq-inference/issues/42" \
                " for {}. Skipping".format(path_prefix))
                return [], "NA", None, None
            else:
                raise


def infer_worker(work):
    """
    Entry point for running a single inference task in a worker process.
    """
    tool, row, sims_dir, n_threads, metric_flags, metrics_only, polytomy_reps = work
    runner = InferenceRunner(tool, row, sims_dir, n_threads, metric_flags, polytomy_reps)
    result = runner.run(metrics_only)
    result['completed'] = True
    return int(row[0]), tool, result


class Dataset(object):
    """
    A dataset is some collection of simulations and associated data.
    """
    name = None
    """
    Each dataset has a unique name. This is used as the prefix for the data
    file and raw_data_dir directory. Within this, replicate instances of datasets
    (each with a different RNG seed) are saved under the seed number
    """
    compute_tree_metrics = METRICS_OFF
    """
    Set to METRICS_ON (which can be combined with other flags) if you wish to compute
    tree metric distances from the source tree sequence to the inferred tree sequence(s).
    """
    random_resolve_polytomy_replicates = 10
    """
    If metrics are calculated by randomly resolving polytomies (by setting
    compute_tree_metrics to |= METRICS_RANDOMLY_BREAK_POLYTOMIES, this parameter gives
    the number of times the same tree will replicate the polytomy breaking process
    (the final metric will be a simple mean of these replicates)
    """
    data_dir = "data"

    tools = [
        ARGWEAVER,
        FASTARG,
        RENTPLUS,
        TSINFER,
    ]

    """
    These are the basic columns that record the simulation used (can be overridden)
    """
    sim_cols = [
        "sample_size", "Ne", "length", "recombination_rate", "mutation_rate",
        ERROR_COLNAME, "edges", "n_trees", "seed"]

    #for a tidier csv file, we can exclude any of the save_stats values or ARGmetrics columns
    exclude_colnames = []

    def __init__(self):
        self.data_path = os.path.abspath(
            os.path.join(self.data_dir, "{}".format(self.name)))
        self.data_file = self.data_path + ".csv"
        self.param_file = self.data_path + ".json"
        self.raw_data_dir = os.path.join(self.data_dir, "raw__NOBACKUP__", self.name)
        self.simulations_dir = os.path.join(self.raw_data_dir, "simulations")
        self.last_data_write_time = time.time()

    def load_data(self):
        self.data = pd.read_csv(self.data_file)

    def dump_data(self, write_index=False, force_flush=True):
        """
        Dumps data if it hasn't been written in the last 30 seconds. If force is true,
        write it out anyway.
        """
        now = time.time()
        if force_flush or (now - self.last_data_write_time) > 30:
            logging.info("Flushing data file")
            self.data.to_csv(self.data_file, index=write_index)
            self.last_data_write_time = time.time()

    #
    # Main entry points.
    #
    def setup(self, args):
        """
        Creates the dataframe and storage directories and then runs the initial
        simulations.
        """
        if os.path.exists(self.simulations_dir):
            shutil.rmtree(self.simulations_dir)
            logging.info("Deleting dir {}".format(self.simulations_dir))
        os.makedirs(self.simulations_dir)
        self.verbosity = args.verbosity
        logging.info("Creating dir {}".format(self.simulations_dir))
        self.data = self.run_simulations(args.replicates, args.seed, args.progress, args.processes)
        for t in self.tools:
            col = t + "_completed"
            if col not in self.data:
                self.data[col] = False
        # Other result columns are added later during the infer step.
        self.dump_data(write_index=True)

    def infer(
            self, num_processes, num_threads, force=False, metrics_only=False,
            specific_tool=None, specific_row=None, flush_all=False, show_progress=False):
        """
        Runs the main inference processes and stores results in the dataframe.
        can 'force' all rows to be (re)run, or specify a specific row to run.
        """
        self.load_data()
        tools = self.tools
        if specific_tool is not None:
            if specific_tool not in self.tools:
                raise ValueError("Tool '{}' not recognised: options = {}".format(
                    specific_tool, list(self.tools)))
            tools = [specific_tool]
        row_ids = self.data.index
        if specific_row is not None:
            if specific_row < 0 or specific_row > len(self.data.index):
                raise ValueError("Row {} out of bounds".format(specific_row))
            row_ids = [specific_row]
        work = []
        tool_work_total = {tool: 0 for tool in tools}
        for row_id in row_ids:
            row = self.data.iloc[row_id]
            for tool in tools:
                #special case for ARGweaver, to allow multiple runs for the same sim
                if getattr(row,"only_AW",False) and tool != ARGWEAVER:
                    logging.info("Data row {} is set to skip {} inference".format(
                        row_id,tool) + " (probably to avoid duplicate effort)")
                    continue
                # Only run for a particular tool if it has not already completed
                # of if --force is specified.
                if metrics_only and not row[tool + "_completed"]:
                    logging.info(
                        "Data row {} has not completed {} inference: skipping metric calculations".format(
                            row_id, tool))
                elif not metrics_only and not force and row[tool + "_completed"]:
                    logging.info(
                        "Data row {} is filled out for {} inference: skipping".format(
                            row_id, tool))
                else:
                    work.append((
                        tool, row, self.simulations_dir, num_threads,
                        self.compute_tree_metrics, metrics_only,
                        self.random_resolve_polytomy_replicates))
                    tool_work_total[tool] += 1
        logging.info(
            "running {} {} (max {} tools over {} of {} rows) with {} "
            "processes and {} threads".format(
                len(work), "metric calculations" if metrics_only else "inference trials",
                len(tools), int(np.ceil(len(work)/len(self.tools))),
                len(self.data.index), num_processes, num_threads))

        # Randomise the order that work is done in so that we get results for all parts
        # of the plots through rather than get complete results for the initial data
        # points.
        random.shuffle(work)
        tool_work_completed = {tool: 0 for tool in tools}
        if show_progress:
            width = max(len(tool) for tool in tools)
            progress = {
                tool:tqdm.tqdm(
                    desc="{:>{}}".format(tool, width),
                    total=tool_work_total[tool]) for tool in tools}

        def store_result(row_id, tool, results):
            tool_work_completed[tool] += 1
            logging.info("{} {}/{} completed for {}".format(
                "Metric calculation" if metrics_only else "Inference",
                tool_work_completed[tool], tool_work_total[tool], tool))
            for k, v in results.items():
                if k not in self.exclude_colnames:
                    self.data.ix[row_id, tool + "_" + k] = v
            self.dump_data(force_flush=flush_all)
            # Update the progress meters
            if show_progress:
                progress[tool].update()

        if num_processes > 1:
            with multiprocessing.Pool(processes=num_processes) as pool:
                for result in pool.imap_unordered(infer_worker, work):
                    store_result(*result)
        else:
            # When we have only one process it's easier to keep everything in the same
            # process for debugging.
            for result in map(infer_worker, work):
                store_result(*result)
        self.dump_data(force_flush=True)

    #
    # Utilities for running simulations and saving files.
    #
    def single_simulation(self, n, Ne, l, rho, mu, seed, mut_seed=None, **kwargs):
        """
        The standard way to run one msprime simulation for a set of parameter
        values. Saves the output to an .hdf5 file, and also saves variant files
        for use in fastARG (a .hap file, in the format specified by
        https://github.com/lh3/fastARG#input-format) ARGweaver (a .sites file:
        http://mdrasmus.github.io/argweaver/doc/#sec-file-sites) tsinfer
        (currently a numpy array containing the variant matrix)

        mutation_seed allows the same
        ancestry to be simulated (if the same genealogy_seed is given) but have
        different mutations thrown onto the trees (even with different
        mutation_rates). If None, then different vaues of mu will create different
        simulations.

        If Ne is a string, it is an identified used for the population model
        which will be saved into the filename & results file, while the simulation
        will be called with Ne=1, and the 

        Returns a tuple of treesequence, filename (without file type extension)
        """
        logging.info(
            "Running neutral simulation for "
            "n = {}, l = {:.2g}, Ne = {}, rho = {}, mu = {}".format(
                n, l, Ne, rho, mu))
        # Since we want to have a finite site model, we force the recombination map
        # to have exactly l loci with a recombination rate of rho between them.
        recombination_map = msprime.RecombinationMap.uniform_map(l, rho, l)
        rng1 = random.Random(seed)
        sim_seed = rng1.randint(1, 2**31)
        if "population_configurations" in kwargs:
            Ne_used = 1
            n_used = None
        else:
            Ne_used = Ne
            n_used = n
        if mut_seed is None:
            ts = msprime.simulate(
                n_used, Ne_used, recombination_map=recombination_map, mutation_rate=mu,
                random_seed=sim_seed, **kwargs)
        else:
            #run with no mutations (should give same result regardless of mutation rate)
            ts = msprime.simulate(
                n_used, Ne_used, recombination_map=recombination_map, mutation_rate=0,
                random_seed=sim_seed, **kwargs)
            #now add the mutations
            rng2 = msprime.RandomGenerator(mut_seed)
            nodes = msprime.NodeTable()
            edges = msprime.EdgeTable()
            sites = msprime.SiteTable()
            muts = msprime.MutationTable()
            ts.dump_tables(nodes=nodes, edges=edges)
            mutgen = msprime.MutationGenerator(rng2, mu)
            mutgen.generate(nodes, edges, sites, muts)
            msprime.sort_tables(nodes=nodes, edges=edges, sites=sites, mutations=muts)
            ts = msprime.load_tables(nodes=nodes, edges=edges, sites=sites, mutations=muts)

        logging.info(
            "Neutral simulation done; {} sites, {} trees".format(ts.num_sites, ts.num_trees))
        sim_fn = mk_sim_name(n, Ne, l, rho, mu, seed, mut_seed, self.simulations_dir)
        logging.debug("writing {}.hdf5".format(sim_fn))
        ts.dump(sim_fn+".hdf5")
        
        # Make sure that there is *some* information in this simulation that can be used
        # to infer a ts, otherwise it's pointless
        if ts.get_num_mutations() == 0:
            raise ValueError("No mutations present")
        if ts_has_non_singleton_variants(ts) == False:
            raise ValueError("No non-singleton variants present ({} singletons)".format(
                sum([np.sum(v)==1 for v in ts.variants()])))
        
        return ts, sim_fn

    def single_simulation_with_human_demography(self, n, sim_name, l, rho, mu, seed, mut_seed=None, **kwargs):
        """
        Run an msprime simulation with a rough approximation of recent human demography
        using the  Gutenkunst et al., (2009) model used by a number of other simulators 
        (e.g. msms), which is an elaboration of https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1310645/
        
        (see http://msprime.readthedocs.io/en/stable/tutorial.html#demography)
        
        the sample_size, n, is divided into 3 roughly equal-sized groups from africa, europe, & china
        (YRI, CEU, and CHB)
        """
        def out_of_africa(nYRI, nCEU, nCHB):
            """
            Straight from the msprime docs, but return the setup params for passing to the
            simulate() function
            """
            # First we set out the maximum likelihood values of the various parameters
            # given in Table 1.
            N_A = 7300
            N_B = 2100
            N_AF = 12300
            N_EU0 = 1000
            N_AS0 = 510
            # Times are provided in years, so we convert into generations.
            generation_time = 25
            T_AF = 220e3 / generation_time
            T_B = 140e3 / generation_time
            T_EU_AS = 21.2e3 / generation_time
            # We need to work out the starting (diploid) population sizes based on
            # the growth rates provided for these two populations
            r_EU = 0.004
            r_AS = 0.0055
            N_EU = N_EU0 / math.exp(-r_EU * T_EU_AS)
            N_AS = N_AS0 / math.exp(-r_AS * T_EU_AS)
            # Migration rates during the various epochs.
            m_AF_B = 25e-5
            m_AF_EU = 3e-5
            m_AF_AS = 1.9e-5
            m_EU_AS = 9.6e-5
            # Population IDs correspond to their indexes in the population
            # configuration array. Therefore, we have 0=YRI, 1=CEU and 2=CHB
            # initially.
            population_configurations = [
                msprime.PopulationConfiguration(
                    sample_size= nYRI, initial_size=N_AF),
                msprime.PopulationConfiguration(
                    sample_size= nCEU, initial_size=N_EU, growth_rate=r_EU),
                msprime.PopulationConfiguration(
                    sample_size= nCHB, initial_size=N_AS, growth_rate=r_AS)
            ]
            migration_matrix = [
                [      0, m_AF_EU, m_AF_AS],
                [m_AF_EU,       0, m_EU_AS],
                [m_AF_AS, m_EU_AS,       0],
            ]
            demographic_events = [
                # CEU and CHB merge into B with rate changes at T_EU_AS
                msprime.MassMigration(
                    time=T_EU_AS, source=2, destination=1, proportion=1.0),
                msprime.MigrationRateChange(time=T_EU_AS, rate=0),
                msprime.MigrationRateChange(
                    time=T_EU_AS, rate=m_AF_B, matrix_index=(0, 1)),
                msprime.MigrationRateChange(
                    time=T_EU_AS, rate=m_AF_B, matrix_index=(1, 0)),
                msprime.PopulationParametersChange(
                    time=T_EU_AS, initial_size=N_B, growth_rate=0, population_id=1),
                # Population B merges into YRI at T_B
                msprime.MassMigration(
                    time=T_B, source=1, destination=0, proportion=1.0),
                # Size changes to N_A at T_AF
                msprime.PopulationParametersChange(
                    time=T_AF, initial_size=N_A, population_id=0)
            ]        
        
            return dict(
                population_configurations=population_configurations,
                migration_matrix=migration_matrix,
                demographic_events=demographic_events
                )
        
        asian_samples = n//3
        afro_european_samples = n - asian_samples
        european_samples = afro_european_samples//2
        african_samples = afro_european_samples - european_samples
        assert african_samples + european_samples + asian_samples
        
        kwargs.update(out_of_africa(african_samples, european_samples, asian_samples))
        return self.single_simulation(n, sim_name, l, rho, mu, seed, mut_seed, **kwargs)        

    def single_simulation_with_selective_sweep(self, n, Ne, l, rho, mu, s, h, stop_freqs,
        seed, mut_seed=None):
        """
        Run a forward simulation with a selective sweep for a set of parameter values.
        using simuPOP.

        Forward simulations are slow, especially for large chromosomes & population sizes.
        So to save time, we can get multiple results from the same simulation, by saving
        populations at different times


        if stop is a single number it is taken as a stop frequency, and
        the simulation is stopped when the selected variant reaches that frequency. If it is a
        tuple, it is taken as (freq, generations), and the simulation is stopped at the
        specified number of generations after that frequency has been reached (e.g. if
        stop = (1.0, 200), the simulation is stopped 200 generations after fixation.

        Convert the output to multiple .hdf5 files using ftprime. Other
        details as for single_simulation()
        Returns an iterator over (treesequence, filename, output_freq) tuples
        (without file type extension)

        """
        from selective_sweep import simulate_sweep #not at top as this fires up a simupop instance
        logging.info(
            "Running forward simulation with selection for "
            "n = {}, l = {:.2g}, Ne = {}, rho = {}, mu = {}, s = {}".format(
                n, l, Ne, rho, mu, s))
        sim_fn = mk_sim_name(n, Ne, l, rho, mu, seed, mut_seed, self.simulations_dir,
            tool="ftprime", s=s, h=h) + "_f" #freq + post_gens added by simulate_sweep()


        saved_files = simulate_sweep(
            popsize=Ne,
            chrom_length=l,
            recomb_rate=rho,
            mut_rate=mu,
            selection_coef=s,
            dominance_coef=h,
            output_at_freqs=[(s,0) if isinstance(s, (str, float, int)) else (s[0],s[1]) for s in stop_freqs],
            nsamples = int(n/2), #sample n/2 diploid individuals from the population
            max_generations=int(1e8), #bail after ridiculous numbers of generations
            mutations_after_simulation=True,
            treefile_prefix=sim_fn,
            seed=seed)

        expected_suffix = ".hdf5"
        for outfreq, fn in saved_files.items():
            assert fn.endswith(expected_suffix)
            ts = msprime.load(fn)
            logging.info(
                "Selective simulation from '{}'; {} sites ({} mutations), {} trees".format(
                    fn, ts.num_sites,ts.get_num_mutations(), ts.num_trees))
            # Make sure that there is *some* information in this simulation that can be used
            # to infer a ts, otherwise it's pointless
            
            if ts.get_num_mutations() == 0:
                raise ValueError("No mutations present")
            if ts_has_non_singleton_variants(ts) == False:
                raise ValueError("No non-singleton variants present ({} singletons) for output at {}".format(
                    sum([np.sum(v.genotypes)==1 for v in ts.variants()]), outfreq))
            yield ts, fn[:-len(expected_suffix)], outfreq


    def save_positions(self, ts, fn):
        outfile = fn + ".pos.npy"
        pos = np.array([v.position for v in ts.variants()])
        logging.debug("writing variant positions to {}".format(outfile))
        np.save(outfile, pos)


    def save_variant_matrices(self, ts, fname, error_rate=0, infinite_sites=True):
        if infinite_sites:
            #for infinite sites, assume we have discretised mutations to ints
            if not all(p.is_integer() for p in pos):
                raise ValueError("Variant positions are not all integers")
        S = generate_samples(ts, error_rate)
        pos = np.array([v.position for v in ts.variants()])
        filename = add_error_param_to_name(fname, error_rate)
        if TSINFER in self.tools:
            outfile = filename + ".npy"
            logging.debug("writing variant matrix to {} for tsinfer".format(outfile))
            np.save(outfile, S)
            self.save_positions(ts,filename)
        if FASTARG in self.tools:
            logging.debug("writing variant matrix to {}.hap for fastARG".format(filename))
            with open(filename+".hap", "w+") as fastarg_in:
                msprime_fastARG.variant_matrix_to_fastARG_in(S.T, pos, fastarg_in)
        if ARGWEAVER in self.tools:
            logging.debug("writing variant matrix to {}.sites for ARGweaver".format(filename))
            with open(filename+".sites", "w+") as argweaver_in:
                msprime_ARGweaver.variant_matrix_to_ARGweaver_in(
                    S.T, pos, ts.get_sequence_length(), argweaver_in,
                    infinite_sites=infinite_sites)
        if RENTPLUS in self.tools:
            logging.debug("writing variant matrix to {}.dat for RentPlus".format(filename))
            with open(filename+".dat", "wb+") as rentplus_in:
                msprime_RentPlus.variant_matrix_to_RentPlus_in(S.T, pos,
                        ts.get_sequence_length(), rentplus_in, infinite_sites=infinite_sites)


class MetricsByMutationRateDataset(Dataset):
    """
    Accuracy of ARG inference (measured by various statistics)
    tending to fully accurate as mutation rate increases
    """
    name = "metrics_by_mutation_rate"

    default_replicates = 100
    default_seed = 123
    compute_tree_metrics = METRICS_ON #| METRICS_RANDOMLY_BREAK_POLYTOMIES

    #for a tidier csv file, we can exclude any of the save_stats values or ARGmetrics columns
    exclude_colnames =[]


    def run_simulations(self, replicates, seed, show_progress, num_processes=1):
        if replicates is None:
            replicates = self.default_replicates
        if seed is None:
            seed = self.default_seed
        rng = random.Random(seed)
        # Variable parameters
        mutation_rates = np.logspace(-8.5, -5, num=8)[:-1] * 1.5
        error_rates = [0, 0.001, 0.01]
        sample_sizes = [15]

        # Fixed parameters
        Ne = 5000
        length = 100000 #should be enough for ~ 50 trees
        recombination_rate = 1e-8
        num_rows = replicates * len(mutation_rates) * len(error_rates) * len(sample_sizes)
        data = pd.DataFrame(index=np.arange(0, num_rows), columns=self.sim_cols)
        row_id = 0
        if show_progress:
            progress = tqdm.tqdm(total=num_rows)
        for replicate in range(replicates):
            for mutation_rate in mutation_rates:
                for sample_size in sample_sizes:
                    done = False
                    while True:
                        replicate_seed = rng.randint(1, 2**31)
                        try:
                            # Run the simulation until we get an acceptable one
                            ts, fn = self.single_simulation(sample_size, Ne, length,
                                recombination_rate, mutation_rate, replicate_seed)
                            break
                        except ValueError as e: #No non-singleton variants
                            logging.warning(e)
                        
                    with open(fn +".nex", "w+") as out:
                        ts.write_nexus_trees(out)
                    self.save_positions(ts, fn)

                    # Add the rows for each of the error rates in this replicate
                    for error_rate in error_rates:
                        row = data.iloc[row_id]
                        row_id += 1
                        row.sample_size = sample_size
                        row.recombination_rate = recombination_rate
                        row.mutation_rate = mutation_rate
                        row.length = length
                        row.Ne = Ne
                        row.seed = replicate_seed
                        row[ERROR_COLNAME] = error_rate
                        row.edges = ts.num_edges
                        row.n_trees = ts.num_trees
                        self.save_variant_matrices(ts, fn, error_rate,
                            #infinite_sites=True)
                            infinite_sites=False)
                        if show_progress:
                            progress.update()
        return data


class TsinferPerformance(Dataset):
    """
    The performance of tsinfer in terms of CPU time, memory usage and
    compression rates for large scale datasets. Contains data for
    the two main dimensions of sample size and sequence length.
    """
    name = "tsinfer_performance"
    compute_tree_metrics = METRICS_OFF
    default_replicates = 20
    default_seed = 123
    tools = [TSINFER]
    fixed_length = 20 * 10**6
    fixed_sample_size = 5000
    mutation_rate = 5e-9

    def run_simulations(self, user_specified_replicates, seed, show_progress, num_processes=1):
        # TODO abstract some of this functionality up into the superclass.
        # There is quite a lot shared with the other dataset.
        replicates = user_specified_replicates or self.default_replicates
        rng = random.Random(seed if seed else self.default_seed)
        # Fixed parameters
        self.Ne = 5000
        # TODO we'll want to do this for multiple error rates eventually. For now
        # just look at perfect data.
        # Variable parameters
        num_points = 20
        sample_sizes = np.linspace(10, 2 * self.fixed_sample_size, num_points).astype(int)
        # Ensure sample sizes are even so we can output diploid VCF.
        sample_sizes[sample_sizes % 2 != 0] += 1
        lengths = np.linspace(self.fixed_length / 10, 2 * self.fixed_length, num_points).astype(int)
        recombination_rates = np.array([1]) * self.mutation_rate
        #parameters that are iterated over within a single simulation
        self.error_rates = [0]

        self.num_sims = (len(sample_sizes) + len(lengths)) * len(recombination_rates) * replicates
        self.num_rows = self.num_sims * len(self.error_rates)
        cols = self.sim_cols + ["sites", "ts_filesize", "vcf_filesize", "vcfgz_filesize"]
        data = pd.DataFrame(index=np.arange(0, self.num_rows), columns=cols)
        progress = tqdm.tqdm(total=self.num_rows) if show_progress else None

        def save_result(data, values_by_row, progress):
            for i,d in values_by_row.items():
                for colname, val in d.items():
                    data.iloc[i][colname]=val
                if progress is not None:
                    progress.update()

        logging.info("Setting up using {} processes".format(num_processes))
        nl = [(self.fixed_sample_size, l) for l in lengths] + [
            (n, self.fixed_length) for n in sample_sizes]
        variable_iterator = itertools.product(nl, recombination_rates, range(replicates))
        seeds = [rng.randint(1, 2**31) for i in range(self.num_sims)]
        combined_iterator = enumerate(itertools.zip_longest(seeds, variable_iterator))

        if num_processes > 1:
            with multiprocessing.Pool(processes=num_processes, maxtasksperchild=2) as pool:
                for result in pool.imap_unordered(self.single_sim, combined_iterator):
                    save_result(data, result, progress)
        else:
            # When we have only one process it's easier to keep everything in the same
            # process for debugging.
            for result in map(self.single_sim, combined_iterator):
                save_result(data, result, progress)
        return data


    def single_sim(self, runtime_information):
        i, (params) = runtime_information
        assert None not in params #one will be none if the lengths of the iterators are different
        rng_seed, ((sample_size, length), recombination_rate, _) = params
        base_row_id = i * self.num_rows//self.num_sims
        return_value = {}
        rng = random.Random(rng_seed)
        while True:
            replicate_seed = rng.randint(1, 2**31)
            try:
                # Run the simulation until we get an acceptable one
                ts, fn = self.single_simulation(
                    sample_size, self.Ne, length, recombination_rate, self.mutation_rate,
                    replicate_seed)
                break
            except ValueError as e: #No non-singleton variants
                logging.warning(e)
                
        vcf_filename = fn + ".vcf"
        with open(vcf_filename, "w") as vcf_file:
            ts.write_vcf(vcf_file, 2)
        vcfgz_filename = vcf_filename + ".gz"
        vcf_filesize = os.path.getsize(vcf_filename)
        # gzip removes the original by default, so might as well save some space.
        subprocess.check_call(["gzip", vcf_filename])

        assert ts.num_sites > 0
        row_id = base_row_id
        for error_rate in self.error_rates:
            row = return_value[row_id] = {}
            row_id += 1
            row['sample_size'] = sample_size
            row['recombination_rate'] = recombination_rate
            row['mutation_rate'] = self.mutation_rate
            row['length'] = length
            row['Ne'] = self.Ne
            row['seed'] = replicate_seed
            row[ERROR_COLNAME] = error_rate
            row['edges'] = ts.num_edges
            row['n_trees'] = ts.num_edges
            row['sites'] = ts.num_sites
            row['ts_filesize'] = os.path.getsize(fn + ".hdf5")
            row['vcf_filesize'] = vcf_filesize
            row['vcfgz_filesize'] = os.path.getsize(vcfgz_filename)
            self.save_variant_matrices(ts, fn, error_rate, infinite_sites=False)
        return return_value

class ProgramComparison(Dataset):
    """
    The performance of the various programs in terms of running time and memory usage
    """
    name = "program_comparison"
    compute_tree_metrics = METRICS_OFF
    default_replicates = 2
    default_seed = 1000
    tools = [FASTARG, TSINFER]
    fixed_length = 5 * 10**6
    fixed_sample_size = 10000

    def run_simulations(self, replicates, seed, show_progress, num_processes=1):
        # TODO abstract some of this functionality up into the superclass.
        # There is quite a lot shared with the other dataset.
        if replicates is None:
            replicates = self.default_replicates
        if seed is None:
            seed = self.default_seed
        rng = random.Random(seed)

        # Variable parameters
        num_points = 20
        sample_sizes = np.linspace(10, 2 * self.fixed_sample_size, num_points).astype(int)
        lengths = np.linspace(self.fixed_length / 10, 2 * self.fixed_length, num_points).astype(int)

        # Fixed parameters
        Ne = 5000
        error_rate = 0
        recombination_rate = 2.5e-8
        mutation_rate = recombination_rate
        num_rows = 2 * num_points * replicates
        cols = self.sim_cols + [tool + pf for tool in self.tools for pf in ("_cputime", "_memory")]
        data = pd.DataFrame(index=np.arange(0, num_rows), columns=cols)
        work = [
            (self.fixed_sample_size, l) for l in lengths] + [
            (n, self.fixed_length) for n in sample_sizes]
        row_id = 0
        if show_progress:
            progress = tqdm.tqdm(total=num_rows)
        for sample_size, length in work:
            for _ in range(replicates):
                while True:
                    replicate_seed = rng.randint(1, 2**31)
                    try:
                        # Run the simulation until we get an acceptable one
                        ts, fn = self.single_simulation(sample_size, Ne, length,
                            recombination_rate, mutation_rate, replicate_seed)
                        break
                    except ValueError as e: #No non-singleton variants
                        logging.warning(e)
                
                row = data.iloc[row_id]
                row_id += 1
                row.sample_size = sample_size
                row.recombination_rate = recombination_rate
                row.mutation_rate = mutation_rate
                row.length = length
                row.Ne = Ne
                row.seed = replicate_seed
                row[ERROR_COLNAME] = 0.0
                row.edges = ts.num_edges
                row.n_trees = ts.num_edges
                # for tool in self.tools:
                #     row[tool + "_completed"] = False
                # # Hack to prevent RentPlus from running when the sizes are too big.
                # if sample_size == self.fixed_sample_size:
                #     if length > lengths[0]:
                #         row.RentPlus_completed = True
                # else:
                #     if sample_size > sample_sizes[0]:
                #         row.RentPlus_completed = True

                self.save_variant_matrices(ts, fn, error_rate, infinite_sites=False)
                if show_progress:
                    progress.update()
        return data
        
### SUPPLEMENTARY MATERIAL
### The following classes are used for figures in the supplementary material
###

class MetricsBySampleSizeDataset(Dataset):
    """
    Accuracy of ARG inference of a fixed subset of samples (measured by various statistics)
    as the population sample size increases.
    """
    name = "metrics_by_sample_size"
    tools = [TSINFER]
    default_replicates = 50
    default_seed = 123
    #to make this a fair comparison, we need to calculate only at the specific variant sites
    #because different sample sizes will be based on different original variant positions
    #which are then cut down to the subsampled ones.
    compute_tree_metrics = METRICS_ON | METRICS_AT_VARIANT_SITES # | METRICS_RANDOMLY_BREAK_POLYTOMIES

    #for a tidier csv file, we can exclude any of the save_stats values or ARGmetrics columns
    exclude_colnames =[]


    def run_simulations(self, replicates, seed, show_progress, num_processes=1):
        if replicates is None:
            replicates = self.default_replicates
        if seed is None:
            seed = self.default_seed
        rng = random.Random(seed)

        # Variable parameters
        lengths = [10000, 100000, 1000000]
        error_rates = [0, 0.001, 0.01]
        sample_sizes = [12, 50, 100, 500, 1000]
        shared_breakpoint_params = [True]#, False]
        shared_length_params = [False]#, True]

        # Fixed parameters
        subsample_size=10
        assert subsample_size <= min(sample_sizes)
        Ne = 5000
        mutation_rate = 1e-8
        recombination_rate = 1e-8
        num_rows = replicates * len(lengths) * len(error_rates) * len(sample_sizes) * \
            len(shared_breakpoint_params) * len(shared_length_params)
        cols = self.sim_cols + ["tsinfer_srb", "tsinfer_sl", "subsample_size"]
        data = pd.DataFrame(index=np.arange(0, num_rows), columns=cols)
        row_id = 0
        if show_progress:
            progress = tqdm.tqdm(total=num_rows)
        for replicate in range(replicates):
            for length in lengths:
                while True:
                    replicate_seed = rng.randint(1, 2**31)
                    try:
                        # Run the simulation until we get an acceptable one
                        base_ts, unused_fn = self.single_simulation(max(sample_sizes), Ne, length,
                            recombination_rate, mutation_rate, replicate_seed)
                        break
                    except ValueError as e: #No non-singleton variants
                        logging.warning(e)
                #Take the same base simulation and sample down to get comparable test sets
                for sample_size in sample_sizes:
                    ts = base_ts.simplify(list(range(sample_size)))
                    fn = mk_sim_name(sample_size, Ne, length, recombination_rate, mutation_rate,
                        replicate_seed, directory=self.simulations_dir)
                    #subsample to produce a nexus file for metric comparison
                    subsampled_fn=add_subsample_param_to_name(fn, subsample_size)
                    subsampled_ts = ts.simplify(list(range(subsample_size)))
                    with open(subsampled_fn +".nex", "w+") as out:
                        subsampled_ts.write_nexus_trees(out)
                    self.save_positions(subsampled_ts, subsampled_fn)
                    # Add the rows for each of the error rates in this replicate
                    for tsinfer_srb in shared_breakpoint_params:
                        for tsinfer_sl in shared_length_params:
                            for error_rate in error_rates:
                                row = data.iloc[row_id]
                                row_id += 1
                                row.sample_size = sample_size
                                row.recombination_rate = recombination_rate
                                row.mutation_rate = mutation_rate
                                row.length = length
                                row.Ne = Ne
                                row.tsinfer_srb = tsinfer_srb
                                row.tsinfer_sl = tsinfer_sl
                                row.subsample_size = subsample_size
                                row.seed = replicate_seed
                                row[ERROR_COLNAME] = error_rate
                                row.edges = subsampled_ts.num_edges
                                row.n_trees = subsampled_ts.num_trees
                                self.save_variant_matrices(ts, fn, error_rate,
                                    #infinite_sites=True)
                                    infinite_sites=False)
                                if show_progress:
                                    progress.update()
        return data

class MetricsByMutationRateWithDemographyDataset(Dataset):
    """
    Accuracy of ARG inference (measured by various statistics)
    tending to fully accurate as mutation rate increases, but with a
    demographic (out of africa) model superimposed.
    """

    name = "metrics_by_mutation_rate_with_demography"

    default_replicates = 50
    default_seed = 123
    compute_tree_metrics = METRICS_ON #| METRICS_RANDOMLY_BREAK_POLYTOMIES

    #for a tidier csv file, we can exclude any of the save_stats values or ARGmetrics columns
    exclude_colnames =[]

    def run_simulations(self, replicates, seed, show_progress, num_processes=1):
        self.replicates = replicates if replicates else self.default_replicates
        rng = random.Random(seed if seed else self.default_seed)
        ## Variable parameters
        # parameters unique to each simulation
        self.mutation_rates = (np.logspace(-8.5, -5, num=6)[:-1] * 1.5)
        self.sample_sizes = [15] #will be split across the 3 human sub pops
        # parameters across a single simulation
        self.error_rates = [0, 0.001, 0.01]

        ## Fixed parameters
        self.length = 100000
        self.recombination_rate = 1e-8

        self.num_sims = self.replicates * len(self.mutation_rates) * len(self.sample_sizes)
        self.num_rows = self.num_sims * len(self.error_rates)

        data = pd.DataFrame(index=np.arange(0, self.num_rows), columns=self.sim_cols)
        progress = tqdm.tqdm(total=self.num_rows) if show_progress else None

        def save_result(data, values_by_row, progress):
            for i,d in values_by_row.items():
                for colname, val in d.items():
                    data.iloc[i][colname]=val
                if progress is not None:
                    progress.update()

        logging.info("Setting up using {} processes".format(num_processes))
        variable_iterator = itertools.product(
            range(self.replicates), self.mutation_rates,  self.sample_sizes)
        seeds = [rng.randint(1, 2**31) for i in range(self.num_sims)]
        combined_iterator = enumerate(itertools.zip_longest(seeds, variable_iterator))

        if num_processes > 1:
            with multiprocessing.Pool(processes=num_processes, maxtasksperchild=2) as pool:
                for result in pool.imap_unordered(self.single_sim, combined_iterator):
                    save_result(data, result, progress)
        else:
            # When we have only one process it's easier to keep everything in the same
            # process for debugging.
            for result in map(self.single_sim, combined_iterator):
                save_result(data, result, progress)
        return data

    def single_sim(self, runtime_information):
        sim_name = "Gutenkunst.out.of.africa"
        i, (params) = runtime_information
        assert None not in params #one will be none if the lengths of the iterators are different
        rng_seed, (replicate, mutation_rate, sample_size) = params
        row_id = i * self.num_rows//self.num_sims #sims may have multiple rows, one for each error rate
        return_value = {}
        rng = random.Random(rng_seed)
        while True:
            replicate_seed = rng.randint(1, 2**31)
            try:
                # Run the simulation until we get an acceptable one
                ts, fn = self.single_simulation_with_human_demography(
                    sample_size, sim_name, self.length,
                    self.recombination_rate, mutation_rate, replicate_seed)
                break
            except ValueError as e: #No non-singleton variants
                logging.warning(e)
        with open(fn +".nex", "w+") as out:
            ts.write_nexus_trees(out)
        for error_rate in self.error_rates:
            row = return_value[row_id] = {}
            row_id += 1
            row['sample_size'] = sample_size
            row['recombination_rate'] = self.recombination_rate
            row['mutation_rate'] = mutation_rate
            row['length'] = self.length
            row['Ne'] = sim_name
            row['seed'] = replicate_seed
            row[ERROR_COLNAME] = error_rate
            row['edges'] = ts.num_edges
            row['n_trees'] = ts.num_trees
            self.save_variant_matrices(ts, fn, error_rate, infinite_sites=False)
        return return_value

class MetricsByMutationRateWithSelectiveSweepDataset(Dataset):
    """
    Accuracy of ARG inference (measured by various statistics)
    tending to fully accurate as mutation rate increases, but with a
    selective sweep superimposed.

    The time since / post sweep is likely to be a major factor in
    misfitting the model. We judge this by stopping the sweep at a
    specific frequency, or at a given number of generations post fixation.
    """

    name = "metrics_by_mutation_rate_with_selective_sweep"

    default_replicates = 50
    default_seed = 123
    compute_tree_metrics = METRICS_ON #| METRICS_RANDOMLY_BREAK_POLYTOMIES

    #for a tidier csv file, we can exclude any of the save_stats values or ARGmetrics columns
    exclude_colnames =[]

    def run_simulations(self, replicates, seed, show_progress, num_processes=1):
        self.replicates = replicates if replicates else self.default_replicates
        rng = random.Random(seed if seed else self.default_seed)
        ## Variable parameters
        # parameters unique to each simulation
        self.mutation_rates = (np.logspace(-8.5, -5, num=6)[:-1] * 1.5)
        self.sample_sizes = [15]
        # parameters across a single simulation
        self.error_rates = [0, 0.001, 0.01]
        self.stop_at = ['0.2', '0.5', '0.8', '1.0', ('1.0', 200), ('1.0', 1000)] #frequencies to output a file.
        #NB - these are strings because they are output as part of the filename

        ## Fixed parameters
        self.Ne = 5000
        self.length = 100000
        self.recombination_rate = 1e-8
        self.selection_coefficient = 0.1
        self.dominance_coefficient = 0.5

        self.num_sims = self.replicates * len(self.mutation_rates) * len(self.sample_sizes)
        self.num_rows = self.num_sims * len(self.error_rates) * len(self.stop_at)

        cols = self.sim_cols + [SIMTOOL_COLNAME, SELECTION_COEFF_COLNAME,
            DOMINANCE_COEFF_COLNAME, SELECTED_FREQ_COLNAME, SELECTED_POSTGEN_COLNAME]
        data = pd.DataFrame(index=np.arange(0, self.num_rows), columns=cols)
        progress = tqdm.tqdm(total=self.num_rows) if show_progress else None


        def save_result(data, values_by_row, progress):
            for i,d in values_by_row.items():
                for colname, val in d.items():
                    data.iloc[i][colname]=val
                if progress is not None:
                    progress.update()

        logging.info("Setting up using {} processes".format(num_processes))
        variable_iterator = itertools.product(
            range(self.replicates), self.mutation_rates,  self.sample_sizes)
        seeds = [rng.randint(1, 2**31) for i in range(self.num_sims)]
        combined_iterator = enumerate(itertools.zip_longest(seeds, variable_iterator))

        if num_processes > 1:
            with multiprocessing.Pool(processes=num_processes, maxtasksperchild=2) as pool:
                for result in pool.imap_unordered(self.single_sim, combined_iterator):
                    save_result(data, result, progress)
        else:
            # When we have only one process it's easier to keep everything in the same
            # process for debugging.
            for result in map(self.single_sim, combined_iterator):
                save_result(data, result, progress)
        return data

    def single_sim(self, runtime_information):
        i, (params) = runtime_information
        assert None not in params #one will be none if the lengths of the iterators are different
        rng_seed, (replicate, mutation_rate, sample_size) = params
        base_row_id = i * self.num_rows//self.num_sims
        return_value = {}
        rng = random.Random(rng_seed)
        while True:
            replicate_seed = rng.randint(1, 2**31)
            logging.info("Running simulation {} of {} in process {} using " \
                "n={}, Ne={}, L={}, rho={}, mu={}, s={}, h={} " \
                "stopping at frequencies {}, and with seed {}".format(
                i, self.num_sims, os.getpid(), sample_size, self.Ne, self.length,
                self.recombination_rate, mutation_rate, self.selection_coefficient,
                self.dominance_coefficient, self.stop_at, replicate_seed))
            try:
                #we have multiple rows per simulation for results after different generations post-fixation
                #save the base number here, which will be incremented
                row_id = base_row_id 
                # Run the simulation, in parallel if necessary - and loop through the returned freqs
                # Reject this entire set if we got no mutations at any point, or all mutations are fixed
                for ts, fn, output_info in self.single_simulation_with_selective_sweep(
                    sample_size, self.Ne, self.length, self.recombination_rate,
                    mutation_rate, self.selection_coefficient, self.dominance_coefficient,
                    self.stop_at, replicate_seed):
                        with open(fn +".nex", "w+") as out:
                            ts.write_nexus_trees(out)
                        for error_rate in self.error_rates:
                            row = return_value[row_id] = {}
                            row_id += 1
                            row['sample_size'] = sample_size
                            row['recombination_rate'] = self.recombination_rate
                            row['mutation_rate'] = mutation_rate
                            row['length'] = self.length
                            row['Ne'] = self.Ne
                            row['seed'] = replicate_seed
                            row[ERROR_COLNAME] = error_rate
                            row['edges'] = ts.num_edges
                            row['n_trees'] = ts.num_trees
                            row[SIMTOOL_COLNAME] = "ftprime"
                            row[SELECTION_COEFF_COLNAME] = self.selection_coefficient
                            row[DOMINANCE_COEFF_COLNAME] = self.dominance_coefficient
                            row[SELECTED_FREQ_COLNAME] = output_info[0]
                            row[SELECTED_POSTGEN_COLNAME] = output_info[1] if len(output_info)>1 else 0
                            self.save_variant_matrices(ts, fn, error_rate, infinite_sites=False)
                break #not rejected, can finish
            except ValueError as e: #No non-singleton variants
                logging.warning(e)

            except (_msprime.LibraryError, MemoryError) as e:
                #we sometimes run out of memory here
                print("Error when running `single_sim()`, probably in" +
                    "single_simulation_with_selective_sweep({},{},{},{},{},{},{},{},{})".format(
                    sample_size, self.Ne, self.length, self.recombination_rate,
                    mutation_rate, self.selection_coefficient, self.dominance_coefficient,
                    self.stop_at, replicate_seed))
                raise
        return return_value

### ADDITIONAL DEBUG
### The following classes are used for drilling down into particular features
### of the data, e.g. why we do better than AW for high mutation rates, 
### some debugging routines, etc.
###


class ARGweaverParamChanges(Dataset):
    """
    Accuracy of ARGweaver inference (measured by various tree statistics)
    as we adjust burn-in time and number of time slices.
    This is an attempt to explain why ARGweaver can do badly e.g. for high mutation rates

    You can check that the timeslices really *are* having an effect by looking at the unique
    times (field 3) in the .arg files within raw__NOBACKUP__/argweaver_param_changes e.g.
    cut -f 3 data/raw__NOBACKUP__/argweaver_param_changes/simulations/<filename>.arg | sort | uniq
    """
    name = "argweaver_param_changes"
    tools = [ARGWEAVER, TSINFER]
    default_replicates = 40
    default_seed = 123
    compute_tree_metrics = METRICS_ON

    #for a tidier csv file, we can exclude any of the save_stats values or ARGmetrics columns
    exclude_colnames =[]


    def run_simulations(self, replicates, seed, show_progress, num_processes=1):
        if replicates is None:
            replicates = self.default_replicates
        if seed is None:
            seed = self.default_seed
        rng = random.Random(seed)
        # Variable parameters
        mutation_rates = np.logspace(-8, -3, num=8)[:-1] * 1.5
        error_rates = [0]
        sample_sizes = [6]
        AW_burnin_steps = [1000,2000,5000] #by default, bin/arg-sim has no burnin time
        AW_num_timepoints = [20,60,200] #by default, bin/arg-sim has n=20
        # Fixed parameters
        Ne = 5000
        length = 10000
        recombination_rate = 2.5e-8
        num_rows = replicates * len(mutation_rates) * len(error_rates) * len(sample_sizes) * \
            len(AW_burnin_steps) * len(AW_num_timepoints)
        cols = self.sim_cols + ["only_AW", "ARGweaver_burnin", "ARGweaver_ntimes"]
        data = pd.DataFrame(index=np.arange(0, num_rows), columns=cols)
        row_id = 0
        if show_progress:
            progress = tqdm.tqdm(total=num_rows)
        for replicate in range(replicates):
            for mutation_rate in mutation_rates:
                for sample_size in sample_sizes:
                    while True:
                        replicate_seed = rng.randint(1, 2**31)
                        try:
                            # Run the simulation
                            ts, fn = self.single_simulation(
                                sample_size, Ne, length, recombination_rate, mutation_rate,
                                replicate_seed, replicate_seed)
                            break;
                        except ValueError as e: #No non-singleton variants
                            logging.warning(e)
                    with open(fn +".nex", "w+") as out:
                        ts.write_nexus_trees(out)
                    # Add the rows for each of the error rates in this replicate
                    for error_rate in error_rates:
                        only_run_ARGweaver_inference = 0
                        #set up new rows for each set of ARGweaver parameters
                        for burnin in AW_burnin_steps:
                            for n_timesteps in AW_num_timepoints:
                                row = data.iloc[row_id]
                                row_id += 1
                                row.sample_size = sample_size
                                row.recombination_rate = recombination_rate
                                row.mutation_rate = mutation_rate
                                row.length = length
                                row.Ne = Ne
                                row.seed = replicate_seed
                                row[ERROR_COLNAME] = error_rate
                                row.edges = ts.num_edges
                                row.n_trees = ts.num_trees
                                row.ARGweaver_burnin = burnin
                                row.ARGweaver_ntimes = n_timesteps
                                row.only_AW = only_run_ARGweaver_inference
                                #only run other infers for the first row in this set of AW run parameters
                                only_run_ARGweaver_inference = 1
                        self.save_variant_matrices(ts, fn, error_rate,
                            #infinite_sites=True)
                            infinite_sites=False)
                        if show_progress:
                            progress.update()
        return data

class TsinferTracebackDebug(Dataset):
    """
    This class can be deleted once the issue below is addressed

    As discussed between Yan and Jerome on 4th Dec, running the current
    implementation of tsinfer in real data is not giving good enough performance
    in terms of the number of inferred vs real edges. Jerome thinks this is because
    of the traceback process. In particular, there are multiple routes
    back through the L&S traceback matrix which have the maximum (normalised)
    likelihood calculated as 1. Previously we simply took the one that involved
    the oldest ancestor: there are many different recent ancestors with L=1, but
    fewer older ancestors with L=1, so picking e.g. the most recent ancestor leads
    to essentially arbitrary resolving of branch points on the trees, whereas
    picking the oldest means that ancestors inferred for different rows end up
    pointing to the same parent (creating a polytomy), which can then be compressed
    and resolved sensibly, resulting in better compression.  Jerome has been trying
    to improve the choice of which ancestor to pick by keeping a pool of all the
    ancestors which start out with L=1 and taking e.g. the one that results in the
    longest L=1 stretch back along the genome. However, this seems to make only
    about a 5% difference.

    This dataset is a first sally into the problem, by using a dataset large enough
    to reveal the problem (n=1000, Ne=10e4, rho=1e-8, l=2Mb) and gradually
    cranking up the mutation rate, which we hope will allow better resolution of the
    trees (hopefully by reducing the number of L=1 paths). We can then try to spot
    features of the correct L=1 paths that will help us pick a method to choose
    between equally likely paths under lower mutation rates.

    We run the simulations with different mutation rates using the same TS, to
    reduce one source of variation

    Note that one problem is that we may create too many ancestors, as we create a
    new ancestor for each possible permutation of variants at a locus,
    but a single ancestor may have more than one permutation, if there have been
    later recombinations which swap the ancestral state back into a subset of the
    descendants of that ancestor. This may result in more edges than strictly
    necessary.
    """
    name = "tsinfer_traceback_debug"
    compute_tree_metrics = METRICS_OFF
    default_replicates = 10
    default_seed = 123
    tools = [TSINFER]

    def run_simulations(self, replicates, seed, show_progress, num_processes=1):
        # TODO abstract some of this functionality up into the superclass.
        # There is quite a lot shared with the other dataset.
        self.replicates = replicates if replicates else self.default_replicates
        self.seed = seed if seed else self.default_seed
        rng = random.Random(self.seed)
        # Variable parameters
        self.mutation_rates = (np.logspace(-8, -5, num=6)[:-1] * 1.5)
        self.shared_breakpoint_params = [True]#, False]
        self.shared_length_params = [False]#, True]
        self.error_rates = [0]
        # Fixed parameters
        self.Ne = 5000
        self.sample_size = 1000
        self.length = 10**6
        self.recombination_rate = 2e-8
        self.num_sims = self.replicates * len(self.mutation_rates)
        self.num_rows = self.num_sims * len(self.error_rates) * \
            len(self.shared_breakpoint_params) * len(self.shared_length_params)
        cols = self.sim_cols + [MUTATION_SEED_COLNAME, "ts_filesize", "tsinfer_srb", "tsinfer_sl"]
        data = pd.DataFrame(index=np.arange(0, self.num_rows), columns=cols)
        progress = tqdm.tqdm(total=self.num_rows) if show_progress else None

        def save_result(data, values_by_row, progress):
            for i,d in values_by_row.items():
                for colname, val in d.items():
                    data.iloc[i][colname]=val
                if progress is not None:
                    progress.update()

        logging.info("Setting up using {} processes".format(num_processes))
        replicate_seeds = [rng.randint(1, 2**31) for i in range(self.replicates)]
        mutation_seeds = [rng.randint(1, 2**31) for i in range(self.num_sims)]
        variable_iterator = itertools.product(
            replicate_seeds, self.mutation_rates)

        combined_iterator = enumerate(itertools.zip_longest(mutation_seeds, variable_iterator))

        if num_processes > 1:
            with multiprocessing.Pool(processes=num_processes, maxtasksperchild=2) as pool:
                for result in pool.imap_unordered(self.single_sim, combined_iterator):
                    save_result(data, result, progress)
        else:
            # When we have only one process it's easier to keep everything in the same
            # process for debugging.
            for result in map(self.single_sim, combined_iterator):
                save_result(data, result, progress)
        return data

    def single_sim(self, runtime_information):
        i, (params) = runtime_information
        assert None not in params #one will be none if the lengths of the iterators are different
        mutation_seed, (replicate_seed, mutation_rate) = params
        base_row_id = i * self.num_rows//self.num_sims
        return_value = {}
        ts, fn = self.single_simulation(self.sample_size, self.Ne, self.length,
            self.recombination_rate, mutation_rate, replicate_seed, mutation_seed)
        row_id = base_row_id
        for error_rate in self.error_rates:
            for tsinfer_srb in self.shared_breakpoint_params:
                for tsinfer_sl in self.shared_length_params:
                    row = return_value[row_id] = {}
                    row_id += 1
                    row['sample_size'] = self.sample_size
                    row['recombination_rate'] = self.recombination_rate
                    row['mutation_rate'] = mutation_rate
                    row['length'] = self.length
                    row['Ne'] = self.Ne
                    row['seed'] = replicate_seed
                    row[MUTATION_SEED_COLNAME] = mutation_seed
                    row[ERROR_COLNAME] = error_rate
                    row['n_trees'] = ts.num_trees
                    row['edges'] = ts.num_edges
                    row['tsinfer_srb'] = tsinfer_srb
                    row['tsinfer_sl'] = tsinfer_sl
                    row['ts_filesize'] = os.path.getsize(fn + ".hdf5")
                    self.save_variant_matrices(ts, fn, error_rate, infinite_sites=False)
        return return_value


######################################
#
# Figures
#
######################################

class Figure(object):
    """
    Superclass of all figures. Each figure depends on a dataset.
    """
    datasetClass = None
    name = None
    figures_dir = "figures"
    tools_format = collections.OrderedDict([
        (TSINFER,   {"mark":"*", "col":"blue"}),
        (RENTPLUS,  {"mark":"s", "col":"red"}),
        (ARGWEAVER, {"mark":"o", "col":"green"}),
        (FASTARG,   {"mark":"^", "col":"magenta"}),
    ])
    """
    Each figure has a unique name. This is used as the identifier and the
    file name for the output plots.
    """

    def __init__(self):
        self.dataset = self.datasetClass()
        self.dataset.load_data()

    def savefig(self, *figures):
        filename = os.path.join(self.figures_dir, "{}.pdf".format(self.name))
        with matplotlib.backends.backend_pdf.PdfPages(filename) as pdf:
            for fig in figures:
                pdf.savefig(fig)

    def plot(self):
        raise NotImplementedError()


class AllMetricsByMutationRateFigure(Figure):
    """
    Simple figure that shows all the metrics at the same time.
    """
    datasetClass = MetricsByMutationRateDataset
    name = "all_metrics_by_mutation_rate"

    def plot(self):
        df = self.dataset.data
        error_rates = df[ERROR_COLNAME].unique()
        sample_sizes = df.sample_size.unique()
        metrics = ARG_metrics.get_metric_names()
        topology_only_metrics = [m for m in metrics if not m.startswith('w')]
        fig, axes = pyplot.subplots(len(topology_only_metrics),
            len(error_rates), figsize=(6*len(error_rates), 20))
        linestyles = ["-", "-."]
        for j, metric in enumerate(topology_only_metrics):
            for k, error_rate in enumerate(error_rates):
                ax = axes[j][k]
                if j == 0:
                    ax.set_title("Error = {}".format(error_rate))
                if k == 0:
                    ax.set_ylabel(metric + " metric")
                if j == len(topology_only_metrics) - 1:
                    ax.set_xlabel("Mutation rate")
                for n, linestyle in zip(sample_sizes, linestyles):
                    df_s = df[np.logical_and(df.sample_size == n, df[ERROR_COLNAME] == error_rate)]
                    group = df_s.groupby(["mutation_rate"])
                    group_mean = group.mean()
                    for tool, setting in self.tools_format.items():
                        colname = tool + "_" + metric
                        if colname in df.columns:
                            ax.semilogx(group_mean[colname], linestyle, color=setting["col"])
        artists = [
            pyplot.Line2D((0,1),(0,0), color= setting["col"],
                marker= setting["mark"], linestyle='')
            for tool,setting in self.tools_format.items()]
        first_legend = axes[0][0].legend(
            artists, self.tools_format.keys(), numpoints=3, loc="upper right")
            # bbox_to_anchor=(0.0, 0.1))
        # ax = pyplot.gca().add_artist(first_legend)
        if len(sample_sizes)>1:
            artists = [
                pyplot.Line2D(
                    (0,0),(0,0), color="black", linestyle=linestyle, linewidth=2)
                for linestyle in linestyles]
            axes[0][-1].legend(
                artists, ["Sample size = {}".format(n) for n in sample_sizes],
                loc="upper right")
        fig.suptitle("Tree comparisons for neutral simulations" +
            " over "  + ",".join(["{:.1f}kb".format(x/1e3) for x in df.length.unique()]) +
            " (Ne=" + ",".join(["{}".format(x) for x in df.Ne.unique()]) +
            " rho="+ ",".join(["{}".format(x) for x in df.recombination_rate.unique()]) +
            ")", fontsize=16)
        self.savefig(fig)


class MetricByMutationRateFigure(Figure):
    """
    Superclass of the metric by mutations rate figure. Each subclass should be a
    single figure for a particular metric.
    """
    datasetClass = MetricsByMutationRateDataset


    def plot(self):
        df = self.dataset.data
        error_rates = df[ERROR_COLNAME].unique()
        sample_sizes = df.sample_size.unique()

        linestyles = ["-", ":"]
        fig, axes = pyplot.subplots(1, len(error_rates), figsize=(12, 6), sharey=True)
        lines = []
        for k, error_rate in enumerate(error_rates):
            ax = axes[k]
            ax.set_title("Error = {}".format(error_rate))
            ax.set_xlabel("Mutation rate")
            ax.set_xscale('log')
            if k == 0:
                ax.set_ylabel(self.metric + " metric")
            for n, linestyle in zip(sample_sizes, linestyles):
                df_s = df[np.logical_and(df.sample_size == n, df[ERROR_COLNAME] == error_rate)]
                group = df_s.groupby(["mutation_rate"])
                mean_sem = [{'mu':g, 'mean':data.mean(), 'sem':data.sem()} for g, data in group]
                for tool,setting in self.tools_format.items():
                    if getattr(self, 'error_bars', None):
                        yerr=[m['sem'][tool + "_" + self.metric] for m in mean_sem]
                    else:
                        yerr = None
                    ax.errorbar(
                        [m['mu'] for m in mean_sem],
                        [m['mean'][tool + "_" + self.metric] for m in mean_sem],
                        yerr=yerr,
                        linestyle=linestyle,
                        color=setting["col"],
                        marker=setting["mark"],
                        elinewidth=1)

        axes[0].set_ylim(self.ylim)

        # Create legends from custom artists
        artists = [
            pyplot.Line2D((0,1),(0,0), color= setting["col"],
                marker= setting["mark"], linestyle='')
            for tool,setting in self.tools_format.items()]
        first_legend = axes[0].legend(
            artists, self.tools_format.keys(), numpoints=3, loc="upper center")
            # bbox_to_anchor=(0.0, 0.1))
        # ax = pyplot.gca().add_artist(first_legend)
        if len(sample_sizes)>1:
            artists = [
                pyplot.Line2D(
                    (0,0),(0,0), color="black", linestyle=linestyle, linewidth=2)
                for linestyle in linestyles]
            axes[-1].legend(
                artists, ["Sample size = {}".format(n) for n in sample_sizes],
                loc="upper center")
        self.savefig(fig)


class RFRootedMetricByMutationRateFigure(MetricByMutationRateFigure):
    name = "rf_rooted_by_mutation_rate"
    metric = "RFrooted"
    ylim = None


class KCRootedMetricByMutationRateFigure(MetricByMutationRateFigure):
    name = "kc_rooted_by_mutation_rate"
    metric = "KCrooted"
    ylim = (0, 40)
    error_bars = True

class CputimeMetricByMutationRateFigure(MetricByMutationRateFigure):
    """
    This figure is useful because we can only really get the CPU times
    for all four methods in the same scale for these tiny examples.
    We can show that ARGWeaver and RentPlus are much slower than tsinfer
    and FastARG here and compare tsinfer and FastARG more thoroughly
    in a dedicated figure.
    """
    name = "cputime_by_mutation_rate"

    def plot(self):
        df = self.dataset.data
        sample_sizes = df.sample_size.unique()

        linestyles = ["-", ":"]

        fig, ax = pyplot.subplots(1, 1)
        lines = []
        error_rate = 0
        n = 50
        ax.set_xlabel("Mutation rate")
        ax.set_ylabel("CPU time (sec)")
        df_s = df[np.logical_and(df.sample_size == n, df[ERROR_COLNAME] == error_rate)]
        group = df_s.groupby(["mutation_rate"])
        group_mean = group.mean()
        for tool, setting in self.tools_format.items():
            ax.semilogx(
                group_mean[tool + "_" + "cputime"],
                color=setting["col"],
                marker=setting["mark"],
                label=tool)
        ax.legend(loc="center left")
        ax.set_ylim(-20, 1000)
        self.savefig(fig)

class AllMetricsByMutationRateSweepFigure(Figure):
    """
    Simple figure that shows all the metrics at the same time for
    a genome under a selective sweep
    """
    datasetClass = MetricsByMutationRateWithSelectiveSweepDataset
    name = "all_metrics_by_mutation_rate_sweep"

    def plot(self):
        df = self.dataset.data
        error_rates = df[ERROR_COLNAME].unique()
        output_freqs = df[[SELECTED_FREQ_COLNAME, SELECTED_POSTGEN_COLNAME]].drop_duplicates()
        sample_sizes = df.sample_size.unique()

        metrics = ARG_metrics.get_metric_names()
        topology_only_metrics = [m for m in metrics if not m.startswith('w')]
        figures = [] #save figures for putting onto a multi-page pdf
        for error_rate in error_rates:
            fig, axes = pyplot.subplots(len(topology_only_metrics),
                len(output_freqs), figsize=(20, 20))
            fig.suptitle("Error-rate = {}".format(error_rate))
            linestyles = ["-", "-.", ":"]
            for j, metric in enumerate(topology_only_metrics):
                for k, output_data in output_freqs.iterrows():
                    freq = output_data[0]
                    gens = output_data[1]
                    ax = axes[j][k]
                    ax.set_xscale('log')
                    if j == 0:
                        ax.set_title("Swept variant @ freq {}{}".format(
                            freq, "+{} gens".format(int(gens)) if gens else ""))
                    if k == 0:
                        ax.set_ylabel(metric + " metric")
                    if j == len(topology_only_metrics) - 1:
                        ax.set_xlabel("Mutation rate")
                    for n, linestyle in zip(sample_sizes, linestyles):
                        df_s = df[np.logical_and.reduce((
                            df.sample_size == n,
                            df[ERROR_COLNAME] == error_rate,
                            df[SELECTED_FREQ_COLNAME] == freq,
                            df[SELECTED_POSTGEN_COLNAME] == gens))]
                        group = df_s.groupby(["mutation_rate"])
                        #NB pandas.DataFrame.mean and pandas.DataFrame.sem have skipna=True by default
                        mean_sem = [{'mu':g, 'mean':data.mean(), 'sem':data.sem()} for g, data in group]
                        for tool, setting in self.tools_format.items():
                            if all(np.isnan(m['mean'][tool + "_" + metric]) for m in mean_sem):
                                #don't plot if all NAs
                                continue
                            ax.errorbar(
                                [m['mu'] for m in mean_sem],
                                [m['mean'][tool + "_" + metric] for m in mean_sem],
                                yerr=[m['sem'][tool + "_" + metric] for m in mean_sem] \
                                    if getattr(self, 'error_bars') else None,
                                color=setting["col"],
                                linestyle= linestyle,
                                marker=setting["mark"], fillstyle='none',
                                elinewidth=1)

            # Create legends from custom artists
            artists = [
                pyplot.Line2D((0,1),(0,0), color= setting["col"],
                    marker= setting["mark"], linestyle='')
                for tool,setting in self.tools_format.items()]
            first_legend = axes[0][0].legend(
                artists, self.tools_format.keys(), numpoints=3, loc="upper right")
            artists = [
                pyplot.Line2D(
                    (0,0),(0,0), color="black", linestyle=linestyle, linewidth=2)
                for linestyle in linestyles]
            axes[1][0].legend(
                artists, ["Sample size = {}".format(n) for n in sample_sizes],
                loc="upper right")
            figures.append(fig)
        self.savefig(*figures)

class AllMetricsBySampleSizeFigure(Figure):
    """
    Figure that shows whether increasing sample size helps with the accuracy of
    reconstructing the ARG for a fixed subsample.
    """
    datasetClass = MetricsBySampleSizeDataset
    name = "all_metrics_by_sample_size"
    error_bars=True

    def plot(self):
        df = self.dataset.data
        lengths = df.length.unique()
        subsample_size = df.subsample_size.unique()
        assert len(subsample_size) == 1
        col="black"
        inferred_linestyles = {False:{False:':',True:'-.'},True:{False:'--',True:'-'}}
        metrics = ARG_metrics.get_metric_names()
        topology_only_metrics = [m for m in metrics if not m.startswith('w')]
        fig, axes = pyplot.subplots(len(topology_only_metrics),
            len(lengths), figsize=(12, 16))
        lines = []
        for j, metric in enumerate(topology_only_metrics):
            for k, length in enumerate(lengths):
                ax = axes[j][k]
                if j == 0:
                    ax.set_title("Sequence length = {} Kb".format(int(length/1000)))
                if k == 0:
                    ax.set_ylabel(metric + " metric")
                if j == len(topology_only_metrics) - 1:
                    ax.set_xlabel("Original sample size")
                for shared_breakpoint in df.tsinfer_srb.unique():
                    for shared_length in df.tsinfer_sl.unique():
                        dfp = df[np.logical_and.reduce((
                            df.length == length,
                            df.tsinfer_srb == shared_breakpoint,
                            df.tsinfer_sl == shared_length))]
                        group = dfp.groupby(["sample_size"])
                            #NB pandas.DataFrame.mean and pandas.DataFrame.sem have skipna=True by default
                        mean_sem = [{'mu':g, 'mean':data.mean(), 'sem':data.sem()} for g, data in group]
                        if getattr(self, 'error_bars', None):
                            yerr=[m['sem'] for m in mean_sem]
                        else:
                            yerr = None
                        ax.errorbar(
                            [m['mu'] for m in mean_sem],
                            [m['mean'][TSINFER + "_" + metric] for m in mean_sem],
                            yerr=[m['sem'][TSINFER + "_" + metric] for m in mean_sem] \
                                if getattr(self, 'error_bars', None) else None,
                            color=col,
                            linestyle=inferred_linestyles[shared_breakpoint][shared_length],
                            marker="o", fillstyle='none',
                            elinewidth=1)
        pyplot.suptitle('ARG metric for trees subsampled down to {} tips'.format(
            subsample_size[0]))
        self.savefig(fig)


class MetricByARGweaverParametersFigure(Figure):
    """
    See the effect of burnin time and number of timeslices on the accuracy of ARGweaver
    as compared to TSinfer, when looking at tree metrics.
    """
    datasetClass = ARGweaverParamChanges

    def plot(self):
        df = self.dataset.data
        tools = self.dataset.tools
        AW_burnin = df.ARGweaver_burnin.unique()
        AW_discrete_timeslices = df.ARGweaver_ntimes.unique()

        # TODO move this into the superclass so that we have consistent styling.
        linestyles = [":","-.", "-"]
        fig, axes = pyplot.subplots(1, 3, figsize=(12, 6), sharey=True)
        lines = []
        for k, ntimes in enumerate(AW_discrete_timeslices):
            ax = axes[k]
            ax.set_title("ARGweaver timeslices = {}".format(ntimes))
            ax.set_xlabel("Mutation rate")
            ax.set_xscale('log')
            if k == 0:
                ax.set_ylabel(self.metric + " metric")

            #get the only tsinfer data for this selection (regardless of ntimes)
            tool = TSINFER
            df_s = df[np.logical_not(df[tool + "_" + self.metric].isnull())]
            group = df_s.groupby(["mutation_rate"])
            mean_sem = [{'mu':g, 'mean':data.mean(), 'sem':data.sem()} for g, data in group]
            if getattr(self, 'error_bars', None):
                yerr=[m['sem'][tool + "_" + self.metric] for m in mean_sem]
            else:
                yerr = None
            ax.errorbar(
                [m['mu'] for m in mean_sem],
                [m['mean'][tool + "_" + self.metric] for m in mean_sem],
                yerr=yerr,
                linestyle=linestyles[0],
                color=self.tools_format[tool]["col"],
                marker=self.tools_format[tool]["mark"],
                elinewidth=1)


            for n, linestyle in zip(AW_burnin, linestyles):
                tool = ARGWEAVER
                df_s = df[np.logical_and(df.ARGweaver_burnin == n, df.ARGweaver_ntimes == ntimes)]
                group = df_s.groupby(["mutation_rate"])
                mean_sem = [{'mu':g, 'mean':data.mean(), 'sem':data.sem()} for g, data in group]
                if getattr(self, 'error_bars', None):
                    yerr=[m['sem'][tool + "_" + self.metric] for m in mean_sem]
                else:
                    yerr = None
                ax.errorbar(
                    [m['mu'] for m in mean_sem],
                    [m['mean'][tool + "_" + self.metric] for m in mean_sem],
                    yerr=yerr,
                    linestyle=linestyle,
                    color=self.tools_format[tool]["col"],
                    marker=self.tools_format[tool]["mark"],
                    elinewidth=1)

        axes[0].set_ylim(self.ylim)

        # Create legends from custom artists
        artists = [
            pyplot.Line2D((0,1),(0,0), color=self.tools_format[tool]["col"],
                marker=self.tools_format[tool]["mark"], linestyle='')
            for tool in tools]
        first_legend = axes[0].legend(
            artists, tools, numpoints=3, loc="upper center")
            # bbox_to_anchor=(0.0, 0.1))
        # ax = pyplot.gca().add_artist(first_legend)
        artists = [
            pyplot.Line2D(
                (0,0),(0,0), color="black", linestyle=linestyle, linewidth=2)
            for linestyle in linestyles]
        axes[-1].legend(
            artists, ["Burn in = {} gens".format(n) for n in AW_burnin],
            loc="upper center")
        self.savefig(fig)

class KCRootedMetricByARGweaverParametersFigure(MetricByARGweaverParametersFigure):
    name = "kc_rooted_metrics_by_argweaver_params"
    metric = "KCrooted"
    ylim = (0, 4)
    error_bars = True

class RFRootedMetricByARGweaverParametersFigure(MetricByARGweaverParametersFigure):
    name = "rf_rooted_metrics_by_argweaver_params"
    metric = "RFrooted"
    ylim = None
    #ylim = (0, 4)
    error_bars = True


class PerformanceFigure(Figure):
    """
    Superclass for the performance metrics figures. Each of these figures
    has two panels; one for scaling by sequence length and the other
    for scaling by sample size. Different lines are given for each
    of the different combinations of tsinfer parameters
    """
    datasetClass = TsinferPerformance
    plotted_column = None
    y_axis_label = None

    def plot(self):
        df = self.dataset.data
        # Rescale the length to MB
        df.length /= 10**6
        # Set statistics to the ratio of observed over expected
        source_colour = "red"
        inferred_colour = "blue"
        # inferred_linestyles = {False:{False:':',True:'-.'},True:{False:'-',True:'--'}}
        #inferred_markers =    {False:{False:':',True:'-.'},True:{False:'--',True:'-'}}
        fig, (ax1, ax2) = pyplot.subplots(1, 2, figsize=(12, 6), sharey=True)
        ax1.set_title("Fixed number of chromosomes ({})".format(self.datasetClass.fixed_sample_size))
        ax1.set_xlabel("Sequence length (MB)")
        ax1.set_ylabel(self.y_axis_label)

        dfp = df[df.sample_size == self.datasetClass.fixed_sample_size]
        group = dfp.groupby(["length"])
            #NB pandas.DataFrame.mean and pandas.DataFrame.sem have skipna=True by default
        mean_sem = [{'mu':g, 'mean':data.mean(), 'sem':data.sem()} for g, data in group]
        if getattr(self, 'error_bars', None):
            yerr=[m['sem'] for m in mean_sem]
        else:
            yerr = None
        ax1.errorbar(
            [m['mu'] for m in mean_sem],
            [m['mean'][self.plotted_column] for m in mean_sem],
            yerr=yerr,
            # linestyle=inferred_linestyles[shared_breakpoint][shared_length],
            color=inferred_colour,
            #marker=self.tools_format[tool]["mark"],
            elinewidth=1)

        ax2.set_title("Fixed sequence length ({:.2f} Mb)".format(self.datasetClass.fixed_length / 10**6))
        ax2.set_xlabel("Sample size")
        ax2.set_ylabel(self.y_axis_label)
        dfp = df[df.length == self.datasetClass.fixed_length / 10**6]
        group = dfp.groupby(["sample_size"])
        #NB pandas.DataFrame.mean and pandas.DataFrame.sem have skipna=True by default
        mean_sem = [{'mu':g, 'mean':data.mean(), 'sem':data.sem()} for g, data in group]
        if getattr(self, 'error_bars', None):
            yerr=[m['sem'] for m in mean_sem]
        else:
            yerr = None
        ax2.errorbar(
            [m['mu'] for m in mean_sem],
            [m['mean'][self.plotted_column] for m in mean_sem],
            yerr=yerr,
            # linestyle=inferred_linestyles[shared_breakpoint][shared_length],
            color=inferred_colour,
            #marker=self.tools_format[tool]["mark"],
            elinewidth=1)

        # ax1.plot(group_mean[self.plotted_column],
        #         color=source_colour, linestyle="-", label="Source")
        # ax1.plot(
        #     group_mean["tsinfer_" + self.plotted_column],
        #     color=inferred_colour, linestyle="-", label="Inferred")
        # ax1.legend(
        #     loc="upper left", numpoints=1, fontsize="small")

        # ax1.set_xlim(-5, 105)
        # ax1.set_ylim(-5, 250)
        # ax2.set_xlim(-5, 105)

        # if len(df.tsinfer_srb.unique())>1 or len(df.tsinfer_sl.unique())>1:
        #     params = [
        #         pyplot.Line2D(
        #             (0,0),(0,0), color= inferred_colour,
        #             linestyle=inferred_linestyles[shared_breakpoint][shared_length], linewidth=2)
        #         for shared_breakpoint, linestyles2 in inferred_linestyles.items()
        #         for shared_length, linestyle in linestyles2.items()]
        #     ax1.legend(
        #         params, ["breakpoints={}, lengths={}".format(srb, sl)
        #             for srb, linestyles2 in inferred_linestyles.items()
        #             for sl, linestyle in  linestyles2.items()],
        #         loc="lower right", fontsize=10, title="Polytomy resolution")

        # fig.text(0.19, 0.97, "Sample size = 1000")
        # fig.text(0.60, 0.97, "Sequence length = 50Mb")
        # pyplot.savefig("plots/simulators.pdf")
        pyplot.suptitle(
            'Tsinfer large dataset performance for mu={}'.format(
                self.datasetClass.mutation_rate))
        self.savefig(fig)



class EdgesPerformanceFigure(PerformanceFigure):
    name = "tsinfer_edges_by_length"
    plotted_column = "metric"
    y_axis_label = "inferred_edges / real_edges"
    def plot(self):
        self.dataset.data[self.plotted_column] = (
            self.dataset.data["tsinfer_edges"] / self.dataset.data["edges"])
        PerformanceFigure.plot(self)


class FileSizePerformanceFigure(PerformanceFigure):
    name = "tsinfer_filesize_by_length"
    plotted_column = "metric"
    y_axis_label = "inferred_filesize / real_filesize"
    y_axis_label = "File size relative to original"
    def plot(self):
        self.dataset.data[self.plotted_column] = (
            self.dataset.data["tsinfer_ts_filesize"] / self.dataset.data["ts_filesize"])
        PerformanceFigure.plot(self)


class CompressionPerformanceFigure(PerformanceFigure):
    name = "tsinfer_compression_by_length"
    plotted_column = "metric"
    y_axis_label = "inferred_filesize / real_filesize"
    y_axis_label = "Compression factor relative to vcf.gz"
    def plot(self):
        self.dataset.data[self.plotted_column] = (
             self.dataset.data["vcfgz_filesize"] / self.dataset.data["tsinfer_ts_filesize"])
        PerformanceFigure.plot(self)


class PerformanceFigure2(Figure):
    """
    Class for the performance metrics against sites as well as length
    (the first is the same as the LHS PerformanceFigure, but the second is the
    same using sites instead)
    """
    name="tsinfer_edges_by_sites"
    datasetClass = TsinferPerformance
    plotted_column = None
    y_axis_label = None
    error_bars = True

    def plot(self):
        df = self.dataset.data
        self.dataset.data[self.plotted_column] = self.dataset.data["tsinfer_edges"] / self.dataset.data["edges"]
        # Rescale the length to MB
        df.length /= 10**6
        # Set statistics to the ratio of observed over expected
        source_colour = "red"
        inferred_colour = "blue"
        inferred_linestyles = {False:{False:':',True:'-.'},True:{False:'-',True:'--'}}
        #inferred_markers =    {False:{False:':',True:'-.'},True:{False:'--',True:'-'}}
        fig, (ax1, ax2) = pyplot.subplots(1, 2, figsize=(12, 6), sharey=True)
        ax1.set_title("Fixed number of chromosomes ({})".format(self.datasetClass.fixed_sample_size))
        ax1.set_xlabel("Sequence length (MB)")
        ax1.set_ylabel(self.y_axis_label)
        for shared_breakpoint in df.tsinfer_srb.unique():
            for shared_length in df.tsinfer_sl.unique():
                dfp = df[np.logical_and.reduce((
                    df.sample_size == self.datasetClass.fixed_sample_size,
                    df.tsinfer_srb == shared_breakpoint,
                    df.tsinfer_sl == shared_length))]
                group = dfp.groupby(["length"])
                    #NB pandas.DataFrame.mean and pandas.DataFrame.sem have skipna=True by default
                mean_sem = [{'mu':g, 'mean':data.mean(), 'sem':data.sem()} for g, data in group]
                ax1.errorbar(
                    [m['mu'] for m in mean_sem],
                    [m['mean'][self.plotted_column] for m in mean_sem],
                    yerr=[m['sem'][self.plotted_column] for m in mean_sem] if getattr(self, 'error_bars') else None,
                    linestyle=inferred_linestyles[shared_breakpoint][shared_length],
                    color=inferred_colour,
                    )

        ax2.set_title("Fixed number of chromosomes ({})".format(self.datasetClass.fixed_sample_size))
        ax2.set_xlabel("Number of variable sites")
        ax2.set_ylabel(self.y_axis_label)
        for shared_breakpoint in df.tsinfer_srb.unique():
            for shared_length in df.tsinfer_sl.unique():
                dfp = df[np.logical_and.reduce((
                    df.length == self.datasetClass.fixed_length / 10**6,
                    df.tsinfer_srb == shared_breakpoint,
                    df.tsinfer_sl == shared_length))]
                ax2.plot(
                    dfp['sites'],
                    dfp[self.plotted_column],
                    color=inferred_colour,
                    linestyle="",marker="o")

        pyplot.suptitle('Tsinfer large dataset performance for mu={}'.format(self.datasetClass.mutation_rate))
        self.savefig(fig)


class TracebackDebugFigure(Figure):
    """
    Superclass for the performance metrics figures to debug traceback problems
    """
    datasetClass = TsinferTracebackDebug
    plotted_column = None
    y_axis_label = None

    def plot(self):
        df = self.dataset.data
        source_colour = "red"
        inferred_colour = "blue"
        inferred_linestyles = {False:{False:':',True:'-.'},True:{False:'-',True:'--'}}
        #inferred_markers =    {False:{False:':',True:'-.'},True:{False:'-',True:'--'}}
        fig, (ax1) = pyplot.subplots(1, 1, figsize=(6, 6), sharey=True)
        ax1.set_title("{} samples, seq length = {}Mb, rho = {}".format(
            ",".join("{}".format(x) for x in df.sample_size.unique()),
            ",".join("{:.1f}".format(x) for x in df.length.unique()/1e6),
            ",".join("{}".format(x) for x in df.recombination_rate.unique())))
        ax1.set_xlabel("Mutation rate per bp")
        ax1.set_ylabel(self.y_axis_label)
        ax1.set_xscale('log')
        for shared_breakpoint in df.tsinfer_srb.unique():
            for shared_length in df.tsinfer_sl.unique():
                dfp = df[np.logical_and.reduce((
                    df.tsinfer_srb == shared_breakpoint,
                    df.tsinfer_sl == shared_length))]
                group = dfp.groupby(["mutation_rate"])
                #NB pandas.DataFrame.mean and pandas.DataFrame.sem have skipna=True by default
                mean_sem = [{'mu':g, 'mean':data.mean(), 'sem':data.sem()} for g, data in group]
                ax1.errorbar(
                    [m['mu'] for m in mean_sem],
                    [m['mean'][self.plotted_column] for m in mean_sem],
                    yerr=[m['sem'][self.plotted_column] for m in mean_sem] if getattr(self, 'error_bars') else None,
                    linestyle=inferred_linestyles[shared_breakpoint][shared_length],
                    color=inferred_colour,
                    #marker=self.tools_format[tool]["mark"],
                    elinewidth=1)
        if len(df.tsinfer_srb.unique())>1 or len(df.tsinfer_sl.unique())>1:
            params = [
                pyplot.Line2D(
                    (0,0),(0,0), color= inferred_colour,
                    linestyle=inferred_linestyles[shared_breakpoint][shared_length], linewidth=2)
                for shared_breakpoint, linestyles2 in inferred_linestyles.items()
                for shared_length, linestyle in linestyles2.items()]
            ax1.legend(
                params, ["breakpoints={}, lengths={}".format(srb, sl)
                    for srb, linestyles2 in inferred_linestyles.items()
                    for sl, linestyle in  linestyles2.items()],
                loc="lower right", fontsize=10, title="Polytomy resolution")

        # fig.text(0.19, 0.97, "Sample size = 1000")
        # fig.text(0.60, 0.97, "Sequence length = 50Mb")
        # pyplot.savefig("plots/simulators.pdf")
        pyplot.suptitle('Tsinfer debug performance')
        self.savefig(fig)



class TracebackDebugEdgesFigure(TracebackDebugFigure):
    name = "traceback_debug_edges"
    plotted_column = "metric"
    y_axis_label = "inferred_edges / real_edges"
    error_bars = True
    def plot(self):
        # Set statistics to the ratio of observed over expected
        self.dataset.data[self.plotted_column] = self.dataset.data["tsinfer_edges"] / self.dataset.data["edges"]
        TracebackDebugFigure.plot(self)

class ProgramComparisonFigure(Figure):
    """
    Superclass for the program comparison figures. Each figure
    has two panels; one for scaling by sequence length and the other
    for scaling by sample size.
    """
    datasetClass = ProgramComparison

    def plot(self):
        df = self.dataset.data
        tools = self.dataset.tools

        # Rescale the length to Mb
        length_scale = 10**6
        df.length /= length_scale
        # Scale time to hours
        time_scale = 3600
        for tool in tools:
            df[tool + "_cputime"] /= time_scale
        # Scale memory to GiB
        for tool in tools:
            df[tool + "_memory"] /= 1024 * 1024 * 1024

        fig, (ax1, ax2) = pyplot.subplots(1, 2, sharey=True, figsize=(8, 5.5))

        dfp = df[df.sample_size == self.datasetClass.fixed_sample_size]
        group = dfp.groupby(["length"])
        group_mean = group.mean()

        for tool in tools:
            col = tool + "_" + self.plotted_column
            ax1.plot(group_mean[col], label=tool, color=self.tools_format[tool]["col"])
        ax1.legend(
            loc="upper left", numpoints=1, fontsize="small")

        ax1.set_xlabel("Length (Mb) for fixed sample of {}".format(self.datasetClass.fixed_sample_size))
        ax1.set_ylabel(self.y_label)

        dfp = df[df.length == self.datasetClass.fixed_length / length_scale]
        group = dfp.groupby(["sample_size"])
        group_mean = group.mean()

        for tool in tools:
            col = tool + "_" + self.plotted_column
            ax2.plot(group_mean[col], label=tool, color=self.tools_format[tool]["col"])

        ax2.set_xlabel("Sample size for fixed length of {} Mb".format(
            self.datasetClass.fixed_length / length_scale))

        # ax1.set_xlim(-5, 105)
        # ax1.set_ylim(-5, 250)
        # ax2.set_xlim(-5, 105)

        fig.tight_layout()

        # fig.text(0.19, 0.97, "Sample size = 1000")
        # fig.text(0.60, 0.97, "Sequence length = 50Mb")
        # pyplot.savefig("plots/simulators.pdf")
        self.savefig(fig)


class ProgramComparisonTimeFigure(ProgramComparisonFigure):
    name = "program_comparison_time"
    plotted_column = "cputime"
    y_label = "CPU time (hours)"

class ProgramComparisonMemoryFigure(ProgramComparisonFigure):
    name = "program_comparison_memory"
    plotted_column = "memory"
    y_label = "Memory (GiB)"

def run_setup(cls, args):
    f = cls()
    f.setup(args)

def run_infer(cls, args):
    logging.info("Inferring {}".format(cls.name))
    f = cls()
    f.infer(
        args.processes, args.threads, force=args.force, metrics_only=args.metrics_only,
        specific_tool=args.tool, specific_row=args.row,
        flush_all=args.flush_all, show_progress=args.progress)

def run_plot(cls, args):
    f = cls()
    f.plot()


def main():
    datasets = Dataset.__subclasses__()
    figures = [
        AllMetricsByMutationRateFigure,
        RFRootedMetricByMutationRateFigure,
        KCRootedMetricByMutationRateFigure,
        AllMetricsBySampleSizeFigure,
        CputimeMetricByMutationRateFigure,
        KCRootedMetricByARGweaverParametersFigure,
        RFRootedMetricByARGweaverParametersFigure,
        EdgesPerformanceFigure,
        FileSizePerformanceFigure,
        CompressionPerformanceFigure,
        PerformanceFigure2,
        TracebackDebugEdgesFigure,
        ProgramComparisonTimeFigure,
        ProgramComparisonMemoryFigure,
        AllMetricsByMutationRateSweepFigure,
    ]
    name_map = dict([(d.name, d) for d in datasets + figures])
    parser = argparse.ArgumentParser(
        description="Set up base data, generate inferred datasets, process datasets and plot figures.")
    parser.add_argument('--verbosity', '-v', action='count', default=0)
    subparsers = parser.add_subparsers()
    subparsers.required = True
    subparsers.dest = 'command'

    subparser = subparsers.add_parser('setup')
    subparser.add_argument(
        'name', metavar='NAME', type=str, nargs=1,
        help='the dataset identifier', choices=[d.name for d in datasets])
    subparser.add_argument(
        "--processes", '-p', type=int, default=1,
        help="number of worker processes, e.g. 40")
    subparser.add_argument(
         '--replicates', '-r', type=int, help="number of replicates")
    subparser.add_argument(
         '--seed', '-s', type=int, help="use a non-default RNG seed")
    subparser.add_argument(
         '--hack_finite_sites', action='store_true',
         help="Mutations at the same (integer) location are superimposed, not shifted along")
    subparser.add_argument(
         '--progress',  "-P", action='store_true',
         help="Show a progress bar.", )
    subparser.set_defaults(func=run_setup)

    subparser = subparsers.add_parser('infer')
    subparser.add_argument(
        "--processes", '-p', type=int, default=1,
        help="number of worker processes, e.g. 40")
    subparser.add_argument(
        "--threads", '-t', type=int, default=1,
        help="number of threads per worker process (for supporting tools), e.g. 8")
    subparser.add_argument(
        "--tool", '-T', default=None,
        help="Only run this specific tool")
    subparser.add_argument(
        "--row", '-r', type=int, default=None,
        help="Only run for a specific row")
    subparser.add_argument(
        'name', metavar='NAME', type=str, nargs=1,
        help='the dataset identifier', choices=[d.name for d in datasets])
    subparser.add_argument(
         '--force',  "-f", action='store_true',
         help="redo all the inferences, even if we have already filled out some", )
    subparser.add_argument(
         '--metrics-only',  "-m", action='store_true',
         help="skip the inference step & just re-calculate metrics for already-run sims", )
    subparser.add_argument(
         '--progress',  "-P", action='store_true',
         help="Show a progress bar.", )
    subparser.add_argument(
         '--flush-all',  "-F", action='store_true',
         help="flush the result file after every result.", )
    subparser.set_defaults(func=run_infer)

    subparser = subparsers.add_parser('figure')
    subparser.add_argument(
        'name', metavar='NAME', type=str, nargs=1,
        help='the figure identifier', choices=[f.name for f in figures])
    subparser.set_defaults(func=run_plot)

    args = parser.parse_args()
    log_level = logging.WARNING
    if args.verbosity == 1:
        log_level = logging.INFO
    if args.verbosity >= 2:
        log_level = logging.DEBUG
    logging.basicConfig(
        format='%(asctime)s %(message)s', level=log_level, stream=sys.stdout)

    # Create a new process group and become the leader.
    os.setpgrp()
    k = args.name[0]
    try:
        if k == "all":
            classes = datasets
            if args.func == run_plot:
                classes = figures
            for name, cls in name_map.items():
                if cls in classes:
                    args.func(cls, args)
        else:
            try:
                cls = name_map[k]
            except KeyError as e:
                e.args = (e.args[0] + ". Select from datasets={} or figures={}".format(
                        [d.name for d in datasets], [f.name for f in figures]),)
                raise
            args.func(cls, args)
    except KeyboardInterrupt:
        print("Interrupted! Trying to kill subprocesses")
        os.killpg(0, signal.SIGINT)

if __name__ == "__main__":
    main()
